---
tags: temp
title: Gradient Ascent
date modified: Monday, October 10th 2022, 2:02:26 pm
date created: Tuesday, July 26th 2022, 8:33:15 pm
---

# Gradient Ascent
- To maximize loss function unlike [[Gradient Descent gradients]]
- Proportional to positive of gradient
- $$\theta_{t+1} = \theta{t} + \eta_t \Sigma_{n=1}^N(\nabla l_n(\theta_t))^T$$

## Backlinks
> - [GAN](Generative Models.md)
>   - D : [[Gradient Ascent]]
>
> - [Contrastive [[loss|Loss]]](Contrastive Loss.md)
>   - Minimize distance between similar inputs [[Gradient Descent gradients]], maximize between dissimilar [[Gradient Ascent]]

_Backlinks last generated 2022-10-04 13:01:19_
