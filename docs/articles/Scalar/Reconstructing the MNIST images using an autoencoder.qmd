
---
title: Reconstructing the MNIST images using an autoencoder

categories: ["article"]
date modified: 
date created: 
---
# Reconstructing MNIST images using an Autoencoder

:::section{.abstract}
## Overview
Given noisy images, an **Autoencoder** is a family of models that can convert these noisy images to their original form. These models are unsupervised and use an **Encoder-Decoder** architecture to re-create the original images given **noisy** variants of the same. In the process of re-creation, the model also learns to model the latent space of the dataset.
::: 
:::section{.main}
## Scope
- This article explores the concepts required to build a simple Autoencoder.
- It explains how to implement an Autoencoder using Tensorflow.
- It explains how to use an Autoencoder to re-create MNIST images.
- The article also explains how to train an Autoencoder model and use the trained model for inference.

# What are we building? 
In this article, we will build an Autoencoder in Tensorflow that can re-create MNIST images. We will create functions to load and pre-process the dataset, along with creating noisy versions of the data points. We will create the Encoder-Decoder structure of the Autoencoder and then use the noisy and real images as inputs to it. After training the model, we will use it to generate new images.
The following sections elaborate on these points.
## Pre-requisites
Before moving to the implementation, we must understand some prerequisite terms.
### Transposed Convolution
2D Convolutions compress information from images into smaller representations by [../../Downsampling|downsampling](../../Downsampling|downsampling.qmd) them. Transposed Convolutions perform the opposite operation. These convolutions take compressed/small images and attempt to expand their sizes. An illustration of how this happens is as follows.

[IMAGE {1} Transposed Conv START SAMPLE]
![Transposed Conv](https://hackmd.io/_uploads/S1cHysVqo.gif)
[IMAGE {1} FINISH SAMPLE]

### What are Autoencoders
Autoencoders are models that we created to reduce noise in images. In attempting to learn how to reduce noise, they model the latent space of the dataset. Any architecture that understands the latent space can then re-create the original forms of the images from the noisy variants. In the process, the model can not only act as an unsupervised classifier but also be used to generate new images. AutoEncoders have an Encoder-Decoder structure where the Encoder compresses the image while the Decoder re-creates the original image from the compressed representation. 

## How are we going to build this? 
To build an autoencoder that can recreate **MNIST** images, we will be using the Tensorflow library. We will create functions to load the MNIST dataset and pre-process it. We will also need to create a random noise generator and a function to plot a batch of images. Once we have these functions, we can create the Autoencoder. The network structure follows an **Encoder-Decoder** pattern, and we will explore how to create that using Tensorflow. We will then train the Autoencoder on the MNIST data and use the trained model to re-create examples from the dataset. 
The sections below elaborate on these steps.

## Final Output 
The final output of the model should be a near-perfect representation of the MNIST dataset. After training the model for a few epochs. The first row of images is the training data, while the second row contains the images generated by the Autoencoder. These rows are almost the same, which shows that our model has done a good job.
[IMAGE {2} Final Output START SAMPLE]
![Final Output](https://hackmd.io/_uploads/BJ9UJsNqo.png)
[IMAGE {2} FINISH SAMPLE]


# Requirements
We must import some libraries and write a few functions to create a model that can read and re-create mnist images. 
Since we will be using the Tensorflow library, we import it and its other useful components. We import the numerical processing library numpy and also a plotting library matplotlib.
```python
from tensorflow.keras.datasets import mnist
import matplotlib.pyplot as plt
from tensorflow.keras import layers
import numpy as np
from tensorflow.keras.models import Model
import tensorflow as tf
```
We also need to write some helper functions. The first function takes an array as an input and reshapes it to the size that the model requires.

```python
def data_proc(dat):
    larr = len(dat)
    return np.reshape(dat.astype("float32") /255.0 , (larr, 28,28,1))
```

The second helper function is used to take an array, add Gaussian noise, and ensure that the values lie in the range (0,1).
```python
def gen_noise(array):
    noisy_array = array + 0.4 * np.random.normal(
        loc=0.0, scale=1.0, size=array.shape
    )
    return np.clip(noisy_array, 0.0, 1.0)
```

To understand if our model is performing well, we will need to display batches of images. The third function takes two arrays - the input array and the predicted images array and plots them in two rows.

```python
def display(array1, array2):
    n = 10
    indices = np.random.randint(len(array1), size=n)
    images1 = array1[indices, :]
    images2 = array2[indices, :]
    plt.figure(figsize=(20, 4))
    for i, (image1, image2) in enumerate(zip(images1, images2)):
        ax = plt.subplot(2, n, i + 1)
        plt.imshow(image1.reshape(28, 28))
        plt.gray()
        ax.get_xaxis().set_visible(False)
        ax.get_yaxis().set_visible(False)
        ax = plt.subplot(2, n, i + 1 + n)
        plt.imshow(image2.reshape(28, 28))
        plt.gray()
        ax.get_xaxis().set_visible(False)
        ax.get_yaxis().set_visible(False)
    plt.show()
``` 

# Building the AutoEncoder
The following sections explain how to create a simple Autoencoder in Tensorflow and use MNIST images to train it. We will first see how to load the MNIST data and preprocess it for our needs. After converting the data to the right format, we will build and train the model.
The architecture of the network is split into three major parts - the Encoder, the Bottleneck, and the Decoder. The Encoder is used to compress the input images while also preserving useful information. The Bottleneck chooses which features are relevant to flow through to the Decoder, and the Decoder re-creates the images using the outputs of the Bottleneck. The Autoencoder attempts to learn the latent space of the data in the process of this reconstruction.

The architecture diagram of an autoencoder is shown below.
[IMAGE {3} arch START SAMPLE]
![arch](https://hackmd.io/_uploads/HkPKzNNqj.png)
[IMAGE {3} FINISH SAMPLE]

## Preparing the dataset
The MNIST dataset is already included with Tensorflow as a split dataset so we can load it directly. We use the default splits into train and test datasets and then pass them to the pre-processing function we defined earlier.
The second half of the inputs to the model are noisy versions of the original MNIST images. We use the **gen_noise** function we defined before to create these noise images. Note that the larger the noise, the more distorted the image gets, and the harder the model must work to re-create them.
We will also visualize the noise data alongside the original.
[IMAGE {4} Data Visualized START SAMPLE]
![Data Visualized](https://hackmd.io/_uploads/SJivks45j.png)
[IMAGE {4} FINISH SAMPLE]


```python
(ds_train, _), (ds_test, _) = mnist.load_data()
ds_train,ds_test = data_proc(ds_train), data_proc(ds_test)

noisy_ds_train, noisy_ds_test = gen_noise(ds_train), gen_noise(ds_test)

display(ds_train, noisy_ds_train)
```

## Defining the Encoder
The Encoder of the network uses blocks of Convolutions and Max Pooling layers with ReLU activations. The objective is to compress the input data before passing it through the network.
The output of this part of the network should be a compressed version of the original data.
Since the MNIST images are of shape 28x28x1, we create an input with that shape.
```python
input = layers.Input(shape=(28, 28, 1))

# Encoder
x = layers.Conv2D(32, (3, 3), activation="relu", padding="same")(input)
x = layers.MaxPooling2D((2, 2), padding="same")(x)
x = layers.Conv2D(32, (3, 3), activation="relu", padding="same")(x)
x = layers.MaxPooling2D((2, 2), padding="same")(x)
```
## Defining the Bottleneck
Unlike the other two components, the Bottleneck does not need to be explicitly programmed. Because the output of the Encoder's final MaxPooling layer is very small, the Decoder must learn to recreate the images using this compressed representation. 
In more complex implementations of Autoencoders, modifying the Bottleneck is also an option.
## Defining the Decoder
The Decoder comprises Transposed Convolutions with a stride of 2. The final layer of the model is a simple 2D convolution with the sigmoid activation function. 
Since this part of the network is used to recreate images from the compressed representation, upsampling is done using the Transposed Convolution. Larger strides are used for upsampling the images in fewer steps.
```python
# Decoder
x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation="relu", padding="same")(x)
x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation="relu", padding="same")(x)
x = layers.Conv2D(1, (3, 3), activation="sigmoid", padding="same")(x)
```

## Training the model
After defining the model, we must compile it with the Optimiser and the loss function. This article will use the **Adam Optimiser** and a **Binary Cross Entropy** loss function.

```python
# conv_autoenc_model
conv_autoenc_model = Model(input, x)
conv_autoenc_model.compile(optimizer="adam", loss="binary_crossentropy")
conv_autoenc_model.summary()
```
After we compile the model, we can finally train it on the modified MNIST images we generated at the start of the article. We will train the model for 50 epochs with a batch size of 128. We also pass the validation data to the model. 
```python
conv_autoenc_model.fit(
    x=ds_train,
    y=ds_train,
    epochs=50,
    batch_size=128,
    shuffle=True,
    validation_data=(ds_test, ds_test),
)
```
## Reconstructing images
After training the model, we can use the trained model to generate predictions. We display the re-created images using the function we wrote previously.
```python
preds = conv_autoenc_model.predict(ds_test)
display(ds_test, preds)
```

:::
:::section{.summary}

## Conclusion
- In this article, we implemented a simple Autoencoder to re-create the MNIST image dataset.
- We learned how to load and pre-process the MNIST images to make them fit the Autoencoder model.
- We explored the architecture of the network and understood how to implement it using Tensorflow. 
- Finally, we learned how to train the Autoencoder and use it to generate new images.
:::



