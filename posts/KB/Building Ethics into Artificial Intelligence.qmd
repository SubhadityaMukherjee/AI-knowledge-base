---
toc: true
title: Building Ethics into Artificial Intelligence

categories: ['ethics']
date modified: Wednesday, January 18th 2023, 4:11:17 pm
date created: Wednesday, January 18th 2023, 3:24:42 pm
---

# Building Ethics into Artificial Intelligence


- Han Yu, Zhiqi Shen, Chunyan Miao, Cyril Leung, Victor R. Lesser, Qiang Yang

## Abstract
- taxonomy which divides the field into four areas: 1) exploring ethical dilemmas; 2) individual ethical decision frameworks; 3) collective ethical decision frameworks; and 4) ethics in human-AI interactions

## Types
- [Consequentialist ethics](Consequentialist ethics.qmd)
- [Utilitarian ethics](Utilitarian ethics.qmd)
- [Deontological ethics](Deontological ethics.qmd)
- [Virtue ethics](Virtue ethics.qmd)
- [Ethical dilemmas](Ethical dilemmas.qmd)

## Exploring Ethical Dilemmas
- explore the ethical dilemmas in the target application scenarios [Anderson and Anderson, 2014]
- [GenEth](GenEth.qmd)
- [Moral Machine project](Moral Machine project.qmd)

## Individual Ethical Decision Frameworks
- AI research community largely agrees that generalized frameworks are preferred over ad-hoc rules
- if updates are provided by people, some review mechanisms should be put in place to prevent abuse
- moral decision-making by humans not only involves utilitarian considerations, but also moral rules.
- Such rules often involve protected values (a.k.a. [sacred values](sacred values.qmd))
- [MoralDM](MoralDM.qmd)
- [Belief-Desire-Intention](Belief-Desire-Intention.qmd)
- [blind ethical judgement](blind ethical judgement.qmd)
- [partially informed ethical judgement](partially informed ethical judgement.qmd)
- [fully informed ethical judgement](fully informed ethical judgement.qmd)
- [Moral decision making frameworks for artificial intelligence](Moral decision making frameworks for artificial intelligence.qmd)
- [Preferences and ethical principles in decision making](Preferences and ethical principles in decision making.qmd)
- [A declarative modular framework for representing and applying ethical principles.](A declarative modular framework for representing and applying ethical principles..qmd)
- [A low-cost ethics shaping approach for designing reinforcement learning agents](A low-cost ethics shaping approach for designing reinforcement learning agents.qmd)
- [Even angels need the rules AI, roboethics, and the law](Even angels need the rules AI, roboethics, and the law.qmd)
- [Norms as a basis for governing sociotechnical systems](Norms as a basis for governing sociotechnical systems.qmd)
- [Embedding ethical principles in collective decision support systems](Embedding ethical principles in collective decision support systems.qmd)
- [A voting-based system for ethical decision making](A voting-based system for ethical decision making.qmd)
- [swap-dominance](swap-dominance.qmd)
- satisfying consequentialist ethics Ethics in Human-AI Interactions Belmont Report
- [Luckin, 2017; Yu et al., 2017b]
- 1) people's personal autonomy should not be violated (they should be able to maintain their free will when interacting with the technology); 2) benefits brought
- about by the technology should outweigh risks; and 3) the benefits
- and risks should be distributed fairly among the users (people should not be discriminated based on their personal backgrounds such as race, gender and religion)
- persuasion agents
- [Kang et al., 2015; Rosenfeld and Kraus, 2016]
- [Stock et al., 2016]
- large-scale study to investigate human perceptions on the ethics of persuasion by an AI agent
- [trolley scenario](trolley scenario.qmd)
- authors tested three persuasive strategies: 1) appealing to the participants emotionally; 2) presenting the participants with utilitarian arguments; and 3) lying
- participants hold a strong preconceived negative attitude towards the persuasion agent, and argumentation-based and lying-based persuasion strategies work better than emotional persuasion strategies
- did not show significant variation across genders or cultures
- adoption of persuasion strategies should take into account differences in individual personality, ethical attitude and expertise in the given domain.
- [Coping Theory](Coping Theory.qmd)
- Argumentation-based explainable AI
- [Fan and Toni, 2015; Langley et al., 2017] well suited to the consequentialist ethics
- depending on how the explanations are used, researchers need to strike a balance on the level of details to be included
- Full transparency may be too overwhelming if the objective is to persuade a user to follow a time-critical recommendation
- useful as a mechanism to trace the AI decision process afterwards not enough transparency may hamper users' trust in the AI



