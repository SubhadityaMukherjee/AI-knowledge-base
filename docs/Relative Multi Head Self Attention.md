---
title: Relative Multi Head Self Attention

tags: architecture 
---

# Relative Multi Head [[Self Attention]]
- [ZihangDai et al., 2019](https://arxiv.org/abs/1901.02860)
- 






















































## Backlinks

> - [Attention](Attention.md)
>   - [[Relative Multi Head Self Attention]]

_Backlinks last generated 2022-07-26 20:33:15_
