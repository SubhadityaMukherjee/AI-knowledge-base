---
title: Learning Rate Scheduling
---

# Learning Rate [[Scheduling]]
- [[Learning Rate Decay tricks]]
- [[Gradient Descent gradients]]
- Increasing the batch size, reduces noise in the #gradients so a larger learning rate is okay
- [[Linear Learning Rate Scaling]]
- [[Learning Rate Warmup]]


































