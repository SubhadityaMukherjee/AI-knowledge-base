---
toc: true
title: Vision Explainibility

tags: ['explainability']
date modified: Monday, January 16th 2023, 6:58:47 pm
date created: Friday, November 18th 2022, 12:31:29 pm
---

# Vision Explainibility

## Links Useful
- [Captum Algos Comparison](https://captum.ai/docs/algorithms_comparison_matrix)

## Flow
- [DeconvNet](DeconvNet.md) (2013)
- [Deep Inside Convolutional Networks](Deep%20Inside%20Convolutional%20Networks.md) (2014)
- [Guided BackProp](Guided%20BackProp.md) (2015) Aka All Conv net
	- Building up on [Deep Inside Convolutional Networks](Deep%20Inside%20Convolutional%20Networks.md) and [DeconvNet](DeconvNet.md)
- [Salience Map](Salience%20Map.md)
	- Not class discriminative
	- Noise
	- Not appealing
- [CAM](CAM.md)
	- less noisy
	- not class discriminative
	- Worked only a restricted set of CNN templates
- [Grad-CAM](Grad-CAM.md)
	- class discriminative
	- not high res
	- Works for any arbitrary CNN
- [Occlusion Map](Occlusion%20Map)
	- Same as the next but not very fast
- [Guided GradCAM](Guided%20GradCAM.md)
- [DeepLIFT](DeepLIFT.md)
- [Noise Tunnel](Noise Tunnel.md)
- [Smooth-Grad](Smooth-Grad.md)
- [SmoothGrad Square](SmoothGrad Square.md)
- [VarGrad](VarGrad.md)
- [Integrated Gradients](Integrated Gradients.md)
- [Proxy Attention](Proxy Attention.md)
- [Conductance](Conductance.md)


## Disadvantages
- [The Unreliability of Saliency Methods](The Unreliability of Saliency Methods.md)
- [Interpretation of Neural networks is fragile](Interpretation of Neural networks is fragile.md)
- Fine grained data

## Links





