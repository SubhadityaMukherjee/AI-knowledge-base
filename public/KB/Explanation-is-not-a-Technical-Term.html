<!DOCTYPE html>
<html lang="en"><head><title>Explanation is not a Technical Term</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM Plex Mono&amp;family=Schibsted Grotesk:wght@400;700&amp;family=Source Sans Pro:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:title" content="Explanation is not a Technical Term"/><meta property="og:description" content="Explanation is not a Technical Term @gilpinExplanationNotTechnical2022 Abstract Artificial Intelligence (XAI) and those explanations that users and other audiences actually ..."/><meta property="og:image" content="https://https://subhadityamukherjee.github.io/AI-knowledge-base//static/og-image.png"/><meta property="og:width" content="1200"/><meta property="og:height" content="675"/><link rel="icon" href="../static/icon.png"/><meta name="description" content="Explanation is not a Technical Term @gilpinExplanationNotTechnical2022 Abstract Artificial Intelligence (XAI) and those explanations that users and other audiences actually ..."/><meta name="generator" content="Quartz"/><link href="../index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><script src="../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("../static/contentIndex.json").then(data => data.json())</script></head><body data-slug="KB/Explanation-is-not-a-Technical-Term"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h2 class="page-title"><a href="..">Subhaditya's KB</a></h2><div class="spacer mobile-only"></div><div class="search"><button class="search-button" id="search-button"><p>Search</p><svg role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title>Search</title><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></button><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="search-layout" data-preview="true"></div></div></div></div><button class="darkmode" id="darkmode"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve" aria-label="Dark mode"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve" aria-label="Light mode"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></button></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="../">Home</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../KB/">Knowledge Base</a><p> ❯ </p></div><div class="breadcrumb-element"><a href>Explanation is not a Technical Term</a></div></nav><h1 class="article-title">Explanation is not a Technical Term</h1><p show-comma="true" class="content-meta"><span>Sep 18, 2024</span><span>7 min read</span></p><ul class="tags"><li><a href="../tags/explainability" class="internal tag-link">explainability</a></li></ul></div></div><article class="popover-hint"><h1 id="explanation-is-not-a-technical-term">Explanation is not a Technical Term<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#explanation-is-not-a-technical-term" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<ul>
<li>@gilpinExplanationNotTechnical2022</li>
</ul>
<h2 id="abstract">Abstract<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#abstract" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>Artificial Intelligence (XAI) and those explanations that users and other audiences actually need, which should be defined by the full spectrum of functional roles, audiences, and capabilities for explanation</li>
<li>In this paper, we explore the features of explanations and how to use those features in evaluating their utility.</li>
<li>we discuss the risk of XAI enabling trust in systems without establishing their trustworthiness and define a critical next step for the field of XAI to establish metrics to guide and ground the utility of system-generated explanations</li>
</ul>
<h2 id="introduction">Introduction<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#introduction" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>The problem is that explainability is not a well-defined goal: there is no common definition, metrics, or benchmarks for success.</li>
<li>Rather than taking a view of explanations as undi↵erentiated artifacts shared by multiple users, we view them as generated in response to their functional roles, audience, and data access</li>
<li>Functional role: How is the explanation going to be used?</li>
<li>Audience: To whom is it directed and what is their knowledge of the system and domain?</li>
<li>Capabilities: What are the capabilities of the system constructing the explanation and the source of data/knowledge used to do so?</li>
</ul>
<h2 id="motivation">Motivation<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#motivation" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>Because explanations are links between agents, we also need to consider the audience and their knowledge background</li>
<li>An explanation’s functional role defines the information that needs to be communicated.</li>
<li>The state of the audience’s initial knowledge of both the domain and processes define a second set of requirements related to the detail and vocabulary used in the explanation.</li>
<li>These three factors define the basis for metrics for an evaluation calculus that can be used to evaluate an explanation based on whether it serves the right functional role with the right level of elaboration for its audience supported by the system’s knowledge of its own reasoning.</li>
<li>By unpacking the idea of “explanation” into these factors, XAI can go beyond the “checking the box” phase to one in which explanations can play the role for which they were designed</li>
</ul>
<h2 id="the-requirements-functional-roles">The Requirements: Functional Roles<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#the-requirements-functional-roles" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>Unfortunately, one of the early findings in the realm of explanation was the discovery that the human bar on what constitutes a “good explanation” is shockingly low.</li>
<li>As Langer discovered in 1978, people are satisfied with “Placebic” information if it has the syntactic form of an explanation [13].</li>
<li>A system’s capabilities and access to knowledge about its own reasoning determine the scope and validity of the explanations it can generate.</li>
</ul>
<h3 id="engineers-and-developers">Engineers and Developers<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#engineers-and-developers" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>explanations are close to the machinery, and the shared language is technical and can contain machine representation</li>
<li>These users have experience working with models, understand limitations, can run experiments, and can intuit from incomplete or partial “explanations” as they perform their task: debugging and iterating on the model to improve its performance and make it trustworthy</li>
</ul>
<h3 id="doctors">Doctors<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#doctors" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>explanations are less about the core mechanics of the models themselves and reflect the logic of the domain, a↵ording exploration, counterfactuals, cohort comparison and transparent reasoning about the features most pertinent to a diagnosis</li>
<li>if a system provides a warning that a particular patient is showing signs of possible heart failure, a doctor will want a list of relevant factors in order of importance or concern, as well as the patient’s prognosis compared to that of other patients, and how that prognosis changes if certain factors are amended</li>
<li>At their best, the interaction between a doctor and an intelligent system should seek to mirror the sorts of interactions two doctors might have when collaborating on the task of developing a diagnosis and refining a treatment plan.</li>
</ul>
<h3 id="patients">Patients<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#patients" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>patient’s goal is more immediate and comes with higher personal stakes</li>
<li>This is the realm of personal decision making and, in cases of emergency, immediate action</li>
<li>These individuals are less informed about aspects of the medical domain, and systems tailored to them must account for that information asymmetry.</li>
<li>Thus, XAI, in this use case, becomes less about collaboration or justification and instead is geared towards confidence building, risk assessment, contextualization, and guided calls to action</li>
</ul>
<h3 id="regulators-and-auditors">Regulators and Auditors<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#regulators-and-auditors" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>require explanations that scope across the mechanisms of a system, the data used to train it, and the medical practices that it embodies.</li>
<li>they require explanations that might include elements of the human in the loop in order to determine responsibility and culpability.</li>
<li>engineers</li>
<li>building a system, explanations need to touch on the aspects of a system’s decisions that can be used in debugging, referencing the data, feature selection, and comparisons.</li>
<li>users interpreting the recommendations of a system</li>
<li>explanations need to include features that can be used to support exploration of hypotheticals, counterfactuals, cohort comparison and likelihoods.</li>
<li>explanations need to support trust and confidence building, risk assessment, contextualization, and decision support</li>
<li>stakeholders impacted by a decision</li>
</ul>
<h2 id="auditors-and-regulators">Auditors and Regulators<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#auditors-and-regulators" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>explanations need to support comparisons and aggregate review of performance and the trail of both algorithmic and human decisions that led to it</li>
</ul>
<h2 id="the-requirements-user-knowledge">The Requirements: User Knowledge<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#the-requirements-user-knowledge" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>The knowledge state of the various stakeholders interacting with the system defines another</li>
<li>As noted above, the functional role of XAI starts in the realm of model debugging and diagnostics – a tool set aimed at technical users capable of deciphering machine representations, interpreting model performance metrics, and updating model training to improve performance</li>
<li>Domain experts may not need explanations that provide insight into the technical workings of systems</li>
<li>They want and understand explanations at the domain level.</li>
<li>While it is often the case that they have the right level of domain knowledge, it is always a possibility that they lack detailed knowledge of specific domain level features and ideas.</li>
<li>Impacted stakeholders are highly variable</li>
<li>they may have no knowledge of either the domain or the technology. They do not have expertise in either but do have basic knowledge of how the world works.</li>
<li>Stakeholders such as auditors and regulators have specialized knowledge of the ways in which data and algorithms interact and how to look at the performance of a system through the lens of comparison and systemic issues.</li>
</ul>
<h2 id="system-capabilities">System Capabilities<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#system-capabilities" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<h3 id="interpretability">Interpretability<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#interpretability" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>how understandable the output representation is to the audience.</li>
<li>depends on the target audience and the task</li>
</ul>
<h3 id="accuracy">Accuracy<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#accuracy" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>
<p>based on correctness</p>
</li>
<li>
<p>except that it is in terms of the explanation itself</p>
</li>
<li>
<p>dependent on both the domain and the user</p>
</li>
<li>
<p>A saliency map applied to cancer images may highlight the hospital name, indicating that the reasons supporting the diagnosis is</p>
</li>
<li>
<p>the hospital where the image was taken [17]</p>
</li>
<li>
<p>This explanation is true to the model but the model is faulty. The explanation is accurate but the model is not.</p>
</li>
<li>
<p><a href="../KB/Elaborateness" class="internal alias" data-slug="KB/Elaborateness">Elaborateness</a></p>
</li>
<li>
<p><a href="../KB/Faithfulness" class="internal alias" data-slug="KB/Faithfulness">Faithfulness</a></p>
</li>
</ul>
<h2 id="trusted-but-not-trustworthy-a-new-dark-pattern">Trusted but not Trustworthy: A New Dark Pattern<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#trusted-but-not-trustworthy-a-new-dark-pattern" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>One of the dominant themes in XAI is the notion of trust</li>
<li>The focus is on getting users to trust a system rather than on making the system trustworthy.</li>
<li>Such trust is developed through output assessment over time and through a host of factors external to the model output itself (including the apparent trust of other experts, design decisions at the system and user experience levels, and ancillary components such as domain-informed conversational interfaces).</li>
<li>hard won and easily lost</li>
</ul>
<h2 id="discussion-metrics---the-next-critical-step-for-xai">Discussion: Metrics - the next Critical step for XAI<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#discussion-metrics---the-next-critical-step-for-xai" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>Explanations should provide new insights: explanations should go beyond the “why, what, how” [20]</li>
<li>We must also be able to compare and contrast them, as explanations can disagree and directly contradict each other [21]</li>
<li>We also want to quantify the system capabilities: how well the explanation actually explains</li>
<li>When we as humans explain something, it is a deductive process. Each claim follows from the last claim</li>
<li>The crucial point is that explanations need to fit the functional role in a manner that is interpretable to the audience</li>
<li>In evaluating an explanation, the question is whether it fits the role and the audience</li>
<li>With a variety of explanation types, a single “one size fits all” metric is inappropriate</li>
<li>Explanations must be built, interpreted, and evaluated through the lens of the functions that they serve and the knowledge situations in which they do so; through the lens of requirements and a system’s capability to meet them.</li>
<li>As work in XAI continues, it must attend to what exactly is being explained, to whom the explanation is directed, and how it is going to be used, and must provide a structured, standard evaluation approach via metrics of success.</li>
</ul>
<h2 id="images">Images<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#images" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li><img src=".././images/Page11Image28.503841911723242_69.0524207960309-390.09416045002604_526.8046627143713.png" alt/></li>
<li><img src=".././images/Page12Image42.55803980601578_445.26651888696006-359.94635491537673_174.37303587724818.png" alt/></li>
</ul></article><hr/><div class="page-footer"></div></div><div class="right sidebar"><div class="graph"><h3>Graph View</h3><div class="graph-outer"><div id="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:false}"></div><button id="global-graph-icon" aria-label="Global Graph"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xml:space="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
                s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
                c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
                C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
                c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
                v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
                s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
                C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
                S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
                s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
                s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></button></div><div id="global-graph-outer"><div id="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:true}"></div></div></div><div class="toc desktop-only"><button type="button" id="toc" class aria-controls="toc-content" aria-expanded="true"><h3>Table of Contents</h3><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><div id="toc-content" class><ul class="overflow"><li class="depth-0"><a href="#explanation-is-not-a-technical-term" data-for="explanation-is-not-a-technical-term">Explanation is not a Technical Term</a></li><li class="depth-1"><a href="#abstract" data-for="abstract">Abstract</a></li><li class="depth-1"><a href="#introduction" data-for="introduction">Introduction</a></li><li class="depth-1"><a href="#motivation" data-for="motivation">Motivation</a></li><li class="depth-1"><a href="#the-requirements-functional-roles" data-for="the-requirements-functional-roles">The Requirements: Functional Roles</a></li><li class="depth-2"><a href="#engineers-and-developers" data-for="engineers-and-developers">Engineers and Developers</a></li><li class="depth-2"><a href="#doctors" data-for="doctors">Doctors</a></li><li class="depth-2"><a href="#patients" data-for="patients">Patients</a></li><li class="depth-2"><a href="#regulators-and-auditors" data-for="regulators-and-auditors">Regulators and Auditors</a></li><li class="depth-1"><a href="#auditors-and-regulators" data-for="auditors-and-regulators">Auditors and Regulators</a></li><li class="depth-1"><a href="#the-requirements-user-knowledge" data-for="the-requirements-user-knowledge">The Requirements: User Knowledge</a></li><li class="depth-1"><a href="#system-capabilities" data-for="system-capabilities">System Capabilities</a></li><li class="depth-2"><a href="#interpretability" data-for="interpretability">Interpretability</a></li><li class="depth-2"><a href="#accuracy" data-for="accuracy">Accuracy</a></li><li class="depth-1"><a href="#trusted-but-not-trustworthy-a-new-dark-pattern" data-for="trusted-but-not-trustworthy-a-new-dark-pattern">Trusted but not Trustworthy: A New Dark Pattern</a></li><li class="depth-1"><a href="#discussion-metrics---the-next-critical-step-for-xai" data-for="discussion-metrics---the-next-critical-step-for-xai">Discussion: Metrics - the next Critical step for XAI</a></li><li class="depth-1"><a href="#images" data-for="images">Images</a></li></ul></div></div><div class="backlinks"><h3>Backlinks</h3><ul class="overflow"><li><a href="../KB/explainability" class="internal">explainability</a></li></ul></div></div></div><footer class><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.3.1</a> © 2025</p><ul><li><a href="https://github.com/SubhadityaMukherjee/AI-knowledge-base/">GitHub</a></li></ul></footer></div></body><script type="application/javascript">function c(){let t=this.parentElement;t.classList.toggle("is-collapsed");let l=t.classList.contains("is-collapsed")?this.scrollHeight:t.scrollHeight;t.style.maxHeight=l+"px";let o=t,e=t.parentElement;for(;e;){if(!e.classList.contains("callout"))return;let n=e.classList.contains("is-collapsed")?e.scrollHeight:e.scrollHeight+o.scrollHeight;e.style.maxHeight=n+"px",o=e,e=e.parentElement}}function i(){let t=document.getElementsByClassName("callout is-collapsible");for(let s of t){let l=s.firstElementChild;if(l){l.addEventListener("click",c),window.addCleanup(()=>l.removeEventListener("click",c));let e=s.classList.contains("is-collapsed")?l.scrollHeight:s.scrollHeight;s.style.maxHeight=e+"px"}}}document.addEventListener("nav",i);window.addEventListener("resize",i);
</script><script type="module">
          let mermaidImport = undefined
          document.addEventListener('nav', async () => {
            if (document.querySelector("code.mermaid")) {
              mermaidImport ||= await import('https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs')
              const mermaid = mermaidImport.default
              const darkMode = document.documentElement.getAttribute('saved-theme') === 'dark'
              mermaid.initialize({
                startOnLoad: false,
                securityLevel: 'loose',
                theme: darkMode ? 'dark' : 'default'
              })

              await mermaid.run({
                querySelector: '.mermaid'
              })
            }
          });
          </script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/contrib/copy-tex.min.js" type="application/javascript"></script><script src="../postscript.js" type="module"></script></html>