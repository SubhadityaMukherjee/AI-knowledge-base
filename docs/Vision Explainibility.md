---
title: Vision Explainibility

tags: explainability explainability flow
date modified: Monday, January 16th 2023, 6:58:47 pm
date created: Friday, November 18th 2022, 12:31:29 pm
---

# Vision Explainibility

## Links Useful
- [Captum Algos Comparison](https://captum.ai/docs/algorithms_comparison_matrix)

## Flow
- [DeconvNet](DeconvNet.md) (2013)
- [Deep Inside Convolutional Networks](Deep%20Inside%20Convolutional%20Networks.md) (2014)
- [Guided BackProp](Guided%20BackProp.md) (2015) Aka All Conv net
	- Building up on [Deep Inside Convolutional Networks](Deep%20Inside%20Convolutional%20Networks.md) and [[DeconvNet]]
- [Salience Map](Salience%20Map.md)
	- Not class discriminative
	- Noise
	- Not appealing
- [CAM](CAM.md)
	- less noisy
	- not class discriminative
	- Worked only a restricted set of CNN templates
- [Grad-CAM](Grad-CAM.md)
	- class discriminative
	- not high res
	- Works for any arbitrary CNN
- [Occlusion Map](Occlusion%20Map)
	- Same as the next but not very fast
- [Guided GradCAM](Guided%20GradCAM.md)
- [[DeepLIFT]]
- [[Noise Tunnel]]
- [[Smooth-Grad]]
- [[SmoothGrad Square]]
- [[VarGrad]]
- [[Integrated Gradients]]
- [[Proxy Attention]]
- [[Conductance]]


## Disadvantages
- [[The Unreliability of Saliency Methods]]
- [[Interpretation of Neural networks is fragile]]
- Fine grained data

## Links





