---
title: Tanh
tags: architecture 
---

# Tanh
- $$\frac{e^x-e^{-x}}{e^x+e^{-x}}$$
- RNN : Hidden
- Xavier/Glorot init
- ![[assets/Pasted image 20220626151651.jpg]]




























## Backlinks

> - [Recurrent](Recurrent.md)
>   - Activation usually [[Sigmoid]] or [[Tanh]]
>    
> - [Squared Hinge](Squared Hinge.md)
>   - [[Tanh]] for last layer
>    
> - [Activation Functions](ActivationFunctions.md)
>   - [[Tanh]]
>    
> - [Visualization Of Layers](Visualization Of Layers.md)
>   - [[Tanh]]
>    
> - [Lisht](Lisht.md)
>   - his activation function simply uses the [[Tanh]] function and scales it linearly, as follows

_Backlinks last generated 2022-07-26 20:33:15_
