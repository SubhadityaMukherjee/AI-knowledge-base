---
tags: temp
date modified: Monday, October 10th 2022, 2:02:25 pm
date created: Tuesday, July 26th 2022, 8:33:15 pm
---

---

title: ImageNet

tags: dataset

---

# ImageNet

## Backlinks
> - [RandAugment](RandAugment.md)
>   - [[CIFAR]], [[COCO]], [[SVHN]], [[ImageNet]]
>
> - [BYOL](BYOL.md)
>   - [[ImageNet]]
>
> - [Imagen](Imagen.md)
>   - better top-1 accuracy on [[ImageNet]] than [[EfficientNet]] at similar latency
>
> - [Robust [[RegNet]]](Robust RegNet.md)
>   - [[ImageNet]]
>   - large-scale self-supervised pre-training yields more robust, fair, less harmful, and less biased results than supervised models or models trained on object centric datasets such as [[ImageNet]]
>
> - [RepVGG](RepVGG.md)
>   - [[ImageNet]]
>
> - [Vision [[Transformer]]](Vision Transformer.md)
>   - [[ImageNet]] , [[CIFAR]], [[VTAB]]
>
> - [MoCO](MoCO.md)
>   - [[ImageNet]]
>
> - [Effects of [[Regularization]]](Effects of Regularization.md)
>   - varying the amount of [[Regularization|regularization]] employed during pre-training of a specific dataset impacts the per-class performances of that pre-trained model on different downstream tasks e.g. an [[ImageNet]] pre-trained ResNet50 deployed on INaturalist sees its performances fall from 70% to 30% on a particular classwhen introducing random crop DA during the [[ImageNet|Imagenet]] pre-training phase
>
> - [ConvNeXt](ConvNeXt.md)
>   - [[ImageNet]]
>
> - [MobileOne](MobileOne.md)
>   - better top-1 accuracy on [[ImageNet]] than [[EfficientNet]] at similar latency
>
> - [BEiT](BEiT.md)
>   - [[ImageNet]]
>
> - [Swin [[Transformer]]](Swin Transformer.md)
>   - [[ImageNet]]
>
> - [DeiT](DeiT.md)
>   - [[ImageNet]]
>
> - [CvT](CvT.md)
>   - [[ImageNet]]
>
> - [Masked Autoencoders](Masked Autoencoders.md)
>   - [[ImageNet]] and in [[Transfer Learning]] that an [[Auto Encoders]] â€”- a simple self-supervised method similar to techniques in NLP â€“ provides scalable benefits
>   - [[ImageNet]]

_Backlinks last generated 2022-10-04 13:01:19_
