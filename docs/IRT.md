---
title: IRT

tags: usermodel learning
date modified: Wednesday, October 12th 2022, 2:17:39 pm
date created: Wednesday, October 12th 2022, 2:17:39 pm
---

# IRT
```toc
```
- assumes that every test item has a difficulty, and different items have different difficulties (Embretson & Reise, 2000)
- Unfortunately, IRT generally assumes that test items are conditionally independent given the student's competence. This is seldom true of the raw measures collected at the step level by tutoring systems
- Although IRT has powerful features, such as calibration algorithms that empirically determine item difficulties and other parameters, considerable work is needed before it can be applied to tutoring systems.

## Backlinks

> - [Coarse-grained Assessment](Coarse-grained assessment.md)
>   - One of their main tools is item-response theory [[IRT]]
>    
> - [The Behavior of Tutoring Systems](The Behavior of Tutoring Systems.md)
>   - Are all learning events equally difficult? If not, then item response theory ([[IRT]]) can be used so that success on easy learning events provides less evidence of competence than success on difficult learning events.

_Backlinks last generated 2022-10-12 16:45:05_
