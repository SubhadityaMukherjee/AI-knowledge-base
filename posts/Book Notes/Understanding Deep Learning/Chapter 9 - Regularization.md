---
title: Chapter 9 - Regularization
toc: true
tags:
  - regularization
date modified: Wednesday 18th September 2024, Wed
date created: Wednesday 18th September 2024, Wed
---

# Chapter 9 - Regularization
```toc
```
> Skeptic : [Mixup](../../KB/Mixup.md)
> Skeptic: How does this tie into [Optimizers](../../KB/Optimizers.md)
> Skeptic : [Label Smoothing](../../KB/Label%20Smoothing.md) : Mentioned later
> [Batch Normalization](../../KB/Batch%20Normalization.md) - The idea is to normalize the inputs of each layer in such a way that, they have a mean activation output zero and a unit standard deviation.
> Skeptic : [AdamW](../../KB/AdamW.md)

- [Regularization](../../KB/Regularization.md)
## Explicit Regularization
- [Regularization Term](../../KB/Regularization%20Term.md)
- From [Maximum Likelihood](../../KB/Maximum%20Likelihood.md), 
	- ![](../../images/Pasted%20image%2020240918104924.png)
- ![](../../images/Pasted%20image%2020240918104935.png)
- from [Negative Log Likelihood](../../KB/Negative%20Log%20Likelihood.md)

## [Lp Regularization](../../KB/Lp%20Regularization.md)

## [Gradient Descent](../../KB/Gradient%20Descent.md)

## [SGD](../../KB/SGD.md)

## Improving Performance
- [Early Stopping tricks](../../KB/Early%20Stopping%20tricks.md)
- Ensembling models
- [Dropout](../../KB/Dropout.md)
- [Adversarial Learning](../../KB/Adversarial%20Learning.md)
- [Bayesian](../../KB/Bayesian.md)
- [Transfer Learning](../../KB/Transfer%20Learning.md)
- [Multi Task Learning](../../KB/Multi%20Task%20Learning.md)
- [augmentation](../../Tag%20Pages/augmentation.md)
- [Label Smoothing](../../KB/Label%20Smoothing.md)
- [Self Supervised](../../KB/Self%20Supervised.md)