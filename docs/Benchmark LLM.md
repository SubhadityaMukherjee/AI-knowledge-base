---
title: Benchmark LLM

tags: dataset 
date modified: Monday, October 10th 2022, 2:02:33 pm
date created: Tuesday, July 26th 2022, 8:33:15 pm
---

# Benchmark LLM
- [Large Language Models Still Canâ€™t Plan (A Benchmark for LLMs on Planning and Reasoning about Change)](A%20Benchmark%20for%20LLMs%20on%20Planning%20and%20Reasoning%20about%20Change)))
- The recent advances in large [language](language.md) models (LLMs) have transformed the field of natural [language](language.md) processing (NLP)
- From [GPT3](GPT3.md) to [PaLM](PaLM.md), the state-of-the-art performance on natural [language](language.md) tasks is being pushed forward with every new large [language](language.md) model
- current benchmarks are relatively simplistic and the performance over these benchmarks cannot be used as an evidence to support
- extensible assessment framework motivated by the above gaps in current benchmarks to test the abilities of LLMs on a central aspect of human intelligence, which is reasoning about actions and change
- multiple test cases

