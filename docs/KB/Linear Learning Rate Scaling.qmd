---
categories: ['temp']
title: Linear Learning Rate Scaling
date modified: Monday, October 10th 2022, 2:02:23 pm
date created: Tuesday, July 26th 2022, 8:33:15 pm
---

# Linear Learning Rate Scaling
- If [He [Initialization](Initialization.qmd) ] is used, 0.1 is a good learning rate for batch size 256 and for a larger b, $0.1\times\frac{\mathrm{b}}{256}$ is okay



