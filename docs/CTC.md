---
title: CTC

tags: loss 
---

# CTC
- [Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks](https://www.cs.toronto.edu/~graves/icml_2006.pdf)
- Many real-world sequence learning tasks require the prediction of sequences of labels from noisy, unsegmented input data
- Recurrent neural networks (RNNs) are powerful sequence learners that would seem well suited to such task
- hey require pre-segmented training data, and post-processing to transform their outputs into label sequences, their applicability has so far been limited
- temporal classification
- label unsegmented sequences directly
- probabilistic principles
- TIMIT speech corpus
















