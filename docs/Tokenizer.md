---
title: Tokenizer
tags: language
---

# Tokenizer
- Tokenizer expands the contraction to recover the essential grammatical [[Features|features]] of the [[pronoun]] and the [[Verb]].
- Space-delimited languages
- White space delimited tokens may not be the valid token
- Chinese and Thai
	- Words are written in succession with no indication of word boundaries
- [[Word Structure]]
- [[Punctuation]]


































































































## Backlinks

> - [Application Dependence](Application dependence.md)
>   - [[Tokenizer]]
>    
> - [Token [[Embedding]]](Token Embedding.md)
>   - WordPiece [[Tokenizer]]

_Backlinks last generated 2022-07-26 20:33:15_
