---
toc: true
title: Explainable Artificial Intelligence (XAI) Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI

categories: ['explainability']
date modified: Monday 6th March 2023, Mon
date created: Monday 6th March 2023, Mon
---

# Explainable Artificial Intelligence (XAI) Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI


- @arrietaExplainableArtificialIntelligence2019
- ## Charactersitics
- [Understandability](Understandability.qmd)
- [Comprehensibility](Comprehensibility.qmd)
- [Interpretability](Interpretability.qmd)
- [Explainability Defn](Explainability Defn.qmd)
- [Transparency](Transparency.qmd)
- [Trustworthiness](Trustworthiness.qmd)
- [Causality](Causality.qmd)
- [Transferability](Transferability.qmd)
- [Informativeness](Informativeness.qmd)
- [Confidence](Confidence.qmd)
- [Fairness](Fairness.qmd)
- [Accessibility](Accessibility.qmd)
- [Interactivity](Interactivity.qmd)
- [Privacy awareness](Privacy awareness.qmd)

## On the Tradeoff between Interpretability and Performance
- it is not necessarily true that models that are more complex are inherently more accurate
- It is in this situation that the trade-off between performance and interpretability can be observed
- In this path toward performance, when the performance comes hand in hand with complexity, interpretability encounters itself on a downwards slope that until now appeared unavoidable
- Another aspect worth mentioning at this point due to its close link to model interpretability and performance is the approximation dilemma: explanations made for a ML model must be made drastic and approximate enough to match the requirements of the audience for which they are sought, ensuring that explanations are representative of the studied model and do not oversimplify its essential features.
- confluence of multiple criteria
- need for having the human in the loop
- Contextual factors, potential impacts and domain-specific needs must be taken into account when devising an approach to interpretability
- a thorough understanding of the purpose for which the AI model is built
- the complexity of explanations that are required by the audience
- the performance and interpretability levels of existing technology, models and methods
- Interpretable techniques should be preferred when possible
- black-box models such as those reviewed in this work (namely, support vector machines, ensemble methods and neural networks) should be selected only when their superior modeling capabilities fit best the characteristics of the problem at hand.
- If a black-box model has been chosen, the third guideline establishes that ethics-, fairnessand safetyrelated impacts should be weighed
- rethink interpretability in terms of the cognitive skills, capacities and limitations of the individual human

## Fairness and Discrimination
- [Individual fairness](Individual fairness.qmd)
- [Group fairness](Group fairness.qmd)
- [Counterfactual fairness](Counterfactual fairness.qmd)
- [Skewed data](Skewed data.qmd)
- [Tainted data](Tainted data.qmd)
- [Limited features](Limited features.qmd)
- [Proxy features](Proxy features.qmd)
- [Independence](Independence.qmd)
- [Separation](Separation.qmd)
- [Sufficiency](Sufficiency.qmd)

## Accountability
- [Auditability](Auditability.qmd)
- [Minimization and reporting of negative impacts](Minimization and reporting of negative impacts.qmd)
- [Redress](Redress.qmd)



