---
title: Dilated Sliding Window Attention

categories: ['architecture']
date modified: Monday, October 10th 2022, 2:02:29 pm
date created: Tuesday, July 26th 2022, 8:33:15 pm
---

# Dilated [Sliding Window Attention](Sliding%20Window%20Attention.qmd)
- Analgous to dilated CNN
- Assuming a fixed $d$ and $w$ for all [layers](Layers.qmd), [receptive field](Receptive%20field.qmd) is $l \times d \times w$ which can reach tens of thousands of tokens even with small values of $d$
- ![Pasted%20image%2020220621181124](images/Pasted%20image%2020220621181124.png)



