---
toc: true
title: Additive Attention

categories: ['architecture']
date modified: Monday, October 10th 2022, 2:02:34 pm
date created: Tuesday, July 26th 2022, 8:33:15 pm
---

# Additive [Attention](Attention.md.md)
- [Bahdanau et al., 2015](https://arxiv.org/pdf/1409.0473.pdf)
- Uses a one layer feedforward network to calculate [Attention Alignment](Attention%20Alignment.md.md)
- Oh, basically it is the same as [Bahdanau Attention](Bahdanau%20Attention.md.md)



