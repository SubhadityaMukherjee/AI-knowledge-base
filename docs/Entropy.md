---
title: Entropy
tags: uncertainty
date modified: Monday, October 10th 2022, 2:02:28 pm
date created: Tuesday, July 26th 2022, 8:33:15 pm
---

# Entropy
- Measure of information content
- $$H = -\Sigma_{x}P(x)logP(x) = \Sigma_{x}P(x)log \frac{1}{P(x)}$$
- Units : bits of $log_{2}$
- [Uniform Distribution](Uniform%20Distribution.md) maximizes entropy. Results harder to predict



