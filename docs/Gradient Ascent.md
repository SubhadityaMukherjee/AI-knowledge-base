---
tags: temp
title: Gradient Ascent
date modified: Thursday, August 11th 2022, 12:32:53 am
date created: Tuesday, July 26th 2022, 8:33:15 pm
---

# Gradient Ascent
- To maximize loss function unlike [Gradient Descent gradients](Gradient%20Descent%20gradients.md)
- Proportional to positive of gradient
- $$\theta_{t+1} = \theta{t} + \eta_t \Sigma_{n=1}^N(\nabla l_n(\theta_t))^T$$

