---
title: Learning Rate Decay #tricks
---

# Learning Rate Decay #tricks
- Scale of loss landscape changes
- Reduce step size near optima
- Factor $$\alpha_{i+1} = d\cdot \alpha_i$$
- [[Cosine Learning Rate Decay]]

## â€¦


































































































## Backlinks

> - [Learning Rate [[Scheduling]]](Learning Rate Scheduling.md)
>   - [[Learning Rate Decay tricks]]
>    
> - [Optimization](Optimizers.md)
>   - [[Learning Rate Decay tricks]]
>    
> - [No Bias Decay](No bias decay.md)
>   - No [[Learning Rate Decay tricks]]

_Backlinks last generated 2022-07-26 20:33:15_
