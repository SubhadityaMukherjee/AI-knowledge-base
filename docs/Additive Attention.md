---
title: Additive Attention

tags: architecture 
---

# Additive Attention
- [Bahdanau et al., 2015](https://arxiv.org/pdf/1409.0473.pdf)
- Uses a one layer feedforward network to calculate [[Attention Alignment]]
- Oh, basically it is the same as [Bahdanau Attention](Bahdanau%20Attention.md)













