---
title: Scaled Dot Product Attention
---

# Scaled Dot Product Attention
- $$Attention(Q, K,V) = softmax(\frac{QK^T}{\sqrt{d_K}})V$$
	- Q is query, K is key V is value. Same dims
	- Generalization of [[soft attention]]




