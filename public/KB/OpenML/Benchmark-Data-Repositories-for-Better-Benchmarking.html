<!DOCTYPE html>
<html lang="en"><head><title>Benchmark Data Repositories for Better Benchmarking</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM Plex Mono&amp;family=Schibsted Grotesk:wght@400;700&amp;family=Source Sans Pro:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:title" content="Benchmark Data Repositories for Better Benchmarking"/><meta property="og:description" content="Benchmark Data Repositories for Better Benchmarking Benchmark Data Repositories for Better Benchmarking comparatively less attention has been paid to the repositories where ..."/><meta property="og:image" content="https://https://subhadityamukherjee.github.io/AI-knowledge-base//static/og-image.png"/><meta property="og:width" content="1200"/><meta property="og:height" content="675"/><link rel="icon" href="../../static/icon.png"/><meta name="description" content="Benchmark Data Repositories for Better Benchmarking Benchmark Data Repositories for Better Benchmarking comparatively less attention has been paid to the repositories where ..."/><meta name="generator" content="Quartz"/><link href="../../index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><script src="../../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("../../static/contentIndex.json").then(data => data.json())</script></head><body data-slug="KB/OpenML/Benchmark-Data-Repositories-for-Better-Benchmarking"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h2 class="page-title"><a href="../..">Subhaditya's KB</a></h2><div class="spacer mobile-only"></div><div class="search"><button class="search-button" id="search-button"><p>Search</p><svg role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title>Search</title><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></button><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="search-layout" data-preview="true"></div></div></div></div><button class="darkmode" id="darkmode"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve" aria-label="Dark mode"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve" aria-label="Light mode"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></button></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="../../">Home</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../KB/">KB</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../KB/OpenML/">OpenML</a><p> ❯ </p></div><div class="breadcrumb-element"><a href>Benchmark Data Repositories for Better Benchmarking</a></div></nav><h1 class="article-title">Benchmark Data Repositories for Better Benchmarking</h1><p show-comma="true" class="content-meta"><span>Oct 09, 2024</span><span>6 min read</span></p><ul class="tags"><li><a href="../../tags/benchmark" class="internal tag-link">benchmark</a></li></ul></div></div><article class="popover-hint"><h1 id="benchmark-data-repositories-for-better-benchmarking">Benchmark Data Repositories for Better Benchmarking<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#benchmark-data-repositories-for-better-benchmarking" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="toc" data-theme="github-light github-dark"><code data-language="toc" data-theme="github-light github-dark" style="display:grid;"><span data-line> </span></code></pre></figure>
<ul>
<li>Benchmark Data Repositories for Better</li>
<li>Benchmarking</li>
<li>comparatively less attention has been paid to the repositories where</li>
<li>these datasets are stored, documented, and shared</li>
</ul>
<h2 id="introduction">Introduction<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#introduction" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>Benchmarking can help quantify</li>
<li>progress on these tasks over time, and the availability of a well-studied, standard task evaluation</li>
<li>environment can be a critical first step before moving to real-world applications, especially in high-</li>
<li>stakes or expensive domains.</li>
<li>Early data repositories, such as the UCI ML Repository, arose to address the data needs that come</li>
<li>with ML benchmarking</li>
<li>the process of selecting a dataset is often less about a scientific or engineering application and more</li>
<li>about the compositional characteristics of the data and its associated tasks, for which a particular</li>
<li>class of methods is applicable</li>
<li>benchmark repository</li>
<li>to describe repositories that support the discovery and use of datasets for evaluating ML models</li>
</ul>
<h2 id="valuing-datasets-as-research-contributions">Valuing Datasets as Research Contributions<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#valuing-datasets-as-research-contributions" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<h2 id="dataset-citations-and-metrics">Dataset Citations and Metrics<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#dataset-citations-and-metrics" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>persistent identifier (PID), such as a DOI, that can reliably</li>
<li>be used to access a dataset has been widely recommended by experts</li>
<li>ML</li>
<li>datasets and their documentation frequently lack PIDs and are often only available via GitHub or</li>
<li>personal/research group websites</li>
<li>In ML, however, datasets are often referred</li>
<li>to using combinations of names, descriptions, and associated papers, which can be challenging to</li>
<li>disambiguate</li>
<li>include the minted DOI</li>
</ul>
<h2 id="connection-metadata">Connection Metadata<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#connection-metadata" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>connects a dataset to associated research entities (such as the dataset’s creators or</li>
<li>maintainers, publications, code, or other datasets)</li>
<li>Introductory papers can give the data a story beyond standardized documentation, providing useful context about the problem,</li>
<li>background on data collection procedures, and guidance about tasks for which the data have already</li>
<li>been used.</li>
<li>Introductory papers can be included in benchmark repositories as a</li>
<li>standardized metadata field</li>
<li>dataset’s point of contact:</li>
<li>someone responsible for answering questions about the dataset and addressing any issues</li>
<li>lthough long-term data maintenance, and determining different</li>
<li>stakeholders’ responsibilities in that maintenance, remain challenging tasks [28, 60, 61], establishing</li>
<li>a point of contact can help prevent the development of a disconnect between a dataset and its creators,</li>
<li>which is not uncommon in ML</li>
</ul>
<h2 id="dataset-licenses">Dataset Licenses<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#dataset-licenses" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>Data repositories can include licenses as part of a dataset’s metadata.</li>
<li>it</li>
<li>is ambiguous if models trained on a dataset count as “derivative work”</li>
<li>current licensing practices for ML datasets are often irregular,</li>
<li>conflicting, poorly documented, or over-permissive given the dataset content</li>
</ul>
<h2 id="addressing-issues-with-dataset-content">Addressing Issues with Dataset Content<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#addressing-issues-with-dataset-content" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>technical flaws such as labeling errors and annotation artifacts</li>
<li>privacy</li>
<li>and copyright violations</li>
<li>inclusions of hate speech or other harmful content</li>
<li>representational biases</li>
<li>miscellaneous ethical issues</li>
</ul>
<h2 id="contextual-metadata">Contextual Metadata<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#contextual-metadata" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>including information about a dataset’s</li>
<li>source, funding, collection, annotation, and preprocessing, benchmark repositories can illuminate the</li>
<li>assumptions and motivations of dataset creators and flag potential dataset issues</li>
<li>Data Cards</li>
<li>datasheets</li>
<li>Dataset Nutrition Label</li>
<li>FAIR principles</li>
<li>Data selection, filtering, and annotation processes are important design decisions that can significantly</li>
<li>impact downstream performance [7, 38, 75, 100, 101]; however, they tend to be under-documented</li>
</ul>
<h2 id="quality-review">Quality Review<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#quality-review" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>datasets containing personally identifiable information should not be released</li>
<li>Benchmark repositories can help</li>
<li>identify these problems throughout the data lifecycle by (1) performing a pre-release quality review</li>
<li>[92] to catch issues before a dataset is shared, and (2) by serving as a centralized location to collect</li>
<li>users’ reports and concerns [72] to flag issues throughout a dataset’s use and reuse</li>
<li>It is an open</li>
<li>question to what extent repositories should be involved in these decisions; several popular repositories</li>
<li>(e.g., Zenodo, Mendeley, etc.) view their role as only providing infrastructure and not conducting any</li>
<li>kind of data review.</li>
</ul>
<h2 id="dataset-revision-and-deprecation">Dataset Revision and Deprecation<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#dataset-revision-and-deprecation" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>dataset revision by documenting data versions and connecting</li>
<li>each dataset to a responsible point of contact</li>
<li>can enforce versioning by assigning a new version number</li>
<li>whenever a data file is changed.</li>
<li>deprecation of datasets.</li>
<li>creators often withdraw their dataset without an explanation of why it</li>
<li>was withdrawn or explicit instructions not to use the dataset</li>
<li>deprecation reports are posted in a scattered, decentralized manner via news articles,</li>
<li>conference papers, or researcher or lab websites</li>
<li>it can be unclear to researchers if a</li>
<li>dataset is acceptable to use; it is not uncommon for datasets to remain in use after their deprecation,</li>
<li>including in published, peer-reviewed papers</li>
<li>If a deprecation report is clearly displayed in the same place where a dataset was available, it</li>
<li>clarifies to researchers (and reviewers) that the dataset should not be used</li>
</ul>
<h2 id="compositional-and-task-metadata">Compositional and Task Metadata<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#compositional-and-task-metadata" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>Compositional metadata</li>
<li>describe the makeup of a dataset,</li>
<li>Croissant</li>
<li>Task metadata</li>
<li>include the intended or appropriate ML tasks for a dataset (e.g., image classification</li>
<li>or time-series prediction) and specialized metadata relevant to those tasks</li>
<li>As an example, HuggingFace Datasets</li>
<li>[17], which specializes in NLP data, collects metadata on language and multilinguality, text creation,</li>
<li>and fine-grained NLP tasks</li>
<li>repositories can require that data</li>
<li>donors provide high-quality compositional and task metadata, including specialized task metadata,</li>
<li>where appropriate</li>
</ul>
<h2 id="benchmark-metadata">Benchmark Metadata<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#benchmark-metadata" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>if a repository displays a</li>
<li>particular benchmarked result for a dataset, they should ensure that specific details on all settings</li>
<li>and hyperparameter values used to obtain that result are available</li>
</ul>
<h2 id="encouraging-holistic-evaluation">Encouraging Holistic Evaluation<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#encouraging-holistic-evaluation" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>Kaggle [18]</li>
<li>and Papers with Code</li>
<li>Leaderboarding</li>
<li>Further, as measures</li>
<li>of uncertainty are seldom incorporated, seemingly record-breaking performance improvements are</li>
<li>not always statistically significant</li>
</ul>
<h2 id="analysis-beyond-single-metrics">Analysis Beyond Single Metrics<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#analysis-beyond-single-metrics" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>variety of metrics, capturing model size and</li>
<li>complexity, energy consumption, inference latency, and the amount of data used</li>
<li>error analysis or disaggregated evaluations</li>
</ul>
<h2 id="metric-uncertainty">Metric Uncertainty<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#metric-uncertainty" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>Metrics shown without any measure of uncertainty can prompt fallacious conclusions, e.g., that</li>
<li>one model performs definitively better than another</li>
<li>Instead, including uncertainty makes these</li>
<li>benchmarked results more informative [1, 157], and a growing body of methodologies have been</li>
<li>developed for estimating uncertainty, computing confidence intervals, and performing statistical</li>
<li>significance testing in the context of model comparison</li>
<li>variance, uncertainty, and statistical significance</li>
<li>in model analysis</li>
</ul>
<h2 id="living-datasets">Living Datasets<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#living-datasets" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>leaderboards can evaluate submitted models</li>
<li>on a private, hitherto unused test set [167—169] (e.g., as done by Kaggle) or on out-of-distribution</li>
<li>data</li>
<li>eaderboards can also support “living” or evolving datasets,</li>
<li>to which dataset creators continuously add new examples or tasks and remove outdated or erroneous</li>
<li>examples.</li>
<li>benchmarked performances of two models evaluated at two</li>
<li>different points in time may not be directly comparable</li>
<li>robust models will generally outperform those using a specific trick or artifact as</li>
<li>evaluations are repeated over time</li>
<li>de-incentivizing</li>
<li>overfitting and helping bridge the gap between benchmarked and real-world performance.</li>
</ul>
<h2 id="dataset-discoverability">Dataset Discoverability<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#dataset-discoverability" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>there also exists a plethora</li>
<li>of other high-quality datasets that could have been used but did not win the “benchmark lottery”</li>
<li>existing standards emphasize</li>
<li>the importance of standardized, rich metadata [39, 129, 130], which enable searching for datasets</li>
<li>via keywords, filtering, and controlled vocabularies</li>
<li>search based on compositional and task</li>
<li>metadata</li>
<li>UCI ML Repository’s search functionality includes a filter</li>
<li>for classification, regression, clustering, or other datasets.</li>
</ul></article><hr/><div class="page-footer"></div></div><div class="right sidebar"><div class="graph"><h3>Graph View</h3><div class="graph-outer"><div id="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:false}"></div><button id="global-graph-icon" aria-label="Global Graph"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xml:space="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
                s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
                c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
                C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
                c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
                v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
                s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
                C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
                S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
                s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
                s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></button></div><div id="global-graph-outer"><div id="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:true}"></div></div></div><div class="toc desktop-only"><button type="button" id="toc" class aria-controls="toc-content" aria-expanded="true"><h3>Table of Contents</h3><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><div id="toc-content" class><ul class="overflow"><li class="depth-0"><a href="#benchmark-data-repositories-for-better-benchmarking" data-for="benchmark-data-repositories-for-better-benchmarking">Benchmark Data Repositories for Better Benchmarking</a></li><li class="depth-1"><a href="#introduction" data-for="introduction">Introduction</a></li><li class="depth-1"><a href="#valuing-datasets-as-research-contributions" data-for="valuing-datasets-as-research-contributions">Valuing Datasets as Research Contributions</a></li><li class="depth-1"><a href="#dataset-citations-and-metrics" data-for="dataset-citations-and-metrics">Dataset Citations and Metrics</a></li><li class="depth-1"><a href="#connection-metadata" data-for="connection-metadata">Connection Metadata</a></li><li class="depth-1"><a href="#dataset-licenses" data-for="dataset-licenses">Dataset Licenses</a></li><li class="depth-1"><a href="#addressing-issues-with-dataset-content" data-for="addressing-issues-with-dataset-content">Addressing Issues with Dataset Content</a></li><li class="depth-1"><a href="#contextual-metadata" data-for="contextual-metadata">Contextual Metadata</a></li><li class="depth-1"><a href="#quality-review" data-for="quality-review">Quality Review</a></li><li class="depth-1"><a href="#dataset-revision-and-deprecation" data-for="dataset-revision-and-deprecation">Dataset Revision and Deprecation</a></li><li class="depth-1"><a href="#compositional-and-task-metadata" data-for="compositional-and-task-metadata">Compositional and Task Metadata</a></li><li class="depth-1"><a href="#benchmark-metadata" data-for="benchmark-metadata">Benchmark Metadata</a></li><li class="depth-1"><a href="#encouraging-holistic-evaluation" data-for="encouraging-holistic-evaluation">Encouraging Holistic Evaluation</a></li><li class="depth-1"><a href="#analysis-beyond-single-metrics" data-for="analysis-beyond-single-metrics">Analysis Beyond Single Metrics</a></li><li class="depth-1"><a href="#metric-uncertainty" data-for="metric-uncertainty">Metric Uncertainty</a></li><li class="depth-1"><a href="#living-datasets" data-for="living-datasets">Living Datasets</a></li><li class="depth-1"><a href="#dataset-discoverability" data-for="dataset-discoverability">Dataset Discoverability</a></li></ul></div></div><div class="backlinks"><h3>Backlinks</h3><ul class="overflow"><li><a href="../../KB/OpenML/Data-storage-for-different-AI-dataset-services" class="internal">Data storage for different AI dataset services</a></li><li><a href="../../KB/OpenML/_Index_of_OpenML" class="internal">_Index_of_OpenML</a></li></ul></div></div></div><footer class><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.3.1</a> © 2025</p><ul><li><a href="https://github.com/SubhadityaMukherjee/AI-knowledge-base/">GitHub</a></li></ul></footer></div></body><script type="application/javascript">function c(){let t=this.parentElement;t.classList.toggle("is-collapsed");let l=t.classList.contains("is-collapsed")?this.scrollHeight:t.scrollHeight;t.style.maxHeight=l+"px";let o=t,e=t.parentElement;for(;e;){if(!e.classList.contains("callout"))return;let n=e.classList.contains("is-collapsed")?e.scrollHeight:e.scrollHeight+o.scrollHeight;e.style.maxHeight=n+"px",o=e,e=e.parentElement}}function i(){let t=document.getElementsByClassName("callout is-collapsible");for(let s of t){let l=s.firstElementChild;if(l){l.addEventListener("click",c),window.addCleanup(()=>l.removeEventListener("click",c));let e=s.classList.contains("is-collapsed")?l.scrollHeight:s.scrollHeight;s.style.maxHeight=e+"px"}}}document.addEventListener("nav",i);window.addEventListener("resize",i);
</script><script type="module">
          let mermaidImport = undefined
          document.addEventListener('nav', async () => {
            if (document.querySelector("code.mermaid")) {
              mermaidImport ||= await import('https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs')
              const mermaid = mermaidImport.default
              const darkMode = document.documentElement.getAttribute('saved-theme') === 'dark'
              mermaid.initialize({
                startOnLoad: false,
                securityLevel: 'loose',
                theme: darkMode ? 'dark' : 'default'
              })

              await mermaid.run({
                querySelector: '.mermaid'
              })
            }
          });
          </script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/contrib/copy-tex.min.js" type="application/javascript"></script><script type="application/javascript">
        const socket = new WebSocket('ws://localhost:3001')
        // reload(true) ensures resources like images and scripts are fetched again in firefox
        socket.addEventListener('message', () => document.location.reload(true))
      </script><script src="../../postscript.js" type="module"></script></html>