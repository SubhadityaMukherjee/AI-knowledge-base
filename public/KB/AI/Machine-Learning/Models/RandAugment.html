<!DOCTYPE html>
<html lang="en"><head><title>RandAugment</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM Plex Mono&amp;family=Schibsted Grotesk:wght@400;700&amp;family=Source Sans Pro:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:title" content="RandAugment"/><meta property="og:description" content="RandAugment Randaugment: Practical automated data augmentation with a reduced search space Ekin D. Cubuk ∗, Barret Zoph∗, Jonathon Shlens, Quoc V. Le ChatGPT Summary Large-scale adoption of data augmentation methods is hindered by the need for a separate and expensive search phase."/><meta property="og:image" content="https://https://subhadityamukherjee.github.io/AI-knowledge-base//static/og-image.png"/><meta property="og:width" content="1200"/><meta property="og:height" content="675"/><link rel="icon" href="../../../../static/icon.png"/><meta name="description" content="RandAugment Randaugment: Practical automated data augmentation with a reduced search space Ekin D. Cubuk ∗, Barret Zoph∗, Jonathon Shlens, Quoc V. Le ChatGPT Summary Large-scale adoption of data augmentation methods is hindered by the need for a separate and expensive search phase."/><meta name="generator" content="Quartz"/><link href="../../../../index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><script src="../../../../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("../../../../static/contentIndex.json").then(data => data.json())</script></head><body data-slug="KB/AI/Machine-Learning/Models/RandAugment"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h2 class="page-title"><a href="../../../..">Subhaditya's KB</a></h2><div class="spacer mobile-only"></div><div class="search"><button class="search-button" id="search-button"><p>Search</p><svg role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title>Search</title><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></button><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="search-layout" data-preview="true"></div></div></div></div><button class="darkmode" id="darkmode"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve" aria-label="Dark mode"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve" aria-label="Light mode"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></button></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="../../../../">Home</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../../../KB/">KB</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../../../KB/AI/">AI</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../../../KB/AI/Machine-Learning/">Machine Learning</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../../../KB/AI/Machine-Learning/Models/">Models</a><p> ❯ </p></div><div class="breadcrumb-element"><a href>RandAugment</a></div></nav><h1 class="article-title">RandAugment</h1><p show-comma="true" class="content-meta"><span>Sep 18, 2024</span><span>7 min read</span></p><ul class="tags"><li><a href="../../../../tags/explainability" class="internal tag-link">explainability</a></li></ul></div></div><article class="popover-hint"><h1 id="randaugment">RandAugment<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#randaugment" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<ul>
<li>Randaugment: Practical automated data augmentation with a reduced search space</li>
<li>Ekin D. Cubuk ∗, Barret Zoph∗, Jonathon Shlens, Quoc V. Le</li>
</ul>
<h2 id="chatgpt-summary">ChatGPT Summary<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#chatgpt-summary" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>Large-scale adoption of data augmentation methods is hindered by the need for a separate and expensive search phase.</li>
<li>Commonly, a smaller proxy task is used to overcome the expense of the search phase, but it is not clear if the optimized hyperparameters found on the proxy task are also optimal for the actual task.</li>
<li>The process of designing automated augmentation strategies is being rethought.</li>
<li>It is proposed to only search for a single distortion magnitude that jointly controls all operations, which reduces computational expense and eliminates the need for a separate proxy task.</li>
<li>The proposed method was tested on various datasets including [CIFAR]-10, [CIFAR](CIFAR]-10, [CIFAR.md) 100, SVHN, ImageNet, and COCO, and showed improvement in performance without the use of a proxy task.</li>
<li>The proposed method, RandAugment, uses a parameter-free procedure of always selecting a transformation with uniform probability from a set of K=14 available transformations, and a single distortion magnitude that jointly controls all operations.</li>
<li>RandAugment is able to achieve comparable or better performance compared to other automated augmentation methods, such as <a href="../../../../KB/AI/Machine-Learning/Training/Augmentation/AutoAugment" class="internal alias" data-slug="KB/AI/Machine-Learning/Training/Augmentation/AutoAugment">AutoAugment</a>, without the need for a separate proxy task.</li>
<li>The results suggest that the optimal data augmentation policies may depend on the specific model and dataset size, and a small proxy task may not provide the best indicator of performance on a larger task.</li>
</ul>
<h2 id="abstract">Abstract<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#abstract" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>An obstacle to a large-scale adoption of these methods is that they require a separate and expensive search phase</li>
<li>A common way to overcome the expense of the search phase was to use a smaller proxy task.</li>
<li>However, it was not clear if the optimized hyperparameters found on the proxy task are also optimal for the actual task.</li>
<li>rethink the process of designing automated augmentation strategies</li>
<li>it is sufficient to only search for a single distortion magnitude that jointly controls all operations</li>
<li>propose a simplified search space that vastly reduces the computational expense of automated augmentation, and permits the removal of a separate proxy task.</li>
<li><a href="../../../../KB/AI/Datasets/CIFAR" class="internal alias" data-slug="KB/AI/Datasets/CIFAR">CIFAR</a>-10</li>
<li><a href="../../../../KB/AI/Datasets/CIFAR" class="internal alias" data-slug="KB/AI/Datasets/CIFAR">CIFAR</a> 100</li>
<li>SVHN</li>
<li>ImageNet</li>
<li>COCO datasets</li>
</ul>
<h2 id="systematic-failures-of-a-separate-proxy-task">Systematic Failures of a Separate Proxy Task<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#systematic-failures-of-a-separate-proxy-task" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>A central premise of learned data augmentation is to construct a small, proxy task that may be reflective of a larger task</li>
<li>Although this assumption is sufficient for identifying learned augmentation policies to improve performance, it is unclear if this assumption is overly stringent and may lead to sub-optimal data augmentation policies.</li>
<li>two separate dimensions that are commonly restricted to achieve a small proxy task: model size and dataset size</li>
<li>First, we train a family of Wide-ResNet architectures, where the model size may be systematically altered through the widening parameter governing the number of convolutional filters</li>
<li>For each of these networks, we train the model on <a href="../../../../KB/AI/Datasets/CIFAR" class="internal alias" data-slug="KB/AI/Datasets/CIFAR">CIFAR</a>-10 and measure the final accuracy compared to a baseline model trained with default data augmentations (i.e. horizontal flips and pad-and-crop)</li>
<li>The Wide-ResNet models are trained with the additional K=14 data augmentations (see Section 3) over a range of global distortion magnitudes M parameterized on a uniform linear scale ranging from [0, 30]</li>
<li>Namely, larger networks demand larger data distortions for <a href="../../../../KB/AI/Machine-Learning/Training/Normalization/Regularization" class="internal alias" data-slug="KB/AI/Machine-Learning/Training/Normalization/Regularization">Regularization</a></li>
<li>Conversely, a policy learned on a proxy task (such as <a href="../../../../KB/AI/Machine-Learning/Training/Augmentation/AutoAugment" class="internal alias" data-slug="KB/AI/Machine-Learning/Training/Augmentation/AutoAugment">AutoAugment</a>) provides a fixed distortion magnitude (Figure 1b, dashed line) for all architectures that is clearly sub-optimal.</li>
<li>A second dimension for constructing a small proxy task is to train the proxy on a small subset of the training data</li>
<li>We first observe that models trained on smaller training sets may gain more improvement from data augmentation</li>
<li>see that the optimal distortion magnitude is larger for models that are trained on larger datasets.</li>
<li>optimal distortion magnitude increases monotonically with training set size</li>
<li>One hypothesis for this counter-intuitive behavior is that aggressive data augmentation leads to a low signal-to-noise ratio in small datasets</li>
<li>learned augmentation may learn an augmentation strength more tailored to the proxy task instead of the larger task of interest.</li>
<li>The dependence of augmentation strength on the dataset and model size indicate that a small proxy task may provide a sub-optimal indicator of performance on a larger task.</li>
</ul>
<h2 id="automated-data-augmentation-without-a-proxy-task">Automated Data Augmentation without a Proxy Task<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#automated-data-augmentation-without-a-proxy-task" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>The reason we wish to remove the search phase is because a separate search phase significantly complicates training and is computationally expensive.</li>
<li>In order to remove a separate search phase, we aspire to fold the parameters for the data augmentation strategy into the hyper-parameters for training a model.</li>
<li>Indeed, previous work enumerated a policy in terms of choosing which transformations to apply out of K=14 available transformations, and probabilities for applying each transformation:</li>
<li>age diversity, we replace the learned policies and probabilities for applying each</li>
<li>transformation with a parameter-free procedure of always selecting a transformation with uniform probability <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></li>
<li>Given N transformations for a training image, RandAugment may thus express <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span></span></span></span></span></span></span></span> potential policies.</li>
<li>magnitude of the each augmentation distortion.</li>
<li>Briefly, each transformation resides on an integer scale from 0 to 10 where a value of 10 indicates the maximum scale for a given transformation</li>
<li>A data augmentation policy consists of identifying an integer for each augmentation.</li>
<li>and postulate that a single global distortion M may suffice for parameterizing all transformations</li>
<li>We experimented with four methods for the schedule of M during training: constant magnitude, random magnitude, a linearly increasing magnitude, and a random magnitude with increasing upper bound</li>
<li>The resulting algorithm contains two parameters N and M</li>
<li>Both parameters are human-interpretable such that larger values of N and M increase <a href="../../../../KB/AI/Machine-Learning/Training/Normalization/Regularization" class="internal alias" data-slug="KB/AI/Machine-Learning/Training/Normalization/Regularization">Regularization</a> strength</li>
<li>In order to reduce the parameter space but still maintain imInvestigating the dependence on the included transformations</li>
<li>RandAugment is largely insensitive to the selection of transformations for different datasets.</li>
<li>We see that while [geometric transformations](geometric transformations.md) individually make the most difference, some of the color transformations lead to a degradation of validation accuracy on average</li>
<li>Surprisingly, rotate can significantly improve performance and lower variation even when included in small subsets of RandAugment transformations, while posterize seems to hurt all subsets of all sizes.</li>
</ul>
<h2 id="learning-the-probabilities-for-selecting-image-transformations">Learning the Probabilities for Selecting Image Transformations<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#learning-the-probabilities-for-selecting-image-transformations" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>For K=14 image transformations and N =2 operations, αij constitutes 28 parameters. We initialize all weights such that each transformation is equal probability (i.e. RandAugment), and update these parameters based on how well a model classifies a held out set of validation images distorted by αij.</li>
<li>This approach was inspired by density matching [19], but instead uses a differentiable approach in lieu of Bayesian optimization.</li>
<li>We label this method as a 1st-order density matching approximation.</li>
<li>The 1st -order method improves accuracy by more than 3.0% for both models on reduced <a href="../../../../KB/AI/Datasets/CIFAR" class="internal alias" data-slug="KB/AI/Datasets/CIFAR">CIFAR</a>-10 compared to the baseline of flips and pad-and-crop</li>
<li>Although the density matching approach is promising, this method can be expensive as one must apply all K transformations N times to each image independently.</li>
<li>Hence, because the computational demand of KN transformations is prohibitive for large images, we reserve this for future exploration.</li>
<li>learning the probabilities through density matching may improve the performance on small-scale tasks and reserve explorations to larger-scale tasks for the future.</li>
<li>RandAugment selects all image transformations with equal probability</li>
<li>This opens up the question of whether learning K probabilities may improve performance further.</li>
<li>Most of the image transformations (except posterize, equalize, and autoContrast) are differentiable, which permits backpropagation to learn the K probabilities</li>
</ul>
<h2 id="discussion">Discussion<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#discussion" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>not tailoring the number of distortions and the distortion magnitude to the dataset size nor the model size leads to sub-optimal performance</li>
<li>In previous work, scaling learned data augmentation to larger dataset and models have been a notable obstacle. For example, [AutoAugment] and Fast [AutoAugment](AutoAugment] and Fast [AutoAugment.md) could only be optimized for small models on reduced subsets of data</li>
<li>The proposed method scales quite well to datasets such as ImageNet and COCO while incurring minimal computational cost (e.g. 2 hyper-parameters), but notable predictive performance gains.</li>
</ul>
<h2 id="images">Images<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#images" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li><img src="../../../.././images/Pasted-image-20230116181447.png" alt/></li>
<li><img src="../../../.././images/Pasted-image-20230116181458.png" alt/></li>
<li><img src="../../../.././images/Pasted-image-20230116181528.png" alt/></li>
<li><img src="../../../.././images/Pasted-image-20230116181537.png" alt/></li>
<li><img src="../../../.././images/Pasted-image-20230116181619.png" alt/></li>
<li><img src="../../../.././images/Pasted-image-20230116181627.png" alt/></li>
<li><img src="../../../.././images/Pasted-image-20230116181636.png" alt/></li>
</ul></article><hr/><div class="page-footer"></div></div><div class="right sidebar"><div class="graph"><h3>Graph View</h3><div class="graph-outer"><div id="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:false}"></div><button id="global-graph-icon" aria-label="Global Graph"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xml:space="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
                s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
                c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
                C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
                c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
                v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
                s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
                C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
                S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
                s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
                s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></button></div><div id="global-graph-outer"><div id="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:true}"></div></div></div><div class="toc desktop-only"><button type="button" id="toc" class aria-controls="toc-content" aria-expanded="true"><h3>Table of Contents</h3><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><div id="toc-content" class><ul class="overflow"><li class="depth-0"><a href="#randaugment" data-for="randaugment">RandAugment</a></li><li class="depth-1"><a href="#chatgpt-summary" data-for="chatgpt-summary">ChatGPT Summary</a></li><li class="depth-1"><a href="#abstract" data-for="abstract">Abstract</a></li><li class="depth-1"><a href="#systematic-failures-of-a-separate-proxy-task" data-for="systematic-failures-of-a-separate-proxy-task">Systematic Failures of a Separate Proxy Task</a></li><li class="depth-1"><a href="#automated-data-augmentation-without-a-proxy-task" data-for="automated-data-augmentation-without-a-proxy-task">Automated Data Augmentation without a Proxy Task</a></li><li class="depth-1"><a href="#learning-the-probabilities-for-selecting-image-transformations" data-for="learning-the-probabilities-for-selecting-image-transformations">Learning the Probabilities for Selecting Image Transformations</a></li><li class="depth-1"><a href="#discussion" data-for="discussion">Discussion</a></li><li class="depth-1"><a href="#images" data-for="images">Images</a></li></ul></div></div><div class="backlinks"><h3>Backlinks</h3><ul class="overflow"><li><a href="../../../../KB/AI/Machine-Learning/Models/Thesis-Flow" class="internal">Thesis Flow</a></li><li><a href="../../../../KB/AI/Machine-Learning/Models/_Index_of_Models" class="internal">_Index_of_Models</a></li><li><a href="../../../../KB/AI/Machine-Learning/Training/Augmentation/Auto-Augment" class="internal">Auto Augment</a></li></ul></div></div></div><footer class><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.3.1</a> © 2025</p><ul><li><a href="https://github.com/SubhadityaMukherjee/AI-knowledge-base/">GitHub</a></li></ul></footer></div></body><script type="application/javascript">function c(){let t=this.parentElement;t.classList.toggle("is-collapsed");let l=t.classList.contains("is-collapsed")?this.scrollHeight:t.scrollHeight;t.style.maxHeight=l+"px";let o=t,e=t.parentElement;for(;e;){if(!e.classList.contains("callout"))return;let n=e.classList.contains("is-collapsed")?e.scrollHeight:e.scrollHeight+o.scrollHeight;e.style.maxHeight=n+"px",o=e,e=e.parentElement}}function i(){let t=document.getElementsByClassName("callout is-collapsible");for(let s of t){let l=s.firstElementChild;if(l){l.addEventListener("click",c),window.addCleanup(()=>l.removeEventListener("click",c));let e=s.classList.contains("is-collapsed")?l.scrollHeight:s.scrollHeight;s.style.maxHeight=e+"px"}}}document.addEventListener("nav",i);window.addEventListener("resize",i);
</script><script type="module">
          let mermaidImport = undefined
          document.addEventListener('nav', async () => {
            if (document.querySelector("code.mermaid")) {
              mermaidImport ||= await import('https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs')
              const mermaid = mermaidImport.default
              const darkMode = document.documentElement.getAttribute('saved-theme') === 'dark'
              mermaid.initialize({
                startOnLoad: false,
                securityLevel: 'loose',
                theme: darkMode ? 'dark' : 'default'
              })

              await mermaid.run({
                querySelector: '.mermaid'
              })
            }
          });
          </script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/contrib/copy-tex.min.js" type="application/javascript"></script><script type="application/javascript">
        const socket = new WebSocket('ws://localhost:3001')
        // reload(true) ensures resources like images and scripts are fetched again in firefox
        socket.addEventListener('message', () => document.location.reload(true))
      </script><script src="../../../../postscript.js" type="module"></script></html>