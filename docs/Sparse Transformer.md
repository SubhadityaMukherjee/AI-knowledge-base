---
title: Sparse Transformer

tags: architecture 
---

# Sparse [[Transformer]]
- [paper](https://arxiv.org/abs/1904.10509v1)
- Uses [[Strided Attention]]




















































## Backlinks

> - [Fixed Factorization [[Attention]]](Fixed Factorization Attention.md)
>   - Part of [[Sparse Transformer]]

_Backlinks last generated 2022-07-26 20:33:15_
