---
title: Tokenizer
tags: language
date modified: Monday, October 10th 2022, 2:02:15 pm
date created: Tuesday, July 26th 2022, 8:33:15 pm
---

# Tokenizer
- Tokenizer expands the contraction to recover the essential grammatical [[Features|features]] of the [[pronoun]] and the [[Verb]].
- Space-delimited languages
- White space delimited tokens may not be the valid token
- Chinese and Thai
	- Words are written in succession with no indication of word boundaries
- [[Word Structure]]
- [[Punctuation]]

## Backlinks
> - [Token [[Embedding]]](Token Embedding.md)
>   - WordPiece [[Tokenizer]]
>
> - [Application Dependence](Application dependence.md)
>   - [[Tokenizer]]

_Backlinks last generated 2022-10-04 13:01:19_
