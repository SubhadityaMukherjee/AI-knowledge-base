<!DOCTYPE html>
<html lang="en"><head><title>pixelattribution</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM Plex Mono&amp;family=Schibsted Grotesk:wght@400;700&amp;family=Source Sans Pro:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:title" content="pixelattribution"/><meta property="og:description" content="Pixelattribution Pixel Attribution Pixel attribution is a special case of feature attribution, but for images Feature attribution explains individual predictions by attributing ..."/><meta property="og:image" content="https://https://subhadityamukherjee.github.io/AI-knowledge-base//static/og-image.png"/><meta property="og:width" content="1200"/><meta property="og:height" content="675"/><link rel="icon" href="../static/icon.png"/><meta name="description" content="Pixelattribution Pixel Attribution Pixel attribution is a special case of feature attribution, but for images Feature attribution explains individual predictions by attributing ..."/><meta name="generator" content="Quartz"/><link href="../index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><script src="../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("../static/contentIndex.json").then(data => data.json())</script></head><body data-slug="KB/pixelattribution"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h2 class="page-title"><a href="..">Subhaditya's KB</a></h2><div class="spacer mobile-only"></div><div class="search"><button class="search-button" id="search-button"><p>Search</p><svg role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title>Search</title><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></button><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="search-layout" data-preview="true"></div></div></div></div><button class="darkmode" id="darkmode"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve" aria-label="Dark mode"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve" aria-label="Light mode"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></button></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="../">Home</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../KB/">Knowledge Base</a><p> ❯ </p></div><div class="breadcrumb-element"><a href>pixelattribution</a></div></nav><h1 class="article-title">pixelattribution</h1><p show-comma="true" class="content-meta"><span>Sep 18, 2024</span><span>8 min read</span></p><ul class="tags"><li><a href="../tags/explainability" class="internal tag-link">explainability</a></li></ul></div></div><article class="popover-hint"><h1 id="pixelattribution">Pixelattribution<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#pixelattribution" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<h2 id="pixel-attribution">Pixel Attribution<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#pixel-attribution" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>Pixel attribution is a special case of feature attribution, but for images</li>
<li>Feature attribution explains individual predictions by attributing each input feature according to how much it changed the prediction (negatively or positively)</li>
<li>The features can be input pixels, tabular data or words</li>
</ul>
<h2 id="occlusion-or-perturbation-based">Occlusion or Perturbation-based<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#occlusion-or-perturbation-based" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>Methods like SHAP and LIME manipulate parts of the image to generateexplanations (modelagnostic).</li>
</ul>
<h2 id="gradient-based">Gradient-based<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#gradient-based" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>compute the gradient of the prediction (or classification score) with respect to theinput feature</li>
<li>The gradient-based methods (of which there are many) mostly differ in how thegradient is computed.</li>
<li>explanation has the same size as the input image (or at least can be meaningfullyprojected onto it) and they assign each pixel a value that can be interpreted as therelevance of the pixel to the prediction or classification of that image.</li>
</ul>
<h2 id="gradient-only-methods">Gradient-only Methods<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#gradient-only-methods" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>whether a change in a pixel would change the prediction</li>
<li>Examples are Vanilla Gradient and Grad-CAM</li>
<li>If I were to increase the color values of the pixel, the predicted class probabilitywould go up (for positive gradient) or down (for negative gradient</li>
<li>The larger the absolute value of the gradient, the stronger the effect of a change ofthis pixel.</li>
</ul>
<h2 id="path-attribution-methods">Path-attribution Methods<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#path-attribution-methods" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>compare the current image to a reference image, which can be an artificial “zero”image such as a completely grey image</li>
<li>The difference in actual and baseline prediction is divided among the pixels</li>
<li>The baseline image can also be multiple images: a distribution of images</li>
<li>model-specific gradient-based methods such as Deep Taylor and IntegratedGradients</li>
<li>model-agnostic methods such as LIME and SHAP.</li>
<li>Some path-attribution methods are “complete”, meaning that the sum of therelevance scores for all input features is the difference between the prediction of theimage and the prediction of a reference image</li>
<li>Examples are SHAP and Integrated Gradients.</li>
<li>The difference between classification scores of the actual image and the baselineimage are attributed to the pixels</li>
<li>The choice of the reference image (distribution) has a big effect on the explanation</li>
</ul>
<h2 id="vanilla-gradient">Vanilla Gradient<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#vanilla-gradient" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>
<p>We calculate the gradient of the loss function for the class we are interested in withrespect to the input pixels</p>
</li>
<li>
<p>This gives us a map of the size of the input features with negative to positive values.</p>
</li>
<li>
<p>The recipe for this approach is:</p>
</li>
<li>
<ol>
<li>Perform a forward pass of the image of interest.</li>
</ol>
</li>
<li>
<ol start="2">
<li>Compute the gradient of the class score of interest with respect to the input pixels:</li>
</ol>
</li>
<li>
<p><img src=".././images/img_p2_1.png" alt/></p>
</li>
<li>
<p>Here we set all other classes to zero.</p>
</li>
<li>
<ol>
<li>Visualize the gradients. You can either show the absolute values or highlight negative and positive contributions separately.</li>
</ol>
</li>
<li>
<p>More formally, we have an image I and the convolutional neural 𝑆𝑐(𝐼) network gives ita score</p>
</li>
<li>
<p>for class c</p>
</li>
<li>
<p>The score is a highly non-linear function of our image.</p>
</li>
<li>
<p>The idea behind using the gradient is that we can approximate that score byapplying a first-order Taylor expansion</p>
</li>
<li>
<p><img src=".././images/img_p3_1.png" alt/></p>
</li>
<li>
<p>some ambiguity how to perform a backward pass of the gradients</p>
</li>
<li>
<p>since non-linear units such as ReLU (Rectifying Linear Unit) “remove” the sign</p>
</li>
<li>
<p>So when we do a backpass, we do not know whether to assign a positive or negativeactivation</p>
</li>
<li>
<p><img src=".././images/img_p4_1.png" alt/></p>
</li>
<li>
<p>This means that when the activation of a neuron is zero, we do not know which valueto backpropagate</p>
</li>
<li>
<p>In the case of Vanilla Gradient, the ambiguity is resolved as follows: 𝛿𝑓= 𝛿𝑓</p>
</li>
<li>
<p><img src=".././images/img_p4_2.png" alt/></p>
</li>
<li>
<p>𝐈 e r e , activation at the lower layer was negative, and one where it is positive orzero</p>
</li>
<li>
<p>Vanilla Gradient takes the gradient we have backpropagated so far up to layer n+1,and then simply sets the gradients to zero where the activation at the layer below isnegative</p>
</li>
</ul>
<h3 id="problems-with-vanilla-gradient">Problems with Vanilla Gradient<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#problems-with-vanilla-gradient" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>saturation problem</li>
<li>When ReLU is used, and when the activation goes below zero, then the activation iscapped at zero and does not change any more</li>
</ul>
<h2 id="deconvnet">DeconvNet<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#deconvnet" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>almost identical to Vanilla Gradient</li>
<li>The goal of DeconvNet is to reverse a neural network and the paper proposesoperations that are reversals of the filtering, pooling and activation layers</li>
<li>but apart from the reversal of the ReLU layer, DeconvNet is equivalent to the Vanilla Gradient approach</li>
<li>Vanilla Gradient can be seen as a generalization of DeconvNet</li>
<li>DeconvNet makes a different choice for backpropagating the gradient- <strong>12:24</strong>  through ReLU:</li>
<li><img src=".././images/img_p5_1.png" alt/></li>
<li>When backpassing from layer n to layer n-1, DeconvNet “remembers” which of theactivations in layer n were set to zero in the forward pass and sets them to zero in layer n-1</li>
<li>𝑋ctivations with a negative value in layer x are set to zero in layer n-1.</li>
</ul>
<h2 id="grad-cam">Grad-CAM<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#grad-cam" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>Grad-CAM provides visual explanations for CNN decisions</li>
<li>Unlike other methods, the gradient is not backpropagated all the way back to theimage, but (usually) to the last convolutional layer to produce a coarse localizationmap that highlights important regions of the image.</li>
<li>Gradient-weighted Class Activation Map</li>
<li>based on the gradient of the neural networks</li>
<li>assigns each neuron a relevance score for the decision of interest</li>
<li>This decision of interest can be the class prediction (which we find in the outputlayer), but can theoretically be any other layer in the neural network</li>
<li>GradCAM can be used with different CNNs: with fully-connected layers, forstructured output such as captioning and in multi-task outputs, and forreinforcement learning.</li>
<li>s a reminder, the first convolutional layer of a CNN takes as input the images andoutputs feature maps that encode learned features</li>
<li>higher-level convolutional layers do the same, but take as input the feature maps ofthe previous convolutional layers</li>
<li>There are k feature maps in the last 𝐴 ,𝐴 ,…,𝐴</li>
<li>Grad-CAM has to decide how important each of the k feature map was to our class cthat we are interested in</li>
<li>We have to weight each pixel of each feature map with the gradient before weaverage over the feature maps</li>
<li>This gives us a heatmap which highlights regions that positively or negatively affectthe class of interest</li>
<li>This heatmap is send through the ReLU function, which is a fancy way of saying thatwe set all negative values to zero</li>
<li>Grad-CAM removes all negative values by using a ReLU function, with the argumentthat we are only interested in the parts that contribute to the selected class c and not to other classes</li>
<li>The word pixel might be misleading here as the feature map is smaller than theimage (because of the pooling units) but is mapped back to the original image</li>
<li>We then scale the GradCAM map to the interval [0,1] for visualization purposes and overlay it over the original image.</li>
<li><img src=".././images/img_p7_1.png" alt/></li>
<li>Forward-propagate the input image through the convolutional neural network.</li>
<li>Obtain the raw score for the class of interest, meaning the activation of the neuron before the softmax layer.</li>
<li>Set all other class activations to zero.</li>
<li><img src=".././images/img_p8_1.png" alt/></li>
<li>Back-propagate the gradient of the class of interest to the last 𝛿𝑦𝑐 𝛿𝐴𝑘 convolutional layer before the fully connected layers.</li>
<li>Weight each feature map “pixel” by the gradient for the class. Indices i and j refer to the width and height dimensions.</li>
<li><img src=".././images/img_p8_2.png" alt/></li>
<li>This means that the gradients are globally pooled</li>
<li>Calculate an average of the feature maps, weighted per pixel by the gradient.</li>
<li>Apply ReLU to the averaged feature map.</li>
<li>Scale values to the interval between 0 and 1. Upscale the image and overlay it over the original image.</li>
<li>Additional step for Guided Grad-CAM: Multiply the heatmap with guided backpropagation.</li>
</ul>
<h2 id="guided-grad-cam">Guided Grad-CAM<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#guided-grad-cam" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>From the description of Grad-CAM you can guess that the localization is verycoarse, since the last convolutional feature maps have a much coarser resolution compared to the input image</li>
<li>In contrast, other attribution techniques backpropagate all the way to the inputpixels</li>
<li>They are therefore much more detailed and can show you individual edges or spotsthat contributed most to a prediction</li>
<li>You compute for an image both the GradCAM explanation and the explanationfrom another attribution method, such as Vanilla Gradient</li>
<li>The Grad-CAM output is then upsampled with bilinear interpolation, then both mapsare multiplied element-wise</li>
<li>Grad-CAM works like a lense that focuses on specific parts of the pixel-wiseattribution map.</li>
</ul>
<h2 id="-smoothgrad"># SmoothGrad<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#-smoothgrad" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>make gradient-based explanations less noisy by adding noise and averaging overthese artificially noisy gradient</li>
<li>SmoothGrad is not a standalone explanation method, but an extension to anygradientbased explanation method.</li>
<li>
<ol>
<li>Generate multiple versions of the image of interest byadding noise to it. 2.Create pixel attribution maps for all images.</li>
</ol>
</li>
<li>
<ol start="3">
<li>Average the pixel attribution maps.</li>
</ol>
</li>
<li>The theory is that the derivative fluctuates greatly at small scales</li>
<li>Neural networks have no incentive during training to keep the gradients smooth,their goal is to classify images correctly</li>
<li>Averaging over multiple maps “smooths out” these fluctuations</li>
<li><img src=".././images/img_p10_1.png" alt/></li>
<li><img src=".././images/img_p10_2.png" alt/></li>
<li><img src=".././images/img_p11_1.png" alt/></li>
<li>And that is the big issue with all of these methods</li>
<li>We do not have a ground truth for the explanations</li>
<li>We can only, in a first step, reject explanations that obviously make no sense (andeven in this step we do not have strong confidence</li>
</ul>
<h2 id="disadvantages">Disadvantages<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#disadvantages" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>it is difficult to know whether an explanation is correct, and a huge part of theevaluation is only qualitative</li>
<li>Pixel attribution methods can be very fragile</li>
<li>Ghorbani et al. (2019)86 showed that introducing small (adversarial) perturbationsto an image, which still lead to the same prediction, can lead to very different pixelsbeing highlighted as explanations.</li>
<li>Kindermans et al. (2019) 87 also showed that these pixel attribution methods can behighly unreliable</li>
<li>They added a constant shift to the input data, meaning they added the same pixelchanges to all images</li>
<li>They compared two networks, the original network and the “shifted” network wherethe bias of the first layer is changed to adapt for the constant pixel shift</li>
<li>Both networks produce the same predictions.</li>
<li>Further, the gradient is the same for both</li>
<li>But the explanations changed, which is an undesirable property. They looked at DeepLift, Vanilla Gradient and Integrated Gradients.</li>
</ul></article><hr/><div class="page-footer"></div></div><div class="right sidebar"><div class="graph"><h3>Graph View</h3><div class="graph-outer"><div id="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:false}"></div><button id="global-graph-icon" aria-label="Global Graph"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xml:space="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
                s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
                c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
                C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
                c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
                v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
                s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
                C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
                S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
                s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
                s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></button></div><div id="global-graph-outer"><div id="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:true}"></div></div></div><div class="toc desktop-only"><button type="button" id="toc" class aria-controls="toc-content" aria-expanded="true"><h3>Table of Contents</h3><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><div id="toc-content" class><ul class="overflow"><li class="depth-0"><a href="#pixelattribution" data-for="pixelattribution">Pixelattribution</a></li><li class="depth-1"><a href="#pixel-attribution" data-for="pixel-attribution">Pixel Attribution</a></li><li class="depth-1"><a href="#occlusion-or-perturbation-based" data-for="occlusion-or-perturbation-based">Occlusion or Perturbation-based</a></li><li class="depth-1"><a href="#gradient-based" data-for="gradient-based">Gradient-based</a></li><li class="depth-1"><a href="#gradient-only-methods" data-for="gradient-only-methods">Gradient-only Methods</a></li><li class="depth-1"><a href="#path-attribution-methods" data-for="path-attribution-methods">Path-attribution Methods</a></li><li class="depth-1"><a href="#vanilla-gradient" data-for="vanilla-gradient">Vanilla Gradient</a></li><li class="depth-2"><a href="#problems-with-vanilla-gradient" data-for="problems-with-vanilla-gradient">Problems with Vanilla Gradient</a></li><li class="depth-1"><a href="#deconvnet" data-for="deconvnet">DeconvNet</a></li><li class="depth-1"><a href="#grad-cam" data-for="grad-cam">Grad-CAM</a></li><li class="depth-1"><a href="#guided-grad-cam" data-for="guided-grad-cam">Guided Grad-CAM</a></li><li class="depth-1"><a href="#-smoothgrad" data-for="-smoothgrad"># SmoothGrad</a></li><li class="depth-1"><a href="#disadvantages" data-for="disadvantages">Disadvantages</a></li></ul></div></div><div class="backlinks"><h3>Backlinks</h3><ul class="overflow"><li><a href="../KB/explainability" class="internal">explainability</a></li></ul></div></div></div><footer class><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.3.1</a> © 2024</p><ul><li><a href="https://github.com/SubhadityaMukherjee/AI-knowledge-base/">GitHub</a></li></ul></footer></div></body><script type="application/javascript">function c(){let t=this.parentElement;t.classList.toggle("is-collapsed");let l=t.classList.contains("is-collapsed")?this.scrollHeight:t.scrollHeight;t.style.maxHeight=l+"px";let o=t,e=t.parentElement;for(;e;){if(!e.classList.contains("callout"))return;let n=e.classList.contains("is-collapsed")?e.scrollHeight:e.scrollHeight+o.scrollHeight;e.style.maxHeight=n+"px",o=e,e=e.parentElement}}function i(){let t=document.getElementsByClassName("callout is-collapsible");for(let s of t){let l=s.firstElementChild;if(l){l.addEventListener("click",c),window.addCleanup(()=>l.removeEventListener("click",c));let e=s.classList.contains("is-collapsed")?l.scrollHeight:s.scrollHeight;s.style.maxHeight=e+"px"}}}document.addEventListener("nav",i);window.addEventListener("resize",i);
</script><script type="module">
          let mermaidImport = undefined
          document.addEventListener('nav', async () => {
            if (document.querySelector("code.mermaid")) {
              mermaidImport ||= await import('https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs')
              const mermaid = mermaidImport.default
              const darkMode = document.documentElement.getAttribute('saved-theme') === 'dark'
              mermaid.initialize({
                startOnLoad: false,
                securityLevel: 'loose',
                theme: darkMode ? 'dark' : 'default'
              })

              await mermaid.run({
                querySelector: '.mermaid'
              })
            }
          });
          </script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/contrib/copy-tex.min.js" type="application/javascript"></script><script src="../postscript.js" type="module"></script></html>