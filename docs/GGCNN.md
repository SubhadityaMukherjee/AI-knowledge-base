---
title: GGCNN

tags: robotics architecture 
date modified: Monday, October 10th 2022, 2:02:27 pm
date created: Thursday, July 28th 2022, 5:59:06 pm
---

# GGCNN
- Learning an object agnostic function to grasp objects
- Grasping using uni-modal data (depth image).  
- Generate pixel-wise grasp configuration for the given input.  
- The [gripper](Gripper.md) approaches the target object in top-down manner. Uses a shallow network, and an eye-in-hand camera configuration.
- ![Pasted image 20220928213943](assets/Pasted%20image%2020220928213943.png)
- Morrison, Douglas, Peter Corke, and JuÌˆrgen Leitner. "Closing the loop for robotic grasping: A real-time, generative grasp synthesis approach." RSS (2018).

