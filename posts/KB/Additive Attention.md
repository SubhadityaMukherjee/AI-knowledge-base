---
toc: true
title: Additive Attention

categories: ['architecture']
date modified: Monday, October 10th 2022, 2:02:34 pm
date created: Tuesday, July 26th 2022, 8:33:15 pm
---

# Additive [[Attention.md]]
- [Bahdanau et al., 2015](https://arxiv.org/pdf/1409.0473.pdf)
- Uses a one layer feedforward network to calculate [[Attention Alignment.md|Attention Alignment]]
- Oh, basically it is the same as [[Bahdanau Attention.md|Bahdanau Attention]]



