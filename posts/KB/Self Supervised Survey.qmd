---
toc: true
title: Self Supervised Survey

categories: ['ssl']
date modified: Tuesday 6th June 2023, Tue
date created: Tuesday 6th June 2023, Tue
---

# Self Supervised Survey


## Abstract
- Large-scale labeled data are generally required to train deep neural networks in order to obtain better performance in visual feature learning from images or videos for computer vision applications 
- as a subset of unsupervised learning methods, self-supervised learning methods are proposed to learn general image and video features from large-scale unlabeled data without using any human-annotated labels 

## Motivation
- The performance of deep convolutional neural networks (ConvNets) greatly depends on their capability and the amount of training data. 
- collection and annotation of large-scale datasets are time-consuming and expensive 
- Compared to image datasets, collection and annotation of video datasets are more expensive due to the temporal dimension 
- To avoid time-consuming and expensive data annotations, many self-supervised methods were proposed to learn visual features from large-scale unlabeled images or videos without using any human annotations 
- During the self-supervised training phase, a predefined pretext task is designed for ConvNets to solve, and the pseudo labels for the pretext task are automatically generated based on some attributes of data 
- Then the ConvNet is trained to learn object functions of the pretext task 
- After the self-supervised training finished, the learned visual features can be further transferred to downstream tasks (especially when only relatively small data available) as pretrained models to improve performance and overcome over- fitting. 
- shallow layers capture general low-level features like edges, corners, and textures while deeper layers capture task related high-level features 

- [Pseudo Label](Pseudo Label.qmd)

- [Pretext Task](Pretext Task.qmd)

- [Downstream Task](Downstream Task.qmd)

- [Weakly-supervised Learning](Weakly-supervised Learning.qmd)

## FORMULATION OF DIFFERENT LEARNING SCHEMAS
- [Supervised Learning Formulation](Supervised Learning Formulation.qmd)

- [Semi-Supervised Learning Formulation](Semi-Supervised Learning Formulation.qmd)

- [Weakly Supervised Learning Formulation](Weakly Supervised Learning Formulation.qmd)
- [Self-supervised Learning](Self-supervised Learning.qmd)

## NN
- [Spatiotemporal Convolutional Neural Network](Spatiotemporal Convolutional Neural Network.qmd)

## Pretext Tasks
- [Pretext Tasks](Pretext Tasks.qmd)

## Datasets
- [Places](Places.qmd)

- [Places365](Places365.qmd)

- [SUNCG](SUNCG.qmd)

- [SVHN](SVHN.qmd)

- [STL-10](STL-10.qmd)
- ![img_p11_1](img_p11_1.png) 

- [YFCC100M](YFCC100M.qmd)

- [SceneNet RGB-D](SceneNet RGB-D.qmd)
- [Moment in Time](Moment in Time.qmd)

- [Kinetics](Kinetics.qmd)

- [AudioSet](AudioSet.qmd)

- [KITTI](KITTI.qmd)

- [UCF101](UCF101.qmd)

- [HMDB51](HMDB51.qmd) 

## Other Tasks
- [Image Generation with Inpainting](Image Generation with Inpainting.qmd)

- [Image Generation with Super Resolution](Image Generation with Super Resolution.qmd)

- [Image Generation with Colorization](Image Generation with Colorization.qmd)

- [Learning with Context Similarity](Learning with Context Similarity.qmd)

- [Learning with Spatial Context Structure](Learning with Spatial Context Structure.qmd)

- [Learning with Labels Generated by Game Engines](Learning with Labels Generated by Game Engines.qmd)

- [Learning with Labels Generated by Hard-code Programs](Learning with Labels Generated by Hard-code Programs.qmd)

- [Learning from Video Colorization](Learning from Video Colorization.qmd)

- [Learning from Video Prediction](Learning from Video Prediction.qmd)

- [Learning from RGB-Flow Correspondence](Learning from RGB-Flow Correspondence.qmd)

- [Learning from Visual-Audio Correspondence](Learning from Visual-Audio Correspondence.qmd)

- [Ego-motion](Ego-motion.qmd)



