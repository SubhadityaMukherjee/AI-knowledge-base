---
title: Relative Multi Head Self Attention

tags: architecture 
---

# Relative Multi Head Self Attention
- [ZihangDai et al., 2019](https://arxiv.org/abs/1901.02860)
- 


## Backlinks

> - [Attention](Attention.md)
>   - [[Relative Multi Head Self Attention]]

_Backlinks last generated 2022-06-21 17:08:56_
