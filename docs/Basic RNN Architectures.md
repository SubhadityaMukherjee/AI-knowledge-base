---
title: Basic RNN Architectures
tags: architecture
date modified: Thursday, August 11th 2022, 12:32:57 am
date created: Tuesday, July 26th 2022, 8:33:15 pm
---

# Basic RNN Architectures

![[assets/Pasted image 20220307171009.png|im]]

- [[Recurrent]]
- [[SRN]]
- [[Stacking RNN]]
- [[Bi Directional RNN]]
- [[Seq2Seq]]
- [[Temporal Conv]]
- [[GRU|[GRU)](Gated Recurrent Unit (GRU|Gated Recurrent Unit (GRU|[GRU)]]]].md)
- [[LSTM|[LSTM)](Long Short Term Memory (LSTM|Long Short Term Memory (LSTM|[LSTM)]]]].md)

## Backlinks

> - [Speech Recognition](Speech Recognition.md)
>   - mixture of several [[Basic RNN Architectures]]
>    
> - [Teacher Forcing](Teacher Forcing.md)
>   - common technique to train [[Basic RNN Architectures]] or [[Transformer]]
>    
> - [Temporal [[Conv]]](Temporal Conv.md)
>   - Outperforms [[Basic RNN Architectures]] such as [[LSTM)](Long Short Term Memory (LSTM|Long Short Term Memory (LSTM)]].md) and [[GRU)](Gated Recurrent Unit (GRU|Gated Recurrent Unit (GRU)]].md)
>    
> - [Nasnet](Nasnet.md)
>   - Controller RNN ([[Basic RNN Architectures]]) produces architectures and evaluated until convergence
>    
> - [Seq2Seq](Seq2Seq.md)
>   - [[Basic RNN Architectures]]
>    
> - [Variational/[[Recurrent]] [[Dropout]]](VariationalRecurrent Dropout.md)
>   - [[Basic RNN Architectures]]
>    
> - [Phrase Representation Learning](Phrase Representation Learning.md)
>   - two [[Recurrent|recurrent]] neural networks [[Basic RNN Architectures]] that is together able to learn the mapping from a sequence of an arbitrary length to another sequence, possibly from a different set, of an arbitrary length.
>    
> - [Elman 1990](Elman 1990.md)
>   - [[Basic RNN Architectures]] can find these
>    
> - [Mirman Et Al](Simulations_Of_language.md)
>   - [[Basic RNN Architectures]]

_Backlinks last generated 2022-10-04 13:01:19_
