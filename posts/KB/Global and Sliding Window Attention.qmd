---
title: Global and Sliding Window Attention

categories: ['architecture']
date modified: Monday, October 10th 2022, 2:02:26 pm
date created: Tuesday, July 26th 2022, 8:33:15 pm
---

# Global and [Sliding Window Attention](Sliding%20Window%20Attention.qmd)
- [Sliding Window Attention](Sliding%20Window%20Attention.qmd) and [Dilated Sliding Window Attention](Dilated%20Sliding%20Window%20Attention.qmd) are not always enough
- global [attention](Attention.qmd)‚Äù on few pre-selected input locations.
- This [attention](Attention.qmd) is operation symmetric: that is, a token with a global [attention](Attention.qmd) attends to all tokens across the sequence, and all tokens in the sequence attend to it
- ![Pasted%20image%2020220621181106](images/Pasted%20image%2020220621181106.png)



