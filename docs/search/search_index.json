{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Subhaditya's KB","text":"<p>About this blog - This is my little knowledge base - If there is something you are looking for, just type it into the search bar     - Of course, since this is not google, it is not a one stop shop     - In essence, it will have something on things that I learn - How to go about finding things?     - Scroll the sidebar and pick something you like. Click the links inside it to go about. Choose your own adventure.</p>"},{"location":"#links","title":"Links","text":"<ul> <li>My Github</li> <li>Blogs</li> <li>Medium -&gt; More blogs</li> <li>My Linkedin</li> <li>My Art</li> <li>Email</li> </ul>"},{"location":"KB/","title":"Knowledge Base","text":""},{"location":"KB/#welcome","title":"Welcome!","text":"<ul> <li>This is my little knowledge base</li> <li>If there is something you are looking for, just type it into the search bar<ul> <li>Of course, since this is not google, it is not a one stop shop</li> <li>In essence, it will have something on things that I learn</li> </ul> </li> <li>How to go about finding things?<ul> <li>Scroll the sidebar and pick something you like. Click the links inside it to go about. Choose your own adventure.</li> </ul> </li> </ul>"},{"location":"KB/#links","title":"Links","text":"<ul> <li>My Github</li> <li>Blogs</li> <li>Medium -&gt; More blogs</li> <li>My Linkedin</li> <li>My Art</li> <li>Email</li> </ul>"},{"location":"KB/0-1%20Loss/","title":"0-1 Loss","text":""},{"location":"KB/0-1%20Loss/#0-1-loss","title":"0-1 Loss","text":"<ul> <li> \\[\\begin{cases} 1 &amp; f(x)=y \\\\ 0 &amp; f(x)\\neq y\\end{cases}\\] </li> <li>Classification</li> </ul>"},{"location":"KB/1D%20piecewise%20linear%20interpolation/","title":"1D piecewise linear interpolation","text":""},{"location":"KB/1D%20piecewise%20linear%20interpolation/#1d-piecewise-linear-interpolation","title":"1D Piecewise Linear Interpolation","text":""},{"location":"KB/1D%20piecewise%20linear%20interpolation/#1d-piecewise-linear-interpolation_1","title":"1D Piecewise Linear Interpolation","text":""},{"location":"KB/1D-ALVINN/","title":"1D-ALVINN","text":""},{"location":"KB/1D-ALVINN/#1d-alvinn","title":"1D-ALVINN","text":"<ul> <li>road simulator</li> <li>predict steering angle from road conditions</li> <li>augmented to produce additional labels representing new tasks, namely: road is one or two lanes, left edge, center, and right edge road locations, location and intensity of road centerline, intensity of road surface and region bordering road</li> <li>Root [MSE]  of steering angle is loss </li> </ul>"},{"location":"KB/2%20X%202%20Study/","title":"2 X 2 Study","text":""},{"location":"KB/2%20X%202%20Study/#2-x-2-study","title":"2 X 2 Study","text":"<ul> <li>First factor has 2 levels (The vs each)</li> <li>Second factor has 2 levels (Distributive vs. Collective situations)</li> <li>We are trying to see how these fixed factors effect responses</li> <li>We control the fixed factors</li> <li>We carefully design them so we know what category an item presented to a participant belongs to</li> </ul>"},{"location":"KB/2%20byte%20character%20set/","title":"2 byte character set","text":""},{"location":"KB/2%20byte%20character%20set/#2-byte-character-set","title":"2 Byte Character Set","text":"<ul> <li>65,536 unique characters Pairs of Bytes for a Single Character</li> <li>Sometimes single byte letters, spaces and punctuations will be interspersed with two-byte characters</li> <li>Chinese characters are encoded in two format:<ul> <li>Big-5 - Complex Mandarin</li> <li>GB - Simple form</li> </ul> </li> </ul>"},{"location":"KB/8%20bit%20character%20set/","title":"8 bit character set","text":""},{"location":"KB/8%20bit%20character%20set/#8-bit-character-set","title":"8 Bit Character Set","text":"<ul> <li>First 128 characters are reserved for ASCII</li> <li>ISO-8859 series of 10+ Character Sets for most European Languages</li> <li>Results in large number of overlapping character sets for different languages</li> </ul>"},{"location":"KB/A%20declarative%20modular%20framework%20for%20representing%20and%20applying%20ethical%20principles/","title":"A declarative modular framework for representing and applying ethical principles.","text":""},{"location":"KB/A%20declarative%20modular%20framework%20for%20representing%20and%20applying%20ethical%20principles/#a-declarative-modular-framework-for-representing-and-applying-ethical-principles","title":"A Declarative Modular Framework for Representing and Applying Ethical Principles.","text":"<ul> <li>Fiona Berreby, Gauvain Bourgne, and JeanGabriel Ganascia</li> <li>high level action language for designing ethical agents in an attempt to shift the burden of moral reasoning to the autonomous agents</li> <li>collects action, event and situation information to enable an agent to simulate the outcome of various courses of actions</li> <li>event traces are then passed to the causal engine to produce causal traces</li> <li>ethical specifications and priority of ethical considerations under a given situation are used to compute the goodness assessment on the consequences</li> <li>combined with deontological specifications (duties, obligations, rights) to produce a final rightfulness assessment</li> </ul>"},{"location":"KB/A%20low-cost%20ethics%20shaping%20approach%20for%20designing%20reinforcement%20learning%20agents/","title":"A low-cost ethics shaping approach for designing reinforcement learning agents","text":""},{"location":"KB/A%20low-cost%20ethics%20shaping%20approach%20for%20designing%20reinforcement%20learning%20agents/#a-low-cost-ethics-shaping-approach-for-designing-reinforcement-learning-agents","title":"A Low-cost Ethics Shaping Approach for Designing Reinforcement Learning Agents","text":"<ul> <li>Yueh-Hua Wu and Shou-De Lin.</li> <li>authors investigated how to enable RL to take ethics into account ethics shaping</li> <li>assuming that the majority of observed human behaviours are ethical, the proposed approach learns ethical shaping policies from available human behaviour data in given application domains</li> <li>rewards positive ethical decisions, punishes negative ethical decisions, and remains neutral when ethical considerations are not involved</li> </ul>"},{"location":"KB/A%20matter%20of%20ambiguity%3F%20Using%20eye%20movements%20to%20examine%20collective%20vs%20distributive%20interpretations%20of%20plural%20sets/","title":"A matter of ambiguity? Using eye movements to examine collective vs. distributive interpretations of plural sets","text":""},{"location":"KB/A%20matter%20of%20ambiguity%3F%20Using%20eye%20movements%20to%20examine%20collective%20vs%20distributive%20interpretations%20of%20plural%20sets/#a-matter-of-ambiguity-using-eye-movements-to-examine-collective-vs-distributive-interpretations-of-plural-sets","title":"A Matter of Ambiguity? Using Eye Movements to Examine Collective Vs. Distributive Interpretations of Plural Sets","text":"<ul> <li>Christine Boylan, Dimka Atanassov, Florian Schwarz, John Trueswell</li> </ul>"},{"location":"KB/A%20matter%20of%20ambiguity%3F%20Using%20eye%20movements%20to%20examine%20collective%20vs%20distributive%20interpretations%20of%20plural%20sets/#previous-work","title":"Previous Work","text":"<ul> <li>Frazier et al. (1999) used eye-tracking reading times to compare processing loads of sentences that were explicitly distributive (involving the adverb each), explicitly collective (involving the adverb together), and locally indeterminate at the predicate.</li> <li>Having found evidence for increased processing load associated with distributive sentences, they concluded that the processor initially pursues a collective reading, and thus the distributive / collective distinction was one of ambiguity and not vagueness.</li> <li>However, an increased processing load for the distributive reading might be expected regardless of whether the underlying representation is vague or ambiguous</li> <li>processor must stipulate a distributive operator D (the spell-out of which is each) to interpret a distributive meaning, which may incur processing delays</li> <li>Moreover, increased reading times at the point of disambiguation preclude conclusions about exactly when listeners may have committed to a distributive reading during the processing the underdetermined predicate.</li> </ul>"},{"location":"KB/A%20matter%20of%20ambiguity%3F%20Using%20eye%20movements%20to%20examine%20collective%20vs%20distributive%20interpretations%20of%20plural%20sets/#introduction","title":"Introduction","text":"<ul> <li>eye movements of listeners were recorded to investigate the representation of collective vs. distributive interpretations of plural subjects in light of the Minimal Semantic Commitment (MSC) hypothesis</li> <li>Minimal Semantic Commitment</li> <li>The crucial difference between these two proposed representation types is that an ambiguous representation forces a decision about an interpretation, while a vague representation tolerates unspecified features.</li> <li>Given the prediction that an ambiguous item will prompt the processor to converge on one interpretation even in the absence of disambiguating information, we tested whether sentences underdetermined for collectivity / distributivity would nonetheless cause listeners to converge on a single interpretation.</li> <li>Rather than relying on processing times to infer representational commitments, we employed the visual world paradigm to track which representations subjects considered over the course of hearing a sentence</li> </ul>"},{"location":"KB/A%20matter%20of%20ambiguity%3F%20Using%20eye%20movements%20to%20examine%20collective%20vs%20distributive%20interpretations%20of%20plural%20sets/#method","title":"Method","text":"<ul> <li>The eye movements of 24 participants were recorded as they listened to explicit/indeterminate collective/distributive sentences while they considered collective and distributive acts depicted on a computer screen</li> <li>An earlier switch in gaze to one of the two images would indicate a processing preference for one interpretation over the other. Results and Discussion</li> <li>Explicitly collective sentences prompted looks to the collective scenario at the point of disambiguation (i.e. together) and explicitly distributive sentences (using each) prompted looks to the distributive scenario (Fig. 2a)</li> <li>Crucially, however, the indeterminate, nulldisambiguator sentences patterned along the same trajectory as together sentences: the predicate alone prompted looks to the collective, prior to hearing the final word of the sentence</li> <li>We also compared the proportion of looks averaged across two time windows: an 800- ms interval before the onset of the predicate and an 800-ms time window following the predicate onset (Fig. 2b)</li> <li>Since the distinction between ambiguity and vagueness lies at the interface of semantics and pragmatics, it is particularly important that we find a psychometric realization of the difference between these two types of representations.</li> <li>Here we presented a method by which to investigate the time courses of these representations as they relate to distributivity, and we suggest this method may further contribute to the study of the semantics-pragmatics interface at large.</li> </ul>"},{"location":"KB/A%20matter%20of%20ambiguity%3F%20Using%20eye%20movements%20to%20examine%20collective%20vs%20distributive%20interpretations%20of%20plural%20sets/#results","title":"Results","text":"<ul> <li>In an ANOVA of proportion of looks to collective and distributive scenes, we found significant interactions between disambiguator and time window.</li> <li>In a targeted analysis of disambiguator effects in each time window, we found significant differences between together and each sentences and the null and each sentences after the predicate onset but not before</li> <li>Moreover, the together sentences did not significantly differ from the null form.</li> <li>Thus, despite a lack of explicit disambiguating information, the indeterminate, nulldisambiguator sentences nonetheless prompted looks to the collective scenario, which was reliably different from the time course of distributive-directed each sentences.</li> <li>This provides evidence that the listener has committed to the collective interpretation in the absence of disambiguating information.</li> <li>This is consistent with a theory that treats the collective / distributive distinction as ambiguous rather than vague.</li> <li>The results also indicate that this processing commitment is essentially immediate; i.e., as soon as listeners begin hearing the ambiguous predicate, they show a preference for the collective interpretation.</li> </ul>"},{"location":"KB/A%20matter%20of%20ambiguity%3F%20Using%20eye%20movements%20to%20examine%20collective%20vs%20distributive%20interpretations%20of%20plural%20sets/#pictures","title":"Pictures","text":""},{"location":"KB/A%20survey%20on%20Image%20Data%20Augmentation%20for%20Deep%20Learning/","title":"Data Augmentation with Curriculum Learning","text":"<ul> <li>@shortenSurveyImageData2019</li> <li>Data Augmentation with Curriculum Learning</li> </ul>"},{"location":"KB/A%20survey%20on%20Image%20Data%20Augmentation%20for%20Deep%20Learning/#methods","title":"Methods","text":"<ul> <li>Geometric Transformations</li> <li>Flipping</li> <li>Color Space Transform</li> <li>Cropping</li> <li>Noise Injection</li> <li>Color Space Transformations</li> <li>Kernel Filters</li> <li>Feature Space Augmentation</li> <li>SMOTE </li> <li>GAN\u2010based Data Augmentation</li> <li>Meta Learning Data Augmentations</li> <li>Neural Augmentation</li> <li>Smart Augmentation</li> <li>AutoAugment</li> <li>Augmented Random Search</li> <li>Test-time Augmentation</li> <li>SamplePairing</li> <li>Data Augmentation with Curriculum Learning</li> <li>Alleviating Class Imbalance with Data Augmentation</li> </ul>"},{"location":"KB/A%20survey%20on%20Image%20Data%20Augmentation%20for%20Deep%20Learning/#discussion","title":"Discussion","text":"<ul> <li>It is easy to explain the benefit of horizontal Flipping or random cropping</li> <li>However, it is not clear why mixing pixels or entire images together such as in PatchShuffle regularization or SamplePairing is so effective.</li> <li>dditionally, it is difficult to interpret the representations learned by neural networks for GAN-based augmentation, variational auto-encoders, and meta-learning.</li> <li>An interesting characteristic of these augmentation methods is their ability to be combined together.</li> <li>The GAN framework possesses an intrinsic property of recursion which is very interesting</li> <li>Samples taken from GANs can be augmented with traditional augmentations such as lighting filters, or even used in neural network augmentation strategies such as [Smart Augmentation] or Neural Augmentation to create even more samples. These samples can be fed into further GANs and dramatically increase the size of the original dataset.</li> <li>An interesting question for practical Data Augmentation is how to determine postaugmented dataset size.</li> <li>no consensus about the best strategy for combining data warping and oversampling techniques</li> <li>One important consideration is the intrinsic bias in the initial, limited dataset</li> <li>There are no existing augmentation techniques that can correct a dataset that has very poor diversity with respect to the testing data</li> </ul>"},{"location":"KB/A%20voting-based%20system%20for%20ethical%20decision%20making/","title":"A voting-based system for ethical decision making","text":""},{"location":"KB/A%20voting-based%20system%20for%20ethical%20decision%20making/#a-voting-based-system-for-ethical-decision-making","title":"A Voting-based System for Ethical Decision Making","text":"<ul> <li>Ritesh Noothigattu, Snehalkumar \u2018Neil\u2019 S. Gaikwad, Edmond Awad, Sohan Dsouza, Iyad Rahwan, Pradeep Ravikumar, and Ariel D. Procaccia</li> <li>voting-based system for autonomous entities to make collective ethical decisions leverages data collected from the Moral Machine project</li> <li>Self reported preference over different outcomes under diverse ethical dilemmas are used to learn models of preference for the human voters over different alternative outcomes.</li> <li>individual models are then summarized to form a model that approximates the collective preference of all voters</li> </ul>"},{"location":"KB/ABN%20Amro%20AI%20Dev/","title":"ABN Amro AI Dev","text":""},{"location":"KB/ABN%20Amro%20AI%20Dev/#abn-amro-motivation-letter-subhaditya","title":"ABN AMRO Motivation Letter - Subhaditya","text":"<p>During COVID, it became increasingly clear how important it was to have stable financial systems. No matter your position in the financial sector, it is essential to consider the customers affected by the pipeline. That being the case, many systems can be created to improve the user experience. I have been using ABN AMRO as my bank of choice ever since I came to the Netherlands two years ago, and recently, I started noticing many AI features such as predicted recurring costs, automated filling in of details from ID cards during new user creation, etc. Given the active development of such features, I am interested in an AI development position at ABN AMRO.</p> <p>My expertise is a combination of data analytics and computer vision, and as of a month ago, I also have a Masters in Artificial Intelligence from the University of Groningen. I am familiar with the tools required for basic and advanced AI from internships, research projects, papers, freelance work, and many personal projects. In the past, I interned at the AI divisions of Emirates NBD (one of the largest banks in the UAE) and KPMG (one of the big four consultancy firms) in similar teams with similar goals of developing disruptive AI solutions, and I quite enjoyed the work there. Working in a team that has a start-up vibe but also in the context of a much larger system is also something that I enjoy. As this position offers something similar, I can contribute to any team I get the chance to work with.</p> <p>In any team, it is essential that each of the members can contribute something to the overall development of the projects. Although I have a lot to learn, I genuinely enjoy developing AI solutions that have some impact, and I hope to get to work with the amazing AI team at ABN AMRO and ship some useful solutions to the users (myself included).</p>"},{"location":"KB/ABN%20amro%20ml/","title":"ABN amro ml","text":""},{"location":"KB/ABN%20amro%20ml/#abn-amro-motivation-letter-subhaditya","title":"ABN AMRO Motivation Letter - Subhaditya","text":"<p>During COVID, it became increasingly clear just how important it was to have stable financial systems. At the end of the day, no matter what position you work in in the financial sector, it is important to consider the customers that will be affected by the pipeline. Even small-scale bank frauds can affect a large number of people. Growing up, I heard many stories of such cases and how many people lost their livelihoods because of financial crime. Back then, of course, I could do nothing about it. But now I have a small chance of contributing to the fight for financial safety, and I want to take it.</p> <p>A while back, I had the privilege of doing an internship at Emirates NBD, one of the biggest banks in the UAE. There I was involved in a project to build a similar system to detect financial fraud. I helped build the ETL pipelines and ML models to identify load defaulters and also generate forecasts of how much customers might be able to pay based on their historical records. I learned quite a bit about the proceedings there. It has been a few years since that internship, and I have completed my Masters in Artificial Intelligence as of last month. That being the case, I am now more prepared to tackle the challenges that this job might bring about.</p> <p>I hope to contribute to this and any future projects to the best of my abilities. It would be good to give customers a bit more peace of mind by helping create such systems.</p>"},{"location":"KB/ACT-R%20Chunk/","title":"ACT-R Chunk","text":""},{"location":"KB/ACT-R%20Chunk/#act-r-chunk","title":"ACT-R Chunk","text":"<ul> <li>id</li> <li>Attribute<ul> <li>Attributes point to other chunks (eg: fact3+2)</li> <li>number of attributes</li> </ul> </li> <li>Activation<ul> <li>determines priority of retrieval</li> <li>if below threshold, chunk cannot be retrieved</li> <li>determines time of retrieval</li> <li>decays with time</li> <li>depends on<ul> <li>How often retrieved or recreated</li> <li>context</li> </ul> </li> </ul> </li> </ul>"},{"location":"KB/ACT-R/","title":"ACT-R","text":""},{"location":"KB/ACT-R/#act-r","title":"ACT-R","text":"<ul> <li>Explain human behavior</li> <li>Manual Control<ul> <li>Motor Cortex</li> </ul> </li> <li>Visual Perception<ul> <li>Visual Cortex</li> </ul> </li> <li>Problem State<ul> <li>Parietal lobe</li> <li>Store intermediate results</li> </ul> </li> <li> <p>Declarative memory</p> </li> <li> <p>Perception</p> </li> <li>Control State<ul> <li>Anterior Cingulate</li> <li>Keep track of goals</li> <li>What? How far?</li> </ul> </li> <li>Time perception</li> <li>Ideas always get reinforced if retrieve</li> </ul>"},{"location":"KB/ADE20K/","title":"ADE20K","text":"<p>toc: true title: ADE20K</p> <p>categories: ['temp']</p>"},{"location":"KB/ADE20K/#ade20k","title":"ADE20K","text":""},{"location":"KB/ADVENT/","title":"ADVENT","text":""},{"location":"KB/ADVENT/#advent","title":"ADVENT","text":"<ul> <li>blog</li> <li>paper</li> <li></li> <li>ADVENT is a flexible technique for bridging the gap between two different domains through entropy minimization</li> <li>models trained only on source domain tend to produce over-confident, i.e., low-entropy, predictions on source-like images and under-confident, i.e., high-entropy, predictions on target-like ones</li> <li>Consequently by minimizing the entropy on the target domain, we make the feature distributions from the two domains more similar.</li> <li>More annotated data has been shown to always improve performance of DNNs</li> <li>Here we are working on Unsupervised DA (UDA), which is a more challenging task where we have access to labeled source samples and only unlabeled target samples. We use as source, data generated by a simulator or video game engine, while for target we consider real-data from car-mounted cameras.</li> <li>The main approaches for UDA include discrepancy minimization between source and target feature distributions usually achieved via adversarial training , , self-training with pseudo-labels  and generative approaches , .</li> <li>We present our two proposed approaches for entropy minimization using (i) an unsupervised entropy loss and (ii) adversarial training. To build our models, we start from existing semantic segmentation frameworks and add an additional network branch used for domain adaptation.</li> <li>Direct entropy minimization</li> <li>Entropy minimization by adverarial learning</li> <li>GTA5</li> <li>SYNTHIA</li> <li>Cityscapes</li> </ul>"},{"location":"KB/ALBERT/","title":"ALBERT","text":""},{"location":"KB/ALBERT/#albert","title":"ALBERT","text":"<ul> <li>Lite BERT</li> <li></li> <li>blog #Roam-Highlights</li> <li>perhaps even better when scaled to the same number of parameters as BERT</li> <li>Factorized Embedding Parameters</li> <li>cross-layer parameter sharing</li> <li>inter-sentence coherence loss</li> <li>We can see that the ALBERT base model attempts to mimic BERT base, with a hidden state size of 768, parameter sharing and a smaller embedding size due to factorization explained above. Contrary to the 108 million parameters, it has only 12 million. This makes a big difference when training the model.</li> <li>Another model, ALBERT xxlarge (extra-extra large) has 235 million parameters, with 12 encoder segments, 4096-dimensional hidden state and 128-dimensional embedding size. It also includes parameter sharing.</li> <li>GLUE</li> <li>SQuAD</li> <li>RACE</li> <li>For Factorized Embedding Parameters, the authors report good performance. Both the case where cross-layer parameters were not shared and where they were, are reported. Without sharing, larger embedding sizes give better performance. With sharing, performance boosts satisfy at an embedding size of 128 dimensions. That's why the 128-size embeddings were used in the table above.</li> <li>For cross-layer parameter sharing, the authors looked at not performing cross-layer sharing, performing cross-layer sharing for the feedforward segments only, performing sharing for the attention segments, and performing sharing for all subsegments. It turns out that sharing the parameters for the attention segments is most effective, while sharing the feedforward segment parameters does not contribute significantly. This clearly illustrates the important role of the attention mechanism in Transformer models. Because, however, all-segment sharing significantly decreases the number of parameters, at only slightly worse performance compared to attention-only sharing, the authors to perform all-segment sharing instead.</li> <li>For the SOP task, we can read that if NSP is performed on a SOP task, performance is poor. NSP on NSP of course performs well, as well as SOP on SOP. However, if SOP is performed on NSP, it performs really well. This suggests that SOP actually captures sentence coherence whereas NSP might not, and that SOP yields a better result than NSP.</li> </ul>"},{"location":"KB/ANOVA/","title":"ANOVA","text":""},{"location":"KB/ANOVA/#anova","title":"ANOVA","text":"<ul> <li>For an ANOVA you aggregate the data</li> <li>so that you get the mean responses per condition for each individual, look at the differences between their means, and then check if the differences for all the</li> </ul>"},{"location":"KB/ASCII/","title":"ASCII","text":""},{"location":"KB/ASCII/#ascii","title":"ASCII","text":"<ul> <li>7 bit character set</li> <li>Roman, Latin</li> </ul>"},{"location":"KB/AUC-Borji/","title":"AUC-Borji","text":""},{"location":"KB/AUC-Borji/#auc-borji","title":"AUC-Borji","text":"<ul> <li>\"PR is calculated in the same way as AUC-Judd\"</li> <li>\"a location-based metric\"</li> <li>FPR is obtained by calculating the proportion of negatives in the thresholded region, where the negatives are collected uniformly at random.</li> <li>\"AUC for the curve is calculated as AUC-Borji.\"</li> <li>\"TPR is calculated in the same way as AUC-Judd\"</li> <li>\"location-based metric\"</li> </ul>"},{"location":"KB/AUC-Judd/","title":"AUC-Judd","text":""},{"location":"KB/AUC-Judd/#auc-judd","title":"AUC-Judd","text":"<ul> <li>\"location-based metric\"</li> <li>The true positive rate (TPR) is calculated as the proportion of fixations falling into the thresholded saliency map</li> <li>The false positive rate (FPR) is calculated as the proportion of no-fixated pixels in the thresholded saliency map.</li> <li>After calculating TPR and FPR at each threshold, the area under the curve (AUC) is calculated for the curve of TPR against FPR.</li> </ul>"},{"location":"KB/Absolute%20Error/","title":"Absolute Error","text":""},{"location":"KB/Absolute%20Error/#absolute-error","title":"Absolute Error","text":"<ul> <li> \\[\\lvert y-f(x)\\rvert\\] </li> <li>Penalize large errors</li> </ul>"},{"location":"KB/Acceleration/","title":"Acceleration","text":""},{"location":"KB/Acceleration/#acceleration","title":"Acceleration","text":"<ul> <li>Change in Velocity wrt Time</li> <li> \\[a_{avg}= \\Delta v/\\Delta t\\] </li> </ul>"},{"location":"KB/Accessibility/","title":"Accessibility","text":""},{"location":"KB/Accessibility/#accessibility","title":"Accessibility","text":"<ul> <li>a minor subset of the reviewed contributions argues for explainability as the property that allows end users to get more involved in the process of improving and developing a certain ML model</li> <li>explainable models will ease the burden felt by non-technical or non-expert users when having to deal with algorithms that seem incomprehensible at first sight</li> </ul>"},{"location":"KB/Action%20Component/","title":"Action Component","text":""},{"location":"KB/Action%20Component/#action-component","title":"Action Component","text":"<ul> <li>reactively dispatches and monitors the execution of actions.</li> </ul>"},{"location":"KB/Action%20Potential/","title":"Action Potential","text":""},{"location":"KB/Action%20Potential/#action-potential","title":"Action Potential","text":"<ul> <li>Sometimes called a \u201cspike\u201d or described as a neuron \u201cfiring,\u201d an action potential occurs when there is a significant increase in the electrical activity along the membrane of a nerve cell. It is associated with neurons passing electrochemical messages down the axon, releasing neurotransmitters to neighboring cells in the synapse.</li> </ul>"},{"location":"KB/Action%20Transitive%20verb/","title":"Action Transitive verb","text":""},{"location":"KB/Action%20Transitive%20verb/#action-transitive-verb","title":"Action Transitive Verb","text":"<ul> <li>a verb has a direct object + verb</li> <li>I made her lower her head or body</li> </ul>"},{"location":"KB/Activation%20Functions/","title":"Activation Functions","text":"<ul> <li>general rule \"which is better\"</li> <li>SELU &gt; Elu &gt; Leaky Relu &gt; Relu &gt; Tanh &gt; Sigmoid</li> </ul>"},{"location":"KB/Active%20Compliant%20Robot/","title":"Active Compliant Robot","text":""},{"location":"KB/Active%20Compliant%20Robot/#active-compliant-robot","title":"Active Compliant Robot","text":"<ul> <li>An active compliant robot is one in which motion modification during the performance of a task is initiated by the control system. The induced motion modification is slight, but sufficient to facilitate the completion of a desired task.</li> </ul>"},{"location":"KB/Active%20tracking/","title":"Active tracking","text":""},{"location":"KB/Active%20tracking/#active-tracking","title":"Active Tracking","text":"<ul> <li>hz evaluated moment-to-moment  </li> <li>Is it already time to start preparing?</li> <li>Makes your models run much slower!</li> </ul>"},{"location":"KB/Actuator/","title":"Actuator","text":""},{"location":"KB/Actuator/#actuator","title":"Actuator","text":"<ul> <li>A power mechanism used to effect motion, or maintain position of the robot (for example, a motor which converts Electrical Energy to effect motion of the robot) (R15.07). The actuator responds to a signal received from the control system.</li> </ul>"},{"location":"KB/Acute/","title":"Acute","text":""},{"location":"KB/Acute/#acute","title":"Acute","text":"<ul> <li>A condition that is often severe but starts and ends quickly</li> </ul>"},{"location":"KB/AdaDelta/","title":"AdaDelta","text":""},{"location":"KB/AdaDelta/#adadelta","title":"AdaDelta","text":"<ul> <li> \\[RMS[\\Delta \\theta]_{t}= \\sqrt{E[\\Delta \\theta^{2}]_{t}+ \\epsilon}$$ $$\\begin{align}\\\\ &amp; \\Delta \\theta_{t}= -\\frac{RMS[\\Delta \\theta]_{t-1}}{RMS[g]_{t}}g_{t}\\\\ &amp; \\theta_{t+1}= \\theta_{t}+ \\Delta \\theta_{t} \\end{align}\\] </li> </ul>"},{"location":"KB/AdaIn/","title":"AdaIn","text":""},{"location":"KB/AdaIn/#adain","title":"AdaIn","text":"<ul> <li>paper</li> <li> \\[AdaIN(x,y) = \\sigma(y) \\big( \\frac{x-\\mu(x)}{\\sigma (x)} \\big)\\] </li> <li>Adaptive Instance Normalization\u00a0is a normalization method that aligns the mean and variance of the content features with those of the style features.</li> <li>no learnable affine features</li> <li>Adaptively computes affine params from style input</li> </ul>"},{"location":"KB/Adagrad/","title":"Adagrad","text":""},{"location":"KB/Adagrad/#adagrad","title":"Adagrad","text":"<ul> <li>Past squared grads as scaling factor for learning rate</li> <li> \\[\\begin{align}&amp; g_{t,i} = \\nabla_\\theta J(\\theta_{t,i}) \\\\ &amp; \\theta_{t+1, i} = \\theta_{t,i} - \\eta \\cdot g_{t,i} \\\\ &amp; \\theta_{t+1, i} = \\theta_{t,i} - \\frac{\\eta}{\\sqrt{G_{t,ii} + \\epsilon}} \\cdot g_{t,i} \\end{align}\\] </li> <li>Doesnt forget past gradients</li> </ul>"},{"location":"KB/Adam/","title":"Adam","text":""},{"location":"KB/Adam/#adam","title":"Adam","text":"<ul> <li>Supervised learning</li> <li>Rmsprop + Momentum</li> <li>Corrects bias in exponentially weighted averages</li> <li>Struggles with large no of params -&gt; Over smooths the gradient</li> <li> \\[\\begin{align} &amp; s_n = \\rho_1 s_{n-1} + (1-\\rho_1) g_n \\\\ &amp; r_n = \\rho_2 r_{n-1} + (1-\\rho_2) g_n \\odot g_n \\\\ &amp; \\Theta_{n+1} = \\Theta_n - \\alpha \\frac{s_n}{\\epsilon + \\sqrt{r_n}} \\frac{1-\\rho_2^n}{1-\\rho^n_1} \\end{align}\\] </li> <li>First and second moments</li> </ul>"},{"location":"KB/AdamW/","title":"AdamW","text":""},{"location":"KB/AdamW/#adamw","title":"AdamW","text":"<ul> <li>@loshchilovDecoupledWeightDecay2019</li> </ul>"},{"location":"KB/AdamW/#adam-features","title":"Adam Features","text":"<ul> <li>why use the same learning rate for every parameter, when we know that some surely need to be moved further and faster than others</li> <li>Since the square of recent gradients tells us how much signal we're getting for each weight, we can just divide by that to ensure even the most sluggish weights get their chance to shine</li> <li>with a little tweak to keep early batches from being biased</li> <li>Few research articles used it to train their models, new studies began to clearly discourage to apply it and showed on several experiments that plain ole SGD with momentum was performing better.</li> <li></li> <li></li> <li>Ilya Loshchilov and Frank Hutter pointed out in their paper that the way weight decay is implemented in Adam in every library seems to be wrong, and proposed a simple way (which they call AdamW) to fix it</li> <li> <p>PhD student Jeremy Bernstein has pointed out that the claimed convergence problems are actually just signs of poorly chosen hyper-parameters, and that perhaps amsgrad won't fix things anyway. Another PhD student, Filip Korzeniowski, showed some early results that seemed to support this discouraging view of amsgrad.</p> </li> <li> <p>Weight Decay Vs L2 Regularization</p> </li> <li>Amsgrad</li> </ul>"},{"location":"KB/Adaptive%20Gradient%20Clipping/","title":"Adaptive Gradient Clipping","text":""},{"location":"KB/Adaptive%20Gradient%20Clipping/#adaptive-gradient-clipping","title":"Adaptive Gradient Clipping","text":"<ul> <li>clips gradients to the ratio between weight gradient and weight value</li> <li>Clipping parameter is more robust than in traditional GC</li> <li>Swapping Batch Normalisation for AGC<ul> <li>faster training for equally sized models</li> <li>Allows for even larger batch size training</li> </ul> </li> </ul>"},{"location":"KB/Adaptive%20Input%20Representation/","title":"Adaptive Input Representation","text":""},{"location":"KB/Adaptive%20Input%20Representation/#adaptive-input-representation","title":"Adaptive Input Representation","text":"<ul> <li>Adaptive Input Representations for Neural Language Modeling</li> <li>varying the size of input word embeddings for neural language modeling</li> <li>improve accuracy while drastically reducing the number of model parameters</li> <li>more than twice as fast to train than the popular character input CNN while having a lower number of parameters</li> <li>English Wikipedia</li> <li>Billion Word</li> </ul>"},{"location":"KB/Adaptive%20Whitening%20Saliency/","title":"Adaptive Whitening Saliency","text":"<ul> <li>@Adaptive deconvolutional networks for mid and high level feature learning</li> <li>is based on the whitening of low-level features and has shown good performance for saliency map estimation.</li> <li>uses the features extracted by the model pre-trained for scene recognition.</li> </ul>"},{"location":"KB/Adaptive%20Whitening%20Saliency/#adaptive-whitening-saliency","title":"Adaptive Whitening Saliency","text":""},{"location":"KB/Adding%20noise/","title":"Noise","text":""},{"location":"KB/Adding%20noise/#noise","title":"Noise","text":"<ul> <li>To training input data<ul> <li>Gaussian random noise</li> <li>Augmentation</li> </ul> </li> <li>While the algo runs<ul> <li>Dropout</li> </ul> </li> <li>Stochastic ensemble learning</li> </ul>"},{"location":"KB/Additive%20Attention/","title":"Additive Attention","text":""},{"location":"KB/Additive%20Attention/#additive-attention","title":"Additive Attention","text":"<ul> <li>Bahdanau et al., 2015</li> <li>Uses a one layer feedforward network to calculate Attention Alignment</li> <li>Oh, basically it is the same as Bahdanau Attention</li> </ul>"},{"location":"KB/Adjective/","title":"Adjective","text":""},{"location":"KB/Adjective/#adjective","title":"Adjective","text":"<ul> <li>Properties of objects</li> </ul>"},{"location":"KB/Adrenal%20Glands/","title":"Adrenal Glands","text":""},{"location":"KB/Adrenal%20Glands/#adrenal-glands","title":"Adrenal Glands","text":"<ul> <li>Located on top of each kidney, these two glands are involved in the body\u2019s response to stress and help regulate growth, blood glucose levels, and the body\u2019s metabolic rate. They receive signals from the brain and secrete several different hormones in response, including cortisol and adrenaline.</li> </ul>"},{"location":"KB/Adrenaline/","title":"Adrenaline","text":""},{"location":"KB/Adrenaline/#adrenaline","title":"Adrenaline","text":"<ul> <li>Also called epinephrine, this hormone is secreted by the adrenal glands in response to stress and other challenges to the body. The release of adrenaline causes a number of changes throughout the body, including the metabolism of carbohydrates to supply the body\u2019s energy demands and increased arousal or alertness.</li> </ul>"},{"location":"KB/Advantages%20of%20Federated%20Learning/","title":"Advantages of Federated Learning","text":""},{"location":"KB/Advantages%20of%20Federated%20Learning/#advantages-of-federated-learning","title":"Advantages of Federated Learning","text":"<ul> <li>All your information is locally stored and is never sent anywhere</li> <li>Saves your personalized data from being leaked</li> <li>Removes all connections to you</li> <li>Allows the model to be updated and become better without compromizing on privacy</li> <li>Nobody \"owns\" your data except you</li> </ul>"},{"location":"KB/Adverb/","title":"Adverb","text":""},{"location":"KB/Adverb/#adverb","title":"Adverb","text":"<ul> <li>Properties of verbs</li> <li>slowly, frequently, nally</li> </ul>"},{"location":"KB/Adversarial%20Distillation/","title":"Adversarial Distillation","text":""},{"location":"KB/Adversarial%20Distillation/#adversarial-distillation","title":"Adversarial Distillation","text":"<ul> <li>Furthermore, an effective intermediate supervision, i.e., the squeezed knowledge, was used by Shu et al. (2019) to mitigate the capacity gap between the teacher and the student.</li> <li>In the third category, adversarial knowledge dis- tillation is carried out in an online manner, i.e., the teacher and the student are jointly optimized in each it- eration (Wang et al., 2018e; Chung et al., 2020)</li> </ul>"},{"location":"KB/Adversarial%20Learning/","title":"Adversarial Learning","text":""},{"location":"KB/Adversarial%20Learning/#adversarial-learning","title":"Adversarial Learning","text":"<ul> <li>Consider data in a Manifold. The PDF is concentrated along a low dim Manifold \\(\\mathcal{M}\\)</li> <li>Now the original picture is a point on the Manifold (dim = output layer size)</li> <li>Add noise to the image such that the image now appears to be in a direction orthogonal to \\(\\mathcal{M}\\) -&gt; value of PDF shrinks dramatically</li> <li>Then the network has never seen this before and will return a random classification</li> </ul>"},{"location":"KB/Adversarial%20Loss/","title":"Adversarial Loss","text":""},{"location":"KB/Adversarial%20Loss/#adversarial-loss","title":"Adversarial Loss","text":"<ul> <li>We apply Adversarial Loss to both the Generators, where the Generator tries to generate the images of it's domain, while its corresponding discriminator distinguishes between the translated samples and real samples.</li> <li>Generator aims to minimize this loss against its corresponding Discriminator that tries to maximize it.</li> </ul>"},{"location":"KB/Adversarial%20Spatial%20Dropout%20for%20Occlusion/","title":"Adversarial Spatial Dropout for Occlusion","text":""},{"location":"KB/Adversarial%20Spatial%20Dropout%20for%20Occlusion/#adversarial-spatial-dropout-for-occlusion","title":"Adversarial Spatial Dropout for Occlusion","text":"<ul> <li>Crops region pixels to generate hard positives for object detection by learning key image regions</li> <li>Within the proposed region only 1/3 pixels are dropped after sorting based on magnitudes</li> <li>Dropped values are non-contiguous here as compared to previously discussed methods</li> </ul>"},{"location":"KB/Afferent/","title":"Afferent","text":""},{"location":"KB/Afferent/#afferent","title":"Afferent","text":"<ul> <li>Sensory Division</li> </ul>"},{"location":"KB/Affine%20Function/","title":"Affine Function","text":""},{"location":"KB/Affine%20Function/#affine-function","title":"Affine Function","text":"<ul> <li>b is a bias term which is padded at the end, size 1</li> <li>Function + bias</li> </ul>"},{"location":"KB/Affordance%20Detection%20Task%20Specific/","title":"Affordance Detection Task Specific","text":""},{"location":"KB/Affordance%20Detection%20Task%20Specific/#affordance-detection-task-specific","title":"Affordance Detection Task Specific","text":"<ul> <li>Kokic, Mia, et al. \u201cAffordance Detection for Task-Specific Grasping using Deep Learning.\u201d Humanoids 2017.</li> <li></li> <li></li> <li>Affordance Score vs Contact Constraint</li> </ul>"},{"location":"KB/Afib/","title":"Afib","text":""},{"location":"KB/Afib/#afib","title":"Afib","text":"<ul> <li>Atrial fibrillation, irregular and rapid heartbeats</li> </ul>"},{"location":"KB/Agglutinating%20words/","title":"Agglutinating words","text":""},{"location":"KB/Agglutinating%20words/#agglutinating-words","title":"Agglutinating Words","text":"<ul> <li>Words divide into smaller units with clear boundaries</li> <li>Compound words are hyphenated (as in English or not as in German)</li> <li>Nachkriegszeit ; Nichtraucher</li> <li>Single token words - end-of-line</li> <li>Multi-token words \u2013 Delhi-based</li> <li>String of Morphology Affix</li> </ul>"},{"location":"KB/Akaike%20Information%20Criterion/","title":"Akaike Information Criterion","text":""},{"location":"KB/Akaike%20Information%20Criterion/#akaike-information-criterion","title":"Akaike Information Criterion","text":"<ul> <li>Considers goodness-of-fit to the data and penalizes complexity of the model</li> <li> \\[AIC=\u22122log\u2061(L)+2q\\] </li> <li>where:</li> <li>L: likelihood function for a particular model</li> <li>q: number of variables of this model</li> <li>If error terms \\(\\epsilon\\) follows Normal Distribution , expected value 0 + constant variance \\(\\(AIC = \\frac{1}{\\eta \\sigma^{2}}(RSS + 2p \\hat \\sigma^2)\\)\\)</li> </ul>"},{"location":"KB/Aleatoric/","title":"Aleatoric","text":""},{"location":"KB/Aleatoric/#aleatoric","title":"Aleatoric","text":"<ul> <li>Uncertainty part of the data</li> <li>Sensor noise etc</li> <li>Simplest noise : additive noise \\(\\(f(x) = x^{3}+ \\epsilon\\)\\)</li> <li> \\[\\epsilon \\sim \\mathcal{N}(0, \\sigma^{2})\\] </li> <li>Homoscedatic</li> <li>Heteroscedatic</li> <li></li> </ul>"},{"location":"KB/Alex%20Net/","title":"Alex Net","text":""},{"location":"KB/Alex%20Net/#alex-net","title":"Alex Net","text":"<ul> <li>Dropout + Relu</li> <li>No of filters increase according to depth</li> <li></li> </ul>"},{"location":"KB/Algebra%20Cognitive%20Tutor/","title":"Algebra Cognitive Tutor","text":""},{"location":"KB/Algebra%20Cognitive%20Tutor/#algebra-cognitive-tutor","title":"Algebra Cognitive Tutor","text":"<ul> <li>Anderson's group (Anderson, Corbett, Koedinger, &amp; Pelletier, 1995), and has been extended and marketed by Carnegie Learning ( <li>Because it is so widely used and has undergone so many positive evaluations, it is arguably the most successful ITS in the world at this time.</li> <li>Inner loop: The inner loop monitors the student's steps while solving an algebra problem.</li> <li>Although most problems, including the one in Figure 2, involve using multiple representational tools (graphs, tables, etc.) to analyze a problem scenario, some problems focus only on specific tools, such as the equation solver. In Figure 2, the problem to be solved is shown in the upper left window. This problem has four parts, labeled 1 through 4. When the student began, the cells of the table in the worksheet window at the lower left were all empty. The student has filled every cell with a number, text or an algebraic formula. In the process of figuring out what to put in the cells, the student used the solver window (upper right) and the graphing window (lower right). Each time the student filled a table cell, plotted a point on the graph, entered an equation in the solver window, etc, the tutor gave immediate feedback that told the student whether the step was correct or incorrect.</li> <li>Outer loop: The outer loop in the Algebra I Algebra Cognitive Tutor selects an algebra problem for the student to do and makes sure that the student submits a solution. The tutor uses its fine-grained assessment to select a task that exercises a few knowledge components that the student has not yet mastered. When the student has mastered all the knowledge components in a unit (all the bars turn gold), the student is advanced to the next unit in the algebra curriculum.</li> <li>Step analysis: The tutor analyzes each student step in terms of a set of anticipated steps (S. Ritter, Blessing, &amp; Wheeler, 2003). The set of anticipated steps for a problem is precomputed by solving the problem in all acceptable ways by running a rule-based problem solver. The rules are written to correspond to knowledge components. Each step is associated with the rules that were used to generate it during the precomputation. During tutoring, the student's step is matched against these anticipated steps.</li> <li>When a student's step matches an anticipated step, the student is credited in the assessment with having applied the associated knowledge components.</li>"},{"location":"KB/Allele/","title":"Allele","text":""},{"location":"KB/Allele/#allele","title":"Allele","text":"<ul> <li>One of two or more varying forms of a gene due to genetic mutation.</li> <li>Differing alleles, which can be found at the same spot on a chromosome, produce variation in inherited characteristics such as hair color or blood type.</li> </ul>"},{"location":"KB/Alleviating%20Class%20Imbalance%20with%20Data%20Augmentation/","title":"Alleviating Class Imbalance with Data Augmentation","text":""},{"location":"KB/Alleviating%20Class%20Imbalance%20with%20Data%20Augmentation/#alleviating-class-imbalance-with-data-augmentation","title":"Alleviating Class Imbalance with Data Augmentation","text":"<ul> <li>Data Augmentation falls under a Data-level solution to class imbalance and there are many different strategies for implementation.</li> <li>A naive solution to oversampling with Data Augmentation would be a simple random oversampling with small geometric transformations such as a 30\u00b0 rotation</li> <li>One problem of oversampling with basic image transformations is that it could cause overfitting on the minority class which is being oversampled</li> <li>The biases present in the minority class are more prevalent post-sampling with these techniques.</li> <li>Neural Style Transfer is an interesting way to create new images. These new images can be created either through extrapolating style with a foreign style or by interpolating styles amongst instances within the dataset.</li> <li>Oversampling with GANs can be done using the entire minority class as 'real' examples, or by using subsets of the minority class as inputs to GANs</li> <li>The use of evolutionary sampling to find these subsets to input to GANs for class sampling is a promising area for future work.</li> </ul>"},{"location":"KB/Allomorph/","title":"Allomorph","text":""},{"location":"KB/Allomorph/#allomorph","title":"Allomorph","text":"<ul> <li>Variants of the same morpheme but cant be replaced by another</li> <li>Un \u2013 happy gives unhappy</li> <li>In-comprehensible gives incomprehensible</li> </ul>"},{"location":"KB/Alpha%20Waves/","title":"Alpha Waves","text":""},{"location":"KB/Alpha%20Waves/#alpha-waves","title":"Alpha Waves","text":"<ul> <li>9-14 Hz</li> <li>Drowsy/Inhibition</li> <li></li> </ul>"},{"location":"KB/Alphacode/","title":"Alphacode","text":""},{"location":"KB/Alphacode/#alphacode","title":"Alphacode","text":"<ul> <li>Other language models have demonstrated an impressive ability to generate code, but these systems still perform poorly when evaluated on more complex, unseen problems</li> <li>Alphacode is a system for code generation for problems that require for deeper reasoning</li> <li>having an extensive dataset for training and evaluation, large and ecient transformer based architectures and a large-scale model sampling.</li> <li>model is firstly pre-trained through GitHub repositories amounting to 715.1 GB of code.</li> <li>more extensive dataset than Codex's pre training dataset.</li> <li>For the training to be better, a fine-tuning dataset is introduced from the Codeforces plataform</li> <li>Codecontests are conducted, for the validation phase, in which we better the performance of the model.</li> <li>transformer-based architecture, they use an encoder-decoder transformer architecture</li> <li>Compared to decoder-only architectures commonly used, this architecture allows for a bidirectional description and extra flexibility.</li> <li>shallow encoder and a deep encoder to further the model's ecienc</li> <li>o reduce the cost of sampling, multi-query attention is used.</li> </ul>"},{"location":"KB/Alzheimer%E2%80%99s%20Disease/","title":"Alzheimer\u2019s Disease","text":""},{"location":"KB/Alzheimer%E2%80%99s%20Disease/#alzheimers-disease","title":"Alzheimer\u2019s Disease","text":"<ul> <li>A debilitating form of dementia, this progressive and irreversible neurodegenerative disease results in the development of protein plaques and tangles that damages neurons and interfere with neural signaling, ultimately affecting memory and other important cognitive skills</li> </ul>"},{"location":"KB/Amdahl%27s%20Law/","title":"Amdahl's Law","text":""},{"location":"KB/Amdahl%27s%20Law/#amdahls-law","title":"Amdahl's Law","text":"<ul> <li>Maximum expected improvement to an overall system when only part of the system is improved</li> <li>Theoretical maximum speedup using multiple processors</li> <li> \\[Speedup = \\frac{\\text{Execution time before improvement}}{\\text{Execution time after improvement}}\\] </li> <li> \\[Speedup = ((1-f_{E})+(\\frac{f_{E}}{f_{I}}))^{-1}\\] <ul> <li>\\(f_E\\) is fraction enhanced</li> <li>\\(f_{I}\\) is factor of improvement</li> <li>\\(S_{e}\\) is speedup enhanced</li> </ul> </li> <li> \\[ExecutionTime_{new} = ExecutionTime_{old}\\times [(1-f_{E})+f_{E}/S_{e}]\\] </li> <li> \\[MaximumSpeedupp = n/(1+(n-1)f )\\] <ul> <li>n is no of processors</li> </ul> </li> </ul>"},{"location":"KB/Amino%20Acid/","title":"Amino Acid","text":""},{"location":"KB/Amino%20Acid/#amino-acid","title":"Amino Acid","text":"<ul> <li>A type of small organic molecule that has a variety of biological roles but is best known as the \u201cbuilding block\u201d of proteins.</li> </ul>"},{"location":"KB/Amsgrad/","title":"Amsgrad","text":""},{"location":"KB/Amsgrad/#amsgrad","title":"Amsgrad","text":""},{"location":"KB/Amsgrad/#modified-adam","title":"Modified Adam","text":"<ul> <li>By analyzing the proof of convergence for the Adam optimizer, they spotted a mistake in the update rule that could cause the algorithm to converge to a sub-optimal point</li> <li>update rule of Adam</li> </ul> <pre><code>avg_grads = beta1 * avg_grads + (1-beta1) * w.grad \navg_squared = beta2 * (avg_squared) + (1-beta2) * (w.grad ** 2) \nw = w - lr * avg_grads / sqrt(avg_squared)\n</code></pre> <ul> <li>We've just skipped the bias correction (useful for the beginning of training) to focus on the important point</li> <li>The error in the proof of Adam the authors spotted is that it requires the quantity</li> </ul> <pre><code>lr / sqrt(avg_squared)\n</code></pre> <ul> <li>which is the step we take in the direction of our average gradients, to be decreasing over training</li> <li>Since the learning rate is often taken constant or decreasing (except for crazy people like us trying to obtain super-convergence), the fix the authors proposed was to force the avg_squared quantity to be increasing by adding another variable to keep track of their maximums.</li> <li>Implementing amsgrad</li> <li>This causes the weight update code from the previous section to be changed to something like this:</li> </ul>"},{"location":"KB/Amsgrad/#results","title":"Results","text":"<ul> <li>Amsgrad turns out to be very disappointing. In none of our experiments did we find that it helped the slightest bit, and even if it's true that the minimum found by amsgrad is sometimes slightly lower (in terms of loss) than the one reached by Adam, the metrics (accuracy, f1 score...) always end up worse</li> <li>The proof of convergence for the Adam optimizer in deep learning (since it's for convex problems) and the mistake they found in it mattered for synthetic experiments that have nothing to do with real-</li> <li>life problems. Actual tests show that when those avg_squared gradients want to decrease, it's best for the final result to do so.</li> </ul>"},{"location":"KB/Amygdala/","title":"Amygdala","text":""},{"location":"KB/Amygdala/#amygdala","title":"Amygdala","text":"<ul> <li>Part of the brain\u2019s limbic system, this primitive brain structure lies deep in the center of the brain and is involved in emotional reactions, such as anger or fear, as well as emotionally charged memories. It also influences behavior such as feeding, sexual interest, and the immediate \u201cfight or flight\u201d stress reaction that helps ensure the person\u2019s needs are met.</li> </ul>"},{"location":"KB/Amyloid%20Plaque/","title":"Amyloid Plaque","text":""},{"location":"KB/Amyloid%20Plaque/#amyloid-plaque","title":"Amyloid Plaque","text":"<ul> <li>The sticky, abnormal accumulations of amyloid-beta protein aggregate around neurons and synapses in the memory and intellectual centers of the brain, in people with Alzheimer\u2019s. These are sometimes referred to as neuritic plaques or senile plaques. While amyloid plaques have long been considered markers of Alzheimer\u2019s, they are also found to some extent in many cognitively normal elderly people. The plaques\u2019 role in Alzheimer\u2019s neurodegeneration remains unclear.</li> </ul>"},{"location":"KB/Amyloid-beta%20%28A%CE%B2%29%20Protein/","title":"Amyloid beta (A\u03b2) Protein","text":""},{"location":"KB/Amyloid-beta%20%28A%CE%B2%29%20Protein/#amyloid-beta-a-protein","title":"Amyloid-beta (A\u03b2) Protein","text":"<ul> <li>A naturally occurring protein in brain cells. Large, abnormal clumps of this protein form the amyloid plaques that are a physiological hallmark of Alzheimer\u2019s disease.</li> </ul>"},{"location":"KB/Amyotrophic%20Lateral%20Sclerosis%20%28ALS%29/","title":"Amyotrophic Lateral Sclerosis (ALS)","text":""},{"location":"KB/Amyotrophic%20Lateral%20Sclerosis%20%28ALS%29/#amyotrophic-lateral-sclerosis-als","title":"Amyotrophic Lateral Sclerosis (ALS)","text":"<ul> <li>Also known as Lou Gehrig\u2019s disease, this neurodegenerative disease results in the death of brain cells that control the muscles.</li> </ul>"},{"location":"KB/Analysis%20of%20Explainers%20of%20Black%20Box%20Deep%20Neural%20Networks%20for%20Computer%20Vision%20A%20Survey/","title":"Analysis of Explainers of Black Box Deep Neural Networks for Computer Vision A Survey","text":"<ul> <li>10:14 --- toc: true title: Analysis of Explainers of Black Box Deep Neural Networks for Computer Vision A Survey</li> </ul> <p>categories: ['explainability'] date modified: Wednesday, October 12th 2022, 4:48:43 pm date created: Wednesday, October 12th 2022, 4:11:22 pm</p>"},{"location":"KB/Analysis%20of%20Explainers%20of%20Black%20Box%20Deep%20Neural%20Networks%20for%20Computer%20Vision%20A%20Survey/#analysis-of-explainers-of-black-box-deep-neural-networks-for-computer-vision-a-survey","title":"Analysis of Explainers of Black Box Deep Neural Networks for Computer Vision A Survey","text":"<ul> <li>@Analysis of Explainers of Black Box Deep Neural Networks for Computer Vision: A Survey</li> <li>Vanessa Buhrmester , David M\u00fcnch and Michael Arens   <code>toc</code></li> </ul>"},{"location":"KB/Analysis%20of%20Explainers%20of%20Black%20Box%20Deep%20Neural%20Networks%20for%20Computer%20Vision%20A%20Survey/#explaining-systems","title":"Explaining Systems","text":"<ul> <li>GAM</li> <li>Partial Dependence Plot</li> <li>Salience Map</li> <li>Explanator</li> <li>Comprehensibility</li> <li>Causality</li> <li>Causability</li> <li>Bayesian Rule List</li> <li>TREPAN</li> </ul>"},{"location":"KB/Analysis%20of%20Explainers%20of%20Black%20Box%20Deep%20Neural%20Networks%20for%20Computer%20Vision%20A%20Survey/#selected-dnn-explainers","title":"Selected DNN Explainers","text":"<ul> <li>Counterfactual Impact Evaluation</li> <li>DeconvNet</li> <li>Layerwise Relevance Propagation</li> <li>Parent Approximations</li> <li>RETAIn</li> <li>SP-LIME</li> <li>Deep Visual Explanation</li> <li>Prediction Difference Analysis</li> <li>Smooth-Grad</li> <li>Multimodal Explanation</li> <li>Summit</li> <li>DeepFool</li> <li>DeconvNet</li> <li>LIME</li> </ul>"},{"location":"KB/Analysis%20of%20Explainers%20of%20Black%20Box%20Deep%20Neural%20Networks%20for%20Computer%20Vision%20A%20Survey/#pictures","title":"Pictures","text":""},{"location":"KB/Andes/","title":"Andes","text":""},{"location":"KB/Andes/#andes","title":"Andes","text":"<ul> <li>Outer loop: The Andes physics tutoring system (http://www.andes.pitt.edu/) helps students learn how to solve physics problems (K. VanLehn et al., 2005; K. VanLehn et al., 2002).</li> <li>Inner loop: The student solves the problem by making steps similar to the ones they would make if solving the problem with pencil and paper. One kind of step is to type an equation into one of the numbered boxes in the right window. Another kind of step is to draw a Cartesian coordinate system, such as the one showing in the lower left. A third kind of step is to sketch a vector, then fill out a dialogue box that defines it. A vector-drawing operation was in progress at the time the screen shot was taken, so its dialogue box covers part of the screen.</li> <li>Every time the student makes a step, Andes gives immediate feedback. For most types of steps, Andes merely colors the step green if it is correct and red if it is incorrect.</li> <li>Step analysis: Like the Algebra Cognitive Tutor, Andes analyzes non-equation steps by precomputing anticipated steps and matching the student's step against them</li> <li>However, this method does not work for the equation steps because there are too many anticipated equations to generate</li> </ul>"},{"location":"KB/Angina/","title":"Angina","text":""},{"location":"KB/Angina/#angina","title":"Angina","text":"<ul> <li>Intermittent chest pain normally caused by insufficient blood flow to the heart</li> </ul>"},{"location":"KB/Angiography/","title":"Angiography","text":""},{"location":"KB/Angiography/#angiography","title":"Angiography","text":"<ul> <li>A medical imaging technique that allows clinicians to visualize the interior of blood vessels, arteries, veins, and the heart.</li> </ul>"},{"location":"KB/Anthropomorphic/","title":"Anthropomorphic","text":""},{"location":"KB/Anthropomorphic/#anthropomorphic","title":"Anthropomorphic","text":"<ul> <li>Human like in shape</li> <li>Very large number of joint</li> <li>Very large number of DOF</li> <li>Compact design</li> </ul>"},{"location":"KB/Apoptosis/","title":"Apoptosis","text":""},{"location":"KB/Apoptosis/#apoptosis","title":"Apoptosis","text":"<ul> <li>A form of programmed cell death that occurs as part of normal growth and development.</li> </ul>"},{"location":"KB/Appendectomy/","title":"Appendectomy","text":""},{"location":"KB/Appendectomy/#appendectomy","title":"Appendectomy","text":"<ul> <li>Surgical procedure to remove the appendix</li> </ul>"},{"location":"KB/Application%20dependence/","title":"Application dependence","text":""},{"location":"KB/Application%20dependence/#application-dependence","title":"Application Dependence","text":"<ul> <li>Word and sentence segmentation are necessary</li> <li>Tokenizer</li> </ul>"},{"location":"KB/Application%20for%20PhD%20-%20AI%20for%20Parkinsons%20%28Subhaditya%20Mukherjee%29/","title":"Application for PhD   AI for Parkinsons (Subhaditya Mukherjee)","text":"<p>Hello Yagmur! My name is Subhaditya, it\u2019s nice to meet you :)</p> <p>I recently graduated with a masters in AI from the RUG (Groningen), and am now looking for a position where I can bring my AI knowledge to healthcare. I found out about this position quite coincidentally a few hours ago, and I knew that I could not miss the chance to apply. There is a history of Parkinsons in my family and while I could do nothing about it as a kid, now I can help contribute to the research. So, here is my formal application to the PhD position :\u2019 Artificial intelligence for monitoring of Parkinson\u2019s disease\u2019.</p> <p>I read that a lot of data was collected over the last few years using a smartwatch and video in the hope of gaining insights that would potentially help a lot of people. Here is where I can contribute to the most. I am not a healthcare professional, and all these years there wasn\u2019t any skill I could bring to the medical side of innovation. But now I have quite a bit of experience in both Computer Vision and Data Analysis. I am comfortable with using deep learning libraries, data analysis pipelines and python to create whatever is necessary for the project. My main skills lie in building these pipelines, analyzing data and subsequently using AI. Over the past few years, I have done many freelance projects, each of which has given me quite a bit of knowledge about using AI in different domains. I think that that knowledge will be useful here too. Since I am familiar with the pipeline, perhaps I can also help anticipate what might be needed for the future, and ensure we are a little more ready for that. I have also worked quite a bit with vision models and sensor data in past internships and personal projects, which is also useful experience.</p> <p>Aside from the technical aspects, I love interdisciplinary research. No field is good on it\u2019s own, AI even less so. But that being the case, I acknowledge my lack of information about medical terms. I do think that is an easy fix though, and I\u2019m willing to put in the effort to learn that side as best I can. This position is the perfect next step for me, as someone who is trying to find a position that bridges the gap between a pure AI background to something more useful, healthcare. I read that your lab is part of the ICAI network as well, and Verity healthcare too. That\u2019s so awesome and helpful.</p> <p>I have done many projects and internships over the past few years, but for most of the time, it did not feel like my work amounted to anything. This is my shot at making it count, and helping make some lives a little better. I know I applied pretty late and you probably have a lot of applications already, but I hope you give me a chance!</p>"},{"location":"KB/Applications%20of%20Knowledge%20Distillation/","title":"Applications of Knowledge Distillation","text":""},{"location":"KB/Applications%20of%20Knowledge%20Distillation/#applications-of-knowledge-distillation","title":"Applications of Knowledge Distillation","text":"<ul> <li>Specifically, in (Luo et al., 2016), the knowledge from the chosen informative neurons of top hint layer of the teacher network is trans- ferred into the student network</li> <li>A recursive knowledge distillation method was designed by using a previous student network to ini- tialize the next one (Yan et al., 2019). Since most face recognition methods perform the open-set recognition, i.e., the classes/identities on test set are unknown to the training set, the face recognition criteria are usually distance metrics between feature representations of positive and negtive samples, e.g., the angular loss in (Duong et al., 2019) and the correlated embedding loss in (Wu et al., 2020).</li> <li>Specifically, Ge et al. (2018) proposed a selective knowledge distillation method, in which the teacher network for high-resolution face recognition selectively transfers its informative facial features into the student network for low-resolution face recognition through sparse graph optimization. In (Kong et al., 2019), cross- resolution face recognition was realized by designing a resolution invariant model unifying both face halluci- nation and heterogeneous recognition sub-nets. To get efficient and effective low resolution face recognition model, the multi-kernel maximum mean discrepancy between student and teacher networks was adopted as the feature loss (Wang et al., 2019c).</li> <li>KD-based face recognition can be extended to face alignment and verification by changing the losses in knowledge distillation (Wang et al., 2017).</li> <li>For incomplete, ambiguous and redundant image labels, the label refinery model through self-distillation and label progression is proposed to learn soft, informative, collective and dynamic labels for complex image classi- fication (Bagherinezhad et al., 2018).</li> <li>To address catas- trophic forgetting with CNN in a variety of image clas- sification tasks, a learning without forgetting method for CNN, including both knowledge distillation and lifelong learning is proposed to recognize a new image task and to preserve the original tasks (Li and Hoiem, 2017).</li> <li>For improving image classification accuracy, Chen et al. (2018a) proposed the feature maps-based knowledge distillation method with GAN.</li> <li>Similar to the KD-based low-resolution face recognition, Zhu et al. (2019) proposed deep feature distillation for the low-resolution image classification, in which the output features of a student match that of teacher.</li> <li>Gordon and Duh (2019) explained the good perfor- mance of sequence-level knowledge distillation from the perspective of data augmentation and regulariza- tion. In (Kim and Rush, 2016), the effective word-level knowledge distillation is extended to the sequence- level one in the sequence generation scenario of NMT. The sequence generation student model mimics the sequence distribution of the teacher. To overcome the multilingual diversity, Tan et al. (2019) proposed multi teacher distillation, in which multiple individual models for handling bilingual pairs are teacher and a mul- tilingual model is student.</li> <li>To improve the transla- tion quality, an ensemble of mutiple NMT models as teacher supervise the student model with a data filtering method Freitag et al. (2017).</li> <li>(Wei et al., 2019) proposed a novel online knowledge distillation method, which addresses the unstableness of the training process and the decreasing performance on each validation set.</li> <li>The proposed pre- trained distillation performs well in sentiment classifi- cation, natural language inference, textual entailment. For a multi-task distillation in the context of natu- ral language understanding, Clark et al. (2019) pro- posed the single-multi born-again distillation, which is based on born-again neural networks (Furlanello et al., 2018).</li> <li>In (Perez et al., 2020), a audio-visual multi- modal knowledge distillation method is proposed. knowl- edge is transferred from the teacher models on visual and acoustic data into a student model on audio data.</li> <li>Pan et al. (2019) designed a enhanced collaborative denoising autoencoder (ECAE) model for recommender systems via knowledge distillation to capture useful knowledge from user feedbacks and to reduce noise. The unified ECAE framework contains a generation network, a retraining network and a distillation layer that trans- fers knowledge and reduces noise from the generation network.</li> </ul>"},{"location":"KB/Approximately%20Compositional%20Semantic%20Parsing/","title":"Approximately Compositional Semantic Parsing","text":""},{"location":"KB/Approximately%20Compositional%20Semantic%20Parsing/#approximately-compositional-semantic-parsing","title":"Approximately Compositional Semantic Parsing","text":"<ul> <li>which Semantic Analysis processing is applied to the result of performing a syntactic parse</li> </ul>"},{"location":"KB/Arbitrary%20Relation%20Bias/","title":"Arbitrary Relation Bias","text":""},{"location":"KB/Arbitrary%20Relation%20Bias/#arbitrary-relation-bias","title":"Arbitrary Relation Bias","text":"<ul> <li>To solve problems related to a group of things or people, it might be more informative to see them as a Graphs. The graph structure imposes arbitrary relationships between the entities, which is ideal when there\u2019s no clear sequential or local relation in the model:</li> <li></li> </ul>"},{"location":"KB/Area%20Minimization/","title":"Area Minimization","text":""},{"location":"KB/Area%20Minimization/#area-minimization","title":"Area Minimization","text":"<ul> <li>Small areas preferable</li> <li>aspect ratio can play role</li> <li></li> </ul>"},{"location":"KB/Articulated%20Manipulator/","title":"Articulated Manipulator","text":""},{"location":"KB/Articulated%20Manipulator/#articulated-manipulator","title":"Articulated Manipulator","text":"<ul> <li>A manipulator with an arm that is broken into sections (links) by one or more joints. Each of the joints represents a degree of freedom in the manipulator system and allows translation and rotary motion.</li> </ul>"},{"location":"KB/Articulation/","title":"Articulation","text":""},{"location":"KB/Articulation/#articulation","title":"Articulation","text":"<ul> <li>Describes a jointed device, such as a jointed manipulator. The joints provide rotation about a vertical axis, and elevation out of the horizontal plane. This allows a robot to be capable of reaching into confined spaces.</li> </ul>"},{"location":"KB/Assembly%20Robot/","title":"Assembly Robot","text":""},{"location":"KB/Assembly%20Robot/#assembly-robot","title":"Assembly Robot","text":"<ul> <li>A robot designed specifically for mating, fitting, or otherwise assembling various parts or components into completed products. Primarily used for grasping parts and mating or fitting them together, such as in assembly line production.</li> </ul>"},{"location":"KB/Astrocyte/","title":"Astrocyte","text":""},{"location":"KB/Astrocyte/#astrocyte","title":"Astrocyte","text":"<ul> <li>A star-shaped glial cell that supports neurons, by helping to both feed and remove waste from the cell, and otherwise modulates the activity of the neuron. Astrocytes also play critical roles in brain development and the creation of synapses.</li> </ul>"},{"location":"KB/Asymptotic%20Decider/","title":"Asymptotic Decider","text":""},{"location":"KB/Asymptotic%20Decider/#asymptotic-decider","title":"Asymptotic Decider","text":"<ul> <li>Consider the bilinear interpolant within cell</li> <li>the true isolines within a cell are hyperbolas</li> <li>investigate order of intersection points along x or y axis</li> <li>build pairs of first two and last two intersections</li> </ul>"},{"location":"KB/Attention%20Alignment/","title":"Attention Alignment","text":""},{"location":"KB/Attention%20Alignment/#attention-alignment","title":"Attention Alignment","text":"<ul> <li>If there are sequences \\(x, y\\)<ul> <li>Encoder is any Recurrent with a forward state \\(\\(\\overrightarrow h^{T}\\)\\) and \\(\\(\\overleftarrow h^{T}\\)\\) for backward</li> <li>Concat them represents the preceding and following word annotations<ul> <li>\\(\\(h_{i}= [\\overrightarrow h_{i}^{T}; \\overleftarrow h_{i}^{T}]\\)\\), \\(i = 1, \u2026, n\\)</li> <li>Decoder has hidden state \\(s_{t}= f(s_{t-1}, y_{t-1}, c_{t})\\) for the output word at position t for \\(t = 1, \u2026, m\\)<ul> <li>Context vector \\(c_{t}\\) is a sum of hidden states of the input seq, weighted by alignment scores</li> <li> \\[c_{t}= \\Sigma_{i=1}^{n}\\alpha_{t,i}h_{i}\\] </li> <li>How well the two words are aligned is given by</li> <li> \\[\\alpha_{t,i} = align(y_{t}, x_{i})\\] </li> <li>Taking softmax<ul> <li> \\[\\frac{exp(score(s_{t-1}, h_{i}))}{\\Sigma_{i'-1}^{n}exp(score(s_{t-1}, h_{i}'))}\\] </li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> <li> \\[f_{att}(h_{i}, s_{j}) = v_{a}^{T}tanh(W_{a}[h_{i};s_{j}])\\] </li> <li>\\(v_{a}\\) and \\(W_{a}\\) are the learned Attention params</li> <li>\\(h\\) is the hidden state for the encoder</li> <li>\\(s\\) is the hidden state for the decoder</li> <li>Matrix of alignment<ul> <li></li> <li>Final scores calculated with a Softmax</li> </ul> </li> </ul>"},{"location":"KB/Attention%20Based%20Distillation/","title":"Attention Based Distillation","text":""},{"location":"KB/Attention%20Based%20Distillation/#attention-based-distillation","title":"Attention Based Distillation","text":"<ul> <li>That is to say, knowledge about feature embedding is transferred using attention map functions. Unlike the attention maps, a different attentive knowledge distillation method was proposed by Song et al. (2018). An attention mechanism is used to assign different confidence rules (Song et al., 2018).</li> </ul>"},{"location":"KB/Attention%20NMT/","title":"Attention NMT","text":""},{"location":"KB/Attention%20NMT/#attention-nmt","title":"Attention NMT","text":"<ul> <li>Effective Approaches to Attention-based Neural Machine Translation</li> <li> proposed an Attention mechanism to improve neural machine translation (NMT) by selectively focusing on parts of the source sentence during translation</li> <li>a global approach which always attends to all source words and a local one that only looks at a subset of source words at a time</li> <li>BLEU</li> </ul>"},{"location":"KB/Attention/","title":"Attention","text":""},{"location":"KB/Attention/#attention","title":"Attention","text":"<ul> <li>Model can decide where to look in the input</li> <li>Self Attention</li> <li>Additive Attention</li> <li>Dot Product Attention</li> <li>Location Aware Attention</li> <li>Relative Multi Head Self Attention</li> <li>Soft Attention</li> <li>Scaled Dot Product Attention</li> <li>Encoder Decoder Attention</li> <li>Multi Head Attention</li> <li>Strided Attention</li> <li>Fixed Factorization Attention</li> <li>Sliding Window Attention</li> <li>Dilated Sliding Window Attention</li> <li>Global and Sliding Window Attention</li> <li>Content Based Attention</li> <li>Location Base Attention</li> <li>Mixed chunk attention</li> </ul>"},{"location":"KB/Attentions%20and%20salience/","title":"Attentions and salience","text":""},{"location":"KB/Attentions%20and%20salience/#attentions-and-salience","title":"Attentions and Salience","text":"<ul> <li>Learning is related to attention</li> <li>We give more attention to salient items</li> <li>Selective attention leads to overshadowing</li> <li>Two cues presented together jointly predict outcomes</li> <li>salience (and then attention) leads to one cue being strongly associated</li> <li>ther cue is only weakly associated (overshadowed)</li> <li>Overshadowing leads to blocking</li> <li>Blocking could model interference</li> <li>Children learn temporal adverbs like hier late (Dale and Fenson 1996)</li> <li>L2 learners go through phases where time is marked with adverbials alone (Bardovi-Harlig 1992; Meisel 1987)</li> <li>This seems to block acquisition of other cues</li> <li>temporal adverbs are highly salient (and easier) so they get stronger associations</li> <li>even though they co-occur with different verb forms, these are hard to learn</li> </ul>"},{"location":"KB/Attentive%20CutMix/","title":"Attentive CutMix","text":""},{"location":"KB/Attentive%20CutMix/#attentive-cutmix","title":"Attentive CutMix","text":"<ul> <li>@walawalkarAttentiveCutMixEnhanced2020</li> <li>builds up on CutMix .</li> <li>Instead of random pasting, it identifies attentive patches for cutout and pastes them at the same location in the other image.</li> <li>avoids the problem of selecting a background region not important for the network and updating the label information</li> <li>A separate pre-trained network is employed to extract attentive regions.</li> <li>The attention output is mapped back onto the original image</li> </ul>"},{"location":"KB/Attribute%20Selection/","title":"Atrribute Selection","text":""},{"location":"KB/Attribute%20Selection/#atrribute-selection","title":"Atrribute Selection","text":"<ul> <li>Some tasks are harder than others due to noise and high dimensionality</li> <li>Another task can help the model to learn a shared feature that is harder to learn with a single task alone.</li> <li>helps models focus into the most important features</li> <li>Consequence of augment </li> </ul>"},{"location":"KB/AttributeMix/","title":"AttributeMix","text":"<ul> <li>@Attribute Mix: Semantic Data Augmentation for Fine Grained Recognition</li> <li>augments images based on se- mantically extracted image attributes</li> <li>Image is divided into a grid of patches where highly activated six responses are pasted onto the training image. These image pairs are selected randomly in every training iteration.</li> <li>attribute classifier by extracting k attributes (e.g., leg, head, and wings of a bird) from each image.</li> <li>The attribute mining procedure for every image is performed repetitively k times, whereas for each iteration, an attribute is masked out from the original image based on the most discriminative region in the attention map.</li> <li>attribute-level classifier is trained to generate new images for the actual classification model.</li> </ul>"},{"location":"KB/AttributeMix/#attributemix","title":"AttributeMix","text":""},{"location":"KB/AudioLM/","title":"AudioLM","text":""},{"location":"KB/AudioLM/#audiolm","title":"AudioLM","text":"<ul> <li>maps the input audio into a sequence of discrete tokens and casts audio generation as language modeling task in this representation space</li> <li>training on large corpora of raw</li> <li>audio waveforms</li> <li>learns to generate natural and coherent continuations given short prompts</li> <li>extended beyond speech by generating coherent piano music continuations, despite being trained without any symbolic representation of music</li> <li>When it comes to audio synthesis, multiple scales make achieving high audio quality while displaying consistency very challenging</li> <li>This gets achieved by this model by combining recent advances in neural audio compression, self-supervised representation learning and language modelling.</li> </ul>"},{"location":"KB/AudioSet%20classification/","title":"AudioSet classification","text":""},{"location":"KB/AudioSet%20classification/#audioset-classification","title":"AudioSet Classification","text":""},{"location":"KB/AudioSet/","title":"AudioSet","text":""},{"location":"KB/AudioSet/#audioset","title":"AudioSet","text":"<ul> <li>2, 084, 320 human-labeled 10-second sound clips drawn from YouTube videos covers ontology of 632 audio event classes </li> <li>The event classes cover a wide range of human and animal sounds, musical instruments and genres, and common everyday environmental sound </li> <li>selfsupervised learning from video and audio consistence</li> </ul>"},{"location":"KB/Auditability/","title":"Auditability","text":""},{"location":"KB/Auditability/#auditability","title":"Auditability","text":"<ul> <li>includes the assessment of algorithms, data and design processes, but preserving the intellectual property related to the AI systems</li> <li>Performing the assessment by both internal and external auditors, and making the reports available, could contribute to the trustworthiness of the technology.</li> <li>When the AI system affects fundamental rights, including safety-critical applications, it should always be audited by an external third party.</li> </ul>"},{"location":"KB/AugMix/","title":"AugMix","text":""},{"location":"KB/AugMix/#augmix","title":"AugMix","text":"<ul> <li>@hendrycksAugMixSimpleData2020</li> <li>using the input image itself</li> <li>t transforms (translate, shear, rotate and etc) the input image and mixes it with the original image</li> <li>Image transformation involves series of randomly selected augmentation operations applied with three parallel augmentation chains.</li> <li>Each chain has a composition of operations that could involve applying, for example, translation on input image followed by shear and so on</li> <li>The output of these three chains is three images mixed to form a new image.</li> <li>This new image is later mixed with the original image to generate the final augmented output image,</li> <li>while we considered mixing by alpha compositing, we chose to use elementwise convex combinations for simplicity. The k-dimensional vector of convex coefficients is randomly sampled from a Dirichlet(\u03b1, . . . , \u03b1) distribution. </li> <li>Once these images are mixed, we use a \u201cskip connection\u201d to combine the result of the augmentation chain and the original image through a second random convex combination sampled from a Beta(\u03b1, \u03b1) distribution. The final image incorporates several sources of randomness from the choice of operations, the severity of these operations, the lengths of the augmentation chains, and the mixing weights</li> <li>Jensen Shannon Divergence Consistency Loss</li> </ul>"},{"location":"KB/Augmentation-wise%20Weight%20Sharing%20strategy/","title":"Augmentation-wise Weight Sharing strategy","text":""},{"location":"KB/Augmentation-wise%20Weight%20Sharing%20strategy/#augmentation-wise-weight-sharing-strategy","title":"Augmentation-wise Weight Sharing Strategy","text":"<ul> <li>improves efficiency significantly and make it affordable to directly search on large scale datasets. </li> <li>[Lin et al., 2019] formulates the augmentation policy as a parameterized probability distribution and the parameters can be optimized jointly with network parameters, known as OHL-Auto-Aug.</li> </ul>"},{"location":"KB/Augmented%20Random%20Search/","title":"Augmented Random Search","text":""},{"location":"KB/Augmented%20Random%20Search/#augmented-random-search","title":"Augmented Random Search","text":"<ul> <li>The authors point out that the sub-policies learned from AutoAugment are inherently flawed because of the discrete search space.</li> <li>They convert the probability and magnitude of augmentations into a continuous space and search for sub-policies with ARS.</li> </ul>"},{"location":"KB/Auto%20Augment/","title":"Auto Augment","text":""},{"location":"KB/Auto%20Augment/#auto-augment","title":"Auto Augment","text":"<ul> <li>search algorithm and search space </li> <li>The search algorithm is designed to find the best policy regarding highest validation accuracy </li> <li>The search space contains many policies which details various augmentation operations and magnitudes with which the operations are applied </li> <li>Fast AutoAugment</li> <li>Population Based Augmentation</li> <li>RandAugment</li> <li>KeepAugment </li> <li>Augmentation-wise Weight Sharing strategy</li> </ul>"},{"location":"KB/Auto%20Encoders/","title":"AutoEncoder","text":""},{"location":"KB/Auto%20Encoders/#autoencoder","title":"AutoEncoder","text":"<ul> <li>Regression by predicting a reconstruction of the data</li> <li>Encoder \\(\\(E : \\mathscr{X} \\rightarrow \\mathscr{F}\\)\\)</li> <li>Decoder \\(\\(\\mathscr{F} \\rightarrow \\mathscr{D}\\)\\)</li> <li>$\\(E_\\theta, D_\\theta = argmin_{E_\\theta, D\\theta}||X-D(E(X))||^2\\)<ul> <li>Learn using Gradient Descent gradients</li> </ul> </li> <li>Compressed rep of data -&gt; Good for Classification or Regression</li> <li>MSE : Unsupervised</li> </ul>"},{"location":"KB/Auto%20Encoders/#difficulties","title":"Difficulties","text":"<ul> <li>dim \\(\\mathscr{F} \\lt \\mathscr{X}\\)<ul> <li>Cannot learn the identity function</li> </ul> </li> <li>usages<ul> <li>data compression / dimensionality reduction</li> <li>encoder to obtain features (use the latent variable as feature)</li> <li>denoising autoencoders<ul> <li>input noisy image and try to obtain image without noise</li> </ul> </li> <li>sparse auto-encoder</li> <li>contractive autoencoder</li> </ul> </li> </ul>"},{"location":"KB/Auto%20Encoders/#types","title":"Types","text":"<ul> <li>Denoising Autoencoder</li> <li>VAE</li> </ul>"},{"location":"KB/AutoAugment/","title":"AutoAugment","text":""},{"location":"KB/AutoAugment/#autoaugment","title":"AutoAugment","text":"<ul> <li>developed by Cubuk et al.</li> <li>much different approach to meta-learning than [Neural Augmentation] or Smart Augmentation</li> <li>AutoAugment is a Reinforcement Learning algorithm that searches for an optimal augmentation policy amongst a constrained set of geometric transformations with miscellaneous levels of distortions. For example, \u2018translateX 20 pixels\u2019 could be one of the transformations in the search space</li> <li>In Reinforcement Learning algorithms, a policy is analogous to the strategy of the learning algorithm. This policy determines what actions to take at given states to achieve some goal. The AutoAugment approach learns a policy which consists of many subpolicies, each sub-policy consisting of an image transformation and a magnitude of transformation</li> <li>Reinforcement Learning is thus used as a discrete search algorithm of augmentations.</li> </ul>"},{"location":"KB/AutoDistill/","title":"AutoDistill","text":""},{"location":"KB/AutoDistill/#autodistill","title":"AutoDistill","text":"<ul> <li>AutoDistill: an End-to-End Framework to Explore and Distill Hardware-Efficient Language Models</li> <li>(NLP) tasks but they are expensive to serve due to long serving latency and large memory usage</li> <li>compress these models, knowledge distillation</li> <li>handling fast evolving models, considering serving performance, and optimizing for multiple objectives.</li> <li>end-to-end model distillation framework integrating model architecture exploration and multi-objective optimization for building hardware-efficient NLP pre-trained models</li> <li>Bayesian Optimization to conduct multi-objective Neural Architecture Search for selecting student model architectures</li> <li>proposed search comprehensively considers both prediction accuracy and serving latency on target hardware</li> <li>TPUv4i</li> <li>MobileBERT</li> <li>GLUE</li> <li>higher than BERT_BASE, DistillBERT, TinyBERT, NAS-BERT, and MobileBERT</li> </ul>"},{"location":"KB/AutoML%20Benchmark/","title":"AutoML Benchmark","text":"","tags":["openml, automl"]},{"location":"KB/AutoML%20Benchmark/#automl-benchmark","title":"AutoML Benchmark","text":"<ul> <li>@gijsbersAMLBAutoMLBenchmark2023</li> </ul>","tags":["openml, automl"]},{"location":"KB/AutoTutor/","title":"AutoTutor","text":""},{"location":"KB/AutoTutor/#autotutor","title":"AutoTutor","text":"<ul> <li>Outer loop: AutoTutor (http://demo.autotutor.org/) teaches by engaging students in a natural language (English) dialogue</li> <li>For AutoTutor, a task corresponds to a single question, such as the one shown in the upper right of Figure 4, that has a complex answer. Its outer loop consists of selecting such a question and working with the student to get it completely answered.</li> <li>Inner loop: The inner loop starts with the student typing in an initial answer to the top level question (see Figure 4; the student types into the lower right window; the whole dialogue is displayed in the lower left window).</li> <li>AutoTutor has been used to compare output modalities.</li> <li>An AutoTutor dialogue is composed of tutor turns alternating with student turns. On most of the student turns, the student makes a small contribution toward completing the whole task. Those student turns count as steps, because they are a user interface event that contributes to a solution of the whole task</li> <li>Step analysis:</li> <li>These are conclusions that are produced by applying knowledge components. For instance, the first two items above correspond to distinct learning events, wherein the student has applied the same Knowledge Component,</li> <li>In addition to having a list of all anticipated correct learning events, such as the ones mentioned above, AutoTutor has a list of several of the most important incorrect learning events</li> <li>To find out which learning events underlie the student's step, AutoTutor measures the semantic similarity between the text of the Learning Event and the text of the step. It uses a measure called Latent Semantic Analysis</li> </ul>"},{"location":"KB/Automation%20Bias/","title":"Automation Bias","text":""},{"location":"KB/Automation%20Bias/#automation-bias","title":"Automation Bias","text":"<ul> <li>When a human decision maker favors recommendations made by an automated decision-making system over information made without automation, even when the automated decision-making system makes errors.</li> </ul>"},{"location":"KB/Autonomic/","title":"Autonomic","text":""},{"location":"KB/Autonomic/#autonomic","title":"Autonomic","text":"<ul> <li>Involuntary</li> <li>Sympathetic + Parasympathetic</li> </ul>"},{"location":"KB/Autoregressive/","title":"Autoregressive","text":""},{"location":"KB/Autoregressive/#autoregressive","title":"Autoregressive","text":"<ul> <li>predict the future by past of TIme Series</li> <li>Multi Variate AR</li> </ul>"},{"location":"KB/Average%20Filter/","title":"Average Filter","text":""},{"location":"KB/Average%20Filter/#average-filter","title":"Average Filter","text":"<ul> <li>Each grey value is replaced by the average value in the kernel in a local surrounding</li> <li>linear</li> <li>flatten edges</li> </ul>"},{"location":"KB/Average%20Number%20of%20Stored%20Instances%20per%20Category/","title":"Average Number of Stored Instances per Category","text":""},{"location":"KB/Average%20Number%20of%20Stored%20Instances%20per%20Category/#average-number-of-stored-instances-per-category","title":"Average Number of Stored Instances per Category","text":"<ul> <li>memory resource required for learning</li> </ul>"},{"location":"KB/Axon%20Terminal/","title":"Axon Terminal","text":""},{"location":"KB/Axon%20Terminal/#axon-terminal","title":"Axon Terminal","text":"<ul> <li>The very end of the axon, where electrochemical signals are passed through the synapse to neighboring cells by means of neurotransmitters and other neurochemicals. A collection of axons coming from, or going to, a specific brain area may be called a white matter fiber tract.</li> </ul>"},{"location":"KB/Axon/","title":"Axon","text":""},{"location":"KB/Axon/#axon","title":"Axon","text":"<ul> <li>A long, single nerve fiber that transmits messages, via electrochemical impulses, from the body of the neuron to dendrites of other neurons, or directly to body tissues such as muscles.</li> </ul>"},{"location":"KB/BART/","title":"BART","text":""},{"location":"KB/BART/#bart","title":"BART","text":"<ul> <li>BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</li> <li>denoising autoencoder</li> <li>pretraining sequence-to-sequence</li> <li>trained by corrupting text with an arbitrary noising function, and learning a model to reconstruct the original text</li> <li>generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder),</li> <li>finding the best performance by both randomly shuffling the order of the original sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token</li> <li>With BERT, random tokens are replaced with masks, and the document is encoded bidirectionally. Missing tokens are predicted independently, so BERT cannot easily be used for generation.</li> <li>With GPT, tokens are predicted auto-regressively (generation of a new token is conditioned on the prior tokens), meaning GPT can be used for generation.</li> <li>noising schemes to an input document and thus corrupts it by replacing spans of text with mask symbols</li> <li>effective when finetuned for text generation but also works well for comprehension tasks</li> <li>matches the performance of RoBERTa with comparable training resource</li> <li>GLUE</li> <li>SQuAD</li> </ul>"},{"location":"KB/BCE%20with%20Logits/","title":"BCE Logits","text":""},{"location":"KB/BCE%20with%20Logits/#bce-logits","title":"BCE Logits","text":"<ul> <li>Cross Entropy + logits \\(\\(\\left( - \\mathrm{sum}\\left( y \\cdot \\mathrm{logsoftmax}\\left( \u0177 \\right) \\cdot weight \\right) \\right) \\cdot \\mathrm{//}\\left( 1, \\mathrm{size}\\left( y, 2 \\right) \\right)\\)\\)</li> </ul>"},{"location":"KB/BCE%20with%20Logits/#_1","title":"\u2026","text":""},{"location":"KB/BERT/","title":"BERT","text":""},{"location":"KB/BERT/#bert","title":"BERT","text":"<ul> <li>Bidirectional Encoder rep from transformers</li> <li>Uses Token Embedding</li> <li>Self Supervised</li> <li>Masked language modeling, next sentence prediction</li> <li></li> <li>[CLS] : start of classification task, [SEP] between sentences, [MASK] : masked token</li> <li> <p>christianversloot #Roam-Highlights</p> <ul> <li>BERT base \\(\\text{BERT}_\\text{BASE}\\), which has 12 Encoder Segments stacked on top of each other, has 768-dimensional intermediate state, and utilizes 12 attention heads (with hence 768/12 = 64-dimensional attention heads).</li> <li>BERT large (\\(\\text{BERT}_\\text{LARGE}\\)), which has 24 Encoder Segments, 1024-dimensional intermediate state, and 16 attention heads (64-dimensional attention heads again).</li> <li>BERT utilizes the encoder segment, meaning that it outputs some vectors \\(T_i\\) for every token. The first vector, \\(T_0\\), is also called \\(C\\) in the BERT paper: it is the \"class vector\" that contains sentence-level information (or in the case of multiple sentences, information about the sentence pair). All other vectors are vectors representing information about the specific token.</li> <li>In other words, structuring BERT this way allows us to perform sentence-level tasks and token-level tasks. If we use BERT and want to work with sentence-level information, we build on top of the \\(C\\) token.</li> <li> <p>Masked Language Modeling</p> </li> <li> <p>Next Sentence Prediction (NSP)</p> <ul> <li>This task ensures that the model learns sentence-level information. It is also really simple, and is the reason why the BERT inputs can sometimes be a pair of sentences. NSP involves textual entailment, or understanding the relationship between two sentences.</li> <li>Constructing a training dataset for this task is simple: given an unlabeled corpus, we take a phrase, and take the next one for the 50% of cases where BERT has a next sentence. We take another phase at random given A for the 50% where this is not the case (Devlin et al., 2018). This way, we can construct a dataset where there is a 50/50 split between 'is next' and 'is not next' sentences.</li> </ul> </li> <li>BooksCorpus</li> <li>English Wikipedia</li> <li>It thus does not matter whether your downstream task involves single text or text pairs: BERT can handle it.<ul> <li>Sentence pairs in paraphrasing tasks.</li> <li>Hypothesis-premise pairs in textual entailment tasks.</li> <li>Question-answer pairs in question answering.</li> <li>Text-empty pair in text classification.</li> </ul> </li> <li>Yes, you read it right: sentence B is empty if your goal is to fine-tune for text classification. There simply is no sentence after the token.</li> <li>Fine-tuning is also really inexpensive</li> </ul> </li> </ul>"},{"location":"KB/BEiT/","title":"BEiT","text":"<p>toc: true title: BEiT</p> <p>categories: ['temp']</p>"},{"location":"KB/BEiT/#beit","title":"BEiT","text":"<ul> <li>BEiT: BERT Pre-Training of Image Transformers<ul> <li>Self Supervised pre-trained representation model</li> <li>Bidirectional Encoder Decoder Attention representations from Vision Transformer</li> <li>masked image modeling task to pretrain vision Transformers</li> <li>each image has two views in their pre-training</li> <li>the embeddings of which are calculated as linear projections of flattened patches</li> <li>visual tokens</li> <li>discrete VAE (dVAE) which acts as an \u201cimage tokenizer\u201d learnt via autoencoding-style reconstruction</li> <li>input image is tokenized into discrete visual tokens obtained by the latent codes of the discrete VAE</li> <li>proposed method is critical to make BERT like pre-training (i.e., auto-encoding with masked input) work well for image Transformers</li> <li>automatically acquired knowledge about semantic regions, without using any human-annotated data</li> <li>randomly masks some image patches and feeds them into the backbone Transformer</li> <li>pre-training objective is to recover the original visual tokens based on the corrupted image patches</li> <li>directly fine-tune the model parameters on downstream tasks by appending task layers upon the pretrained encoder</li> <li>ImageNet</li> <li>outperforming from-scratch DeiT</li> </ul> </li> </ul>"},{"location":"KB/BLEU/","title":"BLEU","text":""},{"location":"KB/BLEU/#bleu","title":"BLEU","text":""},{"location":"KB/BOLD/","title":"BOLD","text":""},{"location":"KB/BOLD/#bold","title":"BOLD","text":"<ul> <li>Blood oxygenation level dependant signal<ul> <li>Indirect measure of neural activity</li> <li>Blood goes to a place</li> </ul> </li> <li>When neurons fire or increase their firing rate, they draw on oxygen and various nutrients.</li> <li>The circulatory system of the brain reacts by sending the region that just fired more highly-oxygenated blood than is needed. This results in an increased blood oxygen level in the activated region.</li> <li>With right pulse sequence, an MRI scanner is able to detect this difference in blood oxygen level</li> <li>Factors such as drugs, substances \u00a0and excitation \u00a0have been shown to increase BOLD response. Conversely, age and brain pathology \u00a0have been shown to decrease BOLD response</li> </ul>"},{"location":"KB/BUCC/","title":"BUCC","text":""},{"location":"KB/BUCC/#bucc","title":"BUCC","text":""},{"location":"KB/BYOL%20Loss/","title":"BYOL Loss","text":"<p>toc: true title: BYOL Loss</p> <p>categories: ['temp']</p>"},{"location":"KB/BYOL%20Loss/#byol-loss","title":"BYOL Loss","text":"<ul> <li>Similarity loss between \\(q_\\theta (z_\\theta)\\) and \\(sg(z^{'}_{\\xi})\\)</li> <li>\\(\\theta\\) is trained weights</li> <li>\\(\\xi\\) is exponentially moving average of \\(\\theta\\) and sg is stop gradient</li> <li>\\(f_\\theta\\) is discarded, \\(y_\\theta\\) is used as image representation</li> <li></li> </ul>"},{"location":"KB/BYOL/","title":"BYOL","text":"<p>toc: true title: BYOL</p> <p>categories: ['temp']</p>"},{"location":"KB/BYOL/#byol","title":"BYOL","text":"<ul> <li>Bootstrap Your Own Latent: a New Approach to Self-supervised Learning<ul> <li>Self Supervised image representation learning</li> <li>predicting previous versions of its outputs, without using negative pairs</li> <li>two neural networks, referred to as online and target networks</li> <li>that interact and learn from each other</li> <li>From an augmented view of an image, they train the Online Learning network to predict the target network representation of the same image under a different augmented view</li> <li>update the target network with a slow-moving average of the online network</li> <li>ImageNet</li> <li>Res Net</li> <li>dependent on existing sets of Augmentation that are specific to vision applications</li> <li>BYOL Loss</li> </ul> </li> </ul>"},{"location":"KB/Back%20Propamine/","title":"backpropamine","text":""},{"location":"KB/Back%20Propamine/#backpropamine","title":"Backpropamine","text":"<ul> <li>@miconiBackpropamineTrainingSelfmodifying2020</li> </ul>"},{"location":"KB/Back%20Propamine/#abstract","title":"ABSTRACT","text":"<ul> <li>The impressive lifelong learning in animal brains is primarily enabled by plastic changes in synaptic connectivity</li> <li>Importantly, these changes are not passive, but are actively controlled by neuromodulation, which is itself under the control of the brain</li> <li>The resulting self-modifying abilities of the brain play an important role in learningand adaptation, and are a major basis for biological reinforcement learning</li> <li>artificial neural networks with such neuromodulated plasticity can be trained withgradient descen</li> <li>differentiable Hebbian plasticity</li> <li>neuromodulated plasticity improves the performance of neural networks on bothreinforcement learning and supervised learning tasks</li> <li>neuromodulated plastic LSTMs with millions of parameters outperform standard LSTMs on a benchmark language modeling task</li> </ul>"},{"location":"KB/Back%20Propamine/#background-differentiable-hebbian-plasticity","title":"BACKGROUND: DIFFERENTIABLE HEBBIAN PLASTICITY","text":"<ul> <li>(Miconi, 2016; Miconi et al., 2018)</li> <li>allows gradient descent to optimize not just the weights, but also the plasticity of each connection</li> <li>each connection in the network is augmented with a Hebbian plastic component that grows and decays automatically as a result of ongoing activity. In effect, each connection contains a fixed and a plastic component:</li> <li>Hebbi,j is initialized to zero at the beginning of each episode/lifetime, and is updatedautomatically</li> <li>purely episodic/intra-life quantity</li> <li>wi,j, fi,j and \u2318 are the structural components of the network, which are optimizedby gradient descent between episodes/lifetimes to minimize the expected loss overan episode.</li> <li>Clip(x) in Eq. 2 is any function or procedure that constrains Hebbi,j to the [1, 1]range, to negate the inherent instability of Hebbian learning.</li> <li>distinction between the \u2318 and fi,j parameters: \u2318 is the intra-life \"learning rate\" ofplastic connections</li> <li>determines how fast new information is incorporated into the plastic component</li> <li>fi,j is a scale parameter, which determines the maximum magnitude of the plasticcomponent (since Hebbi,j is constrained to the [-1,1] range)</li> <li>in contrast to other approaches using uniform plasticity (Schmidhuber, 1993a),including \"fast weights\" (Ba et al., 2016), the amount of plasticity in each connection(represented by fi,j ) is trainable, allowing the meta-optimizer to design complexlearning strategies</li> <li>implementing a plastic recurrent network only requires less than four additional linesof code over a standard recurrent network implementation</li> </ul>"},{"location":"KB/Back%20Propamine/#backpropamine-differentiable-neuromodulation-of-plasticity","title":"BACKPROPAMINE: DIFFERENTIABLE NEUROMODULATION OF PLASTICITY","text":"<ul> <li>plasticity is modulated on a moment-to-moment basis by a network controlled neuromodulatory signal M (t)</li> <li>The computation of M (t) could be done in various ways; at present, it is simply asingle scalar output of the network, which is used either directly (for the simple RLtasks) or passed through a meta-learned vector of weights (one for eachconnection, for the language modeling task)</li> </ul>"},{"location":"KB/Back%20Propamine/#simple-neuromodulation","title":"SIMPLE NEUROMODULATION","text":"<ul> <li>make the (global) \u2318 parameter depend on the output of one or more neurons in the network</li> <li>Because \u2318 essentially determines the rate of plastic change, placing it under network control allows the network to determine how plastic connections should beat any given time.</li> <li>only modification to the equations above in this simple neuromodulation variant is to replace \u2318 in Eq. 2 with the network-computed, time-varying neuromodulatory signalM (t)</li> <li></li> </ul>"},{"location":"KB/Back%20Propamine/#retroactive-neuromodulation-and-eligibility-traces","title":"RETROACTIVE NEUROMODULATION AND ELIGIBILITY TRACES","text":"<ul> <li>alternative neuromodulation scheme that takes inspiration from the short-term retroactive effects of neuromodulatory dopamine on Hebbian plasticity in animalbrains</li> <li>dopamine was shown to retroactively gate the plasticity induced by past activity,within a short time window of about 1s (Yagishita et al., 2014; He et al., 2015; Fisheret al., 2017; Cassenaer &amp; Laurent, 2012)</li> <li>Thus, Hebbian plasticity does not directly modify the synaptic weights, but creates a fast-decaying \"potential\" weight change, which is only incorporated into the actual weights if the synapse receives dopamine within a short time window</li> <li>eligibility trace</li> <li>keeping memory of which synapses contributed to recent activity, while thedopamine signal modulates the transformation of these eligibility traces into actualplastic changes.</li> <li></li> </ul>"},{"location":"KB/Back%20To%20Front%20Raycasting/","title":"Back To Front Raycasting","text":""},{"location":"KB/Back%20To%20Front%20Raycasting/#back-to-front-raycasting","title":"Back To Front Raycasting","text":"<ul> <li>blending over operator for semi-transparent geometry</li> </ul>"},{"location":"KB/Backprop/","title":"Backprop","text":""},{"location":"KB/Backprop/#backprop","title":"Backprop","text":"<ul> <li>Gradient (\\(\\nabla l(\\theta) = [\\frac{\\partial l}{\\partial \\theta_1}(\\theta) , \u2026 , \\frac{\\partial L}{\\partial \\theta_L}(\\theta)]\\)\\)<ul> <li>partial derivs of the loss wrt weights  Forward pass<ul> <li>Store result of operation in u</li> </ul> </li> <li>Backward Pass<ul> <li>Traverse the graph backwards<ul> <li>Chain Rule : \\(\\(\\frac{dl}{d\\theta_i} = \\Sigma_{k \\in parents(l)} \\frac{\\partial l}{\\partial u_k} \\frac{\\partial u_k}{\\partial \\theta_i}\\)\\)</li> <li> \\[\\begin{align} &amp;\\frac{d\\hat y}{d\\mathbf{W_1}}\\\\ &amp;= \\frac{\\partial \\hat y}{\\partial u_2} \\frac{\\partial u_2}{\\partial h_1} \\frac{\\partial h_1}{\\partial u_1} \\frac{\\partial u_1}{\\partial \\mathbf{W_1}} \\\\ &amp;= \\frac{\\partial \\sigma (u2)}{\\partial u_2} \\frac{\\partial \\mathbf{W}^T_2 h_1}{\\partial h_1} \\frac{\\partial \\sigma (u1)}{\\partial u_1} \\frac{\\partial \\mathbf{W}^T_1 x}{\\partial \\mathbf{W}_1} \\end{align}\\] </li> <li>Collecting all the (\\(\\partial \\sigma(u_i)\\)\\) wrt params -&gt; #gradients exponentially decreases wrt depth of the network : Vanishing<ul> <li>Solved by Activation Functions</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"KB/Bag%20of%20Words%20robotics/","title":"Bag of Words Robotics","text":""},{"location":"KB/Bag%20of%20Words%20robotics/#bag-of-words-robotics","title":"Bag of Words Robotics","text":"<ul> <li>Recognizing objects using local descriptors would be computationally expensive.</li> <li>The number of local features for a given object mainly depends on the size of the object, and therefore, varies for different objects.</li> <li>The key idea for fast 3D object recognition is to use mechanisms for representing objects in a compact and uniform format (e.g., histogram).</li> <li>If we represent objects in a uniform format, then we can apply ML algorithms</li> <li>Compute local features for all the discovered objects and make a pool of features.</li> <li>A dictionary is generated via clustering of the pool of features into N clusters (the number of the clusters is the codebook size).</li> <li>Visual word are then defined as the centres of the extracted clusters.</li> <li>Finally, each object is described (abstracted) by a histogram of occurrences of these visual words.</li> <li></li> <li></li> </ul>"},{"location":"KB/Bag%20of%20n-grams/","title":"Bag of n-grams","text":""},{"location":"KB/Bag%20of%20n-grams/#bag-of-n-grams","title":"Bag of N-grams","text":"<ul> <li>consider word phrases of length n to represent documents as fixed-length vectors to capture local word order</li> <li>suffer from data sparsity and high dimensionality.</li> </ul>"},{"location":"KB/Bag%20of%20words/","title":"Bag of words","text":""},{"location":"KB/Bag%20of%20words/#bag-of-words","title":"Bag of Words","text":""},{"location":"KB/Bag%20of%20words/#explained","title":"Explained","text":"<ul> <li>Count based conversion of document into fixed length vectors of integers</li> <li><code>John likes to watch movies. Mary likes movies too.</code><ul> <li><code>[1, 2, 1, 1, 2, 1, 1, 0, 0, 0, 0]</code></li> </ul> </li> <li><code>John also likes to watch football games. Mary hates football.</code><ul> <li><code>[1, 1, 1, 1, 0, 1, 0, 1, 2, 1, 1]</code></li> </ul> </li> <li>Order is arbitary</li> </ul>"},{"location":"KB/Bag%20of%20words/#disadvantages","title":"Disadvantages","text":"<ul> <li>Lose all info about word order</li> <li>Does not learn meaning of the words, so distance isnt very accurate</li> <li>Somewhat solved by Bag of n-grams</li> <li>Curse Of Dimensionality</li> </ul>"},{"location":"KB/Bahdanau%20Attention/","title":"Bahdanau Attention","text":""},{"location":"KB/Bahdanau%20Attention/#bahdanau-attention","title":"Bahdanau Attention","text":"<ul> <li>Neural Machine Translation by Jointly Learning to Align and Translate<ul> <li>Attention mechanism (borrowed from the field of information retrieval) within the context of NLP</li> </ul> </li> <li>Same as Additive Attention</li> <li></li> </ul>"},{"location":"KB/Barycentric%20Interpolation/","title":"Barycentric Interpolation","text":""},{"location":"KB/Barycentric%20Interpolation/#barycentric-interpolation","title":"Barycentric Interpolation","text":"<ul> <li>d+1 points</li> <li>Point x is an Affine Function of \\(x_i\\)</li> </ul>"},{"location":"KB/Basal%20Ganglia/","title":"Basal Ganglia","text":""},{"location":"KB/Basal%20Ganglia/#basal-ganglia","title":"Basal Ganglia","text":"<ul> <li>includes the caudate, putamen and globus pallidus. These nuclei work with the cerebellum to coordinate fine motions, such as fingertip movements.</li> <li>Hypothalamus</li> <li>Pituitary gland</li> <li>Pineal gland</li> <li>Thalamus</li> <li>Limbic system</li> </ul>"},{"location":"KB/Basal%20Ganglia/#basal-ganglia_1","title":"Basal Ganglia","text":"<ul> <li>A group of structures below the cortex involved in motor, cognitive, and emotional functions.</li> </ul>"},{"location":"KB/Base%20Link/","title":"Base Link","text":""},{"location":"KB/Base%20Link/#base-link","title":"Base Link","text":"<ul> <li>The stationary base structure of a robot arm that supports the first joint.</li> </ul>"},{"location":"KB/Basic%20GAN/","title":"Basic GAN","text":""},{"location":"KB/Basic%20GAN/#basic-gan","title":"Basic GAN","text":"<ul> <li>Generative Adversarial Networks</li> <li>Learn a prob distribution directly from data generated by that distribution</li> <li>no need for any Markov Chain or unrolled approximate inference networks during either training or generation of samples</li> <li>Adversarial Learning</li> <li></li> <li>Min Max game \\(\\(max_D min_G V(G,D)\\)\\) where \\(\\(V(G,D) = \\mathbb{E}_{p_{data}(x)}logD(x) + \\mathbb{E}_{p_{data}(x)}log(1-D(x))\\)\\)</li> <li>G : Gradient Descent gradients</li> <li>D : Gradient Ascent</li> <li>Discriminator Loss (Given Generator)<ul> <li> \\[L_{disc}(D_\\theta) =-\\frac{1}{2}(\\mathbb{E}_{x\\sim p_{real}(x)}[log(D_{theta}(x))] + \\mathbb{E}_{x\\sim p_{latent}(x)}[log(1- D_\\theta(G_\\phi(z)))])\\] </li> </ul> </li> <li>Generator Loss (Given Discriminator)<ul> <li> \\[L_{gen}(G_{\\phi})= - \\mathbb{E}_{z\\sim p_{latent}(z)}[log(D_\\theta(G_\\phi(z)))]\\] </li> <li>This is low if Discriminator is fooled by Gen, \\(D_{\\theta}(x_{gen}) \\approx 1\\)</li> </ul> </li> </ul>"},{"location":"KB/Basic%20GAN/#training","title":"Training","text":"<ul> <li>pick mini batch of samples\u00a0</li> <li>update discriminator with\u00a0Gradient Descent based** on discriminator loss with generator obtained from previous update</li> <li>update the generator with\u00a0Gradient Descent based on generator loss with the discriminator from the previous step</li> </ul>"},{"location":"KB/Basic%20GAN/#issues","title":"Issues","text":"<ul> <li>Mode Collapse</li> </ul>"},{"location":"KB/Basic%20RNN%20Architectures/","title":"Basic RNN Architectures","text":""},{"location":"KB/Basic%20RNN%20Architectures/#basic-rnn-architectures","title":"Basic RNN Architectures","text":"<ul> <li>Recurrent</li> <li>SRN</li> <li>Stacking RNN</li> <li>Bi Directional RNN</li> <li>Seq2Seq</li> <li>Temporal Conv</li> <li>[GRU)](Gated Recurrent Unit (GRU|Gated Recurrent Unit (GRU|GRU)](GRU)](Gated Recurrent Unit (GRU|Gated Recurrent Unit (GRU|GRU).md).md)</li> <li>[LSTM)](Long Short Term Memory (LSTM|Long Short Term Memory (LSTM|LSTM)](LSTM)](Long Short Term Memory (LSTM|Long Short Term Memory (LSTM|LSTM).md).md)</li> </ul>"},{"location":"KB/Basic%20Transformer/","title":"Basic Transformer","text":""},{"location":"KB/Basic%20Transformer/#basic-transformer","title":"Basic Transformer","text":"<ul> <li>Feed forward blocks, are two Dense MLPs with Relu. Residual connections in between</li> <li>Uses Attention</li> <li>Embedding Layers transform between 1 hot and vector rep</li> <li>Position Encoding + Token Embedding</li> <li>Position Wise Feed Forward</li> </ul>"},{"location":"KB/Basics%20of%20Federated%20Learning/","title":"Basics of Federated Learning","text":""},{"location":"KB/Basics%20of%20Federated%20Learning/#basics-of-federated-learning","title":"Basics of Federated Learning","text":"<ol> <li>Get data (Hopefully a lot)</li> <li>Preprocess (aka clean up) the data</li> <li>Find/create an architecture</li> <li>Train the model using the data(1) and the architecture(3). This step is done once. And then periodically updated as the data changes over time. Keep this in mind.</li> <li>Push the model out to n users</li> <li>Collect data about how well the model did. (Bye bye privacy)</li> <li>Send this data back to the main model. 7 (#new). Find the difference between the original model and the personalized one's parameters. Do this for multiple users. Remove identifiable information. 7.1 (#new). Aggregate (eg. average) the information and then send that to the main model</li> <li>Retrain the model on new data</li> </ol>"},{"location":"KB/Basilar%20Artery/","title":"Basilar Artery","text":""},{"location":"KB/Basilar%20Artery/#basilar-artery","title":"Basilar Artery","text":"<ul> <li>Located at the base of the skull, the basilar artery is a large, specialized blood vessel that supplies oxygenated blood to the brain and nervous system.</li> </ul>"},{"location":"KB/Batch%20Normalization/","title":"Batch Normalization","text":""},{"location":"KB/Batch%20Normalization/#batch-normalization","title":"Batch Normalization","text":"<ul> <li>bias=False for Linear/Conv2D for input and True for output #tricks</li> <li>Normalizes #activations</li> <li>Input distributions change per layer -&gt; Make sure they stay similar</li> <li>Reduces co variate shift because now the network must adapt per layer</li> <li>During testing : use stats saved during training</li> <li>Simplifies learning dynamics<ul> <li>Can use larger learning rate</li> <li>Higher order interactions are suppressed because the mean and std are independant of the activations which makes training easier</li> </ul> </li> <li>Cant work with small batches. Not great with RNN</li> <li></li> <li> \\[\\mu_j \\leftarrow \\frac{1}{m}\\Sigma_{i=1}^m x_{ij}\\] </li> <li> \\[\\sigma^2_j \\leftarrow \\frac{1}{m}\\Sigma^m_{i=1}(x_{ij}-\\mu_j)^2\\] </li> <li> \\[\\hat x_{ij} \\leftarrow \\frac{x_{ij}-\\mu_j}{\\sqrt{\\sigma^2_j + \\epsilon}}\\] </li> <li> \\[\\hat x_{ij} \\leftarrow \\gamma \\hat x_{ij} + \\beta\\] </li> </ul>"},{"location":"KB/Bayes%20Prediction/","title":"Bayes Prediction","text":""},{"location":"KB/Bayes%20Prediction/#bayes-prediction","title":"Bayes Prediction","text":"<ul> <li> \\[P(y|x) = \\int_{w}P(y|w,x)P(w|x)dw\\] </li> <li>w is model parameters</li> <li>basically gets y with different model parms w</li> <li>prob of those params given input x</li> <li>Model averaging</li> </ul>"},{"location":"KB/Bayes%20Rule/","title":"Bayes Rule","text":""},{"location":"KB/Bayes%20Rule/#bayes-rule","title":"Bayes Rule","text":"<ul> <li> \\[h(\\theta|D) = \\frac{p_{\\otimes_{i}}x(D|\\theta)h(\\theta)}{p(D)}\\] </li> </ul>"},{"location":"KB/Bayesian%20Information%20Criterion/","title":"Bayesian Information Criterion","text":""},{"location":"KB/Bayesian%20Information%20Criterion/#bayesian-information-criterion","title":"Bayesian Information Criterion","text":"<ul> <li> \\[BIC = -2 log(L) + 2log(n)q = \\frac{1}{n}(RSS + log(n) p \\hat \\sigma^{2})\\] </li> <li>L: denotes the likelihood function for a particular model</li> <li>q: number of estimated parameters of the model</li> </ul>"},{"location":"KB/Bayesian%20Model%20Estimation/","title":"Bayesian Model Estimation","text":""},{"location":"KB/Bayesian%20Model%20Estimation/#bayesian-model-estimation","title":"Bayesian Model Estimation","text":"<ul> <li>Unlike frequentist, sometimes things like sample mean is not a good metric because it has a high variance. Might give different results with different trials in a real valued distribution</li> <li>The task is to estimate \\(\\theta\\) from the data</li> <li>Bayesian Prior</li> <li>Now there are two sources of info about the true distribution \\(p_{X}(\\theta)\\)<ul> <li>The likelihood \\(p_{\\otimes_{i}}x(D|\\theta)\\) of \\(\\theta\\) . Empirical data</li> <li>Prior plausibility in \\(h(\\theta)\\)</li> <li>Since these are independant sources we can combine them by multiplication: \\(p_{\\otimes_{i}}x(D|\\theta)h(\\theta)\\)<ul> <li>High values -&gt; Candidate model \\(\\theta\\) is a good estimate</li> <li>Bayesian Posterior</li> <li>Posterior Mean estimate</li> </ul> </li> </ul> </li> </ul>"},{"location":"KB/Bayesian%20Model%20Estimation/#advantages","title":"Advantages","text":"<ul> <li>If priors are well chosen -&gt; Better than frequentists with small sample sizes</li> </ul>"},{"location":"KB/Bayesian%20Model%20Estimation/#disadvantages","title":"Disadvantages","text":"<ul> <li>Integrating over millions of params and performing multiple preds for each param -&gt; infeasible</li> <li>How to encode or represent Bayesian Posterior as very high dim<ul> <li>No closed form representation over weights</li> <li>Represent data with histograms and use Monte Carlo</li> </ul> </li> </ul>"},{"location":"KB/Bayesian%20Model%20Estimation/#example","title":"Example","text":"<ul> <li>Green : prior , Red: Posterior</li> <li>The Posterior Mean estimate is obtained by integrating \\(\\int_{\\mathbb{R}}\\mu h(\\mu|D)d\\mu\\)</li> <li>Since this is different from sample mean -&gt; Prior distribution really does influence the models</li> </ul>"},{"location":"KB/Bayesian%20Model%20Estimation/#protein-modeling","title":"Protein Modeling","text":""},{"location":"KB/Bayesian%20Neural%20Network/","title":"Bayesian Neural Network","text":""},{"location":"KB/Bayesian%20Neural%20Network/#bayesian-neural-network","title":"Bayesian Neural Network","text":"<ul> <li>Bayesian Model Estimation</li> <li>Generally we want to learn Joint Probability distribution \\(P(y|x)\\) but this does not use the model parameters w</li> <li>We need (\\(P(w|D) = \\frac{P(D|w)P(w)}{P(D)}\\)\\)<ul> <li>D is the labelled dataset</li> <li>Model is now defined by structure and parameters</li> </ul> </li> <li>The parameters encode information about Uncertainty<ul> <li>Can be understood using Bayesian Predictive Posterior</li> </ul> </li> </ul>"},{"location":"KB/Bayesian%20Posterior/","title":"Bayesian Posterior","text":""},{"location":"KB/Bayesian%20Posterior/#bayesian-posterior","title":"Bayesian Posterior","text":"<ul> <li>When D is fixed though, this becomes a function of Model Candidates</li> <li>Non negative on K dim param space</li> <li>Not a PDF but if we divide it by its integral -&gt; PDF .<ul> <li> \\[\\frac{p_{\\otimes_{i}}x(D|\\theta)h(\\theta)}{\\int_{\\mathbb{R}^K}p_{\\otimes_{i}}x(D|\\theta)h(\\theta)d\\theta}\\] </li> <li>Prob distrib over candidate models</li> </ul> </li> <li>If the denominator is replaced written as \\(p(D)\\) then it looks like the Bayes Rule</li> <li>Shape : \\(P(D|\\theta)h(\\theta)\\)<ul> <li>Integral not 1</li> <li>Proto Distributions on \\(\\theta\\) space</li> </ul> </li> </ul>"},{"location":"KB/Bayesian%20Predictive%20Posterior/","title":"Bayesian Predictive Posterior","text":""},{"location":"KB/Bayesian%20Predictive%20Posterior/#bayesian-predictive-posterior","title":"Bayesian Predictive Posterior","text":"<ul> <li>Follows from Bayesian Posterior</li> <li>Marginalizing over all possible model parameters w</li> <li>Computes predictions y with different model parameters w and weights them by the Probability of those params given an input x</li> <li>Bayesian Model Averaging</li> <li> \\[P(y|x) = \\int_{w}P(y|w,x)P(w|x)dx\\] </li> </ul>"},{"location":"KB/Bayesian%20Prior/","title":"Bayesian Prior","text":""},{"location":"KB/Bayesian%20Prior/#bayesian-prior","title":"Bayesian Prior","text":"<ul> <li>Use prior knowledge as beliefs (param vectors \\(\\theta\\)). Cast in the form of a Probability distribution over the space \\(\\Theta\\) .<ul> <li>Weak knowledge most times</li> <li>For a K parametric PDF \\(p_{x}\\) , \\(\\Theta \\in \\mathbb{R}^{K}\\) .</li> <li>Not connected to Random variable(RVS).</li> <li>Does not model outcomes. Instead has \"beliefs\" about true distribution \\(P_{X_{i}}\\)</li> <li>Each \\(\\theta \\in \\mathbb{R}^{K}\\) corresponds to one specific PDF \\(p_{X}(\\theta)\\) -&gt; single candidate distribution \\(\\hat P_{X}\\) for values \\(x_i\\) (In frequentist, it models single data points)</li> <li>Since this is a distribution over distributions, it is a hyperdistribution</li> <li>N dim PDF \\(p_{\\otimes}x_{i}: \\mathbb{R}^{N} \\rightarrow \\mathbb{R}^{\\geq 0}\\) for the distribution of \\(RV \\otimes_{i}X_{i}\\)<ul> <li>\\(p_{\\otimes_{i}}x_{i}((x_{i},\u2026, x_{N})) = p_{x_{1}}, \u2026, p_{x_{N}}(x_{N}) = \\Pi_{i}p_{X}(x_{i})\\)</li> <li>\\(p_{\\otimes_{i}}x(D|\\theta)\\) -&gt; PDF values on a data sample D \\(p_{\\otimes_{i}}x_{i}((x_{i},\u2026, x_{N})) = p_{\\otimes_{i}}(\\theta)(D)\\)</li> </ul> </li> <li>When \\(\\theta\\) is fixed then \\(p_{\\otimes_{i}}x(D|\\theta)\\) is a function of data vectors D. For each sample, it describes how probable this distribution is assuming the true distribution of X is \\(p_{X}(\\theta)\\)</li> <li>When D is fixed, then it is a function of \\(\\theta\\). But this does not really measure anything.<ul> <li>Integral over \\(\\theta\\) is not 1</li> <li>It is a function of \\(\\theta\\) and so it is a likelihood function. MLE</li> <li>If given data D -&gt; it can show which models are more likely than others.</li> <li>Higher values of  \\(p_{\\otimes_{i}}x(D|\\theta)\\) are better</li> </ul> </li> </ul> </li> </ul>"},{"location":"KB/Bayesian%20Rule%20List/","title":"Bayesian Rule List","text":"<ul> <li>@Interpretable classifiers using rules and Bayesian analysis: Building a better stroke prediction model</li> <li>The BRL is a generative model that yields a posterior distribution over possible decision lists, which consist of a series of if-then statements that discretize a high-dimensional, multivariate feature space into a series of simple, readily interpretable decision statements. The if statements define a partition of a set of features, and the then statements correspond to the predicted outcome of interest.</li> <li>According to the authors, their experiments showed that the BRL has predictive accuracy on par with the current top algorithms for prediction in Machine Learning</li> <li>The BRL is able to be used to produce highly accurate and interpretable medical scoring systems</li> </ul>"},{"location":"KB/Bayesian%20Rule%20List/#bayesian-rule-list","title":"Bayesian Rule List","text":"<code>toc</code>"},{"location":"KB/Bayesian/","title":"Bayesian","text":""},{"location":"KB/Bayesian/#bayesian","title":"Bayesian","text":"<ul> <li>Subjective</li> <li>Bayes Prediction</li> <li>Bayes Rule</li> <li>Bayesian Model Estimation</li> <li>Probability density function</li> </ul>"},{"location":"KB/Beam%20search/","title":"Beam search","text":""},{"location":"KB/Beam%20search/#beam-search","title":"Beam Search","text":"<ul> <li>(from)</li> <li>at each step, keep track of the\u00a0k\u00a0mos probable translation hypotheses (k, beam size)</li> <li>examine the\u00a0k\u00a0most probable words for each hypothesis, compute their entire scores, keep\u00a0k\u00a0best ones</li> <li>not guaranteed to find optimal solution, but more efficient than exhaustive search</li> <li>it does not only take the best word, it rather takes the best\u00a0B\u00a0(user specified) and generates multiple hypothesis, which will then be evaluated and the best one at each step is chosen for the next ones</li> <li>not guaranteed to find the optimal solution and is therefore an approximate search</li> <li>problems:<ul> <li>when multiplying a lot of probabilities of very unlikely word (e.g. almost 0 but not exactly), the result will get very small and the system can no longer represent it. results in numerical underflow --&gt; instead of multiplying, summing the log of probabilities (more numerical stable)</li> <li>if the sentence is very long, the probabilities get very low, therefore it rather takes smaller translations --&gt; normalize the output by the number of word in the translation (average of the log of each word)</li> </ul> </li> <li>how to choose beam width\u00a0\\(B\\)?<ul> <li>the smaller, the fewer probabilities are considered (worse result, faster)</li> <li>the larger, the more are considered, but the more computing expensive it is (better results, slower)</li> <li>try out different values and cross check</li> </ul> </li> </ul>"},{"location":"KB/Belief-Desire-Intention/","title":"Belief-Desire-Intention","text":""},{"location":"KB/Belief-Desire-Intention/#belief-desire-intention","title":"Belief-Desire-Intention","text":"<ul> <li>To judge the ethics of an agent's own actions, the awareness process generates the beliefs that describe the current situation facing the agent and the goals of the agent.</li> <li>Based on the beliefs and goals, the evaluation process generates the set of possible actions and desirable actions</li> <li>goodness process then computes the set of ethical actions based on the agent's beliefs, desires, actions, and moral value rules</li> <li>rightness process evaluates whether or not executing a possible action is right under the current situation and selects an action which satisfies the rightfulness requirement</li> </ul>"},{"location":"KB/Belmont%20Principles/","title":"Belmont Principles","text":""},{"location":"KB/Belmont%20Principles/#belmont-principles","title":"Belmont Principles","text":"<ul> <li>The three principles\u2014</li> <li>beneficence, distributive justice, and respect for persons\u2014which the 1976 Belmont Report concluded should underlie all conduct in biomedical and behavioral research in order to protect human participants.</li> </ul>"},{"location":"KB/Belmont%20Report/","title":"Belmont Report","text":""},{"location":"KB/Belmont%20Report/#belmont-report","title":"Belmont Report","text":"<ul> <li>An influential report that identified and defined the basic ethical principles (the Belmont principles) that should govern research studies involving human participants.</li> </ul>"},{"location":"KB/Benchmark%20LLM/","title":"Benchmark LLM","text":""},{"location":"KB/Benchmark%20LLM/#benchmark-llm","title":"Benchmark LLM","text":"<ul> <li>Large Language Models Still Can\u2019t Plan (A Benchmark for LLMs on Planning and Reasoning about Change)))</li> <li>The recent advances in large language models (LLMs) have transformed the field of natural language processing (NLP)</li> <li>From GPT3 to PaLM, the state-of-the-art performance on natural language tasks is being pushed forward with every new large language model</li> <li>current benchmarks are relatively simplistic and the performance over these benchmarks cannot be used as an evidence to support</li> <li>extensible assessment framework motivated by the above gaps in current benchmarks to test the abilities of LLMs on a central aspect of human intelligence, which is reasoning about actions and change</li> <li>multiple test cases</li> </ul>"},{"location":"KB/Bend%20Minimization/","title":"Bend Minimization","text":""},{"location":"KB/Bend%20Minimization/#bend-minimization","title":"Bend Minimization","text":"<ul> <li>Curved lines easier to follow than edged lines Gestalt Laws</li> <li>domain specific constraints and traditions have to be acknowledged</li> <li></li> </ul>"},{"location":"KB/Beneficence/","title":"Beneficence","text":""},{"location":"KB/Beneficence/#beneficence","title":"Beneficence","text":"<ul> <li>One of the three Belmont principles, the requirement that physicians and researchers provide, to the best of their ability, positive benefits for patients that participate in clinical trials, including good health and the prevention and removal of harmful conditions.</li> </ul>"},{"location":"KB/Benford%27s%20Law/","title":"Benford's Law","text":""},{"location":"KB/Benford%27s%20Law/#benfords-law","title":"Benford's Law","text":"<ul> <li>In a genuine dataset of numbers<ul> <li>1 will be the leading digit 30.1% of the time</li> <li>2 will be the leading digit 17.6% of the time</li> <li>rest with decreasing frequency</li> </ul> </li> </ul>"},{"location":"KB/Benign/","title":"Benign","text":""},{"location":"KB/Benign/#benign","title":"Benign","text":"<ul> <li>Refers to a tumor that is neither cancerous nor malignant</li> </ul>"},{"location":"KB/Berkeley%20et%20al/","title":"Berkeley et al","text":""},{"location":"KB/Berkeley%20et%20al/#berkeley-et-al","title":"Berkeley Et Al","text":"<ul> <li>576 input patterns</li> <li>5793 epochs needed to reach convergence</li> <li>Model frozen, stimulus set presented again</li> <li>Activation of each hidden unit recorded</li> <li>Single unit recording</li> <li>Why do these bands appear?</li> <li>Gaussian activation function</li> <li>But banding patterns have been found with sigmoidal activation as well</li> <li>Effect = units only respond to a limited number of inputs</li> <li>Bands appear when weights into HUs cancel each other out</li> <li>Activations of hidden neurons can be organized into bands</li> <li>Bands are associated with interpretable features</li> <li>Lesion studies show bands are essential to solving problem</li> <li>For some problems under some circumstances, neural networks develop highly selective hidden units</li> <li>Looks like localist coding (grandmother cells)</li> <li>Patterns of activation can be ambiguous on their own</li> <li>But realistically, more than one pattern might be activated simultaneously</li> <li>Superimposing two or more patterns over same units leads to an ambiguous blend</li> <li>Problem for localist representations, but even more serious with distributed representations</li> </ul>"},{"location":"KB/Bernoulli%20Distribution/","title":"Bernoulli Distribution","text":""},{"location":"KB/Bernoulli%20Distribution/#bernoulli-distribution","title":"Bernoulli Distribution","text":"<ul> <li>Only two possible outcomes</li> <li>PMF : \\(\\(p(s_{i}) = \\begin{cases} 1-q, &amp; \\text{for i = 1} \\\\ q,&amp; \\text{for i =2} \\end{cases}\\)\\)</li> <li>Given : Data - \\({x_{1}, .., x_{N}}\\) and \\(x_{i} \\in {s_{1}, s_{2}}\\) then \\(\\(\\hat q = \\frac{1}{N}|\\{i|x_{i}= s_{2}\\}\\)\\)</li> </ul>"},{"location":"KB/Best%20Maching%20Unit/","title":"Best Matching Unit","text":""},{"location":"KB/Best%20Maching%20Unit/#best-matching-unit","title":"Best Matching Unit","text":"<ul> <li>Neuron whose weight vector best matches input pattern</li> </ul>"},{"location":"KB/Beta%20Distribution/","title":"Beta Distribution","text":""},{"location":"KB/Beta%20Distribution/#beta-distribution","title":"Beta Distribution","text":"<ul> <li>[0,1]</li> <li>Parameterized by two positive shape parameters \\(\\alpha, \\beta\\)</li> <li>Exponents of the random variable and control the shape of the distribution</li> <li>Multiple variables is Dirichlet Distribution</li> </ul>"},{"location":"KB/Beta%20Waves/","title":"Beta Waves","text":""},{"location":"KB/Beta%20Waves/#beta-waves","title":"Beta Waves","text":"<ul> <li>Movement</li> <li></li> </ul>"},{"location":"KB/Beware%20of%20Inmates%20Running%20the%20Asylum/","title":"Beware of Inmates Running the Asylum","text":"<ul> <li> <p>Tim Miller\u2217 and Piers Howe\u2020 and Liz Sonenberg</p> </li> <li>@Explainable AI: Beware of Inmates Running the Asylum Or: How I Learnt to Stop Worrying and Love the Social and Behavioural Sciences</li> </ul>"},{"location":"KB/Beware%20of%20Inmates%20Running%20the%20Asylum/#beware-of-inmates-running-the-asylum","title":"Beware of Inmates Running the Asylum","text":"<p><code>toc</code></p>"},{"location":"KB/Beware%20of%20Inmates%20Running%20the%20Asylum/#tldr","title":"TL;DR","text":"<ul> <li>Essentially proposes to look at behavioral science research as well. Not particularly useful but is a good reminder to look at other research because XAI is meant for people and not programmers.</li> </ul>"},{"location":"KB/Beware%20of%20Inmates%20Running%20the%20Asylum/#abstract","title":"Abstract","text":"<ul> <li>programmers design software for themselves, rather than for their target audience; a phenomenon he refers to as the \u2018inmates running the asylum\u2019.</li> <li>This paper argues that explainable AI risks a similar fate.</li> <li>evaluation of these models is focused more on people than on technology</li> <li>considerable scope to infuse more results from the social and behavioural sciences into explainable AI, and present some key results from these fields that are relevant to explainable AI.</li> </ul>"},{"location":"KB/Beware%20of%20Inmates%20Running%20the%20Asylum/#explainable-ai-survey","title":"Explainable AI Survey","text":""},{"location":"KB/Beware%20of%20Inmates%20Running%20the%20Asylum/#survey-method","title":"Survey Method","text":"<ul> <li> <p>On topic</p> <ul> <li>Each paper was categorised as either being about explainable AI or not, based on our understanding of the topic</li> <li>Data Driven</li> <li>Each paper was given a score from 0\u20132 inclusive.</li> <li>A score of 1 was given if and only if one or more of the references of the paper was an article on explanation in social science</li> <li>Validation</li> <li>Each paper was given a binary 0/1. A score of 1 was given if and only if the evaluation in the survey article (note, not the referenced article) was based on data from human behavioural studies.</li> </ul> </li> </ul>"},{"location":"KB/Beware%20of%20Inmates%20Running%20the%20Asylum/#results","title":"Results","text":"<ul> <li>These results show that for the on-topic papers, only four articles referenced relevant social science research, and only one of them truly built a model on this</li> <li>Further, serious human behavioural experiments are not currently being undertaken.</li> <li>For off topic papers, the results are similar: limited input from social sciences and limited human behavioural experiments.</li> <li>Where to? A Brief Pointer to Relevant Work Contrastive Explanation</li> <li>explanations are contrastive why\u2013questions are contrastive</li> <li>That is, why\u2013questions are of the form \u201cWhy P rather than Q?\u201d, where P is the fact that requires explanation, and Q is some foil case that was expected</li> <li>Importantly, the contrast case helps to frame the possible answers and make them relevant</li> <li>This is a challenge for explainable AI, because it may not be easy to elicit a contrast case from an observer.</li> <li>However, it is also an opportunity: as Lipton [1990] argues, answering a contrastive question is often easier than giving a full cause attribution because one only needs to understand the difference between the two cases, so one can provide a complete explanation without determining or even knowing all causes of the event.</li> </ul>"},{"location":"KB/Beware%20of%20Inmates%20Running%20the%20Asylum/#attribution-theory","title":"Attribution Theory","text":"<ul> <li>study of how people attribute causes to events Social Attribution</li> <li>The book from Malle [2004], based on a large body of work from himself and other researchers in the field, describes a mature model of how people explain behaviour of others using folk psychology</li> <li>people attribute behaviour based on the beliefs, desires, intentions, and traits of people</li> <li>important for systems in which intentional action will be cited as a cause important for systems doing deliberative reasoning</li> </ul>"},{"location":"KB/Beware%20of%20Inmates%20Running%20the%20Asylum/#causal-connection","title":"Causal Connection","text":"<ul> <li>Research on how people connect causes shows that they do so by undertaking a mental simulation of what would have happened had some other event turned out differently</li> </ul>"},{"location":"KB/Bhattacharya%20Distance/","title":"Bhattacharya Distance","text":""},{"location":"KB/Bhattacharya%20Distance/#bhattacharya-distance","title":"Bhattacharya Distance","text":"<ul> <li>In statistics, the\u00a0Bhattacharyya distance\u00a0measures the similarity of two Distributions. It is normally used to measure the separability of classes in classification.</li> <li> \\[D_{B}(p,q) = -ln(BC(p,q))\\] </li> <li> \\[BC(p,q) = \\Sigma_{x\\in X}\\sqrt{p(x)q(x)}\\] </li> </ul>"},{"location":"KB/Bi%20Directional%20RNN/","title":"Bi Directional RNN","text":""},{"location":"KB/Bi%20Directional%20RNN/#bi-directional-rnn","title":"Bi Directional RNN","text":"<ul> <li>Not causal</li> <li>Looks at the forward timestep dimension and also the backward<ul> <li>Both combined to make a prediction</li> </ul> </li> <li></li> </ul>"},{"location":"KB/Bias%20Variance%20Dilemma/","title":"Bias Vs Variance","text":""},{"location":"KB/Bias%20Variance%20Dilemma/#bias-vs-variance","title":"Bias Vs Variance","text":"<ul> <li><ul> <li>m is choices of PC vectors</li> <li>as m increases, weight matrices grow by \\(10\\cdot m\\) . Aka more flexible models.</li> <li>Increasing tail of MSEtest -&gt; overfitting. too flexible</li> <li>Increasing flexibility -&gt; decrease of empirical risk</li> <li>Inc : very low to very high -&gt; less and less underfitting then overfitting</li> <li>Best: min point in curve. But it is defined on test data which we do not have</li> </ul> </li> <li></li> <li></li> <li>Decision function should minimize LossFunctions and yield a function with risk h. This is hopeless \\(\\(R(h) = E[L(h(X), Y)]\\)\\)</li> <li>Tune on Emperical Risk instead using Optimizers</li> <li>\\(\\mathcal{H}\\) is hypothesis space (related to Fitting).</li> </ul>"},{"location":"KB/Bias%20Variance%20Dilemma/#why-is-this-a-dilemma","title":"Why is This a Dilemma","text":"<ul> <li>Any learning algo \\(\\mathcal{A}\\)</li> <li>If we run \\(\\mathcal{A}\\) repeatedly but for different \"fresh\" sampled data -&gt; \\(\\hat h\\) varies from trial to trial</li> <li>For any fixed x, \\(\\hat h(x)\\)<ul> <li>is a random variable</li> <li>value determined by drawn training samples</li> <li>rep by distribution \\(P_{X,Y}\\) (which we cannot really know)</li> <li>Expectation \\(E_{retrain}[\\hat h(x)]\\) . aka taken over ALL possible training runs with sampled data</li> </ul> </li> <li>Quadratic Loss (risk) is minimized by the function (\\(\\Delta(x) = E_{Y|X=x}[Y]\\)\\)<ul> <li>Expectation of Y given x.</li> </ul> </li> <li></li> <li></li> <li>Bias measures how strongly the avg result deviates from optimal value</li> <li>Variance measures how strongly the results vary around the expected value \\(E_{retrain}\\)</li> <li>When flexibility is too low -&gt; bias dominates(too good in train and horrible later) and underfits</li> <li>When flexibility is too high -&gt; variance dominates -&gt; overfitting</li> </ul>"},{"location":"KB/Bias%20Variance%20Dilemma/#tuning-model-flexibility","title":"Tuning Model Flexibility","text":""},{"location":"KB/Bias%20nodes/","title":"Bias nodes","text":""},{"location":"KB/Bias%20nodes/#bias-nodes","title":"Bias Nodes","text":"<ul> <li>Bias nodes give a defaults activation to other nodes<ul> <li>Usually included, the bias node does not connect to input nodes but to the output nodes</li> </ul> </li> </ul>"},{"location":"KB/Big%20Bird/","title":"Big Bird","text":""},{"location":"KB/Big%20Bird/#big-bird","title":"Big Bird","text":"<ul> <li>Big Bird: Transformers for Longer Sequences</li> <li>imitation of Transformer-based models is the quadratic complexity</li> <li>sparse attention mechanism that reduces this quadratic complexity to linear</li> </ul>"},{"location":"KB/Big-Bench/","title":"Big-Bench","text":""},{"location":"KB/Big-Bench/#big-bench","title":"Big-Bench","text":"<ul> <li>Beyond the Imitation Game: Quantifying and Extrapolating the Capabilities of Language Models</li> <li>present and near-future capabilities and limitations of language models</li> <li>Beyond the Imitation Game benchmark (BIG-bench)</li> <li>benchmark that can measure progress well beyond the current state-of-the-art</li> <li>204 tasks, contributed by 442 authors across 132 institutions</li> <li>Task topics are diverse, drawing problems from linguistics, childhood development, math, common-sense reasoning, biology, physics, social bias, software development</li> <li>tasks that are believed to be beyond the capabilities of current language models</li> <li>valuate the behavior of OpenAI\u2019s GPT models, Google-internal dense transformer architectures, and Switch-style sparse transformers on BIG-bench, across model sizes spanning millions to hundreds of billions of parameters</li> </ul>"},{"location":"KB/Bilinear%20Interpolation/","title":"Bilinear Interpolation","text":""},{"location":"KB/Bilinear%20Interpolation/#bilinear-interpolation","title":"Bilinear Interpolation","text":"<ul> <li> \\[f(x,y) = (1-\\beta)(1-\\alpha)f_{i,j}+(1-\\beta)\\alpha f_{i+1,j} + \\beta(1-\\alpha)f_{i,j+1}+\\beta \\alpha f_{i+1,j+1}\\] </li> <li>Quadratic</li> <li>ik, jkl , il -&gt; ij</li> </ul>"},{"location":"KB/Billion%20Word/","title":"Billion Word","text":""},{"location":"KB/Billion%20Word/#billion-word","title":"Billion Word","text":""},{"location":"KB/Binary%20Cross%20Entropy/","title":"Binary Cross Entropy","text":""},{"location":"KB/Binary%20Cross%20Entropy/#binary-cross-entropy","title":"Binary Cross Entropy","text":"\\[-(ylog(p)+(1-y)log(1-p))$$ - $$L(y, \\hat y) = - \\Sigma_{i}y_{i}log(\\hat y_{i})+ (1-y_{i})log(1-\\hat y_{i})\\]"},{"location":"KB/Binary%20pattern/","title":"Binary Pattern Encoding","text":""},{"location":"KB/Binary%20pattern/#binary-pattern-encoding","title":"Binary Pattern Encoding","text":"<ul> <li>If symbol alphabet has a large size k<ul> <li>One hot is too huge</li> </ul> </li> <li>Encode into binary vector of length \\(\\(\\lceil log_{2} \\rceil\\)\\)</li> <li>{a,b,c,d} -&gt; {[0,0]', [0,1]', [1,0]', [1,1]'}</li> <li>Non linear effort as it is a arbitrary encoding</li> <li>Too intensive</li> </ul>"},{"location":"KB/Binary%20pattern/#_1","title":"\u2026","text":""},{"location":"KB/BinaryBERT/","title":"BinaryBERT","text":""},{"location":"KB/BinaryBERT/#binarybert","title":"BinaryBERT","text":"<ul> <li>BinaryBERT: Pushing the Limit of BERT Quantization</li> <li>demand for model compression techniques</li> <li>weight binarization</li> <li>binary BERT is hard to be trained directly than a ternary counterpart due to its steep and complex loss landscape</li> <li>ternary weight splitting</li> <li>initializes BinaryBERT by equivalently splitting from a half-sized ternary network, followed by fine-tuning for further refinement</li> <li>binary model thus inherits the good performance of the ternary one, and can be further enhanced by fine-tuning the new architecture after splitting</li> <li>tailor the size of BinaryBERT based on the edge device constraints</li> <li>GLUE</li> <li>SQuAD</li> </ul>"},{"location":"KB/Binning/","title":"Binning","text":""},{"location":"KB/Binning/#binning","title":"Binning","text":"<ul> <li>k segments</li> <li>Transform each symbol</li> <li>Types<ul> <li>Simplest -&gt; k equal bins</li> <li>Approx Equal no of data points</li> <li>Reduced precision devices perform as well as the high precision ones</li> <li>Continuous range -&gt; adaptive bin boundaris Decision Trees</li> </ul> </li> </ul>"},{"location":"KB/Binomial%20Distribution/","title":"Binomial Distribution","text":""},{"location":"KB/Binomial%20Distribution/#binomial-distribution","title":"Binomial Distribution","text":"<ul> <li>Bernoulli Distribution repeated for N independant trials with success Probability q</li> <li>Aka N times with only 2 outcomes</li> <li>PMF: \\(\\(p(s) = \\binom{N}{s}q^{s}(1-q)^{N-s} = \\frac{N!}{s!(N-s)}q^{s}(1-q)^{N-s}\\)\\)</li> <li>s = 0,1,2..N</li> <li>\\(N\\choose s\\) is binomial coefficient</li> <li> \\[X \\sim Bi(N,s)\\] </li> <li></li> </ul>"},{"location":"KB/Biological%20Neuron/","title":"Biological Neuron","text":""},{"location":"KB/Biological%20Neuron/#biological-neuron","title":"Biological Neuron","text":"<ul> <li>(from)</li> <li>composed of\u00a0<ul> <li>cell body</li> <li>dendrites: many branching extensions</li> <li>axon: very long extension that splits off at its tip into many branches called synaptic terminals</li> </ul> </li> <li>composed in a network (e.g. brain) by synaptic terminals of one neuron connected to dendrites of other neurons</li> <li>electrical impulses (signals) are sent from other neurons via these synapses</li> <li>if a neuron receives a sufficient number of signal from other neurons within a few milliseconds, it is exited and fires its own signals (activation)</li> <li>connectivity in a biological neural system is huge, human brain:<ul> <li>number of neurons: \\(\\approx 10^{11}\\)</li> <li>number of connections per neuron:\u00a0\\(\\approx 10^4\\)</li> </ul> </li> <li>networks are organized into hierarchical structures</li> <li>Irreplacable</li> <li>Requires constant supply of Glucose</li> </ul>"},{"location":"KB/Biomarkers/","title":"Biomarkers","text":""},{"location":"KB/Biomarkers/#biomarkers","title":"Biomarkers","text":"<ul> <li>A measurable physiological indicator of a biological state or condition.</li> </ul>"},{"location":"KB/Biopsy/","title":"Biopsy","text":""},{"location":"KB/Biopsy/#biopsy","title":"Biopsy","text":"<ul> <li>Removal of a small tissue sample for testing</li> </ul>"},{"location":"KB/Block%20Sparse%20Kernel/","title":"Block Sparse Kernel","text":""},{"location":"KB/Block%20Sparse%20Kernel/#block-sparse-kernel","title":"Block Sparse Kernel","text":"<ul> <li>For networks with block sparse weights</li> <li>Can choose amount of sparsity</li> <li>Can replace normal Dense Layers with sparse and wide or sparse and deep</li> <li></li> <li>Enables wider and deeper networks</li> <li>Only compute on non zero blocks</li> <li></li> <li>Connectivity is unaffected in the spatial dimensions</li> <li>Compute cost is only prop to number of non zero weights</li> <li>Small World graphs</li> <li>Also useful for compression</li> </ul>"},{"location":"KB/Block%20Sparse%20Kernel/#refs","title":"Refs","text":"<ul> <li>openai</li> </ul>"},{"location":"KB/BlockNeRF/","title":"BlockNeRF","text":""},{"location":"KB/BlockNeRF/#blocknerf","title":"BlockNeRF","text":"<ul> <li>Block-NeRF: Scalable Large Scene Neural View Synthesis</li> <li>variant of Neural Radiance Field</li> <li>reconstruct large-scale environments</li> <li>scaling NeRF to render city-scale scenes spanning multiple blocks, it is vital to decompose the scene into individually trained NeRFs that can be optimized independently.</li> <li>this decomposition decouples rendering time from scene size</li> <li>allows per-block updates of the environment</li> <li>data collected will necessarily have transient objects and variations in appearance</li> <li>modifying the underlying NeRF architecture to make NeRF robust to data captured over months under different environmental conditions</li> <li>appearance Embedding, learned pose refinement, and controllable exposure to each individual NeRF</li> <li>procedure for aligning appearance between adjacent NeRFs so that they can be seamlessly combined</li> <li>building an entire neighborhood in San Francisco from 2.8M images using a grid of Block-NeRFs, forming the largest neural scene representation to date</li> </ul>"},{"location":"KB/Blood%20Culture/","title":"Blood Culture","text":""},{"location":"KB/Blood%20Culture/#blood-culture","title":"Blood Culture","text":"<ul> <li>Test to reveal the existence of fungi or bacteria in the blood, possibly indicating an infection</li> </ul>"},{"location":"KB/Blood%20Lancet/","title":"Blood Lancet","text":""},{"location":"KB/Blood%20Lancet/#blood-lancet","title":"Blood Lancet","text":"<ul> <li>A double-edged blade or needle used to obtain blood samples</li> </ul>"},{"location":"KB/Blood%20Swab/","title":"Blood Swab","text":""},{"location":"KB/Blood%20Swab/#blood-swab","title":"Blood Swab","text":"<ul> <li>Taking a blood sample using a cotton-tipped stick</li> </ul>"},{"location":"KB/Blood-brain%20Barrier/","title":"Blood brain Barrier","text":""},{"location":"KB/Blood-brain%20Barrier/#blood-brain-barrier","title":"Blood-brain Barrier","text":"<ul> <li>A protective barrier that separates the brain from the blood circulating across the body. The blood-brain barrier is semipermeable, meaning it allows the passage of water as well as molecules like glucose and other amino acids that help promote neural function.</li> </ul>"},{"location":"KB/Blur%20Baseline/","title":"Blur Baseline","text":""},{"location":"KB/Blur%20Baseline/#blur-baseline","title":"Blur Baseline","text":"<ul> <li>@fongInterpretableExplanationsBlack2017</li> <li>Another baseline is called Blur baseline and uses a multi-dimensional gaussian filter (</li> <li>The idea presented by Fong and Vedaldi blurred version of the image is a domain-specific way to represent missing information and therefore be a valid baseline according to the original definition</li> </ul>"},{"location":"KB/Boltzmann%20Distribution/","title":"Boltzmann Distribution","text":""},{"location":"KB/Boltzmann%20Distribution/#boltzmann-distribution","title":"Boltzmann Distribution","text":"<ul> <li>PDF \\(\\(p(s|T)= \\frac{1}{\\int_{s}e^{-C(s)/T}ds}e^{-C(s)/T}\\)\\)</li> <li>Energy function \\(E: S \\rightarrow \\mathbb{R}^{\\geq 0}\\)</li> <li>Markov Random Field</li> </ul>"},{"location":"KB/BooksCorpus/","title":"BooksCorpus","text":""},{"location":"KB/BooksCorpus/#bookscorpus","title":"BooksCorpus","text":""},{"location":"KB/Bottom%20Up%20Parsing/","title":"Bottom Up Parsing","text":""},{"location":"KB/Bottom%20Up%20Parsing/#bottom-up-parsing","title":"Bottom Up Parsing","text":""},{"location":"KB/Bound%20morpheme/","title":"Bound morpheme","text":""},{"location":"KB/Bound%20morpheme/#bound-morpheme","title":"Bound Morpheme","text":"<ul> <li>morphemes that cannot appear as a word by itself</li> <li>e.g., +ing, +s, +ness,ly,ed</li> </ul>"},{"location":"KB/Brain%20Areas/","title":"Brain Areas","text":""},{"location":"KB/Brain%20Areas/#brain-areas","title":"Brain Areas","text":"<ul> <li>Cerebrum</li> <li>Cerebellum</li> <li>Brainstem</li> </ul>"},{"location":"KB/Brain%20Cortex/","title":"Brain Cortex","text":""},{"location":"KB/Brain%20Cortex/#brain-cortex","title":"Brain Cortex","text":"<ul> <li>Also called Cerebral Cortex</li> <li>It has a folded appearance with hills and valleys</li> <li>The nerve cell bodies color the cortex grey-brown giving it its name \u2013 gray matter</li> <li>Beneath the cortex are long nerve fibers (axons) that connect Brain Areas to each other \u2014 called white matter</li> <li></li> <li>Gyrus</li> <li>Basal Ganglia</li> <li>Divided into parts<ul> <li>Medial Prefrontal Cortex, and the Posterior Cingulate Cortex with the nearby Precuneus and Lateral Parietal Cortex **</li> </ul> </li> </ul>"},{"location":"KB/Brain%20Organoid/","title":"Brain Organoid","text":""},{"location":"KB/Brain%20Organoid/#brain-organoid","title":"Brain Organoid","text":"<ul> <li>A research model that uses pluripotent stem cells (iPSCs) to grow structures that resemble brains in some ways, but are grown in a lab dish made of neurons and other brain tissues.</li> </ul>"},{"location":"KB/Brain%20Oscillations/","title":"Brain Oscillations","text":""},{"location":"KB/Brain%20Oscillations/#brain-oscillations","title":"Brain Oscillations","text":"<ul> <li>Periodic</li> <li>Brain waves</li> <li>Delta Waves</li> <li>Theta Waves</li> <li>Alpha Waves</li> <li>Beta Waves</li> <li>Gamma Waves</li> <li>Spectrogram</li> <li></li> </ul>"},{"location":"KB/Brain-derived%20Neurotrophic%20Factor%20%28BDNF%29/","title":"Brain derived Neurotrophic Factor (BDNF)","text":""},{"location":"KB/Brain-derived%20Neurotrophic%20Factor%20%28BDNF%29/#brain-derived-neurotrophic-factor-bdnf","title":"Brain-derived Neurotrophic Factor (BDNF)","text":"<ul> <li>Sometimes referred to as \u201cbrain fertilizer,\u201d BDNF is a protein that helps promote the growth, maintenance, and survival of neurons.</li> </ul>"},{"location":"KB/BrainWave%20Coherence/","title":"BrainWave Coherence","text":""},{"location":"KB/BrainWave%20Coherence/#brainwave-coherence","title":"BrainWave Coherence","text":"<ul> <li>Correlation in the frequency domain</li> <li>Unlike synchronization, this also depends on signal amplitude</li> <li><ul> <li>coherence vs freq</li> <li>decent coherence between CZ and O1</li> <li>O1 and PZ has little coherence</li> </ul> </li> </ul>"},{"location":"KB/BrainWave%20CrossFrequency%20Coupling/","title":"BrainWave CrossFrequency Coupling","text":""},{"location":"KB/BrainWave%20CrossFrequency%20Coupling/#brainwave-crossfrequency-coupling","title":"BrainWave CrossFrequency Coupling","text":"<ul> <li>Low frequency + Superimposed High freq signal</li> <li></li> <li>-<ul> <li>Electrode with low freq + high freq</li> </ul> </li> </ul>"},{"location":"KB/BrainWave%20Synchronization/","title":"BrainWave Synchronization","text":""},{"location":"KB/BrainWave%20Synchronization/#brainwave-synchronization","title":"BrainWave Synchronization","text":"<ul> <li>Consistency of phase difference<ul> <li>If 0 then perfect</li> </ul> </li> <li></li> <li>Phase Locking Value</li> </ul>"},{"location":"KB/Brainstem/","title":"Brainstem","text":""},{"location":"KB/Brainstem/#brainstem","title":"Brainstem","text":"<ul> <li>relay center connecting the cerebrum and cerebellum to the spinal cord. It performs many automatic functions such as breathing, heart rate, body temperature, wake and sleep cycles, digestion, sneezing, coughing, vomiting, and swallowing</li> </ul>"},{"location":"KB/Branch%20Prediction/","title":"Branch Prediction","text":""},{"location":"KB/Branch%20Prediction/#branch-prediction","title":"Branch Prediction","text":"<ul> <li>avoid delays cause of control dependencies to be resolved.</li> <li>determines whether a conditional branch (jump) in the instruction flow of a program is likely to be taken or not</li> </ul>"},{"location":"KB/Broadcasting/","title":"Broadcasting","text":""},{"location":"KB/Broadcasting/#broadcasting","title":"Broadcasting","text":"<ul> <li>Expanding the shape of an operand in a matrix math operation to dimensions compatible for that operation. For instance, linear algebra requires that the two operands in a matrix addition operation must have the same dimensions. Consequently, you can't add a matrix of shape (m, n) to a vector of length n. Broadcasting enables this operation by virtually expanding the vector of length n to a matrix of shape (m,n) by replicating the same values down each column.</li> </ul>"},{"location":"KB/Brocas%20Area/","title":"Brocas Area","text":""},{"location":"KB/Brocas%20Area/#brocas-area","title":"Brocas Area","text":"<ul> <li>If this area is damaged, one may have difficulty moving the tongue or facial muscles to produce the sounds of speech. The person can still read and understand spoken language but has difficulty in speaking and writing</li> <li>Broca's aphasia</li> <li>Discovered by French physician Paul Broca in the late 19th century, this small region in the left frontal lobe has been linked to speech production.</li> </ul>"},{"location":"KB/Broden/","title":"Broden","text":""},{"location":"KB/Broden/#broden","title":"Broden","text":"<ul> <li>Broadly and Densely Labeled Dataset</li> <li>unifies several densely labeled image data sets: ADE [43], OpenSurfaces [4], Pascal-Context [19], Pascal-Part [6], and the Describable Textures Dataset [7]</li> <li>These data sets contain examples of a broad range of objects, scenes, object parts, textures, and materials in a variety of contexts</li> <li>segmented down to the pixel level except textures and scenes which are given for full-images</li> <li>every image pixel in the data set is annotated with one of the eleven common color names according to the human perceptions classified by van de Weijer</li> <li>The concept labels in Broden are normalized and merged from their original data sets so that every class corresponds to an English word</li> <li>Labels are merged based on shared synonyms, disregarding positional distinctions such as 'left' and 'top'</li> </ul>"},{"location":"KB/Bruckhaus%20-%202024%20-%20RAG%20Does%20Not%20Work%20for%20Enterprises/","title":"Bruckhaus - 2024 - RAG Does Not Work for Enterprises","text":"","tags":["llm"]},{"location":"KB/Bruckhaus%20-%202024%20-%20RAG%20Does%20Not%20Work%20for%20Enterprises/#bruckhaus-2024-rag-does-not-work-for-enterprises","title":"Bruckhaus - 2024 - RAG Does Not Work for Enterprises","text":"<ul> <li>@bruckhausRAGDoesNot2024</li> </ul>","tags":["llm"]},{"location":"KB/Bruckhaus%20-%202024%20-%20RAG%20Does%20Not%20Work%20for%20Enterprises/#intro","title":"Intro","text":"<ul> <li>implementing RAG effectively in real-world, enterprise settings poses several challenges.</li> <li>The retriever needs to efficiently search through massive, constantly-updated knowledge bases to find the most relevant information for each query [Karpukhin et al., 2020]</li> <li>The generator needs to intelligently fuse the retrieved content with its own learned knowledge to produce coherent and accurate outputs [Shao et al., 2023]</li> <li>the RAG system needs to satisfy stringent requirements around data security, privacy, interpretability, and auditability [Arrieta et al., 2020].</li> </ul>","tags":["llm"]},{"location":"KB/Bruckhaus%20-%202024%20-%20RAG%20Does%20Not%20Work%20for%20Enterprises/#enterprise-requirements-for-retrieval-augmented-generation","title":"Enterprise Requirements for Retrieval-Augmented Generation","text":"<ul> <li>include built-in access controls, anonymization techniques, and auditing mechanisms.</li> <li>intelligently blending advanced semantic search techniques with hybrid query strategies, advanced RAG solutions retrieve the most relevant and reliable information to augment the generation process</li> <li>such solutions must provide clear explanations and attributions for its outputs, enabling enterprises to trust and act on the insights with confidence.</li> <li>flexible, API-driven architecture and pre-built connectors for popular enterprise systems.</li> </ul>","tags":["llm"]},{"location":"KB/Bruckhaus%20-%202024%20-%20RAG%20Does%20Not%20Work%20for%20Enterprises/#survey-of-current-rag-approaches-and-their-limitations","title":"Survey of Current RAG Approaches and Their Limitations","text":"<ul> <li>Lack of fine-grained control over retrieval and generation processes, which is crucial for ensuring accuracy, consistency, and regulatory compliance [Martorana et al., 2022, Anderljung et al., 2023, Rahwan et al., 2023].</li> <li>Limited scalability and performance when dealing with massive, heterogeneous enterprise knowledge bases [Ahmad et al. 2019 , Nambiar et al., 2023].</li> <li>Insufficient explainability and auditability of RAG outputs, which is essential for building trust and accountability in high-stakes enterprise use cases [Eibich et al. 2024, Gao et al. 2024, Kamath &amp; Liu 2021].</li> <li>Challenges in integrating RAG capabilities into existing enterprise systems and workflows, which often have complex security, governance, and data management requirements.</li> </ul>","tags":["llm"]},{"location":"KB/Bruckhaus%20-%202024%20-%20RAG%20Does%20Not%20Work%20for%20Enterprises/#dense-vector-indexes","title":"Dense Vector Indexes","text":"","tags":["llm"]},{"location":"KB/Bucketing/","title":"Bucketing","text":""},{"location":"KB/Bucketing/#bucketing","title":"Bucketing","text":"<ul> <li>Converting a (usually continuous) feature into multiple binary features called buckets or bins, typically based on value range. For example, instead of representing temperature as a single continuous floating-point feature, you could chop ranges of temperatures into discrete bins. Given temperature data sensitive to a tenth of a degree, all temperatures between 0.0 and 15.0 degrees could be put into one bin, 15.1 to 30.0 degrees could be a second bin, and 30.1 to 50.0 degrees could be a third bin.</li> </ul>"},{"location":"KB/Building%20Ethics%20into%20Artificial%20Intelligence/","title":"Building Ethics into Artificial Intelligence","text":""},{"location":"KB/Building%20Ethics%20into%20Artificial%20Intelligence/#building-ethics-into-artificial-intelligence","title":"Building Ethics into Artificial Intelligence","text":"<ul> <li>Han Yu, Zhiqi Shen, Chunyan Miao, Cyril Leung, Victor R. Lesser, Qiang Yang</li> </ul>"},{"location":"KB/Building%20Ethics%20into%20Artificial%20Intelligence/#abstract","title":"Abstract","text":"<ul> <li>taxonomy which divides the field into four areas: 1) exploring ethical dilemmas; 2) individual ethical decision frameworks; 3) collective ethical decision frameworks; and 4) ethics in human-AI interactions</li> </ul>"},{"location":"KB/Building%20Ethics%20into%20Artificial%20Intelligence/#types","title":"Types","text":"<ul> <li>Consequentialist ethics</li> <li>Utilitarian ethics</li> <li>Deontological ethics</li> <li>Virtue ethics</li> <li>Ethical dilemmas</li> </ul>"},{"location":"KB/Building%20Ethics%20into%20Artificial%20Intelligence/#exploring-ethical-dilemmas","title":"Exploring Ethical Dilemmas","text":"<ul> <li>explore the ethical dilemmas in the target application scenarios [Anderson and Anderson, 2014]</li> <li>GenEth</li> <li>Moral Machine project</li> </ul>"},{"location":"KB/Building%20Ethics%20into%20Artificial%20Intelligence/#individual-ethical-decision-frameworks","title":"Individual Ethical Decision Frameworks","text":"<ul> <li>AI research community largely agrees that generalized frameworks are preferred over ad-hoc rules</li> <li>if updates are provided by people, some review mechanisms should be put in place to prevent abuse</li> <li>moral decision-making by humans not only involves utilitarian considerations, but also moral rules.</li> <li>Such rules often involve protected values (a.k.a. sacred values)</li> <li>MoralDM</li> <li>Belief-Desire-Intention</li> <li>blind ethical judgement</li> <li>partially informed ethical judgement</li> <li>fully informed ethical judgement</li> <li>Moral decision making frameworks for artificial intelligence</li> <li>Preferences and ethical principles in decision making</li> <li>A declarative modular framework for representing and applying ethical principles.</li> <li>A low-cost ethics shaping approach for designing reinforcement learning agents</li> <li>Even angels need the rules AI, roboethics, and the law</li> <li>Norms as a basis for governing sociotechnical systems</li> <li>Embedding ethical principles in collective decision support systems</li> <li>A voting-based system for ethical decision making</li> <li>swap-dominance</li> <li>satisfying consequentialist ethics Ethics in Human-AI Interactions Belmont Report</li> <li>[Luckin, 2017; Yu et al., 2017b]</li> <li>1) people's personal autonomy should not be violated (they should be able to maintain their free will when interacting with the technology); 2) benefits brought</li> <li>about by the technology should outweigh risks; and 3) the benefits</li> <li>and risks should be distributed fairly among the users (people should not be discriminated based on their personal backgrounds such as race, gender and religion)</li> <li>persuasion agents</li> <li>[Kang et al., 2015; Rosenfeld and Kraus, 2016]</li> <li>[Stock et al., 2016]</li> <li>large-scale study to investigate human perceptions on the ethics of persuasion by an AI agent</li> <li>trolley scenario</li> <li>authors tested three persuasive strategies: 1) appealing to the participants emotionally; 2) presenting the participants with utilitarian arguments; and 3) lying</li> <li>participants hold a strong preconceived negative attitude towards the persuasion agent, and argumentation-based and lying-based persuasion strategies work better than emotional persuasion strategies</li> <li>did not show significant variation across genders or cultures</li> <li>adoption of persuasion strategies should take into account differences in individual personality, ethical attitude and expertise in the given domain.</li> <li>Coping Theory</li> <li>Argumentation-based explainable AI</li> <li>[Fan and Toni, 2015; Langley et al., 2017] well suited to the consequentialist ethics</li> <li>depending on how the explanations are used, researchers need to strike a balance on the level of details to be included</li> <li>Full transparency may be too overwhelming if the objective is to persuade a user to follow a time-critical recommendation</li> <li>useful as a mechanism to trace the AI decision process afterwards not enough transparency may hamper users' trust in the AI</li> </ul>"},{"location":"KB/Bunq/","title":"Bunq","text":""},{"location":"KB/Bunq/#bunq","title":"Bunq","text":"<p>Q: How familiar are you with Python, SQL, AWS, and ETL processes?</p> <p>I have a Masters in Artificial Intelligence from the University of Groningen. From my previous internship, experiences, personal and freelance projects, and research papers, I have a good amount of experience with AWS, SQL, and ETL processes.</p> <p>At almost every internship, I helped build/used ETL pipelines that required SQL, AWS, or some other data storage, and I am comfortable with learning new processes that might be required for this position.</p> <p>As for Python, it is my language of choice, and I am very familiar with it. I have experience working with creating data pipelines, data analysis, and AI/ML frameworks such as PyTorch, Tensorflow, NLTK, Hugging face, sklearn, etc. I have built several open-source packages in varying domains over the past couple of years and published many analytics and AI notebooks and articles as well.</p>"},{"location":"KB/Burn-in/","title":"Burn in","text":""},{"location":"KB/Burn-in/#burn-in","title":"Burn-in","text":"<ul> <li>Burn-In is a robot testing procedure where all components of the robot are operated continuously for an extended period of time. This is done to test movement and movement programming of the robot at early stages to avoid malfunctions after deployment.</li> </ul>"},{"location":"KB/C-section/","title":"C section","text":""},{"location":"KB/C-section/#c-section","title":"C-section","text":"<ul> <li>Caesarian section, where a baby is delivered through an abdominal and uterine incision</li> </ul>"},{"location":"KB/CAM/","title":"CAM","text":""},{"location":"KB/CAM/#cam","title":"CAM","text":"<ul> <li>@zhouLearningDeepFeatures2016</li> <li>Class Activation Mapping</li> <li>Similar to Network In Network</li> <li>zeroes out the negative grads during backward pass to provide more visually appealing results</li> <li>Uses Global Average Pooling</li> <li></li> <li> \\[\\alpha_{k}^{c}= \\overbrace{\\frac{1}{Z}\\Sigma_{i}\\Sigma_{j}}^\\text{global avg pool} \\underbrace{\\frac{\\partial y^{c}}{\\partial A^{k}_{ij}}}_\\text{grads via backprop}\\] </li> <li>k is the index of the activation map in the last convolutional layer, and c is the class of interest. Alpha computed above shows the importance of feature map k for the target class c.</li> <li>Finally, we multiply each activation map by its importance score (i.e. alpha) and sum the values</li> </ul>"},{"location":"KB/CAM/#chatgpt","title":"ChatGPT","text":"<ul> <li>The paper, \"Learning Deep Features for Discriminative Localization\" by Zhou et al. (2016) introduces the concept of Class Activation Mapping (CAM) as a way to visualize which regions of an image are most important for a given classification task. CAM is a technique for generating heatmaps that highlight the regions in an image that are most important for a specific classification. The authors propose to use global average pooling (GAP) in the final convolutional layer to generate a feature map, followed by a linear combination of the feature map and the class weight vector to generate a single class activation map.</li> <li>The authors apply CAM to the ResNet architecture and show that it outperforms the traditional fully-connected layer approach in terms of localization performance. They test the CAM on the image classification task using the ILSVRC-2012 dataset. The authors showed that by using CAM, they could identify the specific regions of an image that were important for a given classification, rather than just a \"black box\" decision made by the model. The authors also demonstrate how CAM can be used for fine-grained recognition, where the model is trained to identify sub-categories within a larger class.</li> <li>Additionally, the authors also show that the CAM can be used to improve the interpretability of deep neural networks by providing a visual representation of the model's decision-making process. They also use CAM to identify misclassifications and analyze the model's decision-making process. The authors test CAM on other architectures such as VGG and GoogleNet and show that it can be applied.</li> <li>The authors also use CAM for multi-label classification and show that it can identify the regions in an image that are relevant to multiple labels. They also use CAM for action classification in video and show that it can identify the regions of video frames that are important for a given action. They use CAM for object detection and show that it can be used to identify the regions of an image that contain an object of interest.</li> <li>The authors use CAM for fine-tuning a pre-trained model on a new dataset and show that it can be used to improve the performance of the model on the new dataset. They also use CAM for unsupervised feature learning and show that it can be used to learn features that are useful for a wide range of tasks. They use CAM for zero-shot learning and show that it can be used to identify the regions of an image that are relevant to a class that the model has never seen before.</li> <li>Finally, the authors use CAM for domain adaptation and show that it can be used to identify the regions of an image that are important for a specific task, even when the model has been trained on a different dataset. They also use CAM for weakly-supervised object localization and show that it can be used to identify the regions of an image that contain an object of interest, even when only image-level labels are available. They use CAM for multi-modal learning and show that it can be used to identify the regions of an image that are important for a given task, even when multiple modalities (e.g. image and text) are available.</li> <li>The authors conclude that the CAM is a powerful technique for visualizing the decision-making process of a deep neural network and can be used to improve the interpretability, performance, and robustness of deep models.</li> </ul>"},{"location":"KB/CBOW/","title":"CBOW","text":""},{"location":"KB/CBOW/#cbow","title":"CBOW","text":"<ul> <li>Continous implementation of Bag of words</li> <li>tries to predict the current target word (the center word) based on the source context words (surrounding words)</li> <li>\u201cthe quick brown fox jumps over the lazy dog\u201d, this can be pairs of\u00a0(context_window, target_word)\u00a0where if we consider a context window of size 2, we have examples like\u00a0([quick, fox], brown), ([the, brown], quick), ([the, dog], lazy)\u00a0and so on</li> <li>context window</li> <li></li> <li>several times faster to train than the skip-gram, slightly better accuracy for the frequent words.</li> <li>CBOW is prone to overfit frequent words because they appear several time along with the same context.</li> <li>tends to find the probability of a word occurring in a context</li> <li>it generalizes over all the different contexts in which a word can be used</li> <li>also a 1-hidden-layer neural network</li> <li>The synthetic training task now uses the average of multiple input context words, rather than a single word as in skip-gram, to predict the center word.</li> <li>Again, the projection weights that turn one-hot words into averageable vectors, of the same width as the hidden layer, are interpreted as the word embeddings.</li> </ul>"},{"location":"KB/CDF/","title":"CDF","text":""},{"location":"KB/CDF/#cdf","title":"CDF","text":"<ul> <li>get cumulative density function \\(\\varphi : \\mathbb{R} \\rightarrow [0,1]\\)</li> </ul>"},{"location":"KB/CIFAR/","title":"CIFAR","text":""},{"location":"KB/CIFAR/#cifar","title":"CIFAR","text":"<ul> <li>60'000 images</li> <li>10 classes with 6'000 images</li> <li>image size: 32x32x3</li> <li>50'000 training, 10'000 testing</li> </ul>"},{"location":"KB/CLIP/","title":"CLIP","text":""},{"location":"KB/CLIP/#clip","title":"CLIP","text":"<ul> <li>Learning Transferable Visual Models from Natural Language Supervision</li> <li>introduces CLIP, a pre-training task which efficiently learns visual concepts from natural language supervision</li> <li>performs language-guided image generation</li> <li>uses vision and language encoders trained in isolation and uses a contrastive loss to bring similar image-text pairs closer, while pulling apart dissimilar pairs as a part of pretaining</li> <li>can be applied to any visual classification benchmark by simply providing the names of the visual categories to be recognized, similar to the \u201czero-shot\u201d capabilities of GPT and GPT3</li> <li>pre-trains an image encoder and a text encoder to predict which images were paired with which texts in our dataset</li> <li>zero-shot classifier</li> <li>they convert all of a dataset\u2019s classes into captions such as \u201ca photo of a dog\u201d and predict the class of the caption CLIP estimates best pairs with a given image</li> </ul> <p>toc: true title: CLIP categories: ['architecture']</p>"},{"location":"KB/CLIP/#clip_1","title":"CLIP","text":"<ul> <li>is a neural network trained on a variety of (image, text) pairs</li> <li>Using CLIP, that can be instructed in natural language to predict the most relevant text snippet, given an image, the model has recently merged as a successful representation learner for images</li> <li>Concretely, CLIP embeddings have several desirable properties</li> <li>they are robust to image distribution shift, have impressive zero-shot capabilities and have been fine-tuned to achieve state-of-theart results</li> <li>the CLIP image embedding decoder module is combined with a prior model, which generates possible CLIP image embeddings from a given text caption</li> </ul>"},{"location":"KB/COCO/","title":"COCO","text":""},{"location":"KB/COCO/#coco","title":"COCO","text":""},{"location":"KB/CRISPR%20%28clustered%20Regularly-interspaced%20Short%20Palindromic%20repeats%29/","title":"CRISPR (clustered Regularly interspaced Short Palindromic repeats)","text":""},{"location":"KB/CRISPR%20%28clustered%20Regularly-interspaced%20Short%20Palindromic%20repeats%29/#crispr-clustered-regularly-interspaced-short-palindromic-repeats","title":"CRISPR (clustered Regularly-interspaced Short Palindromic repeats)","text":"<ul> <li>A relatively precise and reliable DNA-editing technique.</li> </ul>"},{"location":"KB/CTC/","title":"CTC","text":""},{"location":"KB/CTC/#ctc","title":"CTC","text":"<ul> <li>Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks</li> <li>Many real-world sequence learning tasks require the prediction of sequences of labels from noisy, unsegmented input data</li> <li>Recurrent neural networks (RNNs) are powerful sequence learners that would seem well suited to such task</li> <li>hey require pre-segmented training data, and post-processing to transform their outputs into label sequences, their applicability has so far been limited</li> <li>temporal classification</li> <li>label unsegmented sequences directly</li> <li>probabilistic principles</li> <li>TIMIT speech corpus</li> </ul>"},{"location":"KB/CUB-200-2011%204/","title":"CUB-200-2011","text":""},{"location":"KB/CUB-200-2011%204/#cub-200-2011","title":"CUB-200-2011","text":"<ul> <li>Caltech-UCSD Birds 200 (CUB-200) is a dataset of images of birds, with 200 different species of birds and 11,788 images in total.</li> </ul>"},{"location":"KB/CUB-200-2011/","title":"CUB-200-2011","text":""},{"location":"KB/CUB-200-2011/#cub-200-2011","title":"CUB-200-2011","text":"<ul> <li>Caltech-UCSD Birds 200 (CUB-200) is a dataset of images of birds, with 200 different species of birds and 11,788 images in total.</li> </ul>"},{"location":"KB/Cache%20Coherence/","title":"Cache Coherence","text":""},{"location":"KB/Cache%20Coherence/#cache-coherence","title":"Cache Coherence","text":"<ul> <li>Individual CPU caches or memories can become out of synch with each other</li> <li>if one processor updates a location in shared memory, all the other processors know about the update</li> </ul>"},{"location":"KB/Calibration%20Layer/","title":"Calibration Layer","text":""},{"location":"KB/Calibration%20Layer/#calibration-layer","title":"Calibration Layer","text":"<ul> <li>A post-prediction adjustment, typically to account for prediction bias. The adjusted predictions and probabilities should match the distribution of an observed set of labels.</li> </ul>"},{"location":"KB/Candidate%20Sampling/","title":"Candidate Sampling","text":""},{"location":"KB/Candidate%20Sampling/#candidate-sampling","title":"Candidate Sampling","text":"<ul> <li>A training-time optimization in which a probability is calculated for all the positive labels, using, for example, softmax, but only for a random sample of negative labels. For example, if we have an example labeled beagle and dog candidate sampling computes the predicted probabilities and corresponding loss terms for the beagle and dog class outputs in addition to a random subset of the remaining classes (cat, lollipop, fence). The idea is that the negative classes can learn from less frequent negative reinforcement as long as positive classes always get proper positive reinforcement, and this is indeed observed empirically. The motivation for candidate sampling is a computational efficiency win from not computing predictions for all negatives.</li> </ul>"},{"location":"KB/Capacitance/","title":"Capacitance","text":""},{"location":"KB/Capacitance/#capacitance","title":"Capacitance","text":"<ul> <li>Charge stored/Potential Difference</li> <li> \\[C= Q/V\\] </li> </ul>"},{"location":"KB/Capsule%20Layer/","title":"Capsule Layer","text":""},{"location":"KB/Capsule%20Layer/#capsule-layer","title":"Capsule Layer","text":"<ul> <li>Each capsule is a group of neurons that is sensitive to a specific feature of the input image</li> <li></li> <li></li> </ul>"},{"location":"KB/Capsule%20Network/","title":"Capsule Network","text":""},{"location":"KB/Capsule%20Network/#capsule-network","title":"Capsule Network","text":"<ul> <li>replace traditional convolutional and pooling layers with a more biologically inspired architecture that better captures the\u00a0spatial relationships between objects in an image</li> <li>idea that the human visual system is composed of a\u00a0hierarchy of \u201ccapsules\u201d\u00a0that process visual information at different levels of abstraction. </li> <li>Each capsule comprises a\u00a0group of neurons\u00a0sensitive to\u00a0specific features\u00a0of an image, such as the presence of an edge or a particular shape. </li> <li>These features are then combined and passed up the hierarchy to\u00a0higher-level capsules, which extract more abstract concepts such as the identity of an object or the presence of a face.</li> <li>Capsule Networks overcome the problem of translational invariance caused by CNNs.</li> <li>Capsule Networks are able to capture better spatial relationship.\u00a0</li> <li>Capsule Networks uses better downsampling methods which do not cause loss of information seen in CNNs.</li> <li>Capsule Network perform much better than CNNs but are more computationally epensive.</li> </ul>"},{"location":"KB/Capsule%20Network/#drawbacks-of-pooling-layers","title":"Drawbacks of pooling layers","text":"<ul> <li>pooling layers, which\u00a0down-sample\u00a0the input image and can lead to the\u00a0loss of important information\u00a0about the spatial relationships between objects in the image. </li> <li>Capsule networks aim to overcome this limitation by using a different down-sampling mechanism that preserves more spatial information.</li> <li>Capsule Layer</li> <li>Primary Capsule</li> <li>Higher Layer Capsule</li> </ul>"},{"location":"KB/Capsule%20Network/#loss","title":"Loss","text":"<ul> <li>Max Margin Loss </li> <li>Reconstruction loss</li> </ul>"},{"location":"KB/Capsule%20Network/#pros","title":"Pros","text":"<ul> <li>Capsule networks are more robust to image distortions and translations than traditional CNNs</li> <li>They can maintain the spatial relationships between objects in an image</li> <li>They can handle partially obscured objects better</li> <li>They can be used for a variety of tasks, including object recognition and segmentation</li> </ul>"},{"location":"KB/Capsule%20Network/#cons","title":"Cons","text":"<ul> <li>Capsule networks are more complex and computationally expensive than traditional CNNs</li> <li>They are a relatively new architecture, and there is still ongoing research to improve their performance and computational efficiency.</li> </ul>"},{"location":"KB/Capture%20bias/","title":"Capture bias","text":""},{"location":"KB/Capture%20bias/#capture-bias","title":"Capture Bias","text":"<ul> <li>photographers tending to take pictures of objects in similar ways</li> <li>Searching for \"mug\" on Google Image Search will reveal another kind of capture bias: almost all the mugs has a right-facing handle</li> <li>Beyond better data sampling strategies, one way to deal with this is to perform various data transformations to reduce this bias</li> </ul>"},{"location":"KB/Cardinality%20Principle/","title":"Cardinality Principle","text":""},{"location":"KB/Cardinality%20Principle/#cardinality-principle","title":"Cardinality Principle","text":"<ul> <li>how each step in the counting sequence (1,2,3,4,5,6\u2026.) means an increase of one individual</li> </ul>"},{"location":"KB/Carousel/","title":"Carousel","text":""},{"location":"KB/Carousel/#carousel","title":"Carousel","text":"<ul> <li>A rotating platform that delivers objects to a robot and serves as an object queuing system. This carousel delivers the objects, or work pieces, to the loading/unloading station of the robot.</li> </ul>"},{"location":"KB/Case%20Grammar/","title":"Case Grammar","text":""},{"location":"KB/Case%20Grammar/#case-grammar","title":"Case Grammar","text":"<ul> <li>The structure that is built by the parser contains some semantic information, although further interpretation may also be necessary</li> </ul>"},{"location":"KB/Causability/","title":"Causability","text":""},{"location":"KB/Causability/#causability","title":"Causability","text":"<ul> <li>measures how exact an interpretable model is in imitating the behavior of a black box. fidelity</li> <li>It is measured in terms of the accuracy score, but with respect to the outcome of the black box, similarly to the model accuracy.</li> </ul>"},{"location":"KB/Causal%201D%20Conv/","title":"Causal 1D Conv","text":""},{"location":"KB/Causal%201D%20Conv/#causal-1d-conv","title":"Causal 1D Conv","text":"<ul> <li>Only past info used for prediction</li> <li>Conv works in both directions and can leak future information into predictions</li> </ul>"},{"location":"KB/Causal%20Dilated%20Conv/","title":"Causal Dilated Conv","text":""},{"location":"KB/Causal%20Dilated%20Conv/#causal-dilated-conv","title":"Causal Dilated Conv","text":"<ul> <li>Receptive field is how much of the input sequence is needed for one prediction</li> </ul>"},{"location":"KB/Causal%20Language%20Model/","title":"Causal Language Model","text":""},{"location":"KB/Causal%20Language%20Model/#causal-language-model","title":"Causal Language Model","text":"<ul> <li>Unlike Masked Language Modeling, this is uni-directional.</li> <li>Can consider words to its left</li> <li>Better for generating text</li> </ul>"},{"location":"KB/Causal%20Systems/","title":"Causal Systems","text":""},{"location":"KB/Causal%20Systems/#causal-systems","title":"Causal Systems","text":"<ul> <li>Does not depend on future input</li> <li>Has memory if current input not fully determined by previous one but influenced by earlier inputs</li> <li>TIme Series</li> </ul>"},{"location":"KB/Causality/","title":"Causality","text":""},{"location":"KB/Causality/#causality","title":"Causality","text":"<ul> <li>An understandable explanation must be created by a machine in a given time (e.g., one hour or one day) and can be comprehended by a user, who need not to be an expert, but has an educational background</li> <li>The user keeps asking a finite number of questions of the machine until he/she can no longer ask why or how because he/she has a satisfactory answer; we say he/she has comprehended.</li> <li>This is the relationship between cause and effect; it is not a synonym for causability</li> <li>Causability is about measuring and ensuring the quality of an explanation and refers to a human model</li> <li>causality requires a wide frame of prior knowledge to prove that observed effects are causal</li> <li>A ML model only discovers correlations among the data it learns from, and therefore might not suffice for unveiling a cause-effect relationship.</li> <li>However, causation involves correlation, so an explainable ML model could validate the results provided by causality inference techniques, or provide a first intuition</li> </ul>"},{"location":"KB/CenterNet/","title":"CenterNet","text":"<p>toc: true title: CenterNet</p> <p>categories: ['temp']</p>"},{"location":"KB/CenterNet/#centernet","title":"CenterNet","text":"<ul> <li>paper</li> <li>center point-based object detection approach</li> <li>end-to-end differentiable</li> <li>bounding box based detectors</li> <li>Anchorless</li> <li>keypoint estimation networks to find center points   id:: 62a89b04-c7bf-4205-9695-39da04c2aafb</li> <li>Linear Regression to all other properties   id:: 62a89d01-53af-46f6-82d4-362fab069b46</li> <li>COCO</li> <li>Single stage   id:: 62a89d42-312d-4f3d-8235-c54a9dfafadf</li> </ul>"},{"location":"KB/Central%20Limit%20Theorem/","title":"Central Limit Theorem","text":""},{"location":"KB/Central%20Limit%20Theorem/#central-limit-theorem","title":"Central Limit Theorem","text":"<ul> <li>When random effects of many independant small sized causes sum up to large scale observable effects : one gets the Normal Distribution</li> <li>Let \\((X_{i})_{i\\in N}\\) is a seq of independant, real valued, [(X_{i}- EX_{i}%20=%20E%5B%5BX_%7Bi%7D-%20E%5BX_%7Bi%7D) \\(P_{S_{n}}\\) of standardized sum variables converge weakly to \\(\\mathscr{N}(0,1|[Square Integrable]\\) . (\\(S_{n}= \\frac{\\Sigma_{i= 1}^{n}(X_{i}- E[X_{i}])}{\\sigma(\\Sigma^{n}_{i=1}X_{i})}\\)\\)<ul> <li>Converge weakly : \\(\\(lim_{n\\rightarrow\\infty}\\int f(x)P_{n}(dx) = \\int f(x)P(dx)\\)\\) for all \\(f: \\mathbb{R} \\rightarrow \\mathbb{R}\\)</li> <li>Lebesgue Integrals</li> </ul> </li> </ul>"},{"location":"KB/Central%20Limit%20Theorem/#x_i-are-identically-distributed","title":"\\(X_{i}\\) Are Identically Distributed","text":"<ul> <li>Regardless of shape of each \\(X_{i}\\), distribution of normalized sum converges to \\(\\mathscr{N}(0,1)\\)</li> <li>Uniformly bounded</li> <li>None of the \\(X_{i}\\) dominates the other \"washing out\"</li> </ul>"},{"location":"KB/Central%20Nervous%20System/","title":"Central Nervous System","text":""},{"location":"KB/Central%20Nervous%20System/#central-nervous-system","title":"Central Nervous System","text":"<ul> <li>brain + Spinal Cord</li> </ul>"},{"location":"KB/Central%20Sulcus/","title":"Central Sulcus","text":""},{"location":"KB/Central%20Sulcus/#central-sulcus","title":"Central Sulcus","text":"<ul> <li>The primary groove in the brain\u2019s cerebrum, which separates the frontal lobe in the front of the brain from the parietal and occipital lobes in the rear of the brain.</li> </ul>"},{"location":"KB/Centrifugal%20Force/","title":"Centrifugal Force","text":""},{"location":"KB/Centrifugal%20Force/#centrifugal-force","title":"Centrifugal Force","text":"<ul> <li>When a body rotates about an axis other than one at it's center of mass, it exerts an outward radial force called centrifugal force upon the axis, which restrains it from moving in a straight tangential line. To offset this force, the robot must exert an opposing torque at the joint of rotation.</li> </ul>"},{"location":"KB/Centripetal%20Force/","title":"Centripetal Force","text":""},{"location":"KB/Centripetal%20Force/#centripetal-force","title":"Centripetal Force","text":"<ul> <li>centripetal force =\u00a0mass x speed2\u00a0  radius of path</li> <li>\\(\\(F_{C}= \\frac{mv^{2}}{r}\\)\\) </li> </ul>"},{"location":"KB/Centroid/","title":"Centroid","text":""},{"location":"KB/Centroid/#centroid","title":"Centroid","text":"<ul> <li>The center of a cluster as determined by a k-means or k-median algorithm. For instance, if k is 3, then the k-means or k-median algorithm finds 3 centroids.</li> </ul>"},{"location":"KB/Cerebellar%20Artery/","title":"Cerebellar Artery","text":""},{"location":"KB/Cerebellar%20Artery/#cerebellar-artery","title":"Cerebellar Artery","text":"<ul> <li>The major blood vessel providing oxygenated blood to the cerebellum.</li> </ul>"},{"location":"KB/Cerebellum/","title":"Cerebellum","text":""},{"location":"KB/Cerebellum/#cerebellum","title":"Cerebellum","text":"<ul> <li>Its function is to coordinate muscle movements, maintain posture, and balance</li> <li>relays information to the Basal Ganglia.</li> <li>It stores automatic learned memories like tying a shoe, playing an instrument, or riding a bike.</li> </ul>"},{"location":"KB/Cerebral%20Palsy/","title":"Cerebral Palsy","text":""},{"location":"KB/Cerebral%20Palsy/#cerebral-palsy","title":"Cerebral Palsy","text":"<ul> <li>A developmental disorder resulting from damage to the brain before or during birth, usually characterized by impaired muscle coordination and body movements, but can also include impaired cognition and social behavior.</li> </ul>"},{"location":"KB/Cerebrospinal%20Fluid%20%28CSF%29/","title":"Cerebrospinal Fluid (CSF)","text":""},{"location":"KB/Cerebrospinal%20Fluid%20%28CSF%29/#cerebrospinal-fluid-csf","title":"Cerebrospinal Fluid (CSF)","text":"<ul> <li>The clear, colorless liquid found surrounding the brain and spinal cord. This fluid can be analyzed to detect diseases.</li> </ul>"},{"location":"KB/Cerebrum/","title":"Cerebrum","text":""},{"location":"KB/Cerebrum/#cerebrum","title":"Cerebrum","text":"<ul> <li>largest part of the brain</li> <li>performs higher functions like interpreting touch, vision and hearing, as well as speech, reasoning, emotions, learning, and fine control of movement</li> <li>Divided by Corpus callosum</li> <li>Surface is called the Brain Cortex</li> <li></li> <li>Frontal lobe</li> <li>Parietal lobe</li> <li>Occipital lobe</li> <li>Temporal lobe</li> </ul>"},{"location":"KB/Chain%20of%20Thought/","title":"Chain of Thought","text":""},{"location":"KB/Chain%20of%20Thought/#chain-of-thought","title":"Chain of Thought","text":"<ul> <li>Chain of Thought Prompting Elicits Reasoning in Large Language Models</li> <li>ability of language models to generate a coherent chain of thought</li> <li>series of short sentences that mimic the reasoning process a person might have when responding to a question</li> <li>the more complex the task of interest is (in the sense of requiring multi-step reasoning approach), the bigger the boost from the chain of thought prompting!</li> <li>chain of thought processing is an emergent property of model scale that can be induced via prompting and can enable sufficiently large language models to better perform reasoning tasks that otherwise have flat scaling curves.</li> </ul>"},{"location":"KB/Challenges%20of%20Words-and-rules/","title":"Challenges of Words-and-rules","text":""},{"location":"KB/Challenges%20of%20Words-and-rules/#challenges-of-words-and-rules","title":"Challenges of Words-and-rules","text":"<ul> <li>Words-and-Rules fits a lot of the data, but is vague on<ul> <li>Exactly what innate structures are available to a child learner</li> <li>Exactly how learning proceeds</li> </ul> </li> </ul>"},{"location":"KB/Change%20Blindness/","title":"Change Blindness","text":""},{"location":"KB/Change%20Blindness/#change-blindness","title":"Change Blindness","text":"<ul> <li>Difficulty detecting changes in separated scenes even after careful inspection</li> <li>Once found viewers agree that it was trivial</li> <li>Not due to limited visual acuity but inappropriate attentional guidance</li> <li>Temporal separation (instead of spatial)</li> <li>sudden changes within a static scene are easily perceived (cf. preattentiveness of motion)</li> <li>Change blindness also in animations if temporal separation spans multiple scenes</li> <li>A scene that should be the same but differs between cuts is known as continuity error</li> </ul>"},{"location":"KB/Change%20in%20Gravitational%20Potential%20Energy/","title":"Change in Gravitational Potential Energy","text":""},{"location":"KB/Change%20in%20Gravitational%20Potential%20Energy/#change-in-gravitational-potential-energy","title":"Change in Gravitational Potential Energy","text":"<ul> <li>mass x gravitational field strenth x\u00a0 difference in height</li> <li> \\[DGPE = mgDh\\] </li> </ul>"},{"location":"KB/Character-set%20dependence/","title":"Character-set dependence","text":""},{"location":"KB/Character-set%20dependence/#character-set-dependence","title":"Character-set Dependence","text":"<ul> <li>ASCII</li> <li>8 bit character set</li> <li>2 byte character set</li> <li>Unicode 5.0</li> </ul>"},{"location":"KB/Characteristics%20of%20Visual%20Variables/","title":"Characteristics of Visual Variables","text":""},{"location":"KB/Characteristics%20of%20Visual%20Variables/#characteristics-of-visual-variables","title":"Characteristics of Visual Variables","text":"<ul> <li>Visual Selective</li> <li>Visual Associative</li> <li>Visual Ordered</li> <li>Visual Quantitative</li> <li>Visual Length </li> </ul>"},{"location":"KB/Charge/","title":"Charge","text":""},{"location":"KB/Charge/#charge","title":"Charge","text":"<ul> <li>Current x time</li> <li> \\[DQ = IDt\\] </li> </ul>"},{"location":"KB/Chat%20GPT%20is%20Not%20All%20You%20Need/","title":"chatgptisnotallyouneed","text":""},{"location":"KB/Chat%20GPT%20is%20Not%20All%20You%20Need/#chatgptisnotallyouneed","title":"Chatgptisnotallyouneed","text":"<ul> <li> <p>@gozalo-brizuelaChatGPTNotAll2023</p> </li> <li> <p>DALL\u00b7E 2</p> </li> <li> <p>CLIP</p> </li> <li> <p>Stable Difusion</p> </li> <li> <p>Muse</p> </li> <li> <p>Dreamfusion</p> </li> <li> <p>Magic3D</p> </li> <li> <p>Flamingo</p> </li> <li> <p>VisualGPT</p> </li> <li> <p>Phenaki</p> </li> <li> <p>Soundify</p> </li> <li> <p>AudioLM</p> </li> <li> <p>Jukebox</p> </li> <li> <p>Whisper</p> </li> <li> <p>ChatGPT</p> </li> <li> <p>LaMDA</p> </li> <li> <p>PEER</p> </li> <li> <p>Meta AI Speech from Brain</p> </li> <li> <p>Codex</p> </li> <li> <p>Alphacode</p> </li> <li> <p>Galactica</p> </li> <li> <p>Minerva</p> </li> <li> <p>Imagen</p> </li> </ul>"},{"location":"KB/ChatGPT/","title":"ChatGPT","text":""},{"location":"KB/ChatGPT/#chatgpt","title":"ChatGPT","text":"<ul> <li>interacts in a conversational way</li> <li>the model answers follow-up questions, challenges incorrect premises and reject inappropriate requests</li> <li>Reinforcement Learning for Human Feedback</li> <li>an initial model is trained using supervised fine-tuning: human AI trainers would provide conversations in which they played both sides, the user and an AI assistant</li> <li>those people would be given the model-written responses to help them compose their response</li> <li>This dataset was mixed to that of InstructGPT [3], which was transformed into a dialogue format</li> </ul>"},{"location":"KB/Chebyshev%20Distance/","title":"Chebyshev Distance","text":""},{"location":"KB/Chebyshev%20Distance/#chebyshev-distance","title":"Chebyshev Distance","text":"<ul> <li> \\[D(x,y) = max_{i}(|x_{i}-y_{i}|)\\] </li> <li>greatest of difference between two vectors along any coordinate dimension</li> <li>simply the maximum distance along one axis.</li> <li>Chessboard distance since the minimum number of moves needed by a king to go from one square to another is equal to Chebyshev distance</li> <li>can be used to extract the minimum number of moves needed to go from one square to another</li> <li>warehouse logistics as it closely resembles the time an overhead crane takes to move an object</li> </ul>"},{"location":"KB/CheckList/","title":"CheckList","text":""},{"location":"KB/CheckList/#checklist","title":"CheckList","text":"<ul> <li>Beyond Accuracy: Behavioral Testing of NLP Models with CheckList</li> <li>ML systems can run to completion without throwing any errors (indicating functional correctness) but can still produce incorrect outputs (indicating behavioral issues)</li> <li>CheckList</li> <li>model-agnostic and task-agnostic methodology for testing NLP models inspired by principles of behavioral testing</li> <li>matrix of general linguistic capabilities and test types that facilitate comprehensive test ideation</li> <li>Minimum Functionality Test (MFT): A Minimum Functionality Test (MFT) uses simple examples to make sure the model can perform a specific task well. For example, they might want to test the performance of a sentiment model when dealing with negations</li> <li>Invariance Test: Besides testing the functionality of a model, they might also want to test if the model prediction stays the same when trivial parts of inputs are slightly perturbed. These tests are called Invariance Tests (IV)</li> <li>Directional Expectation Test: In the Invariance Test, they expect the outputs after the perturbation to be the same. However, sometimes they might expect the output after perturbation to change. That is when Directional Expectation Tests comes in handy</li> </ul>"},{"location":"KB/Chi%20Squared%20Distance/","title":"Chi Squared Distance","text":""},{"location":"KB/Chi%20Squared%20Distance/#chi-squared-distance","title":"Chi Squared Distance","text":"<ul> <li> \\[d= \\Sigma_{i}\\frac{p_{i}-q_{i}}{p_{i}+q_{i}}\\] </li> </ul>"},{"location":"KB/Chimera/","title":"Chimera","text":""},{"location":"KB/Chimera/#chimera","title":"Chimera","text":"<ul> <li>A single organism with cells from more than one distinct genotype.</li> </ul>"},{"location":"KB/Chinchilla/","title":"Chinchilla","text":""},{"location":"KB/Chinchilla/#chinchilla","title":"Chinchilla","text":"<ul> <li>Training Compute-Optimal Large Language Models</li> <li>given a 10x increase in computational budget, model size should increase 5.5x, and the number of tokens should only increase 1.8x</li> <li>model and data size should increase in accordance</li> <li>collecting high-quality datasets will play a key role in further scaling of LLMs</li> <li>optimal model size and number of tokens for training a transformer language model under a given compute budget</li> <li>By training over 400 language models ranging from 70 million to over 16 billion parameters on 5 to 500 billion tokens, they find that for compute-optimal training, the model size and the number of training tokens should be scaled equally: for every doubling of model size the number of training tokens should also be doubled</li> <li>significantly outperforms Gopher (280B), GPT-3 (175B), Jurassic-1 (178B), and Megatron-Turing NLG (530B) on a large range of downstream evaluation tasks</li> <li>ubstantially less compute for fine-tuning and inference, greatly facilitating downstream usage</li> <li>MMLU</li> </ul>"},{"location":"KB/Chronic%20Encephalopathy%20Syndrome%20%28CES%29/","title":"Chronic Encephalopathy Syndrome (CES)","text":""},{"location":"KB/Chronic%20Encephalopathy%20Syndrome%20%28CES%29/#chronic-encephalopathy-syndrome-ces","title":"Chronic Encephalopathy Syndrome (CES)","text":"<ul> <li>Symptoms, including memory issues, depression, and impulsive behavior, that manifest themselves after repeated brain traumas. Over time, CES can result in a diagnosis of chronic traumatic encephalopathy (CTE)).md).</li> </ul>"},{"location":"KB/Chronic%20Traumatic%20Encephalopathy%20%28CTE%29/","title":"Chronic Traumatic Encephalopathy (CTE)","text":""},{"location":"KB/Chronic%20Traumatic%20Encephalopathy%20%28CTE%29/#chronic-traumatic-encephalopathy-cte","title":"Chronic Traumatic Encephalopathy (CTE)","text":"<ul> <li>Once known as dementia pugilistica and thought to be confined largely to former boxers, this neurodegenerative disease, with symptoms including impulsivity, memory problems, and depression, affects the brains of individuals who have suffered repeated concussions and traumatic brain injuries.</li> </ul>"},{"location":"KB/Chronic/","title":"Chronic","text":""},{"location":"KB/Chronic/#chronic","title":"Chronic","text":"<ul> <li>Describes a condition that is persistent or recurring</li> </ul>"},{"location":"KB/Circular%20Motion%20Type/","title":"Circular Motion Type","text":""},{"location":"KB/Circular%20Motion%20Type/#circular-motion-type","title":"Circular Motion Type","text":"<ul> <li>A calculated path that the robot executes, and is circular in shape.</li> </ul>"},{"location":"KB/Circumfix/","title":"Circumfix","text":""},{"location":"KB/Circumfix/#circumfix","title":"Circumfix","text":"<ul> <li>precede and follow the stem</li> </ul>"},{"location":"KB/Cityscapes/","title":"Cityscapes","text":""},{"location":"KB/Cityscapes/#cityscapes","title":"Cityscapes","text":""},{"location":"KB/Clamp/","title":"Clamp","text":""},{"location":"KB/Clamp/#clamp","title":"Clamp","text":"<ul> <li>An end-effector which serves as a pneumatic hand that controls the grasping and releasing of an object. Tactile, and feed-back force sensors are used to manage the applied force to the object by the clamp.</li> </ul>"},{"location":"KB/Clamping/","title":"Clamping","text":""},{"location":"KB/Clamping/#clamping","title":"Clamping","text":"<ul> <li>The maximum permissible force acting on a body region, resulting from a robot collision where the period of contact results in a plastic deformation of a person\u2019s soft tissue.</li> </ul>"},{"location":"KB/Class%20Conditional%20distribution/","title":"Class Conditional Distribution","text":""},{"location":"KB/Class%20Conditional%20distribution/#class-conditional-distribution","title":"Class Conditional Distribution","text":"<ul> <li>\\(f_{i}\\) is the PDF for \\(P_{X|Y=c_{i}}\\)</li> </ul>"},{"location":"KB/Class%20Size/","title":"Class Size","text":""},{"location":"KB/Class%20Size/#class-size","title":"Class Size","text":"<ul> <li>Class inclusion seq : Set of candidate models with increasing flexibility</li> <li> \\[\\mathcal{H}_{1} \\subset \\mathcal{H}_{2} \\subset, \u2026, \\subset \\mathcal{H}_{l} \\] </li> </ul>"},{"location":"KB/Classification%20Ray%20Casting/","title":"Classification Ray Casting","text":""},{"location":"KB/Classification%20Ray%20Casting/#classification-ray-casting","title":"Classification Ray Casting","text":"<ul> <li>Transfer Function</li> <li>Pre Classification</li> <li>Post Classification</li> </ul>"},{"location":"KB/Classifier%20Gradients/","title":"Classifier Gradients","text":""},{"location":"KB/Classifier%20Gradients/#classifier-gradients","title":"Classifier Gradients","text":"<ul> <li>For example, if we want to add sunglasses to an image of a face, we can used a trained classifier that identifies if a personal has that feature.</li> <li>To do this, we can take a batch of noise vector Z that goes through the generator.</li> <li>We then pass this image through a classifier, in this case a sunglasses classifier, which will tell us if the output has that feature.</li> <li>We the use this information to modify the Z vectors, without modifying the weights of the generator at all.</li> <li>To do so, we modify the Z vectors by moving in the direction of the gradient with the costs that will penalize the model for images classified as not having sunglasses. </li> <li>We then repeat this process until the images are classified with the desired feature.</li> <li>The downside with this method is that we need a pre-trained classifier that can detect the desired feature, which may not always be readily available.</li> </ul>"},{"location":"KB/Classifying%20a%20specific%20image%20region%20using%20convolutional%20nets%20with%20an%20ROI%20mask%20as%20input/","title":"Classifying a specific image region using convolutional nets with an ROI mask as input","text":""},{"location":"KB/Classifying%20a%20specific%20image%20region%20using%20convolutional%20nets%20with%20an%20ROI%20mask%20as%20input/#classifying-a-specific-image-region-using-convolutional-nets-with-an-roi-mask-as-input","title":"Classifying a Specific Image Region Using Convolutional Nets with an ROI Mask as Input","text":"<ul> <li>Eppel, Sagi. \u201cClassifying a Specific Image Region Using Convolutional Nets with an ROI Mask as Input,\u201d n.d., 8.</li> </ul>"},{"location":"KB/Classifying%20a%20specific%20image%20region%20using%20convolutional%20nets%20with%20an%20ROI%20mask%20as%20input/#intro","title":"Intro","text":"<ul> <li>In some cases, it is desirable to classify only a specific region of the image that corresponds to a certain object.</li> <li>Hence, assuming that the region of the object in the image is known in advance and is given as a binary region of interest (ROI) mask, the goal is to classify the object in this region using a convolutional neural net.</li> <li>This goal is achieved using a standard image classification net with the addition of a side branch, which converts the ROI mask into an attention map. This map is then combined with the image classification net</li> <li>focus the attention on the object region while still extracting contextual cues from the background</li> <li>COCO</li> <li>OpenSurfaces materials dataset</li> </ul>"},{"location":"KB/Classifying%20a%20specific%20image%20region%20using%20convolutional%20nets%20with%20an%20ROI%20mask%20as%20input/#network","title":"Network","text":"<ul> <li>combining the attention map at the first layer of the net gave better results than combining it at higher layers of the net</li> <li>An alternative approach is to generate an attention map, which can be used by the net to extract features from both objects and the background using the ROI mask as an additional input to the net</li> <li>An attention map can easily be generated from the input ROI mask using a convolution layer</li> <li>This attention map is then combined with one or more layers of the main branch, either by element-wise addition or multiplication</li> <li>The combined layer is then used as an input for the next layer of the main branch</li> <li>In order to allow element-wise addition or multiplication, the attention map must be the same size as the layer with which it is combined. To achieve this, the ROI mask was first resized to match the size of the layer with which it was merged, and a convolution layer was then applied with the same number of filters as the depth of the target layer.</li> <li>For cases where the attention maps were combined with more than one layer , a separate attention map was generated using different convolution filters for each layer</li> </ul>"},{"location":"KB/Classifying%20a%20specific%20image%20region%20using%20convolutional%20nets%20with%20an%20ROI%20mask%20as%20input/#net-initiation","title":"Net Initiation","text":"<ul> <li>The convolution layer of the side branch was initialized as follows: if the attention map was to be merged by element-wise addition, both the weights and the bias were initialized to zero; if the attention map was to be merged multiplication, the bias was set to one and the filter weights to zero</li> <li>This weights initiation method promise that the initial effect of the attention branch on the classification branch is zero at the outset and increases gradually during training.</li> </ul>"},{"location":"KB/Classifying%20a%20specific%20image%20region%20using%20convolutional%20nets%20with%20an%20ROI%20mask%20as%20input/#datasets","title":"Datasets","text":"<ul> <li>The nets were also trained using the OpenSurfaces material classification dataset1 0 ; in this case, the ROI was generated by taking a connected region of the image corresponding to a single material, and the output was the material type.</li> </ul>"},{"location":"KB/Classifying%20a%20specific%20image%20region%20using%20convolutional%20nets%20with%20an%20ROI%20mask%20as%20input/#results","title":"Results","text":"<ul> <li>It can be seen that methods based on generating an attention map and combining it with the main branch net branch gave considerably better accuracy than hard attention methods based on blacking out the background region3</li> <li>The difference in accuracy is particularly large for the classification of small segments where background information is more important in classification.</li> <li>Merging the attention map with the first layer of the net gave significantly better results than merging at higher layers</li> <li>This probably due to the fact that higher layers of the net suffer from a loss of high-resolution information that is relevant in the classification of small objects.</li> <li>Generating several attention maps and merging them with multiple layers of the net gave the same or worse results than generating a single attention map and merging it with the first layer</li> </ul>"},{"location":"KB/Classifying%20a%20specific%20image%20region%20using%20convolutional%20nets%20with%20an%20ROI%20mask%20as%20input/#images","title":"Images","text":""},{"location":"KB/Clear%20Thinking/","title":"Clear Thinking","text":""},{"location":"KB/Clear%20Thinking/#clear-thinking","title":"Clear Thinking","text":"<ul> <li>Developing good abstractions, notations, visualizations, and so forth, is improving the user interfaces for ideas.</li> <li>This helps both with understanding ideas for the first time and with thinking clearly about them.</li> <li>Conversely, if we can\u2019t explain an idea well, that\u2019s often a sign that we don\u2019t understand it as well as we could.</li> </ul>"},{"location":"KB/Clustering/","title":"Clustering","text":""},{"location":"KB/Clustering/#clustering","title":"Clustering","text":"<ul> <li>KMeans</li> <li>SOMs</li> </ul>"},{"location":"KB/Clutter%20In%20Visualisation/","title":"Clutter In Visualisation","text":""},{"location":"KB/Clutter%20In%20Visualisation/#clutter-in-visualisation","title":"Clutter In Visualisation","text":""},{"location":"KB/Co%20adaptation/","title":"Co adaptation","text":""},{"location":"KB/Co%20adaptation/#co-adaptation","title":"Co Adaptation","text":"<ul> <li>Computing the gradient is done with respect to the error, but also with respect to what all other units are doing (Srivastava et al., 2014). This means that certain neurons, through changes in their weights, may fix the mistakes of other neurons. These, Srivastava et al. (2014) argue, lead to complex co-adaptations that may not generalize to unseen data, resulting in overfitting.</li> </ul>"},{"location":"KB/Co-Mixup/","title":"Co-Mixup","text":""},{"location":"KB/Co-Mixup/#co-mixup","title":"Co-Mixup","text":"<ul> <li>@kimCoMixupSaliencyGuided2021</li> <li>salient image mixing on a batch of input images to generate a batch of augmented images</li> <li>This technique maximizes saliency in output images by penalizations to ensure local data smoothness and diverse image regions</li> </ul>"},{"location":"KB/Co-training/","title":"Co training","text":""},{"location":"KB/Co-training/#co-training","title":"Co-training","text":"<ul> <li>A semi-supervised learning approach particularly useful when all of the following conditions are true</li> <li>The ratio of unlabeled examples to labeled examples in the dataset is high.</li> <li>This is a classification problem (binary or multi-class).</li> <li>The dataset contains two different sets of predictive features that are independent of each other and complementary.</li> <li>Co-training essentially amplifies independent signals into a stronger signal.</li> </ul>"},{"location":"KB/Coarse-grained%20assessment/","title":"Coarse-grained assessment","text":""},{"location":"KB/Coarse-grained%20assessment/#coarse-grained-assessment","title":"Coarse-grained Assessment","text":"<ul> <li>If the required assessment is coarse grained, such as a single number reporting the student's competence on the current unit, then it is usually computed from several measures such as:</li> <li>A measure of progress and coverage, such as the number of problems solved or the number of correct steps.</li> <li>A measure of the amount of help given, such as the number of hint sequences started and the proportion that ended with a bottom-out hint.</li> <li>Some measure of competence, such as the frequency of incorrect initial steps, the time required to enter a correct step, or the number of attempts at a step before it is entered correctly.</li> <li>Psychometrics is the field that studies how to do this for conventional tests (e.g., multiple choice tests)</li> <li>One of their main tools is item-response theory IRT</li> </ul>"},{"location":"KB/Cochlea/","title":"Cochlea","text":""},{"location":"KB/Cochlea/#cochlea","title":"Cochlea","text":"<ul> <li>The part of the inner ear that transforms sound vibrations into neural impulses.</li> </ul>"},{"location":"KB/Codex/","title":"Codex","text":""},{"location":"KB/Codex/#codex","title":"Codex","text":"<ul> <li>translates text to code</li> <li>general-purpose programming model, as it can be applied to basically any programming task</li> <li>Programming can be broken down into two parts: breaking a problem down into simpler problems and mapping those problems into existing code (libraries, APIs, or functions) that already exist</li> <li>The second part is the most time-barring part for programmers, and it is where Codex excels the most</li> <li>model is fine-tuned from GPT-3, which already contains strong natural language representations</li> </ul>"},{"location":"KB/CogMod%20Final%20Paper/","title":"CogMod Final Paper","text":""},{"location":"KB/CogMod%20Final%20Paper/#cogmod-final-paper","title":"CogMod Final Paper","text":"<ul> <li>The Reward Experiment</li> <li>An ACT-R model that explains at least one of these effects (well)  </li> <li>Report to justify design choices</li> <li>\u2018cognitive\u2019 interpretation, that is justifiable &amp; plausible</li> </ul>"},{"location":"KB/CogMod%20Final%20Paper/#to-test","title":"To test","text":"<ul> <li>linear decrease in goal activation </li> </ul>"},{"location":"KB/CogMod%20Final%20Paper/#papers","title":"Papers","text":"<ul> <li>Sequential effects within a short foreperiod context Evidence for the conditioning account of temporal preparation : IMPORTANT</li> <li>Traces of times past Representations of temporal intervals in memory : Explain the fanning effect</li> <li>The warning stimulus as retrieval cue The role of associative memory in temporal preparation : temporal preparation , sloping effects</li> <li>Modeling motivation using goal competition in mental fatigue studies : performance in reward vs non reward , distraction, linear decrease in goal activation</li> <li>The neural correlates of mental fatigue and reward processing - A task-based fMRI study : studies the physical brain effect of reward and fatigue</li> <li>Implicitly learning when to be ready - From instances to categories : fanning , maybe the graphs can also be explained by categorical association instead of just instance based</li> <li>On the Distinction Between Perceived Duration and Event Timing - Towards a Unified Model of Time Perception : brain uses temporal expectations to bias perception in a way that stimuli are \u2018regularized\u2019</li> <li>Change of Variable Foreperiod Effects within an Experiment - A Bayesian Modeling Approach : sequential modulation, which is attributed to feature binding and retrieval by the BRAC framework, could have different underlying mechanisms depending on the task scenario.</li> <li>Revisiting variable foreperiod effects evaluating the repetition priming account : change in foreperiod </li> </ul>"},{"location":"KB/Cognition%20Hazard%20Rates/","title":"Cogntition Hazard Rates","text":""},{"location":"KB/Cognition%20Hazard%20Rates/#cogntition-hazard-rates","title":"Cogntition Hazard Rates","text":"<ul> <li>{Proven wrong} : Cognitive fMTP</li> <li>Mathematical construct about probability</li> <li>Continuously tracking the odds the event appeads rn given it has not happened yet</li> <li>Idea : Use this \"hazard rate\" to decide when to prepare</li> <li>RT is proportional to hazard</li> <li>Optimally prepared if certain</li> </ul>"},{"location":"KB/Cognition%20Hazard%20Rates/#distributions-used-pdf","title":"Distributions Used (PDF)","text":"<ul> <li>Constant, exponential, flipped exponential</li> <li>Hazard rate is this pdf by 1-F</li> <li> \\[h(t) = \\frac{f(t)}{1-F(t)}\\] </li> <li></li> </ul>"},{"location":"KB/Cognition%20Hazard%20Rates/#hazard-rates","title":"Hazard Rates","text":"<ul> <li>How does that translate to RT?</li> <li>Proposed<ul> <li>\\(RT = c- h(t)\\) : linear effect</li> <li>\\(RT = c+ \\frac{1}{h(t)}\\) : inverse relation</li> </ul> </li> <li>dashed : \\(\\frac{1}{hazard}\\)</li> <li></li> <li></li> </ul>"},{"location":"KB/Cognition%20Hazard%20Rates/#vs-act-r","title":"Vs ACT-R","text":"<ul> <li>Prepare for \u2018the right moment\u2019  <ul> <li>\u2018degree of preparation\u2019 given by moment-to-moment hz  </li> </ul> </li> <li>\u2018the right moment\u2019 is estimated based on time (pulses) and memory (DM)  <ul> <li>No \u2018time\u2019, no explicit memory?  </li> </ul> </li> <li>If we are prepared\u2192 benefit, else cost  <ul> <li>Scaled benefits (useful for assignment)</li> <li>Does not specify why/how; i.e., what preparation is  </li> </ul> </li> <li>No active process during the interval  <ul> <li>Active tracking</li> </ul> </li> <li>Once we are prepared, it doesn\u2019t \u2018go away\u2019  <ul> <li>A by-product of the Hazard rate</li> </ul> </li> <li>No memory model  <ul> <li>Such mathematical models give no mechanism for how the pdf is stored in memory, retrieved, or used\u2026</li> </ul> </li> </ul>"},{"location":"KB/Cognition%20Hazard%20Rates/#problems","title":"Problems","text":"<ul> <li>Does not explain preparation</li> <li>How do particpants \u2018learn\u2019 the distribution?</li> <li>Do participants truly track \u2018conditional probabilities\u2019 throughout the foreperiod</li> </ul>"},{"location":"KB/Cognition%20Hazard%20Rates/#extending","title":"Extending","text":"<ul> <li>Does not store PDFs in memory, which sucks<ul> <li>Does not keep track of time as well</li> </ul> </li> <li>Subjective hazard/ anticipation function<ul> <li>Temporal uncertainty</li> <li>Blur the pdf such that later points are less certain using a Gaussian filter that gets wider for later points in time</li> <li> \\[f'(t) = \\frac{1}{\\theta t \\sqrt{2 \\pi}} \\int_{-\\infty}^{\\infty}f(\\tau)e^{-\\frac{(r-t)^{2}}{2 \\theta^{2}t^{2}}}d \\tau\\] </li> <li>Climb to 1 after a while</li> <li>Hazard is more even though probs are equal in classical. This equates them and makes them less blurred out</li> <li></li> </ul> </li> </ul>"},{"location":"KB/Cognition%20Hazard%20Rates/#images","title":"Images","text":""},{"location":"KB/Cognitive%20Engagement/","title":"Cognitive Engagement","text":""},{"location":"KB/Cognitive%20Engagement/#cognitive-engagement","title":"Cognitive Engagement","text":"<ul> <li>Cognitive effort is a form of labor, and unsurprisingly, people tend to favor less demanding forms of cognition and other mental shortcuts [18, 51].</li> <li>Unfortunately, this human tendency can lead to unintended or dangerous outcomes because humans are susceptible to a wide variety of cognitive biases such as confirmation bias</li> <li>Confirmation bias [41]</li> <li>refers to the interpreting of new evidence in ways that confirm one's existing beliefs</li> <li>For XAI, this manifests as practitioners only superficially examining explanations instead of digging deeply, leading to over-trust, misuse, and a lack of accurate understanding of the outputs [31]</li> <li>Forcing users to cognitively engage through some small task before showing a system's output yielded the highest performance in a comparative study [21]</li> <li>Train conductors in Japan famously point and call out important information on their journeys\u2014a cognitive forcing method which has reduced human errors by nearly 85% [45].</li> <li>Realistically, how much will users actually cognitively engage with the magnitude of generated outputs to ensure that they are correct and aligned with their intentions?</li> </ul>"},{"location":"KB/Cognitive%20Foreperiod/","title":"Cognitive Foreperiod","text":""},{"location":"KB/Cognitive%20Foreperiod/#cognitive-foreperiod","title":"Cognitive Foreperiod","text":"<ul> <li>Time before stimulus</li> <li>Prepare to act</li> </ul>"},{"location":"KB/Cognitive%20Foreperiod/#constant-fp","title":"Constant FP","text":"<ul> <li>No uncertainty</li> <li>Up to ~150ms : RT decrease, then increase</li> <li>People prepare if warning - faster</li> <li> <p>if longer intervals</p> <ul> <li>avg response time increases</li> <li>Temporal estimates get noiser : Temporal Uncertainty<ul> <li>not really prepared</li> </ul> </li> </ul> </li> <li> <p>Faster if less time to prepare</p> </li> </ul>"},{"location":"KB/Cognitive%20Foreperiod/#variable-fp","title":"Variable FP","text":"<ul> <li>Faster if more time to prepare</li> <li>Asymptotic decrease : plateau</li> <li>Try your best based on exp to be prepared<ul> <li>But stay prepared if you already are</li> </ul> </li> <li>\"Strategic\" : aim to be prepared as late<ul> <li>Why? Dunno. Maybe energy conservation</li> </ul> </li> </ul>"},{"location":"KB/Cognitive%20Foreperiod/#distribution-effects","title":"Distribution Effects","text":"<ul> <li>Uniform</li> <li>Exponential<ul> <li>Many shorts</li> </ul> </li> <li>Anti Exponential<ul> <li>Many long</li> </ul> </li> <li>Prep strategy altered based on which type of distribution</li> </ul>"},{"location":"KB/Cognitive%20Foreperiod/#sequential-effects","title":"Sequential Effects","text":"<ul> <li>Prep dependent on previous trials<ul> <li>If prev short, present longer : RTs are slow</li> </ul> </li> <li>Traces of gradually forgetting previous trials<ul> <li>in the shape of prep effects</li> </ul> </li> <li>Cannot just be accounted for by n-1 trials</li> </ul>"},{"location":"KB/Cognitive%20Foreperiod/#transfer-effects","title":"Transfer Effects","text":"<ul> <li>Start with uniform - then something else - then uniform again</li> <li>Long lasting effects</li> <li>Even if participants were informed that things changed</li> <li>Even a week later</li> <li></li> </ul>"},{"location":"KB/Cognitive%20Foreperiod/#motivation-determined-by","title":"Motivation Determined by","text":"<ul> <li>Time</li> <li>Memory</li> <li> <p>Motivation - still works on earlier prep?</p> </li> <li> <p>Cognition Hazard Rates</p> </li> </ul>"},{"location":"KB/Cognitive%20Multitasking/","title":"Cognitive Multitasking","text":""},{"location":"KB/Cognitive%20Multitasking/#cognitive-multitasking","title":"Cognitive Multitasking","text":"<ul> <li>No overlap between areas of brain in fMRI with similar tasks concurrently</li> <li>Threaded Cognition</li> <li>Natural way of cognition, need to be prepared for a new \"task\"</li> <li>If unused brain resources, put it to use</li> <li>Mental Fatigue</li> </ul>"},{"location":"KB/Cognitive%20Preparation/","title":"Cognitive Preparation","text":""},{"location":"KB/Cognitive%20Preparation/#cognitive-preparation","title":"Cognitive Preparation","text":"<ul> <li>How brains use time to make decisions</li> <li>Reflects implicit learning mechanisms<ul> <li>relies to optimize behavior</li> </ul> </li> <li>Many models assume brain can time but not about how time is implemented</li> <li>Prepartion effects are present on different time scales</li> <li>Within trial</li> <li>Block of trials</li> <li>Across blocks of trials</li> <li>Cognitive Multitasking</li> </ul>"},{"location":"KB/Cognitive%20Preparation/#design","title":"Design","text":"<ul> <li>Task has to be boring -.-</li> </ul>"},{"location":"KB/Cognitive%20Preparation/#terms","title":"Terms","text":"<ul> <li>Cognitive Foreperiod</li> </ul>"},{"location":"KB/Cognitive%20fMTP/","title":"Cognitive fMTP","text":""},{"location":"KB/Cognitive%20fMTP/#cognitive-fmtp","title":"Cognitive fMTP","text":"<ul> <li>Preparation effects manifest in the motor system</li> <li>Preparation is a balance between inhibition and activation</li> <li>A neural representation of time  </li> <li>A (crude) model of the motor system  </li> <li>Hebbian associations + Forgetting &amp; Retrieval</li> </ul>"},{"location":"KB/Cognitive%20fMTP/#between-fore-and-start","title":"Between Fore and Start","text":"<ul> <li>Timing<ul> <li>Layer of time cells</li> <li></li> </ul> </li> <li>Preparation<ul> <li>The motor system \u2018stages\u2019 a response, but holds it under inhibition..</li> <li>When the Go-stimulus (S2) arrives: activation</li> <li></li> </ul> </li> </ul>"},{"location":"KB/Cognitive%20fMTP/#learning","title":"Learning","text":"<ul> <li>Different 'Time cells' and 'motor inhibiton &amp; activation' are active at the same time: this leads to hebbian learning</li> <li>Fire together, wire together</li> <li>Forms memory traces : aka chunk</li> <li></li> </ul>"},{"location":"KB/Cognitive%20fMTP/#retrieval","title":"Retrieval","text":"<ul> <li>At the start, high degree of inhibition and low degree of activation</li> <li>If prev trial is short, inhibition short and more activation</li> <li> \\[RT = \\frac{I}{A}\\] </li> <li>More activation retrieved : faster</li> <li>Recency weighted</li> <li>Declarative Memory Blending</li> <li>Preparation := Ratio of retrieved I vs. A</li> <li></li> </ul>"},{"location":"KB/Cognitive%20fMTP/#vs-act-r","title":"Vs ACT-R","text":"<ul> <li>Prepare for \u2018the right moment\u2019  <ul> <li>Moment-to-moment balance of I and A  </li> </ul> </li> <li>\u2018the right moment\u2019 is estimated based on time (pulses) and memory (DM)  <ul> <li>Similar; but memory \u2018chunks\u2019 contain I- and A-traces not a single moment at which one should be prepared  </li> </ul> </li> <li>If we are prepared\u2192 benefit, else cost  <ul> <li>Scaled benefits </li> <li>Inhibiton increases RT; activation decreases RT  </li> </ul> </li> <li>No active process during timing  <ul> <li>Continuously retrieving associated memories?  </li> </ul> </li> <li>Once we are prepared, it doesn\u2019t \u2018go away\u2019  <ul> <li>Consequence of \u2018more A, less I retrieved\u2019</li> </ul> </li> </ul>"},{"location":"KB/Cold%20email%20templates/","title":"Cold email templates","text":""},{"location":"KB/Cold%20email%20templates/#cold-email-templates","title":"Cold email templates","text":""},{"location":"KB/Cold%20email%20templates/#eg1","title":"Eg1","text":"<p>\"Hi Betsy,</p> <p>My name is Alison Parker. I'm a freelance writer covering science and psychology. I've written for several publications, including\u00a0[X],\u00a0[Y]\u00a0and\u00a0[Z publications].\u00a0I've been doing this work for about three years, and I'm really passionate about making people think critically about the world.</p> <p>My former boss,\u00a0[X boss' name], who you used to work with at\u00a0[X company], mentioned you\u00a0when I told her I was looking for a full-time position. She said your magazine is hiring a senior science reporter. I was pleasantly surprised to hear your name,\u00a0as I've been reading your work for years! I especially enjoyed the cover story you wrote for\u00a0[X name of publication]\u00a0in 2016 about the psychology of consumer spending.</p> <p>I submitted an application for the position online, but even if things don't work out, I'd be so grateful for a 30 minute call to learn about your experience and what advice you have for young professionals in this field. I'm free any time after 3 p.m. (ET) on Wednesday, Thursday and Friday this week.</p> <p>(P.S. I saw your call on Twitter for volunteers to help at the food drive at\u00a0[X location]\u00a0this weekend. I organized a few of these in college and would love to help out, so count me in!)</p> <p>Thanks so much for your time, Alison\"</p>"},{"location":"KB/Collaborative%20Recommender/","title":"Collaborative Recommender","text":""},{"location":"KB/Collaborative%20Recommender/#collaborative-recommender","title":"Collaborative Recommender","text":"<ul> <li>Clusters users according to behavior</li> <li>Match with other users</li> <li>eg : netflix</li> </ul>"},{"location":"KB/Collaborative%20Topic%20Regression/","title":"Collaborative Topic Regression","text":""},{"location":"KB/Collaborative%20Topic%20Regression/#collaborative-topic-regression","title":"Collaborative Topic Regression","text":"<ul> <li>Collaborative Deep Learning for Recommender Systems</li> <li>Collaborative filtering (CF) is a successful approach commonly used by many recommender systems</li> <li>Conventional CF-based methods use the ratings given to items by users as the sole source of information for learning to make recommendation</li> <li>However, the ratings are often very sparse in many applications, causing CF-based methods to degrade significantly in their recommendation performance</li> <li>To address this sparsity problem, auxiliary information such as item content information may be utilized</li> <li>Collaborative topic regression (CTR) is an appealing recent method taking this approach which tightly couples the two components that learn from two different sources of information</li> <li>Nevertheless, the latent representation learned by CTR may not be very effective when the auxiliary information is very sparse.</li> <li>generalizing recent advances in deep learning from i.i.d input to non-i.i.d (CF-based) input and propose a hierarchical Bayesian model called collaborative deep learning (CDL), which jointly performs deep representation learning for the content information and collaborative filtering for the ratings (feedback) matrix.</li> </ul>"},{"location":"KB/Collective%20Ethical%20Decision%20Frameworks/","title":"Collective Ethical Decision Frameworks","text":""},{"location":"KB/Collective%20Ethical%20Decision%20Frameworks/#collective-ethical-decision-frameworks","title":"Collective Ethical Decision Frameworks","text":"<ul> <li>advocates the need of primary rules governing social norms and allowing the creation, modification and suppression of the primary rules with secondary rules as situations evolve.</li> </ul>"},{"location":"KB/Collective%20Interpretation/","title":"Collective Interpretation","text":""},{"location":"KB/Collective%20Interpretation/#collective-interpretation","title":"Collective Interpretation","text":"<ul> <li>No scopal relation</li> <li>Three aliens are holding two flags.</li> <li>Both Np's are interpreted individually and connected to each other</li> </ul>"},{"location":"KB/Collectivity%2C%20Distributivity%2C%20and%20the%20Interpretation%20of%20Plural%20Numerical%20Expressions%20in%20Child%20and%20Adult%20Language/","title":"Collectivity, Distributivity, and the Interpretation of Plural Numerical Expressions in Child and Adult Language","text":""},{"location":"KB/Collectivity%2C%20Distributivity%2C%20and%20the%20Interpretation%20of%20Plural%20Numerical%20Expressions%20in%20Child%20and%20Adult%20Language/#collectivity-distributivity-and-the-interpretation-of-plural-numerical-expressions-in-child-and-adult-language","title":"Collectivity, Distributivity, and the Interpretation of Plural Numerical Expressions in Child and Adult Language","text":"<ul> <li>Kristen Syrett, Ph.D. and Rutgers, The State University of New Jersey, Linguistics, New Brunswick, United States</li> <li>Julien Musolino : Rutgers, The State University of New Jersey, Psychology, Piscataway, United States</li> </ul>"},{"location":"KB/Collectivity%2C%20Distributivity%2C%20and%20the%20Interpretation%20of%20Plural%20Numerical%20Expressions%20in%20Child%20and%20Adult%20Language/#intro","title":"Intro","text":"<ul> <li>Sentences containing plural numerical expressions (e.g., two boys) can give rise to two interpretations (collective and distributive), arising from the fact that their representation admits of a part-whole structure</li> <li>designed to explore children\u2019s understanding of this distinction and its implications for the acquisition of linguistic expressions with number words.</li> <li>preschoolers access both interpretations, indicating that they have the requisite linguistic and conceptual machinery to generate the corresponding representations.</li> <li>hift their interpretation in response to structural and lexical manipulations.</li> <li>unlike adults, they are drawn to the distributive interpretation, and are not yet aware of the lexical semantics of each and together, which should favor one or another interpretation.</li> <li>Here, we take a different approach, and use numerically quantified expressions to study how children acquire a fundamental semantic property shared by a range of plurality-denoting expressions</li> </ul>"},{"location":"KB/Collectivity%2C%20Distributivity%2C%20and%20the%20Interpretation%20of%20Plural%20Numerical%20Expressions%20in%20Child%20and%20Adult%20Language/#findings","title":"Findings","text":"<ul> <li>Our findings demonstrate that the ability to generate collective and distributive interpretations of sentences such as (1) is part of the semantic repertoire of children as young as three (Experiment 1). However, we also uncover intriguing differences in the preferences preschoolers and adults have for resolving the collective/distributive ambiguity: whereas adults strongly prefer the collective interpretation, preschoolers prefer the distributive one (Experiment 2).</li> <li>Following analyses by Link (1983, 1987) and others more recently, we will assume that these sentences are truly ambiguous, and not merely underspecified, and that the source of the ambiguity in our target sentences is the VP predicate. Here, we adopt a default semantics approach in order to illustrate how two different interpretations may be generated.</li> <li>When the predicate in our example sentence is applied to the individuals, the derived reading is the distributive one</li> <li>When the predicate is applied to the group, however, a collective reading is derived, and the extension is an atomic joint \u2018car pushing\u2019 event in which the boys collectively push the car.</li> <li>Beginning with the latter, Musolino (2009) was primarily concerned with the range of readings arising from the interaction of two numerically quantified expressions in so-called relational plural sentences such as (3).</li> </ul>"},{"location":"KB/Collectivity%2C%20Distributivity%2C%20and%20the%20Interpretation%20of%20Plural%20Numerical%20Expressions%20in%20Child%20and%20Adult%20Language/#judgment-task-with-ambiguous-sentences","title":"Judgment Task with Ambiguous Sentences","text":"<ul> <li>The results demonstrate that both children and adults were able to access both the collective and distributive interpretations of the target sentences. While there was a significant main effect of age (p= .02), there was no main effect of context (p=.75) and no interaction between age group and context (p=.26).</li> <li>This difference stems from the fact that while four-year-olds were near ceiling in their acceptance of the sentences in the distributive context, adults\u2019 acceptance rates were slightly suppressed.</li> </ul>"},{"location":"KB/Collectivity%2C%20Distributivity%2C%20and%20the%20Interpretation%20of%20Plural%20Numerical%20Expressions%20in%20Child%20and%20Adult%20Language/#ambiguous-sentences-that-yield-either-interpretation","title":"Ambiguous Sentences That Yield Either Interpretation.","text":"<ul> <li>As the results demonstrate, adults overwhelmingly preferred the collective version of the event</li> <li>In this experiment, we found that while adults robustly prefer the collective context as a match for the ambiguous target sentences, children display a slight preference in the opposite direction, leaning towards preference for the distributive context.</li> <li>structural manipulation of passivization will lead participants to prefer the collective context.</li> <li>As predicted, adults consistently accepted the passive test sentences in the collective context, but largely rejected them in the distributive context. Most children also followed this pattern, although the difference between acceptances in the two contexts was not as striking for children as it was for the adults.</li> <li>whether participants can recruit lexical semantic information provided by individual words to disambiguate the target sentence and assign either a collective or distributive interpretation, depending on the lexical item.</li> <li>As predicted, adults were guided by the presence of the additional lexical item in their interpretation of these sentences, accepting the test sentences with each in the distributive context, but rejecting them in the collective context</li> <li>In place of the ambiguous sentences, children heard sentences with a post-verbal together (</li> <li>Interestingly, despite children\u2019s acceptance of the together sentences in both contexts of the judgment task of Experiment 4, children appeared to be aware of the collectivizing force of together in the current preference task.</li> </ul>"},{"location":"KB/Color%20Compositing/","title":"Color Compositing","text":""},{"location":"KB/Color%20Compositing/#color-compositing","title":"Color Compositing","text":"<ul> <li> \\[C_{i}= c_{i}+ (1-o_{i})C_{i-1}\\] </li> <li>where</li> <li> \\[c_{i}= o_{i}c_{i}'\\] </li> <li></li> <li>First is same as Marching Cubes</li> <li>$$I(p) = \\begin{cases*}</li> </ul> <p>f(\\sigma)&amp; \\(\\exists t \\in [0,T], s(t) = \\sigma\\) \\</p> <p>I_{o}&amp;otherwise</p> <p>\\end{cases*}$$</p> <ul> <li>Higher pixel accurate quality</li> </ul>"},{"location":"KB/Color%20Space%20Transformations/","title":"Color Space Transformations","text":""},{"location":"KB/Color%20Space%20Transformations/#color-space-transformations","title":"Color Space Transformations","text":"<ul> <li>Image data is encoded into 3 stacked matrices, each of size height\u00d7width. These matrices represent pixel values for an individual RGB color value</li> <li>Lighting biases are amongst the most frequently occurring challenges to image recognition problems</li> <li>A quick fix to overly bright or dark images is to loop through the images and decrease or increase the pixel values by a constant value.</li> <li>Another quick color space manipulation is to splice out individual RGB color matrices.</li> <li>Another transformation consists of restricting pixel values to a certain min or max value.</li> <li>Similar to geometric transformations, a disadvantage of color space transformations is increased memory, transformation costs, and training time.</li> <li>Additionally, color transformations may discard important color information and thus are not always a label-preserving transformation.</li> <li>For example, when decreasing the pixel values of an image to simulate a darker environment, it may become impossible to see the objects in the image.</li> <li>Digital image data is usually encoded as a tensor of the dimension (height \u00d7 width \u00d7 color channels)</li> <li>Performing augmentations in the color channels space is another strategy that is very practical to implement.</li> <li>Very simple color augmentations include isolating a single color channel such as R, G, or B.</li> <li>An image can be quickly converted into its representation in one color channel by isolating that matrix and adding 2 zero matrices from the other color channels. Additionally, the RGB values can be easily manipulated with simple matrix operations to increase or decrease the brightness of the image.</li> <li>More advanced color augmentations come from deriving a color histogram describing the image</li> </ul>"},{"location":"KB/Color%20Spaces/","title":"Color Spaces","text":""},{"location":"KB/Color%20Spaces/#color-spaces","title":"Color Spaces","text":"<ul> <li>Divide Oriented</li> <li>Intuitive Color spaces</li> </ul>"},{"location":"KB/ColorMap/","title":"ColorMap","text":""},{"location":"KB/ColorMap/#colormap","title":"ColorMap","text":"<ul> <li>Color Spaces</li> <li></li> </ul>"},{"location":"KB/CommonCrawl/","title":"CommonCrawl","text":""},{"location":"KB/CommonCrawl/#commoncrawl","title":"CommonCrawl","text":""},{"location":"KB/Comparing%20Data%20Augmentation%20Strategies%20for%20Deep%20Image%20Classification/","title":"Comparing Data Augmentation Strategies for Deep Image Classification","text":""},{"location":"KB/Comparing%20Data%20Augmentation%20Strategies%20for%20Deep%20Image%20Classification/#comparing-data-augmentation-strategies-for-deep-image-classification","title":"Comparing Data Augmentation Strategies for Deep Image Classification","text":"<ul> <li>Sarah O'Gara and Kevin McGuinness</li> </ul>"},{"location":"KB/Comparing%20Data%20Augmentation%20Strategies%20for%20Deep%20Image%20Classification/#summary","title":"Summary","text":"<ul> <li>Inject augmentation around 30 epochs</li> <li>Use learning rate decay</li> <li>Random Erasing is useful</li> <li>Use [Adam] + SGD </li> </ul>"},{"location":"KB/Comparing%20Data%20Augmentation%20Strategies%20for%20Deep%20Image%20Classification/#abstract","title":"Abstract","text":"<ul> <li>More complex augmentation methods have recently been developed, but it is still unclear which techniques are most effective, and at what stage of the learning process they should be introduced.</li> <li>The most accurate results in all experiments are achieved using random erasing due to its ability to simulate occlusion</li> <li>reducing the number of training examples significantly increases the importance of augmentation</li> <li>improvements in generalization from augmentation do not appear to be only as a result of augmentation preventing overfitting</li> <li>learning curriculum that injects augmentation after the initial learning phase has passed is more effective than the standard practice of using augmentation throughout, and that injection too late also reduces accuracy</li> <li>We find that careful augmentation can improve accuracy by +2.83% to 95.85% using a ResNet model on CIFAR-10 with more dramatic improvements seen when there are fewer training examples</li> </ul>"},{"location":"KB/Comparing%20Data%20Augmentation%20Strategies%20for%20Deep%20Image%20Classification/#model-and-optimizer","title":"Model and Optimizer","text":"<ul> <li>ResNet</li> <li>[He et al., 2015] presents an adaption of the model (ResNet-56) for use with 32\u00d732 images that obtained an error rate of 6.97% on CIFAR-10, which we adopt in our experiments</li> <li>SGD with Nestrov momentum</li> <li>Although there are more sophisticated first order optimizers (e.g. Adam [Kingma and Ba, 2015]) that consistently improve the loss faster in the initial epochs, SGD has been observed to reach a local minima with lower overall loss and better generalization properties [Ruder, 2016]</li> </ul>"},{"location":"KB/Comparing%20Data%20Augmentation%20Strategies%20for%20Deep%20Image%20Classification/#datasets","title":"Datasets","text":""},{"location":"KB/Comparing%20Data%20Augmentation%20Strategies%20for%20Deep%20Image%20Classification/#cifar-10","title":"CIFAR-10","text":"<ul> <li>randomly sample the dataset to create a 200 samples per class and 1,000 samples per class dataset, reducing the training examples available to 4% and 20% of the original dataset</li> <li>The effects of overfitting and model generalization as noted in [Hussain et al., 2018, Shijie et al., 2017] are more pronounced with data scarcity</li> <li>Skew Tilt</li> <li>Shear</li> <li>Random Distortion</li> <li>Gaussian Distortion</li> <li>We introduce augmentation on epochs 30, 60, and 90 of the baseline model and continue training until epoch 163 to discover the optimal time to introduce augmentation. Epochs 30, 60, and 90 represent three distinct stages in the training process: initial loss rate stabilising, loss rate stagnate before learning rate decrease, and loss rate stagnate after learning rate decrease.</li> </ul>"},{"location":"KB/Comparing%20Data%20Augmentation%20Strategies%20for%20Deep%20Image%20Classification/#experiments","title":"Experiments","text":"<ul> <li>The range of learning rates that provide a stable convergence reduces as batch size increases</li> <li>In the most extreme case, we reduce the training set to 4% of the original dataset, meaning a batch size of 128 would likely degrade performance</li> <li>Large batches tend to converge to sharp minimizers leading to poor generalization due to the numerous large eigenvalues in the Hessian on convergence</li> <li>Small batches, on the other hand, tend to converge to flat minimizers, which have smaller Hessian eigenvalues</li> <li>They generate more noise in gradient calculations, decreasing the chance of the gradient dropping into a sharp local minima</li> <li>Based on these observations, we train the small and medium datasets using three learning rate strategies: 1) the original strategy from [He et al., 2015], 2) using a batch size of 128 with no learning rate schedule, and 3) using a batch size of 8 with original learning rate schedule.</li> </ul>"},{"location":"KB/Comparing%20Data%20Augmentation%20Strategies%20for%20Deep%20Image%20Classification/#results-discussion","title":"Results &amp; Discussion","text":""},{"location":"KB/Comparing%20Data%20Augmentation%20Strategies%20for%20Deep%20Image%20Classification/#single-augmentations","title":"Single Augmentations","text":"<ul> <li>Random erasing shows the best improvement in accuracy of +1.5%</li> <li>Both distortion augmentations obtain worse or similar results to the baseline</li> <li>The complexity of the augmentation effects the overall training time. Traditional, more simplistic augmentations require little processing time, leading to increases in training time of \u223c 3.5 hours. Gaussian distortion sees the most significant increase in training time of 665%</li> <li>We apply each augmentation separately, leading to the dataset increasing from 50k training images to 250k. This leads to the most accurate result seen throughout all experiments of 95.85%</li> <li>Our method of applying several single augmentations produces better generalization properties</li> </ul>"},{"location":"KB/Comparing%20Data%20Augmentation%20Strategies%20for%20Deep%20Image%20Classification/#varying-augmentation-injection-epoch","title":"Varying Augmentation Injection Epoch","text":"<ul> <li>epoch 30 is the optimal time to introduce augmentation</li> <li>y injecting augmentation on the 30th epoch, the model combats the effects of overfitting better with increases in accuracy from +0.05% up to +0.76%</li> <li>Epoch 30 is the point in the training process when the reduction in loss rate begins to decrease drastically, i.e. the model falls into a local minima point</li> <li>The slight improvements in accuracy over the baseline result for introduction at epoch 90 support this conclusion</li> <li>The model has already overfit the training data and can no longer benefit from the augmentation's generalization properties.</li> <li>Epoch 60 presents a more interesting point in the training process. The form of augmentation appears to dictate whether the model will have better generalization properties than training with augmentation from scratch but will always be worse than injection at epoch 30</li> </ul>"},{"location":"KB/Comparing%20Data%20Augmentation%20Strategies%20for%20Deep%20Image%20Classification/#varying-sample-size","title":"Varying Sample Size","text":"<ul> <li>For the small dataset, by decreasing the batch size from 128 to 8, the validation accuracy is shown to improve by +31.45% using random erasing (74.46%) when compared to the baseline (43.01%)</li> <li>augmentation is most effective in training when data is scarce</li> <li>overfitting, as measured by high accuracy on the training set, in many of the augmentation results is more severe than for the baseline</li> <li>his would contradict current assumptions that augmentation improves generalization by preventing overfitting in the case of all NNs</li> <li>In many of these cases where augmentation has proven to prevent overfitting the sample size for each class is large</li> <li>generalization of the model is better in the presence of augmentation</li> <li>With smaller datasets using augmentation increases the models ability to learn certain features present in the training set as augmentation can only alter the data already available, i.e. the model will see similar images twice as much so is more likely to overfit.</li> <li>For the medium dataset, the best accuracy is achieved by random erasing trained with a batch size of 8 at 87.45%, which is an improvement of +6.3% over the baseline.</li> <li>The importance of the learning rate adjustment schedule is apparent with the accuracy decreasing for each model when not applied</li> <li>Augmentation does reduce overfitting with the most significant decrease occurring for the small batch size</li> <li>At this scale, augmentation has similar effects on accuracy as seen in the full dataset</li> <li>When the model has large volumes of training data available, augmentation only slightly increases the generalization capabilities of the network as a large amount of variance already exists</li> </ul>"},{"location":"KB/Comparing%20Data%20Augmentation%20Strategies%20for%20Deep%20Image%20Classification/#conclusion","title":"Conclusion","text":"<ul> <li>The initial augmentation gives rise to the most significant increase in training time with any additional augmentations adding little overhead</li> <li>processing time required to apply said augmentation to the dataset, which must be considered when choosing a form of augmentation to apply</li> <li>combining multiple single augmentations with the original dataset is the most effective augmentation strategy with an increase in accuracy of +2.36% to 95.85%</li> <li>Random distortion and Gaussian distortion are the worst forms of augmentation tested leading to changes in accuracy of -0.15% and +0.05%, respectively</li> <li>This is due to the augmented images not representing the original class and highlights the importance of the choice of augmentation</li> <li>The most effective form of single augmentation is found to be random erasing with an increase in accuracy of +1.5%. This is due to its ability to combat the effects of occlusion, and is similar to preventing co-adaption through the use of dropout.</li> <li>An interesting avenue to explore is the generalization and overfitting properties of augmentation for data scarcity</li> <li>Validation accuracy is seen to improve with augmentation, with the most significant improvement of +31.45% for random erasing, indicating better generalization capabilities.</li> <li>However, the model also appears to overfit the training data more</li> <li>Exploring the interaction of augmentation with more advanced optimizers such as the Adam optimizer, could lead to further improvements in accuracy and training times</li> <li>generalization gap between SGD and Adam can be reduced by switching from Adam to SGD during the training process</li> <li>During the switching process the learning rate for SGD is calculated as noted in [Keskar and Socher, 2017] and must be switched at the optimal time to ensure better generalization properties.</li> <li>Building on this approach, the optimizer switching approach could be combined with data augmentation potentially yielding improvements in accuracy.</li> <li>Injecting augmentation at epoch 30 yielded the best improvements in accuracy for single augmentations, indicating a learning curriculum is most effective for augmentation</li> <li>Late injection of augmentation improves the generalization capabilities of the network similar to the optimizer switching method of [Keskar and Socher, 2017].</li> </ul>"},{"location":"KB/Comparing%20Data%20Augmentation%20Strategies%20for%20Deep%20Image%20Classification/#images","title":"Images","text":""},{"location":"KB/Complete%20AI%20Pipeline/","title":"Complete AI Pipeline","text":"","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#complete-ai-pipeline","title":"Complete AI Pipeline","text":"","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#planning","title":"Planning","text":"<ul> <li>Data Availability</li> <li>Applicability</li> <li>Legal Constraints</li> <li>Robustness</li> <li>Scalability</li> <li>Explainability</li> <li>Availability of Resources</li> </ul>","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#data-collection","title":"Data Collection","text":"","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#data-standards","title":"Data Standards","text":"<ul> <li>Healthcare<ul> <li>DICOM</li> <li>HL7</li> <li>FHIR</li> </ul> </li> </ul>","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#data-formats","title":"Data Formats","text":"<ul> <li>Healthcare    <ul> <li>Next generation sequencing<ul> <li>Raw sequencing data<ul> <li>FASTQ<ul> <li>BioPython</li> </ul> </li> </ul> </li> <li>Aligned Reads<ul> <li>SAM/BAM<ul> <li>pysam</li> </ul> </li> </ul> </li> <li>Variant Calls<ul> <li>VCF<ul> <li>pyVCF</li> </ul> </li> </ul> </li> </ul> </li> <li>Mass spectrometry<ul> <li>mzML/mzXML<ul> <li>pyteomics</li> </ul> </li> <li>MGF<ul> <li>pyOpenMS</li> </ul> </li> </ul> </li> <li>MRI<ul> <li>DICOM</li> </ul> </li> <li>CT<ul> <li>DICOM</li> </ul> </li> <li>Ultrasound<ul> <li>DICOM</li> <li>SCU</li> <li>ACR-NEMA</li> </ul> </li> <li>Functional (pre)clinical studies</li> <li>E-health and m-health technology</li> <li>Wearable Device monitoring</li> <li>Unstructured vocal information</li> <li>Unstructured textual information</li> </ul> </li> </ul>","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#data-processing-and-transformation","title":"Data Processing and Transformation","text":"","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#aws-services","title":"AWS Services","text":"<ul> <li>Glue<ul> <li>Fully managed ETL (Extract, Transform, Load) service for preparing and loading data.</li> </ul> </li> </ul>","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#data-annotation","title":"Data Annotation","text":"","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#data-integration","title":"Data Integration","text":"","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#data-storage","title":"Data Storage","text":"","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#aws-services_1","title":"AWS Services","text":"<ul> <li> <p>S3</p> <ul> <li>Object storage service, suitable for storing and retrieving any amount of data at any time.</li> </ul> </li> <li> <p>Dynamo DB</p> <ul> <li>Modern</li> <li>High activity</li> <li>High Velocity data (sensors and stuff)</li> <li>Structured/unstructured</li> <li>multi data, multi cloud</li> <li>NoSQL database service designed for high-performance applications that require seamless scalability.</li> </ul> </li> <li> <p>RDS</p> <ul> <li>Tables</li> <li>low velocity/activity</li> <li>Harder to modify</li> <li>Relational Database Service, supports multiple database engines, managing backups, and software patching.</li> </ul> </li> <li> <p>HealthImaging</p> </li> <li> <p>HealthLake</p> <ul> <li>A HIPAA-eligible service for storing, transforming, and analyzing healthcare data.</li> </ul> </li> <li> <p>Lake Formation</p> <ul> <li>Simplifies the process of setting up, securing, and managing a data lake.</li> </ul> </li> </ul>","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#data-analysis-and-querying","title":"Data Analysis and Querying","text":"","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#aws-services_2","title":"AWS Services","text":"<ul> <li>Redshift<ul> <li>Fully managed data warehouse service, designed for high-performance analysis using SQL queries.</li> </ul> </li> </ul>","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#streaming-data-processing","title":"Streaming Data Processing","text":"","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#aws-services_3","title":"AWS Services","text":"<ul> <li>Kinesis<ul> <li>Streaming data service that enables real-time processing of large data streams.</li> </ul> </li> </ul>","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#model-development","title":"Model Development","text":"","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#model-architectures","title":"Model Architectures","text":"","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#model-metrics","title":"Model Metrics","text":"","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#cicd","title":"CI/CD","text":"","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#tracking-experiments-metadata-features-code-changes","title":"Tracking Experiments, Metadata, Features, Code Changes","text":"<ul> <li>MLFlow</li> </ul>","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#state-of-the-models","title":"State of the Models","text":"<ul> <li>Staging</li> <li>Production</li> <li>Archived</li> </ul>","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#model-evaluation","title":"Model Evaluation","text":"","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#machine-learning","title":"Machine Learning","text":"","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#aws-services_4","title":"AWS Services","text":"<ul> <li>SageMaker<ul> <li>Machine learning service that helps build, train, and deploy machine learning models at scale.</li> </ul> </li> </ul>","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#model-deployment","title":"Model Deployment","text":"","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#real-time-prediction","title":"Real Time Prediction","text":"","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#monitoring-and-maintenance","title":"Monitoring and Maintenance","text":"","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#interpretability-and-explainability","title":"Interpretability and Explainability","text":"","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#regulatory-compliance","title":"Regulatory Compliance","text":"<ul> <li>HIPAA</li> </ul>","tags":["ai"]},{"location":"KB/Complete%20AI%20Pipeline/#collaboration","title":"Collaboration","text":"","tags":["ai"]},{"location":"KB/Complex%20Geometry/","title":"Challenge of Complex Geometry","text":""},{"location":"KB/Complex%20Geometry/#challenge-of-complex-geometry","title":"Challenge of Complex Geometry","text":"<ul> <li>Manifold</li> </ul>"},{"location":"KB/Compliant%20Robot/","title":"Compliant Robot","text":""},{"location":"KB/Compliant%20Robot/#compliant-robot","title":"Compliant Robot","text":"<ul> <li>A robot that performs tasks, with respect to external forces, by modifying its motions in a manner that minimizes those forces. The indicated or allowed motion is accomplished through lateral (horizontal), axial (vertical) or rotational compliance.</li> </ul>"},{"location":"KB/Comprehensibility/","title":"Comprehensibility","text":""},{"location":"KB/Comprehensibility/#comprehensibility","title":"Comprehensibility","text":"<ul> <li>ability of a learning algorithm to represent its learned knowledge in a human understandable fashion</li> <li>An understandable explanation must be created by a machine in a given time (e.g., one hour or one day) and can be comprehended by a user, who need not to be an expert, but has an educational background</li> <li>The user keeps asking a finite number of questions of the machine until he/she can no longer ask why or how because he/she has a satisfactory answer; we say he/she has comprehended.</li> <li>This is the relationship between cause and effect; it is not a synonym for causability</li> </ul>"},{"location":"KB/Computational%20Graph/","title":"Computational Graph","text":""},{"location":"KB/Computational%20Graph/#computational-graph","title":"Computational Graph","text":"<ul> <li>patterns in backward flow<ul> <li>add gate: gradient distributor</li> <li>max gate: gradient router</li> <li>mul gate: gradient switcher</li> <li>branches: sum up gradients</li> </ul> </li> <li>pros<ul> <li>intuitive interpretation of gradient</li> <li>easily define new nodes using forward/backward pattern (i.e. only these two functions must be implemented)</li> <li>any complex learning architecture can be composed of atomic nodes (node composition or factorization)</li> <li>no need to compute manually complex gradients</li> <li>loss function can be seen as extra nodes in the end of the graph</li> </ul> </li> </ul>"},{"location":"KB/Conceptual%20Parsing/","title":"Conceptual Parsing","text":""},{"location":"KB/Conceptual%20Parsing/#conceptual-parsing","title":"Conceptual Parsing","text":"<ul> <li>Syntactic Analysis and Semantic Analysis knowledge are combined into a single interpretation system that is driven by the semantic knowledge</li> </ul>"},{"location":"KB/Concurrency/","title":"Concurrency","text":""},{"location":"KB/Concurrency/#concurrency","title":"Concurrency","text":"<ul> <li>The number of tasks that can be executed in parallel is the degree of concurrency of a decomposition.</li> <li>always equal to the number of leaves in the tree</li> <li>Both the maximum and the average degrees of concurrency usually increase as the Parallel Granularity of tasks becomes smaller (finer)</li> <li> \\[CriticalPath = \\frac{\\text{Total amount of work}}{\\text{Critical path length}}\\] </li> <li></li> </ul>"},{"location":"KB/Concussion/","title":"Concussion","text":""},{"location":"KB/Concussion/#concussion","title":"Concussion","text":"<ul> <li>A type of mild traumatic brain injury resulting from a blow or hit to the head that causes the brain to move rapidly back and forth inside the skull.</li> </ul>"},{"location":"KB/Conditional%20GAN/","title":"Conditional GAN","text":""},{"location":"KB/Conditional%20GAN/#conditional-gan","title":"Conditional GAN","text":"<ul> <li>Image2Image, Face Aging, Text to Image</li> <li>Generate images with certain extra conditions or attributes</li> <li>The Generator and Discriminator both receive some additional conditioning input information. This could be the class of the current image or some other property.</li> <li>add an additional input layer with values of one-hot-encoded image labels</li> <li>Adding a vector of features controls the output and guide Generator figure out what to do.</li> <li>Such a vector of features should derive from a image which encode the class(like an image of a woman or a man if we are trying to create faces of imaginary actors) or a set of specific characteristics we expect from the image (in case of imaginary actors, it could be the type of hair, eyes or complexion).</li> <li>Whereas conditional generation uses labels during training, controllable generation focuses on controlling the features that you want in the output examples.</li> <li>We can incorporate the information into the images that will be learned and also into the Z input, which is not completely random anymore.</li> <li>This can be done by adjusting the input noise vector z that is fed into the generator after it has been trained.</li> <li>We can use the same DCGANs and imposed a condition on both Generator\u2019s and Discriminator\u2019s inputs. The condition should be in the form of a one-hot vector version of the digit. This is associated with the image to Generator or Discriminator as real or fake.</li> <li>Typically this is done with a one-hot vector, meaning there are zeros in every position except for the position of the class we want to generate</li> </ul>"},{"location":"KB/Conditional%20GAN/#architecture","title":"Architecture","text":"<ul> <li>GAN Z Space</li> </ul>"},{"location":"KB/Conditional%20GAN/#the-discriminators-network","title":"The Discriminator\u2019s network","text":"<ul> <li>Discriminator\u2019s evaluation is done not only on the similarity between fake data and original data but also on the correspondence of the fake data image to its input label (or features)</li> <li>Same as [DCGAN] except one hot vector for conditioning</li> </ul>"},{"location":"KB/Conditional%20GAN/#the-generators-network","title":"The Generator\u2019s network","text":"<ul> <li>To create an image that looks as \u201creal\u201d as possible to fool the Discriminator.</li> <li>Same as [DCGAN] except one hot vector.</li> <li></li> </ul>"},{"location":"KB/Conditional%20GAN/#loss-functions","title":"Loss functions","text":"<ul> <li>We need to calculate two losses for the Discriminator. The sum of the \u201cfake\u201d image and \u201creal\u201d image loss is the overall Discriminator loss. So the loss function of the Discriminator is aiming at minimizing the error of predicting real images coming from the dataset and fake images coming from the Generator given their one-hot labels.</li> </ul>"},{"location":"KB/Conditional%20GAN/#gen","title":"Gen","text":"<ul> <li>The loss function of the Generator minimizes the correct prediction of the Discriminator on fake images conditioned on the specified one-hot labels.</li> <li> \\[\\mathcal{L}^{(G)}(\\theta^{(G)}, \\theta^{(D)}) = - \\mathbb{E}_{z} log \\mathcal{D} (\\mathcal{G} (z|y\u2019))\\] </li> </ul>"},{"location":"KB/Conditional%20GAN/#disc","title":"Disc","text":"<ul> <li>has to correctly label real images which are coming from training data set as real.</li> <li>has to correctly label generated images which are coming from Generator as fake.</li> <li> \\[ \\mathcal{L}^{(D)}(\\theta^{(G)}, \\theta^{(D)})= - \\mathbb{E}_{x \\sim p_{data}}log \\mathcal{D}(x|y) - \\mathbb{E}_{z} log (1- \\mathcal{D}(\\mathcal{G}(z|y')))\\] </li> </ul>"},{"location":"KB/Conditional%20GAN/#training","title":"Training","text":"<ul> <li>The Discriminator is trained using real and fake data and generated </li> <li>After the Discriminator has been trained, both models are trained together.</li> <li>First, the Generator creates some new examples.</li> <li>The Discriminator\u2019s weights are frozen, but its gradients are used in the Generator model so that the Generator can update its weights.</li> </ul>"},{"location":"KB/Conditional%20GAN/#training-flow","title":"Training Flow","text":"<ul> <li>For the Disc </li> <li>For the Gen </li> </ul>"},{"location":"KB/Conditional%20GAN/#challenges-with-conditional-generation","title":"Challenges with Conditional generation","text":"<ul> <li>Not strictly unsupervised. Needs labels</li> <li>With a conditional GAN, you get a random example from the class you specify</li> <li>With conditional generation, you have to train the GAN with labeled datasets.</li> <li>Feature Correlationa</li> <li>Z-Space Entanglement</li> <li>Classifier Gradients</li> </ul>"},{"location":"KB/Conditional%20GAN/#dcgan-vs-cgan","title":"DCGAN vs CGAN","text":"DCGAN CGAN Output features are not controllable Output features can be controlled Unsupervised Semi-Supervised Discriminator does not receive labels Discriminator requires labels Discriminator evaluates similarity between input and target images Discriminator considers input and target images and their respective labels"},{"location":"KB/Conditional%20Independence/","title":"Conditional Independence","text":""},{"location":"KB/Conditional%20Independence/#conditional-independence","title":"Conditional Independence","text":"<ul> <li>A Naive Bayes classifier assumes that the attribute values are independent of each other given the class. Normally distributed: many statistical methods assume that data is normally distributed.</li> </ul>"},{"location":"KB/Conductance/","title":"Conductance","text":""},{"location":"KB/Conductance/#conductance","title":"Conductance","text":"<ul> <li>@dhamdhereHowImportantNeuron2018</li> <li>Kedar Dhamdhere, Mukund Sundararajan, Qiqi Yan</li> </ul>"},{"location":"KB/Conductance/#summary","title":"Summary","text":"<ul> <li>This paper introduces the concept of conductance as a way to understand the importance of hidden units in deep networks. Conductance is defined as the flow of Integrated Gradients' attribution via a hidden unit, and is used to understand the importance of a hidden unit to the prediction for a specific input or over a set of inputs. The effectiveness of conductance is evaluated in multiple ways, including theoretical properties, ablation studies, and a feature selection task using the Inception network over ImageNet data and a sentiment analysis network over reviews. The properties of conductance include completeness, linearity and insensitivity to variations in inputs or hidden unit values. The paper also discusses the issue of saturation in neural networks, where the gradient of the output with respect to the input can be near-zero, and how conductance addresses this issue. The authors also compare conductance with other methods of understanding hidden unit importance and find it to be more intuitive and accurate.</li> </ul>"},{"location":"KB/Conductance/#abstract","title":"Abstract","text":"<ul> <li>We introduce the notion of conductance to extend the notion of attribution to the understanding the importance of hidden units</li> <li>conductance of a hidden unit of a deep network is the flow of attribution via this hidden unit</li> <li>conductance to understand the importance of a hidden unit to the prediction for a specific input, or over a set of inputs</li> <li>We evaluate the effectiveness of conductance in multiple ways, including theoretical properties, ablation studies, and a feature selection task</li> <li>Inception network over ImageNet data, and a sentiment analysis network over reviews</li> <li>Informally, the conductance of a hidden unit of a deep network is the flow of Integrated Gradients' attribution via this hidden unit</li> <li>The key idea behind conductance is to decompose the computation of Integrated Gradients via the chain rule</li> </ul>"},{"location":"KB/Conductance/#conductance_1","title":"Conductance","text":"<ul> <li>Integrated Gradients produces attributions for base features</li> <li>There is a natural way to 'lift' these attributions to a neuron in a hidden layer. Consider a specific neuron y in a hidden layer of a network</li> <li>$$</li> </ul> <p>F:R^{n} \\rightarrow [0,1] $$  represents a deep network. - \\(x \\in R^{n}\\) is input, \\(x' \\in R^{n}\\) is baseline input - Integrated Gradients is path integral of gradient along straightline path from baseline \\(x'\\) to input \\(x\\). The function F varies from a near zero value for the informationless baseline to its final value. The gradients of F with respect to the image pixels explain each step of the variation in the value of F - The integration (sum) over the gradients cumulates these micro explanations and accounts for the net difference between the baseline prediction score (near zero) and the prediction value at the input x. - $$ IG_{i}(x) ::== (x_{i}- x_{i}') \\int_{\\alpha=0}^{1} \\frac{\\partial F(x' + \\alpha(x-x'))}{\\partial x_{i}}d \\alpha $$ where \\(\\frac{\\partial F(x)}{\\partial x_{i}}\\) is grad of F along i^th dimension at x - Conductance of neuron y for attribution to input variable i is $$ Cond_{i}^{y}(x) ::== (x_{i}- x_{i}') \\int_{\\alpha=0}^{1} \\frac{\\partial F(x' + \\alpha(x-x'))}{\\partial y} \\cdot \\frac{\\partial y}{\\partial x_{i}} d \\alpha $$</p>"},{"location":"KB/Conductance/#evaluation-of-conductance","title":"Evaluation of Conductance","text":"<ul> <li>Activation: The value of the hidden unit is the feature importance score.</li> <li>\\(Gradient\\times Activation\\) : $$ y \\times \\frac{\\partial F(x' + \\alpha \\times (x-x'))}{\\partial y} d \\alpha $$</li> <li>Internal Influence : $$ Int Inf ^{y}(x) ::= \\int^{1}_{\\alpha=0} \\frac{\\partial F(x' + \\alpha(x-x'))}{\\partial y} d \\alpha $$</li> <li>The premise is that hidden units that are important across a set of inputs from a class should be predictive of this input class.</li> </ul>"},{"location":"KB/Conductance/#properties-of-conductance","title":"Properties of Conductance","text":""},{"location":"KB/Conductance/#completeness","title":"Completeness","text":"<ul> <li>conductances for any single hidden layer add up to the difference between the predictions \\(F(x) - F(x')\\)</li> <li>conductances thus satisfy the Layerwise Conservation Principle</li> </ul>"},{"location":"KB/Conductance/#linearity","title":"Linearity","text":"<ul> <li>So do internal influence and gradient*activations</li> <li>Suppose that we linearly compose hidden neurons f1 and f2 to form the final network that models the function \\(a \\times f_{1} + b \\times f_{2}\\). Then, the conductances of the two hidden neurons will be \\(a \\times (f_{1}(x) f_{1}(x_{0}))\\) and \\(b \\times (f_{2}(x) f_{2}(x'))\\) respectively.</li> <li>This is a sanity-check because if the action of a network is mostly linear from a hidden layer, the conductances will match what is intuitively the obvious solution.</li> </ul>"},{"location":"KB/Conductance/#insensitive","title":"Insensitive","text":"<ul> <li>If varying the values of a hidden unit does not change the network's prediction, it has zero conductance</li> <li>If varying the inputs does not change value of the hidden unit, the hidden unit has zero conductance</li> <li>Based on \\(\\frac{\\partial F}{\\partial y_{j}}\\) and \\(\\frac{\\partial y_{j}}{\\partial x_{i}}\\) being 0</li> </ul>"},{"location":"KB/Conductance/#saturation-of-neural-networks","title":"Saturation of Neural Networks","text":"<ul> <li>Basically, for a network, or a sub-network, even when the output crucially depends on some input, the gradient of the output w.r.t. the input can be near-zero.</li> <li>As an artificial example, suppose the network first transforms the input x linearly to y = 2x, and then transforms it to z = max(y, 1). Suppose the input is x = 1 (where z is saturated at value 1), with 0 being the baseline. Then for the hidden unit of y, gradient of z w.r.t. y is 0. Gradient*activation would be 0 for y, which does not reflect the intuitive importance of y. Like in Integrated Gradients, in computing conductance, we consider all extrapolated inputs for x between 0 and 1, and look at the gradients of output w.r.t. y at these points. This takes the non-saturated region into account, and ends up attributing 1 to y, as desired.</li> <li>wrong Polarity/Sensitivity</li> </ul>"},{"location":"KB/Conductance/#methods","title":"Methods","text":"<ul> <li>we compare against can yield scores that have signs and magnitudes that are intuitively incorrect</li> <li>This is intuitively because each misses terms/paths that our method considers.</li> <li>Activation values for a ReLU based network are always positive. However, ReLU nodes can have positive or negative influence on the output depending on the upstream weights. Here, Activation does not distinguish the sign of the influence, whereas condutance can.</li> <li>Gradient*Activation as a linear projection can overshoot</li> <li>Certain hidden units that actually have near zero influence can be assigned high</li> <li>importance scores.</li> <li>For example, suppose that the network is the composition of two functions f (x) = x and a weighted ReLU g(y) = max(y 1, 0). Again, the network computes the composition g(f(x)). Suppose that the baseline is x = 0 and the input is x = 1 . The output of the network is 0. But the feature importance of the unit f is deemed to be 1 (activation) times 1 (gradient), which is 1 . Notice that this is the only unit in its layer, so the fact that its influence does not agree in magnitude with the output is undesirable. In contrast, conductance assigns all hidden units a score of zero. The example can be extended to show that the feature importance score can disagree in sign with the actual direction of influence.</li> <li>Suppose that the network is the composition two functions f(x) = x and g(y) = y, i.e., the network computes the composition g(f(x)). Suppose that the baseline is x = 0 and the input is x = 1. The output of the network is 1. But the internal influence of the unit represented by the function g is +1 (regardless of the choice of the input or the path). Notice that this is the only unit in</li> <li>its layer, so the fact that its influence does not agree in sign with the output is highly undesirable. In contrast, conductance assigns an influence score of 1.</li> </ul>"},{"location":"KB/Conductance/#applying-conductance-to-an-object-recognition-model","title":"Applying Conductance to an Object Recognition Model","text":"<ul> <li>We use conductance as a measure to identify influential filters in hidden layers in the Inception network.</li> <li>Given an input image, we identify the top predicted label</li> <li>For the pre-softmax score for this label, we compute the conductance for each of the filters in each of the hidden layers</li> <li>The visualization is done by aggregating the conductance along the color channel and scaling the pixels in the actual image by the conductance values.</li> </ul>"},{"location":"KB/Conductance/#ablation-study","title":"Ablation Study","text":"<ul> <li>Next we studied how many filters we need to ablate in the network in order for the network to change its prediction. We found that, it is sufficient to ablate 3.7 on an average for the network to change its prediction for an image. Only 3 out of 100 images needed more than 10 filter ablations to change the predicted label. The maximum was 16. This provides further evidence that using conductance we can identify filters that are important for the prediction.</li> <li>We compare this to the filters with highest internal influence. Out of the 100 sample images, the network prediction changed for only 5 images when their top 10 filters</li> </ul>"},{"location":"KB/Conductance/#division-of-labour","title":"Division of Labour","text":"<ul> <li>We notice that almost all the filters either capture positive sentiment or negative sentiment, but not both.</li> <li>We substantiate via Figure 3, which is a clustered heatmap of signs of conductances of the 256 filters (columns) for around four thousand examples (rows) from the Stanford Sentiment Tree Bank [24]. Notice that very few filters have</li> <li>both negative and positive conductance. Negation</li> <li>Negation is commonly used in expressing sentiments, in phrases like \"this is not good\" or \"this is not bad\". Does the sentiment network understand negation? Does it have hidden units dedicated to implement the logic of negation? We first identify high conductance filters for the input \"this is not good\" that have a high attribution to the pattern \"not good\".</li> <li>Sentences with high conductance for filters that have high conductance for the phrase \"not bad\". These filters are largerly focussed on negation.</li> </ul>"},{"location":"KB/Conductance/#images","title":"Images","text":""},{"location":"KB/Cone/","title":"Cone","text":""},{"location":"KB/Cone/#cone","title":"Cone","text":"<ul> <li>A type of photoreceptor cell responsible for color vision that is found in the retina.</li> </ul>"},{"location":"KB/Confidence/","title":"Confidence","text":""},{"location":"KB/Confidence/#confidence","title":"Confidence","text":"<ul> <li>confidence should always be assessed on a model in which reliability is expected.</li> <li>stability is a must-have when drawing interpretations from a certain model</li> <li>Trustworthy interpretations should not be produced by models that are not stable.</li> <li>Hence, an explainable model should contain information about the confidence of its working regime.</li> </ul>"},{"location":"KB/Confirmation%20Bias/","title":"Confirmation Bias","text":""},{"location":"KB/Confirmation%20Bias/#confirmation-bias","title":"Confirmation Bias","text":"<ul> <li>fairness</li> <li>The tendency to search for, interpret, favor, and [recall] information in a way that confirms one's preexisting beliefs or hypotheses. Machine learning developers may inadvertently collect or label data in ways that influence an outcome supporting their existing beliefs. Confirmation bias is a form of implicit bias.</li> <li>Experimenter's bias is a form of confirmation bias in which an experimenter continues training models until a preexisting hypothesis is confirmed.</li> <li> </li> <li>Using a dataset not gathered scientifically in order to run quick experiments. Later on, it's essential to switch to a scientifically gathered dataset</li> <li> </li> <li>The process of using mathematical techniques such as gradient descent to find the minimum of a convex function. A great deal of research in machine learning has focused on formulating various problems as convex optimization problems and in solving those problems more efficiently.</li> </ul>"},{"location":"KB/Confirmation%20Bias/#convenience-sampling","title":"convenience sampling","text":""},{"location":"KB/Confirmation%20Bias/#convex-optimization","title":"convex optimization","text":""},{"location":"KB/Conformer/","title":"Conformer","text":""},{"location":"KB/Conformer/#conformer","title":"Conformer","text":"<ul> <li>Conformer: Convolution-augmented Transformer for Speech Recognition</li> <li>Transformer models are good at capturing content-based global interactions, while CNNs exploit local features effectively</li> <li>integrating components from both CNNs and Transformers for end-to-end speech recognition to model both local and global dependencies of an audio sequence in a parameter-efficient way</li> <li>importance of each component, and demonstrated that the inclusion of convolution modules is critical to the performance of the Conformer model</li> <li>propose the convolution-augmented transformer for speech recognition, named Conformer</li> <li>LibriSpeech</li> </ul>"},{"location":"KB/Confusion%20Matrix/","title":"Confusion Matrix","text":""},{"location":"KB/Confusion%20Matrix/#confusion-matrix","title":"Confusion Matrix","text":"<ul> <li>Measures the test performance of a classification system on a per-class basis by indicating the number of samples of actual class\u00a0a\u00a0predicted as class\u00a0b.</li> <li>The rows relate to the actual class labels\u00a0a\u00a0and the columns to the predicted class labels\u00a0b.</li> </ul>"},{"location":"KB/Connectionism/","title":"Connectionism","text":""},{"location":"KB/Connectionism/#connectionism","title":"Connectionism","text":"<ul> <li>So called symbols like noun, verb or noun-phrase are just epiphenomenal misunderstandings we have of learned through network arrangements of non-linguistic primitive elements</li> </ul>"},{"location":"KB/Connectionist%20Networks/","title":"Connectionist Networks","text":""},{"location":"KB/Connectionist%20Networks/#connectionist-networks","title":"Connectionist Networks","text":"<ul> <li>Intelligence 'emerges' through the changes in the connections (weights)</li> <li>Basically deep learning</li> </ul>"},{"location":"KB/Connectives/","title":"Connectives","text":""},{"location":"KB/Connectives/#connectives","title":"Connectives","text":"<ul> <li>connect words, phrases (and, but, when)</li> </ul>"},{"location":"KB/Connectome/","title":"Connectome","text":""},{"location":"KB/Connectome/#connectome","title":"Connectome","text":"<ul> <li>the graph of how neurons in a brain connect</li> </ul>"},{"location":"KB/Connectome/#connectome_1","title":"Connectome","text":""},{"location":"KB/Consequentialist%20ethics/","title":"Consequentialist ethics","text":""},{"location":"KB/Consequentialist%20ethics/#consequentialist-ethics","title":"Consequentialist Ethics","text":"<ul> <li>an agent is ethical if and only if it weighs the consequences of each choice and chooses the option which has the most moral outcomes</li> </ul>"},{"location":"KB/Conservation%20Of%20Momentum/","title":"Conservation Of Momentum","text":""},{"location":"KB/Conservation%20Of%20Momentum/#conservation-of-momentum","title":"Conservation Of Momentum","text":"<ul> <li> \\[\\Sigma p_{i}= \\Sigma p _{f}\\] </li> <li> \\[m_{1}u_{1}+m_{2}u_{2}= m_{1}v_{1}+ m_{2}v_{2}\\] </li> <li>p is momentum</li> <li>v and d are velocity</li> <li>m is mass</li> </ul>"},{"location":"KB/Contact%20Sensor/","title":"Contact Sensor","text":""},{"location":"KB/Contact%20Sensor/#contact-sensor","title":"Contact Sensor","text":"<ul> <li>A device that detects the presence of an object or measures the amount of applied force or torque applied on the object through physical contact with it. Contact sensing can be used to determine location, identity, and orientation of work pieces.</li> </ul>"},{"location":"KB/Content%20Based%20Attention/","title":"Content Based Attention","text":""},{"location":"KB/Content%20Based%20Attention/#content-based-attention","title":"Content Based Attention","text":"<ul> <li>Graves2014</li> <li>Attention Alignment score \\(score(s_{t}, h_{i}) = cosine[s_{t}, h_{i}]\\)$</li> </ul>"},{"location":"KB/Content%20Based%20Recommender/","title":"Content Based Recommender","text":""},{"location":"KB/Content%20Based%20Recommender/#content-based-recommender","title":"Content Based Recommender","text":"<ul> <li>User actions linked to content</li> <li>User model rep as info context</li> <li>eg: Google</li> </ul>"},{"location":"KB/Content%20Morpheme/","title":"Content Morpheme","text":""},{"location":"KB/Content%20Morpheme/#content-morpheme","title":"Content Morpheme","text":"<ul> <li>carry some semantic content</li> <li>e.g. able, un, van</li> </ul>"},{"location":"KB/Content%20words/","title":"Content words","text":""},{"location":"KB/Content%20words/#content-words","title":"Content Words","text":"<ul> <li>Identifies part of a word</li> <li>Noun</li> <li>Adjective</li> <li>Verb</li> <li>Adverb</li> </ul>"},{"location":"KB/Context%20Free%20Grammar/","title":"Context Free Grammar","text":""},{"location":"KB/Context%20Free%20Grammar/#context-free-grammar","title":"Context Free Grammar","text":"<ul> <li>formal system that describes a language by specifying how any legal text can be derived from a distinguished symbol called the axiom, or sentence symbol.</li> <li>It consists of a set of productions, each of which states that a given symbol can be replaced by a given sequence of symbols</li> <li>Types of Words</li> <li></li> <li></li> <li>Top Down Parsing</li> <li>Bottom Up Parsing</li> </ul>"},{"location":"KB/Context%20Similarity/","title":"Context Similarity","text":""},{"location":"KB/Context%20Similarity/#context-similarity","title":"Context Similarity","text":"<ul> <li>between image patches </li> <li>image clusteringbased methods </li> <li>graph constraint-based methods</li> </ul>"},{"location":"KB/Continous%20-%3E%20Discrete/","title":"Continous -> Discrete","text":""},{"location":"KB/Continous%20-%3E%20Discrete/#continous-discrete","title":"Continous -&gt; Discrete","text":""},{"location":"KB/Continous%20-%3E%20Discrete/#binning","title":"Binning","text":""},{"location":"KB/Continous%20-%3E%20Discrete/#hierarchial-refinement","title":"Hierarchial Refinement","text":""},{"location":"KB/Continous%20-%3E%20Discrete/#vector-quantization","title":"Vector Quantization","text":""},{"location":"KB/Continous%20-%3E%20Discrete/#neural-dynamics","title":"Neural Dynamics","text":""},{"location":"KB/Continuous%20Path/","title":"Continuous Path","text":""},{"location":"KB/Continuous%20Path/#continuous-path","title":"Continuous Path","text":"<ul> <li>Describes the process where by a robot is controlled over the entire path traversed, as opposed to a point-to-point method of traversal. This is used when the trajectory of the end-effector is most important to provide a smooth movement, such as in spray painting etc</li> </ul>"},{"location":"KB/Contour/","title":"Contour","text":""},{"location":"KB/Contour/#contours","title":"Contours","text":"<ul> <li>For nD \\(\\(\\{x \\in \\mathbb{R}^{n}|f(x)=c\\}\\)\\)</li> <li>Always closed curves</li> <li>Never self instersect</li> <li>Nested</li> <li>Contours cut the plane into values smaller or larger than the isovalue c</li> <li>Isoline</li> <li>Isosurface</li> <li>Countouring with Transparency</li> </ul>"},{"location":"KB/Contrastive%20Loss/","title":"Contrastive Loss","text":""},{"location":"KB/Contrastive%20Loss/#contrastive-loss","title":"Contrastive Loss","text":"<ul> <li>Minimize distance between similar inputs Gradient Descent gradients, maximize between dissimilar Gradient Ascent</li> <li>Learn Embedding/Feature space using neighbors</li> <li>dim(Embedding d) &lt; dim(input Space D)</li> <li>Encoded using a learnable function(NN) \\(\\(G_\\theta(x) : \\mathcal{R}^D \\rightarrow \\mathcal{R}^d\\)\\)</li> <li>Binary labels : similar or not</li> <li>$\\(D_\\theta(x_1, x_2) = ||G_\\theta(x_1) - G_\\theta(x_2)||_2\\)</li> <li> \\[L(\\theta, y, x_1, x_2) = \\frac{(1-y)(D_\\theta(x_1, x_2))^2}{2} + \\frac{y(max(0,m-D\\theta(x_1, x_2)))^2}{2}\\] <ul> <li>m is enforced margin between similar and dissimilar (m&gt;0)</li> <li>Labeled points \\(\\((y,x_1,x_2)\\)\\) are generated</li> </ul> </li> </ul>"},{"location":"KB/Contrastive%20Predictive%20Coding/","title":"Contrastive Predictive Coding","text":""},{"location":"KB/Contrastive%20Predictive%20Coding/#contrastive-predictive-coding","title":"Contrastive Predictive Coding","text":"<ul> <li>Representation Learning with Contrastive Predictive Coding</li> <li>Contrastive Predictive Coding</li> <li>framework for extracting compact latent representations to encode predictions over future observations</li> <li>learn such representations by predicting the future in latent space by using powerful autoregressive models</li> <li>probabilistic contrastive loss based on NCE, which both the encoder and autoregressive model are trained to jointly optimize, which they call InfoNCE</li> <li>InfoNCE induces the latent space to capture information that is maximally useful to predict future samples</li> <li>combines autoregressive modeling and noise-contrastive estimation with intuitions from predictive coding to learn abstract representations in an unsupervised fashion</li> <li>negative sampling</li> </ul>"},{"location":"KB/Contributions%20of%20Shape%2C%20Texture%2C%20and%20Color%20in%20Visual%20Recognition%20Abstract/","title":"Contributions of Shape, Texture, and Color in Visual Recognition Abstract","text":""},{"location":"KB/Contributions%20of%20Shape%2C%20Texture%2C%20and%20Color%20in%20Visual%20Recognition%20Abstract/#contributions-of-shape-texture-and-color-in-visual-recognition-abstract","title":"Contributions of Shape, Texture, and Color in Visual Recognition Abstract","text":"<ul> <li>/zotero</li> <li>Yunhao Ge, Yao Xiao, Zhi Xu, Xingrui Wang, and Laurent Itti   <code>toc</code></li> </ul>"},{"location":"KB/Contributions%20of%20Shape%2C%20Texture%2C%20and%20Color%20in%20Visual%20Recognition%20Abstract/#abstract","title":"Abstract","text":"<ul> <li>humanoid vision engine (HVE) that explicitly and separately computes shape, texture, and color features from images</li> <li>resulting feature vectors are then concatenated to support the final classification</li> <li>HVE can summarize and rankorder the contributions of the three features to object recognition.</li> <li>We use human experiments to confirm that both HVE and humans predominantly use some specific features to support the classification of specific classes</li> <li>To demonstrate more usefulness of HVE, we use it to simulate the open-world zeroshot learning ability of humans with no attribute labeling</li> <li>Finally, we show that HVE can also simulate human imagination ability with the combination of different features.</li> </ul>"},{"location":"KB/Contributions%20of%20Shape%2C%20Texture%2C%20and%20Color%20in%20Visual%20Recognition%20Abstract/#introduction","title":"Introduction","text":"<ul> <li>A widely accepted intuition about the success of CNNs on perceptual tasks is that CNNs are the most predictive models for the human ventral stream object recognition</li> <li>To understand which feature is more important for CNN-based recognition, recent paper shows promising results: ImageNet-trained CNNs are biased towards texture while increasing shape bias improves accuracy and robustness [33]</li> <li>Here, inspired by HVS, we wish to find a general way to understand how shape, texture, and color contribute to a recognition task by pure data-driven learning.</li> <li>It has been shown by neuroscientists that there are separate neural pathways to process these different visual features in primate</li> <li>Among the many kinds of features crucial to visual recognition in humans, the shape property is the one that we primarily rely on in static object recognition [16]. Meanwhile, some previous studies show that surface-based cues also play a key role in our vision system</li> <li>For example, [21] shows that scene recognition is faster for color images compared with grayscale ones</li> <li>Humanoid Vision Engine</li> </ul>"},{"location":"KB/Contributions%20of%20Shape%2C%20Texture%2C%20and%20Color%20in%20Visual%20Recognition%20Abstract/#image-parsing-and-foreground-identification","title":"Image Parsing and Foreground Identification.","text":"<ul> <li>we use the entity segmentation method [41] to simulate the process of parsing objects from a scene in our brain.</li> <li>Entity segmentation is an open-world model and can segment the object from the image without labels.</li> <li>This method aligns with human behavior, which can (at least in some cases; e.g., autostereograms [29]) segment an object without deciding what it is</li> <li>After we get the segmentation of the image, we use a pre-trained CNN and Grad-CAM [47] to find the foreground object among all masks.</li> <li>We design three different feature extractors after identifying the foreground object segment: shape extractor, texture extractor, and color extractor, similar to the separate neural pathways in the human brain which focus on specific property</li> </ul>"},{"location":"KB/Contributions%20of%20Shape%2C%20Texture%2C%20and%20Color%20in%20Visual%20Recognition%20Abstract/#shape-feature-extractor","title":"Shape Feature Extractor","text":"<ul> <li>want to keep both 2D and 3D shape information while eliminating the information of texture and color</li> <li>first use a 3D depth prediction model [44,43] to obtain the 3D depth information of the whole image</li> <li>After element-wise multiplying the 3D depth estimation and 2D mask of the object, we obtain our shape feature</li> <li>We can notice that this feature only contains 2D shape and 3D structural information (the 3D depth) and without color or texture information</li> </ul>"},{"location":"KB/Contributions%20of%20Shape%2C%20Texture%2C%20and%20Color%20in%20Visual%20Recognition%20Abstract/#texture-feature-extractor","title":"Texture Feature Extractor","text":"<ul> <li>want to keep both local and global texture information while eliminating shape and color information.</li> <li>to remove the color information, we convert the RGB object segmentation to a grayscale image</li> <li>cut this image into several square patches with an adaptive strategy (the patch size and location are adaptive with object sizes to cover more texture information)</li> <li>If the overlap ratio between the patch and the original 2D object segment is larger than a threshold \u03c4, we add that patch to a patch pool (we set \u03c4 to be 0.99 in our experiments, which means the over 99% of the area of the patch belongs to the object</li> <li>Since we want to extract both local (one patch) and global (whole image) texture information, we randomly select 4 patches from the patch pool and concatenate them into a new texture image</li> </ul>"},{"location":"KB/Contributions%20of%20Shape%2C%20Texture%2C%20and%20Color%20in%20Visual%20Recognition%20Abstract/#color-feature-extractor","title":"Color Feature Extractor","text":"<ul> <li>The first method is phase scrambling</li> </ul>"},{"location":"KB/Contributions%20of%20Shape%2C%20Texture%2C%20and%20Color%20in%20Visual%20Recognition%20Abstract/#phase-scrambling","title":"Phase Scrambling","text":"<ul> <li>transforms the image into the frequency domain using the fast Fourier transform (FFT)</li> <li>In the frequency domain, the phase of the signal is then randomly scrambled, which destroys shape information while preserving color statistics</li> <li>Then we use IFFT to transfer back to image space</li> <li>We also used simple color histograms (see suppl.) as an alternative, but the results were not as good, hence we focus here on the phase scrambling approach for color representation.</li> </ul>"},{"location":"KB/Contributions%20of%20Shape%2C%20Texture%2C%20and%20Color%20in%20Visual%20Recognition%20Abstract/#humanoid-neural-network","title":"Humanoid Neural Network","text":"<ul> <li>After preprocessing, we have three features</li> <li>To simulate the separate neural pathways in humans' brains for different feature information [1,11], we design three feature representation encoders for shape, texture, and color, respectively</li> <li>ResNet-18 [24] as the backbone for all feature encoders to project the three types of features to the corresponding well-separated embedding spaces.</li> <li>hard to define the ground-truth label of the distance between features.</li> <li>Given that the objects from the same class are relatively consistent in shape, texture, and color, the encoders can be trained in the classification problem independently instead, with the supervision of class labels.</li> <li>fter training our encoders as classifiers, the feature map of the last convolutional layer will serve as the final feature representation</li> <li>We also propose a gradient-based contribution attribution method to interpret the contributions of shape, texture, and color to the classification decision,</li> <li>Take the shape feature as an example, given a prediction p and the probability of</li> <li>class k, namely pk, we compute the gradient of pk with respect to the shape feature Vs</li> <li>gradient as shape importance weights \u21b5sk</li> <li>In other words, Ssk represents the \"contribution\" of shape feature to classifying this</li> <li>image as class k</li> </ul>"},{"location":"KB/Contributions%20of%20Shape%2C%20Texture%2C%20and%20Color%20in%20Visual%20Recognition%20Abstract/#effectiveness-of-feature-encoders","title":"Effectiveness of Feature Encoders","text":"<ul> <li>handcrafted three subsets of ImageNet</li> <li>Shape-biased dataset containing 12 classes, where the classes were chosen which intuitively are strongly determined by shape</li> <li>Texture-biased dataset uses 14 classes which we believed are more strongly determined by texture</li> <li>Color-biased dataset includes 17 classes</li> <li>After pre-processing the original images and getting their feature images, we input the feature images into feature encoders and get the T-SNE</li> <li>Each row represents one feature-biased dataset and each column is bounded with one feature encoder, each image shows the results of one combination</li> </ul>"},{"location":"KB/Contributions%20of%20Shape%2C%20Texture%2C%20and%20Color%20in%20Visual%20Recognition%20Abstract/#effectiveness-of-humanoid-neural-network","title":"Effectiveness of Humanoid Neural Network","text":"<ul> <li>As these classifiers classify images based on corresponding feature representation, we call them feature nets.</li> <li>If we combine these three feature nets with the interpretable aggregation module, the classification accuracy is very close to the upper bound, which means our vision system can classify images based on these three features almost as well as based on the full original color images.</li> </ul>"},{"location":"KB/Contributions%20of%20Shape%2C%20Texture%2C%20and%20Color%20in%20Visual%20Recognition%20Abstract/#more-humanoid-applications-with-hve-open-world-zero-shot-learning-with-hve","title":"More Humanoid Applications with HVE Open-world Zero-shot Learning with HVE","text":"<ul> <li>Most current methods [37,32,13] need humans to provide detailed attribute labels for each image, which is costly in time and energy. However, given an image from an unseen class, humans can still describe it with their learned knowledge</li> <li>First, to represent learnt knowledge, we use feature extractors</li> <li>To retrieve learnt classes as description, we calculate the average distance dkm</li> <li>between Iun and images of other class k in the latent space on feature m Open-world classification</li> <li>To further predict the actual class of Iun based on the feature-wise description, we use ConceptNet as common knowledge to conduct reasoning</li> <li>We form a reasoning root pool R\u21e4 consisting of feature roots Rs, Rt, Rc obtained during image description, and shared attribute roots Ras , Rat , Rac . The reasoning roots will be our evidence for reasoning</li> <li>We humans can intuitively imagine an object when seeing one aspect of a feature, especially when this feature is prototypical (contribute most to classification)</li> <li>For instance, we can imagine a zebra when seeing its stripe (texture). This process is similar but harder than the classical image generation task since the input features modality here dynamic which can be any feature among shape, texture, or color</li> </ul>"},{"location":"KB/Contributions%20of%20Shape%2C%20Texture%2C%20and%20Color%20in%20Visual%20Recognition%20Abstract/#cross-feature-retrieval","title":"Cross Feature Retrieval","text":"<ul> <li>In order to reasonably retrieve the most possible other two corresponding features given only one feature (among shape, texture, or color), we learn a feature agnostic encoder that projects the three features into one same feature space and makes sure that the features belonging to the same class are in the nearby regions.</li> <li>In the retrieval process, given any feature of any object, we can map it into the cross feature embedding space by the corresponding encoder net and the feature agnostic net</li> <li>Then we apply the 2 norm to find the other two features closest to the input one as output. The output is correct if they belong to the same class as the input.</li> </ul>"},{"location":"KB/Contributions%20of%20Shape%2C%20Texture%2C%20and%20Color%20in%20Visual%20Recognition%20Abstract/#cross-feature-imagination","title":"Cross Feature Imagination","text":"<ul> <li>To stimulate imagination, we propose a crossfeature imagination model to generate a plausible final image with the input and retrieved features</li> <li>Inspired by the pixel2pixel GAN[26] and AdaIN[25] in the style transfer, we design a crossfeature pixel2pixel GAN model to generate the final image.</li> </ul>"},{"location":"KB/Contributions%20of%20Shape%2C%20Texture%2C%20and%20Color%20in%20Visual%20Recognition%20Abstract/#pictures","title":"Pictures","text":""},{"location":"KB/Conv%20Based%20Noise%20Reduction/","title":"Conv Based Noise Reduction","text":""},{"location":"KB/Conv%20Based%20Noise%20Reduction/#conv-based-noise-reduction","title":"Conv Based Noise Reduction","text":"<ul> <li>Noise is high frequency component, suppress via low-pass filters</li> <li>Ideal low-pass filter</li> <li>multiply with box filter in frequency domain</li> <li>convolution with sinc in spatial domain (impractical: infinite extent)</li> <li></li> <li></li> <li>Spatially narrow (wide) filter has wide (narrow) spectrum and low (high) smoothing effect</li> </ul>"},{"location":"KB/Conv/","title":"Convnd","text":""},{"location":"KB/Conv/#convnd","title":"Convnd","text":"<ul> <li> \\[A\\ast B\\] </li> <li>Connect a neighbor only to spatial neighborhood -&gt; spatial order<ul> <li>Some rotation and illumination invariance</li> </ul> </li> <li>Slide over -&gt; Same weights independant of location -&gt; less weights</li> <li>Subsample after conv</li> <li>multiple 2d feature maps</li> <li>Similar to Gabor filters after learning</li> <li>Some might collapse to 0</li> <li> \\[out(x,y) = \\Sigma_i \\Sigma_j input(x+i, y+j) kernel(i,j)\\] </li> <li> \\[Z^j = \\Sigma_{i=0}^{l-1}W^{ji} \\ast X^i + b^{ij}\\] </li> <li> \\[Y^j = g(Z^j)\\] </li> <li>Output shape : (\\(\\frac{()_i-f+2p}{s}\\)\\)<ul> <li>If \\(\\(p = \\frac{f-1}{2}\\)\\) and \\(\\(s=1\\)\\) then dimensions maintained</li> </ul> </li> <li>One operation repeated over and over starting with raw</li> <li>Padded Conv</li> <li>Strided</li> <li>Depthwise Separable</li> <li>Causal 1D Conv</li> <li>Causal Dilated Conv</li> </ul>"},{"location":"KB/ConvBERT/","title":"ConvBERT","text":""},{"location":"KB/ConvBERT/#convbert","title":"ConvBERT","text":"<ul> <li>Convolutional BERT (ConvBERT) improves the original BERT by replacing some Multi Head Attention Self Attention segments with cheaper and naturally local operations, so-called span-based dynamic convolutions. These are integrated into the self-attention mechanism to form a mixed attention mechanism, allowing Multi-headed Self-attention to capture global patterns; the Convolutions focus more on the local patterns, which are otherwise captured anyway. In other words, they reduce the computational intensity of training BERT.</li> </ul>"},{"location":"KB/ConvNeXt/","title":"ConvNeXt","text":""},{"location":"KB/ConvNeXt/#convnext","title":"ConvNeXt","text":"<ul> <li>@liuConvNet2020s2022</li> <li>modifying a standard Res Net , following design choices closely inspired by Vision Transformer</li> <li>A vanilla ViT, on the other hand, faces difficulties when applied to general computer vision tasks such as object detection and semantic segmentation</li> <li>hierarchical Transformers (e.g., Swin Transformer ) that reintroduced several Conv priors, making Transformers practically viable as a generic vision backbone</li> <li>effectiveness of such hybrid approaches is still largely credited to the intrinsic superiority of Transformers, rather than the inherent inductive biases of convolutions</li> <li>extending the number of epochs, using AdamW optimizer, Stochastic Depth, Label Smoothing</li> <li>number of blocks in each stage (stage compute ratio), which was adjusted from (4, 4, 6, 3) to (3, 3, 9, 3)</li> <li>The second is the stem cell configuration, which in the original ResNet consisted of 7\u00d77 convolutions with stride 2 followed by a max-Pooling layer. This was substituted by a more Transformer-like \u201cpatchify\u201d layer which utilizes 4\u00d74 non-overlapping convolutions with stride 4</li> <li>Depthwise Separable , which are interestingly similar to self-Attention as they work on a per-channel basis</li> <li>higher number of channels (from 64 to 96)</li> <li>Inverted Bottleneck: An essential configuration of Transformers is the expansion-compression rate in the MLP block (the hidden dimension is 4 times higher than the input and output dimension)</li> <li>input is expanded using 1 \\times 1 convolutions and then shrunk through depthwise convolution and 1 \\times 1 convolutions</li> <li>move the depthwise convolution before the convolution</li> <li>7 \\times 7 window (higher values did not bring any alterations in the results</li> <li>GELU instead of Relu , a single activation for each block (the original Transformer module has just one activation after the MLP), fewer normalization Layers, Batch Normalization substituted by Layer Normalization , and separate downsampling layer</li> <li>ImageNet</li> <li>COCO</li> <li>ADE20K</li> <li>A case in point is multi-modal learning, in which a cross-attention module may be preferable for modeling feature interactions across many modalities</li> <li>Transformers may be more flexible when used for tasks requiring discretized, sparse, or structured outputs</li> </ul>"},{"location":"KB/Convolutional%20RNN/","title":"Convolutional RNN","text":""},{"location":"KB/Convolutional%20RNN/#convolutional-rnn","title":"Convolutional RNN","text":"<ul> <li> \\[h_t = \\sigma_h(W_{hh}\\star h_{t-1} + W_{xh}\\star x_t + b_h)\\] </li> <li> \\[y_t = \\sigma_y(W_{hy}\\star h_t + b_y)\\] </li> <li>\\(\\(\\star\\)\\) is spatial Conv</li> <li>5D shapes -&gt; [samples, timesteps, width, height, channels]</li> <li>Very memory intensive</li> <li> \\[x^{2}+x\\] </li> </ul>"},{"location":"KB/Coping%20Theory/","title":"Coping Theory","text":""},{"location":"KB/Coping%20Theory/#coping-theory","title":"Coping Theory","text":"<ul> <li>[Marsella and Gratch, 2003]</li> <li>allow agents to deal with strong negative emotions by changing the appraisal of the given situation was proposed</li> <li>agent assesses the ethical effects of its own actions and other agents' actions</li> <li>If its own action violates a given moral value, the shame emotion is triggered which serves to lower the priority of continuing with the given action</li> <li>If another agent's action violates a given moral value, the reproach emotion is triggered in the observing agent which serves to increase social distance with the given agent</li> <li>similar to existing individual ethical decision frameworks implicit reward</li> <li>humans in the loop</li> </ul>"},{"location":"KB/Coronary%20Bypass/","title":"Coronary Bypass","text":""},{"location":"KB/Coronary%20Bypass/#coronary-bypass","title":"Coronary Bypass","text":"<ul> <li>Surgical transplant of a healthy blood vessel into the heart to bypass or replace an unhealthy vessel</li> </ul>"},{"location":"KB/Corpus%20callosum/","title":"Corpus callosum","text":""},{"location":"KB/Corpus%20callosum/#corpus-callosum","title":"Corpus Callosum","text":"<ul> <li>bundle of fibers that transmits messages from one side to the other</li> </ul>"},{"location":"KB/Corpus%20dependence/","title":"Corpus dependence","text":""},{"location":"KB/Corpus%20dependence/#corpus-dependence","title":"Corpus Dependence","text":"<ul> <li>Misspellings</li> <li>Erroneous Punctuations and Spacing</li> <li>Difficult to write rules to govern the corpora from the Internet</li> <li>Di\ufb03cult to prescribe rules governing the use of a written language</li> <li>Punctuations mean \u2013 Suprasegmentals in Spoken Language but might not be the same for corpora</li> <li>Algorithms may expect corpora need to obey some rules</li> </ul>"},{"location":"KB/Correlation/","title":"Correlation","text":"<p>toc: true title: Correlation</p> <p>categories: ['temp']</p>"},{"location":"KB/Correlation/#correlation","title":"Correlation","text":"<ul> <li>How strong a relationship is between data.</li> <li>The formulas return a value between -1 and 1, where:<ul> <li>1 indicates a strong positive relationship.</li> <li>-1 indicates a strong negative relationship.</li> <li>A result of zero indicates no relationship at all.</li> <li></li> </ul> </li> </ul>"},{"location":"KB/Cortical%20Homunculus/","title":"Cortical Homunculus","text":""},{"location":"KB/Cortical%20Homunculus/#cortical-homunculus","title":"Cortical Homunculus","text":""},{"location":"KB/Cortisol/","title":"Cortisol","text":""},{"location":"KB/Cortisol/#cortisol","title":"Cortisol","text":"<ul> <li>A steroid hormone produced by the adrenal glands that controls how the body uses fat, protein, carbohydrates, and minerals, and helps reduce inflammation. Cortisol is released in the body\u2019s stress response; scientists have found that prolonged exposure to cortisol has damaging effects on the brain</li> </ul>"},{"location":"KB/Cosine%20Distance/","title":"Cosine Distance","text":""},{"location":"KB/Cosine%20Distance/#cosine-distance","title":"Cosine Distance","text":"<ul> <li>Complement of Cosine Similarity</li> <li> \\[D_{c}(A,B) := 1- S_{c}(A,B)\\] </li> </ul>"},{"location":"KB/Cosine%20Learning%20Rate%20Decay/","title":"Cosine Learning Rate Decay","text":""},{"location":"KB/Cosine%20Learning%20Rate%20Decay/#cosine-learning-rate-decay","title":"Cosine Learning Rate Decay","text":"<ul> <li>Instead of Learning Rate Warmup and then decay</li> <li> \\[\\eta_{\\mathrm{t}}=\\frac{1}{2}\\left(1+\\cos\\left(\\frac{\\mathrm{t}\\pi}{\\mathrm{\\mathrm{T}}}\\right)\\right)\\eta\\] </li> <li>Rate decreases slowly at first, then almost linear in the middle and slows down again in the end</li> <li></li> </ul>"},{"location":"KB/Cosine%20Similarity/","title":"Cosine Similarity","text":""},{"location":"KB/Cosine%20Similarity/#cosine-similarity","title":"Cosine Similarity","text":"<ul> <li>Lp Regularization l2norm aka p = 2</li> <li> \\[S_{c}(A,B) := cos(\\theta) = \\frac{A\\cdot B}{||A|| ||B||} = \\frac{\\Sigma_{i=1}^{n}A_{i}B_{i}}{\\sqrt{\\Sigma_{i=1}^{n}A^{2}_{i}} \\sqrt{\\Sigma_{i=1}^{n}B_{i}^{2}}}\\] </li> <li>ranges from -1 : exactly opposite, 1 : exactly same, 0: orthogonal/not correlated, intermediate</li> <li>Cosine Distance</li> <li>Cosine similarity is $$ - \\mathrm{sum}\\left( \\mathrm{l2norm}\\left( y \\right) \\cdot \\mathrm{l2norm}\\left( \u0177 \\right) \\right)$$</li> <li></li> <li>magnitude of vectors is not taken into account, merely their direction</li> <li>In practice, this means that the differences in values are not fully taken into account</li> <li>If you take a recommender system, for example, then the cosine similarity does not take into account the difference in rating scale between different users</li> <li>high-dimensional data and when the magnitude of the vectors is not of importance</li> </ul>"},{"location":"KB/Counterfactual%20Fairness/","title":"Counterfactual Fairness","text":""},{"location":"KB/Counterfactual%20Fairness/#counterfactual-fairness","title":"Counterfactual Fairness","text":"<ul> <li>A fairness metric that checks whether a classifier produces the same result for one individual as it does for another individual who is identical to the first, except with respect to one or more sensitive attributes. Evaluating a classifier for counterfactual fairness is one method for surfacing potential sources of bias in a model.</li> <li>See \"When Worlds Collide Integrating Different Counterfactual Assumptions in Fairness\" for a more detailed discussion of counterfactual fairness.</li> </ul>"},{"location":"KB/Counterfactual%20Images/","title":"Counterfactual Images","text":""},{"location":"KB/Counterfactual%20Images/#counterfactual-images","title":"Counterfactual Images","text":"<ul> <li>Concepts in images, removing which would increment networks confidence about the target (aka competing class)</li> </ul>"},{"location":"KB/Counterfactual%20Impact%20Evaluation/","title":"Counterfactual Impact Evaluation","text":""},{"location":"KB/Counterfactual%20Impact%20Evaluation/#counterfactual-impact-evaluation","title":"Counterfactual Impact Evaluation","text":"<ul> <li>local method of comparison for different predictions. Counterfactuals are contrastive. They explain why a decision was made instead of another. A counterfactual explanation of a prediction may be defined as the smallest change to the feature values that changes the prediction to a predefined output.</li> </ul>"},{"location":"KB/Countouring%20with%20Transparency/","title":"Countouring with Transparency","text":""},{"location":"KB/Countouring%20with%20Transparency/#countouring-with-transparency","title":"Countouring with Transparency","text":"<ul> <li>draw several contours for several isovalues</li> <li>assign \u201cadequate\u201d transparency</li> </ul>"},{"location":"KB/Covariance/","title":"Covariance","text":"<p>toc: true title: Covariance</p> <p>categories: ['temp']</p>"},{"location":"KB/Covariance/#covariance","title":"Covariance","text":"<ul> <li>how much two\u00a0random variables\u00a0vary together</li> <li></li> <li> \\[Cov(X,Y) = \\frac{\\Sigma(x_{i}- \\bar x)(y_{i}- \\bar y)}{N-1}\\] </li> <li>\\(\\bar x\\) is the mean of x</li> </ul>"},{"location":"KB/Coverage%20Bias/","title":"Coverage Bias","text":""},{"location":"KB/Coverage%20Bias/#coverage-bias","title":"Coverage Bias","text":"<ul> <li>The population represented in the dataset does not match the population that the machine learning model is making predictions about.</li> </ul>"},{"location":"KB/Coverage%20of%20ethics%20within%20the%20artificial%20intelligence%20and%20machine%20learning%20academic%20literature/","title":"Coverage of ethics within the artificial intelligence and machine learning academic literature","text":""},{"location":"KB/Coverage%20of%20ethics%20within%20the%20artificial%20intelligence%20and%20machine%20learning%20academic%20literature/#coverage-of-ethics-within-the-artificial-intelligence-and-machine-learning-academic-literature","title":"Coverage of ethics within the artificial intelligence and machine learning academic literature","text":"<ul> <li>Lillywhite, Aspen; Wolbring, Gregor</li> </ul>"},{"location":"KB/Coverage%20of%20ethics%20within%20the%20artificial%20intelligence%20and%20machine%20learning%20academic%20literature/#abstract","title":"Abstract","text":"<ul> <li>Disabled people are often the anticipated users of scientific and technological products and processes advanced and enabled by artificial intelligence</li> <li>also impacted by societal impacts of AI/ML</li> <li>problems have been identified in how ethics discourses engage with disabled people</li> <li>Of the n = 1659 abstracts engaging with AI/ML and ethics downloaded from Scopus (which includes all Medline articles) and the 70 databases of EBSCO ALL, we found 54 relevant abstracts using the term \"patient\" and 11 relevant abstracts mentioning terms linked to \"impair\", \"disab\" and \"deaf\"</li> </ul>"},{"location":"KB/Coverage%20of%20ethics%20within%20the%20artificial%20intelligence%20and%20machine%20learning%20academic%20literature/#study-design","title":"Study design","text":"<ul> <li>We used a modified scoping review drawing from (Arksey &amp; O'Malley, 2005) as the most appropriate approach for the study given the aim of our study</li> <li>Scoping studies \"map rapidly the key concepts underpinning a research area\" (Arksey &amp; O'Malley, 2005, p. 21), to identify the extent of research conducted on a given topic (Davis, Drey, &amp; Gould, 2009; Grant &amp; Booth, 2009) and the current understanding of a given topic (S. Anderson, Allen, Peckham, &amp; Goodwin, 2008).</li> </ul>"},{"location":"KB/Coverage%20of%20ethics%20within%20the%20artificial%20intelligence%20and%20machine%20learning%20academic%20literature/#data-sources","title":"Data sources","text":"<ul> <li>EBSCO ALL, an umbrella database that includes over 70 other databases itself and Scopus, which incorporates the full Medline database collection</li> <li>The first article with the term \"ethic*\" and any of the AI terms within the EBSCO databases was published in 1981, while the first article within Scopus was published in 1962</li> </ul>"},{"location":"KB/Coverage%20of%20ethics%20within%20the%20artificial%20intelligence%20and%20machine%20learning%20academic%20literature/#limitation","title":"Limitation","text":"<ul> <li>Our findings also do not cover all words one could use to depict disabled people and as such, our results can not be generalized to every disability term</li> </ul>"},{"location":"KB/Coverage%20of%20ethics%20within%20the%20artificial%20intelligence%20and%20machine%20learning%20academic%20literature/#discussion","title":"Discussion","text":"<ul> <li>Many ethics issues pertinent to disabled people were discussed within the abstracts; for example the ethical decision making of robots but without engaging with disabled people.</li> <li>However, many barriers have been identified for disabled people to shape technology governance discussions in an anticipatory way</li> <li>including that the medical imagery of disabled people is seen to hinder their involvement in policy discussions (Wolbring, Mackay, Rybchinski, &amp; Noga, 2013)</li> <li>In one study, it is acknowledged that ethical, moral, social, cultural, and political issues have been traditionally de-emphasized in research guided by usability concerns (Fallman, 2010)</li> <li>Given the breadth of academic disciplines, including disability studies covered by the two databases, and given that we found only one article coming from a disability studies program based out of Bremen, Germany (Bruhn et al., 2006), it might be warranted to investigate how academics choose their topics of investigation and why the topics we found lacking in the literature were not chosen</li> <li>Another angle of investigation could be why students are not acting as knowledge producers on the topics we found lacking</li> <li>As to disabled students, based on a study that investigated the experience of disabled postsecondary students in postsecondary education (Hutcheon &amp; Wolbring, 2012) we suggest that the experience reported (feeling medicalized, hesitant to self-advocate, to try to fit in with the norm) might be factors that hinder disabled students to be knowledge producers especially on contentious issues such as ethics and disabled people</li> </ul>"},{"location":"KB/CowMask/","title":"CowMask","text":""},{"location":"KB/CowMask/#cowmask","title":"CowMask","text":"<ul> <li>@frenchMilkingCowMaskSemiSupervised2020</li> <li>semi-supervised learning</li> <li>original and augmented images are brought closer during training</li> <li>CowMask suggests two types of mixing approaches 1) erasing and 2) mixing two images similar to cutmix</li> <li>The mask here is of irregular shape rather than rectangular and generated by masking or keeping a proportion of image pixels through thresholding.</li> <li>Gaussian filter is applied to remove noise before thresholding.</li> <li>Pixel values below the threshold are either erased or replaced by the pixel values of the randomly selected image at the corresponding locations.</li> </ul>"},{"location":"KB/Crash%20Blossom/","title":"Crash Blossom","text":""},{"location":"KB/Crash%20Blossom/#crash-blossom","title":"Crash Blossom","text":"<ul> <li>A sentence or phrase with an ambiguous meaning. Crash blossoms present a significant problem in natural language understanding. For example, the headline Red Tape Holds Up Skyscraper is a crash blossom because an NLU model could interpret the headline literally or figuratively.</li> </ul>"},{"location":"KB/Critical%20Points/","title":"Critical Points","text":""},{"location":"KB/Critical%20Points/#critical-points","title":"Critical Points","text":"<ul> <li>sink (attracting node): all vectors converge  </li> <li>source (repelling node): all vectors diverge  </li> <li>saddle point: slopes are zero in orthogonal directions, no extremum \u2022 center point: embedded by (circular) flow around  </li> <li>attracting focus: flow is attracted in a spiral pattern</li> <li>repelling focus, where the flow is repelled in a spiral pattern</li> <li></li> </ul>"},{"location":"KB/Cropping/","title":"Cropping","text":""},{"location":"KB/Cropping/#cropping","title":"Cropping","text":"<ul> <li>Cropping images can be used as a practical processing step for image data with mixed height and width dimensions by cropping a central patch of each image</li> <li>Additionally, random cropping can also be used to provide an effect very similar to translations.</li> <li>whereas translations preserve the spatial dimensions of the image</li> <li>Depending on the reduction threshold chosen for cropping, this might not be a label-preserving transformation. Rotation</li> <li>Rotation augmentations are done by rotating the image right or left on an axis between 1\u00b0 and 359\u00b0</li> <li>The safety of rotation augmentations is heavily determined by the rotation degree parameter.</li> <li>as the rotation degree increases, the label of the data is no longer preserved post-transformation. Translation</li> <li>Shifting images left, right, up, or down can be a very useful transformation to avoid positional bias in the data</li> <li>For example, if all the images in a dataset are centered, which is common in face recognition datasets, this would require the model to be tested on perfectly centered images as well.</li> <li>remaining space can be filled with either a constant value such as 0 s or 255 s, or it can be filled with random or Gaussian noise</li> </ul>"},{"location":"KB/Cross%20Entropy/","title":"Cross Entropy","text":""},{"location":"KB/Cross%20Entropy/#cross-entropy","title":"Cross Entropy","text":"<ul> <li>Entropy</li> <li>Cross-entropy is a measure from the field of information theory, building upon entropy and generally calculating the difference between two Probability distributions.</li> <li>It is closely related to but is different from KL Divergence that calculates the relative entropy between two Probability distributions, whereas cross-entropy can be thought to calculate the total entropy between the distributions.</li> <li>implicit distribution $$ p(Y|x;\\theta) $$ -&gt; use CE</li> <li> \\[ \\mathscr{L}(\\theta) = -\\mathbb{E}_{(x,y) \\sim P(X,Y)} log (p_{model}(Y|x)) \\] <ul> <li>Categorical CE<ul> <li>Classification</li> <li>Labels should be One hot </li> <li> \\[ \\mathscr{L}(\\theta) = -\\mathbb{E}_{(x,y) \\sim P(X,Y)} \\Sigma_{i=1}^C 1(y=i)log (p_{model}f_i(x|\\theta)) \\] </li> <li>C is no of classes</li> <li> \\[ L(y, \\hat y) = - \\Sigma_{i}\\Sigma_{c}y_{i}^{c} log(\\hat y_{i}^{c}) \\] </li> </ul> </li> <li>MSE<ul> <li>Regression</li> <li> \\[ \\mathscr{L}(\\theta) = \\frac{1}{2}\\mathbb{E}_{(x,y) \\sim P(X,Y)}||y-f(x;\\theta)||^2 \\] </li> </ul> </li> </ul> </li> <li> <p>Binary Cross Entropy</p> </li> <li> <p>The Cross Entropy Loss function is a popular loss function that is used in multi-class image classification tasks. Derived from the field of information theory, it uses the concept of entropy to quantifies the discrepancy between two given probability distributions. The formula for computing the loss is given by $$ \\mathscr{l}(x,y) = L = {l_{1}, ..., l_{N}}^{T} $$ where $$ l_{n} = -w_{y_{n}}log \\frac{exp(x_{n, y_{n}})}{\\Sigma_{c=1}^{C}exp(x_{n,c})} $$, \\(x\\) is the input, \\(y\\) is the target, \\(C\\) is the number of classes</p> </li> </ul>"},{"location":"KB/Cross%20Minimization/","title":"Cross Minimization","text":""},{"location":"KB/Cross%20Minimization/#cross-minimization","title":"Cross Minimization","text":"<ul> <li>planar graph: can be drawn on a plane without edge crossings</li> <li>from Euler\u2019s formula - the maximum number of edges for planar graphs: \\(\\(e \\leq 3v-6\\)\\)</li> <li></li> </ul>"},{"location":"KB/Cross%20Modal%20Distillation/","title":"Cross Modal Distillation","text":""},{"location":"KB/Cross%20Modal%20Distillation/#cross-modal-distillation","title":"Cross Modal Distillation","text":"<ul> <li>Moreover, Do et al. (2019) proposed a knowledge distillation-based visual question answering method, in which knowledge from trilinear interaction teacher model with image-question-answer as inputs is distilled into the learning of a bilinear interaction student model with image-question as inputs</li> </ul>"},{"location":"KB/Cross%20Modal-based%20Methods/","title":"Cross Modal-based Methods","text":""},{"location":"KB/Cross%20Modal-based%20Methods/#cross-modal-based-methods","title":"Cross Modal-based Methods","text":"<ul> <li>train ConvNets to verify whether two different channels of input data are corresponding to each other </li> <li>Visual-Audio Correspondence Verification </li> <li>RGB-Flow Correspondence Verification </li> <li>egomotion</li> </ul>"},{"location":"KB/Cross%20Validation/","title":"Cross Validation","text":""},{"location":"KB/Cross%20Validation/#cross-validation","title":"Cross Validation","text":""},{"location":"KB/Cross%20Validation/#kfold","title":"KFold","text":"<ul> <li>Repeat for m = 1..L<ul> <li>Split data into roughly equal sizes. Disjoint subsets</li> <li>Get model with min Emperical Risk</li> <li>Test it with validation set</li> <li>Avg it for the folds for this value of m</li> </ul> </li> <li>Find optimal class for that m that had min avg validation risk (aka training error)</li> <li>Compute \\(h_{opt}\\) using the original training data</li> </ul>"},{"location":"KB/Cross%20Validation/#leave-one-out","title":"Leave One Out","text":"<ul> <li>Each D contains a single training example</li> <li>For tiny datasets</li> </ul>"},{"location":"KB/Cross%20angle%20Maximization/","title":"Cross angle Maximization","text":""},{"location":"KB/Cross%20angle%20Maximization/#cross-angle-maximization","title":"Cross Angle Maximization","text":"<ul> <li>avoid ambiguities</li> <li></li> </ul>"},{"location":"KB/Cross-dataset%20generalization/","title":"Cross-dataset generalization","text":""},{"location":"KB/Cross-dataset%20generalization/#cross-dataset-generalization","title":"Cross-dataset Generalization","text":"<ul> <li>virtually no papers demonstrating cross-dataset generalization, e.g. training on ImageNet, while testing on PASCAL VOC</li> <li>if our datasets were truly representative of the real world, this would be a very easy thing to do, and would give access to more of the much needed labelled data</li> <li>But from our perspective, all the datasets are really trying to represent the same domain \u2013 our visual world \u2013 and we would like to measure how well or badly they do it.</li> <li>Overall the results look rather depressing, as little generalization appears to be happening beyond the given dataset</li> </ul>"},{"location":"KB/Cross-situational%20learning/","title":"Cross-situational learning","text":""},{"location":"KB/Cross-situational%20learning/#cross-situational-learning","title":"Cross-situational Learning","text":"<ul> <li>Speakers 'take statistics' about word-concept co-occurrences</li> <li>Predicts gradual learning</li> </ul>"},{"location":"KB/Cuboids/","title":"Cuboids","text":""},{"location":"KB/Cuboids/#cuboids","title":"Cuboids","text":""},{"location":"KB/Cumulative%20Interpretation/","title":"Cumulative Interpretation","text":""},{"location":"KB/Cumulative%20Interpretation/#cumulative-interpretation","title":"Cumulative Interpretation","text":"<ul> <li>No scopal relation</li> <li>Three aliens are holding two flags.</li> </ul>"},{"location":"KB/Curl%20And%20Vorticity/","title":"Curl And Vorticity","text":""},{"location":"KB/Curl%20And%20Vorticity/#curl-and-vorticity","title":"Curl And Vorticity","text":"<ul> <li>Helmholtz Theorem</li> </ul>"},{"location":"KB/Curriculum%20Learning/","title":"Curriculum Learning","text":""},{"location":"KB/Curriculum%20Learning/#curriculum-learning","title":"Curriculum Learning","text":"<ul> <li>Formal Mathematics Statement Curriculum Learning</li> <li>neural theorem prover using GPT-f</li> <li>solve a curriculum of increasingly difficult problems out of a set of formal statements of sufficiently varied difficulty</li> <li>high-school Math Olympiad problems</li> <li>language model to find proofs of formal statements</li> <li>formal mathematics</li> <li>at same compute budget, expert iteration, by which they mean proof search interleaved with learning, dramatically outperforms proof search only</li> <li>expert iteration is capable of finding and solving a curriculum of increasingly difficult problems, without the need for associated ground-truth proofs</li> <li>miniF2F</li> <li>automatically solving multiple challenging problems drawn from high school olympiads</li> <li>lack of self-play in the formal mathematics setup can be effectively compensated for by automatically as well as manually curated sets of formal statement</li> <li>cheaper to formalize than full proofs</li> </ul>"},{"location":"KB/Curse%20Of%20Dimensionality/","title":"Curse of Dimensionality","text":""},{"location":"KB/Curse%20Of%20Dimensionality/#curse-of-dimensionality","title":"Curse of Dimensionality","text":"<ul> <li>In an n dim hypercube -&gt; greatest possible distance is \\(\\sqrt{n}\\)</li> <li>Aka the higher the dimension -&gt; wider the training points from each other</li> <li>But there are fewer data points than dimensions and the distances are huge</li> <li>Dimensionality Reduction</li> </ul>"},{"location":"KB/Cut%20and%20Delete/","title":"Cut and Delete","text":""},{"location":"KB/Cut%20and%20Delete/#cut-and-delete","title":"Cut and Delete","text":"<ul> <li>data augmentation by deleting image patches randomly or semantically.</li> <li>learn in case of occlusions</li> <li>This kind of [dropout] is different from conventional [dropout] because it drops contiguous image regions, whereas values in traditional dropout work at noncontiguous locations</li> </ul>"},{"location":"KB/Cut%20and%20Mix/","title":"Cut and Mix","text":""},{"location":"KB/Cut%20and%20Mix/#cut-and-mix","title":"Cut and Mix","text":"<ul> <li>@yunCutMixRegularizationStrategy2019</li> <li>instead of deleting a patch, the patch is replaced with some other image region</li> <li>y this approach, an image shares multiple class labels, whereas the major class label belongs to the original class label</li> <li>Hence, the model learns to differentiate between two classes within a single image.</li> <li>CutMix can be defined by the following operations \\(\\(\\overset{\\sim}x = M \\odot x_{A} + (1-M) \\odot x_{B}\\)\\)</li> <li> \\[\\overset{\\sim}y = \\lambda y_{A}+ (1- \\lambda)y_{B}\\] </li> <li>where \\(x\\) is an RGB image, \\(y\\) is the respective label, \\(M\\) is a binary mask of the patch of the image that will be dropped and \\(\\odot\\) represents element wise multiplication. The new training sample \\(\\overset{\\sim}x , \\overset{\\sim}y\\) is created by combining two other training samples \\(x_{A}, y_{A}\\) and \\(x_{B} , y_{B}\\). To control the combination ratio \\(\\lambda\\), a sample from the \\(\\beta(1,1)\\) distribution is chosen. This combination is quite similar to Mixup. </li> </ul>"},{"location":"KB/Cut%2C%20Paste%20and%20Learn/","title":"Cut, Paste and Learn","text":""},{"location":"KB/Cut%2C%20Paste%20and%20Learn/#cut-paste-and-learn","title":"Cut, Paste and Learn","text":"<ul> <li>@dwibediCutPasteLearn2017</li> <li>generates new data by extracting object instances and pasting them on randomly selected background images.</li> <li>Instances are blended with various blending approaches, for example, gaussian blurring and poison blending, to reduce pixel artifacts around the augmented object boundaries.</li> <li>Added instances are also rotated, oc- cluded, and truncated to make the learning algo- rithm robust.</li> </ul>"},{"location":"KB/CutMix/","title":"CutMix","text":""},{"location":"KB/CutMix/#cutmix","title":"CutMix","text":"<ul> <li>@yunCutMixRegularizationStrategy2019</li> <li>images are augmented by sampling patch coordinates, x, y, h, w from a uniform distribution</li> <li>selected patch is replaced at the</li> <li>corresponding location with a patch from the other randomly picked image from the current mini-batch during training.</li> <li>M is the image mask, xa and xb are images, \u03bb is the proportion of label, and ya and yb are the labels of images.</li> <li> \\[ x_{new}= M.x_{a}+(1-M).x_{b} \\] </li> <li> \\[ y_{new}= \\lambda.y_{a}+ (1-\\lambda).y_{b} \\] </li> </ul>"},{"location":"KB/Cutout/","title":"Cutout","text":""},{"location":"KB/Cutout/#cutout","title":"Cutout","text":"<ul> <li>@devriesImprovedRegularizationConvolutional2017</li> <li>removes constant size square patches randomly by replacing them with any constant value.</li> <li>The selection of region is performed by selecting a pixel value randomly and placing a square around it</li> <li>Cutout can be expressed as an element-wise multiplication operation \\(x_{cutout} = x \\odot M\\), where \\(x\\) is the original image, \\(M\\) is a binary mask of the same size as \\(x\\) with randomly chosen coordinates of a square patch of pixels to be cut out, and \\(\\odot\\) denotes element-wise multiplication.</li> </ul>"},{"location":"KB/CvT/","title":"CvT","text":"<p>toc: true title: CvT</p> <p>categories: ['temp']</p>"},{"location":"KB/CvT/#cvt","title":"CvT","text":"<ul> <li>CvT: Introducing Convolutions to Vision Transformers<ul> <li>improves Vision Transformer</li> <li>introducing Conv</li> <li>a hierarchy of Transformers containing a new convolutional token Embedding</li> <li>convolutional Transformer block leveraging a convolutional projection</li> <li>shift, scale, and distortion invariance</li> <li>dynamic Attention , global context, and better generalization</li> <li>ImageNet</li> <li>Position Encoding , a crucial component in existing Vision Transformers, can be safely removed in our model</li> <li>potential advantage for adaption</li> <li>built-in local context structure introduced by convolutions, CvT no longer requires a position embedding</li> </ul> </li> </ul>"},{"location":"KB/Cycle%20Consistency%20Loss/","title":"Cycle Consistency Loss","text":""},{"location":"KB/Cycle%20Consistency%20Loss/#cycle-consistency-loss","title":"Cycle Consistency Loss","text":"<ul> <li>For two domains X, Y mapping \\(G: X \\rightarrow Y\\), \\(F: Y \\rightarrow X\\)</li> <li>trying to enforce the intuition that these mappings should be reverses of each other and that both mappings should be bijections</li> <li>Encourages \\(\\(F(G(x)) \\approx x \\text{ and } G(F(y)) \\approx y\\)\\)</li> <li>reduces the space of possible mapping functions by enforcing forward and backwards consistency</li> <li> \\[L_{cyc}(G,F) = \\mathbb{E}_{x \\sim p_{data}(x)}[||F(G(x))-x)||_{1}] + \\mathbb{E}_{x \\sim p_{data}(y)}[||G(F(x))-x)||_{1}]\\] </li> <li> \\[\\mathcal{L}_{cyc}(G, F, X, Y) = \\frac{1}{m}\\Sigma_{i=1}^{m}[(F(G(x_{i})-x_{i})+ (G(F(y_{i}))-y_{i})]\\] </li> </ul>"},{"location":"KB/CycleGAN/","title":"CycleGAN","text":""},{"location":"KB/CycleGAN/#cyclegan","title":"CycleGAN","text":"<ul> <li>Unpaired image2image</li> <li>2 Mapping functions G, F : generator and \\(D_{X}, D_{Y}\\) as generators</li> <li>Adversarial Loss</li> <li>\\(\\mathcal{L}_{cyc}\\) Cycle Consistency Loss</li> <li>Full objective<ul> <li>Adversarial Loss + Cycle Consistency Loss</li> <li>\\(\\lambda\\) is a hyperparam. Generally set to 10</li> <li> \\[\\mathcal{L}_{GAN}(G, F, D_{X}, D_{Y}) = \\mathcal{L}_{GAN}(G, D_{Y}, X, Y) + \\mathcal{L}_{GAN}(F, D_{X}, X, Y) + \\lambda \\mathcal{L}_{cyc}(G,F)\\] </li> </ul> </li> <li>To Solve</li> <li> \\[G^{*},F^{*} =\\underset{G,F}{argmin} \\underset{D_{X}, D_{Y}}{max} \\mathcal{L}_{GAN}(G, F, D_{X}, D_{Y})\\] </li> <li>two stride-2 convolutions, several residual blocks, and two fractionally strided convolutions with stride \\(\\frac{1}{2}\\)</li> <li>Instance Normalization</li> </ul>"},{"location":"KB/CycleGAN/#architecture","title":"Architecture","text":""},{"location":"KB/CycleGAN/#generator","title":"Generator","text":""},{"location":"KB/CycleGAN/#encoder","title":"Encoder","text":"<ul> <li>The encoder extracts features from the input image by using Convolutions and compressed the representation of image but increase the number of channels</li> <li>The encoder consists of 3 convolution that reduces the representation by 1/4 th of actual image size</li> </ul>"},{"location":"KB/CycleGAN/#transforming-block","title":"Transforming Block","text":"<ul> <li>The transformer contains 6 or 9 residual blocks based on the size of input.</li> <li>The output of transformer is then passed into the decoder which uses 2 -deconvolution block of fraction strides to increase the size of representation to original size.</li> </ul>"},{"location":"KB/CycleGAN/#discriminator","title":"Discriminator","text":"<ul> <li>PatchGAN</li> </ul>"},{"location":"KB/CycleGAN/#applications","title":"Applications","text":"<ul> <li>Style Transfer<ul> <li>Unlike other works on neural style transfer, CycleGAN learns to mimic the style of an entire collection of artworks, rather than transferring the style of a single selected piece of art</li> </ul> </li> <li>Object Transformation<ul> <li>CycleGAN can transform object from one ImageNet class to another such as: Zebra to Horses and vice-versa, Apples to Oranges and vice versa etc</li> </ul> </li> <li>Season Transfer<ul> <li>CycleGAN can also transfer images from Winter Season to Summer season and vice-versa. For this the model is trained on 854 winter photos and 1273 summer photos of Yosemite from Flickr.</li> </ul> </li> <li>Photo Generation from Painting<ul> <li>can also be used to transform photo from paintings and vice-versa</li> <li>Identity Loss</li> </ul> </li> </ul>"},{"location":"KB/CycleGAN/#limits","title":"Limits","text":"<ul> <li>applied to perform geometrical transformation, CycleGAN does not perform very well. This is because of the generator architecture which is trained to perform appearance changes in the image.</li> </ul>"},{"location":"KB/CycleGAN/#reduce-model-oscillation","title":"Reduce Model Oscillation","text":"<ul> <li>To prevent the model from changing drastically from iteration to iteration, the discriminators were fed a history of generated images, rather than just the ones produced by the latest versions of the generator.</li> <li>To do this we keep storing the 50 most recently generated images. Based on this technique we reduce the model Oscillation as well as model overfitting.</li> </ul>"},{"location":"KB/CycleGAN/#technical-implementation","title":"Technical Implementation","text":"<p>The CycleGAN paper provides a number of technical details regarding how to implement the technique in practice.</p> <p>The generator network implementation is based on the approach described for style transfer by\u00a0Justin Johnson\u00a0in the 2016 paper toc: true titled \u201cPerceptual Losses for Real-Time Style Transfer and Super-Resolution.\u201d</p> <p>The generator model starts with best practices for generators using the deep convolutional GAN, which is implemented using multiple residual blocks (e.g. from the\u00a0ResNet).</p> <p>The discriminator models use PatchGAN, as described by\u00a0Phillip Isola, et al. in their 2016 paper toc: true titled \u201cImage-to-Image Translation with Conditional Adversarial Networks.\u201d</p> <p>This discriminator tries to classify if each NxN patch in an image is real or fake. We run this discriminator convolutionally across the image, averaging all responses to provide the ultimate output of D.</p> <p>\u2014\u00a0Image-to-Image Translation with Conditional Adversarial Networks, 2016.</p> <p>PatchGANs are used in the discriminator models to classify 70\u00d770 overlapping patches of input images as belonging to the domain or having been generated. The discriminator output is then taken as the average of the prediction for each patch.</p> <p>The adversarial loss is implemented using a least-squared loss function, as described in\u00a0Xudong Mao, et al\u2019s 2016 paper toc: true titled \u201cLeast Squares Generative Adversarial Networks.\u201d</p> <p>[\u2026] we propose the Least Squares Generative Adversarial Networks (LSGANs) which adopt the least squares loss function for the discriminator. The idea is simple yet powerful: the least squares loss function is able to move the fake samples toward the decision boundary, because the least squares loss function penalizes samples that lie in a long way on the correct side of the decision boundary.</p> <p>\u2014\u00a0Least squares generative adversarial networks, 2016.</p> <p>Additionally, a buffer of 50 generated images is used to update the discriminator models instead of freshly generated images, as described in\u00a0Ashish Shrivastava\u2019s\u00a02016 paper toc: true titled \u201cLearning from Simulated and Unsupervised Images through Adversarial Training.\u201d</p> <p>[\u2026] we introduce a method to improve the stability of adversarial training by updating the discriminator using a history of refined images, rather than only the ones in the current minibatch.</p> <p>\u2014\u00a0Learning from Simulated and Unsupervised Images through Adversarial Training, 2016.</p> <p>The models are trained with the\u00a0Adam version of stochastic gradient descent\u00a0and a small learning rate for 100 epochs, then a further 100 epochs with a learning rate decay. The models are updated after each image, e.g. a batch size of 1.</p>"},{"location":"KB/Cyclic%20Learning%20Rate/","title":"Cyclic Learning Rate","text":""},{"location":"KB/Cyclic%20Learning%20Rate/#cyclic-learning-rate","title":"Cyclic Learning Rate","text":"<ul> <li>With respect to local minima and saddle points, one could argue that you could simply walk \"past\" them if you set steps that are large enough. Having a learning rate that is too small will thus ensure that you get stuck.</li> <li>Now,\u00a0Cyclical Learning Rates\u00a0- which were introduced by Smith (2017) - help you fix this issue. These learning rates are indeed cyclical, and ensure that the learning rate moves back and forth between a\u00a0minimum value\u00a0and a\u00a0maximum value\u00a0all the time.</li> <li></li> <li></li> <li></li> </ul>"},{"location":"KB/Cyclo%20Drive/","title":"Cyclo Drive","text":""},{"location":"KB/Cyclo%20Drive/#cyclo-drive","title":"Cyclo Drive","text":"<ul> <li>A brand name for a speed reduction device that converts high speed low torque to low speed high torque, usually used on the major (larger) axis.</li> </ul>"},{"location":"KB/Cylinders/","title":"Cylinders","text":""},{"location":"KB/Cylinders/#cylinders","title":"Cylinders","text":""},{"location":"KB/Cylindrical%20Topology/","title":"Cylindrical Topology","text":""},{"location":"KB/Cylindrical%20Topology/#cylindrical-topology","title":"Cylindrical Topology","text":"<ul> <li>A topology where the arm follows a radius of a horizontal circle, with a prismatic joint to raise or lower the circle. Not popular in industry</li> </ul>"},{"location":"KB/DALL-E%203/","title":"DALL-E 2","text":""},{"location":"KB/DALL-E%203/#dall-e-2","title":"DALL-E 2","text":"<ul> <li>Hierarchical Text-Conditional Image Generation with CLIP Latents</li> <li>DALL-E 2, generates more realistic and accurate images with 4x greater resolution, better caption matching and photorealism</li> <li>Contrastive models like CLIP have been shown to learn robust representations of images that capture both semantics and style</li> <li>two-stage model: a prior that generates a CLIP image embedding given a text caption, and a \u201cunCLIP\u201d decoder that generates an image conditioned on the image embedding</li> <li>explicitly generating image representations improves image diversity with minimal loss in photorealism and caption similarity</li> <li>decoder, which is conditioned on image representations, can also produce variations of an image that preserve both its semantics and style, while varying the non-essential details absent from the image representation</li> <li>diffusion models for the decoder and experiment with both autoregressive and diffusion models for the prior, finding that the latter are computationally more efficient and produce higher-quality samples</li> </ul>"},{"location":"KB/DALL-E/","title":"DALL-E","text":""},{"location":"KB/DALL-E/#dall-e","title":"DALL-E","text":"<ul> <li>AdaIn</li> <li>it was capable of generating text that could not be distinguished from human-written text</li> <li>named after Salvador Dal\u00ed and Pixar's WALL\u00b7E</li> <li>based on the GPT3</li> <li>Previous approaches like BERT and the original GPT model followed the fine-tuning approach.</li> <li>GPT-2 and GPT-3 recognized that even while pretraining already provided lots of benefits compared to training from scratch, so-called zero-shot learning - where the model is finetuned and then applied to language tasks, without pretraining - could be the way forward.</li> <li>DALL\u00b7E is capable of performing a variety of tasks:<ul> <li>Controlling attributes, instructing the model what particular attributes of an object should look like. For example: \"a collection of glasses is sitting on a table\" (OpenAI, 2021). Here, we instruct the model about the glasses, and more precisely, their location.</li> <li>Drawing multiple objects is also possible, but is more challenging, because it can be unknown whether certain characteristics belong to one object or another (OpenAI, 2021). DALL\u00b7E is however also capable of performing that task, but at the risk of making mistakes - once again due to the issue mentioned previously. The success rate decreases rapidly when the number of objects increases.</li> <li>Visualizing perspective and three-dimensionality, meaning that DALL\u00b7E can be instructed to take a particular \"perspective\" when generating the image (OpenAI, 2021).</li> <li>Visualizing across many levels, from \"extreme close-up\" to \"higher-level concepts\" (OpenAI, 2021).</li> <li>Inferring context, meaning that particular elements can be added to an image that normally do not belong to a particular context (e.g. the OpenAI logo in the image above; this is normally not displayed on a store front).</li> </ul> </li> <li>Uses<ul> <li>Industrial and interior design, to aid designers when creating a variety of household and other objects.</li> <li>Architecture, to guide the creation of buildings and other forms of constructions.</li> <li>Photography, to create an image specifically tailored to one's requirements.</li> <li>Graphic design, with e.g. the creation of a variety of icons.</li> </ul> </li> <li>Zero-Shot Text-to-Image Generation</li> <li>DALL-E which offers a simple approach for text-to-image generation based on an autoregressive transformer which models the text and image tokens as a single stream of data</li> <li>simple decoder-only transformer that receives both the text and the image as a single stream of 1280 tokens\u2014256 for the text and 1024 for the image\u2014and models all of them autoregressively</li> <li>They find that sufficient data and scale can lead to improved generalization, both in terms of zero-shot performance relative to previous domain-specific approaches</li> <li>and in terms of the range of capabilities that emerge from a single generative model.</li> </ul>"},{"location":"KB/DALL%C2%B7E%202/","title":"DALL\u00b7E 2","text":""},{"location":"KB/DALL%C2%B7E%202/#dalle-2","title":"DALL\u00b7E 2","text":"<ul> <li>generate original, genuine and realistic images and art from a prompt consisting on a text description</li> <li>DALL\u00b7E 2 manages to combine concepts, attributes and diferent styles - it uses the CLIP neural network</li> </ul>"},{"location":"KB/DCGAN/","title":"DCGAN","text":""},{"location":"KB/DCGAN/#dcgan","title":"DCGAN","text":""},{"location":"KB/DCGAN/#architecture","title":"Architecture","text":""},{"location":"KB/DCGAN/#weight-init","title":"Weight Init","text":"<ul> <li>If conv Random Normal with mean = 0 and std.dev = 0.02</li> <li>If BatchNorm with mean = 1.0 and std.dev = 0.02, Bias = 0</li> </ul>"},{"location":"KB/DCGAN/#generator","title":"Generator","text":"<ul> <li>Map latent space vector z to data space</li> <li>Creating RGB with same size as training image</li> <li>[Transposed Conv] , [Batch Normalization] and Relu</li> <li>Output is 3x64x64</li> <li>Output passed through Tanh to return it to [-1,1]</li> <li>[Batch Normalization] AFTER Transposed Conv is super important as it helps with flow of gradients</li> <li>Notice, how the inputs we set in the input section (nz,\u00a0ngf, and\u00a0nc) influence the generator architecture in code.\u00a0nz\u00a0is the length of the z input vector,\u00a0ngf\u00a0relates to the size of the feature maps that are propagated through the generator, and\u00a0nc\u00a0is the number of channels in the output image (set to 3 for RGB images)</li> <li></li> </ul>"},{"location":"KB/DCGAN/#discriminator","title":"Discriminator","text":"<ul> <li>[Strided] [Conv], [Batch Normalization], and Leaky Relu</li> <li>3x64x64 input</li> <li>Binary classification network - outputs prob of real/fake</li> <li>Final is a Sigmoid layer</li> <li>For [downsampling], good Practise to use [Strided] rather than Pooling as it lets the network learn it's own pooling function</li> <li>Almost a direct inverse of the Generator</li> </ul>"},{"location":"KB/DCGAN/#special-features","title":"Special Features","text":"<ul> <li>Explicitly uses convolutional layers in the discriminator and transposed-convolutional layers in the generator</li> <li>Further the discriminator uses batch norm layers and\u00a0[Leaky Relu]\u00a0activations while the generator uses\u00a0Relu\u00a0activations</li> <li>The input is a latent vector drawn from a standard normal distribution and the output is a\u00a0\\(3 \\times 32 \\times 32\\)\u00a0RGB image</li> <li>In this implementation, I also added in\u00a0Label Smoothing</li> </ul>"},{"location":"KB/DCGAN/#loss-functions","title":"Loss functions","text":""},{"location":"KB/DCGAN/#discriminator-loss","title":"Discriminator loss","text":"<p>The Discriminator penalizes wrongly classifying a real image as a fake or a fake image as real. This can be thought of as maximizing the following function. \\(\\(\\nabla_{\\theta_{d}} \\frac{1}{m} \\Sigma_{i=1}^{m}[log D(x^{(i)}) + log(1-D(G(z^{(i)})))]\\)\\)</p>"},{"location":"KB/DCGAN/#generator-loss","title":"Generator loss","text":"<ul> <li> <p>The Generator loss takes the output of the Discriminator into account and rewards it if the Generator is fooled into thinking the fake image is real. If this condition is not satisfied, the Generator is penalized.</p> </li> <li> <p>This can be thought of as minimizing the following function. \\(\\(\\nabla_{\\theta_{g}} \\frac{1}{m} \\Sigma_{i=1}^{m}log(1-D(G(z^{(i)})))\\)\\)</p> </li> </ul>"},{"location":"KB/DICOM/","title":"DICOM","text":"","tags":["medical"]},{"location":"KB/DICOM/#dicom","title":"DICOM","text":"<ul> <li>Medical Imaging Standards</li> <li>pydicom<ul> <li>pip install pydicom</li> </ul> </li> </ul>","tags":["medical"]},{"location":"KB/DLRM/","title":"DLRM","text":""},{"location":"KB/DLRM/#dlrm","title":"DLRM","text":"<ul> <li>Deep Learning Recommendation Model for Personalization and Recommendation Systems</li> <li>DLRM</li> <li>The DLRM model handles continuous (dense) and categorical (sparse) features that describe users and products</li> <li>wide range of hardware and system components, such as memory capacity and bandwidth, as well as communication and compute resources</li> <li>design a specialized parallelization scheme utilizing model parallelism on the embedding tables to mitigate memory constraints while exploiting data parallelism to scale-out compute from the fully-connected layers</li> <li>it computes the feature interactions explicitly while limiting the order of interaction to pairwise interactions.</li> <li>treats each embedded feature vector (corresponding to categorical features) as a single unit, whereas other methods (such as Deep and Cross) treat each element in the feature vector as a new unit that should yield different cross terms</li> <li>These design choices help reduce computational/memory cost while maintaining competitive accuracy</li> </ul>"},{"location":"KB/DT%20Tutor/","title":"DT Tutor","text":""},{"location":"KB/DT%20Tutor/#dt-tutor","title":"DT Tutor","text":"<ul> <li>DT Tutor (Murray, VanLehn, &amp; Mostow, 2004) implements a version of this ideal tutoring policy.</li> <li>The tutor applies decision theory to make its choice about whether to give a hint.</li> <li>For each tutor action it can make (e.g., to give a hint, and which kind of hint), it uses a probabilistic model of the student to predict all possible student reactions to the tutor's action and their probability.</li> <li>The predicted student state includes the likelihood of learning, of becoming frustrated, of entering the next step correctly, etc.</li> <li>DT Tutor evaluates the utility of each of the predicted student states, multiplies the state's utility by the state's probability, and eventually produces the expected utility of each proposed tutor action.</li> <li>It then takes the tutor action with the highest expected utility. Although advances in probabilistic reasoning make it feasible for DT Tutor to perform this calculation in real time, considerable data from human students is needed in order to set the parameters in its model of student learning</li> </ul>"},{"location":"KB/Data%20Augmentation%20via%20Latent%20Space%20Interpolation%20for%20Image%20Classification/","title":"Data Augmentation via Latent Space Interpolation for Image Classification","text":""},{"location":"KB/Data%20Augmentation%20via%20Latent%20Space%20Interpolation%20for%20Image%20Classification/#data-augmentation-via-latent-space-interpolation-for-image-classification","title":"Data Augmentation via Latent Space Interpolation for Image Classification","text":"<ul> <li>@liuDataAugmentationLatent2018</li> </ul>"},{"location":"KB/Data%20Augmentation%20via%20Latent%20Space%20Interpolation%20for%20Image%20Classification/#abstract","title":"Abstract","text":"<ul> <li>standard data augmentation produces only limited plausible alternative data by for example, flipping, distorting, adding noise to, cropping(cropping.qmd) a patch from the original samples</li> <li>adversarial autoencoder (AAE) to impose the feature representations with uniform distribution and apply the linear interpolation on latent space, which is potential to generate a much broader set of augmentations for image classification</li> <li>improves the generalization and performance of state-of-the-art deep neural networks</li> <li>Generative models are often evaluated by examining samples from the latent space </li> <li>Techniques frequently used are random sampling and linear interpolation But often these can result in sampling the latent space from locations very far outside the manifold of probable location In high dimensional space, even with a uniform distribution most points lie on a thin shell in the unit cube. We utilize both the uniform distribution prior to avoid the \"hole\" of dead zone.</li> <li>1) We propose a novel framework to augment the dataset using the interclass interpolation of latent feature representations. 2)uniform distribution are imposed as the prior to avoid \"hole\" effect of the inter-class interpolation via the adversarial autoencoder network. 3) we explore the linear interpolation on the ILSVRC 2012 and CIFAR(CIFAR.qmd)-10 datasets</li> </ul>"},{"location":"KB/Data%20Augmentation%20via%20Latent%20Space%20Interpolation%20for%20Image%20Classification/#proposed-method","title":"PROPOSED METHOD","text":"<ul> <li>latent space interpolation followed two useful principles when sampling the latent space of a generative model avoid sampling from locations that are highly unlikely given the prior of the model. being used in the original VAE paper which adjusted sampling through the inverse CDF(CDF.qmd) of the Gaussian to accommodate the Gaussian prior recognize that the dimensionality of the latent space is often artificially high and may contains dead zones that are not on the manifold learned during training implies that simply matching the model's prior will not always be sufficient to yield samples that appear to have been drawn from the training set</li> <li>it does not require significant domain knowledge. that interpolation and extrapolation in feature space can improve generalization</li> <li>Recent approaches have also proposed to regularize(regularize.qmd) the output distribution of a neural network by label smoothing [27], or penalizing highconfidence softmax distributions [28]These methods bear similarities with mixup in the sense that supervision depends on multiple smooth labels, rather than on single hard labels as in traditional ERMthe label smoothing in these works is applied or regularized independently from the associated feature values. the supervision of every example is not overly dominated by the groundtruth labe</li> <li>LSI transformation establishes a linear relationship between data augmentation and the supervision signal.strong regularizer that improves generalization The linearity constraint, through its effect on the</li> <li>derivatives of the function approximated, also relates mixup to other methods such as Sobolev training of neural networks [29] or WGAN-GP [30].</li> <li>When other types of data augmentation are employed in addition to our technique, we can apply them for each image before mixing them into the final image for training</li> <li>The data augmentation incurs additional time to prepare the input image, but this can be done on the CPU while the GPU is executing the training through back propagation</li> <li>a single data loader to obtain one minibatch, and then latent space interpolation is applied to the same minibatch after random shuffling</li> </ul>"},{"location":"KB/Data%20Augmentation%20via%20Latent%20Space%20Interpolation%20for%20Image%20Classification/#uniform-distribution-representations","title":"Uniform distribution representations","text":"<ul> <li>(images/Pasted image 20230209131445.png.qmd)</li> <li>Adversarial autoencoder (AAE) [31] can be treated as the combination of generative adversarial networks (GANs) [20] and variational autoencoder (VAE)maintains the autoencoder structure like the VAE but replaces the KLdivergence loss with a discriminative network, denoted by Dis</li> <li>Instead of generating images from random noise as in GAN, AAE utilizes the encoder part to learn the latent variables approximated on certain prior, making the style of generated images controllable AAE better captures the data manifold compared to VAEinput as x, output as x', and the distribution of the training data as \u0000!\u0000\u0be7\u0000(\u0754 ,(then the distribution of z is q(z|x). Assuming p(z) is a prior distribution, and denotes the random sampling process from p(z). The min-max objective function can be used to\u0000 train the Enc and Dis</li> <li> \\[\\mathbb{E}_{z* \\sim p(z)}[log(Dis(z*))] \\mathbb{E}_{x \\sim p_{data}(x)}[\\overset{min Enc}{log(1-Dis_{z}(z*))}]\\] </li> <li>As for the Dec, the L2 loss is used as the reconstruction loss</li> <li> \\[L_{recon}= ||x-x'||^{2}_{2}\\] </li> <li>Dis imposes a prior distribution (i.e., uniform distribution) on z Dis aims to discriminate the z generated by encoder Enc Enc will be trained to generate z that could fool Dis</li> <li>Such adversarial process forces the distribution of the generated z to gradually approach the prio uniform distribution as the prior, forcing z to evenly populate the latent space with no apparent \"holes\". the generated z's (depicted by blue dots in a 2-D space) present uniform distribution under the regularization(regularization.qmd) of Dis, while the distribution of z exhibits a \"hole\" without the application of Dis Exhibition of the \"hole\" indicates that the samples generated by interpolating between arbitrary z's may not lie on the real image manifold \u2013 generating unrealistic appearancesnot to generate photorealistic images as in GAN offer more informative and discriminative training sample, the adversarial loss in pixel-level is dropped in here for faster training and processing.</li> </ul>"},{"location":"KB/Data%20Augmentation%20via%20Latent%20Space%20Interpolation%20for%20Image%20Classification/#linear-interpolation","title":"Linear interpolation","text":"<ul> <li>The difference with mixup [17] in here is that the linear interpolation manipulation is conducted in latent space which align the uniform distribution instead of the pixel-level</li> <li>The one-hot vectors are used to label the original samples</li> <li>The loss function for a generated sample are calculated as the weighted sum (via \u07e3 (of two cross-entropy losses corresponding to both of its original samples</li> <li>When the 0.5=\u07e3, we can simply use two-hot vector to label the generated sample belongs to two of its original samples for faster processing.</li> </ul>"},{"location":"KB/Data%20Augmentation%20via%20Latent%20Space%20Interpolation%20for%20Image%20Classification/#conclusion","title":"CONCLUSION","text":"<ul> <li>vicinal risk minimization trains on virtual examples constructed via interpolations of the features in a latent space with uniform distributionSeveral methods are employed to avoid the dead zone in manifold of feature representations.</li> <li>the ILSVRC 2012</li> <li>CIFAR(CIFAR.qmd)-10</li> <li>valuable for tasks with a limited number of samples, such as medical image classification tasks</li> </ul>"},{"location":"KB/Data%20Augmentation%20via%20Latent%20Space%20Interpolation%20for%20Image%20Classification/#images","title":"Images","text":"<ul> <li>(images/Pasted image 20230209131412.png.qmd)</li> <li>(images/Pasted image 20230209131420.png.qmd)</li> <li>(images/Pasted image 20230209131428.png.qmd)</li> <li></li> </ul>"},{"location":"KB/Data%20Augmentation%20with%20Curriculum%20Learning/","title":"Data Augmentation with Curriculum Learning","text":"<ul> <li>Curriculum learning decisions are especially important for One-Shot Learning systems such as FaceNet</li> <li>In this sense, the concept of curriculum learning shares many similarities with adversarial search algorithms or learning only on hard examples.</li> <li>originally coined by Bengio et al.</li> <li>Plotting out training accuracy over time across different initial training subsets could help reveal patterns in the data that dramatically speed up training time.</li> </ul>"},{"location":"KB/Data%20Augmentation%20with%20Curriculum%20Learning/#data-augmentation-with-curriculum-learning","title":"Data Augmentation with Curriculum Learning","text":""},{"location":"KB/Data%20Free%20Distillation/","title":"Data Free Distillation","text":""},{"location":"KB/Data%20Free%20Distillation/#data-free-distillation","title":"Data Free Distillation","text":"<ul> <li>Just as \u201cdata free\u201d implies, there is no training data. Instead, the data is newly or synthetically generated.</li> <li>Specifically, in (Chen et al., 2019a; Ye et al., 2020; Micaelli and Storkey, 2019; Yoo et al., 2019; Hu et al., 2020), the transfer data is generated by a GAN. In the proposed data-free knowledge distillation method (Lopes et al., 2017), the transfer data to train the student network is reconstructed by using the layer ac- tivations or layer spectral activations of the teacher net- work.</li> <li>Yin et al. (2020) proposed DeepInversion, which uses knowledge distillation to generate synthesized images for data-free knowledge transfer. Nayak et al. (2019) proposed zero-shot knowledge distillation that does not use existing data.</li> <li>The transfer data is pro- duced by modelling the softmax space using the pa- rameters of the teacher network. In fact, the target data in (Micaelli and Storkey, 2019; Nayak et al., 2019) is generated by using the information from the fea- ture representations of teacher networks.</li> <li>distilling knowl- edge from a teacher model into a student neural network (Kimura et al., 2018; Shen et al., 2021).</li> <li>data distillation, which is similar to data-free distillation (Radosavovic et al., 2018; Liu et al., 2019d; Zhang et al., 2020d). In data distillation, new training annotations of unlabeled data generated from the teacher model are employed to train a student model.</li> </ul>"},{"location":"KB/Data%20Structures/","title":"Data Structures","text":""},{"location":"KB/Data%20Structures/#data-structures","title":"Data Structures","text":"<ul> <li>Grids</li> </ul>"},{"location":"KB/Data%20aug%20for%20spoken%20language/","title":"Data aug for spoken language","text":""},{"location":"KB/Data%20aug%20for%20spoken%20language/#data-aug-for-spoken-language","title":"Data Aug for Spoken Language","text":"<ul> <li>Comparing Data Augmentation and Annotation Standardization to Improve End-to-end Spoken Language Understanding Models</li> <li>All-neural end-to-end (E2E) Spoken Language Understanding (SLU) models can improve performance over traditional compositional SLU models, but have the challenge of requiring high-quality training data with both audio and annotations</li> <li>they struggle with performance on \u201cgolden utterances\u201d, which are essential for defining and supporting features, but may lack sufficient training data</li> <li>using data augmentation to compare two data-centric AI methods to improve performance on golden utterances</li> <li>improving the annotation quality of existing training utterances and augmenting the training data with varying amounts of synthetic data</li> <li>both data-centric approaches to improving E2E SLU achieved the desired effect, although data augmentation was much more powerful than annotation standardization.</li> <li>leads to improvement in intent recognition error rate (IRER) on their golden utterance test set by 93% relative to the baseline without seeing a negative impact on other test metrics</li> </ul>"},{"location":"KB/Decision%20Boundaries/","title":"Decision Boundaries","text":""},{"location":"KB/Decision%20Boundaries/#decision-boundaries","title":"Decision Boundaries","text":"<ul> <li>Minimal risk decision function is unique and must be represented in terms of Distributions of data generating RVs X and Y<ul> <li>A is some subvolume of P. (n dimensional hypercubes or volume bodies)</li> <li>\\(P_{X,Y}\\) is ground truth<ul> <li>Function that assigns every choice of \\(A \\subseteq P , c \\in C\\) the number P</li> </ul> </li> </ul> </li> <li>Decision function \\(h: P \\rightarrow {c_{1}, \u2026, c_{k}}\\) partitions pattern space into k disjoint decision regions \\(R_{1}, \u2026, R_{k}\\) by \\(\\(R_{i}= \\{x \\in P | h(x) = c_{i}\\}\\)\\)</li> <li>If a test pattern falls into \\(R_{i}\\) it is classified as class i</li> </ul>"},{"location":"KB/Decision%20Boundaries/#finding-decision-regions","title":"Finding Decision Regions","text":"<ul> <li>which yields the lowerst misclassification rate or highest Probability of correct classification</li> <li>\\(f_{i}\\) be the PDF for Class Conditional distribution</li> <li>Probability of obtaining a correct classification for \\(R_{i}\\) is \\(\\(\\Sigma_{i=1}^{k}P(X \\in R_{i}, Y = c_{i})\\)\\)</li> <li></li> <li>This region has curved boundaries aka decision boundaries<ul> <li>Folded and on higher dims : very complex and fragmented</li> </ul> </li> <li>x is a vector</li> <li>For patterns on these boundaries, two or more classifications are equally probable</li> <li>Maximal if \\(\\(R_{i}= \\{x \\in P| i = argmax_{j} P(Y=c_{j})f_{j}(x)\\}\\)\\)</li> <li>Then \\(\\(h_{opt}: P \\rightarrow C_{j}x \\rightarrow c_{argmax_{j}P(Y=c_{j})f_{j}(x)}\\)\\)</li> <li>Algo learns estimates of the Class Conditional distribution and class probabilities aka priors</li> <li>The separator between classes learned by a model in a binary class or multi-class classification problems. For example, in the following image representing a binary classification problem, the decision boundary is the frontier between the orange class and the blue class</li> </ul>"},{"location":"KB/Decision%20Trees/","title":"DT","text":""},{"location":"KB/Decision%20Trees/#dt","title":"DT","text":""},{"location":"KB/Declarative%20Memory%20Blending/","title":"Declarative Memory Blending","text":""},{"location":"KB/Declarative%20Memory%20Blending/#declarative-memory-blending","title":"Declarative Memory Blending","text":"<ul> <li>Like \"weighted avg\"</li> <li>store no of pulses</li> <li>activation decays in time<ul> <li> \\[A(t) = log(t-t_{creation})^{-d}+\\text{mismatchpenalty}\\] </li> <li>Retrieval probability<ul> <li>Softmax</li> <li> \\[P_{i}= \\frac{e^{\\frac{A_{t}}{t}}}{\\Sigma_{i}e^{\\frac{A_{t}}{t}}}\\] </li> </ul> </li> <li>Adds up to 1</li> <li> \\[Result = \\Sigma_{j}P_{j}V_{j}\\] </li> <li>t controls noise<ul> <li>if t is high : 1/no of competitors , more prob of retrieval</li> </ul> </li> <li>Looking for long interval (partial matching)</li> <li>Penalty for short intervals</li> <li>Apply \\(P_{i}\\)</li> <li>Weighted avg \\(Result\\)</li> </ul> </li> <li>Too short is positive. else negative, correct is 0</li> <li>no of pulses to wait : duration + feedback from memory</li> </ul>"},{"location":"KB/Declarative%20Memory%20Blending/#fit","title":"Fit","text":"<ul> <li>Exp done on generated data as well</li> <li>Compares if same as when run on original</li> <li>Does well with unmodified mode    </li> <li></li> </ul>"},{"location":"KB/Declarative%20memory/","title":"Declarative memory","text":""},{"location":"KB/Declarative%20memory/#declarative-memory","title":"Declarative Memory","text":""},{"location":"KB/Declarative%20memory/#info","title":"Info","text":"<ul> <li>All decisions are based on knowledge</li> <li>Depends on frequency and recency of use</li> <li>Semantic , episodic</li> <li>Representation similar to semantic networks</li> <li>No inheritence</li> <li>Partially sub-symbolic</li> <li>Related to Prefrontal cortex</li> </ul>"},{"location":"KB/Declarative%20memory/#programming","title":"Programming","text":"<ul> <li>ACT-R Chunk</li> </ul>"},{"location":"KB/DeconvNet/","title":"DeconvNet","text":""},{"location":"KB/DeconvNet/#deconvnet","title":"DeconvNet","text":"<p><code>toc</code> - @zeilerVisualizingUnderstandingConvolutional2013 - Zeiler, Fergus</p>"},{"location":"KB/DeconvNet/#summary","title":"Summary","text":"<ul> <li>Deconvnets are designed to work similar to convolutional networks but reverse (reversing pooling component, reversing filter component etc.), and they can be trained using an unsupervised approach.</li> <li>To reconstruct the activation on a specific layer, we are attaching deconv layers to corresponding CNN layers</li> <li>To examine a reconstruction for a given class c, we have to set all activations except the one responsible for predicting class c to zero.</li> <li>Then we can propagate through deconvnet layers and pass all the feature maps as inputs to corresponding layers</li> <li>Propagation through the whole deconvnet gives us a representation of the features from the first layer of the original CNN</li> <li>This approach causes the saliency map to feature some biases from the first convolutional layer and the representation looks like a localized edge detector</li> <li>works better when there is a clear distinction in the feature importance rather than similar values for the whole image</li> <li>Basically invert operations between input and the chosen layer.<ul> <li>Conv -&gt; Deconv</li> <li>Pool -&gt; Unpooling</li> <li>ReLU -&gt; ReLU with negative valyes clamped going backward from the activation space to image space</li> <li>Pooling is non invertible, but uses a switch module : recover positions of maxima in the forward pass</li> </ul> </li> <li>DeconvNet is a calculation of a backward convolutional network that reuses the weights at each layer from the output layer back to the input image</li> <li>The employed mechanisms are deconvolution and unpooling, which are especially designed for CNNs with convolutions, max-pooling, and Rectified Linear Units (ReLUs). The method makes it possible to create feature maps of an input image that activates certain hidden units most, linked to a particular prediction</li> <li>With their propagation technique, they identified the most responsible patterns for this output. The patterns are visualized in the input space</li> <li>DeconvNet is limited to max-pooling layers, but the unpooling uses an approximate inverse</li> </ul>"},{"location":"KB/DeconvNet/#filtering","title":"Filtering","text":"<ul> <li>Filtering in the original CNN computes feature maps using learned filters. Reversing that operation requires the use of a transposed version of the same filters. Those transposed filters are then applied to the Rectified Unpooled Maps.</li> </ul>"},{"location":"KB/DeconvNet/#rectification","title":"Rectification","text":"<ul> <li>same ReLU non-linearity</li> <li>simply just rectifying the values and propagate only non-negative ones to the filtering layer</li> </ul>"},{"location":"KB/DeconvNet/#unpooling","title":"Unpooling","text":"<ul> <li>The original max-pooling operation is non-invertible, but this approach uses additional variables called switch variables, which are responsible for remembering the locations of the maxima for each pooling region.</li> </ul>"},{"location":"KB/DeconvNet/#images","title":"Images","text":""},{"location":"KB/Deductive%20Approaches/","title":"Deductive Approaches","text":""},{"location":"KB/Deductive%20Approaches/#deductive-approaches","title":"Deductive Approaches","text":"<ul> <li>Settling on one hypothesis by eliminating all others</li> </ul>"},{"location":"KB/Deep%20Brain%20Stimulation/","title":"Deep Brain Stimulation","text":""},{"location":"KB/Deep%20Brain%20Stimulation/#deep-brain-stimulation","title":"Deep Brain Stimulation","text":"<ul> <li>A method of treating various neuropsychiatric and neurodegenerative disorders through small, controlled electric shocks administered from a special battery-operated neurostimulation implant. The implant, sometimes called a \u201cbrain pacemaker,\u201d is placed within deep brain regions such as the globus pallidus or subthalamus.</li> </ul>"},{"location":"KB/Deep%20Generative%20Models/","title":"Deep Generative Models","text":""},{"location":"KB/Deep%20Generative%20Models/#deep-generative-models","title":"Deep Generative Models","text":"<ul> <li>The ultimate goal of data augmentation is to draw samples from the distribution, which represent the generating mechanism of dataset </li> <li>the data distribution we generate data from should not be different with the original one </li> <li>This is the core idea of deep generative models. </li> <li>Pix2Pix </li> <li>CycleGAN </li> <li>StarGAN</li> <li>StarGAN v2</li> </ul>"},{"location":"KB/Deep%20Inside%20Convolutional%20Networks/","title":"Deep Inside Convolutional Networks","text":""},{"location":"KB/Deep%20Inside%20Convolutional%20Networks/#deep-inside-convolutional-networks","title":"Deep Inside Convolutional Networks","text":"<ul> <li>Karen Simonyan, Andrea Vedaldi, Andrew Zisserman</li> <li> <p>@simonyanDeepConvolutionalNetworks2014</p> </li> <li> <p>Because the word saliency is often related to the whole approach to display input attribution called Saliency Map, this method is also known as Vanilla Gradient</p> </li> <li>finding L2 regularized image III that maximizes score \\(S_{c}\\)\u200b for a given class c</li> <li>It can be written formally as:</li> <li> \\[arg \\underset{I}max S_{c}(I) - \\lambda||I||^{2}_{2}\\] </li> <li>Where \\(\\lambda\\) is a regularisation parameter</li> <li>To find the value of I, we can use the back-propagation method. Unlike in the standard learning process, we are going to back-propagate with respect to the input image, not the first convolution layer</li> </ul>"},{"location":"KB/Deep%20Inside%20Convolutional%20Networks/#from-class-visualization-to-saliency","title":"From class visualization to Saliency","text":"<ul> <li>This idea can be extrapolated, and with minor modifications, we should be able to query for spatial support of class ccc in a given image I0I_0I0\u200b.</li> <li>rank pixels of \\(I_{0}\\)\u200b in relation to their importance in predicting score \\(S_{c}(I_{0})\\)</li> <li>Authors assume that we can approximate \\(S_{c}(I)\\) with a linear function in the neighborhood of \\(I_{0}\\)</li> <li> \\[S_{c}(I) \\approx w^{T}I + b\\] </li> <li>For a pair of input image \\(\\(I_{0} \\in \\mathbb{R}^{m \\times n}\\)\\) and the class c, we are able to compute saliency map \\(A \\in \\mathbb{R}^{m \\times n}\\) (where m and n are the height and width of the input in pixels).</li> <li>compute derivative w and rearrange elements in the returned vector.</li> <li>uses different approaches base on the number of channels in the input image \\(I_{0}\\)\u200b.</li> <li>For grey-scale pixels (one color channel), we can rearrange the pixels to match the shape of the image</li> <li>If the number of channels is greater than one, we are going to use the maximum value from each set of values related to the specified pixel.</li> <li> \\[A_{i,j}= \\underset{ch}max |w_{h_{(i,j,ch)}}|\\] </li> <li>ch is a color channel of the pixel (i,j) and h(i,j,ch) is an index of the www corresponding to the same pixel (i,j).</li> <li>The original Saliency method produces a lot of additional noise but still gives us an idea of which part of the input image is relevant when predicting a specific class.</li> <li>This often causes a problem when the object on the image has a lot of details and the model is using most of them to make a prediction.</li> </ul>"},{"location":"KB/Deep%20Inside%20Convolutional%20Networks/#images","title":"Images","text":""},{"location":"KB/Deep%20Neural%20Networks%20are%20Easily%20Fooled%20High%20Confidence%20Predictions%20for%20Unrecognizable%20Images/","title":"Deep Neural Networks are Easily Fooled High Confidence Predictions for Unrecognizable Images","text":""},{"location":"KB/Deep%20Neural%20Networks%20are%20Easily%20Fooled%20High%20Confidence%20Predictions%20for%20Unrecognizable%20Images/#deep-neural-networks-are-easily-fooled-high-confidence-predictions-for-unrecognizable-images","title":"Deep Neural Networks Are Easily Fooled High Confidence Predictions for Unrecognizable Images","text":"<ul> <li>@nguyenDeepNeuralNetworks2015</li> <li>Current study<ul> <li>False positives</li> <li>MAP Elites algorithm </li> <li>parallel generation</li> <li>Direct encodings</li> <li>Indirect encodings</li> <li>Gradient ascent generation</li> </ul> </li> </ul>"},{"location":"KB/Deep%20Neural%20Networks%20are%20Easily%20Fooled%20High%20Confidence%20Predictions%20for%20Unrecognizable%20Images/#ga","title":"GA","text":"<ul> <li>Population of individuals </li> <li>Each individual has a fitness </li> <li>Mutation makes small edits to specific individuals </li> <li>Recombination (not used here)</li> </ul>"},{"location":"KB/Deep%20Neural%20Networks%20are%20Easily%20Fooled%20High%20Confidence%20Predictions%20for%20Unrecognizable%20Images/#direct-encoding","title":"Direct Encoding","text":"<ul> <li>Individuals are images in pixel space </li> <li>Fitness is the confidence of the DNN that the individual is a class </li> <li>Mutations make edits to the pixel values</li> </ul>"},{"location":"KB/Deep%20Neural%20Networks%20are%20Easily%20Fooled%20High%20Confidence%20Predictions%20for%20Unrecognizable%20Images/#indirect-encoding","title":"Indirect Encoding","text":"<ul> <li>Individuals are Compositional Pattern-Producing Networks (CPPNs) </li> <li>The CPPN generates an image </li> <li>All individuals initially have no hidden neurons </li> <li>Mutations add new neurons to the networks</li> <li>Maximize confidence of the network</li> </ul>"},{"location":"KB/Deep%20Neural%20Networks%20are%20Easily%20Fooled%20High%20Confidence%20Predictions%20for%20Unrecognizable%20Images/#gradient-ascent","title":"Gradient Ascent","text":"<ul> <li>Take the gradient with respect to the image pixel values </li> <li>Modify the image by moving it in the direction of the gradient</li> </ul>"},{"location":"KB/Deep%20Neural%20Networks%20are%20Easily%20Fooled%20High%20Confidence%20Predictions%20for%20Unrecognizable%20Images/#mnist-results-eas","title":"MNIST Results - EAs","text":""},{"location":"KB/Deep%20Neural%20Networks%20are%20Easily%20Fooled%20High%20Confidence%20Predictions%20for%20Unrecognizable%20Images/#imagenet-results-eas","title":"ImageNet Results - EAs","text":"<ul> <li>Harder to fool</li> <li>Different runs result into differences in patterns</li> <li>Removing repetitive patterns does not cause a dramatic confidence drop</li> <li>Global structures are not learned</li> <li></li> <li></li> <li></li> </ul>"},{"location":"KB/Deep%20Neural%20Networks%20are%20Easily%20Fooled%20High%20Confidence%20Predictions%20for%20Unrecognizable%20Images/#what-about-a-fooling-class","title":"What about a Fooling Class?","text":"<ul> <li>MNIST<ul> <li>Added an 11th fooling class. </li> <li>Evolved unrecognizable images were still recognized as digits. </li> <li>Number of misclassifications did not decrease.</li> </ul> </li> <li>ImageNet<ul> <li>Added an 1001st fooling class. </li> <li>No decrease in confidence for directly evolved images, but already low confidence. </li> <li>Confidence decreased from 88.1% to 11.7% for indirectly evolved images.</li> </ul> </li> <li>Indirectly evolved images are easier to differentiate.</li> </ul>"},{"location":"KB/Deep%20Neural%20Networks%20are%20Easily%20Fooled%20High%20Confidence%20Predictions%20for%20Unrecognizable%20Images/#gradient-ascent-results","title":"Gradient Ascent Results","text":"<ul> <li>Maximize softmax output</li> <li>Produced unrecognizable images classified with 99.99% confidence</li> </ul>"},{"location":"KB/Deep%20Visual%20Explanation/","title":"Deep Visual Explanation","text":""},{"location":"KB/Deep%20Visual%20Explanation/#deep-visual-explanation","title":"Deep Visual Explanation","text":"<ul> <li>@babikerIntroductionDeepVisual2018</li> <li>They captured the discriminative areas of the input image by considering the activation of high and low spatial scales in the Fourier space.</li> <li>\"Deep,\" because it is the development and performance of deep neural network models that we want to understand. \"Visual,\" because we believe that the most rapid insight into a complex multi-dimensional model is provided by appropriate visualization techniques, and \"Explanation,\" because in the spectrum from instrumentation by inserting print statements to the abductive inference of explanatory hypotheses, we believe that the key to understanding deep learning relies on the identification and exposure of hypotheses about the performance behavior of a learned deep model.</li> <li>Deep convolutional neural networks (DCNN) produce spatial information at the convolution layers</li> <li>loss of information makes the explanation process challenging, especially when it comes to interpreting the output of sensitive data such as medical images</li> <li>Our immediate goal is to create an explanation about the outcome of a DCNN, i.e., to identify which discriminative pixels in the image influence the final prediction</li> <li>To approach this task in this restricted context, we assume that the convolution feature maps X at pooling layer l contain some relevant information about class y</li> <li>We can then write our solution as: \\(D : I \\rightarrow y_{i} \\rightarrow S\\) i.e., map the input I to class \\(y_{i}\\) using network D, and compute the evidence/explanation S</li> <li>output. So to explain \\(y_{i} \\rightarrow S\\), we can compute the low-spatial scale and high-spatial scale activations of every feature map</li> </ul>"},{"location":"KB/Deep%20Visual%20Explanation/#visual-explanation","title":"Visual Explanation","text":"<ul> <li>Explanaton in Fourier domain. Function \\(F(x)\\) represents transform with \\(x \\in \\mathbb{R}\\) , \\(x\\) is a feature map at a conv layer</li> <li>For every \\(x_{i} \\in X\\) of size \\(M \\times N\\) , the transform  can be written as $$ F(u,v) = \\Sigma_{k=0}^{M-1} \\Sigma_{j=0}^{N-1}f(k,j)e^{-i2\\pi(\\frac{uk}{M}+ \\frac{vj}{N})} $$<ul> <li>\\(f(k,j)\\) is feature map at layer \\(l\\)</li> <li>exp term is the basis function</li> <li>inverse of fourier is $$ f(m,n) = \\frac{1}{M\\times N} \\Sigma_{u=0}^{M-1} \\Sigma_{v=0}^{N-1}F(u,v)e^{i2\\pi(\\frac{ux}{M}+ \\frac{vy}{N})} $$</li> </ul> </li> <li>For every feature map, \\(x_{i} \\in X\\), visual explanation is $$ S = \\Sigma_{i=1}F^{-1}(F(x_{i} * G_{1}) * F^{-1}(F(x_{i})*(1-G_{2}))) $$<ul> <li>\\(G_{1}, G_{2}\\) are Guassians at different \\(\\sigma\\) values,</li> <li>Low spatial scale activation \\(F(x_{i})*G_{1}\\)</li> <li>High scale activation \\(F^{-1}(F(x_{i})*(1-G_{2}))\\)</li> </ul> </li> <li></li> </ul>"},{"location":"KB/Deep%20Visual%20Explanation/#targeted-deep-visual-explanation","title":"Targeted Deep Visual Explanation","text":"<ul> <li>In our simple case of image classification (cf. speech, language) one of the ultimate goals of the visual explanation in the context of debugging is to be precise when determining the component salient patch.</li> <li>Therefore, we should penalize any activations that do not contribute much</li> <li>To handle this, we propose a method called targeted-DVE to provide a more targeted explanation. This algorithm removes any pixel that has less influence on the best explanation</li> <li>The process is identical to our previous approach except that, we slightly modify the final output S obtained in Algorithm 1. This is done, by computing S0 as follows</li> <li> \\[S' = F^{\u22121}(F(S) * G_{1}) * F^{\u22121}(F(S * (1 \u2212 G_{2})) \\] </li> <li>Our approach captures the discriminative pixels by considering the activation of high and low spatial scales in Fourier space.</li> <li>We experimented with a simple version of our approach on image classification.</li> </ul>"},{"location":"KB/Deep%20Visual%20Explanation/#images","title":"Images","text":""},{"location":"KB/DeepFM/","title":"DeepFM","text":""},{"location":"KB/DeepFM/#deepfm","title":"DeepFM","text":"<ul> <li>DeepFM: a Factorization-Machine Based Neural Network for CTR Prediction</li> <li>Learning sophisticated feature interactions behind user behaviors is critical in maximizing CTR for recommender systems</li> <li>existing methods seem to have a strong bias towards low- or high-order interactions, or require expertise feature engineering</li> <li>an end-to-end learning model that emphasizes both low- and high-order feature interactions</li> <li>DeepFM is a Factorization-Machine (FM) based Neural Network for CTR prediction, to overcome the shortcomings of the state-of-the-art models and to achieve better performance.</li> <li>DeepFM trains a deep component and an FM component jointly and models low-order feature interactions through FM and models high-order feature interactions through the DNN</li> <li>DeepFM can be trained end-to-end with a shared input to its \u201cwide\u201d and \u201cdeep\u201d parts, with no need of feature engineering besides raw features.</li> <li>1) it does not need any pre-training; 2) it learns both high- and low-order feature interactions; 3) it introduces a sharing strategy of feature embedding to avoid feature engineering</li> <li>combines the power of factorization machines for recommendation and deep learning for feature learning in a new neural network architecture</li> <li>Criteo</li> </ul>"},{"location":"KB/DeepFool/","title":"DeepFool","text":"<ul> <li><code>toc</code></li> <li>@DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks</li> <li> </li> </ul>"},{"location":"KB/DeepFool/#deepfool","title":"DeepFool","text":""},{"location":"KB/DeepFool/#_1","title":"DeepFool","text":""},{"location":"KB/DeepLIFT/","title":"DeepLIFT","text":""},{"location":"KB/DeepLIFT/#deeplift","title":"DeepLIFT","text":"<ul> <li>@liDeepLIFTDeepLabelSpecific2022</li> </ul>"},{"location":"KB/DeepLearning/","title":"Index","text":"<ul> <li>Features</li> <li>Fundamentals</li> <li>Issues</li> <li>Layers</li> <li>Architectures</li> <li>Optimizers</li> <li>Regularization</li> <li>LossFunctions</li> <li>Activation Functions</li> <li>Initialization</li> <li>Augmentation</li> <li>Uncertainty</li> <li>Optimizing Code</li> <li>Useful Codes</li> <li>Federated Learning</li> <li>Reinforcement Learning</li> <li>Refs</li> </ul> <p>#anchor</p>"},{"location":"KB/DeepNet/","title":"DeepNet","text":""},{"location":"KB/DeepNet/#deepnet","title":"DeepNet","text":"<ul> <li>DeepNet: Scaling Transformers to 1,000 Layers</li> <li>allows train extremely deep transformers with 1000L+ layers</li> <li>fundamental, effective and simple</li> <li>can be used in any Transformer architecture (encoder, decoder, encoder-decoder) which covers almost all different tasks across AI areas (language, vision, speech, multimodal, and beyond)</li> <li>newly proposed normalization function</li> <li>DeepNorm</li> <li>It works alongside a dedicated initialization scheme based on Xavier initialization.</li> <li>These two tricks lead to greater stability during the training which allows the authors to scale their modified Transformer architecture (DeepNet) up to 1000 layers</li> </ul>"},{"location":"KB/DeepNorm/","title":"DeepNorm","text":""},{"location":"KB/DeepNorm/#deepnorm","title":"DeepNorm","text":"<ul> <li>which modifies the residual connection in Transformers</li> <li>theoretical justification of bounding the model update by a constant which makes stable training possible in a principled way</li> <li>DeepNorm modifies the residual connection in the Transformer architecture by up-scaling it before performing layer normalization</li> </ul>"},{"location":"KB/DeepPERF/","title":"DeepPERF","text":""},{"location":"KB/DeepPERF/#deepperf","title":"DeepPERF","text":"<ul> <li>DeepPERF: a Deep Learning-Based Approach for Improving Software Performance</li> <li>Performance bugs may not cause system failure and may depend on user input, so detecting them can be challenging</li> <li>harder to fix than non-performance bugs</li> <li>performance bug detection approaches have emerged to help developers identify performance issues</li> <li>Building rule-based analyzers is a non-trivial task, as it requires achieving the right balance between precision and recall</li> <li>Once developed, maintaining these rules can also be costly</li> <li>large transformer model to suggest changes at application source code level to improve its performance</li> <li>first pretrain the model using masked language modelling (MLM) tasks on English text and source code taken from open source repositories on GitHub, followed by finetuning on millions of performance commits made by .NET developers</li> <li>recommend patches to provide a wide-range of performance optimizations in C<code>#</code> applications</li> <li>Most suggested changes involve modifications to high-level constructs like API/Data Structure usages or other algorithmic changes, often spanning multiple methods, which cannot be optimized away automatically by the C<code>#</code> compiler and could, therefore, lead to slow-downs on the user\u2019s side</li> </ul>"},{"location":"KB/Default%20mode%20network/","title":"Default mode network","text":"<p>toc: true title: Default mode network</p> <p>categories: ['temp']</p>"},{"location":"KB/Default%20mode%20network/#default-mode-network","title":"Default Mode Network","text":"<ul> <li>Brain is organized into coherent spatio-temporal networks such as this one</li> <li>Brain areas in the Brain Cortex that constantly decreased their activity while performing highly demanding task</li> <li>Some studies revealed task-induced activations in the DMN, e.g. when internally directed/self-related cognition is required</li> <li>Altered with addictions</li> <li>Functional connectivity within DMN may predict successful quitting, the intensity of withdrawal-induced craving and the degree of cognitive decline in addictions</li> <li>They ^1 (as key node of the cognitive control network) and the Anterior Cingulate/Prefrontal cortex (as key nodes of the DMN)</li> </ul> <p>^1 associated with individual differences in Internet tendency in healthy young adults , Neuropsychologia</p>"},{"location":"KB/Defibrillator/","title":"Defibrillator","text":""},{"location":"KB/Defibrillator/#defibrillator","title":"Defibrillator","text":"<ul> <li>A device that discharges an electric current to the heart to correct cardiac arrhythmia or arrest</li> </ul>"},{"location":"KB/Degrees%20of%20Freedom/","title":"Degrees of Freedom","text":""},{"location":"KB/Degrees%20of%20Freedom/#degrees-of-freedom","title":"Degrees of Freedom","text":"<ul> <li>The number of independent directions or joints of the robot (R15.07), which would allow the robot to move its end effector through the required sequence of motions. For arbitrary positioning, 6 degrees of freedom are needed: 3 for position (left-right, forward-backward and up- down), and 3 for orientation (yaw, pitch and roll).</li> </ul>"},{"location":"KB/DeiT/","title":"DeiT","text":"<p>toc: true title: DeiT</p> <p>categories: ['temp']</p>"},{"location":"KB/DeiT/#deit","title":"DeiT","text":"<ul> <li>paper</li> <li>blog</li> <li>Conv free Transformer, Vision Transformer</li> <li>does not require very large amount of data   id:: 62a8a66a-941e-4a6d-918a-bb49cd496b15</li> <li>Knowledge Distillation</li> <li>teacher-student strategy specific to transformers</li> <li>Distillation Token</li> <li>ConvNet as teacher through Attention   id:: 62a8a6b2-abf4-4869-934e-c75d05884304</li> <li>ImageNet</li> <li> </li> </ul>"},{"location":"KB/DeiT/#begin_caution","title":"+BEGIN_CAUTION","text":"Heh. Didnt they say no convs?   #+END_CAUTION"},{"location":"KB/Delta%20Waves/","title":"Delta Waves","text":""},{"location":"KB/Delta%20Waves/#delta-waves","title":"Delta Waves","text":"<ul> <li>2-4 Hz</li> <li>sleep</li> <li></li> </ul>"},{"location":"KB/Demographic%20Parity/","title":"Demographic Parity","text":""},{"location":"KB/Demographic%20Parity/#demographic-parity","title":"Demographic Parity","text":"<ul> <li>A fairness metric that is satisfied if the results of a model's classification are not dependent on a given sensitive attribute.</li> <li>For example, if both Lilliputians and Brobdingnagians apply to Glubbdubdrib University, demographic parity is achieved if the percentage of Lilliputians admitted is the same as the percentage of Brobdingnagians admitted, irrespective of whether one group is on average more qualified than the other.</li> <li>Contrast with equalized odds and equality of opportunity, which permit classification results in aggregate to depend on sensitive attributes, but do not permit classification results for certain specified ground-truth labels to depend on sensitive attributes. See \"Attacking discrimination with smarter machine learning\" for a visualization exploring the tradeoffs when optimizing for demographic parity.</li> </ul>"},{"location":"KB/Dendrites/","title":"Dendrites","text":""},{"location":"KB/Dendrites/#dendrites","title":"Dendrites","text":"<ul> <li>Short nerve fibers that project from a neuron, generally receiving messages from the axons of other neurons and relaying them to the cell\u2019s nucleus.</li> </ul>"},{"location":"KB/Denoising%20Autoencoder/","title":"Denoising Autoencoder","text":""},{"location":"KB/Denoising%20Autoencoder/#denoising-autoencoder","title":"Denoising Autoencoder","text":"<ul> <li>Corrupt inputs with noise</li> <li>Salt pepper noise</li> <li>Normal Distribution</li> <li>Compare outputs to clean inputs</li> <li>$\\(L(X) = n^{-1}\\Sigma_i||x_i - D(E(\\tilde x))||^2\\)</li> </ul>"},{"location":"KB/Dense%20Net/","title":"Dense Net","text":""},{"location":"KB/Dense%20Net/#dense-net","title":"Dense Net","text":"<ul> <li>Generalized Res Net</li> <li>Skip connections inside the Dense block itself</li> <li>![im](images/Dense Skip Connections]</li> <li>Transition layer -&gt; Dense -&gt; 1x1 Conv , 2x2 avg pool -&gt; Dense</li> </ul>"},{"location":"KB/Dense%20Skip%20Connections/","title":"Dense Skip Connections","text":""},{"location":"KB/Dense%20Skip%20Connections/#dense-skip-connections","title":"Dense Skip Connections","text":"<ul> <li> \\[x_i = F(x_0,x_1 ,\u2026 ,x_{i-1})\\] <ul> <li>F : 3x3 Conv + Relu -&gt; k feature maps</li> <li>no of feature maps : \\(\\(k(i-1) + k_0\\)\\) where k is growth rate (hyperparam)</li> </ul> </li> <li>Skip Connection</li> </ul>"},{"location":"KB/Dense%20Vector%20Indexes/","title":"Dense Vector Indexes","text":""},{"location":"KB/Dense%20Vector%20Indexes/#dense-vector-indexes","title":"Dense Vector Indexes","text":"<ul> <li> <p>advanced dense vector indexing techniques to capture the semantic meaning and context of documents more effectively than traditional keyword-based methods in the enterprise knowledge base</p> </li> <li> <p>HNSW</p> </li> <li> <p>PQ</p> </li> <li> <p>IVFADC</p> </li> <li> <p>Sparse Encoder Indexes</p> </li> </ul>"},{"location":"KB/Dense/","title":"Dense","text":""},{"location":"KB/Dense/#dense","title":"Dense","text":"<ul> <li>Weighted LinearRegression</li> <li>Forward<ul> <li> \\[z = W\\cdot x + b$$ , $$y=g(z)\\] </li> </ul> </li> <li>Backward<ul> <li> \\[\\delta = g'(z)\\circ \\nabla_y E\\] </li> <li> \\[\\nabla_WE = \\delta \\cdot x^T$$ , $$\\nabla_bE = \\delta\\] </li> <li> \\[\\nabla_xE = W^T\\cdot \\delta\\] </li> </ul> </li> </ul>"},{"location":"KB/Density/","title":"Density","text":""},{"location":"KB/Density/#density","title":"Density","text":"<ul> <li>mass / vol</li> <li> \\[r - m/V\\] </li> </ul>"},{"location":"KB/Deontological%20ethics/","title":"Deontological ethics","text":""},{"location":"KB/Deontological%20ethics/#deontological-ethics","title":"Deontological Ethics","text":"<ul> <li>an agent is ethical if and only if it respects obligations, duties and rights related to given situations</li> <li>act in accordance to established social norms</li> </ul>"},{"location":"KB/Depthwise%20Separable/","title":"Depthwise Separable","text":""},{"location":"KB/Depthwise%20Separable/#depthwise-separable","title":"Depthwise Separable","text":"<ul> <li>Only transforms the input once and saves computation -&gt; elongate it to more channels</li> <li>From C -&gt; F channels : Use F instances of a 1x1xC filter</li> <li></li> </ul>"},{"location":"KB/Derivational%20Morphology/","title":"Derivational Morphology","text":""},{"location":"KB/Derivational%20Morphology/#derivational-morphology","title":"Derivational Morphology","text":"<ul> <li>creates new word by changing the POS tag</li> </ul>"},{"location":"KB/Detailed%20Balance/","title":"Detailed Balance","text":""},{"location":"KB/Detailed%20Balance/#detailed-balance","title":"Detailed Balance","text":"<ul> <li>To find a transition kernel T(x|y) for a homogenous, Ergodic Markov Chain</li> <li>If we pick some state x with the Probability given by g and multiply its prob g(x) with the transition Probability density T(x|y) (weighted by Probability density of x) then its the same as the reverse weighted transiting Probability density from y to x</li> <li> \\[\\forall x,y \\in \\mathbb{R}^{k}: T(y|x)g(x) = T(x|y)g(y)\\] </li> <li>If T(x|y) has detailed balance wrt g, then it is an Invariant Distribution</li> <li> \\[\\int_{\\mathbb{R}^{k}}T(x|y)g(y)dy = \\int_{\\mathbb{R}^{k}}T(y|x)g(x)dy = g(x)\\int_{\\mathbb{R}^{k}}P(y|x)dy = g(x)\\] </li> </ul>"},{"location":"KB/Determiners/","title":"Determiners","text":""},{"location":"KB/Determiners/#determiners","title":"Determiners","text":"<ul> <li>indicate specific object (a, the,that)</li> </ul>"},{"location":"KB/DevOn%20AI%20dev/","title":"DevOn AI dev","text":""},{"location":"KB/DevOn%20AI%20dev/#devon-ai-dev","title":"DevOn AI Dev","text":"<p>As the days go by, Machine Learning and AI are slowly becoming terms that every company wants to have in their portfolio. While this drive leads to many innovations, most companies are not sure how to do AI \"well\". They want to use AI but need clarification on whether it is required, how to handle bias, how to create proper data, or even what models (ML vs. DL) to choose. The job of an AI dev, then, is to provide the key information required to find and fulfill KPIs given any project. </p> <p>My expertise is a combination of data analytics and computer vision, and as of a month ago, I also have a Master in Artificial Intelligence from the University of Groningen. I am familiar with the tools required for basic and advanced AI and analytics from internships, research projects, papers, freelance work, and many personal projects. That being the case, I can step aside from my experience with AI and decide if a project needs another solution in reality. I am familiar with PyTorch, Tensorflow, supervised and unsupervised learning, data preprocessing, and many of the other tools that are required to create successful AI applications. I am familiar with the pipeline, from analyzing data to building the model to deployment.</p> <p>The customer is king, they say, and the first step in having happy clients is understanding what they truly want and then being able to give them a solution they can use. Although I have a lot to learn, I can contribute to any team I get the chance to work with. This job would be the perfect next step for me, and so I hope you give me a chance to work with you and your team.</p>"},{"location":"KB/DiTransitive%20verb/","title":"DiTransitive verb","text":""},{"location":"KB/DiTransitive%20verb/#ditransitive-verb","title":"DiTransitive Verb","text":"<ul> <li>a verb has two noun objects</li> <li>I cooked a duck for her</li> </ul>"},{"location":"KB/Dialyser/","title":"Dialyser","text":""},{"location":"KB/Dialyser/#dialyser","title":"Dialyser","text":"<ul> <li>A machine that replaces the function of the kidneys by removing solutes, excess water and toxins from the blood</li> </ul>"},{"location":"KB/Dialysis/","title":"Dialysis","text":""},{"location":"KB/Dialysis/#dialysis","title":"Dialysis","text":"<ul> <li>Process to filter the blood, usually performed as a result of kidney failure</li> </ul>"},{"location":"KB/Dice%20Score/","title":"Dice Score","text":""},{"location":"KB/Dice%20Score/#dice-score","title":"Dice Score","text":"<ul> <li>2 * the Area of Overlap divided by the total number of pixels in both images</li> </ul>"},{"location":"KB/Dictionary%20Learning/","title":"Dictionary Learning","text":""},{"location":"KB/Dictionary%20Learning/#dictionary-learning","title":"Dictionary Learning","text":"<ul> <li>Given : N unlabeled data points \\(\\(x_i \\in \\mathcal{R}^d\\)\\)</li> <li>To find:<ul> <li>Linear rep of these points based on set of basis vectors<ul> <li> \\[x = \\Sigma_i^k r_i \\cdot d_i = Dr\\] </li> <li>dimension d</li> <li>r are repr weights corresponding to basis vector d</li> <li>D is a dict with basis vectors</li> <li>R contains weights. Scalar</li> <li>$\\(||d_i|| \\leq 1\\)</li> </ul> </li> </ul> </li> <li>Sparse Dictionary Learning Loss</li> <li>After learning, these can be used as discriminative features<ul> <li>Expensive to compute</li> </ul> </li> </ul>"},{"location":"KB/Diffusion%20LM/","title":"Diffusion LM","text":""},{"location":"KB/Diffusion%20LM/#diffusion-lm","title":"Diffusion LM","text":"<ul> <li>Diffusion-LM Improves Controllable Text Generation</li> <li>Controlling the behavior of language models (LMs) without re-training is a major open problem in natural language generation</li> <li>non-autoregressive language model based on continuous diffusions</li> <li>substantial departure from the current paradigm of discrete autoregressive generation</li> <li>iteratively denoises a sequence of Gaussian vectors into word vectors, yielding a sequence of intermediate latent variables</li> <li>continuous, hierarchical nature of these intermediate variables enables a simple gradient-based algorithm to perform complex, controllable generation tasks</li> <li>successful control of Diffusion-LM for six challenging fine-grained control tasks</li> </ul>"},{"location":"KB/Diffusion%20Tensor/","title":"Diffusion Tensor","text":""},{"location":"KB/Diffusion%20Tensor/#diffusion-tensor","title":"Diffusion Tensor","text":""},{"location":"KB/Digital%20Phenotyping/","title":"Digital Phenotyping","text":""},{"location":"KB/Digital%20Phenotyping/#digital-phenotyping","title":"Digital Phenotyping","text":"<ul> <li>The use of data collected from personal electronic devices like smart phones to diagnose and monitor medical and psychiatric conditions.</li> </ul>"},{"location":"KB/Dikes%20and%20Rivers/","title":"Dikes and Rivers","text":""},{"location":"KB/Dikes%20and%20Rivers/#dikes-and-rivers","title":"Dikes and Rivers","text":"<ul> <li>Subjects alternate producing time intervals of a short and a long duration.  </li> <li>Initially, short is 2 seconds and long is 3.1 seconds</li> <li>They receive feedback on whether their estimate is within +/- 12.5% of the target, and receive \u201ctoo short\u201d or \u201ctoo long\u201d as feedback otherwise.</li> <li>After a number of trials, the criterion for the long interval starts to change</li> <li></li> <li>Short intervals are also effected and vice versa</li> </ul>"},{"location":"KB/Dikes%20and%20Rivers/#model","title":"Model","text":"<ul> <li>ACTR declarative memory + Declarative Memory Blending</li> </ul>"},{"location":"KB/Dilated%20Sliding%20Window%20Attention/","title":"Dilated Sliding Window Attention","text":""},{"location":"KB/Dilated%20Sliding%20Window%20Attention/#dilated-sliding-window-attention","title":"Dilated Sliding Window Attention","text":"<ul> <li>Analgous to dilated CNN</li> <li>Assuming a fixed \\(d\\) and \\(w\\) for all layers, receptive field is \\(l \\times d \\times w\\) which can reach tens of thousands of tokens even with small values of \\(d\\)</li> <li></li> </ul>"},{"location":"KB/Dimensionality%20Reduction/","title":"Dimensionality Reduction","text":""},{"location":"KB/Dimensionality%20Reduction/#dimensionality-reduction","title":"Dimensionality Reduction","text":"<ul> <li>Given<ul> <li>\\(\\((x_i)_{i = 1, \u2026,N}\\)\\) raw data points, \\(\\(x_i \\in \\mathbb{R}^n\\)\\) : High dim</li> </ul> </li> <li>To get<ul> <li>Low dim \\(\\(x_i \\in \\mathbb{R}^m\\)\\) where \\(\\(m &lt;n\\)\\)</li> </ul> </li> <li>f(x) is composed of m component functions aka features<ul> <li>\\(\\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\)\\) : scalar characteristic</li> <li>m such features : feature map<ul> <li> \\[(f_1 , \u2026, f_m)' =: f : \\mathbb{R}^n \\rightarrow \\mathbb{R}^m\\] </li> <li>maps input vectors to feature vectors</li> </ul> </li> </ul> </li> <li>KMeans</li> <li>PCA</li> <li>SOMs</li> </ul>"},{"location":"KB/Dimensionality%20Reduction/#anchor","title":"anchor","text":""},{"location":"KB/Dirac%20Delta/","title":"Dirac Delta","text":""},{"location":"KB/Dirac%20Delta/#dirac-delta","title":"Dirac Delta","text":"<p>-\\(\\(P(X \\in A) = \\begin{cases}1&amp; \\text{if 0}\\in A\\\\[2ex] 0&amp; \\text{if } 0 \\notin A \\end{cases}\\)\\)</p> <ul> <li> \\[P(X \\in A) = \\int_{A}\\delta(x)dx\\] </li> </ul>"},{"location":"KB/Dirac%20Delta/#in-mathbbrn","title":"In \\(\\mathbb{R}^{n}\\)","text":"<ul> <li>it is a PDF which describes prob concentrated in the origin</li> <li>Multi Point Distribution -&gt; combine dirac deltas</li> <li></li> </ul>"},{"location":"KB/Direct%20entropy%20minimization/","title":"Direct entropy minimization","text":""},{"location":"KB/Direct%20entropy%20minimization/#direct-entropy-minimization","title":"Direct Entropy Minimization","text":"<ul> <li>On the source domain we train our model,</li> <li>as usual using a supervised loss</li> <li>For the target domain, we do not have annotations and we can no longer use the segmentation loss to train</li> <li>supervision signal that could leverage visual information from the target samples, in spite of the lack of annotations</li> <li>constrain</li> <li>to produce high-confident predictions on target samples similarly to source samples</li> <li>entropy loss \\(\\mathcal{L}_{ent}\\) to maximize directly the prediction confidence in the target domain.</li> <li>Shannon Entropy</li> </ul>"},{"location":"KB/Direct-drive/","title":"Direct drive","text":""},{"location":"KB/Direct-drive/#direct-drive","title":"Direct-drive","text":"<ul> <li>Joint actuation, including no transmission elements (i.e., the link is bolted onto the output of the motor.)</li> </ul>"},{"location":"KB/Dirichlet%20Distribution/","title":"Dirichlet Distribution","text":""},{"location":"KB/Dirichlet%20Distribution/#dirichlet-distribution","title":"Dirichlet Distribution","text":"<ul> <li>PDF</li> <li> \\[h(\\theta|\\alpha) = \\frac{1}{Z(\\alpha)} \\Pi_{j=1}^{l}\\theta_{j}^{a_{j}-1}\\] </li> <li>\\(\\(Z(\\alpha) = \\int_{\\mathcal{H}}\\Pi_{j=1}^{l}\\theta_{j}^{\\alpha_{j}-1}d\\theta\\)\\) is normalization constant. Ensures integral of h over \\(\\mathcal{H}\\) is 1</li> </ul>"},{"location":"KB/Discrete%20-%3E%20Continuous/","title":"Discrete -> Continous Transforms","text":""},{"location":"KB/Discrete%20-%3E%20Continuous/#discrete-continous-transforms","title":"Discrete -&gt; Continous Transforms","text":""},{"location":"KB/Discrete%20-%3E%20Continuous/#one-hot","title":"One hot","text":""},{"location":"KB/Discrete%20-%3E%20Continuous/#binary-pattern","title":"Binary pattern","text":""},{"location":"KB/Discrete%20-%3E%20Continuous/#linear-scale","title":"Linear scale","text":""},{"location":"KB/Discrete%20-%3E%20Continuous/#word-vectors","title":"Word Vectors","text":""},{"location":"KB/Discrete%20Cosine%20Transform/","title":"Discrete Cosine Transform","text":""},{"location":"KB/Discrete%20Cosine%20Transform/#discrete-cosine-transform","title":"Discrete Cosine Transform","text":"<ul> <li>machine-learning-articles/cnns-and-feature-extraction-the-curse-of-data-sparsity.md at main \u00b7 christianversloot/machine-learning-articles #Roam-Highlights</li> <li>expresses a finite sequence of data points in terms of a sum of cosine functions oscillating at different frequencies<ul> <li>you make the CNN blind to the unique aspects represented by the numbers\u2026 despite the fact that they are already in there</li> <li>In my opinion, this can be explained by looking at the internals of a convolutional layer. It works as follows. You specify a number of filters which, during training, learn to recognize unique aspects of the image-like data. They can then be used to classify new samples - quite accurately, as we have seen with raw MNIST data. This means that the convolutional layer already makes your data representation sparser. What's more, this effect gets even stronger when layers like Pooling are applied</li> <li>But when you downsample the data first by e.g. applying the DCT, you thus effectively apply sparsening twice. My only conclusion can thus be that by consequence, the convolutional filters can no longer learn the unique aspects within the image-like data, as they are hidden in the data set made compact. Only then, I literally found out why people always suggest to input your image data into CNNs as untransformed as possible.</li> <li>Besides the architectural differences between them, one must also conclude that CNNs make data essentially sparser while SVMs do not.</li> </ul> </li> </ul>"},{"location":"KB/Disparate%20Impact/","title":"Disparate Impact","text":""},{"location":"KB/Disparate%20Impact/#disparate-impact","title":"Disparate Impact","text":"<ul> <li>Making decisions about people that impact different population subgroups disproportionately. This usually refers to situations where an algorithmic decision-making process harms or benefits some subgroups more than others.</li> <li>For example, suppose an algorithm that determines a Lilliputian's eligibility for a miniature-home loan is more likely to classify them as \u201cineligible\u201d if their mailing address contains a certain postal code. If Big-Endian Lilliputians are more likely to have mailing addresses with this postal code than Little-Endian Lilliputians, then this algorithm may result in disparate impact.</li> </ul>"},{"location":"KB/Disparate%20Treatment/","title":"Disparate Treatment","text":""},{"location":"KB/Disparate%20Treatment/#disparate-treatment","title":"Disparate Treatment","text":"<ul> <li>Factoring subjects' sensitive attributes into an algorithmic decision-making process such that different subgroups of people are treated differently.</li> <li>For example, consider an algorithm that determines Lilliputians\u2019 eligibility for a miniature-home loan based on the data they provide in their loan application. If the algorithm uses a Lilliputian\u2019s affiliation as Big-Endian or Little-Endian as an input, it is enacting disparate treatment along that dimension.</li> <li>Contrast with disparate impact, which focuses on disparities in the societal impacts of algorithmic decisions on subgroups, irrespective of whether those subgroups are inputs to the model.</li> <li>Because sensitive attributes are almost always correlated with other features the data may have, explicitly removing sensitive attribute information does not guarantee that subgroups will be treated equally. For example, removing sensitive demographic attributes from a training data set that still includes postal code as a feature may address disparate treatment of subgroups, but there still might be disparate impact upon these groups because postal code might serve as a proxy for other demographic information.</li> </ul>"},{"location":"KB/Displacement/","title":"Displacement","text":""},{"location":"KB/Displacement/#displacement","title":"Displacement","text":"<ul> <li> \\[\\Delta x = x_{f}-x_{i}\\] </li> </ul>"},{"location":"KB/Distance%20Measures/","title":"Distance Measures","text":""},{"location":"KB/Distance%20Measures/#distance-measures","title":"Distance Measures","text":"<ul> <li>Euclidean Distance</li> <li>Cosine Similarity</li> <li>Hamming Distance</li> <li>Manhattan Distance</li> <li>Chebyshev Distance</li> <li>Hausdorff Distance</li> <li>Chi Squared Distance</li> <li>Bhattacharya Distance</li> <li>Minkowski Distance</li> <li>Jaccard Distance</li> <li>Haversine Distance</li> <li>S\u00f8rensen-Dice Index</li> </ul>"},{"location":"KB/DistillBERT/","title":"DistillBERT","text":""},{"location":"KB/DistillBERT/#distillbert","title":"DistillBERT","text":"<ul> <li>DistilBERT, a Distilled Version of BERT: Smaller, Faster, Cheaper and Lighter</li> <li>Huggingface</li> <li>general-purpose pre-trained version of BERT</li> <li>40% smaller, 60% faster, cheaper to pre-train, and retains 97% of the language understanding capabilities</li> <li>knowledge distillation during the pre-training phase</li> <li>triple loss combining language modeling, distillation and cosine-distance losses</li> </ul>"},{"location":"KB/Distillation%20Algorithms/","title":"Distillation Algorithms","text":""},{"location":"KB/Distillation%20Algorithms/#distillation-algorithms","title":"Distillation Algorithms","text":"<ul> <li>Adversarial Distillation</li> <li>Multi Teacher Distillation</li> <li>Cross Modal Distillation</li> <li>Graph Based Distillation</li> <li>Attention Based Distillation</li> <li>Data Free Distillation</li> <li>Quantized Distillation</li> </ul>"},{"location":"KB/Distillation%20Loss/","title":"Distillation Loss","text":""},{"location":"KB/Distillation%20Loss/#distillation-loss","title":"Distillation Loss","text":"<ul> <li> \\[\\mathscr{l}(p, softmax(z))+T^{2}\\mathscr{l}(softmax(\\frac{r}{T}), softmax(\\frac{z}{T}))\\] </li> <li>Negative Cross Entropy + other</li> <li>p is the true probability Distributions</li> <li>z,r are outputs of the student and teacher model</li> <li>T is the temperature to make Softmax smoother</li> </ul>"},{"location":"KB/Distillation%20Schemes/","title":"Distillation Schemes","text":""},{"location":"KB/Distillation%20Schemes/#distillation-schemes","title":"Distillation Schemes","text":"<ul> <li>Offline Distillation</li> <li>Self Distillation</li> </ul>"},{"location":"KB/Distillation%20Token/","title":"Distillation Token","text":"<p>toc: true title: Distillation Token</p> <p>categories: ['temp']</p>"},{"location":"KB/Distillation%20Token/#distillation-token","title":"Distillation Token","text":"<ul> <li>A learned vector that flows through the network along with the transformed image data</li> <li>cues the model for its distillation output, which can differ from its class output</li> <li>Specific to Transformers</li> </ul>"},{"location":"KB/Distilling%20the%20Knowledge%20in%20a%20Neural%20Network/","title":"Distilling the Knowledge in a Neural Network","text":""},{"location":"KB/Distilling%20the%20Knowledge%20in%20a%20Neural%20Network/#distilling-the-knowledge-in-a-neural-network","title":"Distilling the Knowledge in a Neural Network","text":"<ul> <li>Geoffrey Hinton, Oriol Vinyals, Jeff Dean</li> </ul>"},{"location":"KB/Distilling%20the%20Knowledge%20in%20a%20Neural%20Network/#intro","title":"Intro","text":"<ul> <li>compress the knowledge in an ensemble into a single model which is much easier to deploy</li> <li>new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse</li> <li>Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel</li> <li>Many insects have a larval form that is optimized for extracting energy and nutrients from the environment and a completely different adult form that is optimized for the very different requirements of traveling and reproduction</li> <li>training must extract structure from very large, highly redundant datasets but it does not need to operate in real time and it can use a huge amount of computation. Deployment to a large number of users, however, has much more stringent requirements on latency and computational resources.</li> <li>The cumbersome model could be an ensemble of separately trained models or a single very large model trained with a very strong regularizer such as dropout</li> <li>we tend to identify the knowledge in a trained model with the learned parameter values and this makes it hard to see how we can change the form of the model but keep the same knowledge.</li> <li>learned</li> <li>where T is a temperature that is normally set to 1</li> </ul>"},{"location":"KB/Distilling%20the%20Knowledge%20in%20a%20Neural%20Network/#observations","title":"Observations","text":"<ul> <li>This net achieved 67 test errors whereas a smaller net with two hidden layers of 800 rectified linear hidden units and no regularization achieved 146 errors</li> <li>soft targets can transfer a great deal of knowledge to the distilled model, including the knowledge about how to generalize that is learned from translated training data even though the transfer set does not contain any translations.</li> <li>When the distilled net had 300 or more units in each of its two hidden layers, all temperatures above 8 gave fairly similar results</li> <li>But when this was radically reduced to 30 units per layer, temperatures in the range 2.5 to 4 worked significantly better than higher or lower temperatures.</li> </ul>"},{"location":"KB/Distilling%20the%20Knowledge%20in%20a%20Neural%20Network/#automatic-speech-recognition","title":"Automatic Speech Recognition","text":"<ul> <li>State-of-the-art ASR systems currently use DNNs to map a (short) temporal context of features derived from the waveform to a probability distribution over the discrete states of a Hidden Markov Model (HMM)</li> <li>DNN produces a probability distribution over clusters of tri-phone states at each time and a decoder then finds a path through the HMM states that is the best compromise between using high probability states and producing a transcription that is probable under the language model.</li> <li>There is, however, another important objection to ensembles: If the individual models are large neural networks and the dataset is very large, the amount of computation required at training time is excessive, even though it is easy to parallelize.</li> </ul>"},{"location":"KB/Distilling%20the%20Knowledge%20in%20a%20Neural%20Network/#jft","title":"JFT","text":"<ul> <li>JFT is an internal Google dataset that has 100 million labeled images with 15,000 labels. When we did this work, Google\u2019s baseline model for JFT was a deep convolutional neural network that had been trained for about six months using asynchronous stochastic gradient descent on a large number of cores.</li> <li>When the number of classes is very large, it makes sense for the cumbersome model to be an ensemble that contains one generalist model trained on all the data and many 'specialist' models, each of which is trained on data that is highly enriched in examples from a very confusable subset of the classes (like different types of mushroom)</li> <li>The softmax of this type of specialist can be made much smaller by combining all of the classes it does not care about into a single dustbin class.</li> <li>To reduce overfitting and share the work of learning lower level feature detectors, each specialist model is initialized with the weights of the generalist model</li> <li>These weights are then slightly modified by training the specialist with half its examples coming from its special subset and half sampled at random from the remainder of the training set. After training, we can correct for the biased training set by incrementing the logit of the dustbin class by the log of the proportion by which the specialist class is oversampled.</li> <li>In order to derive groupings of object categories for the specialists, we decided to focus on categories that our full network often confuses.</li> <li>Even though we could have computed the confusion matrix and used it as a way to find such clusters, we opted for a simpler approach that does not require the true labels to construct the clusters. In particular, we apply a [clustering] algorithm to the covariance matrix of the predictions of our generalist model, so that a set of classes Sm that are often predicted together will be used as targets for one of our specialist models, m.</li> <li>on-line version of the K-means algorithm to the columns of the covariance matrix, and obtained reasonable clusters</li> <li>One of our main claims about using soft targets instead of hard targets is that a lot of helpful information can be carried in soft targets that could not possibly be encoded with a single hard target.</li> <li>It is even more remarkable to note that we did not have to do early stopping: the system with soft targets simply 'converged' to 57%. This shows that soft targets are a very effective way of communicating the regularities discovered by a model trained on all of the data to another model.</li> <li>The specialists that we used in our experiments on the JFT dataset collapsed all of their non-specialist classes into a single dustbin class. If we allow specialists to have a full softmax over all classes, there may be a much better way to prevent them overfitting than using early stopping. A specialist is trained on data that is highly enriched in its special classes.</li> <li>This means that the effective size of its training set is much smaller and it has a strong tendency to overfit on its special classes.</li> <li>The use of specialists that are trained on subsets of the data has some resemblance to mixtures of experts which use a gating network to compute the probability of assigning each example to each expert</li> <li>At the same time as the experts are learning to deal with the examples assigned to them, the gating network is learning to choose which experts to assign each example to based on the relative discriminative performance of the experts for that example.</li> <li>Using the discriminative performance of the experts to determine the learned assignments is much better than simply clustering the input vectors and assigning an expert to each cluster, but it makes the training hard to parallelize: First, the weighted training set for each expert keeps changing in a way that depends on all the other experts and second, the gating network needs to compare the performance of different experts on the same example to know how to revise its assignment probabilities.</li> </ul>"},{"location":"KB/Distilling%20the%20Knowledge%20in%20a%20Neural%20Network/#conclusions","title":"Conclusions","text":"<ul> <li>These difficulties have meant that mixtures of experts are rarely used in the regime where they might be most beneficial: tasks with huge datasets that contain distinctly different subsets.</li> <li>It is much easier to parallelize the training of multiple specialists</li> <li>e first train a generalist model and then use the confusion matrix to define the subsets that the specialists are trained on</li> <li>We have shown that distilling works very well for transferring knowledge from an ensemble or from a large highly regularized model into a smaller, distilled model.</li> <li>For really big neural networks, it can be infeasible even to train a full ensemble, but we have shown that the performance of a single really big net that has been trained for a very long time can be significantly improved by learning a large number of specialist nets, each of which learns to discriminate between the classes in a highly confusable cluster. We have not yet shown that we can distill the knowledge in the specialists back into the single large net.</li> </ul>"},{"location":"KB/Distributive%20Interpretation%20%282%29/","title":"Distributive Interpretation (2)","text":""},{"location":"KB/Distributive%20Interpretation%20%282%29/#distributive-interpretation-2","title":"Distributive Interpretation (2)","text":"<ul> <li>Object takes scope over the subject:</li> <li>Three aliens are holding two flags. = (Two flags, and then three aliens hold them)</li> </ul>"},{"location":"KB/Distributive%20Interpretation/","title":"Distributive Interpretation","text":""},{"location":"KB/Distributive%20Interpretation/#distributive-interpretation","title":"Distributive Interpretation","text":"<ul> <li>Subject takes scope over the object: Three aliens are holding two flags.</li> <li>Both Np's are interpreted individually and connected to each other No indicators of how they are connected.</li> </ul>"},{"location":"KB/Distributive%20units/","title":"Distributive units","text":""},{"location":"KB/Distributive%20units/#distributive-units","title":"Distributive Units","text":"<ul> <li>each unit responds to multiple categories</li> <li>You must see the entire pattern over a collection of units, to uniquely categorize an input.</li> <li>The states of individual units are uninterpretable</li> </ul>"},{"location":"KB/Divergence/","title":"Divergence","text":""},{"location":"KB/Divergence/#divergence","title":"Divergence","text":"<ul> <li>Flow field transports mass \\(\\(v:\\mathbb{R}^{3}\\rightarrow \\mathbb{R}^{3}\\)\\)</li> <li>Increase/loss of mass at point p</li> <li> \\[div_v: \\mathbb{R}^{3} \\rightarrow \\mathbb{R} = \\nabla \\cdot v = \\frac{\\partial v_{x}}{\\partial x} + \\frac{\\partial v_{y}}{\\partial y} + \\frac{\\partial v_{z}}{\\partial z}\\] </li> <li></li> </ul>"},{"location":"KB/Divide%20Oriented/","title":"Divide Oriented","text":""},{"location":"KB/Divide%20Oriented/#divide-oriented","title":"Divide Oriented","text":"<ul> <li>corresponds to physical realization (screen,printer), e.g., RGB, CMYK</li> </ul>"},{"location":"KB/Docker%20Cheatsheet/","title":"Docker Cheatsheet","text":"","tags":["cheatsheets"]},{"location":"KB/Docker%20Cheatsheet/#docker-cheatsheet","title":"Docker Cheatsheet","text":"","tags":["cheatsheets"]},{"location":"KB/Docker%20Cheatsheet/#minimal-workflow","title":"Minimal Workflow","text":"<pre><code>docker init\ndocker compose up --build\ndocker compose up --build -d #run_in_background\ndocker compose down #stop\n</code></pre>","tags":["cheatsheets"]},{"location":"KB/Docker%20Cheatsheet/#managing-containers","title":"Managing Containers","text":"Name Command Starting Containers docker container start nginx Stopping Containers docker container stop nginx Restarting Containers docker container restart nginx Pausing Containers docker container pause nginx Unpausing Containers docker container unpause nginx Blocking a Container docker container wait nginx Sending SIGKILL Containers docker container kill nginx Sending another signal docker container kill -s HUP nginx Connecting to an Existing Container docker container attach nginx Check the Containers docker ps To see all running containers docker container ls Container Logs docker logs infinite \u2018tail -f\u2019 Containers\u2019 Logs docker container logs infinite -f Inspecting Containers docker container inspect infinite Inspecting Containers for certain docker container inspect \u2013format \u2018{{ .NetworkSettings.IPAddress }}\u2019 $(docker ps -q) Containers Events docker system events infinite docker system events infinite docker container port infinite Running Processes docker container top infinite Container Resource Usage docker container stats infinite Inspecting changes to files or directories on a container\u2019s filesystem docker container diff infinite","tags":["cheatsheets"]},{"location":"KB/Docker%20Cheatsheet/#manage-images","title":"Manage Images","text":"Name Command Listing Images docker image ls Building Images docker build. From a Remote GIT Repository docker build github.com/creack/docker-firefox Instead of Specifying a Context, You Can Pass a Single Dockerfile in the URL or Pipe the File in via STDIN docker build \u2013 &lt; Dockerfile Building and Tagging docker build -t eon/infinite. Building a Dockerfile while Specifying the Build Context docker build -f myOtherDockerfile. Building from a Remote Dockerfile URI curl example.com/remote/Dockerfile|docker build -f \u2013 . Removing an Image docker image rm nginx Loading a Tarred Repository from a File or the Standard Input Stream docker image load &lt; ubuntu.tar.gz Saving an Image to a Tar Archive docker image save busybox &gt; ubuntu.tar Showing the History of an Image docker image history Creating an Image From a Container docker container commit nginx Tagging an Image docker image tag nginx eon01/nginx Pushing an Image docker image push eon01/nginx","tags":["cheatsheets"]},{"location":"KB/Docker%20Cheatsheet/#removing-images","title":"Removing Images","text":"Name Command Removing a Running Container docker container rm nginx Removing a Container and its Volume docker container rm -v nginx Removing all Exited Containers docker container rm $(docker container ls -a -f status=exited -q) Removing All Stopped Containers docker container rm <code>docker container ls -a -q</code> Removing a Docker Image docker image rm nginx Removing Dangling Images docker image rm $(docker image ls -f dangling=true -q) Removing all Images docker image rm $(docker image ls -a -q) Removing all Untagged Images docker image rm -f $(docker image ls |grep \u201c^\u201d|awk \u201c{print $3}\u201d) Stopping &amp; Removing all Containers docker container stop $(docker container ls -a -q) &amp;&amp; docker container rm $(docker container ls -a -q) Removing Dangling Volumes docker volume rm $(docker volume ls -f dangling=true -q) Removing all unused (containers, images, networks and volumes) docker system prune -f Clean all docker system prune -a","tags":["cheatsheets"]},{"location":"KB/Docker%20Cheatsheet/#dockerfile-commands","title":"Dockerfile Commands","text":"Command Description Example FROM Specifies the base image for the build FROM ubuntu:latest RUN Executes a command inside the container during build time RUN apt-get update &amp;&amp; apt-get install -y curl CMD Specifies the default command to run when the container starts CMD [\u201cnpm\u201d, \u201cstart\u201d] EXPOSE Informs Docker that the container listens on specific network ports at runtime EXPOSE 80/tcp ENV Sets environment variables inside the container ENV NODE_ENV=production COPY Copies files or directories from the build context into the container COPY app.js /usr/src/app/ ADD Similar to COPY but supports additional features like URL retrieval and decompression ADD https://example.com/file.tar.gz /usr/src/ WORKDIR Sets the working directory for subsequent instructions WORKDIR /usr/src/app ARG Defines variables that users can pass at build-time to the builder with the docker build command ARG VERSION=1.0 ENTRYPOINT Configures a container to run as an executable ENTRYPOINT [\u201cpython\u201d, \u201capp.py\u201d] VOLUME Creates a mount point and assigns it to a specified volume VOLUME /data USER Sets the user or UID to use when running the image USER appuser LABEL Adds metadata to an image in the form of key-value pairs LABEL version=\u201d1.0\u2033 maintainer=\u201dJohn Doe ONBUILD Configures commands to run when the image is used as the base for another build ONBUILD ADD . /app/src","tags":["cheatsheets"]},{"location":"KB/Docker%20Cheatsheet/#volume-commands","title":"Volume Commands","text":"Command Description Example volume create Creates a named volume docker volume create mydata volume ls Lists the available volumes docker volume ls volume inspect Displays detailed information about a volume docker volume inspect mydata volume rm Removes one or more volumes docker volume rm mydata volume prune Removes all unused volumes docker volume prune","tags":["cheatsheets"]},{"location":"KB/Document%20Triage/","title":"Document Triage","text":""},{"location":"KB/Document%20Triage/#document-triage","title":"Document Triage","text":"<ul> <li>Characters in file must be MACHINE READABLE (Character Encoding)</li> <li>Character Encoding Identification (ASCII, UNICODE..)</li> <li>Language Identification (English, French,..)</li> <li>Text Sectioning</li> </ul>"},{"location":"KB/Dopamine/","title":"Dopamine","text":"<p>toc: true title: Dopamine</p> <p>categories: ['temp']</p>"},{"location":"KB/Dopamine/#dopamine","title":"Dopamine","text":"<ul> <li>Dopamine is chemically expressed as C2H11NO2.</li> <li>It is a neuro-chemical created in various parts of the brain and is critical for all kinds of brain functions including thinking, carrying, sleeping, mood, attention, motivation, seeking and rewarding.</li> <li>The dopamine is responsible for the feeling of pleasure.</li> <li>When a person eats, drinks or performs a pleasurable action, dopamine is stimulated in his brain to repeat the action.</li> <li>Unexpected rewards increase the activity of dopamine neurons, acting as positive feedback signals for the brain regions associated with the preceding behavior.</li> <li>As learning takes place, the timing of activity will shift until it occurs upon the cue alone, with the expected reward having no additional effect.<ul> <li>And should the expected reward not be received, dopamine activity drops, sending a negative feedback signal to the relevant parts of the brain, weakening the positive association</li> </ul> </li> </ul>"},{"location":"KB/Dot%20Product%20Attention/","title":"Dot Product Attention","text":""},{"location":"KB/Dot%20Product%20Attention/#dot-product-attention","title":"Dot Product Attention","text":"<ul> <li>Luong et al., 2015</li> <li> \\[f_{att}(h_{i}, s_{j}) = h_{i}^{T}s_{j}\\] </li> <li>Equivalent to Multiplicative Attention with no trainable weight matrix. Performs better at larger dimensions</li> <li>Identity matrix</li> <li>\\(h\\) is hidden state for encoder and \\(s\\) is hidden state for decoder</li> <li>A type of Attention Alignment</li> <li>Final scores after Softmax</li> <li></li> </ul>"},{"location":"KB/Double%20Descent/","title":"Double Descent","text":""},{"location":"KB/Double%20Descent/#double-descent","title":"Double Descent","text":"<ul> <li>When increasing the model size or the number of epochs, performance on the test set initially improves, then worsens but then again starts to improve and finally saturates.  </li> <li>This phenomena is against conventional wisdom, because the test error should not be decreasing again after increasing.</li> <li>occurs often in the over-parameterization regime<ul> <li>models which have a lot of parameters</li> <li>models that have huge complexity</li> </ul> </li> <li></li> </ul>"},{"location":"KB/Down%20Syndrome/","title":"Down Syndrome","text":""},{"location":"KB/Down%20Syndrome/#down-syndrome","title":"Down Syndrome","text":"<ul> <li>A genetic disorder characterized by intellectual impairment and physical abnormalities that arises from the genome having an extra copy of chromosome 21.</li> </ul>"},{"location":"KB/Downsampling/","title":"Downsampling","text":""},{"location":"KB/Downsampling/#downsampling","title":"Downsampling","text":"<ul> <li>Overloaded term that can mean either of the following</li> <li>Reducing the amount of information in a feature in order to train a model more efficiently. For example, before training an image recognition model, downsampling high-resolution images to a lower-resolution format.</li> <li>Training on a disproportionately low percentage of over-represented class examples in order to improve model training on under-represented classes. For example, in a class-imbalanced dataset, models tend to learn a lot about the majority class and not enough about the minority class. Downsampling helps balance the amount of training on the majority and minority classes.</li> </ul>"},{"location":"KB/Downstream%20Task/","title":"Downstream Task","text":""},{"location":"KB/Downstream%20Task/#downstream-task","title":"Downstream Task","text":"<ul> <li>computer vision applications that are used to evaluate the quality of features learned by self-supervised learnin </li> <li>training data are scarce </li> <li>In general, human-annotated labels are needed to solve the downstream tasks. </li> <li>in some applications, the downstream task can be the same as the pretext task without using any human-annotated labels.</li> </ul>"},{"location":"KB/DrawBench/","title":"DrawBench","text":""},{"location":"KB/DrawBench/#drawbench","title":"DrawBench","text":"<ul> <li>comprehensive and challenging benchmark for text-to-image models</li> <li>With DrawBench, we compare Imagen with recent methods including VQGAN+CLIP, Latent Diffusion Models, and DALL-E, and find that human raters prefer Imagen over other models in side-by-side comparisons, both in terms of sample quality and image-text alignment</li> </ul>"},{"location":"KB/Dreamfusion/","title":"Dreamfusion","text":""},{"location":"KB/Dreamfusion/#dreamfusion","title":"Dreamfusion","text":"<ul> <li>text-to-3D model</li> <li>uses a pretrained 2D text-to-image difusion model to perform textto-3D synthesis</li> <li>Dreamfusion replaces previous CLIP techniques with a loss derived from distillation of a 2D difusion model</li> <li>the difusion model can be used as a loss within a generic continuous optimization problem to generate samples</li> <li>sampling in parameter space is much harder than in pixels as we want to create 3D models that look like good images when rendered from random angles</li> <li>this model uses a diferentiable generator - Other approaches are focused on sampling pixels, however, this model instead focuses on creating 3D models that look like good images when rendered from random angles</li> </ul>"},{"location":"KB/Drop%20Delivery/","title":"Drop Delivery","text":""},{"location":"KB/Drop%20Delivery/#drop-delivery","title":"Drop Delivery","text":"<ul> <li>A method of introducing an object to the workplace by Gravity. Usually, a chute or container is so placed that, when work on the part is finished, it will fall or drop into a chute or onto a conveyor with little or no transport by the robot.</li> </ul>"},{"location":"KB/Dropout/","title":"Dropout","text":""},{"location":"KB/Dropout/#dropout","title":"Dropout","text":"<ul> <li>Applied to Dense Layers</li> <li>Training : Randomly (Bernoulli, p = 0.5 say) set #activations to 0</li> <li>Generally p = 0.1, 0.5</li> <li>Testing: Reweight by p<ul> <li>Because after training values will increase by \\(\\(1/(1-p)\\)\\)</li> </ul> </li> <li>Reduces co dependence between neurons</li> <li>Decreases overfitting</li> <li>Start with small rate : 20 %</li> <li>Helps with small datasets</li> <li>Reducing Co adaptation by making the presence of other hidden [neurons] unreliable</li> <li>The authors found that there is a trade-off between when Dropout is necessary, and when it's no longer useful. First, to cover the case where the dataset is extremely small: even Dropout does not improve performance in that case, simply because the dataset size is too small. The same is true for datasets that are large enough: Dropout then does no longer improve the model, but rather, model performance gets worse.</li> </ul>"},{"location":"KB/Dual-memory%20Approach/","title":"Dual-memory Approach","text":""},{"location":"KB/Dual-memory%20Approach/#dual-memory-approach","title":"Dual-memory Approach","text":"<ul> <li>Combination of several memories specialized for storing different types of data and supporting different functionalities</li> </ul>"},{"location":"KB/Dual-memory%20Approach/#triplestores","title":"Triplestores","text":"<ul> <li>The contents of this memory system is semantic in nature (small)</li> </ul>"},{"location":"KB/Dual-memory%20Approach/#leveldb","title":"LevelDB","text":"<ul> <li>key-value storage database, operate in RAM (developed by Google)</li> <li>Interpretation includes computing spatial relations between objects to keep an updated relational model of the scene around the robot</li> </ul>"},{"location":"KB/Dynamic%20Eager%20Execution/","title":"Dynamic Eager Execution","text":""},{"location":"KB/Dynamic%20Eager%20Execution/#dynamic-eager-execution","title":"Dynamic Eager Execution","text":"<ul> <li>operations are executed immediately</li> <li>more readable code and easier to debug</li> <li>lower performance than\u00a0Static Graph Execution</li> <li>graph architecture can evolve dynamically</li> </ul>"},{"location":"KB/Dynamic%20Sparsity/","title":"Dynamic Sparsity","text":""},{"location":"KB/Dynamic%20Sparsity/#dynamic-sparsity","title":"Dynamic Sparsity","text":"<ul> <li>train intrinsically sparse neural networks from scratch using only a small proportion of parameters and FLOPs</li> <li>Dynamic sparsity enables training sparse models from scratch, hence the training and inference FLOPs and memory requirements are only a small fraction of the dense models.</li> <li>models built with dynamic sparsity can be trained from scratch to match their dense counterparts without involving any pre-training or dense training</li> </ul>"},{"location":"KB/Dynamic%20visual%20attention/","title":"Dynamic visual attention","text":"<ul> <li>@Dynamic visual attention: searching for coding length increments</li> <li>Incremental coding length (ICL) using the features of local image patches is proposed to maximise the entropy of the sampled visual features</li> <li>unexpected features elicit entropy gain in the perception state and are therefore assigned high energy</li> <li>The probability function of feature activities of this model is updated dynamically</li> </ul>"},{"location":"KB/Dynamic%20visual%20attention/#dynamic-visual-attention","title":"Dynamic Visual Attention","text":""},{"location":"KB/EEG%20Artifacts/","title":"EEG Artifacts","text":""},{"location":"KB/EEG%20Artifacts/#eeg-artifacts","title":"EEG Artifacts","text":"<ul> <li>ICA</li> <li></li> </ul>"},{"location":"KB/EEG%20Artifacts/#drift","title":"Drift","text":"<ul> <li>A</li> </ul>"},{"location":"KB/EEG%20Artifacts/#probably-disconnected","title":"Probably Disconnected","text":""},{"location":"KB/EEG%20Artifacts/#periodic-probably-from-ecg","title":"Periodic - Probably From ECG","text":"<ul> <li>Arteries in neck exposed when person is nervous</li> </ul>"},{"location":"KB/EEG%20Baseline%20Correction/","title":"EEG Baseline Correction","text":""},{"location":"KB/EEG%20Baseline%20Correction/#eeg-baseline-correction","title":"EEG Baseline Correction","text":"<ul> <li>Signal drifts</li> <li>Adjust pre stimulus value by averaging across pre stimulus points during baseline period</li> <li>Subtract average value from post stimulus period</li> <li>Period where nothing is going on</li> <li>100-200 ms</li> <li></li> </ul>"},{"location":"KB/EEG%20Cap/","title":"EEG Cap","text":""},{"location":"KB/EEG%20Cap/#eeg-cap","title":"EEG Cap","text":"<ul> <li>![im](images/Pasted%20Image%2020220510230806.png|]</li> <li></li> </ul>"},{"location":"KB/EEG%20Cluster%20Testing/","title":"EEG Cluster Testing","text":""},{"location":"KB/EEG%20Cluster%20Testing/#eeg-cluster-testing","title":"EEG Cluster Testing","text":"<ul> <li>If done for each point, same test repeated and false positives increase</li> <li>eg: t test in each electrode</li> <li>A result is more believable if it occurs in a set of adjacent channels:  <ul> <li>Threshold data of statistical test  </li> <li>Compute clusters  </li> <li>Threshold randomized data  </li> <li>Compute clusters for 100 or so distr of randomized data</li> <li>Decide if its rare</li> </ul> </li> <li> \\[sumT = \\text{sum of all t stats}\\] </li> <li><ul> <li>There was a significant difference between easy and more difficult trials between 712 ms post-stimulus and 768 ms post-stimulus. This difference was initially localized to a few central electrodes but over time spread out more posteriorly. This is consistent with previous studies that have shown</li> </ul> </li> </ul>"},{"location":"KB/EEG%20Filtering/","title":"EEG Filtering","text":""},{"location":"KB/EEG%20Filtering/#eeg-filtering","title":"EEG Filtering","text":"<ul> <li>Remove 50/60Hz notch filter for line noise</li> <li>Might introduce distortion</li> </ul>"},{"location":"KB/EEG%20Statistical%20Analysis/","title":"EEG Statistical Analysis","text":""},{"location":"KB/EEG%20Statistical%20Analysis/#eeg-statistical-analysis","title":"EEG Statistical Analysis","text":"<ul> <li>EEG Cluster Testing</li> </ul>"},{"location":"KB/EEG/","title":"EEG","text":""},{"location":"KB/EEG/#eeg","title":"EEG","text":"<ul> <li>Electrical activity on the surface of the brain</li> <li>Frequencies</li> <li>Pyramidal cell</li> <li>Electrode nomenclature</li> <li>Cheaper than fMRI</li> <li>Fast signals</li> <li>Low anatomical specificity<ul> <li>Cant find where its coming from</li> <li>Lots of noise</li> </ul> </li> <li>EEG Artifacts</li> <li>EEG Filtering</li> <li>ERP</li> <li>EEG Baseline Correction</li> <li>EEG Statistical Analysis</li> <li>EEG Cap</li> <li>This might be related to fMRI</li> </ul>"},{"location":"KB/ELECTRA/","title":"ELECTRA","text":""},{"location":"KB/ELECTRA/#electra","title":"ELECTRA","text":"<ul> <li>ELECTRA: Pre-training Text Encoders As Discriminators Rather Than Generators</li> <li>Pre-training methods such as BERT corrupt the input by replacing some tokens with [MASK] and then train a model to reconstruct the original tokens.</li> <li>sample-efficient pre-training alternative task called replaced token detection</li> <li>self-supervised task for language representation learning</li> <li>Instead of masking the input, their approach corrupts it by replacing some tokens with plausible alternatives sampled from a small generator network</li> <li>Then, instead of training a model that predicts the original identities of the corrupted tokens, the key idea is training a discriminative text encoder model to distinguish input tokens from high-quality negative samples produced by an small generator network</li> <li>more compute-efficient and results in better performance on downstream tasks</li> <li>particularly strong for small models</li> <li>GLUE</li> <li>performs comparably to RoBERTa|[RoBERTa](./RoBERTa.md) and XLNet while using less than 1/4 of their compute and outperforms them when using the same amount of compute.</li> </ul>"},{"location":"KB/ELMO/","title":"ELMO","text":""},{"location":"KB/ELMO/#elmo","title":"ELMO","text":"<ul> <li>Deep Contextualized Word Representations</li> <li>context-sensitive word embeddings using the [LSTM)](Long Short Term Memory (LSTM|Long Short Term Memory (LSTM|LSTM)](LSTM)](Long Short Term Memory (LSTM|Long Short Term Memory (LSTM|LSTM).md).md)-based Embedding from Language Models (ELMo) architecture</li> </ul>"},{"location":"KB/ERP/","title":"ERP","text":""},{"location":"KB/ERP/#erp","title":"ERP","text":"<ul> <li>Event related potentials</li> <li>-</li> <li></li> <li></li> </ul>"},{"location":"KB/Eager%20Execution/","title":"Eager Execution","text":""},{"location":"KB/Eager%20Execution/#eager-execution","title":"Eager Execution","text":"<ul> <li>A TensorFlow programming environment in which operations run immediately. By contrast, operations called in graph execution don't run until they are explicitly evaluated. Eager execution is an imperative interface , much like the code in most programming languages. Eager execution programs are generally far easier to debug than graph execution programs.</li> </ul>"},{"location":"KB/Early%20Ray%20Termination/","title":"Early Ray Termination","text":""},{"location":"KB/Early%20Ray%20Termination/#early-ray-termination","title":"Early Ray Termination","text":"<ul> <li>General acceleration idea: neglect regions with irrelevant information</li> </ul>"},{"location":"KB/Early%20Stopping%20tricks/","title":"Early Stopping","text":""},{"location":"KB/Early%20Stopping%20tricks/#early-stopping","title":"Early Stopping","text":"<ul> <li>No of epochs is a hyper parameter : to prevent overfitting</li> <li>Early Stopping is a regularization technique that improves image classification accuracy by intentionally stopping the training when validation loss increases. Training is stopped as training a model for too many epochs sometimes causes Overfitting.</li> <li>In Early Stopping, the number of epochs becomes a tunable hyperparameter. We continuously store the best parameters during training, and when these parameters no longer change for several epochs, we stop training.</li> </ul>"},{"location":"KB/Earth%20Mover%27s%20Distance%20%28EMD%29/","title":"Earth Mover's Distance (EMD)","text":""},{"location":"KB/Earth%20Mover%27s%20Distance%20%28EMD%29/#earth-movers-distance-emd","title":"Earth Mover's Distance (EMD)","text":"<ul> <li>A measure of the relative similarity between two documents. The lower the value, the more similar the documents.</li> <li>Spatial Distance between two PDF</li> </ul>"},{"location":"KB/Eavesdropping/","title":"Eavesdropping","text":""},{"location":"KB/Eavesdropping/#eavesdropping","title":"Eavesdropping","text":"<ul> <li>Two tasks \\(T_{A}, T_{B}\\) , share feature F<ul> <li>F is harder to learn in one task</li> <li>One task can eavesdrop into another ([Hard Parameter Sharing] , Soft Parameter Sharing)</li> <li>Extra info in each task</li> </ul> </li> </ul>"},{"location":"KB/Edema/","title":"Edema","text":""},{"location":"KB/Edema/#edema","title":"Edema","text":"<ul> <li>Swelling as a result of fluid retention or build-up</li> </ul>"},{"location":"KB/Effect%20Of%20Depth/","title":"Effect of Depth","text":""},{"location":"KB/Effect%20Of%20Depth/#effect-of-depth","title":"Effect of Depth","text":"<ul> <li>Adding skip connections make the loss surface smoother</li> <li></li> </ul>"},{"location":"KB/Effect%20Of%20Depth/#deeper-architectures","title":"Deeper Architectures","text":"<ul> <li>Makes more uneven and chaotic</li> <li></li> </ul>"},{"location":"KB/Effect%20Of%20Depth/#wider-architectures","title":"Wider Architectures","text":"<ul> <li>Makes landscape smoother and flatter</li> <li></li> </ul>"},{"location":"KB/Effects%20of%20Contextual%20Cues%20on%20Inferring%20and%20Remembering%20Meanings%20of%20New%20Word/","title":"Effects of Contextual Cues on Inferring and Remembering Meanings of New Word","text":""},{"location":"KB/Effects%20of%20Contextual%20Cues%20on%20Inferring%20and%20Remembering%20Meanings%20of%20New%20Word/#effects-of-contextual-cues-on-inferring-and-remembering-meanings-of-new-word","title":"Effects of Contextual Cues on Inferring and Remembering Meanings of New Word","text":"<ul> <li>xiaolongli</li> <li>Li, X. (1988). Effects of contextual cues on inferring and remembering meanings of new words. Applied linguistics, 9(4), 402-413.</li> </ul>"},{"location":"KB/Effects%20of%20Contextual%20Cues%20on%20Inferring%20and%20Remembering%20Meanings%20of%20New%20Word/#abstract","title":"Abstract","text":"<ul> <li>This study tested four directional hypotheses: Compared with those receiving cue- inadequate sentences, subjects receiving cue-adequate sentences will (1) report greater ease in word inference, and (2) score higher in inferring and remembering the contextual meanings of unfamiliar words. (3) Contextual cues being equally adequate, subjects reading, in contrast to listening to, the sentences will better infer and remember the contextual meanings ofunfamiliar words. (4) The higher the scores of word inference, the better the retention of the contextual meanings of the target word</li> <li>An approach combining schema theory and the generative model of comprehension was usedfor the rationale of this study and the discussion of its findings.</li> </ul>"},{"location":"KB/Effects%20of%20Contextual%20Cues%20on%20Inferring%20and%20Remembering%20Meanings%20of%20New%20Word/#literature-review","title":"LITERATURE REVIEW","text":"<ul> <li>Inferring, or 'inferencing', the meanings of unfamiliar words in context can be seen as 'a process of identifying and acquiring' new vocabulary by utilizing 'attributes and contexts that are familiar'</li> <li>In language learning, inferring word meanings while reading or listening is a process of vocabulary acquisition which has an important influence upon comprehension either in a first language (Kruse 1979) or in a second language (Yorio 1971).</li> <li>Contextual cues can affect the process and outcome of word inference.</li> <li>Carton (1971) hypothesized that in the process of identifying and acquiring unfamiliar words in context, greater certainty results from guesses based on many cues than on few.</li> <li>However, for contextual cues to be of real help for word inference, they must (1) be perceptually and conceptually familiar to the text-receiver, and (2) contain the information available for the text-receiver to find the relevant schemata in order to (a) account for the oncoming input in the text, and (b) identify unfamiliar stimuli in context.</li> <li>Memories are, in a sense, natural effects of the comprehension process (Rumelhart and Ortony 1977) which, by nature, is schematic (Bartlett 1932</li> <li>memory performance is enhanced to the extent that the encoding context forms an integrated unit with the to-be-remembered word</li> </ul>"},{"location":"KB/Effects%20of%20Contextual%20Cues%20on%20Inferring%20and%20Remembering%20Meanings%20of%20New%20Word/#this-study-purpose-and-hypotheses","title":"THIS STUDY: PURPOSE AND HYPOTHESES","text":"<ul> <li>The present study was conducted among second language learners</li> <li>It not only focused on the effects of cue adequacy on inferring and remembering the meanings of new words in discrete, semantically disconnected sentences, but also aimed at an empirical exploration concerning the relationship between word inference and retention.</li> <li>this study compared the effects of cue adequacy in both reading and listening contexts</li> <li>cue-adequate sentences were compared with their cue- inadequate counterparts for testing four directional hypotheses. These were: Compared with those receiving cue-inadequate sentences, subjects receiving cue-adequate sentences will (1) report greater ease in inferring the meanings of new words, and (2) score higher in inferring and remembering the meanings of new words. (3) Contextual cues being equally adequate, subjects reading, in contrast to listening to, the sentences will better infer and remember the meanings of unfamiliar words. (4) The higher the scores of word inference, the better the retention of the meanings of the target words.</li> <li>a sentence with certain input information that contains clues sufficient for inferring the contextual meaning of a target word was defined as a cue-adequate sentence, while a sentence without such input information was defined as a cue-inadequate one</li> <li>For example, the sentence John took out a collapsible bicycle and rode to school was treated as a cue- inadequate sentence, for, in this sentence, there was no input information signaling any clue to the contextual meaning of the target word collapsible</li> <li>However, the sentence John took out a collapsible bicycle, unfolded it, and rode to school was treated as a cue-adequate one, for the word unfolded provided the clue to the approximate meaning of the target word.</li> </ul>"},{"location":"KB/Effects%20of%20Contextual%20Cues%20on%20Inferring%20and%20Remembering%20Meanings%20of%20New%20Word/#method","title":"METHOD","text":""},{"location":"KB/Effects%20of%20Contextual%20Cues%20on%20Inferring%20and%20Remembering%20Meanings%20of%20New%20Word/#participant","title":"Participant","text":"<ul> <li>Forty-eight advanced trainees from an EAP (English for Academic Purposes) center in China were involved in this study.</li> <li>Their average age was 35 (SD = 7), ranging from 22 to 48</li> <li>They were randomly assigned into four treatment groups, namely</li> <li>LC\u2014 (i.e. listening group with inadequate cues); RC\u2014 (i.e. reading group with inadequate cues); LC + (i.e. listening group with adequate cues), and RC+ (i.e. reading group with adequate cues). Of the four groups, two (i.e. LC\u2014 and RC\u2014) received cue-inadequate sentences, and the others (i.e. LC+ and RC+), cue- adequate sentences. In each pair of groups that received the same sentences, one group (i.e. LC\u2014 and LC+) took the listening test, and the other (i.e. RC\u2014 and RC+), the reading test</li> <li>There were two independent variables. The first one, text, had two levels- sentences with adequate cues versus inadequate cues. The second one, language skills, also had two levels\u2014reading versus listening dependent</li> <li>These were group means in terms of: (1) measures of word inference (i.e. inferring the meanings of unfamiliar words); (2) ratings of degrees of difficulty of word inference, and (3) measures of word retention (i.e. recall of the inferred meanings of the target words).</li> </ul>"},{"location":"KB/Effects%20of%20Contextual%20Cues%20on%20Inferring%20and%20Remembering%20Meanings%20of%20New%20Word/#task","title":"Task","text":"<ul> <li>Sixty discrete, semantically disconnected sentences were constructed for the experiment.</li> <li>They formed two sets of counterparts. Each set was composed of 30 sentences.</li> <li>One set consisted of cue-adequate sentences, and the other of cue-inadequate sentences</li> <li>A target word was defined as a perceptually, not conceptually, unfamiliar term.</li> <li>Since the target words were only perceptually unfamiliar, it would not be a prerequisite for the subjects to acquire any new concept to perform the task for this experiment.</li> <li>By the same token, the topic of all the test items was based on common knowledge; thus, there was no need to turn to any biased or specialized frame of reference for inferring word meanings in this experiment</li> <li>Furthermore, no meaning of any target word for this study could be deduced simply by applying morphological knowledge in terms of stems, affixes, or other devices of word formation.</li> <li>In the pretest, the subjects were asked to write down (either in English or Chinese) the common meanings of the target words they knew.</li> <li>Three more tasks were performed after the pretest. The first one, word inference, was to infer the contextual meanings of the target words based on the input information in the sentences in which the target words were embedded.</li> <li>Both tapes, one containing sentences with adequate, and the other sentences with inadequate cues, were produced by a native English speaker at a speed of about 90 words per minute.</li> <li>The subjects listened to the sentences one by one, with each sentence repeated three times.</li> <li>Sentences were shown one by one on the screens by using a mask, and presented at the same rate as the corresponding items on the tapes for the listening groups.</li> <li>The tests were presented in an open-ended, not in a multiple-choice, form</li> <li>After reading or listening to each sentence, the subjects were asked to state (either in English or Chinese) their guesses of the contextual meaning of the target word in the sentence</li> <li>The second task after the pretest was to rate the degrees of difficulty in terms of word inferences</li> <li>The last task, word retention, was a cued recall of the target words' inferred contextual meanings.</li> <li>Each target word was cued by another word from the same sentence that had been processed for inferring the contextual meaning of the target word.</li> <li>The target words were listed in exactly the same order as they appeared in the tests for word inference.</li> </ul>"},{"location":"KB/Effects%20of%20Contextual%20Cues%20on%20Inferring%20and%20Remembering%20Meanings%20of%20New%20Word/#data-analyses","title":"DATA ANALYSES","text":"<ul> <li>Hypothesis 1 was tested by a Chi-square, Hypothesis 2 by two separate one-way ANOVAs, Hypothesis 3 by two separate Duncan's Multiple Range Tests, and Hypothesis 4 by a Correlation Test</li> <li>Since the Chi-square is a test especially designed for nominal data, it was decided beforehand that the nine-point scale should be dichotomized: ratings less than 5 were defined as 'difficult' (to infer the contextual meanings of the target words from the discrete sentences), while ratings equal to or greater than 5 were defined as 'easy'.</li> <li>Cronbach's Alpha was used for computing the test reliability. Reliability coefficients for the four tests of word inference were 0.60 for LC\u2014, 0.54 for RC-, 0.68 for LC+, and 0.64 for RC+, which were rather low.</li> <li>However, they can be considered as being acceptable for this study, for both the sample size (12 per cell) and the number of test items (30 for each test) were very small.</li> </ul>"},{"location":"KB/Effects%20of%20Contextual%20Cues%20on%20Inferring%20and%20Remembering%20Meanings%20of%20New%20Word/#results","title":"RESULTS","text":"<ul> <li>Data analyses indicated that all the four hypotheses were confirmed with statistical significance.</li> </ul>"},{"location":"KB/Effects%20of%20Contextual%20Cues%20on%20Inferring%20and%20Remembering%20Meanings%20of%20New%20Word/#hypothesis-1","title":"Hypothesis 1","text":"<ul> <li>no significant difference between the four groups in rating degrees of difficulty of word inference</li> <li>result of the Chi-square Test presented null hypothesis could be rejected</li> </ul>"},{"location":"KB/Effects%20of%20Contextual%20Cues%20on%20Inferring%20and%20Remembering%20Meanings%20of%20New%20Word/#hypothesis-2","title":"Hypothesis 2","text":"<ul> <li>subjects in the four groups performed differently on both tasks of word inference and word retention</li> <li>showed that RC+ scored significantly higher than LC+, and that both RC+ and LC+</li> <li>scored significantly higher than RC\u2014 and LC\u2014</li> <li>However, there was no significant difference between RC\u2014 and LC\u2014</li> <li>showed both RC+ and LC+ scored significantly higher than RC\u2014 and LC\u2014, and that R C + scored significantly higher than LC+. However, there was no significant difference between RC\u2014 and LC-.</li> </ul>"},{"location":"KB/Effects%20of%20Contextual%20Cues%20on%20Inferring%20and%20Remembering%20Meanings%20of%20New%20Word/#hypothesis-3","title":"Hypothesis 3","text":"<ul> <li>both in word inference and retention, R C + scored significantly higher than LC+; however, in either word inference or retention, there was no significant difference between RC\u2014 and LC\u2014</li> </ul>"},{"location":"KB/Effects%20of%20Contextual%20Cues%20on%20Inferring%20and%20Remembering%20Meanings%20of%20New%20Word/#hypothesis-4","title":"Hypothesis 4","text":"<ul> <li>there was a positive correlation of statistical significance between word inference and word retention</li> </ul>"},{"location":"KB/Effects%20of%20Contextual%20Cues%20on%20Inferring%20and%20Remembering%20Meanings%20of%20New%20Word/#discussion-and-conclusion","title":"DISCUSSION AND CONCLUSION","text":"<ul> <li>ubjects receiving cue- adequate sentences, in contrast to cue-inadequate sentences, not only reported greater ease in word inference, but also scored significantly higher in inferring and remembering the meanings of unfamiliar words in context</li> <li>existed a positive correlation between word inference and word retention. That is, the higher the group means in inferring the contextual meanings of unfamiliar words, the better the performance in remembering the meanings of those words</li> <li>contextual cues being equally adequate, subjects reading the sentences scored significantly higher in both inferring and remembering the contextual meanings of unfamiliar words than those listening to the sentences.</li> <li>This finding further sustained Carton's (1971) hypothesis that texts with adequate contextual cues minimize errors in the process of identifying and acquiring new words in a natural context</li> <li>The presence of contextual cues means 'bridging information' (Garrod and Sanford 1981), grammatical and/or semantic, conceptual as well as perceptual.</li> <li>Without adequate bridging information, it would seem next to impossible to infer and recall the contextual meaning of any unfamiliar word.</li> <li>This explains why the LC\u2014 and RC\u2014 groups scored so low on both word inference and word retention.</li> <li>the target words associated with more powerful retrieval cues were more recallable than those associated with less powerful retrieval cues</li> <li>Probably, more powerfully associated retrieval cues better triggered the schematic memory, which created a 'short cut' that linked the process needed for recalling the contextual meaning of the target word and the initial process involved in inferring the contextual meaning of that target word.</li> <li>contextual cues being equally adequate (not inadequate), subjects in the reading group scored significantly higher in both word inference and word retention than subjects in the listening group.</li> <li>not clear why this was so</li> <li>That is, the subjects might be more competent in reading than in listening contextual cues presented visually were more accessible</li> </ul>"},{"location":"KB/Effects%20of%20Contextual%20Cues%20on%20Inferring%20and%20Remembering%20Meanings%20of%20New%20Word/#implications","title":"Implications","text":"<ul> <li>irst, since adequate cues in context can relieve learners of English as a second language from the anxiety of unfamiliar words, it might follow that reasonably sufficient contextual cues should be provided in texts for second language learners, so that enough information can be created for them to play the 'psychoUnguistic guessing game' (Goodman 1983)</li> <li>contextual cues can enhance inferring and remembering the meanings of unfamiliar words in context,</li> <li>since contextual cues being equally adequate, subjects can, within the same amount of time, better acquire vocabulary through visual patterns of learning than through oral patterns, it might follow that learners whose learning styles are congruent or similar to the subjects in this study, may well enlarge their vocabulary for reading in a more efficient way through visual ways of learning</li> </ul>"},{"location":"KB/Effects%20of%20Contextual%20Cues%20on%20Inferring%20and%20Remembering%20Meanings%20of%20New%20Word/#pictures","title":"Pictures","text":""},{"location":"KB/Effects%20of%20Regularization/","title":"Effects of Regularization","text":""},{"location":"KB/Effects%20of%20Regularization/#effects-of-regularization","title":"Effects of Regularization","text":"<ul> <li>The Effects of Regularization and Data Augmentation are Class Dependent</li> <li>Current Deep Networks heavily rely on regularizers such as data Augmentation (DA) or Weight Decay, and employ structural risk minimization, i.e., Cross Validation, to select the optimal regularization hyper-parameters</li> <li>weight decay increases the average test performances at the cost of significant performance drops on some specific classes</li> <li>unfair across classes</li> <li>By focusing on maximizing aggregate performance statistics we have produced learning mechanisms that can be potentially harmful, especially in transfer learning tasks</li> <li>optimal amount of DA or weight decay found from cross-validation leads to disastrous model performances on some classes</li> <li>only by introducing random crop DA during training</li> <li>such performance drop also appears when introducing uninformative regularization techniques such as weight decay</li> <li>ur search for ever increasing generalization performance \u2013 averaged over all classes and samples \u2013 has left us with models and regularizers that silently sacrifice performances on some classes.</li> <li>varying the amount of regularization employed during pre-training of a specific dataset impacts the per-class performances of that pre-trained model on different downstream tasks e.g. an ImageNet pre-trained ResNet50 deployed on INaturalist sees its performances fall from 70% to 30% on a particular classwhen introducing random crop DA during the Imagenet pre-training phase</li> <li>designing novel regularizers without class-dependent bias remains an open research question</li> <li>Categories largely identifiable by color or texture (for e.g., yellow bird, textured mushroom) are unaffected by aggressive [cropping], while categories identifiable by shape (for e.g., corkscrew) see a performance degradation with aggressive cropping that only contains part of the object</li> <li>Conversely, color jitter does not affect shape or texture-based categories (for e.g., zebra), but affects color-based categories (for e.g., basket ball)</li> </ul>"},{"location":"KB/Efferent/","title":"Efferent","text":""},{"location":"KB/Efferent/#efferent","title":"Efferent","text":"<ul> <li>Motor Division</li> <li>Instructions from brain to muscle and glands</li> <li>Also includes Somatic + Autonomic</li> </ul>"},{"location":"KB/EfficientNet/","title":"EfficientNet","text":""},{"location":"KB/EfficientNet/#efficientnet","title":"EfficientNet","text":"<ul> <li>@tanEfficientnetRethinkingModel2019</li> </ul>"},{"location":"KB/Ego-motion/","title":"Ego-motion","text":""},{"location":"KB/Ego-motion/#ego-motion","title":"Ego-motion","text":"<ul> <li>self-driving car </li> <li>equipped with various sensors </li> <li>large-scale egocentric video along with ego-motor signal can be easily collected with very low cost by driving the car in the street </li> <li>the correspondence between visual signal and motor signal for self-supervised feature learning </li> <li>correspondence between visual signal and motor signal for s </li> <li>underline intuition of this type of methods is that a self-driving car can be treated as a camera moving in a scene </li> <li>egomotion of the visual data captured by the camera is as same as that of the car </li> <li>correspondence between visual data and egomotion can be utilized for self- supervised feature learning </li> <li>inputs to the network are two frames sampled from an egocentric video within a short time </li> <li>labels for the network indicate the rotation and translation relation between the two sampled images which can be derived from the odometry data of the dataset. </li> <li>ConvNet is forced to identify visual elements that are present in both sampled images. </li> <li>ego-motor signal is a type of accurate supervision signal </li> <li>In addition to directly applying it for self-supervised feature learning, it has also been used for unsupervised learning of depth and ego-motion</li> </ul>"},{"location":"KB/EigenCAM/","title":"EigenCAM","text":""},{"location":"KB/EigenCAM/#eigencam","title":"EigenCAM","text":"<ul> <li>@banymuhammadEigenCAMVisualExplanations2021</li> </ul>"},{"location":"KB/EigenCAM/#summary-by-me","title":"Summary by Me","text":"<p>Another method for computing Saliency Maps without modifying the architecture of the network, EigenCAM was proposed by Bany et al. \\cite{banymuhammadEigenCAMVisualExplanations2021}. EigenCAM uses a combination of an Eigen analysis of the class activated output by projecting it on the input, and a PCA of it to remove unnecessary features from the maps. The Eigen-Saliency map is computed across the network and produces sharper outputs based on the distance (using PCA) from the input image. EigenCAM and Eigen Saliency maps were fused by a point wise multiplication operation. </p>"},{"location":"KB/Eigenvector/","title":"Eigenvector","text":""},{"location":"KB/Eigenvector/#eigenvector","title":"Eigenvector","text":""},{"location":"KB/Einsum/","title":"Einsum","text":""},{"location":"KB/Einsum/#einsum","title":"Einsum","text":"<ul> <li>Matrix transpose<ul> <li>ij -&gt; ji</li> </ul> </li> <li>Sum<ul> <li>ij -&gt;</li> </ul> </li> <li>Column sum<ul> <li>ij -&gt; j</li> </ul> </li> <li>Row sum<ul> <li>ij -&gt; i</li> </ul> </li> <li>Matrix vector multiply<ul> <li>ik, k -&gt; i</li> </ul> </li> <li>Matrix matrix multiply<ul> <li>ik, kj -&gt; ij</li> </ul> </li> <li>Dot product<ul> <li>i,i -&gt;</li> <li>ij, ij -&gt;</li> </ul> </li> <li>Hadmard product<ul> <li>ij, ij -&gt; ij</li> </ul> </li> <li>Outer product<ul> <li>i,j -&gt; ij</li> </ul> </li> <li>Batch matrix multiply<ul> <li>ijk, ikl -&gt; ijl</li> </ul> </li> <li>Tensor Contraction<ul> <li>pqrs , tuvr -&gt; pstuv</li> </ul> </li> </ul>"},{"location":"KB/Elaborateness/","title":"Elaborateness","text":""},{"location":"KB/Elaborateness/#elaborateness","title":"Elaborateness","text":"<ul> <li>depth or detail of the explanation</li> <li>a doctor may tell a patient that their diagnosis looks \"similar to\" another diagnosis</li> <li>This is a \"shallow\" explanation; it does not point to the root cause of the diagnosis</li> </ul>"},{"location":"KB/Electrical%20Energy/","title":"Electrical Energy","text":""},{"location":"KB/Electrical%20Energy/#electrical-energy","title":"Electrical Energy","text":"<ul> <li>Electrical energy changed into heat = potential difference x current x time</li> <li> \\[E= \\frac{V}{t}\\] </li> </ul>"},{"location":"KB/Electroconvulsive%20Therapy%20%28ECT%29/","title":"Electroconvulsive Therapy (ECT)","text":""},{"location":"KB/Electroconvulsive%20Therapy%20%28ECT%29/#electroconvulsive-therapy-ect","title":"Electroconvulsive Therapy (ECT)","text":"<ul> <li>A therapeutic treatment for depression and other mental illnesses that sends small electric currents over the scalp to trigger a brief seizure.</li> </ul>"},{"location":"KB/Electrode%20nomenclature/","title":"Electrode nomenclature","text":"<p>5---</p> <p>toc: true title: Electrode nomenclature</p>"},{"location":"KB/Electrode%20nomenclature/#electrode-nomenclature","title":"Electrode Nomenclature","text":"<ul> <li>Bathing cap</li> <li>Top of head</li> <li>Cz : middle of head</li> <li>Left : odd</li> <li>Right : even</li> <li>Frontal : F</li> <li>Frontal Polar : Fp</li> <li>Temporal : T</li> <li>Posterior : Pz</li> <li>Occipital : Oz</li> </ul>"},{"location":"KB/Elements%20of%20sets/","title":"Elements of sets","text":""},{"location":"KB/Elements%20of%20sets/#elements-of-sets","title":"Elements of Sets","text":"<ul> <li>The stickers we have in stocks are stars, the moons, item and a flag.</li> <li>I\u2019ll take two moons.</li> <li>The moons in the 2nd sentences should be understood to be some of the moons mentioned in the 1st sentence.</li> <li>Notice that to understand the 2nd sentence at all requires that we use the context of the first sentence to establish that the word \u2018moons\u2019 means moon stickers.</li> </ul>"},{"location":"KB/Ellipsoids/","title":"Ellipsoids","text":""},{"location":"KB/Ellipsoids/#ellipsoids","title":"Ellipsoids","text":"<ul> <li>Fractional Anisotropy</li> <li></li> <li>Linear, Planar, Spherical</li> <li>2D projection can convey ambiguous 3D orientation</li> </ul>"},{"location":"KB/Elman%201990/","title":"Elman 1990","text":""},{"location":"KB/Elman%201990/#elman-1990","title":"Elman 1990","text":"<ul> <li>The network learned generalizations</li> <li>examine hidden unit activation pattern for each word measure distance between each pattern and every other pattern (Euclidean distance)</li> <li>Use this to create a hierarchical cluster.</li> <li>Network learned semantic classes</li> <li>If the input to a simulation is preselected to avoid problems, one has instantiated an expert filtering system.</li> <li>in order to accomplish the goal of creating word classes by surface structure alone, it appears that the input must be filtered in just the right way.</li> <li>Instead of semantic representations, semantics gets replaced with distributional information<ul> <li>This is not what humans know about word classes.</li> <li>If the simulation's goals are accomplished by avoiding pronouns then we have the equivalent of a pronoun filter</li> </ul> </li> <li>Some strings in English are both nouns and verbs, e.g. smell, break</li> <li>The simulation did not learn what children learn</li> <li>Yes, the input was oversimplified, but it's not clear that adding these additional features will make the model perform worse</li> <li>language is very redundant, so certain simplifications actually remove helpful features</li> <li>Categories can 'emerge' via statistical regularities</li> <li>Basic RNN Architectures can find these</li> </ul>"},{"location":"KB/Elman%201991/","title":"Elman 1990","text":""},{"location":"KB/Elman%201991/#elman-1990","title":"Elman 1990","text":"<ul> <li>The network learned generalizations</li> <li>examine hidden unit activation pattern for each word measure distance between each pattern and every other pattern (Euclidean distance)</li> <li>Use this to create a hierarchical cluster.</li> <li>Network learned semantic classes</li> <li>If the input to a simulation is preselected to avoid problems, one has instantiated an expert filtering system.</li> <li>in order to accomplish the goal of creating word classes by surface structure alone, it appears that the input must be filtered in just the right way.</li> <li>Instead of semantic representations, semantics gets replaced with distributional information<ul> <li>This is not what humans know about word classes.</li> <li>If the simulation's goals are accomplished by avoiding pronouns then we have the equivalent of a pronoun filter</li> </ul> </li> <li>Some strings in English are both nouns and verbs, e.g. smell, break</li> <li>The simulation did not learn what children learn</li> <li>Yes, the input was oversimplified, but it's not clear that adding these additional features will make the model perform worse</li> <li>language is very redundant, so certain simplifications actually remove helpful features</li> <li>Categories can 'emerge' via statistical regularities</li> <li>Basic RNN Architectures can find these</li> </ul>"},{"location":"KB/Elman%201992/","title":"Elman 1990","text":""},{"location":"KB/Elman%201992/#elman-1990","title":"Elman 1990","text":"<ul> <li>The network learned generalizations</li> <li>examine hidden unit activation pattern for each word measure distance between each pattern and every other pattern (Euclidean distance)</li> <li>Use this to create a hierarchical cluster.</li> <li>Network learned semantic classes</li> <li>If the input to a simulation is preselected to avoid problems, one has instantiated an expert filtering system.</li> <li>in order to accomplish the goal of creating word classes by surface structure alone, it appears that the input must be filtered in just the right way.</li> <li>Instead of semantic representations, semantics gets replaced with distributional information<ul> <li>This is not what humans know about word classes.</li> <li>If the simulation's goals are accomplished by avoiding pronouns then we have the equivalent of a pronoun filter</li> </ul> </li> <li>Some strings in English are both nouns and verbs, e.g. smell, break</li> <li>The simulation did not learn what children learn</li> <li>Yes, the input was oversimplified, but it's not clear that adding these additional features will make the model perform worse</li> <li>language is very redundant, so certain simplifications actually remove helpful features</li> <li>Categories can 'emerge' via statistical regularities</li> <li>Basic RNN Architectures can find these</li> </ul>"},{"location":"KB/Elman%201993/","title":"Elman 1990","text":""},{"location":"KB/Elman%201993/#elman-1990","title":"Elman 1990","text":"<ul> <li>The network learned generalizations</li> <li>examine hidden unit activation pattern for each word measure distance between each pattern and every other pattern (Euclidean distance)</li> <li>Use this to create a hierarchical cluster.</li> <li>Network learned semantic classes</li> <li>If the input to a simulation is preselected to avoid problems, one has instantiated an expert filtering system.</li> <li>in order to accomplish the goal of creating word classes by surface structure alone, it appears that the input must be filtered in just the right way.</li> <li>Instead of semantic representations, semantics gets replaced with distributional information<ul> <li>This is not what humans know about word classes.</li> <li>If the simulation's goals are accomplished by avoiding pronouns then we have the equivalent of a pronoun filter</li> </ul> </li> <li>Some strings in English are both nouns and verbs, e.g. smell, break</li> <li>The simulation did not learn what children learn</li> <li>Yes, the input was oversimplified, but it's not clear that adding these additional features will make the model perform worse</li> <li>language is very redundant, so certain simplifications actually remove helpful features</li> <li>Categories can 'emerge' via statistical regularities</li> <li>Basic RNN Architectures can find these</li> </ul>"},{"location":"KB/Elu/","title":"Elu","text":""},{"location":"KB/Elu/#elu","title":"Elu","text":"<ul> <li> \\[f(x) = max(x, a \\cdot (e^x-1))\\] </li> <li></li> </ul>"},{"location":"KB/Embedding%20Human%20Knowledge%20into%20Deep%20Neural%20Network%20via%20Attention%20Map/","title":"Embedding Human Knowledge into Deep Neural Network via Attention Map","text":""},{"location":"KB/Embedding%20Human%20Knowledge%20into%20Deep%20Neural%20Network%20via%20Attention%20Map/#embedding-human-knowledge-into-deep-neural-network-via-attention-map","title":"Embedding Human Knowledge into Deep Neural Network via Attention Map","text":"<ul> <li>@mitsuharaEmbeddingHumanKnowledge2019</li> </ul>"},{"location":"KB/Embedding%20Human%20Knowledge%20into%20Deep%20Neural%20Network%20via%20Attention%20Map/#intro","title":"Intro","text":"<ul> <li>focus on the attention mechanism of an attention branch network (ABN)</li> <li>propose a fine-tuning method that utilizes a single-channel attention map which is manually edited by a human expert.</li> <li>Our fine-tuning method can train a network so that the output attention map corresponds to the edited ones. As a result, the fine-tuned network can out- put an attention map that takes into account human knowl- edge</li> <li>ImageNet</li> <li>CUB-200-2010</li> <li>IDRiD</li> <li>human intuitive edit- ing via a visual interface and suggest new possibilities for human-machine cooperation in addition to the improvement of visual explanations.</li> <li>Typical visual explanation approaches in- clude class activation mapping (CAM) and Grad-CAM</li> <li>However, an inconsistency between the tar- get region of the recognition result, namely the ground truth (GT), and an attention region may occur.</li> <li>To this end, we focus on the visual explanation and the attention mechanism of ABN</li> <li>ABN applies an atten- tion map for visual explanation to the attention mechanism.</li> <li>We propose a fine-tuning method based on the characteristics of ABN and an edited attention map</li> <li>The proposed method fine-tunes the attention and perception branches of ABN to output the same attention map as the edited one.</li> </ul>"},{"location":"KB/Embedding%20Human%20Knowledge%20into%20Deep%20Neural%20Network%20via%20Attention%20Map/#related-work","title":"Related Work","text":""},{"location":"KB/Embedding%20Human%20Knowledge%20into%20Deep%20Neural%20Network%20via%20Attention%20Map/#embedding-human-knowledge","title":"Embedding Human Knowledge","text":"<ul> <li>human-in-the- loop (HITL)</li> <li>Branson et al. [4] pro- posed an interactive HITL approach that helps to train a decision tree by using a question and answer with respect to a specific bird.</li> <li>Deng et al. [7] used a bubble, that is, a circular bounding box, as human knowl- edge. This bubble information is annotated from an atten- tion region when a user distinguishes the two types of birds. By annotating the bubble with various pairs and users, char- acteristic regions of bird images can be obtained when we recognize bird categories.</li> <li>Linsley et al. [18] proposed a method that incorpo- rates human knowledge into large-scale deep neural net- works using the HITL framework. This method added a spatial attention mechanism into the attention mecha- nism [19, 15, 13, 2, 20, 35, 33, 37, 39, 40] of squeeze-and- excitation networks (SENet) [13] and trained the network by using a ClickMe map that introduces human knowledge to the weights of the attention mechanism.</li> </ul>"},{"location":"KB/Embedding%20Human%20Knowledge%20into%20Deep%20Neural%20Network%20via%20Attention%20Map/#editing-the-attention-map","title":"Editing the Attention Map","text":"<ul> <li>In this experiment, we used an ABN whose backbone is 152-layer ResNet [12] (ResNet152+ABN) as a network mode</li> <li>Then, we selected the 1k misclassified samples from the validation samples and edited the maps</li> <li>btain the attention map from the at- tention branch, where the size of the attention map is 14\u00d714 pixels. Then, we edit the obtained attention map manually. Note that the attention map is resized to 224\u00d7224 pixels and is overlaid with the input image for ease of manual editing. The edited attention map is resized to 14 \u00d7 14 pixels and used for an attention mechanism to infer classification re- sults from the perception branch.</li> <li>By training the attention and percep- tion branches with the edited attention map including hu- man knowledge, ABN can output an attention map that con- siders this knowledge and thereby improve the classification performance.</li> <li>During the fine-tuning process, we update the parameters of the attention and perception branches by using the loss calculated from the attention map obtained from ABN and the edited attention map in addition to the loss of ABN</li> <li>To make an attention map from the bubbles, we use a kernel density estimation with multiple bubbles</li> <li>A dense region of bubbles indicates an impor- tant region for recognizing the bird category.</li> <li>In contrast, the proposed method highlights the local characteristic regions, such as the color and the head of the bird. In addition, the proposed method removes noise from the attention map by fine-tuning. Thus, the proposed method can also improve the performance of fine-grained recognition.</li> <li>Consequently, our method can gener- ate a more interpretable attention map and successfully em- bed human knowledge.</li> </ul>"},{"location":"KB/Embedding%20Human%20Knowledge%20into%20Deep%20Neural%20Network%20via%20Attention%20Map/#fine-tuning-branches","title":"Fine Tuning Branches","text":"<ul> <li>\\(x_i\\) is the i-th sample $$ L_{abn}(x_{i})=L_{att}(x_{i})+L_{per}(x_{i}) $$<ul> <li>where \\(L_{arr}, L_{per}\\) are conventional cross entropy losses for the attention and perception branches, respectively $$ L(x_{i})=L_{abn}(x_{i})+L_{map}(x_{i}) $$</li> </ul> </li> <li>Edited map : M' $$ L_{map}(x_{i})=\\gamma||M'(x_{i})-M(x_{i})||_{2} $$         - \\(\\gamma\\) is a scale factor         - \\(L_{map}\\) is larger than the others, hence needs to be scaled</li> </ul>"},{"location":"KB/Embedding%20Human%20Knowledge%20into%20Deep%20Neural%20Network%20via%20Attention%20Map/#images","title":"Images","text":""},{"location":"KB/Embedding%20ethical%20principles%20in%20collective%20decision%20support%20systems/","title":"Embedding ethical principles in collective decision support systems","text":""},{"location":"KB/Embedding%20ethical%20principles%20in%20collective%20decision%20support%20systems/#embedding-ethical-principles-in-collective-decision-support-systems","title":"Embedding Ethical Principles in Collective Decision Support Systems","text":"<ul> <li>Joshua Greene, Francesca Rossi, John Tasioulas, Kristen Brent Venable, and Brian Williams.</li> <li>authors envisioned a possible way forward to enable human-agent collectives [Jennings et al., 2014] to make ethical collective decisions</li> <li>By imbuing individual agents with ethical decision-making mechanisms (such as those mentioned in the previous section), a population of agents can take on different roles when evaluating choices of action with moral considerations in a given scenario</li> <li>Based on a set of initial ethics rules, more complex rules can be acquired gradually through learning.</li> <li>Their evaluations, manifested in the form of preferences and limited by feasibility constraints, can be aggregated to reach a collective decision</li> <li>need for new forms of preference representation in collective ethical decisionmaking</li> <li>potential candidate actions to choose from can vastly outnumber the number of agents involved which is very different from multi-agent voting scenarios.</li> <li>candidate actions may not be independent from each other, some of them may share certain features which describe their ethical dilemma situations</li> </ul>"},{"location":"KB/Embedding/","title":"Embedding","text":""},{"location":"KB/Embedding/#embedding","title":"Embedding","text":"<ul> <li>More complex than 1 hot</li> <li>Lookup table is an example.<ul> <li> \\[token\\_embedding(i) = gather(W, i)\\] </li> </ul> </li> <li>Say vocabulary is (the cat walks)<ul> <li>Embedding vector v that will be learnt</li> <li>Values like : \\(v_{the}\\), \\(v_{cat}\\), \\(v_{walks}\\)</li> </ul> </li> </ul>"},{"location":"KB/Embolism/","title":"Embolism","text":""},{"location":"KB/Embolism/#embolism","title":"Embolism","text":"<ul> <li>A clot caused by blood, fat, air or other types of fluid, gas or foreign material</li> </ul>"},{"location":"KB/Emergentism/","title":"Emergentism","text":""},{"location":"KB/Emergentism/#emergentism","title":"Emergentism","text":"<ul> <li>What seems symbolic emerges from distributed representations<ul> <li>qualitatively newand more complex structures can emerge from simpler, basic facts</li> <li>Language structure can emerge from simply listening and producing speech</li> <li>Structural properties of language, e.g. part-of-speech (nouns, verbs) can emerge from serial order, distributional properties and procedural memory.</li> </ul> </li> </ul>"},{"location":"KB/Emperical%20Risk/","title":"Emperical Risk","text":""},{"location":"KB/Emperical%20Risk/#emperical-risk","title":"Emperical Risk","text":"<ul> <li>TRAINING ERROR. Mean loss computed over training examples</li> <li> \\[R(f) = \\mathbb{E} _{(X,Y) \\sim P(X,Y)}[l(y, f(x))]\\] </li> <li> \\[R^{emp}(h) = \\frac{1}{N}\\Sigma_{i=1}^{N}L(h(x_{i}), y_{i})\\] </li> <li> <p>joint prob distribution \\(P(X\\in A,Y=c)\\) is unknown</p> <ul> <li>Decision Boundaries</li> </ul> </li> <li> <p>Learning set \\(\\(\\mathcal L\\)\\) is finite</p> </li> <li>Need an estimator to evaluate it<ul> <li>Supervised Learning<ul> <li>Compute \\(\\(\\mathcal L_{train}\\)\\)</li> <li>Risk train = (1/M)(sum of loss values for (y, f(x)))</li> <li>This is an unbiased estimator, so we can use it to approximate the optimal function f* that minimizes \\(\\(\\mathbb{R}\\)\\)</li> <li>This means that we find \\(\\(argmin_{f\\in F} \\hat R(f, \\mathcal{L}_Train)\\)\\) (out of all the possible functions)</li> <li>\\(\\(lim_{M\\rightarrow \\infty}(f^*_{\\mathcal{L}_Train}) = f^*\\)\\) : converges to the fn that minimizes emprical risk</li> </ul> </li> <li>Ordinary least squares regression</li> </ul> </li> </ul>"},{"location":"KB/Enabling%20Device/","title":"Enabling Device","text":""},{"location":"KB/Enabling%20Device/#enabling-device","title":"Enabling Device","text":"<ul> <li>A manually operated device which when continuously activated, permits motion. Releasing the device shall stop robot motion and motion of associated equipment that may present a hazard.</li> </ul>"},{"location":"KB/Encoder%20Decoder%20Attention/","title":"Encoder Decoder Attention","text":""},{"location":"KB/Encoder%20Decoder%20Attention/#encoder-decoder-attention","title":"Encoder Decoder Attention","text":"<ul> <li>Q comes from prev decoder</li> <li>K,V from encoder</li> </ul>"},{"location":"KB/Encodings/","title":"Encoding","text":""},{"location":"KB/Encodings/#encoding","title":"Encoding","text":""},{"location":"KB/Encodings/#discrete-continuous","title":"Discrete -&gt; Continuous","text":""},{"location":"KB/Encodings/#continous-discrete","title":"Continous -&gt; Discrete","text":""},{"location":"KB/End-effector/","title":"End effector","text":""},{"location":"KB/End-effector/#end-effector","title":"End-effector","text":"<ul> <li>An accessory device or tool, specifically designed for attachment to the robot wrist or tool mounting plate to enable the robot to perform its intended task. (Examples may include: gripper, spot weld gun, arc weld gun, spray point gun or any other application tools.)</li> </ul>"},{"location":"KB/Endoscope/","title":"Endoscope","text":""},{"location":"KB/Endoscope/#endoscope","title":"Endoscope","text":"<ul> <li>An optical instrument containing a tube with a lighted end used for internal examinations</li> </ul>"},{"location":"KB/Endpoint/","title":"Endpoint","text":""},{"location":"KB/Endpoint/#endpoint","title":"Endpoint","text":"<ul> <li>The nominal commanded position that a manipulator will attempt to achieve at the end of a path of motion. The end of the distal link.</li> </ul>"},{"location":"KB/Eneco%20Data%20Scientist/","title":"ABN Amro AI Dev","text":""},{"location":"KB/Eneco%20Data%20Scientist/#eneco-motivation-letter-subhaditya","title":"Eneco Motivation Letter - Subhaditya","text":"<p>As I write this motivation letter, the temperatures in NL have hit yet another record for the hottest September ever. One of the biggest reasons for this is global warming, and carbon emissions are a massive component. Eneco's mission to be carbon neutral and help customers shift towards sustainable energy sources greatly resonates with me, so I am applying for this position as a Data Scientist.</p> <p>My expertise is a combination of data analytics and computer vision, and as of a month ago, I also have a Master in Artificial Intelligence from the University of Groningen. I am familiar with the tools required for basic and advanced AI and analytics from internships, research projects, papers, freelance work, and many personal projects. In my previous internship at KPMG, I built 10+ dashboards using PowerBI for a project with the Abu Dhabi government. In other internships, I have made several analytics pipelines and machine learning implementations. </p> <p>In any team, it is essential that each of the members can contribute something to the overall development of the projects. Although I have a lot to learn, I genuinely enjoy developing solutions that have a positive impact, and I can contribute quite a bit to any team I get the chance to work with. If there is anything I do not know, I am also ready to develop those skills quickly.</p>"},{"location":"KB/Energy%20Transferred%20in%20a%20Component/","title":"Energy Transferred in a Component","text":""},{"location":"KB/Energy%20Transferred%20in%20a%20Component/#energy-transferred-in-a-component","title":"Energy Transferred in a Component","text":"<ul> <li>charge passing through it x potential difference acorss it</li> <li> \\[W = QV\\] </li> </ul>"},{"location":"KB/English%20Wikipedia/","title":"English Wikipedia","text":""},{"location":"KB/English%20Wikipedia/#english-wikipedia","title":"English Wikipedia","text":""},{"location":"KB/Ensemble%20Distillation/","title":"Ensemble Distillation","text":""},{"location":"KB/Ensemble%20Distillation/#ensemble-distillation","title":"Ensemble Distillation","text":"<ul> <li>Distilling the Knowledge in a Neural Network</li> <li>training many different models on the same data and then to average their predictions</li> <li>making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets</li> <li>compress the knowledge in an ensemble into a single model</li> <li>MNIST</li> <li>ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse</li> <li>specialist models can be trained rapidly and in parallel</li> <li>distillation works remarkably well even when the transfer set that is used to train the distilled model lacks any examples of one or more of the classes</li> <li>performance of a single really big net that has been trained for a very long time can be significantly improved by learning a large number of specialist nets, each of which learns to discriminate between the classes in a highly confusable cluster.</li> </ul>"},{"location":"KB/Ensemble%20of%20Shape%20Functions/","title":"Ensemble of Shape Functions","text":""},{"location":"KB/Ensemble%20of%20Shape%20Functions/#ensemble-of-shape-functions","title":"Ensemble of Shape Functions","text":"<ul> <li>ESF</li> <li></li> </ul>"},{"location":"KB/Entities%20involving%20in%20actions/","title":"Entities involving in actions","text":""},{"location":"KB/Entities%20involving%20in%20actions/#entities-involving-in-actions","title":"Entities Involving in Actions","text":"<ul> <li>Her house was broken into last week.</li> <li>They took the TV and the stereo.</li> <li>The pronoun \u2018they\u2019 should be recognized as referring to the burglars who broke into the house.</li> </ul>"},{"location":"KB/Entourage%20Plot/","title":"Entourage Plot","text":""},{"location":"KB/Entourage%20Plot/#entourage-plot","title":"Entourage Plot","text":""},{"location":"KB/Entropy%20minimization%20by%20adverarial%20learning/","title":"Entropy minimization by adverarial learning","text":""},{"location":"KB/Entropy%20minimization%20by%20adverarial%20learning/#entropy-minimization-by-adverarial-learning","title":"Entropy Minimization by Adverarial Learning","text":"<ul> <li>A limitation of the entropy loss is related to the absence of structural dependencies between local semantics.</li> <li>This is caused by the aggregation of the pixel-wise prediction entropies by summation.</li> <li>unified adversarial training framework which minimizes indirectly the entropy of target data, by encouraging it to become similar to the source one.</li> <li>minimizing distribution distance between source and target on the weighted self-information space</li> <li>We perform the adversarial adaptation on weighted self-information maps using a fully-convolutional discriminator network</li> <li>the discriminator produces domain classification outputs, i.e., class label for the source (resp. target) domain.</li> <li>discriminate outputs coming from source and target images, and at the same time, train the segmentation network to fool the discriminator.</li> </ul>"},{"location":"KB/Entropy/","title":"Entropy","text":""},{"location":"KB/Entropy/#entropy","title":"Entropy","text":"<ul> <li>Measure of information content</li> <li> \\[H = -\\Sigma_{x}P(x)logP(x) = \\Sigma_{x}P(x)log \\frac{1}{P(x)}\\] </li> <li>Units : bits of \\(log_{2}\\)</li> <li>Uniform Distribution maximizes entropy. Results harder to predict</li> </ul>"},{"location":"KB/Ependymal%20Cell/","title":"Ependymal Cell","text":""},{"location":"KB/Ependymal%20Cell/#ependymal-cell","title":"Ependymal Cell","text":"<ul> <li>Line cavities</li> <li>Create, secrete and circulate Cerebrospinal Fluid (CSF)).md)</li> </ul>"},{"location":"KB/Epigenetics/","title":"Epigenetics","text":""},{"location":"KB/Epigenetics/#epigenetics","title":"Epigenetics","text":"<ul> <li>A subset of genetics that focuses on how specific environmental factors can influence where, when, and how a gene is expressed, resulting in variation in the gene\u2019s related traits.</li> </ul>"},{"location":"KB/Epilepsy/","title":"Epilepsy","text":""},{"location":"KB/Epilepsy/#epilepsy","title":"Epilepsy","text":"<ul> <li>A neurological disorder characterized by abnormal electrical activity in the brain, leading to seizures.</li> </ul>"},{"location":"KB/Epistemic/","title":"Epistemic","text":""},{"location":"KB/Epistemic/#epistemic","title":"Epistemic","text":"<ul> <li>Uncertainty produced by the model</li> <li>Class imbalance etc</li> <li>Reduce by adding more info</li> <li></li> </ul>"},{"location":"KB/Equal%20And%20Opposite%20Force%20Pairs/","title":"Equal And Opposite Force Pairs","text":""},{"location":"KB/Equal%20And%20Opposite%20Force%20Pairs/#equal-and-opposite-force-pairs","title":"Equal And Opposite Force Pairs","text":"<ul> <li>\"When one body exerts a force on a second body, the second body simultaneously exerts a force equal in magnitude and opposite in direction on the first body.\"</li> <li> \\[F_{1}= -F_{2}\\] </li> </ul>"},{"location":"KB/Equality%20of%20Opportunity/","title":"Equality of Opportunity","text":""},{"location":"KB/Equality%20of%20Opportunity/#equality-of-opportunity","title":"Equality of Opportunity","text":"<ul> <li>fairness</li> <li>A fairness metric that checks whether, for a preferred label (one that confers an advantage or benefit to a person) and a given attribute, a classifier predicts that preferred label equally well for all values of that attribute. In other words, equality of opportunity measures whether the people who should qualify for an opportunity are equally likely to do so regardless of their group membership.</li> <li>For example, suppose Glubbdubdrib University admits both Lilliputians and Brobdingnagians to a rigorous mathematics program. Lilliputians\u2019 secondary schools offer a robust curriculum of math classes, and the vast majority of students are qualified for the university program. Brobdingnagians\u2019 secondary schools don\u2019t offer math classes at all, and as a result, far fewer of their students are qualified. Equality of opportunity is satisfied for the preferred label of \"admitted\" with respect to nationality (Lilliputian or Brobdingnagian) if qualified students are equally likely to be admitted irrespective of whether they're a Lilliputian or a Brobdingnagian.</li> <li>For example, let's say 100 Lilliputians and 100 Brobdingnagians apply to Glubbdubdrib University, and admissions decisions are made as follows</li> </ul>"},{"location":"KB/Equalized%20Odds/","title":"Equalized Odds","text":""},{"location":"KB/Equalized%20Odds/#equalized-odds","title":"Equalized Odds","text":"<ul> <li>A fairness metric that checks if, for any particular label and attribute, a classifier predicts that label equally well for all values of that attribute.</li> <li>For example, suppose Glubbdubdrib University admits both Lilliputians and Brobdingnagians to a rigorous mathematics program. Lilliputians' secondary schools offer a robust curriculum of math classes, and the vast majority of students are qualified for the university program. Brobdingnagians' secondary schools don\u2019t offer math classes at all, and as a result, far fewer of their students are qualified. Equalized odds is satisfied provided that no matter whether an applicant is a Lilliputian or a Brobdingnagian, if they are qualified, they are equally as likely to get admitted to the program, and if they are not qualified, they are equally as likely to get rejected.</li> </ul>"},{"location":"KB/Equations%20of%20motion/","title":"Equations of motion","text":""},{"location":"KB/Equations%20of%20motion/#equations-of-motion","title":"Equations of Motion","text":"<ul> <li>\\(\\Delta x\\) is displacement</li> <li>$\\Delta t $ is time</li> <li>v is final velocity</li> <li>u is initial velocity</li> <li>a is acceleration</li> <li> \\[v = u + a\\Delta t\\] </li> <li> \\[\\Delta x = u \\Delta t + \\frac{1}{2}a \\Delta t^{2}\\] </li> <li> \\[\\Delta x = \\frac{1}{2}(v+u) \\Delta t\\] </li> <li> \\[v^{2}= u^{2}+2a \\Delta x\\] </li> </ul>"},{"location":"KB/Equivalent%20Current%20Dipole/","title":"Equivalent Current Dipole","text":""},{"location":"KB/Equivalent%20Current%20Dipole/#equivalent-current-dipole","title":"Equivalent Current Dipole","text":"<ul> <li>Generates an electric field</li> <li></li> <li>Perpendicular is Magnetic field - MEG</li> </ul>"},{"location":"KB/Eraneous/","title":"Eraneous","text":"","tags":["jobs"]},{"location":"KB/Eraneous/#eraneous","title":"Eraneous","text":"<p>Hey Naiyara, This is Subhaditya, I just finished my masters in AI and am now looking for an AI job in the NL. I found some really cool projects from Eraneos and was wondering if there were any opportunities to work there. It would be awesome to have a chat :) Best, SM</p>","tags":["jobs"]},{"location":"KB/Ergodic/","title":"Ergodic","text":""},{"location":"KB/Ergodic/#ergodic","title":"Ergodic","text":"<ul> <li>If only one Invariant Distribution</li> <li>Sequence of distributions \\(g^{(n)}\\) converges to g from any initial distribution</li> <li>Asymptotic, stationary, equilibrium distribution</li> </ul>"},{"location":"KB/Ethical%20dilemmas/","title":"Ethical dilemmas","text":""},{"location":"KB/Ethical%20dilemmas/#ethical-dilemmas","title":"Ethical Dilemmas","text":"<ul> <li>situations in which any available choice leads to infringing some accepted ethical principle and yet a decision has to be made</li> </ul>"},{"location":"KB/Euclidean%20Distance/","title":"Euclidean Distance","text":""},{"location":"KB/Euclidean%20Distance/#euclidean-distance","title":"Euclidean Distance","text":"<ul> <li> \\[d = \\sqrt{\\Sigma_{i=1}^{n}(p_{i}-q_{i})^{2}}\\] </li> <li>It is a distance measure that best can be explained as the length of a segment connecting two points.</li> <li>calculated from the cartesian coordinates of the points using the Pythagorean theorem</li> <li>Euclidean distance is not scale in-variant which means that distances computed might be skewed depending on the units of the features. Typically, one needs to\u00a0normalize\u00a0the data before using this distance measure.</li> <li>Moreover, as the dimensionality increases of your data, the less useful Euclidean distance becomes. This has to do with the curse of dimensionality</li> <li>works great when you have low-dimensional data and the magnitude of the vectors is important to be measured</li> </ul>"},{"location":"KB/Eugenics/","title":"Eugenics","text":""},{"location":"KB/Eugenics/#eugenics","title":"Eugenics","text":"<ul> <li>A 19th century scientific theory that advocated for selective mating of people with desirable hereditary traits.</li> </ul>"},{"location":"KB/Euler%20Integration/","title":"Euler Integration","text":""},{"location":"KB/Euler%20Integration/#euler-integration","title":"Euler Integration","text":"<ul> <li> \\[\\frac{dx}{dt} = f(x,t), x(t_{0}) = x_{0}\\] </li> <li>First order integration</li> <li>Midpoint Method</li> <li>Runge Kutta</li> </ul>"},{"location":"KB/Eulerian%20Grid/","title":"Eulerian Grid","text":""},{"location":"KB/Eulerian%20Grid/#eulerian-grid","title":"Eulerian Grid","text":"<ul> <li>Focus on domain</li> <li>Properties given on a grid  </li> <li>(Position of particles is implicit)</li> <li></li> </ul>"},{"location":"KB/Europarl-ST/","title":"Europarl-ST","text":""},{"location":"KB/Europarl-ST/#europarl-st","title":"Europarl-ST","text":"<ul> <li>multilingual speech translation corpus</li> <li>based on speeches and debates in the European parliament between 2008-2013</li> <li>Creative Common Non-Commercial license</li> <li>data belongs to the European Union</li> <li>by releasing, authors want to improve speech translation</li> <li>consists of audio, transcript and translation of the transcript</li> <li>72 translation directions</li> <li>includes also noisy samples</li> </ul>"},{"location":"KB/Even%20angels%20need%20the%20rules%20AI%2C%20roboethics%2C%20and%20the%20law/","title":"Even angels need the rules AI, roboethics, and the law","text":""},{"location":"KB/Even%20angels%20need%20the%20rules%20AI%2C%20roboethics%2C%20and%20the%20law/#even-angels-need-the-rules-ai-roboethics-and-the-law","title":"Even Angels Need the Rules AI, Roboethics, and the Law","text":"<ul> <li>Ugo Pagallo</li> <li>Collective Ethical Decision Frameworks</li> </ul>"},{"location":"KB/Evidence%20For%20Distributivity%20Effects%20in%20Comprehension/","title":"Evidence For Distributivity Effects in Comprehension","text":""},{"location":"KB/Evidence%20For%20Distributivity%20Effects%20in%20Comprehension/#evidence-for-distributivity-effects-in-comprehension","title":"Evidence For Distributivity Effects in Comprehension","text":"<ul> <li>Nikole D. Patson and Tessa Warren</li> </ul>"},{"location":"KB/Evidence%20For%20Distributivity%20Effects%20in%20Comprehension/#intro","title":"Intro","text":"<ul> <li>In the current paper, we introduce a new methodology for detecting whether a word in a sentence is conceptually represented as plural and use it to shed light on a debate about whether comprehenders interpret singular indefinite noun phrases within a distributed predicate as plural during on-line reading.</li> <li>self-paced reading on a sentence presented in one- and two-word chunk</li> <li>indicated that participants were slower to judge that one word was on the screen when the word was plural (e.g., cats) than when it was singular (e.g., cat)</li> <li>build different conceptual representations for distributed versus collective predicates, and interpret a singular indefinite noun phrase within a distributed predicate as plura</li> </ul>"},{"location":"KB/Evidence%20For%20Distributivity%20Effects%20in%20Comprehension/#results","title":"Results","text":"<ul> <li>When the group was conceptually distributed (5a), participants incorrectly (in American English) used a plural verb (were) more often in their continuations than when the group was conceptually collective (5b). This indicates that participants were more likely to treat the gang as a plural when its individuals were more salient (5a) rather than when the group was the relevant referent (5b). This suggests that distributivity can make grammatically singular lexical items that have plural referents (e.g., gang, group) functionally plural during language production.</li> <li>This production and off-line comprehension work suggests that readers build different conceptual representations for collective and distributed predicates, and is consistent with the hypothesis that singular indefinite noun phrases within distributed predicates are often treated as conceptually plural.</li> </ul>"},{"location":"KB/Evidence%20For%20Distributivity%20Effects%20in%20Comprehension/#experiment-1","title":"Experiment 1","text":"<ul> <li>Experiment 1 was conducted to test whether the Berent et al. (2005) methodology could be extended to sentences. It is possible that the added complexity involved in building and maintaining a sentence representation during the number judgment task, or the task demands of simultaneously carrying out self-paced reading and number judgments, might make participants less sensitive to interference than they were in Berent et al. (2005). Experiment 1 is also important because in order to use the paradigm to test ambiguous cases (as in Experiment 2), we must first establish that the paradigm works on simple, unambiguous sentences.</li> <li>The critical measure was the reaction time for the number judgment for correct number judgment trials only. There was a significant main effect of noun type such that 'one' responses were slower when the target word was plural</li> <li>Experiment 1 confirmed that even in sentential contexts, semantic plural information on a word interferes with singular number judgments.</li> <li>Specifically, if the distributing quantifier takes wide scope over the indefinite, and comprehenders build conceptual representations for distributed predicates that contain multiple exemplars of the referent introduced by the singular indefinite noun phrase, then one-word judgment times should be slower for indefinite noun phrases in distributed predicates than collective predicates.</li> <li>The experiment had a 2 \u00d7 2 within-participants design. The first factor was the quantifier type and was either distributed (a) or collective (b)</li> <li>They were asked to rate on a scale of 1 \u2013 5 (where 1 was 'definitely one' and 5 was 'definitely more than one') whether the last word in the sentence referred to one or more than one object. Results indicated that the singular-marked distributed items were indeed biased toward a plural interpretation of the noun phrase. Participants rated the singular-marked distributed items as being closer to the 'definitely more than one' end of the scale</li> <li>than the singular-marked collective items</li> </ul>"},{"location":"KB/Evidence%20For%20Distributivity%20Effects%20in%20Comprehension/#experiment-2","title":"Experiment 2","text":"<ul> <li>The results of Experiment 2 confirm the hypothesis that singular indefinite noun phrases in distributed predicates can indeed be treated as conceptually plural during reading</li> <li>There was no reliable effect of distributivity and no reliable difference between the plural-marked conditions, indicating that the difference in the singular-marked conditions was unlikely to be the result of one kind of predicate being more costly to compute than the other. These results indicate that in these items the distributing quantifier took wide scope over the indefinite</li> <li>indicate that conceptual plurality interferes with number judgments during sentence comprehension</li> <li>These findings (Filik et al., 2004; Paterson et al., 2008) indicate that comprehenders do not build conceptually plural referents on-line for indefinite noun phrases in distributed structures that off-line norming had indicated were likely to be interpreted as plural.</li> </ul>"},{"location":"KB/Explainability%20Defn/","title":"Explainability Defn","text":""},{"location":"KB/Explainability%20Defn/#explainability-defn","title":"Explainability Defn","text":"<ul> <li>associated with the notion of explanation as an interface between humans and a decision maker that is, at the same time, both an accurate proxy of the decision maker and comprehensible to humans</li> </ul>"},{"location":"KB/Explainability%20Taxonomy/","title":"Explainability Taxonomy","text":""},{"location":"KB/Explainability%20Taxonomy/#explainability-taxonomy","title":"Explainability Taxonomy","text":"<ul> <li>Explainable Artificial Intelligence (XAI) Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI</li> <li>Analysis of Explainers of Black Box Deep Neural Networks for Computer Vision A Survey</li> </ul>"},{"location":"KB/Explainable%20Artificial%20Intelligence%20%28XAI%29%20Concepts%2C%20Taxonomies%2C%20Opportunities%20and%20Challenges%20toward%20Responsible%20AI/","title":"Explainable Artificial Intelligence (XAI) Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI","text":""},{"location":"KB/Explainable%20Artificial%20Intelligence%20%28XAI%29%20Concepts%2C%20Taxonomies%2C%20Opportunities%20and%20Challenges%20toward%20Responsible%20AI/#explainable-artificial-intelligence-xai-concepts-taxonomies-opportunities-and-challenges-toward-responsible-ai","title":"Explainable Artificial Intelligence (XAI) Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI","text":"<ul> <li>@arrietaExplainableArtificialIntelligence2019</li> <li> </li> <li>Understandability</li> <li>Comprehensibility</li> <li>Interpretability</li> <li>Explainability Defn</li> <li>Transparency</li> <li>Trustworthiness</li> <li>Causality</li> <li>Transferability</li> <li>Informativeness</li> <li>Confidence</li> <li>Fairness</li> <li>Accessibility</li> <li>Interactivity</li> <li>Privacy awareness</li> </ul>"},{"location":"KB/Explainable%20Artificial%20Intelligence%20%28XAI%29%20Concepts%2C%20Taxonomies%2C%20Opportunities%20and%20Challenges%20toward%20Responsible%20AI/#charactersitics","title":"Charactersitics","text":""},{"location":"KB/Explainable%20Artificial%20Intelligence%20%28XAI%29%20Concepts%2C%20Taxonomies%2C%20Opportunities%20and%20Challenges%20toward%20Responsible%20AI/#on-the-tradeoff-between-interpretability-and-performance","title":"On the Tradeoff between Interpretability and Performance","text":"<ul> <li>it is not necessarily true that models that are more complex are inherently more accurate</li> <li>It is in this situation that the trade-off between performance and interpretability can be observed</li> <li>In this path toward performance, when the performance comes hand in hand with complexity, interpretability encounters itself on a downwards slope that until now appeared unavoidable</li> <li>Another aspect worth mentioning at this point due to its close link to model interpretability and performance is the approximation dilemma: explanations made for a ML model must be made drastic and approximate enough to match the requirements of the audience for which they are sought, ensuring that explanations are representative of the studied model and do not oversimplify its essential features.</li> <li>confluence of multiple criteria</li> <li>need for having the human in the loop</li> <li>Contextual factors, potential impacts and domain-specific needs must be taken into account when devising an approach to interpretability</li> <li>a thorough understanding of the purpose for which the AI model is built</li> <li>the complexity of explanations that are required by the audience</li> <li>the performance and interpretability levels of existing technology, models and methods</li> <li>Interpretable techniques should be preferred when possible</li> <li>black-box models such as those reviewed in this work (namely, support vector machines, ensemble methods and neural networks) should be selected only when their superior modeling capabilities fit best the characteristics of the problem at hand.</li> <li>If a black-box model has been chosen, the third guideline establishes that ethics-, fairnessand safetyrelated impacts should be weighed</li> <li>rethink interpretability in terms of the cognitive skills, capacities and limitations of the individual human</li> </ul>"},{"location":"KB/Explainable%20Artificial%20Intelligence%20%28XAI%29%20Concepts%2C%20Taxonomies%2C%20Opportunities%20and%20Challenges%20toward%20Responsible%20AI/#fairness-and-discrimination","title":"Fairness and Discrimination","text":"<ul> <li>Individual fairness</li> <li>Group fairness</li> <li>Counterfactual fairness</li> <li>Skewed data</li> <li>Tainted data</li> <li>Limited features</li> <li>Proxy features</li> <li>Independence</li> <li>Separation</li> <li>Sufficiency</li> </ul>"},{"location":"KB/Explainable%20Artificial%20Intelligence%20%28XAI%29%20Concepts%2C%20Taxonomies%2C%20Opportunities%20and%20Challenges%20toward%20Responsible%20AI/#accountability","title":"Accountability","text":"<ul> <li>Auditability</li> <li>Minimization and reporting of negative impacts</li> <li>Redress</li> </ul>"},{"location":"KB/Explanation%20is%20not%20a%20Technical%20Term/","title":"Explanation is not a Technical Term","text":""},{"location":"KB/Explanation%20is%20not%20a%20Technical%20Term/#explanation-is-not-a-technical-term","title":"Explanation is not a Technical Term","text":"<ul> <li>@gilpinExplanationNotTechnical2022</li> </ul>"},{"location":"KB/Explanation%20is%20not%20a%20Technical%20Term/#abstract","title":"Abstract","text":"<ul> <li>Artificial Intelligence (XAI) and those explanations that users and other audiences actually need, which should be defined by the full spectrum of functional roles, audiences, and capabilities for explanation</li> <li>In this paper, we explore the features of explanations and how to use those features in evaluating their utility.</li> <li>we discuss the risk of XAI enabling trust in systems without establishing their trustworthiness and define a critical next step for the field of XAI to establish metrics to guide and ground the utility of system-generated explanations</li> </ul>"},{"location":"KB/Explanation%20is%20not%20a%20Technical%20Term/#introduction","title":"Introduction","text":"<ul> <li>The problem is that explainability is not a well-defined goal: there is no common definition, metrics, or benchmarks for success.</li> <li>Rather than taking a view of explanations as undi\u21b5erentiated artifacts shared by multiple users, we view them as generated in response to their functional roles, audience, and data access</li> <li>Functional role: How is the explanation going to be used?</li> <li>Audience: To whom is it directed and what is their knowledge of the system and domain?</li> <li>Capabilities: What are the capabilities of the system constructing the explanation and the source of data/knowledge used to do so?</li> </ul>"},{"location":"KB/Explanation%20is%20not%20a%20Technical%20Term/#motivation","title":"Motivation","text":"<ul> <li>Because explanations are links between agents, we also need to consider the audience and their knowledge background</li> <li>An explanation's functional role defines the information that needs to be communicated.</li> <li>The state of the audience's initial knowledge of both the domain and processes define a second set of requirements related to the detail and vocabulary used in the explanation.</li> <li>These three factors define the basis for metrics for an evaluation calculus that can be used to evaluate an explanation based on whether it serves the right functional role with the right level of elaboration for its audience supported by the system's knowledge of its own reasoning.</li> <li>By unpacking the idea of \"explanation\" into these factors, XAI can go beyond the \"checking the box\" phase to one in which explanations can play the role for which they were designed</li> </ul>"},{"location":"KB/Explanation%20is%20not%20a%20Technical%20Term/#the-requirements-functional-roles","title":"The Requirements: Functional Roles","text":"<ul> <li>Unfortunately, one of the early findings in the realm of explanation was the discovery that the human bar on what constitutes a \"good explanation\" is shockingly low.</li> <li>As Langer discovered in 1978, people are satisfied with \"Placebic\" information if it has the syntactic form of an explanation [13].</li> <li>A system's capabilities and access to knowledge about its own reasoning determine the scope and validity of the explanations it can generate.</li> </ul>"},{"location":"KB/Explanation%20is%20not%20a%20Technical%20Term/#engineers-and-developers","title":"Engineers and Developers","text":"<ul> <li>explanations are close to the machinery, and the shared language is technical and can contain machine representation</li> <li>These users have experience working with models, understand limitations, can run experiments, and can intuit from incomplete or partial \"explanations\" as they perform their task: debugging and iterating on the model to improve its performance and make it trustworthy</li> </ul>"},{"location":"KB/Explanation%20is%20not%20a%20Technical%20Term/#doctors","title":"Doctors","text":"<ul> <li>explanations are less about the core mechanics of the models themselves and reflect the logic of the domain, a\u21b5ording exploration, counterfactuals, cohort comparison and transparent reasoning about the features most pertinent to a diagnosis</li> <li>if a system provides a warning that a particular patient is showing signs of possible heart failure, a doctor will want a list of relevant factors in order of importance or concern, as well as the patient's prognosis compared to that of other patients, and how that prognosis changes if certain factors are amended</li> <li>At their best, the interaction between a doctor and an intelligent system should seek to mirror the sorts of interactions two doctors might have when collaborating on the task of developing a diagnosis and refining a treatment plan.</li> </ul>"},{"location":"KB/Explanation%20is%20not%20a%20Technical%20Term/#patients","title":"Patients","text":"<ul> <li>patient's goal is more immediate and comes with higher personal stakes</li> <li>This is the realm of personal decision making and, in cases of emergency, immediate action</li> <li>These individuals are less informed about aspects of the medical domain, and systems tailored to them must account for that information asymmetry.</li> <li>Thus, XAI, in this use case, becomes less about collaboration or justification and instead is geared towards confidence building, risk assessment, contextualization, and guided calls to action</li> </ul>"},{"location":"KB/Explanation%20is%20not%20a%20Technical%20Term/#regulators-and-auditors","title":"Regulators and Auditors","text":"<ul> <li>require explanations that scope across the mechanisms of a system, the data used to train it, and the medical practices that it embodies.</li> <li>they require explanations that might include elements of the human in the loop in order to determine responsibility and culpability.</li> <li>engineers</li> <li>building a system, explanations need to touch on the aspects of a system's decisions that can be used in debugging, referencing the data, feature selection, and comparisons.</li> <li>users interpreting the recommendations of a system</li> <li>explanations need to include features that can be used to support exploration of hypotheticals, counterfactuals, cohort comparison and likelihoods.</li> <li>explanations need to support trust and confidence building, risk assessment, contextualization, and decision support</li> <li>stakeholders impacted by a decision</li> </ul>"},{"location":"KB/Explanation%20is%20not%20a%20Technical%20Term/#auditors-and-regulators","title":"Auditors and Regulators","text":"<ul> <li>explanations need to support comparisons and aggregate review of performance and the trail of both algorithmic and human decisions that led to it</li> </ul>"},{"location":"KB/Explanation%20is%20not%20a%20Technical%20Term/#the-requirements-user-knowledge","title":"The Requirements: User Knowledge","text":"<ul> <li>The knowledge state of the various stakeholders interacting with the system defines another</li> <li>As noted above, the functional role of XAI starts in the realm of model debugging and diagnostics \u2013 a tool set aimed at technical users capable of deciphering machine representations, interpreting model performance metrics, and updating model training to improve performance</li> <li>Domain experts may not need explanations that provide insight into the technical workings of systems</li> <li>They want and understand explanations at the domain level.</li> <li>While it is often the case that they have the right level of domain knowledge, it is always a possibility that they lack detailed knowledge of specific domain level features and ideas.</li> <li>Impacted stakeholders are highly variable</li> <li>they may have no knowledge of either the domain or the technology. They do not have expertise in either but do have basic knowledge of how the world works.</li> <li>Stakeholders such as auditors and regulators have specialized knowledge of the ways in which data and algorithms interact and how to look at the performance of a system through the lens of comparison and systemic issues.</li> </ul>"},{"location":"KB/Explanation%20is%20not%20a%20Technical%20Term/#system-capabilities","title":"System Capabilities","text":""},{"location":"KB/Explanation%20is%20not%20a%20Technical%20Term/#interpretability","title":"Interpretability","text":"<ul> <li>how understandable the output representation is to the audience.</li> <li>depends on the target audience and the task</li> </ul>"},{"location":"KB/Explanation%20is%20not%20a%20Technical%20Term/#accuracy","title":"Accuracy","text":"<ul> <li>based on correctness</li> <li>except that it is in terms of the explanation itself</li> <li>dependent on both the domain and the user</li> <li>A saliency map applied to cancer images may highlight the hospital name, indicating that the reasons supporting the diagnosis is</li> <li>the hospital where the image was taken [17]</li> <li> <p>This explanation is true to the model but the model is faulty. The explanation is accurate but the model is not.</p> </li> <li> <p>Elaborateness</p> </li> <li> <p>Faithfulness</p> </li> </ul>"},{"location":"KB/Explanation%20is%20not%20a%20Technical%20Term/#trusted-but-not-trustworthy-a-new-dark-pattern","title":"Trusted but not Trustworthy: A New Dark Pattern","text":"<ul> <li>One of the dominant themes in XAI is the notion of trust</li> <li>The focus is on getting users to trust a system rather than on making the system trustworthy.</li> <li>Such trust is developed through output assessment over time and through a host of factors external to the model output itself (including the apparent trust of other experts, design decisions at the system and user experience levels, and ancillary components such as domain-informed conversational interfaces).</li> <li>hard won and easily lost</li> </ul>"},{"location":"KB/Explanation%20is%20not%20a%20Technical%20Term/#discussion-metrics-the-next-critical-step-for-xai","title":"Discussion: Metrics - the next Critical step for XAI","text":"<ul> <li>Explanations should provide new insights: explanations should go beyond the \"why, what, how\" [20]</li> <li>We must also be able to compare and contrast them, as explanations can disagree and directly contradict each other [21]</li> <li>We also want to quantify the system capabilities: how well the explanation actually explains</li> <li>When we as humans explain something, it is a deductive process. Each claim follows from the last claim</li> <li>The crucial point is that explanations need to fit the functional role in a manner that is interpretable to the audience</li> <li>In evaluating an explanation, the question is whether it fits the role and the audience</li> <li>With a variety of explanation types, a single \"one size fits all\" metric is inappropriate</li> <li>Explanations must be built, interpreted, and evaluated through the lens of the functions that they serve and the knowledge situations in which they do so; through the lens of requirements and a system's capability to meet them.</li> <li>As work in XAI continues, it must attend to what exactly is being explained, to whom the explanation is directed, and how it is going to be used, and must provide a structured, standard evaluation approach via metrics of success.</li> </ul>"},{"location":"KB/Explanation%20is%20not%20a%20Technical%20Term/#images","title":"Images","text":""},{"location":"KB/Explanator/","title":"Explanator","text":""},{"location":"KB/Explanator/#explanator","title":"Explanator","text":"<ul> <li>synonym for an explaining system or explaining process that gives answers to questions in understandable terms, which could, computationally, be considered a program execution trace.</li> <li>or instance, if the question is how a machine is working, the explainer makes the internal structure of a machine more transparent to humans</li> </ul>"},{"location":"KB/Exploding%20Gradient/","title":"Exploding Gradient","text":""},{"location":"KB/Exploding%20Gradient/#exploding-gradient","title":"Exploding Gradient","text":"<ul> <li>weight matrices have max eigenvalue \\(max_{i} \\lambda_{j} &gt; 1\\) , gradient increases per layer <ul> <li>if enough depth, then converges to infinity </li> </ul> </li> </ul>"},{"location":"KB/Exponential%20Distribution/","title":"Exponential Distribution","text":""},{"location":"KB/Exponential%20Distribution/#exponential-distribution","title":"Exponential Distribution","text":"<ul> <li>How long you have to wait for something after the it has happened once already</li> <li>Average rate /unit reference time</li> <li>PDF \\(\\(p(x) = \\lambda e^{-\\lambda x}\\)\\) and \\(x \\geq 0\\)</li> <li>Expectation \\(\\(E(X) = \\frac{1}{\\lambda}\\)\\)</li> <li></li> <li>Rate : \\(\\(\\hat \\lambda = \\frac{1}{N-1}\\Sigma_{i = 1, \u2026, N}t_{i+1}-t_{i}\\)\\)</li> <li>Spiking Networks</li> </ul>"},{"location":"KB/Extensions%20to%20SlimStampen/","title":"Extensions to SlimStampen","text":""},{"location":"KB/Extensions%20to%20SlimStampen/#extensions-to-slimstampen","title":"Extensions to SlimStampen","text":"<ul> <li>Konteksti<ul> <li>Semantic similarity</li> </ul> </li> <li>Increase activation of similar facts</li> <li>Dual-lingo<ul> <li>Word + Picture based cues</li> </ul> </li> <li>Type of info<ul> <li>Eg vocabulary</li> </ul> </li> <li>Perfect pitch<ul> <li>auditory stimuli</li> </ul> </li> <li>Fun with flags<ul> <li>Improve scheduling by computing a continous stimuli</li> </ul> </li> <li>CramDroid<ul> <li>App that helps with between-sessions</li> <li>Track decay functions and send notif</li> </ul> </li> <li>Space Times<ul> <li>Game based memorization of tables</li> </ul> </li> <li>Vocab Warrior<ul> <li>play against an ACT-R</li> <li>answer faster</li> </ul> </li> </ul>"},{"location":"KB/Extra-position/","title":"Extra-position","text":""},{"location":"KB/Extra-position/#extra-position","title":"Extra-position","text":"<ul> <li>Did anyone who you expected to help actually help?</li> <li>Did anyone actually help who you expected to help?</li> </ul>"},{"location":"KB/Eye%20Tracking/","title":"Eye Tracking","text":""},{"location":"KB/Eye%20Tracking/#eye-tracking","title":"Eye Tracking","text":"<ul> <li>Gaze position</li> </ul>"},{"location":"KB/Eye-to-hand%20System/","title":"Eye-to-hand System","text":""},{"location":"KB/Eye-to-hand%20System/#eye-to-hand-system","title":"Eye-to-hand System","text":"<ul> <li>The task in visual servoing is to use visual information to control the robot's endeffector relative to a target object.</li> <li>provide feedback to the robot controller at each time step</li> <li></li> </ul>"},{"location":"KB/FGSM/","title":"FGSM","text":""},{"location":"KB/FGSM/#fgsm","title":"FGSM","text":"<ul> <li>FGSM is a method of generating noise in the direction of the cost function gradient concerning the data</li> <li>Given original input image x, label y, model parameter \u03b8, and loss J.  </li> <li> \\[adv_{x}= x+ \\epsilon \\ast sign(\\nabla_{x}(J(\\theta, x, y)))\\] </li> <li>this gives us the perturbations</li> </ul>"},{"location":"KB/FGVC%20Aircraft/","title":"FGVC Aircraft","text":""},{"location":"KB/FGVC%20Aircraft/#fgvc-aircraft","title":"FGVC Aircraft","text":"<ul> <li>This dataset contains images of 100 different types of aircrafts, with a total of 10,000 images.</li> </ul>"},{"location":"KB/FGVCx/","title":"FGVCx","text":""},{"location":"KB/FGVCx/#fgvcx","title":"FGVCx","text":"<ul> <li>FGVCx is a dataset that includes a number of fine-grained datasets, such as the FGVC Aircraft, Stanford Cars and Stanford Dogs datasets.</li> </ul>"},{"location":"KB/FHIR/","title":"FHIR","text":"","tags":["medical"]},{"location":"KB/FHIR/#fhir","title":"FHIR","text":"<ul> <li>specific standard within HL7 that leverages modern web technologies and is gaining traction for its flexibility in healthcare data exchange</li> <li>fhir-py<ul> <li><code>apt install protobuf-compiler protoc --version # Ensure version 3+ pip install google-fhir-views[r4,bigquery,spark]</code></li> </ul> </li> </ul>","tags":["medical"]},{"location":"KB/FLASH/","title":"FLASH","text":""},{"location":"KB/FLASH/#flash","title":"FLASH","text":"<ul> <li>Transformer Quality in Linear Time</li> <li>weaknesses in handling long sequences</li> <li>FLASH</li> <li>performant layer (gated linear unit) and by combining it with an accelerator-efficient approximation strategy (mixed chunk attention)</li> <li>GAU</li> <li>Mixed chunk attention</li> <li>outperforms three baselines: vanilla Transformer, Performer and Combiner in terms of quality and efficiency</li> <li>Wiki</li> <li>PG-19</li> </ul>"},{"location":"KB/FLAVA/","title":"FLAVA","text":""},{"location":"KB/FLAVA/#flava","title":"FLAVA","text":"<ul> <li>FLAVA: a Foundational Language and Vision Alignment Model</li> <li>foundational vision and language alignment model that performs well on all three target modalities: 1) vision, 2) language, and 3) vision &amp; language</li> <li>use a single holistic universal model, as a \u201cfoundation\u201d, that targets all modalities at once</li> <li>wide range of 35 tasks spanning these target modalities</li> </ul>"},{"location":"KB/FP16%20training/","title":"FP16 training","text":""},{"location":"KB/FP16%20training/#fp16-training","title":"FP16 Training","text":"<ul> <li>@micikeviciusMixedPrecisionTraining2018</li> <li>Reduced precision has a narrower range that might make the results more out of range and worsen the training progress</li> <li>Can store all parameters and activations in FP16 and then use that for gradients.</li> <li>Also copy to FP32 for parameter updates</li> <li>Multiply scalar to loss to align range of FP16</li> </ul>"},{"location":"KB/FTSwish/","title":"FTSwish","text":""},{"location":"KB/FTSwish/#ftswish","title":"FTSwish","text":"<ul> <li>Relu + Sigmoid</li> <li> \\[\\begin{equation} FTSwish: f(x) = \\begin{cases} T, &amp; \\text{if}\\ x &lt; 0 \\\\ \\frac{x}{1 + e^{-x}} + T, &amp; \\text{otherwise} \\\\ \\end{cases} \\end{equation}\\] </li> <li>As we can see, the sparsity principle is still true - the neurons that produce negative values are taken out.</li> <li>What we also see is that the derivative of FTSwish is smooth, which is what made Swish theoretically better than ReLU in terms of the loss landscape</li> <li>However, what I must note is that this function does not protect us from the dying ReLU problem: the gradients for \\(x &lt; 0\\) are zero, as with ReLU.</li> </ul>"},{"location":"KB/FaceNet/","title":"FaceNet","text":""},{"location":"KB/FaceNet/#facenet","title":"FaceNet","text":"<ul> <li>FaceNet: a Unified Embedding for Face Recognition and Clustering</li> <li>mapping from face images to a compact Euclidean space where distances directly correspond to a measure of face similarity</li> <li>Optimize the embedding itself</li> <li>FaceNet directly trains its output to be a compact 128-D embedding using a Triplet Loss function</li> <li>Choosing which triplets to use turns out to be very important for achieving good performance<ul> <li>inspired by curriculum learning</li> <li>online negative exemplar mining strategy which ensures consistently increasing difficulty of triplets as the network trains</li> <li>also explore hard-positive mining techniques which encourage spherical clusters for the embeddings of a single person</li> </ul> </li> <li>squared Lp Regularization L2 distance, in the embedding space directly correspond to face similarity: faces of the same person have small distances and faces of distinct people have large distances</li> <li>face verification simply involves thresholding the distance between the two embeddings; recognition becomes a KNN classification problem</li> <li>Labeled Faces in the Wild</li> <li>Zeiler Fergus</li> <li>Inception</li> <li>Harmonic Embedding</li> </ul>"},{"location":"KB/Factorized%20Embedding%20Parameters/","title":"Factorized Embedding Parameters","text":""},{"location":"KB/Factorized%20Embedding%20Parameters/#factorized-embedding-parameters","title":"Factorized Embedding Parameters","text":"<ul> <li>Factorization of these parameters is achieved by taking the matrix representing the weights of the word embeddings \\(E\\) and decomposing it into two different matrices. Instead of projecting the one-hot encoded vectors directly onto the hidden space, they are first projected on some-kind of lower-dimensional embedding space, which is then projected to the hidden space (Lan et al, 2019). Normally, this should not produce a different result, but let's wait.</li> <li>Another thing that actually ensures that this change reduces the number of parameters is that the authors suggest to reduce the size of the embedding matrix.</li> <li>In BERT, the shape of the vocabulary/embedding matrix E equals that of the matrix for the hidden state H.</li> <li>First of all, theoretically, the matrix E captures context-independent information</li> <li>whereas the hidden representation H captures context-dependent information</li> <li>ALBERT solves this issue by decomposing the embedding parameters into two smaller matrices, allowing a two-step mapping between the original word vectors and the space of the hidden state. In terms of computational cost, this no longer means \\(\\text{O(VxH)}\\) but rather \\(\\text{O(VxE + ExH)}\\), which brings a significant reduction when \\(\\text{H &gt;&gt; E}\\).</li> </ul>"},{"location":"KB/Factors%20for%20MC%20estimate/","title":"Factors for MC Estimate","text":""},{"location":"KB/Factors%20for%20MC%20estimate/#factors-for-mc-estimate","title":"Factors for MC Estimate","text":"<ul> <li>Amount of computation required to simulate transition kernel</li> <li>Time for chain to converge to equilibrium -&gt; no of states that must be discarded</li> <li>No of transitions needed to move from one state in the equilibrium to another that is independant<ul> <li>Redundant information</li> <li>First value will depend to a decreasing degree on the distance from this timestep to the previous ones. Then washout (because old ones are too far away)</li> </ul> </li> </ul>"},{"location":"KB/Fairness%20Constraint/","title":"Fairness Constraint","text":""},{"location":"KB/Fairness%20Constraint/#fairness-constraint","title":"Fairness Constraint","text":"<ul> <li>Applying a constraint to an algorithm to ensure one or more definitions of fairness are satisfied. Examples of fairness constraints include</li> </ul>"},{"location":"KB/Fairness/","title":"Fairness","text":""},{"location":"KB/Fairness/#fairness","title":"Fairness","text":"<ul> <li>explainability can be considered as the capacity to reach and guarantee fairness in ML models.</li> <li>an explainable ML model suggests a clear visualization of the relations affecting a result, allowing for a fairness or ethical analysis</li> <li>a related objective of XAI is highlighting bias in the data a model was exposed to</li> </ul>"},{"location":"KB/Faithfulness/","title":"Faithfulness","text":""},{"location":"KB/Faithfulness/#faithfulness","title":"Faithfulness","text":"<ul> <li>how well the explanation describes the underlying model. This is also known as model completeness [18]</li> </ul>"},{"location":"KB/Familar%20Object%20Grasping%20Object%20Viiew%20recog/","title":"Familar Object Grasping Object Viiew recog","text":""},{"location":"KB/Familar%20Object%20Grasping%20Object%20Viiew%20recog/#familar-object-grasping-object-viiew-recog","title":"Familar Object Grasping Object Viiew Recog","text":"<ul> <li>Shafii, Nima, S. Hamidreza Kasaei, and Lui\u0301s Seabra Lopes. \"Learning to grasp familiar objects using object view recognition and template matching.\" IROS 2016.</li> <li>Grasp template :</li> <li>Local shape feature for graspable regions<ul> <li>spin-image feature</li> </ul> </li> <li>Global feature, the radius (distance from the CoM to the selected keypoint)<ul> <li>important to represent a stable grasp</li> </ul> </li> <li>Finger configuration</li> <li>New objects that are similar to known ones (i.e. they are familiar) can be grasped in a similar way<ul> <li>As an example, if the robot knows how to grasp a pen, it may use the same grasp temple to take a marker</li> </ul> </li> </ul>"},{"location":"KB/Fashion%20MNIST/","title":"Fashion MNIST","text":""},{"location":"KB/Fashion%20MNIST/#fashion-mnist","title":"Fashion MNIST","text":"<ul> <li>https://github.com/zalandoresearch/fashion-mnist</li> <li>alternative to\u00a0MNIST<ul> <li>60'000 train images</li> <li>10'000 test images</li> <li>28x28x1 grayscale</li> <li>10 classes</li> </ul> </li> <li>bit more challenging than\u00a0MNIST</li> </ul>"},{"location":"KB/Fast%20AutoAugment/","title":"Fast AutoAugment","text":""},{"location":"KB/Fast%20AutoAugment/#fast-autoaugment","title":"Fast AutoAugment","text":"<ul> <li>that finds effective augmentation policies via a more efficient search strategy based on density matching</li> </ul>"},{"location":"KB/FastText/","title":"FastText","text":""},{"location":"KB/FastText/#fasttext","title":"FastText","text":"<pre><code>def FastTextNew(vocab_size, embedding_dim, output_dim):\n    return nn.Sequential(\n        Rearrange('t b -&gt; t b'),\n        nn.Embedding(vocab_size, embedding_dim),\n        Reduce('t b c -&gt; b c', 'mean'),\n        nn.Linear(embedding_dim, output_dim),\n        Rearrange('b c -&gt; b c'),\n    )\n</code></pre>"},{"location":"KB/Fastai%20Blocks/","title":"Fastai Blocks","text":""},{"location":"KB/Fastai%20Blocks/#fastai-blocks","title":"Fastai Blocks","text":""},{"location":"KB/Fastai%20Blocks/#building-blocks","title":"Building Blocks","text":"<pre><code># Image Classification\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path)\n\ndls.show_batch(max_n=6)\nlearn = cnn_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(8)\n</code></pre> <pre><code># Label regex\npets = DataBlock(blocks = (ImageBlock, CategoryBlock),\n                 get_items=get_image_files, \n                 splitter=RandomSplitter(seed=42),\n                 get_y=using_attr(RegexLabeller(r'(.+)_\\d+.jpg$'), 'name'),\n                 item_tfms=Resize(460),\n                 batch_tfms=aug_transforms(size=224, min_scale=0.75))\ndls = pets.dataloaders(path/\"images\")\n</code></pre> <ul> <li>DataBlock is more general<ul> <li>list models</li> </ul> </li> </ul> <pre><code>timm.list_models('convnex*')\n</code></pre> <pre><code># Segmentation\npath = untar_data(URLs.CAMVID_TINY)\ndls = SegmentationDataLoaders.from_label_func(\n    path, bs=8, fnames = get_image_files(path/\"images\"),\n    label_func = lambda o: path/'labels'/f'{o.stem}_P{o.suffix}',\n    codes = np.loadtxt(path/'codes.txt', dtype=str)\n)\nlearn = unet_learner(dls, resnet34)\nlearn.fine_tune(8)\n</code></pre> <ul> <li>Segmentation Dataloaders is just another abstraction of the DataBlock for a specific case. Can use the DataBlock as well</li> </ul> <pre><code># Tabular\ndls = TabularDataLoaders.from_csv(path/'adult.csv', path=path, y_names=\"salary\",\n    cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race'],\n    cont_names = ['age', 'fnlwgt', 'education-num'],\n    procs = [Categorify, FillMissing, Normalize])\nlearn = tabular_learner(dls, metrics=accuracy)\nlearn.fit_one_cycle(2)\n</code></pre> <ul> <li>Fitting because pretrained models are not going to be there</li> </ul> <pre><code># Collaborative [Filtering](./Filtering.md)\ndls = CollabDataLoaders.from_csv(path/'ratings.csv')\nlearn = collab_learner(dls, y_range=(0.5,5.5))\nlearn.fine_tune(8)\n</code></pre> <ul> <li>Range is for the output (Since its not a binary output)</li> <li>Saving a model</li> </ul> <pre><code>learn.export('model.pkl')\n</code></pre>"},{"location":"KB/Fastai%20Deployment/","title":"Fastai Deployment","text":""},{"location":"KB/Fastai%20Deployment/#fastai-deployment","title":"Fastai Deployment","text":"<ul> <li>Gradio</li> </ul>"},{"location":"KB/Fastai%20Deployment/#save","title":"Save","text":"<pre><code>from fastai.vision.widgets import *\n</code></pre> <pre><code>path = Path()\npath.ls(file_exts='.pkl')\n\nlearn_inf = load_learner(path/'export.pkl')\nlearn_inf.predict('images/grizzly.jpg')\nlearn_inf.dls.vocab\n</code></pre>"},{"location":"KB/Fastai%20Interpretation/","title":"Fastai Interpretation","text":""},{"location":"KB/Fastai%20Interpretation/#fastai-interpretation","title":"Fastai Interpretation","text":""},{"location":"KB/Fastai%20Interpretation/#classification-interpretation","title":"Classification Interpretation","text":"<pre><code>interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\ninterp.plot_top_losses(5, nrows=1)\n</code></pre> <ul> <li>Ordered by loss</li> <li>If predicted correctly but still shown, then low confidence</li> </ul>"},{"location":"KB/Fastai%20Interpretation/#cleaner","title":"Cleaner","text":"<pre><code>cleaner = ImageClassifierCleaner(learn)\ncleaner\n\nfor idx in cleaner.delete(): cleaner.fns[idx].unlink()\nfor idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat)\n</code></pre>"},{"location":"KB/Fastai%20Interpretation/#get-all-classes-and-their-probabilities","title":"Get All Classes and Their Probabilities","text":"<pre><code>def classify_image(img):\n    pred,idx,probs = learn.predict(img)\n\nreturn dict(zip(categories, map(float,probs)))\n\nclassify_image(im)\n</code></pre>"},{"location":"KB/Fastai%20Tricks/","title":"Fasai Tricks","text":""},{"location":"KB/Fastai%20Tricks/#fasai-tricks","title":"Fasai Tricks","text":""},{"location":"KB/Fastai%20Tricks/#batched-map","title":"Batched Map","text":"<pre><code>tok_ds = ds.map(tok_func, batched=True)\n</code></pre>"},{"location":"KB/Fastai%20Tricks/#learning-rate-finder","title":"Learning Rate Finder","text":"<pre><code>learn.lr_find(suggest_funcs=(slide, valley))\n</code></pre>"},{"location":"KB/Fastai%20Tricks/#test-dataset","title":"Test Dataset","text":"<pre><code>tst_dl = learn.dls.test_dl(tst_df)\npreds,_ = learn.get_preds(dl=tst_dl)\n</code></pre>"},{"location":"KB/Fastai%20Tricks/#ensemble","title":"Ensemble","text":"<pre><code>def ensemble():\n    learn = tabular_learner(dls, metrics=accuracy, layers=[10,10])\n    with learn.no_bar(),learn.no_logging(): learn.fit(16, lr=0.03)\n    return learn.get_preds(dl=tst_dl)[0]\nlearns = [ensemble() for _ in range(5)]\n\nens_preds = torch.stack(learns).mean(0) # stack and mean\n</code></pre>"},{"location":"KB/Faster%20RCNN/","title":"Faster RCNN","text":""},{"location":"KB/Faster%20RCNN/#faster-rcnn","title":"Faster RCNN","text":"<ul> <li>Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</li> <li>SPNet</li> <li>Fast-RCNN + Region Proposal</li> <li>Attention is also used</li> <li>Vgg</li> <li>PASCAL VOC, ILSVRC, COCO</li> </ul>"},{"location":"KB/FeatMatch/","title":"FeatMatch","text":""},{"location":"KB/FeatMatch/#featmatch","title":"FeatMatch","text":"<ul> <li>novel learned feature-based refinement and augmentation method to produce a varied set of complex transformations </li> <li>utilize information from both within-class and across-class prototypical repre- sentations</li> </ul>"},{"location":"KB/Feature%20Augmentation/","title":"Feature Augmentation","text":""},{"location":"KB/Feature%20Augmentation/#feature-augmentation","title":"Feature Augmentation","text":"<ul> <li>Rather than conduct augmentation only in the input space, feature augmentation performs the transformation in a learned feature space </li> <li>[DeVries and Taylor, 2017a] </li> <li>when traversing along the manifold it is more likely to encounter realistic samples in feature space than compared to input space </li> <li>manipulating the vector representation of data within a learned feature space are investigated </li> <li>FeatMatch</li> <li>Moment Exchange</li> </ul>"},{"location":"KB/Feature%20Based%20Knowledge/","title":"Feature Based Knowledge","text":""},{"location":"KB/Feature%20Based%20Knowledge/#feature-based-knowledge","title":"Feature Based Knowledge","text":"<ul> <li>Huang and Wang (2017) using neuron selectivity trans- fer. Passalis and Tefas (2018) transferred knowledge by matching the probability distribution in feature space.</li> <li>Kim et al. (2018) introduced so called \u201cfactors\u201d as a more understandable form of intermediate repre- sentations. To reduce the performance gap between teacher and student, Jin et al. (2019) proposed route constrained hint learning, which supervises student by outputs of hint layers of teacher. Recently, Heo et al. (2019c) proposed to use the activation boundary of the hidden neurons for knowledge transfer. Interestingly, the parameter sharing of intermediate layers of the teacher model together with response-based knowledge is also used as the teacher knowledge (Zhou et al., 2018).</li> <li>To match the semantics between teacher and stu- dent, Chen et al. (2021) proposed cross-layer knowledge distillation, which adaptively assigns proper teacher layers for each student layer via attention allocation.</li> <li>Though feature-based knowledge transfer provides favorable information for the learning of the student model, how to effectively choose the hint layers from the teacher model and the guided layers from the student model remains to be further investigated (Romero et al., 2015).</li> <li>Distillation Schemes</li> <li>Teacher Student Architecture</li> <li>Distillation Algorithms</li> <li>Applications of Knowledge Distillation</li> <li>For example, on one hand, some recent works find that the student model can learn little from some teacher models due to the model capac- ity gap between the teacher model and the student model (Zhang et al., 2019b; Kang et al., 2020); On the other hand, from some early theoretical analysis on the capacity of neural networks, shallow networks are capable of learning the same representation as deep neural networks (Ba and Caruana, 2014).</li> </ul>"},{"location":"KB/Feature%20Correlationa/","title":"Feature Correlationa","text":""},{"location":"KB/Feature%20Correlationa/#feature-correlationa","title":"Feature Correlationa","text":"<ul> <li>If certain features in a dataset have a high correlation in a dataset, it becomes difficult to control specific features without changing the closely correlated ones.</li> <li>For example, let's say you have a dataset of \u00a0face images and want to add facial hair to an image of a woman, it's likely that you'll end up modifying more features as this feature is highly correlated with a male's face.</li> </ul>"},{"location":"KB/Feature%20Learning/","title":"Feature Learning","text":""},{"location":"KB/Feature%20Learning/#feature-learning","title":"Feature Learning","text":"<ul> <li>Dictionary Learning</li> <li>Methods for Feature Learning</li> <li>Contrastive Loss</li> <li>Max Margin Loss</li> <li>Triplet Loss</li> </ul>"},{"location":"KB/Feature%20Map%20Visualization/","title":"Feature Map Visualization","text":""},{"location":"KB/Feature%20Map%20Visualization/#feature-map-visualization","title":"Feature Map Visualization","text":"<ul> <li>Feature maps are visualized to show the attention of networks </li> <li>Larger activation represents the neural network pays more attention to the corresponding region in the imag </li> <li>eature maps are usually qualitatively visualized and compared with that of super- vised models [28], [36].</li> </ul>"},{"location":"KB/Feature%20Space%20Augmentation/","title":"Feature Space Augmentation","text":""},{"location":"KB/Feature%20Space%20Augmentation/#feature-space-augmentation","title":"Feature Space Augmentation","text":"<ul> <li>The sequential processing of neural networks can be manipulated such that the intermediate representations can be separated from the network as a whole. The lower-dimensional representations of image data in fully-connected layers can be extracted and isolated.</li> <li>DeVries and Taylor tested their feature space augmentation technique by extrapolating between the 3 nearest neighbors per sample to generate new data and compared their results against extrapolating in the input space and using affine transformations in the input space</li> <li>Vector representations are then found by training a CNN and then passing the training set through the truncated CNN. These vector representations can be used to train any machine learning model from Naive Bayes, Support Vector Machine, or back to a fully-connected multilayer network.</li> <li>A disadvantage of feature space augmentation is that it is very difficult to interpret the vector data.</li> </ul>"},{"location":"KB/Feature%20Spec/","title":"Feature Spec","text":""},{"location":"KB/Feature%20Spec/#feature-spec","title":"Feature Spec","text":"<ul> <li>Describes the information required to extract features data from the tf.Example protocol buffer. Because the tf.Example protocol buffer is just a container for data, you must specify the following<ul> <li>the data to extract (that is, the keys for the features)</li> <li>the data type (for example, float or int)</li> <li>The length (fixed or variable)</li> </ul> </li> </ul>"},{"location":"KB/Features/","title":"Features","text":""},{"location":"KB/Features/#features","title":"Features","text":""},{"location":"KB/Features/#dimensions","title":"Dimensions","text":""},{"location":"KB/Features/#wide","title":"Wide","text":"<ul> <li>Had to train</li> <li>More number of neurons</li> <li>Easy parallel</li> <li>Infinitely wide -&gt; Gaussian process</li> </ul>"},{"location":"KB/Features/#deep","title":"Deep","text":"<ul> <li>Easier to train</li> <li>Less data</li> <li>Linear amount</li> <li>Difficult to parallelize</li> </ul>"},{"location":"KB/Features/#why","title":"Why","text":"<ul> <li>Domain Adaptation</li> <li>Structure exploitation</li> <li>Relevant features</li> </ul>"},{"location":"KB/Features/#random-things","title":"Random Things","text":"<ul> <li>1 hidden layer Perceptron -&gt; Universal fn estimator</li> <li>Best generalization -&gt; First order optimization</li> </ul>"},{"location":"KB/Federated%20Learning/","title":"Federated Learning","text":""},{"location":"KB/Federated%20Learning/#federated-learning","title":"Federated Learning","text":"<ul> <li>Basics of Federated Learning</li> <li>Advantages of Federated Learning</li> <li>Federated Updates</li> </ul>"},{"location":"KB/Federated%20Learning/#refs","title":"Refs","text":"<ul> <li>OpenMined Blog</li> <li>Nvidia</li> <li>Unite.ai</li> <li>Google blog</li> <li>Wiki</li> <li>Digital health : Rieke, N., Hancox, J., Li, W. et al. The future of digital health with federated learning. npj Digit. Med. 3, 119 (2020). https://doi.org/10.1038/s41746-020-00323-1</li> <li>Gboard : Chen, M., Mathews, R., Ouyang, T., &amp; Beaufays, F. (2019). Federated learning of out-of-vocabulary words. arXiv preprint arXiv:1903.10635. Paper</li> <li>Chen, M., Mathews, R., Ouyang, T., &amp; Beaufays, F. (2019). Federated learning of out-of-vocabulary words. arXiv preprint arXiv:1903.10635.</li> </ul>"},{"location":"KB/Federated%20Updates/","title":"Federated Updates","text":""},{"location":"KB/Federated%20Updates/#federated-updates","title":"Federated Updates","text":"<ul> <li>Structured Update</li> <li>Sketched Update</li> </ul>"},{"location":"KB/Feedback%20Loop/","title":"Feedback Loop","text":""},{"location":"KB/Feedback%20Loop/#feedback-loop","title":"Feedback Loop","text":"<ul> <li>In machine learning, a situation in which a model's predictions influence the training data for the same model or another model. For example, a model that recommends movies will influence the movies that people see, which will then influence subsequent movie recommendation models.</li> </ul>"},{"location":"KB/Few%20Shot%20Order%20Sensitivity/","title":"Few Shot Order Sensitivity","text":""},{"location":"KB/Few%20Shot%20Order%20Sensitivity/#few-shot-order-sensitivity","title":"Few Shot Order Sensitivity","text":"<ul> <li>Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity</li> <li>When primed with only a handful of training samples, very large, pretrained language models such as GPT-3 have shown competitive results when compared to fully-supervised, fine-tuned, large, pretrained language models</li> <li>few-shot prompts suffer from order sensitivity</li> <li>for the same prompt the order in which samples are provided can make the difference between state-of-the-art and random performance \u2013 essentially some permutations are \u201cfantastic\u201d and some not</li> <li>problem is prevalent across tasks, model sizes (even for the largest current models), prompt templates, it is not related to a specific subset of samples, number of training samples, and that a given good permutation for one model is not transferable to another.</li> <li>novel probing method that exploits the generative nature of language models to construct an artificial development set</li> <li>identity performant permutations for prompts using entropy-based statistics over this set, which yields a 13% relative improvement for GPT-family models across eleven different established text classification tasks</li> </ul>"},{"location":"KB/Filter%20Bubble%20Problem/","title":"Filter Bubble Problem","text":""},{"location":"KB/Filter%20Bubble%20Problem/#filter-bubble-problem","title":"Filter Bubble Problem","text":"<ul> <li>Shows only things that you have seen before</li> </ul>"},{"location":"KB/Filter%20Wise%20Normalization/","title":"Filter Wise Normalization","text":""},{"location":"KB/Filter%20Wise%20Normalization/#filter-wise-normalization","title":"Filter Wise Normalization","text":"<ul> <li>Following up from Random Directions  $$ d_{i,j} \\leftarrow \\frac{d_{i,j}}{||d_{i,j}||}||\\theta_{i,j}|| $$<ul> <li>d is a random Gaussian Direction vector</li> <li>\\(d_{i,j}\\) is \\(j_{th}\\) filter of the \\(i_{th}\\) layer of the direction vector d</li> <li>\\(||\\cdot||\\) is the Frobenius norm</li> </ul> </li> <li></li> <li></li> </ul>"},{"location":"KB/Filtering/","title":"Filtering","text":""},{"location":"KB/Filtering/#filtering","title":"Filtering","text":"<ul> <li>Noise Suppression</li> </ul>"},{"location":"KB/Final%20Paper%20Language%20Modeling/","title":"Final Paper LM","text":""},{"location":"KB/Final%20Paper%20Language%20Modeling/#final-paper-lm","title":"Final Paper LM","text":""},{"location":"KB/Final%20Paper%20Language%20Modeling/#tips","title":"Tips","text":"<ul> <li>Identify a Research Question that links with previous research</li> <li>Identify a Method that will let you answer the research question, or at least partially</li> <li>Develop an experiment (or two) that would then test this research question</li> <li>Predict what the results will look like given current theory/theories     If your experiment tests the predictions of more than one theory then you should have one set of predictions for each theory  </li> <li>What are the consequences of certain results for our understanding of the phenomena studied?</li> <li>What should following research do given certain results?</li> <li>How will you analyze the results statistically? What methods, which tests, what does your data look like?</li> <li>So write a 2-3 page paper about an experiment that would answer an open question about quantification.</li> <li>This paper can be written as if you are proposing it (e.g. \"We would then test x children with \u2026.\" ) or you could write it as if you already did the experiment, imagining the results, e.g. \"We tested 30 Spanish speakers \u2026\".</li> <li>Give it the kind of toc: true title you would give to a paper. (Don't call it \"My Gedankenexperiment\" !;)).</li> <li>Give an introduction to the research area, summarize the results you already know, using references to relevant papers. This could be the background section. Explain what's still missing in our knowledge and how we should test it.</li> <li>In the methods section I need to know the details of the experimental design, including examples of sentences that will be tested and pictures that might be used (use clip art, or I also don't mind simple drawings. Don't worry if you are not very artistic!).</li> <li>Explain what kind of participants you will need to test, how many, and what features they need to have. Be realistic. Just because it's fantasy, you shouldn't propose testing 1000 children.</li> <li>Do you also want to do additional testing? (working memory, inhibition?) Make sure you motivate it.</li> </ul>"},{"location":"KB/Final%20Paper%20Language%20Modeling/#idea","title":"Idea.","text":"<ul> <li>Shortcuts to Quantifier Interpretation in Children and Adults But studies and comparisons were weird. Change?</li> <li>They were salty about This feature of their design provided children with unambiguous cues as to which set of entities was the focus of attention. : Crain and Thornton (1998)</li> <li>Crain et al.\u2019s (1996) claim that preschoolers have full competence with uni- versal quantifiers would seem to be undermined by the fact that even older school-age children make errors identifyi- 04:40 ng the domain of a universal quantifier.</li> <li></li> <li>Brooks and Braine (1996, Experiment 1) tested adults with actional scenes and found no errors. Their data, however, came from 10 undergraduates at a highly selective private university (Carnegie Mellon) and thus may not be representative of adults in general.</li> <li>Test same thing as Shorts. but different data</li> <li>Pictures</li> </ul>"},{"location":"KB/Final%20Paper%20Language%20Modeling/#abstract","title":"Abstract","text":"<ul> <li>Ostensive cues</li> <li>Locative bias</li> <li>Mouse tracking</li> </ul>"},{"location":"KB/Final%20Paper%20Language%20Modeling/#participants","title":"Participants","text":"<ul> <li>We recruited and tested twelve 5-year-olds (M = 5;5, range = 5;2\u20135;11), twelve 6-year-olds (M = 6;6, range = 6;2\u20136;10), twelve 7-yearolds (M = 7;6, range = 7;1\u20137;11), twelve 8-year-olds (M = 8;6, range = 8;0\u20138;11), and twelve 9-year-olds (M = 9;6, range = 9;1\u20139;11), twelve adults at private elementary schools and after-school programs in Atlanta, Georgia.</li> <li>adults from RUG, kiddos from some school</li> </ul>"},{"location":"KB/Final%20Paper%20Language%20Modeling/#procedure","title":"Procedure","text":"<ul> <li>single, 20-min session conducted in a quiet room of their school</li> <li>We showed children two pictures at a time and asked them to point to the picture that went best with a sentence read aloud</li> <li>After the child looked at both pictures, the experimenter read the corresponding sentence and asked the child to point to the picture that went best with the sentence.</li> <li>Same for adults (Contrary to this paper itself)</li> <li>the teddy thing was nice and cute too</li> </ul>"},{"location":"KB/Final%20Paper%20Language%20Modeling/#experimental-design","title":"Experimental Design","text":"<ul> <li>16 test items</li> <li>2x2 study (Picture: Collective vs. Distributive) and Sentence: (With marker (\"each\" or \"together\") or without)</li> <li>2 practice trials</li> <li>7 controls</li> <li>3 fillers</li> </ul>"},{"location":"KB/Final%20Paper%20Language%20Modeling/#what-do-we-expect","title":"What Do We Expect","text":"<ul> <li>Both children and adults make errors</li> <li>Only 9 y/o were consistent</li> <li>7 y/o : extra animals/objects vs containers</li> <li>Better performance :<ul> <li>Quantifier modifying the containers vs subject (Disprove Kang et al.)</li> <li>Children , Not Adults</li> </ul> </li> <li>Prefer locative scenes with all filled containers (Drozd et al.)<ul> <li>Children , Not Adults</li> </ul> </li> <li>The rate of rejection of the sentences as true descriptions of the visually represented situations significantly correlated with the type of the visual representation.</li> <li>The sentence\u2013 drawing pairs were rejected in 10.53% of the cases.</li> <li>n the case of the sentence\u2013photo pairs, the rate of rejection was a mere 3.51%.</li> <li>Just as in Pint\u00e9r's (2016) experiment, the rate of rejection (i.e., the rate of the exhaustive interpretation of the sentences) was slightly even higher in the adult control group: 13.33% in the case of sentence\u2013drawing pairs, and 8.88% in the case of sentence\u2013photo p</li> <li>Crucially, the photos contained many more extra agents and extra objects than the drawings, still they elicited significantly less rejections.</li> <li>What made the presence of extra objects in the drawings ostensive was the minimality of the drawings, suggesting that everything irrelevant had been eliminated from them.</li> <li>This suggests that the problem does not reside in the child's syntax, given the similarities in sentence structures used across studies, but in</li> <li>stead has to do with the difficulty of selecting the appropriate set of entities and avoiding distraction by salient objects.</li> <li>Taken together, the experiments suggest that it was the collective scenes as opposed to the use of all that improved children's performance in Experiment 1. Collective scenes were easier presumably because the group depiction aided the child in isolating one set of entities relative to the other</li> <li>We suspect that both children and adults make errors in comprehension because they engage in shallow processing that causes inaccurate mapping between syntactic and semantic representations.</li> <li>Shallow processing also provides a straightforward explanation of the errors made by adults in Experiment 3. Their high error rates suggest that adult listeners often do not tax their limited information-processing capacities by conducting exhaustive syntactic analyses of sentences but rather make use of simpler strategies in generating reasonable guesses</li> </ul>"},{"location":"KB/Final%20Paper%20Language%20Modeling/#literature","title":"Literature","text":"<ul> <li>Quantifier spreading children misled by ostensive cues</li> <li>Shortcuts to Quantifier Interpretation in Children and Adults</li> <li>A matter of ambiguity? Using eye movements to examine collective vs. distributive interpretations of plural sets</li> </ul>"},{"location":"KB/Final%20Paper%20Language%20Modeling/#experiment","title":"Experiment","text":"<ul> <li>Replace doodles with images , Use more</li> <li>Combine locative bias fix + old version of exp</li> <li>Mouse tracking</li> </ul>"},{"location":"KB/Final%20Paper%20Language%20Modeling/#sentences","title":"Sentences","text":"<ul> <li>Each of the (people) is (verb)ing an (object), for example, Each of the men is washing a bear.</li> <li>There is a (person) (verb)ing each of the (objects), for example, There is a man washing each of the bears.</li> <li>Every (person) is (verb)ing an (object), for example, Every man is washing a bear.</li> <li>There is a (person) (verb)ing every (object), for example, There is a man washing every bear.</li> <li>All of the (people) are (verb)ing an (object), for example, All of the men are washing a bear.</li> <li>There is a (person) (verb)ing all of the (objects), for example, There is a man washing all of the bears.</li> <li>All of the (objects) are in a (container), for example, All of the alligators are in a bathtub.</li> <li>All of the (containers) have an (object) in them, for example, All of the bathtubs have an alligator in them.</li> <li>There is an (object) in all of the (containers), for example, There is an alligator in all of the bathtubs.</li> <li>Each of the (objects) is in a (container), for example, Each of the alligators is in a bathtub.</li> <li>Each of the (containers) has an (object) in it, for example, Each of the bathtubs has an alligator in it.</li> <li>There is an (object) in each of the (containers), for example, There is an alligator in each of the bathtubs.</li> <li>Every (object) is in a (container), for example, Every alligator is in a bathtub.</li> <li>Every (container) has an (object) in it, for example, Every bathtub has an alligator in it.</li> <li>There is an (object) in every (container), for example, There is an alligator in every bathtub.</li> </ul>"},{"location":"KB/Final%20Paper%20User%20Models/","title":"Final Paper User Models","text":""},{"location":"KB/Final%20Paper%20User%20Models/#final-paper-user-models","title":"Final Paper User Models","text":""},{"location":"KB/Final%20Paper%20User%20Models/#literature","title":"Literature","text":"<ul> <li>van den Broek, G. S., Takashima, A., Segers, E., &amp; Verhoeven, L. (2018). Contextual richness and word learning: Context enhances comprehension but retrieval enhances retention. Language learning, 68(2), 546-585.</li> <li>Effects of Contextual Cues on Inferring and Remembering Meanings of New Word</li> <li>SlimStampen</li> <li>The Behavior of Tutoring Systems</li> <li>The Effect of Three Consecutive Context Sentences on EFL Vocabulary-Learning</li> <li>Second Language Vocabulary Learning , The role of context  versus translation</li> <li>Learning L2 German Vocabulary Through Reading</li> </ul>"},{"location":"KB/Final%20Paper%20User%20Models/#members","title":"Members","text":"<ul> <li>Hila Schwartz</li> <li>Juliette Bruin</li> <li>Isabelle Tilleman</li> <li>Subhaditya Mukherjee</li> </ul>"},{"location":"KB/Final%20Paper%20User%20Models/#concept","title":"Concept","text":"<ul> <li>Outlines the general concept of our system, meaning how we tried to adjust and improve the slimstampen system, and any additional improvements we made to the system.</li> </ul>"},{"location":"KB/Final%20Paper%20User%20Models/#main-idea","title":"Main Idea","text":"<ul> <li>The main idea we have for this project is to improve the SlimStampen system by presenting vocabulary in context. The way we would like to do this, is by presenting users with the word they need to learn in a sentence. As the learner gets better, the system will increase the difficulty by presenting words without context. If the words are presented out of context and the user makes a mistake, the correct answer will also be shown without context.</li> <li>An example of this would be as follows:</li> <li>Prompt: Wij kopen een huis</li> <li>Correct answer: to buy OR buy OR buying</li> <li>This idea is based on research by van den Broek et al. (2018), which showed that presenting novel words in context during the initial learning phase, and then reducing context later on improves long-term word retention. Next to that, Li (1988) found that learning words in context improves understanding of the word.</li> <li>Based on previous feedback, we have decided to have two contexts for each word. If a user gets a word wrong consistently, they will be shown a different context. This is based on the idea that they perhaps do not understand the first context they were provided with, and that perhaps the second context will provide them with the information they need to get the word correct. Unlike previously stated, this addition will not be tested in a separate condition. The only conditions we will test are no contexts at all and two contexts.</li> </ul>"},{"location":"KB/Final%20Paper%20User%20Models/#params","title":"Params","text":"<ul> <li>WORD_THRESHOLD = 0.29</li> <li>CONTEXT2_THRESHOLD = 0.35</li> <li>DEFAULT_ALPHA = 0.3</li> </ul>"},{"location":"KB/Final%20Paper%20User%20Models/#fact","title":"Fact","text":"<pre><code>Fact(fact_id = 6,\u00a0\n\u00a0question = 'gemiddeld',\u00a0\n\u00a0context_1 = \"Deze opleiding heeft 'gemiddeld' \u2026\",\u00a0\n\u00a0context_2 = \"De temperatuur is 'gemiddeld' \u2026\",\u00a0\n\u00a0answer = 'average',\u00a0\n\u00a0chosen_context = \"Deze opleiding heeft 'gemiddeld' \u2026\",\n\u00a0encounter_2 = True)\n</code></pre>"},{"location":"KB/Final%20Paper%20User%20Models/#additional-improvements","title":"Additional Improvements","text":"<ul> <li>We added a few things to the system of which we will not test the effects:</li> </ul>"},{"location":"KB/Final%20Paper%20User%20Models/#1-ui-improvements","title":"1 UI Improvements","text":"<ul> <li>The UI was updated for a cleaner look and feel, as well as to improve readability for dyslexic participants.</li> </ul>"},{"location":"KB/Final%20Paper%20User%20Models/#2-gamification","title":"2 Gamification","text":"<ul> <li>We have decided to add a few small gamification elements. One of those is that through the use of colors (green/red). Another is displaying a score which shows how many answers you got correct out of the total number of trials you have done so far.</li> </ul>"},{"location":"KB/Final%20Paper%20User%20Models/#3-multiple-translations","title":"3 Multiple Translations","text":"<ul> <li>For some of the words, we added multiple correct answers. This means that multiple different answers can be counted as correct. This is especially useful for verbs, since there are different ways to translate those which do not really change the meaning of the words. An example of this is the word vergeten, which can be translated to forget, to forget, and forgot. Out-of-context, all three of these meanings make sense. Having multiple options be marked as correct also helped with gathering context sentences, since you are not as restricted to one specific use of the word.</li> </ul>"},{"location":"KB/Final%20Paper%20User%20Models/#system","title":"System","text":"<ul> <li>Explains how the system itself works, meaning how it switches between words and context, and how it decided which word to show next.</li> </ul>"},{"location":"KB/Final%20Paper%20User%20Models/#word-order","title":"Word Order","text":"<ul> <li>Similarly to the set-up of slimstampen, we let the system decide which words to show and how based on rate of forgetting. What we changed is that we have different thresholds for when it shows the context, which context it shows, and when it shows just the word.</li> <li>Once it enters the second context, it will not go back to the first. This is based on the assumption that the first context did not help the participant figure out the meaning of the word. Thresholds were decided through trial-and-error, based on what felt like a natural progression of conditions.</li> <li>In the original system, the same word (and in this case also context) was shown thrice without changing at all based on input. We changed that to twice in our system.</li> </ul>"},{"location":"KB/Final%20Paper%20User%20Models/#testing","title":"Testing","text":"<ul> <li>Explains how we aim to test the system, including each of the conditions and the full experimental procedure.</li> </ul>"},{"location":"KB/Final%20Paper%20User%20Models/#stimuli-and-design","title":"Stimuli and Design","text":"<ul> <li>To test whether the improvements we made to the SlimStampen system have an effect on word retrieval, we want to do a within-participant study. For each condition, we will vary whether words are presented in a sentence, and how many sentences are available. The independent variables in this study are accuracy and response time. The dependent variable is number of contexts available.</li> </ul>"},{"location":"KB/Final%20Paper%20User%20Models/#conditions","title":"Conditions","text":"<ul> <li>We are planning to have two conditions:</li> <li>Baseline condition: In this condition, participants are only shown words without context.</li> <li>Two-context condition: In this condition, participants will be presented with words in-context as well as out of context. If participants repeatedly give the wrong answer when an item is shown in-context, they will be shown a different context.</li> </ul>"},{"location":"KB/Final%20Paper%20User%20Models/#components","title":"Components","text":"<ul> <li>The experiment consists of different components:</li> <li>Questionnaire: This will ask the participants for some basic info: age, their native language, and their previous experience with learning Dutch.</li> <li>Level Evaluation: Participants will be shown 20 Dutch words and will be asked to translate them to English. We can use this data to compare the Dutch level of each participant, in case we see some weird results. The words were chosen by taking vocabulary from different levels of Dutch (a1-b2).</li> <li>Training: Participants will try to learn new Dutch words using our adapted SlimStampen system. This is where the conditions come into play. This segment lasts either 150 trials or until they have seen all words.</li> <li>Distractor: A small dot-counting task that functions as a distractor task. Participants need to do this 10 times between training and testing. The number of blue dots that are shown is between 10 and 20.</li> <li>Test: Participants will be tested on the words learned during training using a simple translation task. In this test, they are only presented with words that they saw during training. They immediately receive feedback on how they did.</li> <li>Break: Participants will be asked to take a small break between testing and starting the training in a new condition.</li> <li>We will present each participant with the same two word/context lists, but they will be randomized over the conditions. The order of the conditions will also be randomized.</li> </ul>"},{"location":"KB/Final%20Paper%20User%20Models/#procedure","title":"Procedure","text":"<ul> <li>The experiment will be performed on our personal laptops using OpenSesame in a quiet place. Participants will be presented with a small introduction to the experiment. Then, they will answer a small questionnaire about their Dutch level. After that, they will do a small Dutch test. All participants will be asked to do the same Dutch test. The words in this test will not be used in any of the conditions. This test will provide a frame of reference for each participant's Dutch level, in case we see unexpected results. After the test, there is a small break.</li> <li>Next, participants will be asked to practice a word list in one of the two conditions. This finishes after 150 trials or after a participant has seen all of the words. Next, participants will do a small distractor test. In this distractor test, they are asked to count dots. They need to do this 10 times. Then, we will test their word retrieval with a simple single-word translation test. After this, participants are asked to take a small break. This process is repeated a total of 2 times, once for each of the conditions.</li> <li>After each participant has done each of the two conditions, we will end the experiment by thanking them for their efforts.</li> </ul>"},{"location":"KB/Final%20Paper%20User%20Models/#results","title":"Results","text":"<ul> <li>Not significant ):</li> <li>Not effective for all learners\u00a0</li> <li>Short time frame</li> <li>Effect : Using words in sentences vs Retrieval (Prince, 1996)</li> </ul>"},{"location":"KB/Final%20Paper%20User%20Models/#limitations","title":"Limitations","text":"<ul> <li>Very small participant pool</li> <li>Variation in participant backgrounds</li> <li>Ceiling effect</li> <li>No external motivation to do well</li> <li>Not enough attention to the context</li> </ul>"},{"location":"KB/Final%20Paper%20User%20Models/#future-directions","title":"Future Directions","text":"<ul> <li>Additional focus on gamification</li> <li>Longer term studies (Like SlimStampen)</li> <li>Harder words : Ceiling Effect</li> <li>More informed context in sentences (van den Broek et al., 2018)\u00a0</li> <li>Other ways of testing context</li> <li>Investigate thresholds</li> </ul>"},{"location":"KB/Final%20Paper%20User%20Models/#pictures","title":"Pictures","text":""},{"location":"KB/Fine%20Grained%20assesment/","title":"Fine Grained assesment","text":""},{"location":"KB/Fine%20Grained%20assesment/#fine-grained-assesment","title":"Fine Grained Assesment","text":""},{"location":"KB/Fine%20Grained%20assesment/#counting-learning-events","title":"Counting Learning Events","text":"<ul> <li>We also assumed that a step is the product of one or more learning events, and defined a Learning Event to be a mental event based on a Knowledge Component. Learning events and knowledge components are not directly observable, but steps are.</li> <li>Mastery really means the probability that a Knowledge Component will be applied when it should be applied. If the student's competence was frozen instead of constantly changing due to learning and forgetting, then mastery could be estimated by counting the number of times a Knowledge Component was applied and dividing by the number of times it should have been applied. Thus, we need to discuss three issues: (1) How to detect applications of a Knowledge Component, (2) how to detect times when a Knowledge Component should have been applied, and (3) how to adjust for instruction, learning and forgetting.</li> </ul>"},{"location":"KB/Fine%20Grained%20assesment/#counting-failures","title":"Counting Failures","text":"<ul> <li>Counting only the successful applications of a Knowledge Component is not enough; we need to know how many times the student failed to apply it as well.</li> <li>One approach is to detect failed attempts at steps. Suppose for simplicity that there is a one-to-one correspondence between a step and a Learning Event</li> <li>If the student fails to make the step, then the student must lack the knowledge that underlies the Learning Event.</li> </ul>"},{"location":"KB/Fine%20Tuning%20Based%20Pruning/","title":"Fine Tuning Based Pruning","text":""},{"location":"KB/Fine%20Tuning%20Based%20Pruning/#fine-tuning-based-pruning","title":"Fine Tuning Based Pruning","text":"<ul> <li>Some store weights before Pruning and use that to continue training.</li> <li>Others somehow try to rewind to a previous state and reinitialize the network entirely</li> </ul>"},{"location":"KB/Fine%20grained%20datasets/","title":"Fine grained datasets","text":""},{"location":"KB/Fine%20grained%20datasets/#fine-grained-datasets","title":"Fine Grained Datasets","text":"<ul> <li>CUB-200-2011</li> <li>Stanford Dogs</li> <li>FGVC Aircraft</li> <li>FGVCx</li> <li>iNaturalist</li> <li>PlantCLEF</li> </ul>"},{"location":"KB/Fine-grained%20Object%20Recognition/","title":"Fine-grained Object Recognition","text":""},{"location":"KB/Fine-grained%20Object%20Recognition/#fine-grained-object-recognition","title":"Fine-grained Object Recognition","text":"<ul> <li>An object can be represented by:</li> <li>a shared (generic) dictionary, which is used to describe the content of all categories (basic-level)</li> <li>and a set of category-specific dictionaries for highlighting the small diversity within the different categories (fine-grained )</li> <li></li> </ul>"},{"location":"KB/Finite%20Differences/","title":"Finite Differences","text":""},{"location":"KB/Finite%20Differences/#finite-differences","title":"Finite Differences","text":"<ul> <li> \\[f'(x) = \\frac{df}{dx} \\rightarrow \\frac{\\Delta f}{\\Delta x}\\] </li> <li></li> <li>Forward differences \\(\\(f'(x) = \\frac{f(x_{i+1})-f(x_{i})}{\\Delta x}\\)\\)</li> <li>Non Isotropic</li> <li>Backward differences \\(\\(f'(x) = \\frac{f(x_{i})-f(x_{i-1})}{\\Delta x}\\)\\)</li> <li>Non Isotropic</li> <li>Central differences \\(\\(f'(x) = \\frac{f(x_{i+1})-f(x_{i-1})}{2\\Delta x}\\)\\)</li> <li>High pass filter</li> <li>Non isotropic</li> </ul>"},{"location":"KB/First%20order%20generalization/","title":"First order generalization","text":""},{"location":"KB/First%20order%20generalization/#first-order-generalization","title":"First Order Generalization","text":"<ul> <li>Present model with an example, ask it to choose which of three objects most likely of the same category</li> </ul>"},{"location":"KB/First%20order%20integration/","title":"First order integration","text":""},{"location":"KB/First%20order%20integration/#first-order-integration","title":"First Order Integration","text":"<ul> <li> \\[x(t+ \\Delta t) = x(t)+ \\Delta t f(x,t)\\] </li> <li>Global error proportional to \\(\\Delta t\\)</li> <li>Not stable</li> <li></li> <li></li> </ul>"},{"location":"KB/Fisher%20Spanish-English/","title":"Fisher Spanish-English","text":""},{"location":"KB/Fisher%20Spanish-English/#fisher-spanish-english","title":"Fisher Spanish-English","text":""},{"location":"KB/Fitting/","title":"Fitting","text":""},{"location":"KB/Fitting/#fitting","title":"Fitting","text":"<ul> <li>Bayes risk<ul> <li>Minimal expected risk over set of all functions \\(\\(R_B = min_{f\\in y^X} R(f)\\)\\)</li> <li>If minimized -&gt; Best possible function</li> <li>Capacity of hypothesis space \\(\\mathcal{H}\\)</li> <li>It is essentally all possible things. In reg, all possible affine linear fns. In neural networks, all possible specific connection structure.<ul> <li>If low, \\(\\(\\mathscr{F} = R(f) - R_B\\)\\) is large : Underfitting (Huge difference between best risk and current risk)</li> <li>If high, \\(\\(\\mathscr{F} = R(f) - R_B\\)\\) is small : Overfitting (Tiny difference between best risk and current risk)</li> </ul> </li> </ul> </li> </ul>"},{"location":"KB/Fixed%20Factorization%20Attention/","title":"Fixed Factorization Attention","text":""},{"location":"KB/Fixed%20Factorization%20Attention/#fixed-factorization-attention","title":"Fixed Factorization Attention","text":"<ul> <li>paper</li> <li>Specific cells summarize previous locations and propagate to all future cells.</li> <li>Part of Sparse Transformer</li> <li>Fixed attention pattern with c = 1 limits expressivity</li> <li>many representations in the network are only used for one block whereas a small number of locations are used by all blocks.</li> <li>Choosing $c \\in 8, 16, 32</li> <li>when using multiple heads, having them attend to distinct subblocks of length \\(c\\) within the block of size \\(l\\) was preferable to having them attend to the same subblock</li> <li></li> </ul>"},{"location":"KB/Fixed%20Factors/","title":"Fixed Factors","text":""},{"location":"KB/Fixed%20Factors/#fixed-factors","title":"Fixed Factors","text":"<ul> <li>Another term: independent variables</li> <li>This is a \"Between subjects ANOVA\"</li> <li>participants go in the same directions\u2026</li> <li>BUT, because item is also a random factor, we have to check that too</li> <li>This is a \"Between items ANOVA\"</li> <li>Check that for each item, what's the difference between the conditions, and check if they go in the same direction.</li> </ul>"},{"location":"KB/Flamingo/","title":"Flamingo","text":""},{"location":"KB/Flamingo/#flamingo","title":"Flamingo","text":"<ul> <li>Flamingo: a Visual Language Model for Few-Shot Learning</li> <li>large-scale pre-training followed by task-specific fine-tuning has emerged as a standard approach, but the fine-tuning step still requires a lot of samples.</li> <li>building models that can be rapidly adapted to numerous tasks using only a handful of annotated examples is an open challenge for multimodal machine learning research</li> <li>family of Visual Language Models (VLM) which seek to train a multi-modal model (i.e., with the ability to understand different types of input \u2013 visual, audio, text etc.) in a few-shot learning approach (which refers to the ability to learn a new task with just a few samples for training).</li> <li>bridge powerful pretrained vision-only and language-only models</li> <li>handle sequences of arbitrarily interleaved visual and textual data</li> <li>seamlessly ingest images or videos as inputs</li> <li>Interleave cross-attention layers with language-only self-attention layers (frozen).</li> <li>Perceiver-based architecture that transforms the input sequence data (videos) into a fixed number of visual token</li> <li>Large-scale (web) multi-modal data by scraping webpages which has inter-leaved text and images</li> <li>Flamingo models can be trained on large-scale multimodal web corpora containing arbitrarily interleaved text and images, which is key to endow them with in-context few-shot learning capabilities</li> </ul> <p>toc: true title: Flamingo categories: ['architecture']</p>"},{"location":"KB/Flamingo/#flamingo_1","title":"Flamingo","text":"<ul> <li>A Visual Language Model created by Deepmind using few shot learning on a wide range of open-ended vision and language tasks, simply by being prompted with a few input/output examples</li> <li>the input of Flamingo contains visually conditioned autoregressive text generation models able to ingest a sequence of text tokens interleaved with images and/or videos</li> <li>and produce text as output</li> <li>A query is made to the model along with a photo or a video and the model answers with a text answer</li> <li>Flamingo models take advantage of two complementary models: a vision model that analyzes visual scenes and a large language model which performs a basic form of reasoning</li> <li>The language model is trained on a large amount of text data.</li> </ul>"},{"location":"KB/Flickr30K/","title":"Flickr30K","text":""},{"location":"KB/Flickr30K/#flickr30k","title":"Flickr30K","text":""},{"location":"KB/Flipping/","title":"Flipping","text":""},{"location":"KB/Flipping/#flipping","title":"Flipping","text":"<ul> <li>Horizontal axis flipping is much more common than flipping the vertical axis.</li> <li>On datasets involving text recognition such as MNIST or SVHN, this is not a label-preserving transformation.</li> </ul>"},{"location":"KB/FlowNet/","title":"FlowNet","text":"<ul> <li>FlowNet <ul> <li>end-to-end convolution neural network for optical flow estimation from two consecutive frames [151], [152] </li> <li>ConvNet needs to capture appearance changes of two frames </li> <li>self-supervised feature learning </li> <li>automatically generated by simulators such as game engines or by hard-code programs without human annotation.</li> </ul> </li> </ul>"},{"location":"KB/Flynn%27s%20Taxonomy/","title":"Flynn's Taxonomy","text":""},{"location":"KB/Flynn%27s%20Taxonomy/#flynns-taxonomy","title":"Flynn's Taxonomy","text":"<ul> <li>Classify multi processor architectures</li> <li>SISD</li> <li>SIMD</li> <li>MISD</li> <li>MIMD</li> </ul>"},{"location":"KB/Fmix/","title":"Fmix","text":""},{"location":"KB/Fmix/#fmix","title":"Fmix","text":"<ul> <li>random binary masks obtained by applying a threshold to low-frequency images sampled from Fourier space. Fmix can take on a wide range of shapes of random masks and can improve performance over Mixup and CutMix</li> </ul>"},{"location":"KB/Focal%20Loss/","title":"Focal Loss","text":""},{"location":"KB/Focal%20Loss/#focal-loss","title":"Focal Loss","text":"<ul> <li>two-stage approach popularized by R-CNN, where a classifier is applied to a sparse set of candidate object locations.</li> <li>In contrast, one-stage detectors that are applied over a regular, dense sampling of possible object locations have the potential to be faster and simpler, but have trailed the accuracy of two-stage detectors thus far.</li> <li>Extreme foreground-background class imbalance encountered during training of dense detectors is the central cause</li> <li>modulating term to Cross Entropy in order to focus learning on hard misclassified examples</li> <li>scaling factor decays to zero as confidence in the correct class increases</li> <li>training on a sparse set of hard examples and prevents the vast number of easy negatives from overwhelming the detector during training</li> <li>RetinaNet</li> </ul>"},{"location":"KB/Foley/","title":"Foley","text":""},{"location":"KB/Foley/#foley","title":"Foley","text":"<ul> <li>A catheter inserted into the bladder to help with urinary drainage</li> </ul>"},{"location":"KB/Force%20Directed%20Graph%20Layout/","title":"Force Directed Graph Layout","text":""},{"location":"KB/Force%20Directed%20Graph%20Layout/#force-directed-graph-layout","title":"Force Directed Graph Layout","text":"<ul> <li>Model a graph as rings and springs</li> <li>Attractive forces between adjacent nodes</li> <li>edges are modeled as springs with uniform length</li> <li>Repulsive forces between non-adjacent nodes could be seen as springs of infinite length or repelling forces of electrically charged metal spheres</li> <li></li> </ul>"},{"location":"KB/Force/","title":"Force","text":""},{"location":"KB/Force/#force","title":"Force","text":"<ul> <li>\"The vector sum of the external forces F on an object is equal to the mass m of that object multiplied by the acceleration vector of the object.\"</li> <li> \\[\\Sigma F = ma\\] </li> <li>mass times Acceleration</li> </ul>"},{"location":"KB/Forceps/","title":"Forceps","text":""},{"location":"KB/Forceps/#forceps","title":"Forceps","text":"<ul> <li>A hinged instrument, like scissors, used to grasp and hold objects</li> </ul>"},{"location":"KB/Forgetting/","title":"Forgetting","text":""},{"location":"KB/Forgetting/#forgetting","title":"Forgetting","text":"<ul> <li>If our memories are too precise and overfitted, then we can't actually use them to make predictions about future situations</li> <li>Forgetting is an essential component of adaptive system</li> <li>Simple memories that store the gist of our experiences and avoid complicated details will be better for generalizing to future events.</li> <li>orgetting has been regarded as a passive decay over time of the information stored in the memory.</li> </ul>"},{"location":"KB/Forgetting/#passive-forgetting","title":"Passive Forgetting","text":"<ul> <li>Concepts stored in the memory can be forgotten \"passively\" based on: Decay over time (fading factor)</li> <li>Loss of context cue</li> <li>Retrieval interference</li> </ul>"},{"location":"KB/Forgetting/#active-forgetting","title":"Active Forgetting","text":"<ul> <li>may be more potent at erasing memory than the passive forgetting mechanisms Motivated forgetting</li> <li>forgetting is often more intentional</li> <li>unpleasant memories (categories) Intrinsic forgetting</li> <li>redundant data Interference-based forgetting samples that cause interference</li> </ul>"},{"location":"KB/Forward%20Backward%20Matching/","title":"Forward Backward Matching","text":""},{"location":"KB/Forward%20Backward%20Matching/#forward-backward-matching","title":"Forward Backward Matching","text":"<ul> <li>Matching proceeds from the end of the string of characters</li> <li>Results are compared</li> <li>Optimised Segmentation occurs</li> <li>Language-specific heuristics are used later</li> </ul>"},{"location":"KB/Forward%20Kinematic%20Solution/","title":"Forward Kinematic Solution","text":""},{"location":"KB/Forward%20Kinematic%20Solution/#forward-kinematic-solution","title":"Forward Kinematic Solution","text":"<ul> <li>The calculation required to find the endpoint position, given the joint positions. For most robot topologies this is easier than finding the inverse kinematic solution.</li> </ul>"},{"location":"KB/Forward%20Kinematics/","title":"Forward Kinematics","text":""},{"location":"KB/Forward%20Kinematics/#forward-kinematics","title":"Forward Kinematics","text":"<ul> <li>Computational procedures which determine where the end-effector of a robot is located in space. The procedures use mathematical algorithms along with joint sensors to determine its location.</li> <li> <ol> <li>For a robot with n joints, what is the endeffector pose (\u03be ), given the joint angles (q)</li> <li>\u03be = \u03ba(q) : q = {qi,i \u2208 [1,\u2026,n]},</li> </ol> </li> </ul>"},{"location":"KB/Fractional%20Anisotropy/","title":"Fractional Anisotropy","text":""},{"location":"KB/Fractional%20Anisotropy/#fractional-anisotropy","title":"Fractional Anisotropy","text":"<ul> <li> \\[FA = \\sqrt{\\frac{3}{2}}\\frac{\\sqrt{\\Sigma_{i=1}^{3}(\\lambda_{1}-\\mu)^{2}}}{\\Sigma_{i=1}^{3}\\lambda_{i}^{2}}\\] </li> <li></li> </ul>"},{"location":"KB/Fracture/","title":"Fracture","text":""},{"location":"KB/Fracture/#fracture","title":"Fracture","text":"<ul> <li>A cracked or broken bone</li> </ul>"},{"location":"KB/Free%20Semantic%20Label-based%20Method/","title":"Free Semantic Label-based Method","text":""},{"location":"KB/Free%20Semantic%20Label-based%20Method/#free-semantic-label-based-method","title":"Free Semantic Label-based Method","text":"<ul> <li>automatically generated semantic labels </li> <li>The labels are generated by traditional hardcode algorithms </li> <li>game engines </li> <li>moving object segmentation </li> <li>contour detection </li> <li>relative depth prediction</li> </ul>"},{"location":"KB/Free%20morpheme/","title":"Free morpheme","text":""},{"location":"KB/Free%20morpheme/#free-morpheme","title":"Free Morpheme","text":"<ul> <li>can appear as a word by itself, often combined with other morphemes too.</li> <li>e.g., house (houses) , walk (walked ) of ,or,the</li> </ul>"},{"location":"KB/Freedom/","title":"Freedom","text":""},{"location":"KB/Freedom/#freedom","title":"Freedom","text":"<ul> <li>(N, D, P) N samples, D degrees of freedom</li> <li>If N&lt;D , then ill posed</li> <li>Need N &gt;&gt; D</li> <li>If P learnable params , \\(\\(P&lt;N\\)\\) : underspecified</li> <li>If \\(\\(P &gt;&gt; N\\)\\) : overparameterized</li> <li>No of params not a good indicator of overfitting</li> <li>Solution : Regularization</li> </ul>"},{"location":"KB/Frequentist/","title":"Frequentist","text":""},{"location":"KB/Frequentist/#frequentist","title":"Frequentist","text":"<ul> <li>Measure probablity -&gt; Counting</li> <li>Repeat an experiment n times and get the estimate : \\(\\hat P\\) (estimate based on finite amount of data)</li> <li>Law of large numbers</li> <li>Random variable X which takes values in a sample space S.</li> <li>Measurement process hard to carry out in reality</li> <li>What does unbiased means? Especially because most things related to future input that we do not have yet</li> <li>Distibution of data points</li> <li>MLE</li> </ul>"},{"location":"KB/Friction/","title":"Friction","text":""},{"location":"KB/Friction/#friction","title":"Friction","text":"<ul> <li>Friction scales linearly with the normal force.</li> <li>Friction is not affected by the area of contact between surfaces.</li> <li>Stationary objects have more friction than sliding objects.</li> <li>Sliding friction is not affected by sliding velocity.</li> <li>You can look up the magnitude of friction for each pair of materials</li> <li>Static Friction</li> <li>Kinetic Friction</li> </ul>"},{"location":"KB/Frobenius%20norm/","title":"Frobenius norm","text":""},{"location":"KB/Frobenius%20norm/#frobenius-norm","title":"Frobenius Norm","text":"<ul> <li>The Frobenius norm, sometimes also called the Euclidean norm </li> <li>Lp Regularization</li> <li>When\u00a0p\u00a0=\u00a0q\u00a0= 2\u00a0for the\u00a0\\(L_{p,q}norm\\), it is called the\u00a0Frobenius norm\u00a0or the\u00a0Hilbert\u2013Schmidt norm, though the latter term is used more frequently in the context of operators on (possibly infinite-dimensional)\u00a0Hilbert space. $$ { |A|{\\text{F}}={\\sqrt {\\sum {i}^{m}\\sum {j}^{n}|a{ij}|^{2}}}={\\sqrt {\\operatorname {trace} \\left(A^{*}A\\right)}}={\\sqrt {\\sum {i=1}^{\\min{m,n}}\\sigma {i}^{2}(A)}},} $$</li> <li>where \\({ \\sigma _{i}(A)}\\) are the singular values of A</li> </ul>"},{"location":"KB/Front%20to%20Back%20Raycasting/","title":"Front to Back Raycasting","text":""},{"location":"KB/Front%20to%20Back%20Raycasting/#front-to-back-raycasting","title":"Front to Back Raycasting","text":"<ul> <li>Color Compositing</li> </ul>"},{"location":"KB/Frontal%20Operculum/","title":"Frontal Operculum","text":""},{"location":"KB/Frontal%20Operculum/#frontal-operculum","title":"Frontal Operculum","text":"<ul> <li>The part of the frontal lobe that sits over the insula.</li> </ul>"},{"location":"KB/Frontal%20lobe/","title":"Frontal lobe","text":""},{"location":"KB/Frontal%20lobe/#frontal-lobe","title":"Frontal Lobe","text":"<ul> <li>Personality, behavior, emotions</li> <li>Judgment, planning, problem solving</li> <li>Speech: speaking and writing (Brocas Area)</li> <li>Body movement (motor strip)</li> <li>Intelligence, concentration, self awareness</li> </ul>"},{"location":"KB/Function%20words/","title":"Function words","text":""},{"location":"KB/Function%20words/#function-words","title":"Function Words","text":"<ul> <li>Glues words and phrases together</li> <li>Determiners</li> <li>Quantifiers</li> <li>Prepositions</li> <li>Connectives</li> </ul>"},{"location":"KB/Functional%20Connectivity/","title":"Functional Connectivity","text":""},{"location":"KB/Functional%20Connectivity/#functional-connectivity","title":"Functional Connectivity","text":""},{"location":"KB/Functional%20Connectivity/#symmetric","title":"Symmetric","text":"<ul> <li>BrainWave Synchronization</li> <li>BrainWave Coherence</li> <li>BrainWave CrossFrequency Coupling</li> </ul>"},{"location":"KB/Functional%20Connectivity/#directedasymmetric","title":"Directed/Asymmetric","text":"<ul> <li>Granger Causallity</li> </ul>"},{"location":"KB/Functional%20Morpheme/","title":"Functional Morpheme","text":""},{"location":"KB/Functional%20Morpheme/#functional-morpheme","title":"Functional Morpheme","text":"<ul> <li>provides grammatical information</li> <li>e.g. s (plural ) third person singular</li> </ul>"},{"location":"KB/Functional%20correlates/","title":"Functional correlates","text":"<p>toc: true title: Functional correlates</p> <p>categories: ['temp']</p>"},{"location":"KB/Functional%20correlates/#functional-correlates","title":"Functional Correlates","text":"<ul> <li>Dimensionality Reduction technique used to quantify the Correlation and dependence between two variables when the data is functional</li> <li>Relations between the surface and phenomena that influence or are influenced by the topography.</li> </ul>"},{"location":"KB/Fundamentals/","title":"Fundamentals","text":""},{"location":"KB/Fundamentals/#fundamentals","title":"Fundamentals","text":"<ul> <li>Emperical Risk</li> <li>LinearRegression</li> <li>TemporalLearning</li> <li>Dimensionality Reduction</li> <li>Unsupervised Learning</li> <li>Semi Supervised</li> <li>Self Supervised</li> <li>Encodings</li> <li>Probability</li> <li>Universal Approximation Theorem</li> <li>Sampling</li> <li>Distributions</li> </ul>"},{"location":"KB/GAM/","title":"GAM","text":""},{"location":"KB/GAM/#gam","title":"GAM","text":"<ul> <li>Early explaining systems for ML black boxes go back to 1986 with Generalized Additive Models (GAM)</li> <li>GAMs are global statistic models that use smooth functions, which are estimated using a scatterplot smoother</li> <li>The technique is applicable to any likelihood-based regression model, provides a flexible method for identifying nonlinear covariate effects in exponential family models and other likelihood-based regression models, and has the advantage of being completely automatic</li> <li>In its most general form, the algorithm can be applied to any situation in which a criterion is optimized involving one or more smooth functions</li> </ul>"},{"location":"KB/GAN%20Z%20Space/","title":"GAN Z Space","text":""},{"location":"KB/GAN%20Z%20Space/#gan-z-space","title":"GAN Z Space","text":""},{"location":"KB/GAN%20Z%20Space/#vector-algebra-in-z-space","title":"Vector Algebra in Z-Space","text":"<ul> <li>Controllable generation is somewhat similar to interpolation.</li> <li>With interpolation, you get intermediate examples between two generated observations.</li> <li>These intermediate examples between to two targets by manipulating the inputs from Z-space, which is the same idea behind controllable generation.</li> <li>In order to get intermediate values between two images, for example, you can make an interpolation between their two input vectors v1 and v2 in the Z-space.</li> <li>Controllable generation also uses changes in Z-space and makes use of how adjustments to the noise vector are reflected in the output from the generator.</li> <li>Differences in the features generated, for example different hair colors, occur due to changes in the direction that you have to move in Z-space to modify the features of the image.</li> <li>If image output of \\(g(v_{1})\\) , new controlled output with \\(g(v_{1}+d)\\)</li> </ul>"},{"location":"KB/GAN%E2%80%90based%20Data%20Augmentation/","title":"GAN\u2010based Data Augmentation","text":""},{"location":"KB/GAN%E2%80%90based%20Data%20Augmentation/#ganbased-data-augmentation","title":"GAN\u2010based Data Augmentation","text":"<ul> <li>Bowles et al. describe GANs as a way to 'unlock' additional information from a dataset</li> <li>Another useful strategy for generative modeling worth mentioning is variational auto-encoders. The GAN framework can be extended to improve the quality of samples produced with variational auto-encoders</li> <li>Using CycleGANs to translate images from the other 7 classes into the minority classes was very effective in improving the performance of the CNN model on emotion recognition.</li> <li>As exciting as the potential of GANs is, it is very difficult to get high-resolution outputs from the current cutting-edge architectures. Increasing the output size of the images produced by the generator will likely cause training instability and non-convergence</li> </ul>"},{"location":"KB/GAU/","title":"GAU","text":""},{"location":"KB/GAU/#gau","title":"GAU","text":"<ul> <li>gated attention unit; a generalization of GLU - gated linear unit</li> <li>allows for better and more efficient approximation of multi-head attention than many other efficient attention methods by using a weaker single-head attention with minimal quality loss</li> </ul>"},{"location":"KB/GE2E/","title":"GE2E","text":""},{"location":"KB/GE2E/#ge2e","title":"GE2E","text":"<ul> <li>Generalized End-to-end Loss for Speaker Verification</li> <li>new loss function</li> <li>training of speaker verification models more efficient</li> <li>Unlike TE2E, the GE2E loss function updates the network in a way that emphasizes examples that are difficult to verify at each step of the training process</li> <li>pushes the embedding towards the [centroid] of the true speaker, and away from the centroid of the most similar different speaker</li> <li>does not require an initial stage of example selection</li> <li>MultiReader technique</li> </ul>"},{"location":"KB/GELU/","title":"GELU","text":""},{"location":"KB/GELU/#gelu","title":"GELU","text":"<ul> <li>Paper</li> <li>Smoother Relu</li> <li>\\(\\(x\\Phi(x)\\)\\) where \\(\\Phi(x)\\) is the Normal Distribution CDF</li> <li>Weights inputs by percentile, rather than by sign like ReLU</li> <li> \\[GELU(x) = xP(X \\leq x) = x\\Phi(x) = x. \\frac{1}{2}\\left[ 1+erf\\left( \\frac{x}{\\sqrt{ 2 }} \\right) \\right]\\] </li> <li>If \\(X \\sim \\mathscr{N}(0,1)\\)</li> <li>Used in GPT3, Transformer, Vision Transformer, BERT</li> <li></li> </ul>"},{"location":"KB/GGCNN/","title":"GGCNN","text":""},{"location":"KB/GGCNN/#ggcnn","title":"GGCNN","text":"<ul> <li>Learning an object agnostic function to grasp objects</li> <li>Grasping using uni-modal data (depth image).  </li> <li>Generate pixel-wise grasp configuration for the given input.  </li> <li>The gripper approaches the target object in top-down manner. Uses a shallow network, and an eye-in-hand camera configuration.</li> <li></li> <li>Morrison, Douglas, Peter Corke, and Ju\u0308rgen Leitner. \"Closing the loop for robotic grasping: A real-time, generative grasp synthesis approach.\" RSS (2018).</li> </ul>"},{"location":"KB/GLOW/","title":"GLOW","text":""},{"location":"KB/GLOW/#glow","title":"GLOW","text":"<pre><code>def unsqueeze2d_new(input, factor=2):\n    return rearrange(input, 'b (c h2 w2) h w -&gt; b c (h h2) (w w2)', h2=factor, w2=factor)\n\ndef squeeze2d_new(input, factor=2):\n    return rearrange(input, 'b c (h h2) (w w2) -&gt; b (c h2 w2) h w', h2=factor, w2=factor)\n</code></pre>"},{"location":"KB/GLUE/","title":"GLUE","text":""},{"location":"KB/GLUE/#glue","title":"GLUE","text":""},{"location":"KB/GOMS/","title":"GOMS","text":""},{"location":"KB/GOMS/#goms","title":"GOMS","text":""},{"location":"KB/GOMS/#parts","title":"Parts","text":"<ul> <li>Goals</li> <li>Operations</li> <li>Methods</li> <li>Selection Rules</li> </ul>"},{"location":"KB/GOMS/#rest","title":"Rest","text":"<ul> <li>Human Computer Interaction</li> <li>Atomic</li> <li>Reactive vs proactive</li> <li>Performance vs control</li> </ul>"},{"location":"KB/GPT/","title":"GPT","text":""},{"location":"KB/GPT/#gpt","title":"GPT","text":"<ul> <li>Pretrained using Unsupervised Learning and finetuned</li> <li>Log Likelihood Loss</li> <li></li> </ul>"},{"location":"KB/GPT3/","title":"GPT3","text":""},{"location":"KB/GPT3/#gpt3","title":"GPT3","text":"<ul> <li>Language Models are Few-Shot Learners</li> <li>shows that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches</li> <li>autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting</li> <li>without any gradient updates or fine-tuning</li> <li>on-the-fly reasoning or domain adaptation</li> <li>methodological issues related to training on large web corpora</li> <li>can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans</li> </ul>"},{"location":"KB/GRConvNet/","title":"GRConvNet","text":""},{"location":"KB/GRConvNet/#grconvnet","title":"GRConvNet","text":"<ul> <li>Generative Residual Convolutional Neural Network</li> <li>Learning an object agnostic function to grasp objects</li> <li>Uses multi modal input data (RGB + depth images).</li> <li>Generates pixel-wise antipodal grasp configuration.</li> <li>State-of-the-art performance (97% on Cornell dataset).</li> <li>Use eye-to-hand camera configuration.</li> <li>Sulabh Kumra, et al. \"Antipodal robotic grasping using generative residual convolutional neural network.\" IROS 2020.</li> <li></li> </ul>"},{"location":"KB/GRU/","title":"Gated Recurrent Unit (GRU)","text":""},{"location":"KB/GRU/#gated-recurrent-unit-gru","title":"Gated Recurrent Unit (GRU)","text":"<ul> <li>Simplified [LSTM)](Long Short Term Memory (LSTM|Long Short Term Memory (LSTM|LSTM)](LSTM)](Long Short Term Memory (LSTM|Long Short Term Memory (LSTM|LSTM).md).md)</li> <li>It has an input and forget gate, no output gate</li> <li>Faster than LSTM in training, but does not perform well in many tasks</li> <li>Tries to forget what is not important</li> </ul>"},{"location":"KB/GRU/#the-math","title":"The Math","text":"<ul> <li>Two gates, Sigmoid<ul> <li>Reset : \\(\\(g_r = \\sigma(W_{hr}h_{t-1} + W_{xr}x_t + b_r)\\)\\)</li> <li>Update : \\(\\(g_u = \\sigma(W_{hu}h_{t-1} + W_{xu}x_t + b_u)\\)\\)</li> </ul> </li> <li>Hidden state proposal<ul> <li> \\[\\hat h_t = tanh(W_{xh}x_t + W_{hh}g_r\\cdot h_{t-1} + b_h)\\] </li> </ul> </li> <li>Final hidden state<ul> <li>Linear Interpolation between last hidden state and proposal</li> <li> \\[h_t = (1-g_u)\\cdot h_{t-1} + g_u \\cdot \\hat h_t\\] </li> </ul> </li> </ul>"},{"location":"KB/GTA5/","title":"GTA5","text":""},{"location":"KB/GTA5/#gta5","title":"GTA5","text":""},{"location":"KB/Galactica/","title":"Galactica","text":""},{"location":"KB/Galactica/#galactica","title":"Galactica","text":"<ul> <li>new large model for automatically organizing science developed by Meta AI and Papers with Code</li> <li>ability to train on it for multiple epochs without overfitting, where upstream and downstream performance improves with use of repeated token</li> <li>The dataset design is critical to the approach as all of it is processed in a common markdown format to blend knowledge between sources.</li> <li>Citations are processed via a certain token that allows researchers to predict a citation given any input context</li> <li>The capability of the model of predicting citations improves with scale and the model becomes better at the distribution of citations</li> <li>the model can perform multi-modal tasks involving SMILES chemical formulas and protein sequences</li> <li>transformer architecture in a decoder-only setup with GeLU activation for all model sizes.</li> </ul>"},{"location":"KB/Game%20Based%20Learning/","title":"Game Based Learning","text":""},{"location":"KB/Game%20Based%20Learning/#game-based-learning","title":"Game Based Learning","text":"<ul> <li>gamified learning tasks</li> <li>improve engagement</li> <li>Learning progress</li> <li>Interactivity<ul> <li>Seductive details<ul> <li>interesting, but irrelevant</li> </ul> </li> <li>Should support a specific function</li> </ul> </li> <li>Does it work?<ul> <li>Mixed</li> <li>Studies use many game elements in a study - makes it hard to understand if any work</li> <li>Not a lot of directed, guided</li> <li>Makes it fun though</li> </ul> </li> </ul>"},{"location":"KB/Gamification/","title":"Gamification","text":""},{"location":"KB/Gamification/#gamification","title":"Gamification","text":"<ul> <li>Use of game-like design elements</li> <li>Non game concepts</li> <li>Interface</li> <li>Mechanics</li> <li>Design</li> <li>Serious Games</li> <li>Game Based Learning</li> </ul>"},{"location":"KB/Gaming%20addiction/","title":"Gaming addiction","text":"<p>toc: true title: Gaming addiction</p> <p>categories: ['temp']</p>"},{"location":"KB/Gaming%20addiction/#gaming-addiction","title":"Gaming Addiction","text":"<ul> <li>fMRI was performed while showing game images to online game addicts.</li> <li>According to Brain Areas control group, right orbitofrontal cortex, right nucleus accumbens, bilateral anterior cingulate and medial frontal cortex, right dorsolateral prefrontal cortex and right caudate nucleus activation were observed.</li> <li>These areas are the rewarding areas</li> <li>The results show that the same addiction to substance can share the same neuro-biological mechanisms with the extreme gaming demands of online gaming addiction.</li> <li>Paper</li> </ul>"},{"location":"KB/Gamma%20Waves/","title":"Gamma Waves","text":""},{"location":"KB/Gamma%20Waves/#gamma-waves","title":"Gamma Waves","text":"<ul> <li>28-90 Hz</li> <li>Attention/Consciousness</li> <li></li> </ul>"},{"location":"KB/Gamma-aminobutyric%20Acid%20%28GABA%29/","title":"Gamma aminobutyric Acid (GABA)","text":""},{"location":"KB/Gamma-aminobutyric%20Acid%20%28GABA%29/#gamma-aminobutyric-acid-gaba","title":"Gamma-aminobutyric Acid (GABA)","text":"<ul> <li>A neurotransmitter implicated in brain development, muscle control, and reduced stress response</li> </ul>"},{"location":"KB/Gantry%20Robot/","title":"Gantry Robot","text":""},{"location":"KB/Gantry%20Robot/#gantry-robot","title":"Gantry Robot","text":"<ul> <li>A robot which has three degrees of freedom along the X, Y and Z coordinate system. Usually consists of a spooling system (used as a crane), which when reeled or unreeled provides the up and down motion along the Z axis. The spool can slide from left to right along a shaft which provides movement along the Z axis. The spool and shaft can move forward and back along tracks which provide movement along the Y axis. Usually used to position its end effector over a desired object and pick it up.</li> </ul>"},{"location":"KB/Gas%20Law/","title":"Gas Law","text":""},{"location":"KB/Gas%20Law/#gas-law","title":"Gas Law","text":"<ul> <li>combination of Boyle's Law and Charles' Law</li> <li> \\[\\frac{P_{1}V_{1}}{T_{1}}= \\frac{P_{2}V_{2}}{T_{2}}\\] </li> <li>Temp must be in Kelvin</li> <li>pressure x volume of a gas = number of moles x molar gas constant x absolute temperature</li> <li> \\[pV = nRT\\] </li> </ul>"},{"location":"KB/Gato/","title":"Gato","text":""},{"location":"KB/Gato/#gato","title":"Gato","text":"<ul> <li>A Generalist Agent</li> <li>Gato</li> <li>single generalist agent beyond the realm of text outputs, inspired by progress in large-scale language modeling</li> <li>multi-modal, multi-task, multi-embodiment generalist policy</li> <li>same network with the same weights can play Atari, caption images, chat, stack blocks with a real robot arm and much more, deciding based on its context whether to output text, joint torques, button presses, or other tokens</li> <li>To enable processing this multi-modal data from different tasks and modalities, it is serialized into a flat sequence of tokens</li> <li>In this representation, Gato can be trained and sampled from akin to a standard large-scale language model</li> <li>Masking is used such that the loss function is applied only to target outputs, i.e text and various actions</li> <li>During deployment, sampled tokens are assembled into dialogue responses, captions, button presses, or other actions based on the context</li> <li>Transformer sequence models are effective as multi-task multi-embodiment policies, including for real-world text, vision and robotics tasks</li> </ul>"},{"location":"KB/Gaussian%20Baseline/","title":"Gaussian Baseline","text":""},{"location":"KB/Gaussian%20Baseline/#gaussian-baseline","title":"Gaussian Baseline","text":"<ul> <li>One of the first propositions was to add Gaussian noise to the original image</li> <li>Gaussian baseline was introduced by Smilkov et al. @smilkovSmoothGradRemovingNoise2017</li> <li>used a Gaussian distribution centered on the current image with a variance \u03c3\\sigma\u03c3.</li> <li>This variance is the only parameter when tuning the method</li> <li>This is in Smooth-Grad </li> </ul>"},{"location":"KB/Gaussian%20Distortion/","title":"Gaussian Distortion","text":""},{"location":"KB/Gaussian%20Distortion/#gaussian-distortion","title":"Gaussian Distortion","text":"<ul> <li>Grid width and height, and magnitude are kept the same as the random distortion values of 6, 6, and 5, respectively</li> <li>The Gaussian distortion has the added parameters of applying the distortion based on the 2D normal distribution</li> <li>normal distortion is applied to each grid point on a circular surface (corner=\"bell\") and with default values for the mean and standard deviation (\\(\\mu_{x}\\) = \\(\\mu_{y}\\) = 0.5,\\(\\sigma_{x}\\) = \\(\\sigma_{y}\\) = 0.05)</li> <li> \\[p(x,y) = exp\\{-(\\frac{(x-\\mu_{x})^{2}}{\\sigma_{x}} + \\frac{(x-\\mu_{y})^{2}}{\\sigma_{y}}))\\}\\] </li> </ul>"},{"location":"KB/Gaussian%20Filter/","title":"Gaussian Filter","text":""},{"location":"KB/Gaussian%20Filter/#gaussian-filter","title":"Gaussian Filter","text":"<ul> <li>Filtering with a discretized Gaussian function</li> <li>Weights follow \\(\\(G(x) = e^{-ax^{2}}\\)\\)</li> </ul>"},{"location":"KB/Gaze%20position/","title":"Gaze position","text":""},{"location":"KB/Gaze%20position/#gaze-position","title":"Gaze Position","text":"<ul> <li>Where the subject is looking</li> <li>Process how that moves with new stimuli</li> <li>Pupil size</li> <li>Gaze direction is a good metric of Attention</li> <li>Pupil Dilation</li> </ul>"},{"location":"KB/GenEth/","title":"GenEth","text":""},{"location":"KB/GenEth/#geneth","title":"GenEth","text":"<ul> <li>ethical dilemma analyzer</li> <li>ethical issues related to intelligent systems are likely to exceed the grasp of the original system designers, and designed GenEth to include ethicists into the discussion process in order to codify ethical principles in given application domains.</li> <li>Features: denoting the presence or absence of factors (e.g.,harm,benefit) with integer values;</li> <li>Duties: denoting the responsibility of an agent to minimize/maximize a given feature;</li> <li>Actions: denoting whether an action satisfies or violates certain duties as an integer tuple;</li> <li>Cases: used to compare pairs of actions on their collective ethical impact</li> <li>Principles: denoting the ethical preference among different actions as a tuple of integer tuples.</li> </ul>"},{"location":"KB/Gene%20Expression/","title":"Gene Expression","text":""},{"location":"KB/Gene%20Expression/#gene-expression","title":"Gene Expression","text":"<ul> <li>The process by which a gene</li> <li>\u2019s nucleotide sequence is transcribed into the form of RNA</li> <li>\u2014often as a prelude to being translated into a protein.</li> </ul>"},{"location":"KB/Generalization%20Curve/","title":"Generalization Curve","text":""},{"location":"KB/Generalization%20Curve/#generalization-curve","title":"Generalization Curve","text":"<ul> <li>A loss curve showing both the training set and the validation set. A generalization curve can help you detect possible overfitting. For example, the following generalization curve suggests overfitting because loss for the validation set ultimately becomes significantly higher than for the training set.</li> </ul>"},{"location":"KB/Generalizing%20Adversarial%20Explanations%20with%20Grad-CAM/","title":"Generalizing Adversarial Explanations with Grad-CAM","text":""},{"location":"KB/Generalizing%20Adversarial%20Explanations%20with%20Grad-CAM/#generalizing-adversarial-explanations-with-grad-cam","title":"Generalizing Adversarial Explanations with Grad-CAM","text":"<ul> <li>@Generalizing Adversarial Explanations with Grad-CAM</li> <li>Chakraborty, Tanmay, Utkarsh Trehan, Khawla Mallat, and Jean-Luc Dugelay. \u201cGeneralizing Adversarial Explanations with Grad-CAM.\u201d In 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), 186\u201392. New Orleans, LA, USA: IEEE, 2022. https://doi.org/10.1109/CVPRW56347.2022.00031.</li> <li>Adversarial Learning</li> </ul>"},{"location":"KB/Generalizing%20Adversarial%20Explanations%20with%20Grad-CAM/#intro","title":"Intro","text":"<ul> <li>The drawback of Grad-CAM is that it cannot be used to generalize CNN behaviour.</li> <li>extends Grad-CAM from example-based explanations to a method for explaining global model behaviour</li> <li>These metrics are computed by comparing a Normalized Inverted Structural Similarity Index (NISSIM) metric of the Grad-CAM generated heatmap for samples from the original test set and samples from the adversarial test set.</li> <li>We observe a consistent shift in the region highlighted in the Grad-CAM heatmap, reflecting its participation to the decision making, across all models under adversarial attacks.</li> <li>These adversarial attacks display specific properties, i) They are not perceptible to the human eye, ii) They are controllable, and iii) Transferability, i.e., an attack designed for one model is capable of attacking multiple models</li> <li>There are mainly two kinds of attacks: targeted and non-targeted attacks. Targeted attack makes a model predict a certain label for the adversarial example, while for non-targeted attacks the labels for adversarial examples are not important, as long as the model is wrong</li> <li>These attacks can also be subdivided into black-box attacks and white-box attacks. Black-box attacks have no information about the target model, training procedure, architecture, whereas white-box attacks know the target model, training procedure, architecture, parameters.</li> <li>The CKA-similarity algorithm was used to compare the hidden representations of broad and deep models . They found that when the model capacity is large compared to the training set, a block structure emerges, which shows that the models propagate the main component of their hidden representation.</li> <li>More recent methods leverage explainability of machine learning and use SHAP based signatures to detect adversarial attacks</li> <li>As a result, we observed a global pattern displayed by all models. The shifting in the region of participation can be defined as when a model sees adversarial examples. Some parts of the input image no longer participate in the decision-making, while new parts do participate.</li> <li>These changes are not deterministic, and given an adversarial example, there is no way to tell how it will affect the shift</li> <li>FGSM</li> </ul>"},{"location":"KB/Generalizing%20Adversarial%20Explanations%20with%20Grad-CAM/#new-metrics","title":"New Metrics","text":"<ul> <li>Normalized Inverted Structural Similarity Index</li> <li>Mean Observed Dissimilarity</li> <li>Variation in Dissimilarity Variation in Dissimilarity</li> </ul>"},{"location":"KB/Generalizing%20Adversarial%20Explanations%20with%20Grad-CAM/#face-dataset-case-study","title":"Face Dataset Case Study","text":"<ul> <li>VGGFace2</li> <li>First, we preprocess the dataset to align and crop the faces. Then, the dataset is split into 80% training, 10% testing, and 10% validation sets.</li> <li>Once the training step is completed, the stored models are loaded and used to generate perturbations from the test set using FGSM.</li> <li>Then the test set is attacked with different values of \\(\\epsilon\\) from the stored perturbations and these counterexamples are stored as perturbed test sets</li> <li>Finally, Grad- CAM was used to generate heatmaps for every layer in each model and each \u03f5 in the perturbed test set.</li> <li>VGG 16: we can observe clearly that all the attacks were successful and illustrates a clear shift of participating regions as the \u03f5 increases.</li> <li>ResNet50 : the number of layers are too many to pin point out some example, yet if observed very carefully the hidden layers as the \u03f5 increases, we can find a shifting in the region of participation.</li> <li>In ResNet101: it seems more resilient there are some observable region shifts, but overall much less.</li> <li>InceptionNet v3 : seems to have learnt something different, the focus was more on forehead than face, but the overall shifting is much higher for this model, we even see focus regions getting inverted as the \u03f5 increases.</li> <li>For XceptionNet : the phenomenon is more clear, some regions get expanded, and background areas are being highlighted.</li> <li>We use the heatmap obtained from the original image (without adversarial perturbation) as our ground truth heatmap, i.e., what the model expects to see in order to make a decision, then the second heatmap is generated from the adversarially attacked image, and we create a dataframe with all the NISSIM values for the entire test set comparing with the adversarial test set for all values of \u03f5.</li> <li>We can also use this metric to explain the performance of VGG16. Since the shift was smaller, the model was less likely to fail.</li> <li>We also find that deep networks perform better than wide networks for similar shifts</li> <li>The main idea, that is examined here, is that the lower the shift in distribution, more the model is robust to adversarial attacks</li> <li>This indicates that VGG16 is a stable model for this task, over the other models.</li> </ul>"},{"location":"KB/Generalizing%20Adversarial%20Explanations%20with%20Grad-CAM/#observations","title":"Observations","text":"<ul> <li>We see a shift in the focus of the model in different directions, sometimes backgrounds get highlighted, other times, participation region expands or shrinks.</li> <li>Deeper models are much robust to this changes, for similar amount of shift, deeper models provide better performance than wider models.</li> <li>neural networks fail because of a shifting behaviour in the region of participation to the decision-making, when the model sees adversarial examples, its focus changes and it now sees a different hidden representation</li> <li>The main observation to keep in mind is, as \u03f5 increases, the dissimilarity increases, indicating that the focus of the model is diverted when it is presented an adversarial example, this value indicates that the more the examples differ, the more likely the model will fail.</li> <li>We can observe a pattern that wide models fail more than deep models as the \u03f5 increases</li> </ul>"},{"location":"KB/Generalizing%20Adversarial%20Explanations%20with%20Grad-CAM/#images","title":"Images","text":""},{"location":"KB/Generative%20Models/","title":"Generative_Models","text":""},{"location":"KB/Generative%20Models/#generative_models","title":"Generative_Models","text":"<ul> <li>Basic GAN</li> <li>GAN</li> </ul>"},{"location":"KB/Generative%20RNN/","title":"Generative RNN","text":""},{"location":"KB/Generative%20RNN/#generative-rnn","title":"Generative RNN","text":"<ul> <li>initial sequence is used as seed and output is sampled\u00a0<ul> <li>random or argmax to sample</li> <li>normally not taking argmax but sample with respective\u00a0Softmax probabilities -&gt; allows to generate something different than input</li> </ul> </li> <li>new output is used as seed to generate next\u00a0</li> <li>repeat until termination criterion</li> </ul>"},{"location":"KB/Generative%20Spoken%20Language%20Modeling/","title":"Generative Spoken Language Modeling","text":""},{"location":"KB/Generative%20Spoken%20Language%20Modeling/#generative-spoken-language-modeling","title":"Generative Spoken Language Modeling","text":"<ul> <li>Generative Spoken Language Modeling from Raw Audio</li> <li>learns speech representations from CPC, Wav2Vec2.0, and HuBERT for synthesizing speech</li> <li>task of learning the acoustic and linguistic characteristics of a language from raw audio</li> <li>et of metrics to automatically evaluate the learned representations at acoustic and linguistic levels for both encoding and generation</li> <li>set up baseline systems consisting of a discrete speech encoder (returning pseudo-text units)</li> <li>generative language model (trained on pseudo-text)</li> <li>speech decoder (generating a waveform from pseudo-text)</li> <li>trained without supervision</li> <li>number of discrete units (50, 100, or 200) matters in a task-dependent and encoder-dependent way, and that some combinations approach text-based systems</li> </ul>"},{"location":"KB/Generative%20vs%20Discriminative%20Models/","title":"Generative vs Discriminative Models","text":""},{"location":"KB/Generative%20vs%20Discriminative%20Models/#generative-vs-discriminative-models","title":"Generative vs Discriminative Models","text":""},{"location":"KB/Generative%20vs%20Discriminative%20Models/#generative","title":"Generative","text":"<ul> <li>LDA</li> <li>Bayesian Model Estimation</li> <li>HMM</li> <li>Autoregressive</li> <li>Basic GAN</li> </ul>"},{"location":"KB/Generative%20vs%20Discriminative%20Models/#discriminative","title":"Discriminative","text":"<ul> <li>Logistic Regression</li> <li>SVM</li> <li>Decision Trees</li> <li>Random Forest</li> </ul>"},{"location":"KB/Geometric%20Transformations/","title":"Geometric Transformations","text":""},{"location":"KB/Geometric%20Transformations/#geometric-transformations","title":"Geometric Transformations","text":"<ul> <li>The safety of a Data Augmentation method refers to its likelihood of preserving the label post-transformation.</li> <li>A non-label preserving transformation could potentially strengthen the model\u2019s ability to output a response indicating that it is not confident about its prediction. However, achieving this would require refined labels post-augmentation.</li> <li>Due to the challenge of constructing refined labels for post-augmented data, it is important to consider the \u2018safety\u2019 of an augmentation. This is somewhat domain dependent</li> </ul>"},{"location":"KB/Gestalt%20Laws/","title":"Gestalt Laws","text":""},{"location":"KB/Gestalt%20Laws/#gestalt-laws","title":"Gestalt Laws","text":"<ul> <li>Good form can dominate other laws</li> <li>crossing swarms in our visual field are perceived as different swarms</li> </ul>"},{"location":"KB/Git%20Commands/","title":"Git Commands","text":"","tags":["mlops"]},{"location":"KB/Git%20Commands/#git-commands","title":"Git Commands","text":"<ul> <li>Sources<ul> <li>The Essential GitHub CLI Commands</li> </ul> </li> </ul>","tags":["mlops"]},{"location":"KB/Git%20Commands/#managing-gists","title":"Managing Gists","text":"<pre><code>gh gist create my\\_mergify\\_gist.py\n</code></pre> <pre><code>gh gist create --public my\\_mergify\\_gist.py\n</code></pre>","tags":["mlops"]},{"location":"KB/Git%20Commands/#list-all-your-gists","title":"List All Your Gists","text":"<pre><code>gh gist list\n</code></pre> <ul> <li>You can also apply filters on this list using the <code>--limit int</code> argument (default to 10) along with the <code>--public</code> and <code>--secret</code> flags.</li> </ul>","tags":["mlops"]},{"location":"KB/Git%20Commands/#view","title":"View","text":"<pre><code>gh gist view 4b5ba0b5daabf386ee01bc37ab667e58\n</code></pre>","tags":["mlops"]},{"location":"KB/Git%20Commands/#delete","title":"Delete","text":"<pre><code>gh gist delete 4b5ba0b5daabf386ee01bc37ab667e58\n</code></pre>","tags":["mlops"]},{"location":"KB/Git%20Commands/#managing-issues","title":"Managing Issues","text":"","tags":["mlops"]},{"location":"KB/Git%20Commands/#creating-an-issue","title":"Creating an Issue","text":"<pre><code>gh issue create --toc: true\ntitle \"Is it a bug?\" --body \"the behavior\u2019s description\"\n</code></pre>","tags":["mlops"]},{"location":"KB/Git%20Commands/#listing-all-the-repositorys-issues","title":"Listing All the repository\u2019s Issues","text":"<pre><code>gh issue list\n</code></pre> <ul> <li>You can even open your browser with <code>--web</code></li> </ul>","tags":["mlops"]},{"location":"KB/Git%20Commands/#status","title":"Status","text":"<pre><code>gh issue status\n</code></pre>","tags":["mlops"]},{"location":"KB/Git%20Commands/#closing-an-issue","title":"Closing an Issue","text":"<pre><code>gh issue close &lt;num&gt;\n</code></pre>","tags":["mlops"]},{"location":"KB/Git%20Commands/#reopening-an-issue","title":"Reopening an Issue","text":"<pre><code>gh issue reopen &lt;num&gt;\n</code></pre>","tags":["mlops"]},{"location":"KB/Git%20Commands/#managing-repositories","title":"Managing Repositories","text":"","tags":["mlops"]},{"location":"KB/Git%20Commands/#create-a-public-repository","title":"Create a Public Repository","text":"<pre><code>gh repo create\n</code></pre>","tags":["mlops"]},{"location":"KB/Git%20Commands/#forking-a-repository","title":"Forking a Repository","text":"<pre><code>gh repo fork Mergifyio/react-crisp\n</code></pre>","tags":["mlops"]},{"location":"KB/Git%20Commands/#listing-the-repository-of-an-account","title":"Listing the Repository of an account","text":"<pre><code>gh repo list CamClrt\n</code></pre> <ul> <li>You can filter this list down using the <code>--archived</code>, <code>--no-archived</code>, or <code>--source</code> flags.</li> </ul>","tags":["mlops"]},{"location":"KB/Git%20Commands/#managing-prs","title":"Managing PRs","text":"","tags":["mlops"]},{"location":"KB/Git%20Commands/#creating-a-pull-request-with-a-specific-title-and-body","title":"Creating a Pull Request with a Specific Title and Body","text":"<pre><code>gh pr create --toc: true\ntitle \"feat: my\\_super\\_feature\" --body \"all the details\" \n</code></pre>","tags":["mlops"]},{"location":"KB/Git%20Commands/#listing-all-the-pull-requests-in-the-repository","title":"Listing All the Pull Requests in the Repository","text":"<pre><code>gh pr list\n</code></pre> <ul> <li>this command allows you to apply a large number of filters like <code>--assignee</code>, <code>--base</code>, <code>--label</code>, and more</li> </ul>","tags":["mlops"]},{"location":"KB/Git%20Commands/#status-of-your-pull-requests","title":"Status of Your Pull Requests","text":"<pre><code>gh pr status\n</code></pre>","tags":["mlops"]},{"location":"KB/Git%20Commands/#getting-a-pull-request-to-inspect-it","title":"Getting a Pull Request to Inspect it","text":"<pre><code>gh pr checkout 2530\n</code></pre>","tags":["mlops"]},{"location":"KB/Git%20Commands/#displaying-continuous-integration-ci-status-for-a-specific-pull-request","title":"Displaying Continuous Integration (CI) Status for a Specific Pull Request","text":"<pre><code>gh pr checks 1234\n</code></pre>","tags":["mlops"]},{"location":"KB/Git%20Commands/#diff","title":"Diff","text":"<pre><code>gh pr checkout &lt;num&gt;\ngh pr diff\n</code></pre>","tags":["mlops"]},{"location":"KB/Git%20Commands/#merge","title":"Merge","text":"<pre><code>gh pr merge &lt;num&gt;\n</code></pre> <pre><code>gh pr merge -m -d &amp;lt;number&amp;gt; &amp;amp;&amp;amp; git pull\n</code></pre>","tags":["mlops"]},{"location":"KB/Git%20Commands/#display-the-title-body-and-other-information-about-a-pull-request","title":"Display the Title, Body, and other Information about a Pull Request.","text":"<pre><code>gh pr view\n</code></pre>","tags":["mlops"]},{"location":"KB/Git%20Commands/#make-a-pull-request-as-ready-for-review","title":"Make a Pull Request as Ready for Review","text":"<pre><code>gh pr ready\n</code></pre>","tags":["mlops"]},{"location":"KB/Git%20Commands/#add-a-review-to-a-pull-request","title":"Add a Review to a Pull Request","text":"<pre><code>gh pr review\n</code></pre>","tags":["mlops"]},{"location":"KB/Git%20Commands/#closereopen","title":"Close/reopen","text":"<pre><code>gh pr &lt;close, reopen&gt;\n</code></pre>","tags":["mlops"]},{"location":"KB/Glia/","title":"Glia","text":""},{"location":"KB/Glia/#glia","title":"Glia","text":"<ul> <li>The supporting cells of the central nervous system. They may contribute to the transmission of nerve impulses and play a critical role in protecting and nourishing neurons.</li> <li>Previously thought of as protective covering</li> <li>Central Nervous System<ul> <li>Astrocyte</li> <li>Microglia</li> <li>Ependymal Cell</li> <li>Ogliodendrocytes</li> </ul> </li> <li>Peripheral Nervous System<ul> <li>Satellite Cell</li> <li>Schwann Cell</li> </ul> </li> </ul>"},{"location":"KB/Glioblastoma/","title":"Glioblastoma","text":""},{"location":"KB/Glioblastoma/#glioblastoma","title":"Glioblastoma","text":"<ul> <li>An invasive brain tumor made up of glial tissue, blood vessels, and dead neurons.</li> </ul>"},{"location":"KB/Glioma/","title":"Glioma","text":""},{"location":"KB/Glioma/#glioma","title":"Glioma","text":"<ul> <li>A tumor that arises from the brain\u2019s glial tissue.</li> </ul>"},{"location":"KB/GloVE/","title":"GloVE","text":""},{"location":"KB/GloVE/#glove","title":"GloVE","text":""},{"location":"KB/GloVE/#explanation","title":"Explanation","text":"<ul> <li>GloVe: Global Vectors for Word Representation</li> <li>Word2Vec relies only on local information of language. That is, the semantics learnt for a given word, is only affected by the surrounding words.</li> <li>Unsupervised Learning algorithm which captures both global statistics and local statistics of a corpus</li> <li>aggregated global word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space</li> <li>whether distributional word representations are best learned from count-based methods or from prediction-based methods</li> <li>probe the underlying co-occurrence statistics of the corpus</li> <li>reformulated word2vec optimizations as a special kind of factorization for word co-occurence matrices</li> <li>Note that GloVe does not use neural networks</li> <li>utilizes this main benefit of count data while simultaneously capturing the meaningful linear substructures prevalent in recent log-bilinear prediction-based methods like word2vec</li> <li>global log-bilinear LinearRegression model for the unsupervised learning of word representations</li> <li></li> <li>There\u2019s a straight red column through all of these different words. They\u2019re similar along that dimension (and we don\u2019t know what each dimensions codes for)</li> <li>There are clear places where \u201cking\u201d and \u201cqueen\u201d are similar to each other and distinct from all the others. Could these be coding for a vague concept of royalty?</li> </ul>"},{"location":"KB/GloVE/#analogies","title":"Analogies","text":""},{"location":"KB/Global%20Average%20Pooling/","title":"Global Average Pooling","text":""},{"location":"KB/Global%20Average%20Pooling/#global-average-pooling","title":"Global Average Pooling","text":"<p>```mermaid graph TD;</p> <p>E1[Averages activations of each feature map] --&gt; E2[concatenates them] --&gt; E3[outputs as a vector] ```</p>"},{"location":"KB/Global%20Classification%20Accuracy/","title":"Global Classification Accuracy","text":""},{"location":"KB/Global%20Classification%20Accuracy/#global-classification-accuracy","title":"Global Classification Accuracy","text":"<ul> <li>an accuracy computed using all predictions in a complete experiment</li> </ul>"},{"location":"KB/Global%20Gradient%20Magnitude%20Based%20Pruning/","title":"Global Gradient Magnitude Based Pruning","text":""},{"location":"KB/Global%20Gradient%20Magnitude%20Based%20Pruning/#global-gradient-magnitude-based-pruning","title":"Global Gradient Magnitude Based Pruning","text":"<ul> <li>Identifies lowest absolute value \\((weight*gradient)\\) in the whole network and removes them</li> </ul>"},{"location":"KB/Global%20Magnitude%20Based%20Pruning/","title":"Global Magnitude Based Pruning","text":""},{"location":"KB/Global%20Magnitude%20Based%20Pruning/#global-magnitude-based-pruning","title":"Global Magnitude Based Pruning","text":"<ul> <li>Takes the lowest values in the entire network. Drops them.</li> </ul>"},{"location":"KB/Global%20and%20Sliding%20Window%20Attention/","title":"Global and Sliding Window Attention","text":""},{"location":"KB/Global%20and%20Sliding%20Window%20Attention/#global-and-sliding-window-attention","title":"Global and Sliding Window Attention","text":"<ul> <li>Sliding Window Attention and Dilated Sliding Window Attention are not always enough</li> <li>global attention\u201d on few pre-selected input locations.</li> <li>This attention is operation symmetric: that is, a token with a global attention attends to all tokens across the sequence, and all tokens in the sequence attend to it</li> <li></li> </ul>"},{"location":"KB/Glucose/","title":"Glucose","text":""},{"location":"KB/Glucose/#glucose","title":"Glucose","text":"<ul> <li>A natural sugar that is carried in the blood and is the principal source of energy for the cells of the brain and body.</li> </ul>"},{"location":"KB/Glymphatic%20System/","title":"Glymphatic System","text":""},{"location":"KB/Glymphatic%20System/#glymphatic-system","title":"Glymphatic System","text":"<ul> <li>The system that helps clear debris from the brain. During sleep, special glial cells called astrocytes form a network of conduits that allow cerebrospinal fluid to flush unwanted and unnecessary proteins out of the brain.</li> </ul>"},{"location":"KB/Glyphs/","title":"Glyphs","text":""},{"location":"KB/Glyphs/#glyphs","title":"Glyphs","text":"<ul> <li>Alpha Blending</li> </ul>"},{"location":"KB/Goodhart%27s%20Law/","title":"Goodhart's Law","text":""},{"location":"KB/Goodhart%27s%20Law/#goodharts-law","title":"Goodhart's Law","text":"<ul> <li>\u201cWhen a measure becomes a target, it ceases to be a good measure.\u201d</li> <li>Proxy Objective</li> <li>Rejection Sampling</li> </ul>"},{"location":"KB/Goodhart%27s%20Law/#refs","title":"Refs","text":"<ul> <li>openai</li> </ul>"},{"location":"KB/Google%20Conceptual%20Captions/","title":"Google Conceptual Captions","text":""},{"location":"KB/Google%20Conceptual%20Captions/#google-conceptual-captions","title":"Google Conceptual Captions","text":""},{"location":"KB/Google%20NMT/","title":"Google NMT","text":""},{"location":"KB/Google%20NMT/#google-nmt","title":"Google NMT","text":"<ul> <li>Google\u2019s Neural Machine Translation System: Bridging the Gap Between Human and Machine Translation<ul> <li>deep [LSTM)](Long Short Term Memory (LSTM|Long Short Term Memory (LSTM|LSTM)](LSTM)](Long Short Term Memory (LSTM|Long Short Term Memory (LSTM|LSTM).md).md) network with 8 encoder and 8 decoder layers using attention and residual connections</li> <li>improve parallelism and therefore decrease training time, their attention mechanism connects the bottom layer of the decoder to the top layer of the encoder</li> <li>low-precision arithmetic during inference computations (FP16 training ???)</li> <li>improve handling of rare words, we divide words into a limited set of common sub-word units</li> <li>good balance between the flexibility of \u201ccharacter\u201d-delimited models and the efficiency of \u201cword\u201d-delimited models</li> <li>Beam search technique employs a length-normalization procedure and uses a coverage penalty</li> </ul> </li> </ul>"},{"location":"KB/Google%20voice%20search%20task/","title":"Google voice search task","text":""},{"location":"KB/Google%20voice%20search%20task/#google-voice-search-task","title":"Google Voice Search Task","text":""},{"location":"KB/Grad-CAM/","title":"GradCAM","text":""},{"location":"KB/Grad-CAM/#gradcam","title":"GradCAM","text":"<ul> <li>@selvarajuGradCAMVisualExplanations</li> <li>Modified CAM</li> <li>Importance of feature map k for target class c<ul> <li>A is input</li> <li>\\(Y_{c}=\\text{score of class c}\\) : value of output before softmax</li> <li>grad of \\(Y_{c}\\) wrt A and take avg</li> <li>$$</li> </ul> </li> </ul> <p>\\alpha_{k}^{c}= average(\\partial \\frac{Y_{c}}{\\partial A^{k}{ij}}) $$     - If avg is high : important     - 0 : not     - neg : background/ others - Weighted combination -&gt; relu     - $$ L^{c}{GRADCAM}=Resize(ReLU(\\Sigma_{k}(\\alpha^{c}_{k}A^{k}))) $$     - This is a coarse heatmap because the image is resized     - ReLU used because we only care about positive values (actualy image pixel) - To identify Counterfactual Images, flip the signs     -  $$</p> <p>\\alpha_{k}^{c}=average(- \\partial \\frac{Y_{c}}{\\partial A^{k}_{ij}})</p> <p>$$     -  - Followed by Guided GradCAM</p>"},{"location":"KB/Grad-CAM/#other-stuff","title":"Other Stuff","text":"<ul> <li>producing \u2018visual explanations\u2019 for decisions from a large class of CNN-based models, making them more transparent and explainable</li> <li>Gradient-weighted Class Activation Mapping</li> <li>uses the gradients of any target concept</li> <li>flowing into the final convolutional layer to produce a coarse localization map highlighting the important regions in the image for predicting the concept</li> <li>lend insights into failure modes of these models (showing that seemingly unreasonable predictions have reasonable explanations)</li> <li>are robust to adversarial perturbations</li> <li>are more faithful to the underlying model</li> <li>help achieve model generalization by identifying dataset bias</li> <li>identify important neurons through GradCAM and combine it with neuron names to provide textual explanations for model decisions</li> </ul>"},{"location":"KB/Grad-CAM/#gradcam-vs-cam","title":"GradCAM Vs CAM","text":"<ul> <li>Gradient-weighted Class Activation Mapping (Grad-CAM) is an improvement over Class Activation Mapping ([CAM]) that provides a more detailed and accurate visualization that provides a more detailed and accurate [visualization.md) of the regions of an image that are important for a given classification.</li> <li>CAM generates heatmaps by using global average pooling (GAP) in the final convolutional layer to generate a feature map, followed by a linear combination of the feature map and the class weight vector to generate a single class activation map. However, this approach does not take into account the gradients of the class scores with respect to the feature maps, which can provide additional information about the contribution of different regions of the image to the final classification decision.</li> <li>Grad-CAM, on the other hand, uses the gradients of the class scores with respect to the feature maps in order to generate heatmaps. Specifically, it uses the gradients of the class scores with respect to the final feature maps of the network, which are then upsampled to the same size as the input image. The resulting heatmap highlights the regions of the input image that are most important for the given classification.</li> <li>In summary, Grad-CAM is an improvement over CAM because it provides a more detailed and accurate visualization of the regions of an image that are important for a given classification by using gradients of the class scores with respect to the feature maps, providing additional information about the contribution of different regions of the image to the final classification decision.</li> </ul>"},{"location":"KB/GradCAM%2B%2B/","title":"GradCAM++","text":""},{"location":"KB/GradCAM%2B%2B/#gradcam","title":"GradCAM++","text":"<ul> <li>@chattopadhayGradCAMGeneralizedGradientBased2018</li> </ul>"},{"location":"KB/Gradient%20Accumulation/","title":"Gradient Accumulation","text":""},{"location":"KB/Gradient%20Accumulation/#gradient-accumulation","title":"Gradient Accumulation","text":"<ul> <li>Pytorch</li> <li>helps when the model is not able to be trained with a big enough batch size</li> <li>often caused by memory limitations of the GPU</li> <li>Accumulate the gradients (for each trainable model value) of several forward passes and after some steps use the accumulated gradients to update the weights</li> <li>Is then equal to using a large batch size</li> <li>example with \\(\\(SGD: \\theta_{i}=\\theta_{i}\u22121\u2212 \\alpha\\ast(\\Sigma_{i=0}^{N}grad_{\\theta_{i}})\\)\\)</li> </ul>"},{"location":"KB/Gradient%20Ascent/","title":"Gradient Ascent","text":""},{"location":"KB/Gradient%20Ascent/#gradient-ascent","title":"Gradient Ascent","text":"<ul> <li>To maximize loss function unlike Gradient Descent gradients</li> <li>Proportional to positive of gradient</li> <li> \\[\\theta_{t+1} = \\theta{t} + \\eta_t \\Sigma_{n=1}^N(\\nabla l_n(\\theta_t))^T\\] </li> </ul>"},{"location":"KB/Gradient%20Boosting/","title":"Gradient Boosting","text":""},{"location":"KB/Gradient%20Boosting/#gradient-boosting","title":"Gradient Boosting","text":"<ul> <li>A training algorithm where weak models are trained to iteratively improve the quality (reduce the loss) of a strong model. For example, a weak model could be a linear or small decision tree model. The strong model becomes the sum of all the previously trained weak models.</li> <li>In the simplest form of gradient boosting, at each iteration, a weak model is trained to predict the loss gradient of the strong model.</li> </ul>"},{"location":"KB/Gradient%20Checkpointing/","title":"Gradient Checkpointing","text":""},{"location":"KB/Gradient%20Checkpointing/#gradient-checkpointing","title":"Gradient Checkpointing","text":"<ul> <li>https://spell.ml/blog/gradient-checkpointing-pytorch-YGypLBAAACEAefHs</li> </ul>"},{"location":"KB/Gradient%20Clipping/","title":"Gradient Clipping","text":""},{"location":"KB/Gradient%20Clipping/#gradient-clipping","title":"Gradient Clipping","text":"<ul> <li>Limit the value or the norm of a gradient to a fixed Hyperparameter \u03bb.</li> <li>mitigate the Vanishing &amp; Exploding Gradients, exploding ones</li> <li>idea is to clip the gradients during Backpropagation to a certain threshold (limit the value)</li> <li>most often used in RNN or GAN, where Batch Normalisation is tricky to use</li> <li>methods<ul> <li>clip by norm<ul> <li>clip the whole gradient if its L2 norm is greater than the threshold</li> <li>remains the orientation</li> </ul> </li> <li>clip by value<ul> <li>clip the gradient by a fixed value</li> <li>problem: orientation of the gradient may change due to clipping<ul> <li>example: [0.9,100.0]\u2192[0.9,1.0]</li> <li>however, this works well in practice</li> </ul> </li> </ul> </li> </ul> </li> <li>pros:<ul> <li>larger batch sizes</li> </ul> </li> <li>cons:<ul> <li>sensible to tuning Hyperparameter \u03bb</li> </ul> </li> <li>Adaptive Gradient Clipping</li> </ul>"},{"location":"KB/Gradient%20Descent%20gradients/","title":"Gradient Descent","text":""},{"location":"KB/Gradient%20Descent%20gradients/#gradient-descent","title":"Gradient Descent","text":"<ul> <li>Backprop</li> <li> <p>Gradient Direction</p> </li> <li> <p>Gradient Magnitude</p> </li> <li>Edge Strength $\\(||\\triangledown f|| = \\sqrt{(\\frac{\\partial f}{\\partial x})^{2} + (\\frac{\\partial f}{\\partial y})^{2}}\\)</li> <li>Params \\(\\(\\theta\\)\\)</li> <li>Minimize loss function \\(\\(\\mathscr{L}(\\theta) = \\Sigma^N_{n=1}l_n(\\theta)\\)\\)</li> <li>Simple Gradient Descent</li> <li>SGD</li> <li>Mini Batch GD</li> <li>SGD Momentum</li> <li>Adagrad</li> <li>Nesterov Momentum</li> <li>AdaDelta</li> <li>Rmsprop</li> <li>Adam</li> </ul>"},{"location":"KB/Gradient%20Descent%20gradients/#_1","title":"\u2026","text":""},{"location":"KB/Gradient%20Direction/","title":"Gradient Direction","text":""},{"location":"KB/Gradient%20Direction/#gradient-direction","title":"Gradient Direction","text":"<ul> <li>Direction of Steepest Descent \\(\\(\\theta = tan^{-1}(\\frac{\\frac{\\partial f}{\\partial y}}{\\frac{\\partial f}{\\partial x}})\\)\\)</li> </ul>"},{"location":"KB/Gradient%20Sensitivity/","title":"Gradient Sensitivity","text":""},{"location":"KB/Gradient%20Sensitivity/#gradient-sensitivity","title":"Gradient Sensitivity","text":"<ul> <li>if for every input and baseline that differ in one feature but have different predictions, then the differing feature should be given a non-zero attribution</li> <li>If the function implemented by the deep network does not depend (mathematically) on some variable, then the attribution to that variable is always zero.</li> <li>The sensitivity axiom introduces the baseline</li> <li>A baseline is defined as an absence of a feature in an input</li> <li>This definition is confusing, especially when dealing with complex models, but the baseline could be interpreted as \u201cinput from the input space that produces a neutral prediction\u201d.</li> <li>A baseline can be treated as an input to produce a counterfactual explanation by checking how the model behaves when moving from baseline to the original image.</li> <li>The authors give the example of the baseline for an object recognition network, which is a black image.</li> <li>Authors argue that gradient-based methods are violating Sensitivity</li> <li>As an example, we are presented with the case of simple function, \\(\\(f(x)=1-ReLU(1-x)\\)\\) </li> <li>and the baseline being \\(x=0\\)</li> <li>When trying to generate attribution for \\(x=2\\), the functions\u2019 output changes from 0 to 1 but after \\(x=1\\), it becomes flat and causes the gradient to equal zero.</li> <li>Obviously, x attributes to the result, but because the function is flat at the input we are testing results in invalid attribution and breaks the Sensitivity</li> <li>Sundararajan et al. think that breaking Sensitivity causes gradients to focus on irrelevant features.</li> </ul>"},{"location":"KB/Gradio/","title":"Gradio","text":""},{"location":"KB/Gradio/#gradio","title":"Gradio","text":"<pre><code>from fastai.vision.all import *\npath = untar_data(URLs.PETS)\ndls = ImageDataLoaders.from_name_re(path, get_image_files(path/'images'), pat='(.+)_\\d+.jpg', item_tfms=Resize(460), batch_tfms=aug_transforms(size=224, min_scale=0.75))\nlearn = vision_learner(dls, models.resnet50, metrics=accuracy)\nlearn.fine_tune(1)\nlearn.path = Path('.')\nlearn.export()\n\nlearn = load_learner('export.pkl')\n\nlabels = learn.dls.vocab\ndef predict(img):\n    img = PILImage.create(img)\n    pred,pred_idx,probs = learn.predict(img)\n    return {labels[i]: float(probs[i]) for i in range(len(labels))}\n\ntoc: true\ntitle = \"Pet Breed Classifier\"\ndescription = \"A pet breed classifier trained on the Oxford Pets dataset with [fastai](./fastai.md). Created as a demo for Gradio and HuggingFace Spaces.\"\narticle=\"&lt;p style='text-align: center'&gt;&lt;a href='https://tmabraham.github.io/blog/gradio_hf_spaces_tutorial' target='_blank'&gt;Blog post&lt;/a&gt;&lt;/p&gt;\"\nexamples = ['siamese.jpg']\ninterpretation='default'\nenable_queue=True\n\ngr.Interface(fn=predict,inputs=gr.inputs.Image(shape=(512, 512)),outputs=gr.outputs.Label(num_top_classes=3),toc: true\ntitle=toc: true\ntitle,description=description,article=article,examples=examples,interpretation=interpretation,enable_queue=enable_queue).launch()\n</code></pre>"},{"location":"KB/Gram%20matrix/","title":"Gram matrix","text":""},{"location":"KB/Gram%20matrix/#gram-matrix","title":"Gram Matrix","text":"<pre><code>def gram_matrix_new(y):\n    b, ch, h, w = y.shape\n    return torch.einsum('bchw,bdhw-&gt;bcd', [y, y]) / (h * w)\n</code></pre>"},{"location":"KB/Granger%20Causallity/","title":"Granger Causallity","text":""},{"location":"KB/Granger%20Causallity/#granger-causallity","title":"Granger Causallity","text":"<ul> <li>Autoregressive</li> <li>If significant then electrode Granger-causes another</li> <li>Theres some causality but not sure if physical or causal</li> <li></li> <li>Partial Directed Coherence</li> <li>Directed Transfer Function</li> <li><ul> <li>Magnitude vs freq</li> <li>Undirected</li> <li>From O1 to PZ is different from PZ to O1</li> <li>How well can activity in one channel predict one in another</li> </ul> </li> </ul>"},{"location":"KB/Graph%20Based%20Distillation/","title":"Graph Based Distillation","text":""},{"location":"KB/Graph%20Based%20Distillation/#graph-based-distillation","title":"Graph Based Distillation","text":"<ul> <li>Lee and Song (2019) analysed intra-data rela- tions using a multi-head graph, in which the vertices are the features from different layers in CNNs. Park et al. (2019) directly transferred the mutual relations of data samples, i.e., to match edges between a teacher graph and a student graph. Tung and Mori (2019) used the similarity matrix to represent the mutual relations of the activations of the input pairs in teacher and student models. The similarity matrix of student matches that of teacher.</li> <li>Peng et al. (2019a) not only matched the response-based and feature-based knowl- edge, but also used the graph-based knowledge. In (Liu et al., 2019g), the instance features and instance relationships are modeled as vertexes and edges of the graph, respectively.</li> <li>Specifically, Luo et al. (2018) considered the modal- ity discrepancy to incorporate privileged information from the source domain. A directed graph, referred to as a distillation graph is introduced to explore the relationship between different modalities. Each vertex represent a [modality] and the edges indicate the connection strength between one modality and another.</li> <li>Minami et al. (2019) proposed a bidirectional graph-based diverse collaborative learning to explore diverse knowledge transfer patterns. Yao et al. (2020) introduced GNNs to deal with the knowledge trans- fer for graph-based knowledge.</li> <li>Besides, using knowl- edge distillation, the topological semantics of a graph convolutional teacher network as the topology-aware knowledge are transferred into the graph convolutional student network (Yang et al., 2020b)</li> </ul>"},{"location":"KB/Graph-based%20visual%20saliency/","title":"Graph-based visual saliency","text":"<ul> <li>TODO</li> <li>exploits channel-wise feature maps computed by linear filtering followed by a nonlinear transformation.</li> <li>To estimate saliency maps, the feature maps are transformed into activation maps and normalised by using the fully-connected directed graph of the feature maps.</li> </ul>"},{"location":"KB/Graph-based%20visual%20saliency/#graph-based-visual-saliency","title":"Graph-based Visual Saliency","text":""},{"location":"KB/Graphs/","title":"Graphs","text":""},{"location":"KB/Graphs/#graphs","title":"Graphs","text":"<ul> <li>Graph \\(G= (V,E)\\) where</li> <li>edges \\(E \\subseteq V \\times V\\)</li> <li>vertices \\(V\\)</li> <li>Small World graphs</li> </ul>"},{"location":"KB/Grasp%20Point%20Detection/","title":"Grasp Point Detection","text":""},{"location":"KB/Grasp%20Point%20Detection/#grasp-point-detection","title":"Grasp Point Detection","text":"<ul> <li>Choose a grasp point either from above or from side by considering:<ul> <li>Size of object\u2019s bounding box</li> <li>Principle axes</li> <li>Projections/Views</li> </ul> </li> <li>GGCNN, GRConvNet, MVGrasp, Unet Grasping, Learning to Detect Grasp Affordance, Volumetric Grasping Network , Affordance Detection Task Specific</li> <li>Kinesthetic Teaching</li> </ul>"},{"location":"KB/Gravity%20Loading/","title":"Gravity Loading","text":""},{"location":"KB/Gravity%20Loading/#gravity-loading","title":"Gravity Loading","text":"<ul> <li>The force exerted downward, due to the weight of the robot arm and/or the load at the end of the arm. The force creates an error with respect to position accuracy of the end effector. A compensating force can be computed and applied bringing the arm back to the desired position.</li> </ul>"},{"location":"KB/Gravity/","title":"Gravity","text":""},{"location":"KB/Gravity/#gravity","title":"Gravity","text":"<ul> <li>Mass\u00a0is a measure of an object's inertia.\u00a0Mass\u00a0also determines the strength of gravity. Because of gravity all objects are attracted to each other, but we mostly notice the attraction towards the Earth because it is so large and so close.</li> <li> \\[F_{g}= mg\\] </li> <li>\\(g = 9.8 m/s^2\\)</li> </ul>"},{"location":"KB/Greedy%20Policy/","title":"Greedy Policy","text":""},{"location":"KB/Greedy%20Policy/#greedy-policy","title":"Greedy Policy","text":"<ul> <li>In reinforcement learning, a policy that always chooses the action with the highest expected return.</li> </ul>"},{"location":"KB/Grey%20sheep%20problem/","title":"Grey sheep problem","text":""},{"location":"KB/Grey%20sheep%20problem/#grey-sheep-problem","title":"Grey Sheep Problem","text":"<ul> <li>Fall outside the bounds in something like clustering</li> <li>gets assigned to something close by but not really related</li> </ul>"},{"location":"KB/GridMask/","title":"GridMask","text":""},{"location":"KB/GridMask/#gridmask","title":"GridMask","text":"<ul> <li>@chenGridMaskDataAugmentation2020</li> <li>The algorithm tries to overcome drawbacks of [Cutout], [Random Erasing], and Hide and Seek that are prone to deleting important information entirely or leaving it untouched without making it harder for the algorithm to learn.</li> <li>To handle this, GridMask creates multiple blacked-out regions in evenly spaced grids to maintain a good balance between deletion and retention of critical information</li> <li>The number of masking grids and their sizes are tuneable</li> </ul>"},{"location":"KB/Grids/","title":"Grids","text":""},{"location":"KB/Grids/#grids","title":"Grids","text":""},{"location":"KB/Gripper/","title":"Gripper","text":""},{"location":"KB/Gripper/#gripper","title":"Gripper","text":"<ul> <li>An end effector that is designed for seizing and holding (ISO 8373) and \"grips\" or grabs an object. It is attached to the last link of the arm. It may hold an object using several different methods, such as: applying pressure between its \"fingers\", or may use magnetization or vacuum to hold the object, etc</li> <li></li> </ul>"},{"location":"KB/Group%20Modeling%20Approach/","title":"Group Modeling Approach","text":""},{"location":"KB/Group%20Modeling%20Approach/#group-modeling-approach","title":"Group Modeling Approach","text":"<ul> <li>Take all users -&gt; Split them into groups</li> <li>Not personalized</li> <li>Easy to classify a user</li> <li>Grey sheep problem</li> </ul>"},{"location":"KB/Group%20fairness/","title":"Group fairness","text":""},{"location":"KB/Group%20fairness/#group-fairness","title":"Group fairness","text":"<ul> <li>fairness is analyzed by modeling the differences between each subject and the rest of the population.</li> </ul>"},{"location":"KB/Guided%20BackProp/","title":"Guided BackProp","text":""},{"location":"KB/Guided%20BackProp/#guided-backprop","title":"Guided BackProp","text":"<ul> <li>@springenbergStrivingSimplicityAll2015</li> <li>Striving for simplicity, the All conv net</li> </ul>"},{"location":"KB/Guided%20BackProp/#summary","title":"Summary","text":"<ul> <li>Combination of [DeconvNet] and  Deep Inside Convolutional Networks </li> <li>DeconvNet has an issue with flow of negative gradients which decrease accuracy of higher layers</li> <li>Their idea is to combine two approaches and add a \u201cguide\u201d to the Saliency with the help of deconvolution.</li> <li>focus on the ReLU activation function</li> <li>When computing values at the Rectification component of the deconvnet, we are masking all non-positive values with the ReLU</li> <li>In that layer, the computed values are calculated only base on the top signal (reconstruction from the upper layer), and the input is ignored</li> <li>On the other hand, in the Saliency method, we are focusing on the gradient values computed base on the input image</li> <li>If we take deconvnet masking of the Rectification layer and apply it on the gradient values of the Saliency method, we could remove noise caused by the negative gradient values.</li> <li>Deconvolution guides backpropagation values of the Saliency method to produce sharper images</li> <li>The idea of GBP is often misunderstood and interpreted as \u201capplying deconvolution results on the saliency results\u201d.</li> <li>This is not true because ReLU masking extracted from the deconvnet is applied on every level and therefore affects the gradient values all the way down to the input of the CNN, not only at the first level of the CNN</li> </ul>"},{"location":"KB/Guided%20BackProp/#images","title":"Images","text":""},{"location":"KB/Guided%20GradCAM/","title":"Guided GradCAM","text":""},{"location":"KB/Guided%20GradCAM/#guided-grad-cam","title":"Guided Grad-CAM","text":"<ul> <li>@selvarajuGradCAMWhyDid2017</li> <li>Pointwise multiply betwen [Grad-CAM] and Guided BackProp</li> <li>Class Discriminative</li> <li>High resolution</li> <li>Similar to Occlusion Map but faster</li> <li>Guided [Grad-CAM] is a variation of Grad-CAM that combines the gradients of the class scores with respect to the feature maps with the gradients of a guided backpropagation algorithm. Guided backpropagation is a method for visualizing the internal representations of a neural network by backpropagating the output of the network to the input image, while only propagating the positive gradients.</li> <li>The main difference between [Grad-CAM] and Guided [Grad-CAM] is that while [Grad-CAM] focuses on finding the regions of an image that are most important for a given classification, Guided [Grad-CAM] also takes into account the positive gradients of the guided backpropagation algorithm, in order to provide a more fine-grained [visualization] of the internal representations of the network. This can make Guided Grad-CAM more effective for understanding how the model is making its decisions, and for identifying the specific features of an image that the model is using for a given classification.</li> <li></li> </ul>"},{"location":"KB/Gyrus/","title":"Gyrus","text":""},{"location":"KB/Gyrus/#gyrus","title":"Gyrus","text":"<ul> <li>The folding of the cortex increases the brain\u2019s surface area allowing more neurons to fit inside the skull and enabling higher functions</li> <li>Each groove between folds is called a sulcus.</li> <li>There are names for the folds and grooves that help define specific brain regions.</li> </ul>"},{"location":"KB/H3%20View/","title":"H3 View","text":""},{"location":"KB/H3%20View/#h3-view","title":"H3 View","text":""},{"location":"KB/HL7/","title":"HL7","text":"","tags":["medical"]},{"location":"KB/HL7/#hl7","title":"HL7","text":"<ul> <li>broader range of standards for clinical and administrative data exchange</li> <li>HL7apy<ul> <li>pip install hl7apy</li> </ul> </li> </ul>","tags":["medical"]},{"location":"KB/HMDB51/","title":"HMDB51","text":""},{"location":"KB/HMDB51/#hmdb51","title":"HMDB51","text":"<ul> <li>smaller video dataset for human action recognition </li> <li>7,000 video clips in this dataset belong to 51 human action categories </li> <li>videos in HMDB51 dataset have 320 x 240 pixels spatial resolution and 30 FPS frame rate </li> <li>the self-supervised models are fine-tuned on the dataset to evaluate the quality of the learned video features.</li> </ul>"},{"location":"KB/HNSW/","title":"HNSW","text":""},{"location":"KB/HNSW/#hnsw","title":"HNSW","text":"<ul> <li>approximate nearest neighbor search algorithm that enables efficient similarity search over dense vector representations</li> <li>It builds a multi-layer navigable small world graph structure to index the vectors, allowing for fast and scalable retrieval of semantically similar documents.</li> </ul>"},{"location":"KB/Hallucination%20Text%20Generation/","title":"Hallucination Text Generation","text":""},{"location":"KB/Hallucination%20Text%20Generation/#hallucination-text-generation","title":"Hallucination Text Generation","text":"<ul> <li>Survey of Hallucination in Natural Language Generation</li> <li>often produces false statements that are disconnected from reality because such models are not grounded in reality</li> <li>hallucinated texts</li> </ul>"},{"location":"KB/Hallucination/","title":"Hallucination","text":""},{"location":"KB/Hallucination/#hallucination","title":"Hallucination","text":"<ul> <li>The production of plausible-seeming but factually incorrect output by a generative model that purports to be making an assertion about the real world. For example, if a dialog agent claims that Barack Obama died in 1865, the agent is hallucinating.</li> </ul>"},{"location":"KB/Hamming%20Distance/","title":"Hamming Distance","text":""},{"location":"KB/Hamming%20Distance/#hamming-distance","title":"Hamming Distance","text":"<ul> <li> \\[d = \\Sigma_{i}|p_{i}- q_{i}|\\] </li> <li>Hamming distance is the number of values that are different between two vectors</li> <li>It is typically used to compare two binary strings of equal length.</li> <li>difficult to use when two vectors are not of equal length</li> </ul>"},{"location":"KB/Hand%20Guiding/","title":"Hand Guiding","text":""},{"location":"KB/Hand%20Guiding/#hand-guiding","title":"Hand Guiding","text":"<ul> <li>allows an operator to hand guide the robot to a desired position. This task can be achieved by utilizing additional external hardware mounted directly to the robot or by a robot specifically designed to support this feature. Both solutions will require elements of functional safety to be utilized. A risk assessment shall be used to determine if any additional safeguarding is necessary to mitigate risks within the robot system.</li> </ul>"},{"location":"KB/Hard%20Parameter%20Sharing/","title":"Hard Parameter Sharing","text":""},{"location":"KB/Hard%20Parameter%20Sharing/#hard-parameter-sharing","title":"Hard Parameter Sharing","text":""},{"location":"KB/Harmonic%20Drive/","title":"Harmonic Drive","text":""},{"location":"KB/Harmonic%20Drive/#harmonic-drive","title":"Harmonic Drive","text":"<ul> <li>Compact lightweight speed reducer that converts high speed low torque to low speed high torque. Usually found on the minor (smaller) axis.</li> </ul>"},{"location":"KB/Harness/","title":"Harness","text":""},{"location":"KB/Harness/#harness","title":"Harness","text":"<ul> <li>Usually several wires, bundled together to deliver power and/or signal communications to/from devices. For example, the robot motors are connected to the controller through a wire harness.</li> </ul>"},{"location":"KB/Hashing/","title":"Hashing","text":""},{"location":"KB/Hashing/#hashing","title":"Hashing","text":"<ul> <li>In machine learning, a mechanism for bucketing categorical data, particularly when the number of categories is large, but the number of categories actually appearing in the dataset is comparatively small.</li> <li>For example, Earth is home to about 60,000 tree species. You could represent each of the 60,000 tree species in 60,000 separate categorical buckets. Alternatively, if only 200 of those tree species actually appear in a dataset, you could use hashing to divide tree species into perhaps 500 buckets.</li> </ul>"},{"location":"KB/Hausdorff%20Distance/","title":"Hausdorff Distance","text":""},{"location":"KB/Hausdorff%20Distance/#hausdorff-distance","title":"Hausdorff Distance","text":"<ul> <li> \\[d= max_{i}(|p_{i}-q_{i}|)\\] </li> </ul>"},{"location":"KB/Haversine%20Distance/","title":"Haversine Distance","text":""},{"location":"KB/Haversine%20Distance/#haversine-distance","title":"Haversine Distance","text":"<ul> <li> \\[d = 2r\\times arcsin(\\sqrt{sin^{2}(\\frac{\\varphi_{2}-\\varphi_{1}}{2})+cos(\\varphi_{1})cos(\\varphi_{2})sin^{2}(\\frac{\\lambda_{2}-\\lambda_{1}}{2}))}\\] </li> <li>Haversine distance is the distance between two points on a sphere given their longitudes and latitudes</li> <li>The main difference is that no straight line is possible since the assumption here is that the two points are on a sphere.</li> <li>ssumed the points lie on a sphere</li> <li>As you might have expected, Haversine distance is often used in navigation</li> <li>calculate the distance between two countries when flying between them</li> <li>Note that it is much less suited if the distances by themselves are already not that large. The curvature will not have that large of an impact.</li> </ul>"},{"location":"KB/He%20Initialization/","title":"He Initialization","text":""},{"location":"KB/He%20Initialization/#he-initialization","title":"He Initialization","text":"<ul> <li>bring the variance of those outputs to approximately one</li> <li>However, Kumar indeed proves mathematically that for the ReLU activation function, the best weight initialization strategy is to initialize the weights randomly but with this variance:<ul> <li> \\[\\begin{equation} v^{2} = 2/N \\end{equation}\\] </li> </ul> </li> <li>For Sigmoid based activation functions</li> </ul>"},{"location":"KB/Heaviside/","title":"Heaviside","text":""},{"location":"KB/Heaviside/#heaviside","title":"Heaviside","text":"<ul> <li>$$\\begin{cases} 1, \\text{if } z \\geq 0\\ 0, \\text{if } z &lt; 0</li> </ul> <p>\\end{cases}$$</p> <ul> <li>used in Rosenblatt's\u00a0Perceptron</li> <li>not\u00a0Differentiable\u00a0-&gt;\u00a0SGD\u00a0not possible</li> <li>no practical use</li> </ul>"},{"location":"KB/Height%20Plots/","title":"Height Plots","text":""},{"location":"KB/Height%20Plots/#height-plots","title":"Height Plots","text":"<ul> <li>2D scalar field</li> <li> \\[\\{(x,y, f(x,y))|(x,y)\\in \\mathbb{R}^{2}\\}\\] </li> <li>Displacement along \\(z = f(x,y)\\)</li> <li></li> </ul>"},{"location":"KB/Heightmaps%20Kinesthetic/","title":"Heightmaps Kinesthetic","text":""},{"location":"KB/Heightmaps%20Kinesthetic/#heightmaps-kinesthetic","title":"Heightmaps Kinesthetic","text":"<ul> <li>Herzog, Alexander, et al. \"Learning of grasp selection based on shape-templates.\" Autonomous Robots 36: pp. 51-65, 2014</li> <li></li> <li></li> </ul>"},{"location":"KB/Helmholtz%20Theorem/","title":"Helmholtz Theorem","text":""},{"location":"KB/Helmholtz%20Theorem/#helmholtz-theorem","title":"Helmholtz Theorem","text":""},{"location":"KB/Help%20Abuse/","title":"Help Abuse","text":""},{"location":"KB/Help%20Abuse/#help-abuse","title":"Help Abuse","text":"<p>Some students ask for help even when they don't need it. In the extreme cases, some students ask for help on every step.</p>"},{"location":"KB/Help%20Refusal/","title":"Help Refusal","text":""},{"location":"KB/Help%20Refusal/#help-refusal","title":"Help Refusal","text":"<p>Some students refuse to ask for help even when they need it. They enter a long series of incorrect steps, which may be guesses, instead of clicking on the help button.</p>"},{"location":"KB/Heteroscedatic/","title":"Heteroscedatic","text":""},{"location":"KB/Heteroscedatic/#heteroscedatic","title":"Heteroscedatic","text":"<ul> <li>if \\(\\sigma^{2}\\) is a function of the input or variable in \\(\\epsilon \\sim \\mathcal{N}(0, \\sigma^{2})\\)</li> <li></li> </ul>"},{"location":"KB/HiFI-GAN%20Denoising/","title":"HiFI-GAN_Denoising","text":""},{"location":"KB/HiFI-GAN%20Denoising/#hifi-gan_denoising","title":"HiFI-GAN_Denoising","text":"<ul> <li>HiFi-GAN: High-Fidelity Denoising and Dereverberation Based on Speech Deep [Features](./Features.md) in Adversarial Networks&gt;</li> <li>Real-world audio recordings are often degraded by factors such as noise, reverberation, and equalization distortion</li> <li>transform recorded speech to sound as though it had been recorded in a studio</li> <li>end-to-end feed-forward WaveNet architecture, trained with multi-scale adversarial discriminators in both the time domain and the time-frequency domain</li> <li>relies on the deep feature matching losses of the discriminators to improve the perceptual quality of enhanced speech</li> </ul>"},{"location":"KB/HiFI-GAN%20Synthesis/","title":"HiFI-GAN Synthesis","text":""},{"location":"KB/HiFI-GAN%20Synthesis/#hifi-gan-synthesis","title":"HiFI-GAN Synthesis","text":"<ul> <li>HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis</li> <li>synthesis</li> <li>As speech audio consists of sinusoidal signals with various periods, they demonstrate that modeling periodic patterns of an audio is crucial for enhancing sample quality</li> <li>shows a significant improvement in terms of synthesis speed.</li> <li>MOS</li> <li>characteristic of speech audio that consists of patterns with various periods and applied it to neural networks, and verified that the existence of the proposed discriminator greatly influences the quality of speech synthesis through the ablation study</li> <li>generalize to the mel-spectrogram inversion of unseen speakers and synthesize speech audio comparable to human quality from noisy inputs in an end-to-end setting</li> <li>progress towards on-device natural speech synthesis, which requires low latency and memory footprint</li> <li>generators of various configurations can be trained with the same discriminators and learning mechanism</li> <li>possibility of flexibly selecting a generator configuration according to the target specifications without the need for a time-consuming hyper-parameter search for the discriminators</li> </ul>"},{"location":"KB/Hide%20and%20Seek/","title":"Hide and Seek","text":""},{"location":"KB/Hide%20and%20Seek/#hide-and-seek","title":"Hide and Seek","text":"<ul> <li>@singhHideandSeekDataAugmentation2018</li> <li>divides an image into a specified number of grids and turns on and off each grid with an assigned probability</li> <li>various image regions are deleted, and they can be connected or disconnected from each other</li> <li>Values in turned-off regions are replaced with the average of all the pixel values in the entire dataset.</li> </ul>"},{"location":"KB/Hierarchial%20Refinement/","title":"Heirarchial Refinement","text":""},{"location":"KB/Hierarchial%20Refinement/#heirarchial-refinement","title":"Heirarchial Refinement","text":"<ul> <li>Split n dim volume -&gt; finite set of discrete regions</li> <li>n dim hypercubes</li> <li>Construct regions where there is a higher point density</li> <li>Fine grained info encoded -&gt; smaller hypercubes to increase resolution</li> <li>n = 2 : quadtree</li> <li>n = 3 : octree</li> <li></li> <li>Mesh refinement</li> </ul>"},{"location":"KB/Hierarchial%20Refinement/#_1","title":"\u2026","text":""},{"location":"KB/Hierarchical%20Edge%20Bundling/","title":"Hierarchical Edge Bundling","text":""},{"location":"KB/Hierarchical%20Edge%20Bundling/#hierarchical-edge-bundling","title":"Hierarchical Edge Bundling","text":"<ul> <li>Exploit the hierarchical structure to bundle non-hierarchical edges visually together</li> <li>conceptual similarity to bundling streamlines</li> <li></li> </ul>"},{"location":"KB/High%20pass%20filter/","title":"High pass filter","text":""},{"location":"KB/High%20pass%20filter/#high-pass-filter","title":"High Pass Filter","text":"<ul> <li>That passes signals with a frequency higher than a certain cutoff frequency and attenuates signals with frequencies lower than the cutoff frequency.</li> </ul>"},{"location":"KB/Higher%20Layer%20Capsule/","title":"Higher Layer Capsule","text":""},{"location":"KB/Higher%20Layer%20Capsule/#higher-layer-capsule","title":"Higher Layer Capsule","text":"<ul> <li>The outputs of the Primary Capsule are then passed to higher-layer capsules, which\u00a0combine the information from multiple primary capsules\u00a0to extract more abstract concepts, such as the identity of an object or the presence of a face.</li> <li>Routing by Agreement</li> </ul>"},{"location":"KB/Highway%20Convolutions/","title":"Highway Convolutions","text":""},{"location":"KB/Highway%20Convolutions/#highway-convolutions","title":"Highway Convolutions","text":"<ul> <li>Conv</li> </ul> <pre><code>class HighwayConv1dNew(nn.Conv1d):\n    def forward(self, inputs):\n        L = super().forward(inputs)\n        H1, H2 = rearrange(L, 'b (split c) t -&gt; split b c t', split=2)\n        torch.sigmoid_(H1)\n        return H1 * H2 + (1.0 - H1) * inputs\n</code></pre>"},{"location":"KB/Hinge%20Loss/","title":"Hinge","text":""},{"location":"KB/Hinge%20Loss/#hinge","title":"Hinge","text":"<ul> <li>Classification</li> <li>SVM </li> <li>the w are weights of the model</li> <li> <p>labels are 1 or -1</p> </li> <li> \\[\\mathrm{max}\\left( 0, 1 + \\mathrm{max}\\left( w_{y} \\cdot x - w_{t} \\cdot x \\right) \\right)\\] </li> <li> \\[L(y, \\hat y) = \\Sigma_{i}max(0, 1- y_{i}\\hat y_{i})\\] </li> <li> <p>maximum margin classification </p> </li> </ul>"},{"location":"KB/Hit%20list/","title":"Hit list","text":""},{"location":"KB/Hit%20list/#hit-list","title":"Hit List","text":"<ul> <li>A shape feature which is powerful for Retrieval may not be strong in Recognition!</li> <li>Feature B: hit list should provide nice, intuitive rank in a satisfying \u2018hit list\u2019</li> <li>Feature A: target word class should survive competit with the other word classes (emerging needle from the heterogeneous hay stack)</li> </ul>"},{"location":"KB/Holdout%20Data/","title":"Holdout Data","text":""},{"location":"KB/Holdout%20Data/#holdout-data","title":"Holdout Data","text":""},{"location":"KB/Homoscedatic/","title":"Homoscedatic","text":""},{"location":"KB/Homoscedatic/#homoscedatic","title":"Homoscedatic","text":"<ul> <li>if \\(\\sigma^{2}\\) is constant in \\(\\epsilon \\sim \\mathcal{N}(0, \\sigma^{2})\\)</li> <li></li> </ul>"},{"location":"KB/Hopfield%20networks/","title":"Hopfield networks","text":""},{"location":"KB/Hopfield%20networks/#hopfield-networks","title":"Hopfield Networks","text":"<ul> <li>from</li> <li>Older architecture used to store and retrieve patterns</li> <li>Building blocks<ul> <li>Data (list of patterns)</li> <li>Network<ul> <li>Nodes</li> <li>All nodes are connected with each other</li> </ul> </li> <li>Retrieval<ul> <li>Input: partial pattern</li> <li>Output: full pattern (retrieved)<ul> <li>\"best match\" partial pattern to entire data</li> <li>Filling out the missing nodes with the best pattern is called\u00a0update rule</li> </ul> </li> </ul> </li> <li>Energy Function<ul> <li>Theoretical concept, similar to a loss function</li> <li>Is not being optimized directly but trough update function</li> </ul> </li> <li>Update function<ul> <li>Optimizes the pattern that will be retrieved to best match the partial pattern</li> </ul> </li> </ul> </li> </ul>"},{"location":"KB/How%20the%20Sciences%20Faded%20From%20India/","title":"How the Sciences Faded From India","text":"","tags":["indianhistory"]},{"location":"KB/How%20the%20Sciences%20Faded%20From%20India/#how-the-sciences-faded-from-india","title":"How the Sciences Faded From India","text":"<p>How the Sciences Faded From India   - Maintenance of secrecy, foreign invasions, easy availability of the means of subsistence, lack of royal patronage, and the apathy of the Indian people due to general introverted tendencies\u2013all these gradually stemmed the flow of scientific research in ancient India, and in time reduced it to an antique. Even then, we must certainly remember with pride that the scientific research of ancient India is indeed an essential chapter of Indian culture in the evolution of national pedigree   - during the colonization of India, a trend was set by the British in a systematic manner to discard all traditional systems of knowledge in India and to look at traditional practices with contempt. Unfortunately, this trend continued further after independence, and can still be detected even today. This resulted in the neglect of all the traditional knowledge systems, practices and indigenous science and technology systems of India.   - one of the bands of scholars whose primary interest was the converting of Hindus to the one \"true faith\" by any means necessary were those at the University of Oxford who started the Boden Professorship of Sanskrit.   - And the British system of education was a great means of making Indians forget their culture and all that they once were, and how India was once the wealthiest area in the world and a center for great learning   - Moreover, it was also a means to make the Indian people feel backwards and unworthy, and that only by accepting the Western values could they again become truly progressive and part of the civilized world.   - we can only guess at how much more advanced the world could have been, and how many more developments may have originated out of Vedic culture if it had been allowed to continue, uninterrupted by the invaders over the past 1000 years or so, whether they be the Muslims, Moghuls, the British, the Portuguese, or so on. They cared little for the culture and even preferred to destroy it, and had even less concern for the people. - T. B. Macaulay</p>","tags":["indianhistory"]},{"location":"KB/How%20to%20take%20your%20visual%20storytelling%20to%20the%20next%20level/","title":"How to take your visual storytelling to the next level","text":"","tags":["composition"]},{"location":"KB/How%20to%20take%20your%20visual%20storytelling%20to%20the%20next%20level/#how-to-take-your-visual-storytelling-to-the-next-level","title":"How to Take Your Visual Storytelling to the Next Level","text":"<ul> <li>Details matter. Little specks on clothes etc  </li> <li>Neutral light is best for taking shot. Easiest to control  </li> <li>thumbnails first always  </li> <li>planning is important</li> </ul>","tags":["composition"]},{"location":"KB/Huber/","title":"Huber/Smooth L1/Smooth MAE","text":""},{"location":"KB/Huber/#hubersmooth-l1smooth-mae","title":"Huber/Smooth L1/Smooth MAE","text":"<ul> <li>It is less sensitive to outliers than the MSE and in some cases prevents exploding #gradients</li> <li>Fast-RCNN</li> </ul> <p>if $$\\left( \\left|y - \u0177\\right| \\lt 1.0 \\right) &gt;1 $$</p> \\[\\frac{1}{\\mathrm{length}\\left( y \\right)} \\cdot \\mathrm{sum}\\left( 0.5 \\cdot \\left( y - \u0177 \\right)^{2} \\right)\\] <p>else</p> \\[\\frac{1}{\\mathrm{length}\\left( y \\right)} \\cdot \\mathrm{sum}\\left( \\left\\|y - \u0177\\right\\| - 0.5 \\right)\\]"},{"location":"KB/Huber/#_1","title":"\u2026","text":""},{"location":"KB/Human%20Action%20Recognition/","title":"Human Action Recognition","text":""},{"location":"KB/Human%20Action%20Recognition/#human-action-recognition","title":"Human Action Recognition","text":"<ul> <li>The action recognition task is often used to evaluate the quality of video features learned by self-supervised learning methods </li> <li>first trained on unlabeled video data with pretext tasks, then it is fine-tuned on action recognition datasets with human annotations to recognize the actions</li> </ul>"},{"location":"KB/Humanoid%20Vision%20Engine/","title":"Humanoid Vision Engine","text":""},{"location":"KB/Humanoid%20Vision%20Engine/#humanoid-vision-engine","title":"Humanoid Vision Engine","text":"<ul> <li>HVE</li> <li>summarize the contribution of shape, texture, and color in a given task (dataset) by separately computing the three features to support image classification</li> <li>end-to-end learning with backpropagation to simulate the learning process of humans and to summarize the contribution of shape, texture, and color</li> <li>advantage of end-to-end training is that we can avoid introducing human bias, which may influence the objective of contribution attribution</li> </ul>"},{"location":"KB/Huntington%E2%80%99s%20Disease/","title":"Huntington\u2019s Disease","text":""},{"location":"KB/Huntington%E2%80%99s%20Disease/#huntingtons-disease","title":"Huntington\u2019s Disease","text":"<ul> <li>A neurodegenerative disorder that causes progressive death of neurons in the brain, resulting in severe movement and cognitive problems. The disorder is caused by the mutation of a single gene</li> <li>\u2014and symptoms typically present when an individual is in his or her 30\u2019s or 40\u2019s.</li> </ul>"},{"location":"KB/HyTAS/","title":"HyTAS","text":"","tags":["automl"]},{"location":"KB/HyTAS/#hytas","title":"HyTAS","text":"","tags":["automl"]},{"location":"KB/HyTAS/#rebuttal","title":"Rebuttal","text":"","tags":["automl"]},{"location":"KB/HyTAS/#reviewer-2","title":"Reviewer 2","text":"<ul> <li>which seems to have the problem of local optimization<ul> <li>HyTAS seems to test specific variants of the same architecture : increasing depth/width. I think the reviewer meant that it does not test different kinds of transformer architectures -&gt; more branches/more concatenations etc. </li> <li>they thought it was a general metric to evaluate any kind of transformer. this is not the case. perhaps a clarification would be nice?</li> </ul> </li> <li>more detailed optimization<ul> <li>architecture diagram</li> </ul> </li> </ul>","tags":["automl"]},{"location":"KB/HyTAS/#general-comments","title":"General Comments","text":"<ul> <li>ZICO -&gt; ZICO++ ?</li> <li>difference between CNNs and transformers and why this architecture specifically?</li> </ul>","tags":["automl"]},{"location":"KB/Hybrid%20Word%20Segmentation/","title":"Hybrid Word Segmentation","text":""},{"location":"KB/Hybrid%20Word%20Segmentation/#hybrid-word-segmentation","title":"Hybrid Word Segmentation","text":"<ul> <li>combination</li> <li>weighted Finite State Transducer to identify dictionary entries</li> </ul>"},{"location":"KB/HyperStreamlines/","title":"HyperStreamlines","text":""},{"location":"KB/HyperStreamlines/#hyperstreamlines","title":"HyperStreamlines","text":""},{"location":"KB/Hypertension/","title":"Hypertension","text":""},{"location":"KB/Hypertension/#hypertension","title":"Hypertension","text":"<ul> <li>Unusually high blood pressure</li> </ul>"},{"location":"KB/Hypodermic%20Needle/","title":"Hypodermic Needle","text":""},{"location":"KB/Hypodermic%20Needle/#hypodermic-needle","title":"Hypodermic Needle","text":"<ul> <li>A very thin, hollow needle used with a syringe to inject substances into the body or to extract blood</li> </ul>"},{"location":"KB/Hypotension/","title":"Hypotension","text":""},{"location":"KB/Hypotension/#hypotension","title":"Hypotension","text":"<ul> <li>Unusually low blood pressure</li> </ul>"},{"location":"KB/Hypothalamus/","title":"Hypothalamus","text":""},{"location":"KB/Hypothalamus/#hypothalamus","title":"Hypothalamus","text":"<ul> <li>is located in the floor of the third ventricle and is the master control of the autonomic system.</li> <li>It plays a role in controlling behaviors such as hunger, thirst, sleep, and sexual response.</li> <li>It also regulates body temperature, blood pressure, emotions, and secretion of hormones.</li> </ul>"},{"location":"KB/Hysterectomy/","title":"Hysterectomy","text":""},{"location":"KB/Hysterectomy/#hysterectomy","title":"Hysterectomy","text":"<ul> <li>Surgical procedure to remove the uterus</li> </ul>"},{"location":"KB/ICA%20Noise%20Removal/","title":"ICA Noise Removal","text":""},{"location":"KB/ICA%20Noise%20Removal/#ica-noise-removal","title":"ICA Noise Removal","text":"<ul> <li>Notch filter</li> <li>High pass filter</li> </ul>"},{"location":"KB/ICA/","title":"ICA","text":""},{"location":"KB/ICA/#ica","title":"ICA","text":"<ul> <li>Independant Component Analysis</li> <li>Unmix combinations of signals</li> <li>Look for rotations of data into maximally independant components</li> <li>Not always orthogonal</li> <li>Better after noise removal</li> <li>Remove fewer than 20%</li> <li>Remove really bad parts first</li> <li></li> <li>ICA Noise Removal</li> </ul>"},{"location":"KB/IDRiD/","title":"IDRiD","text":""},{"location":"KB/IDRiD/#idrid","title":"IDRiD","text":"<ul> <li>IDRiD is con- cerned with the disease grade recognition of retina images, and the presence or absence of diseases is recognized from exudates and hemorrhages.</li> <li>IDRiD includes a segmentation label of disease regions annotated by a specialist</li> </ul>"},{"location":"KB/IID/","title":"IID","text":""},{"location":"KB/IID/#iid","title":"IID","text":"<ul> <li>Neural networks assumes that the data points are independent and identically distributed.</li> </ul>"},{"location":"KB/ILSVRC/","title":"ILSVRC","text":""},{"location":"KB/ILSVRC/#ilsvrc","title":"ILSVRC","text":""},{"location":"KB/IMDB/","title":"IMDB","text":""},{"location":"KB/IMDB/#imdb","title":"IMDB","text":"<ul> <li>Movie reviews</li> </ul>"},{"location":"KB/IRT/","title":"IRT","text":""},{"location":"KB/IRT/#irt","title":"IRT","text":"<ul> <li>assumes that every test item has a difficulty, and different items have different difficulties (Embretson &amp; Reise, 2000)</li> <li>Unfortunately, IRT generally assumes that test items are conditionally independent given the student's competence. This is seldom true of the raw measures collected at the step level by tutoring systems</li> <li>Although IRT has powerful features, such as calibration algorithms that empirically determine item difficulties and other parameters, considerable work is needed before it can be applied to tutoring systems.</li> </ul>"},{"location":"KB/ISIC%202018/","title":"ISIC 2018","text":""},{"location":"KB/ISIC%202018/#isic-2018","title":"ISIC 2018","text":"<ul> <li>2386 dermoscopy images, all of them annotated with patterns on skin lesions unanimously recognized as indicators of potential malignancy</li> <li>binary masks highlighting the presence of five \"features\" at pixel-level</li> <li>globules, streaks, pigment network, negative network, and milia-like cysts.</li> <li>The performances on the feature extraction task are measured using the Jaccard index.</li> </ul>"},{"location":"KB/ITM%20Loss/","title":"ITM Loss","text":""},{"location":"KB/ITM%20Loss/#itm-loss","title":"ITM Loss","text":"<ul> <li>ITM loss is an alignment loss that encompasses cross-modality interaction between image and text</li> <li>ITM requires positive and negative pairs</li> </ul>"},{"location":"KB/IVFADC/","title":"IVFADC","text":""},{"location":"KB/IVFADC/#ivfadc","title":"IVFADC","text":"<ul> <li>indexing structure that combines an inverted file system with a quantization-based approach</li> <li>It allows for efficient indexing and retrieval of large-scale vector databases by partitioning the vector space and using asymmetric distance computation.</li> </ul>"},{"location":"KB/Ideas%20for%20Fact%20Learning/","title":"Ideas for Fact Learning","text":""},{"location":"KB/Ideas%20for%20Fact%20Learning/#ideas-for-fact-learning","title":"Ideas for Fact Learning","text":"<ul> <li>Type of information<ul> <li>Methods of presentation</li> <li>Types of feedback</li> <li>Time pressure</li> <li>Study time</li> <li>Visualize progress</li> <li>Decide when an item is mastered</li> </ul> </li> <li>Increase system info about the user<ul> <li>Reaction times</li> <li>accuracy</li> <li>Eye Tracking</li> <li>biometric</li> <li>pupil dilation</li> <li>Detect learning styles</li> </ul> </li> <li>Framework<ul> <li>Gamification</li> </ul> </li> </ul>"},{"location":"KB/Identity%20Loss/","title":"Identity Loss","text":""},{"location":"KB/Identity%20Loss/#identity-loss","title":"Identity Loss","text":"<ul> <li> \\[L_{identity}(G,F) = \\mathbb{E}_{y \\sim p_{data}(y)}[||G(y)-y)||_{1}] + \\mathbb{E}_{x \\sim p_{data}(x)}[||F(x)-x)||_{1}]\\] </li> <li>The identity loss is used to preserve the color and prevent reverse color in the result.</li> <li>This loss can regularize the generator to be near an identity mapping when real samples of the target domain are provided. If something already looks like from the target domain, you should not map it into a different image.</li> <li>The model will be more conservative for unknown content.</li> <li>In general, it can help bette preserve the content if that is your priority.</li> </ul>"},{"location":"KB/Image%20Classification/","title":"Image Classification","text":""},{"location":"KB/Image%20Classification/#image-classification","title":"Image Classification","text":"<ul> <li>When choosing image classification as a downstream task to evaluate the quality of image features learned from self-supervised learning methods, the self-supervised learned model is applied on each image to extract features which then are used to train a classifier such as Support Vector Machine (SVM) [105].</li> </ul>"},{"location":"KB/Image%20Data%20Augmentation%20Survey/","title":"Image Data Augmentation Survey","text":""},{"location":"KB/Image%20Data%20Augmentation%20Survey/#image-data-augmentation-survey","title":"Image Data Augmentation Survey","text":""},{"location":"KB/Image%20Data%20Augmentation%20Survey/#introduction","title":"Introduction","text":"<ul> <li>sufficient open datasets like Imagenet [Russakovsky et al., 2015], MS-COCO [Lin et al., 2014] and PASCAL VOC [Everingham et al., 2015] are crucial to the development of deep learning models. </li> <li>imbalance among the developments of these three perspectives </li> <li>The core idea of data augmentation is to improve the sufficiency and diversity of training data by generating synthetic dataset </li> <li>The augmented data can be regarded as being extracted from a distribution that is close to the real one </li> <li>augmented dataset can represent more comprehensive characteristics </li> <li>data augmentation methods are tasks-independent </li> <li>Because the operations are performed on the image data and labels at the same time, and the label types are different under different tasks, the data augmentation methods for object detection task can not be directly applied to semantic segmentation task  </li> <li> </li> <li>it is meaningful to apply basic image manipulations only under the assumption that the existing data obeys the distribution close to the actual data distribution. </li> <li>some basic image manipulation methods, such as translation and rotation, suffer from the padding effect </li> <li>, some areas of the images will be moved out of the boundary and lost </li> <li> <p>Therefore, some interpolation methods will be applied to fill in the blank part. Generally, the region outside the image boundary is assumed to be constant 0, which will be black after manipulation. </p> </li> <li> <p>Image Erasing</p> </li> <li> <p>Image Mix</p> </li> <li> <p>Image Manipulation</p> </li> <li> <p>Auto Augment</p> </li> <li> <p>Feature Augmentation</p> </li> <li> <p>Deep Generative Models</p> </li> </ul>"},{"location":"KB/Image%20Data%20Augmentation%20Survey/#semantic-segmentation","title":"Semantic Segmentation","text":"<ul> <li>PASCAL VOC  </li> <li> </li> </ul>"},{"location":"KB/Image%20Data%20Augmentation%20Survey/#image-classification","title":"Image Classification","text":""},{"location":"KB/Image%20Data%20Augmentation%20Survey/#object-detection","title":"Object Detection","text":""},{"location":"KB/Image%20Data%20Augmentation%20Survey/#discussion-for-future-directions","title":"Discussion for Future Directions","text":"<ul> <li>lack of theoretical research on data augmentation   </li> <li>some methods can improve the accuracy, but we do not fully understand the reasons behind, such as pairing samples and mixup </li> <li>To human eyes, the augmented data with pairing samples and mixup are visually meaningless </li> <li>no theory on the size of sufficient training datasets </li> <li>The size of the dataset suitable for tasks and models is usually designed based on personal experience and through extensive experiments </li> <li>no unified metrics </li> <li>saturate the minority class and cause overfitting </li> <li>Ultimately, we expect generated data can simulate distribution similar with training data while diversity never losses. </li> <li>increase in the amount of training data is not exactly proportional to the increase in the performance </li> <li>When a certain amount of data is reached, continue to increase the data without improving the effect. </li> <li>despite the increase in the number of data, the diversity of data remains unchanged </li> <li>Since various data augmentation can be combined together to generate new image data, the selection and combination of data augmentation techniques are critical </li> <li>how to choose and combine methods is a key point when performing data augmentation </li> </ul>"},{"location":"KB/Image%20Data/","title":"Image Data","text":""},{"location":"KB/Image%20Data/#image-data","title":"Image Data","text":"<ul> <li>Cant use MLPs<ul> <li>Too many weights to learn</li> <li>No translation equi-invariance</li> </ul> </li> </ul>"},{"location":"KB/Image%20Erasing/","title":"Image Erasing","text":""},{"location":"KB/Image%20Erasing/#image-erasing","title":"Image Erasing","text":"<ul> <li>delete one or more sub-regions in the image </li> <li>replace the pixel values of these sub-regions with constant values or random values </li> <li>Hide-and-Seek </li> <li>random erasing </li> <li>GridMask </li> <li>Cutout </li> <li>FenceMask </li> <li>simulation of object occlusion strategy.</li> </ul>"},{"location":"KB/Image%20Generation%20with%20Colorization/","title":"Image Generation with Colorization","text":""},{"location":"KB/Image%20Generation%20with%20Colorization/#image-generation-with-colorization","title":"Image Generation with Colorization","text":"<ul> <li>Image colorization is a task of predicting a plausible color version of the photograph given a gray-scale photograph as input </li> <li>To correctly colorize each pixel, networks need to recognize objects and to group pixels of the same part together. Therefore, visual features can be learned in the process of accomplishing this task. </li> <li>Zhang et al. proposed to handle the uncertainty by posting the task as a clas- sification task and used class-rebalancing to increase the diversity of predicted colors [18] </li> <li>Some work specifically employs the image colorization task as the pretext for self- supervised image representation learning [18], [42], [82], [124] </li> <li>After the image colorization training is finished, the features learned through the colorization process are specifically evaluated on other downstream high-level tasks with transfer learning.</li> </ul>"},{"location":"KB/Image%20Generation%20with%20Inpainting/","title":"Image Generation with Inpainting","text":""},{"location":"KB/Image%20Generation%20with%20Inpainting/#image-generation-with-inpainting","title":"Image Generation with Inpainting","text":"<ul> <li>Image inpainting is a task of predicting arbitrary missing regions based on the rest of an image </li> <li>To correctly predict missing regions, networks are required to learn the common knowledge including the color and structure of the common objects </li> <li>Only by knowing this knowledge, networks are able to infer missing regions based on the rest part of the image.</li> </ul>"},{"location":"KB/Image%20Generation%20with%20Super%20Resolution/","title":"Image Generation with Super Resolution","text":""},{"location":"KB/Image%20Generation%20with%20Super%20Resolution/#image-generation-with-super-resolution","title":"Image Generation with Super Resolution","text":"<ul> <li>Image super-resolution (SR) is a task of enhancing the resolution of images </li> <li>With the help of fully convolutional networks, finer and realistic high-resolution images can be generated from low-resolution images </li> <li>perceptual loss which consists of an adversarial loss and a content loss </li> <li>With the perceptron loss, the SRGAN is able to recover photo-realistic textures from heavily downsampled images and show significant gains in perceptual quality. </li> <li>The networks for image super-resolution task are able to learn the semantic features of images</li> </ul>"},{"location":"KB/Image%20Generation/","title":"Image Generation","text":""},{"location":"KB/Image%20Generation/#image-generation","title":"Image Generation","text":"<ul> <li>Visual features are learned through the process of image generation tasks. </li> <li>image colorization </li> <li>super resolution </li> <li>inpainting </li> <li>image generation with Generative Adversarial Networks (GANs)</li> </ul>"},{"location":"KB/Image%20Manipulation/","title":"Image Manipulation","text":""},{"location":"KB/Image%20Manipulation/#image-manipulation","title":"Image Manipulation","text":"<ul> <li>image transformations, such as rotation, flipping, and cropping, etc </li> <li>manipulate the images directly and are easy to implement </li> <li>CutMix </li> <li>Fmix</li> <li>AugMix </li> <li>ManifoldMix</li> </ul>"},{"location":"KB/Image%20Mix/","title":"Image Mix","text":""},{"location":"KB/Image%20Mix/#image-mix","title":"Image Mix","text":"<ul> <li>mixing two or more images or sub-regions of images into one. </li> <li>synthesizing every new image with two images randomly selected in the training set, known as pairing samples. The synthesis method used is to average the intensity of two images on each pixel </li> <li>Mixup</li> </ul>"},{"location":"KB/Image%20Mixing%20and%20Deletion/","title":"Image Mixing and Deletion","text":""},{"location":"KB/Image%20Mixing%20and%20Deletion/#image-mixing-and-deletion","title":"Image Mixing and Deletion","text":"<ul> <li>@naveedSurveyImageMixing2023</li> <li>[Cutout] and CutMix argues that hindering image regions enforces the classifier to learn from the partially visible objects and understand the overall structure</li> <li>CutMix verifies this argument by showing enhanced focus towards the target class in</li> <li>Opposite to this, MixUp has shown to improve classifier's calibration and reduced prediction uncertainity</li> <li>mean of predictions vs accuracy where the confidence distribution for MixUp trained model is evenly distributed against the standard model whose disovertribution is towards higher conficence i.e. confidence</li> <li>Similarly, the loss contours obtained for a network trained with MixUp are smooth as compared to sharp contours in standarad training</li> <li>better generalization and robustness of MixUp against adversarial attacks.</li> <li>Mixup</li> <li>Cut and Delete</li> <li>Cutout</li> <li>Random Erasing</li> <li>Hide and Seek</li> <li>GridMask</li> <li>Adversarial Spatial Dropout for Occlusion</li> <li>Cut and Mix</li> <li>CutMix</li> <li>Attentive CutMix</li> <li>AttributeMix</li> <li>RICAP</li> <li>Mixed Example</li> <li>CowMask</li> <li>ResizeMix</li> <li>SaliencyMix</li> <li>Intra-Class Part Swapping</li> <li>SnapMix</li> <li>KeepAugment</li> <li>Visual Context Augmentation</li> <li>Cut, Paste and Learn</li> <li>Manifold MixUp</li> <li>AugMix</li> <li>SmoothMix</li> <li>Co-Mixup</li> <li>Sample Pairing</li> <li>Puzzle Mix</li> <li>ReMix</li> </ul>"},{"location":"KB/ImageNet/","title":"ImageNet","text":"<p>toc: true title: ImageNet</p> <p>categories: ['temp']</p>"},{"location":"KB/ImageNet/#imagenet","title":"ImageNet","text":""},{"location":"KB/Imagen/","title":"Imagen","text":""},{"location":"KB/Imagen/#imagen","title":"Imagen","text":"<ul> <li>better top-1 accuracy on ImageNet than EfficientNet at similar latency</li> <li>Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding</li> <li>text-to-image diffusion model</li> <li>large Transformer language models in understanding text and hinges on the strength of diffusion models in high-fidelity image generation</li> <li>Imagen produces \\(1024 \\times 1024\\) samples with unprecedented photorealism and alignment with text</li> <li>generic large language models (e.g. T5), pretrained on text-only corpora, are surprisingly effective at encoding text for image synthesis</li> <li>increasing the size of the language model in Imagen boosts both sample fidelity and image-text alignment much more than increasing the size of the image diffusion model</li> <li>FID score</li> <li>COCO</li> </ul>"},{"location":"KB/Implementation%20Invariance/","title":"Implementation Invariance","text":""},{"location":"KB/Implementation%20Invariance/#implementation-invariance","title":"Implementation Invariance","text":"<ul> <li>Two networks are functionally equivalent if their outputs are equal for all inputs, despite having very different implementations.</li> <li>Attribution methods should satisfy Implementation Invariance, i.e., the attributions are always identical for two functionally equivalent networks.</li> </ul>"},{"location":"KB/Implicit%20Bias/","title":"Implicit Bias","text":""},{"location":"KB/Implicit%20Bias/#implicit-bias","title":"Implicit Bias","text":"<ul> <li>The unconscious attitudes, beliefs, or stereotypes we hold that have the power to affect our perceptions, actions, and decisions.</li> </ul>"},{"location":"KB/Implicit%20Bias/#implicit-bias_1","title":"Implicit Bias","text":"<ul> <li>Automatically making an association or assumption based on one\u2019s mental models and memories. Implicit bias can affect the following<ul> <li>How data is collected and classified.</li> <li>How machine learning systems are designed and developed.</li> </ul> </li> <li>For example, when building a classifier to identify wedding photos, an engineer may use the presence of a white dress in a photo as a feature. However, white dresses have been customary only during certain eras and in certain cultures.</li> </ul>"},{"location":"KB/Implicitly%20learning%20when%20to%20be%20ready%20-%20From%20instances%20to%20categories/","title":"Implicitly learning when to be ready - From instances to categories","text":""},{"location":"KB/Implicitly%20learning%20when%20to%20be%20ready%20-%20From%20instances%20to%20categories/#implicitly-learning-when-to-be-ready-from-instances-to-categories","title":"Implicitly learning when to be ready - From instances to categories","text":"<ul> <li> <p>Wouter Kruijne \u00b7 Riccardo M. Galli \u00b7 Sander A. Los</p> </li> <li> <p>role of long-term memory in guiding temporal preparation in speeded reaction time tasks.</p> </li> <li>In experiments with variable foreperiods between a warning stimulus (S1) and a target stimulus (S2), preparation is affected by foreperiod distributions experienced in the past, long after the distribution has changed</li> <li>associative nature of memory-guided preparation</li> <li>When distinct S1s predict different foreperiods, they can trigger differential preparation accordingly</li> <li>memory-guided preparation allows for another key feature of learning: the ability to generalize across acquired associations and apply them to novel situations</li> <li>Images of either category were paired with different distributions with predominantly shorter versus predominantly longer foreperiods.</li> <li>differential preparation to never-before seen images of either category, without being aware of the predictive nature of these categories</li> <li>continued doing so in a subsequent Transfer phase, after they had been informed that these contingencies no longer held</li> <li>rolling regression analysis revealed at a fine timescale how category-guided preparation gradually developed throughout the task</li> <li>explicit information about these contingencies only briefly disrupted memory-guided preparation</li> </ul>"},{"location":"KB/Implicitly%20learning%20when%20to%20be%20ready%20-%20From%20instances%20to%20categories/#preparation-across-phases","title":"Preparation across phases","text":""},{"location":"KB/Implicitly%20learning%20when%20to%20be%20ready%20-%20From%20instances%20to%20categories/#results","title":"Results","text":"<ul> <li>the RT-FP curve, separately for the different S1 types during the Acquisition and Transfer phase</li> <li>this curve is flatter for trials paired with S1E types than S1A types in both phases, indicating that the categories yielded differential preparation</li> <li>significant FP \u00d7 Phase interaction</li> <li>suggesting that there was a steeper RTFP slope during Acquisition than during Transfer</li> <li>evidence for a two-way S1 type \u00d7 FP interaction</li> <li>but not for a three way S1 type \u00d7 Phase \u00d7 FP interaction</li> <li>different S1 types led to differential preparation in both phases</li> <li>biased distributions in the Acquisition phase gave rise to long-lasting effects on preparation, persisting after the bias was removed</li> </ul>"},{"location":"KB/Implicitly%20learning%20when%20to%20be%20ready%20-%20From%20instances%20to%20categories/#time-course-of-differential-preparation","title":"Time course of differential preparation","text":"<ul> <li>participants might have gotten somewhat fatigued throughout each block, but that block breaks allowed them to largely recover to baseline</li> <li>the longer interruption between the Phases led to a more pronounced speeding up for the remaining two blocks</li> <li>overall temporal preparation remained largely consistent throughout the experiment</li> <li>the results with a shorter window of 40 trials highlight that the 'dip' in the S1 type \u00d7 FP time course at the start of the Transfer phase was very shortlived</li> <li>The brevity of this effect could therefore explain why our earlier work, using block-wise analyses, consistently led us to conclude that this transition between phases had no noticeable effect on differential preparation</li> </ul>"},{"location":"KB/Implicitly%20learning%20when%20to%20be%20ready%20-%20From%20instances%20to%20categories/#discussion","title":"Discussion","text":"<ul> <li>Our findings raise the possibility that participants in that study might have demonstrated similar memoryguided preparation even if they would have been unaware of the image-FP pairings</li> <li>complex interplay between implicit associative guidance and guidance by explicit awareness</li> <li>Nevertheless, differential preparation was robust once acquired, persisting well into the Transfer phase despite the change in underlying FP distributions</li> <li>longer Transfer phases, we similarly observed that the S1 type \u00d7 FP interaction barely attenuated across Transfer blocks</li> <li>The gradual acquisition of differential preparation and its longevity throughout the Transfer phase illustrate how temporal preparation is affected by long-term memory and sluggishly adapts to changing environmental statistics</li> <li>Many probability-driven models characterize preparation as guided by static representations of the current FP distribution (Janssen &amp; Shadlen, 2005; Grabenhorst et al., 2019; Trillenberg et al., 2000; Vangkilde et al., 2013), foregoing the role of memory and learning</li> <li>Transfer effects like those in the present study illustrate the need for a flexible basis for preparation, subject to learning and updating</li> </ul>"},{"location":"KB/Implicitly%20learning%20when%20to%20be%20ready%20-%20From%20instances%20to%20categories/#images","title":"Images","text":""},{"location":"KB/Impulse/","title":"Impulse","text":""},{"location":"KB/Impulse/#impulse","title":"Impulse","text":"<ul> <li>An impulse is defined as a force applied over a period of time. Applying a larger force or longer lasting force produces a larger impulse. A large impulse produces a large change in momentum.</li> <li> \\[J = \\Delta p \\] </li> <li> \\[F \\Delta t = \\Delta p\\] </li> <li> \\[F \\Delta t = mv - mu\\] </li> <li> \\[F \\Delta t = m \\Delta v\\] </li> <li> \\[\\Delta v = \\frac{F}{m} \\Delta t\\] </li> <li>J is impulse in kg m/s</li> <li>F is force</li> <li>p is momentum</li> <li>v,u is velocity</li> </ul>"},{"location":"KB/In%20Silico/","title":"In Silico","text":""},{"location":"KB/In%20Silico/#in-silico","title":"In Silico","text":"<ul> <li>An experimental method to study brain or neural function using computer modeling or computer simulation.</li> </ul>"},{"location":"KB/In%20Vitro/","title":"In Vitro","text":""},{"location":"KB/In%20Vitro/#in-vitro","title":"In Vitro","text":"<ul> <li>An experimental method to study brain or neural function by looking at cells outside a living organism, for example, in a test tube or petri dish.</li> </ul>"},{"location":"KB/In%20Vivo/","title":"In Vivo","text":""},{"location":"KB/In%20Vivo/#in-vivo","title":"In Vivo","text":"<ul> <li>An experimental method allowing scientists to study brain or neural function in a living organism.</li> </ul>"},{"location":"KB/In-group%20Bias/","title":"In group Bias","text":""},{"location":"KB/In-group%20Bias/#in-group-bias","title":"In-group Bias","text":"<ul> <li><code>#</code>fairness</li> <li>Showing partiality to one's own group or own characteristics. If testers or raters consist of the machine learning developer's friends, family, or colleagues, then in-group bias may invalidate product testing or the dataset.</li> <li>In-group bias is a form of group attribution bias.</li> </ul>"},{"location":"KB/Inattentional%20Blindness/","title":"Inattentional Blindness","text":""},{"location":"KB/Inattentional%20Blindness/#inattentional-blindness","title":"Inattentional Blindness","text":"<ul> <li>Viewers can fail to perceive visual elements or activities caused by an absence of attention to the unseen object</li> <li>Related to Change Blindness</li> </ul>"},{"location":"KB/Inception/","title":"Inception","text":""},{"location":"KB/Inception/#inception","title":"Inception","text":"<ul> <li>@szegedyGoingDeeperConvolutions2014</li> <li>Rethinking the Inception Architecture for Computer Vision</li> </ul>"},{"location":"KB/Inception/#v1","title":"V1","text":"<ul> <li>Conv at different filter scales to find different kinds of features -&gt; stack them up</li> <li>Increasing both the depth and width of the network while keeping computations at a manageable level</li> <li>Human visual system wherein information is processed at multiple scales and then aggregated locally</li> <li>channel dimensionality reduction, by reducing the output channels of the input</li> <li>To enable concatenation of features convolved with different kernels, they pad the output to make it the same size as the input.<ul> <li>without dilation</li> <li>padding \\(p = (k-1)/2p\\)</li> <li>since \\(out = in +2p -k +1\\)</li> </ul> </li> <li></li> </ul>"},{"location":"KB/Inception/#v2v3","title":"V2/V3","text":"<ul> <li>nxn Conv -&gt; 1xn followed by nx1 Conv</li> <li>5x5, 7x7 -&gt; 2 and three 3x3 seq Conv</li> <li>More filters (wider)</li> <li>Distributed the computational budget in a balanced way between the depth and width of the network</li> <li>Added Batch Normalization</li> <li></li> </ul>"},{"location":"KB/Inception/#v4","title":"V4","text":"<ul> <li>(from) Paper:\u00a0https://arxiv.org/pdf/1602.07261.pdf Year: 2016 Summary: New Residual\u00a0Inception\u00a0Architecture (deep\u00a0CNN)</li> <li>Why?<ul> <li>Introduction of residual connections on traditional architectures yielded SOTA performance (2015)</li> </ul> </li> <li>Research question<ul> <li>Are there benefits when combining residual connections with the\u00a0Inception\u00a0architecture?</li> </ul> </li> <li>Findings<ul> <li>Residual connections accelerates training of the\u00a0Inception\u00a0architecture</li> <li>Residual\u00a0Inception\u00a0outperforming similar architecture only close</li> <li>When the number of filters were higher than\u00a01\u2032000\u00a0the residual variants of the network died early in the training (e.g. outputted only zeros)<ul> <li>was not able to fix with lowering the\u00a0Learning Rate\u00a0or\u00a0Batch Normalization</li> </ul> </li> <li>Scaling down the residuals before adding them with the residual connection stabilized the training (factor:\u00a00.1\u22120.3)</li> </ul> </li> <li>General Ideas<ul> <li>Parallel convolutions: Similar to the GoogLeNet architecture within their\u00a0modules\u00a0the authors simultaneously use multiple convolutional branches with different receptive field sizes on the same input activation maps and again concatenate those activations for further processing.</li> <li>Reduction modules: Instead of simply applying a single max pooling or a 2-stride convolution to downsize the spatial dimensions, the authors dedicated whole modules to this task again employing parallel branches.\u00a0</li> <li>Strong usage of small convolutional kernels(e.g.\u00a03\u00d73): Throughout the network the authors pefer smaller convolutional kernel size over larger ones, as this enables the same receptive field with less parameters (e.g. a single\u00a05\u00d75convolution \u223c25\u00a0params  as 2 consecutive\u00a03\u00d73convolutions [\u223c18\u00a0params ], but the later has less parameters)</li> <li>Factorization of convolutions: They factorize convolutions of filter size\u00a0n\u00d7n\u00a0to a combination of\u00a01\u00d7n\u00a0and\u00a0n\u00d71\u00a0convolutions, in order to reduce the nr of parameters even further (e.g.\u00a07\u00d77\u00a0[\u223c49\u00a0params ] results in\u00a01\u00d77\u00a0and\u00a07\u00d71\u00a0[\u223c14\u00a0params ]!)</li> <li>Residual connections: In the\u00a0<code>Inception-ResNet-v1</code>\u00a0and\u00a0<code>Inception-ResNet-v2</code>\u00a0the authors employ the usage of residual connections. Although the residual version of the networks converge faster, the final accuracy seems to mainly depend on the model size.</li> <li>Usage of bottleneck layers: In order to reduce the cost of the individual convolutional branches within their modules, they apply\u00a01\u00d71convolutions at the beginning to reduce the depth of the input activation maps.</li> </ul> </li> <li>Remarks<ul> <li>Authors disagree with residual paper one some points\u00a0<ul> <li>Residual connections are nessecary for training deep convolutional models<ul> <li>They show that it is not hard to train very deep models which achieve high performance without residual connections</li> <li>They argue that residual connections do only speed up the training greatly</li> </ul> </li> <li>\"Warm up\" phases (pre-training with very low LR followed by a high LR) do not help to stabilize training very deep networks<ul> <li>high LR had the chance to destroy already learnt features</li> <li>Scaling should be used instead</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"KB/Inceptionism/","title":"Inceptionism","text":""},{"location":"KB/Inceptionism/#inceptionism","title":"Inceptionism","text":"<ul> <li>Google AI Blog: Inceptionism: Going Deeper into Neural Networks #Roam-Highlights</li> <li>Le Net</li> <li></li> <li></li> <li></li> <li></li> <li></li> <li></li> <li></li> <li>One of the challenges of neural networks is understanding what exactly goes on at each layer</li> <li>We know that after training, each layer progressively extracts higher and higher-level features of the image, until the final layer essentially makes a decision on what the image shows</li> <li>For example, the first layer maybe looks for edges or corners</li> <li>Intermediate layers interpret the basic features to look for overall shapes or components, like a door or a leaf</li> <li>The final few layers assemble those into complete interpretations\u2014these neurons activate in response to very complex things such as entire buildings or trees.</li> <li>One way to visualize what goes on is to turn the network upside down and ask it to enhance an input image in such a way as to elicit a particular interpretation.</li> <li>Why is this important? Well, we train networks by simply showing them many examples of what we want them to learn, hoping they extract the essence of the matter at hand (e.g., a fork needs a handle and 2-4 tines), and learn to ignore what doesn\u2019t matter (a fork can be any shape, size, color or orientation)</li> <li>But how do you check that the network has correctly learned the right features? It can help to visualize the network\u2019s representation of a fork.</li> <li>Indeed, in some cases, this reveals that the neural net isn\u2019t quite looking for the thing we thought it was.</li> <li>Instead of exactly prescribing which feature we want the network to amplify, we can also let the network make that decision</li> <li>In this case we simply feed the network an arbitrary image or photo and let the network analyze the picture</li> <li>We then pick a layer and ask the network to enhance whatever it detected.</li> <li>If we choose higher-level layers, which identify more sophisticated features in images, complex features or even whole objects tend to emerge</li> <li>Again, we just start with an existing image and give it to our neural net.</li> <li>We ask the network: \u201cWhatever you see there, I want more of it!\u201d This creates a feedback loop: if a cloud looks a little bit like a bird, the network will make it look more like a bird</li> <li>This in turn will make the network recognize the bird even more strongly on the next pass and so forth, until a highly detailed bird appears, seemingly out of nowhere.</li> <li>The results are intriguing\u2014even a relatively simple neural network can be used to over-interpret an image, just like as children we enjoyed watching clouds and interpreting the random shapes</li> <li>This network was trained mostly on images of animals, so naturally it tends to interpret shapes as animals</li> <li>But because the data is stored at such a high abstraction, the results are an interesting remix of these learned features.</li> <li>Of course, we can do more than cloud watching with this technique</li> <li>We can apply it to any kind of image</li> <li>The results vary quite a bit with the kind of image, because the features that are entered bias the network towards certain interpretations</li> <li>For example, horizon lines tend to get filled with towers and pagodas</li> <li>Rocks and trees turn into buildings</li> <li>Birds and insects appear in images of leaves.</li> <li>We must go deeper: Iterations If we apply the algorithm iteratively on its own outputs and apply some zooming after each iteration, we get an endless stream of new impressions, exploring the set of things the network knows about</li> <li>We can even start this process from a random-noise image, so that the result becomes purely the result of the neural network, as seen in the following images:</li> <li>The techniques presented here help us understand and visualize how neural networks are able to carry out difficult classification tasks, improve network architecture, and check what the network has learned during training</li> <li>It also makes us wonder whether neural networks could become a tool for artists\u2014a new way to remix visual concepts\u2014or perhaps even shed a little light on the roots of the creative process in general.</li> </ul>"},{"location":"KB/Independence/","title":"Independence","text":""},{"location":"KB/Independence/#independence","title":"Independence","text":"<ul> <li>model predictions are independent of the sensitive feature.</li> <li>the proportion of positive samples (namely, those ones belonging to the class of interest) given by the model is the same for all the subgroups within the sensitive feature</li> </ul>"},{"location":"KB/Indirect%20Volume%20Visualization/","title":"Indirect Volume Visualization","text":""},{"location":"KB/Indirect%20Volume%20Visualization/#indirect-volume-visualization","title":"Indirect Volume Visualization","text":"<ul> <li>Isosurface</li> </ul>"},{"location":"KB/Individual%20Fairness/","title":"Individual Fairness","text":""},{"location":"KB/Individual%20Fairness/#individual-fairness","title":"Individual Fairness","text":"<ul> <li>A fairness metric that checks whether similar individuals are classified similarly. For example, Brobdingnagian Academy might want to satisfy individual fairness by ensuring that two students with identical grades and standardized test scores are equally likely to gain admission.</li> <li> <p>Note that individual fairness relies entirely on how you define \"similarity\" (in this case, grades and test scores), and you can run the risk of introducing new fairness problems if your similarity metric misses important information (such as the rigor of a student\u2019s curriculum).</p> </li> <li> <p>deals with fairness from the perspective of all individual</p> </li> </ul>"},{"location":"KB/Individual%20Modeling/","title":"Individual Modeling","text":""},{"location":"KB/Individual%20Modeling/#individual-modeling","title":"Individual Modeling","text":"<ul> <li>More personalized</li> <li>Less data per category</li> <li>Ramp up problem</li> </ul>"},{"location":"KB/Induced%20Pluripotent%20Stem%20Cell%20%28iPSC%29/","title":"Induced Pluripotent Stem Cell (iPSC)","text":""},{"location":"KB/Induced%20Pluripotent%20Stem%20Cell%20%28iPSC%29/#induced-pluripotent-stem-cell-ipsc","title":"Induced Pluripotent Stem Cell (iPSC)","text":"<ul> <li>A cell that has been taken from adult tissue and genetically modified to behave like an embryonic stem cell, with the ability to develop into any type of cell found in the body, including nerve cells.</li> </ul>"},{"location":"KB/Inductive%20Bias/","title":"Inductive Bias","text":""},{"location":"KB/Inductive%20Bias/#inductive-bias","title":"Inductive Bias","text":"<ul> <li>Set of assumptions that the learner uses to predict outputs of given inputs that it has not yet encountered</li> <li>In Bayesian<ul> <li>Bayesian Prior can shape the Bayesian Posterior in the way that it can be a similar distribution to the former</li> </ul> </li> <li>In KNN<ul> <li>we assume that similar data points are clustered near each other away from the dissimilar ones</li> </ul> </li> <li>in LinearRegression<ul> <li>we assume that the variable Y is linearly dependent on the explanatory variables X.</li> <li>Therefore, the resulting model linearly fits the training data. However, this assumption can limit the model\u2019s capacity to learn non-linear functions.</li> </ul> </li> <li>in Logistic Regression<ul> <li>assume that there\u2019s a hyperplane that separates the two classes from each other. This simplifies the problem, but one can imagine that if the assumption is not valid, we won\u2019t have a good model.</li> </ul> </li> <li>Non Relational Inductive Bias</li> <li>Relational Inductive Bias</li> </ul>"},{"location":"KB/Inductive%20Learning/","title":"Inductive Learning","text":""},{"location":"KB/Inductive%20Learning/#inductive-learning","title":"Inductive Learning","text":"<ul> <li>Bayesian is inductive learning</li> <li>Learning is identifying which hypothesis set is a concept</li> <li>Hypotheses don't disappear, they just become less likely</li> <li>Learning develops through more experience</li> <li>One challenge of Bayesian learning is that any small subset is consistent with many hypotheses</li> <li>Different hypotheses have different likelihoods based on the examples we are exposed to</li> <li>But in the end we also prefer smaller hypotheses over larger ones: The size principle</li> <li>Simple clustering methods can be used to get the data to automatically create the hypothesis space needed for Bayesian modelling</li> <li>Probabilities of different sets then match with human judgments surprisingly well</li> <li>Clustering based on biology worked worse!</li> <li>Clustering using linguistic co-occurrences with Latent Semantic Analysis also worked worse!</li> <li>Human subject judgements of similarity worked best</li> <li>Suggests some human reasoning relies on probability</li> <li>Bayesian learning can also learn categories</li> <li>Models are capable of making generalizations about the specific objects as well as the appropriate generalizations about categorization (superordinate categories!) in general.</li> <li>Advanced learning means learn constraints on what is a possible hypothesis</li> <li>Hierarchical Bayesian Modelling (HBM) can explain how we acquire overhypotheses</li> <li>using observations from the lowest level (data) and calculating statistical inferences</li> </ul>"},{"location":"KB/Inductive%20Sensor/","title":"Inductive Sensor","text":""},{"location":"KB/Inductive%20Sensor/#inductive-sensor","title":"Inductive Sensor","text":"<ul> <li>The class of proximity sensors, which has half of a ferrite core, whose coil is part of an oscillator circuit. When a metallic object enters this field, at some point, the object will absorb enough energy from the field to cause the oscillator to stop oscillating. This signifies that an object is present in a given proximity.</li> </ul>"},{"location":"KB/Inertia/","title":"Inertia","text":""},{"location":"KB/Inertia/#inertia","title":"Inertia","text":"<ul> <li>\"A body either remains at rest or continues to move at a constant velocity, unless acted upon by a net external force.\"</li> </ul>"},{"location":"KB/Inference%20Path/","title":"Inference Path","text":""},{"location":"KB/Inference%20Path/#inference-path","title":"Inference Path","text":"<ul> <li>In a decision tree, during inference, the route a particular example takes from the root to other conditions, terminating with a leaf.</li> </ul>"},{"location":"KB/Infix/","title":"Infix","text":""},{"location":"KB/Infix/#infix","title":"Infix","text":"<ul> <li>inserted inside the stem</li> </ul>"},{"location":"KB/Inflectional%20Morphology/","title":"Inflectional Morphology","text":""},{"location":"KB/Inflectional%20Morphology/#inflectional-morphology","title":"Inflectional Morphology","text":"<ul> <li>creates the new forms of the same word</li> <li>e.g.bring, brought, brings</li> </ul>"},{"location":"KB/Inflectional%20words/","title":"Inflectional words","text":""},{"location":"KB/Inflectional%20words/#inflectional-words","title":"Inflectional Words","text":"<ul> <li>boundaries unclear, can express more than one grammar meaning</li> </ul>"},{"location":"KB/Influence%20of%20image%20classification%20accuracy%20on%20saliency%20map%20estimation/","title":"Influence of image classification accuracy on saliency map estimation","text":""},{"location":"KB/Influence%20of%20image%20classification%20accuracy%20on%20saliency%20map%20estimation/#influence-of-image-classification-accuracy-on-saliency-map-estimation","title":"Influence of Image Classification Accuracy on Saliency Map Estimation","text":"<ul> <li>@oyamaInfluenceImageClassification2018.</li> </ul>"},{"location":"KB/Influence%20of%20image%20classification%20accuracy%20on%20saliency%20map%20estimation/#intro","title":"Intro","text":"<ul> <li>Saliency map estimation in computer vision aims to estimate the locations where people gaze in images.</li> <li>Since people tend to look at objects in images, the parameters of the model pre-trained on ImageNet for image classification are useful for the saliency map estimation</li> <li>no research on the relationship between the image classification accuracy and the performance of the saliency map estimation</li> <li>strong correlation between image classification accuracy and saliency map estimation accuracy</li> <li>It the models pre-trained on ImageNet are useful for saliency map estimation the parameters of is known that</li> <li>This would be because a human tends to look at the centres of objects , which are learned to be recognised in the pre-trained model for the ImageNet classification task.</li> <li>Although the model based on DenseNet has achieved the state-of-the-art performance in the ACPR 2017 paper, this additional study led to even better performance using the model based on dual path networks (DPNs)</li> </ul>"},{"location":"KB/Influence%20of%20image%20classification%20accuracy%20on%20saliency%20map%20estimation/#related-work","title":"Related Work","text":"<ul> <li>uses the coefficients of Attention based on Information the basis Maximization (AIM) calculated by the independent component analysis (ICA) in local image patches</li> <li>The distribution of the coefficients is estimated by the kernel density estimation, which is used for estimating saliency maps based on the the local patches self-information of</li> <li>Graph-based visual saliency</li> <li>Saliency using natural statistics</li> <li>Dynamic visual attention</li> <li>Adaptive Whitening Saliency</li> <li>SAM-ResNet</li> </ul>"},{"location":"KB/Influence%20of%20image%20classification%20accuracy%20on%20saliency%20map%20estimation/#components-of-readout-net","title":"Components of Readout Net","text":"<ul> <li>The operation attempts to directly minimise the reconstruction error of the input image under a sparsity constraint on an over-complete set of feature maps</li> <li>The mini-batch size and learning rate were set to 1 and 10\u22125 during training, respectively.</li> <li>We subtract the per-channels mean value of training images from each image as pre-processing</li> </ul>"},{"location":"KB/Influence%20of%20image%20classification%20accuracy%20on%20saliency%20map%20estimation/#dc","title":"DC","text":"<ul> <li>\"DC is also called as transposed convolution\"</li> <li>When DC is used for the up-sampling layers in Readout Net, the first, second, and third DC followed by a ReLU layer in Readout Net reduce the channels to 128, 64, and 32, respectively. Then, the 1 \u00d7 1 convolution reduces the channel to 1 to predict the saliency map. The filter size of DC was set to 4 \u00d7 4.</li> <li>method to recover a high-resolution image from its additional low resolution counterpart with little computational cost, by rearranging the data along the channel into feature maps with a convolution operation.</li> </ul>"},{"location":"KB/Influence%20of%20image%20classification%20accuracy%20on%20saliency%20map%20estimation/#spc","title":"SPC","text":"<ul> <li>When SPC is used for the up-sampling layers, each SPC layer reduces the channels to one forth, followed by a 3 \u00d7 3 convolution and a ReLU layer. Then, the 1 \u00d7 1 convolution predicts the saliency map from the output of the last SPC layer.</li> <li>each BI layer in the up-sampling network resizes a feature map twice while maintaining the feature-map channels, GPU was out of memory when three up-sampling layers were used for all channels of outputs of Main Net</li> </ul>"},{"location":"KB/Influence%20of%20image%20classification%20accuracy%20on%20saliency%20map%20estimation/#bi","title":"BI","text":"<ul> <li>the order of up-sampling and projection (1 \u00d7 1 convolution) can be inverted without any influence on the output</li> <li>the concatenated feature maps from Main Nets are first processed by the 1 \u00d7 1 convolution to output feature map, followed by the BI up-sampling layers. the 1-channel</li> </ul>"},{"location":"KB/Influence%20of%20image%20classification%20accuracy%20on%20saliency%20map%20estimation/#datasets","title":"Datasets","text":"<ul> <li>Salicon dataset</li> <li>OSIE</li> <li>PASCAL-S</li> <li>MIT1003</li> <li>MIT300</li> </ul>"},{"location":"KB/Influence%20of%20image%20classification%20accuracy%20on%20saliency%20map%20estimation/#metrics","title":"Metrics","text":"<ul> <li>AUC-Judd</li> <li>AUC-Borji</li> <li>Shuffled-AUC</li> </ul>"},{"location":"KB/Influence%20of%20image%20classification%20accuracy%20on%20saliency%20map%20estimation/#conclusions","title":"Conclusions","text":"<ul> <li>strong correlation between image classification accuracy and saliency map estimation accuracy.</li> <li>not only the architecture but also the initialisation strategy using the weights pre-trained with the ImageNet classification task were important for estimating the saliency maps</li> <li>model which is pre-trained with the ImageNet classification and has achieved high</li> <li>\"for performance on the classification task is also useful the\"</li> <li>\"saliency map estimation task\"</li> <li>human fixations often concentrate on objects in the image, while the model pre-trained on ImageNet can react on many objects in images because ImageNet has a wide variety of object categories.</li> <li>If the model is initialised with random weights and is trained on a fixation dataset with the limited categories of objects for saliency map estimation, to the objects in the training dataset the model would overfit</li> <li>if the model is trained for the image classification task which includes a wide variety of categories, overfitting for the objects in the training dataset would be suppressed owing to a large number of categories.</li> </ul>"},{"location":"KB/Influence%20of%20image%20classification%20accuracy%20on%20saliency%20map%20estimation/#images","title":"Images","text":"<ul> <li>{:height 598, :width 600}</li> <li></li> <li></li> </ul>"},{"location":"KB/Information%20Gain/","title":"Information Gain","text":""},{"location":"KB/Information%20Gain/#information-gain","title":"Information Gain","text":"<ul> <li>In decision forests, the difference between a node's entropy and the weighted (by number of examples) sum of the entropy of its children nodes. A node's entropy is the entropy of the examples in that node.</li> </ul>"},{"location":"KB/Information%20Visualization/","title":"Information Visualization","text":""},{"location":"KB/Information%20Visualization/#information-visualization","title":"Information Visualization","text":"<ul> <li>Visualization of abstract data</li> <li>Visual mappings often have to be learned</li> <li>spatial layout is chosen</li> <li>Perception</li> <li>Visual Encoding</li> </ul>"},{"location":"KB/Informativeness/","title":"Informativeness","text":""},{"location":"KB/Informativeness/#informativeness","title":"Informativeness","text":"<ul> <li>ML models are used with the ultimate intention of supporting decision making</li> <li>should not be forgotten that the problem being solved by the model is not equal to that being faced by its human counterpart</li> <li>great deal of information is needed in order to be able to relate the user's decision to the solution given by the model, and to avoid falling in misconception pitfalls.</li> <li>explainable ML models should give information about the problem being tackled.</li> </ul>"},{"location":"KB/Inhibitory%20Control%20Network/","title":"Inhibitory Control Network","text":"<p>toc: true title: Inhibitory Control Network</p> <p>categories: ['temp']</p>"},{"location":"KB/Inhibitory%20Control%20Network/#inhibitory-control-network","title":"Inhibitory Control Network","text":"<ul> <li>Brain areas related to response inhibition ability</li> <li>inferior Frontal Gyri and Medial Frontal Gyri, the Opercular Cingulate, Insular Cingulate, Orbital Posterior Cingulate and Posterior Parietal Cortex</li> </ul>"},{"location":"KB/Initialization/","title":"Initialization","text":""},{"location":"KB/Initialization/#initialization","title":"Initialization","text":"<ul> <li>Xavier Initialization , He Initialization , LeCun Init</li> </ul>"},{"location":"KB/Instance%20Normalization/","title":"Instance Normalization","text":""},{"location":"KB/Instance%20Normalization/#instance-normalization","title":"Instance Normalization","text":"<ul> <li>Contrast Normalization</li> <li> \\[     y_{tijk} = \\frac{x_{tijk} - \\mu_{ti}}{\\sqrt{\\sigma_{ti}^2 + \\epsilon}},     \\quad     \\mu_{ti} = \\frac{1}{HW}\\sum_{l=1}^W \\sum_{m=1}^H x_{tilm},     \\quad     \\sigma_{ti}^2 = \\frac{1}{HW}\\sum_{l=1}^W \\sum_{m=1}^H (x_{tilm} - mu_{ti})^2 \\] </li> <li>This prevents instance-specific mean and covariance shift simplifying the learning process.</li> <li>Intuitively, the normalization process allows to remove instance-specific contrast information from the content image in a task like image stylization, which simplifies generation.</li> <li></li> </ul>"},{"location":"KB/Instance-based%20Learning/","title":"Instance-based Learning","text":""},{"location":"KB/Instance-based%20Learning/#instance-based-learning","title":"Instance-based Learning","text":"<ul> <li>an object category is represented by a set of known instances a nearest neighbor classifier is used</li> <li>IBL considers category learning as a process of learning about the instances of the category:</li> <li>The training phase is very fast</li> <li>IBL can recognize objects using a very small number of experiences IBL is a baseline approach to evaluate object representations Simple and easy to implement</li> <li>Memory usage in instance-based systems is continuously growing. Computational complexity grows with the number of training instances</li> <li>The computational complexity of classifying a single new instance is O(n), where n is number of instances stored in perceptual memory.</li> <li>Salience and forgetting mechanisms can be used to bound the memory usage which are also useful for reducing the risk of overfitting to noise in the training set.</li> <li>Overfitting</li> <li>Sensitive to noise</li> <li></li> </ul>"},{"location":"KB/Instant%20NeRF/","title":"Instant NeRF","text":""},{"location":"KB/Instant%20NeRF/#instant-nerf","title":"Instant NeRF","text":"<ul> <li>Instant Neural Graphics Primitives with a Multiresolution Hash Encoding</li> <li>Neural Radiance Field</li> <li>Neural graphics primitives, parameterized by fully connected neural networks, can be costly to train and evaluate</li> <li>rely on task specific data structures</li> <li>new input encoding that permits the use of a smaller network without sacrificing quality</li> <li>educing the number of floating point and memory access operations</li> <li>near-instant training of neural graphics primitives on a single GPU for multiple tasks</li> <li>small neural network is augmented by a multiresolution hash table of trainable feature vectors whose values are optimized through Gradient Descent gradients</li> <li>automatically focuses on relevant detail, independent of task at hand</li> <li>low overhead</li> <li>In a gigapixel image, they represent an image by a neural network. SDF learns a signed distance function in 3D space whose zero level-set represents a 2D surface</li> <li>2D images and their camera poses to reconstruct a volumetric radiance-and-density field that is visualized using ray marching.</li> <li>neural volume learns a denoised radiance and density field directly from a volumetric path tracer.</li> <li>only vary the hash table size which trades off quality and performance</li> <li>disambiguate hash collisions, making for a simple architecture that is trivial to parallelize on modern GPUs</li> <li>parallelism</li> <li>fully-fused Operator Fusion CUDA kernels with a focus on minimizing wasted bandwidth and compute operations</li> </ul>"},{"location":"KB/Instruction%20Bandwidth/","title":"Instruction Bandwidth","text":""},{"location":"KB/Instruction%20Bandwidth/#instruction-bandwidth","title":"Instruction Bandwidth","text":"<ul> <li>Bandwidth is the maximum amount of data that can travel through a 'channel'</li> </ul>"},{"location":"KB/Instruction%20Cycle/","title":"Instruction Cycle","text":""},{"location":"KB/Instruction%20Cycle/#instruction-cycle","title":"Instruction Cycle","text":"<ul> <li>The time it takes for a robot controller system's cycle to decode a command or instruction before it is executed. The Instruction Cycle must be analyzed very closely by robotic programmers to enable speedy and proper reaction to varying commands.</li> </ul>"},{"location":"KB/Instruction%20Latency/","title":"Instruction Latency","text":""},{"location":"KB/Instruction%20Latency/#instruction-latency","title":"Instruction Latency","text":"<ul> <li>Amount of time to complete a task(time , seconds)</li> <li>function of how long it takes the data to get sent all the way from the start point to the end</li> </ul>"},{"location":"KB/Instruction%20Pipelining/","title":"Instruction Pipelining","text":""},{"location":"KB/Instruction%20Pipelining/#instruction-pipelining","title":"Instruction Pipelining","text":"<ul> <li>used in the design of modern microprocessors, microcontrollers and CPUs to increase their Instruction Throughput for the entire workload</li> <li>divide the processing of a CPU instruction into a series of independent steps o microinstructions with storage at the end of each step.</li> <li>This allows the CPUs control logic to handle instructions at the processing rate of the slowest step, which is much faster than the time needed to process the instruction as a single step</li> <li>IF: Instruction Fetch</li> <li>ID: Instruction Decode, register fetch</li> <li>EX: Execution</li> <li>MEM: Memory Access</li> <li>WB: Register write Back</li> </ul>"},{"location":"KB/Instruction%20Throughput/","title":"Instruction Throughput","text":""},{"location":"KB/Instruction%20Throughput/#instruction-throughput","title":"Instruction Throughput","text":"<ul> <li>the number of instructions that can be executed in a unit of time</li> <li>(Jobs/Hour)</li> <li>how much data actually does travel through the 'channel' successfully</li> </ul>"},{"location":"KB/Instruction%20level%20programming/","title":"Instruction level programming","text":""},{"location":"KB/Instruction%20level%20programming/#instruction-level-programming","title":"Instruction Level Programming","text":"<ul> <li>ILP</li> <li>allows the compiler and the processor to overlap the execution of multiple instructions or even to change the order in which instructions are executed</li> <li>Instruction Pipelining</li> <li>SuperScalar</li> <li>Out of Order Execution</li> <li>Register Renaming</li> <li>Speculative Execution</li> <li>Branch Prediction</li> </ul>"},{"location":"KB/Insula/","title":"Insula","text":""},{"location":"KB/Insula/#insula","title":"Insula","text":"<ul> <li>Sometimes referred to as the insular cortex, this small region of the cerebrum is found deep within the lateral sulcus, and is believed to be involved in consciousness, emotion, and keeping the body in balance.</li> </ul>"},{"location":"KB/Integral%20Lines/","title":"Integral Lines","text":""},{"location":"KB/Integral%20Lines/#integral-lines","title":"Integral Lines","text":"<ul> <li>Seed particles in a flow field  </li> <li>Let the particles move in the flow field</li> <li>Compute and show the trajectories</li> <li></li> <li></li> <li>Streamlines</li> <li>Pathlines</li> </ul>"},{"location":"KB/Integrated%20Gradients/","title":"Integrated Gradients","text":""},{"location":"KB/Integrated%20Gradients/#integrated-gradients","title":"Integrated Gradients","text":"<ul> <li>@sundararajanAxiomaticAttributionDeep2017</li> </ul>"},{"location":"KB/Integrated%20Gradients/#terms","title":"Terms","text":"<ul> <li>Gradient Sensitivity</li> <li>Implementation Invariance</li> </ul>"},{"location":"KB/Integrated%20Gradients/#calculation","title":"Calculation","text":"<ul> <li>a function F representing our model</li> <li>input \\(x \\in \\mathbb{R}^{n}\\) because this is a general definition of IG and not CNN specific),</li> <li>baseline \\(x' \\in \\mathbb{R}^{n}\\)</li> <li>We assume a straight line path between x and x' and compute gradients along that path</li> <li>The integrated gradient along \\(i^{th}\\) dimension is defined as:</li> <li> \\[IntegratedGrads_i\u200b(x)::=(x_i\u200b-x_i'\u200b)\\times \\int_{\\alpha=0}^{1}\\frac{\\partial F(x' + \\alpha \\times (x-x'))}{\\partial x_{i}}d \\alpha\\] </li> <li>The original definition of Integrated Gradients is incalculable (because of the integral).</li> <li>Therefore, the implementation of the method uses approximated value by replacing the integral with the summation:</li> <li> \\[IntegratedGrads_i\u200b^{approx}(x)::=(x_i\u200b-x_i'\u200b)\\times \\Sigma_{k=1}^{m}\\frac{\\partial F(x' + \\frac{k}{m} \\times (x-x'))}{\\partial x_{i}} \\times \\frac{1}{m}\\] </li> <li>In the approximated calculation (Eq. 2), m defines a number of interpolation steps.</li> </ul>"},{"location":"KB/Integrated%20Gradients/#explanation-chatgpt","title":"Explanation (chatgpt)","text":"<ul> <li>In IntegratedGrads, the goal is to understand the contribution of each pixel in the input image towards the model's prediction. Specifically, for a given pixel \\(i\\), IntegratedGrads computes the partial derivative of the model output with respect to that pixel and integrates it along a path from a baseline image to the input image, weighting each step of the path by the partial derivative.</li> <li>The equation you provided is an approximation of IntegratedGrads, which involves dividing the path into \\(m\\) equally spaced steps and approximating the integral using a Riemann sum. Let's break down the equation using an example of an image of a bird:</li> <li>\\(IntegratedGrads_i^{approx}(x)\\) represents the attribution of pixel \\(i\\) towards the model's prediction, using the IntegratedGrads approximation.</li> <li>\\((x_i-x_i')\\) is the difference between the input image pixel \\(i\\) and the baseline pixel \\(i'\\).</li> <li>\\(\\Sigma_{k=1}^{m}\\) is a sum over the \\(m\\) steps of the path from the baseline image to the input image.</li> <li>\\(\\frac{\\partial F(x' + \\frac{k}{m} \\times (x-x'))}{\\partial x_i}\\) is the partial derivative of the model output \\(F\\) with respect to pixel \\(i\\) at the \\(k\\)-th step of the path, where \\(x' + \\frac{k}{m} \\times (x-x')\\) is the image at that step.</li> <li>\\(\\frac{1}{m}\\) is a weighting factor that ensures that each step of the path is given equal importance in the approximation.</li> <li>For example, let's say we have an image of a bird and we want to understand the contribution of the pixel at position \\((10, 20)\\) towards the model's prediction that the image is a bird. We set the baseline pixel value to be zero and divide the path into 10 steps. We compute the partial derivative of the model output with respect to pixel \\((10, 20)\\) at each step of the path and weight each step by \\(\\frac{1}{10}\\) to obtain the approximation of IntegratedGrads for pixel \\((10, 20)\\). The resulting attribution value will give us an indication of how important that pixel is in the model's prediction.</li> </ul>"},{"location":"KB/Integrated%20Gradients/#baselines","title":"Baselines","text":"<ul> <li>replacing the constant color baseline with an alternative</li> <li>Gaussian Baseline</li> <li>Blur Baseline</li> <li>Visualizing the Impact of Feature Attribution Baselines</li> </ul>"},{"location":"KB/Inter-rater%20Agreement/","title":"Inter rater Agreement","text":""},{"location":"KB/Inter-rater%20Agreement/#inter-rater-agreement","title":"Inter-rater Agreement","text":"<ul> <li>A measurement of how often human raters agree when doing a task. If raters disagree, the task instructions may need to be improved. Also sometimes called inter-annotator agreement or inter-rater reliability.</li> </ul>"},{"location":"KB/Interactivity/","title":"Interactivity","text":""},{"location":"KB/Interactivity/#interactivity","title":"Interactivity","text":"<ul> <li>the ability of a model to be interactive with the user as one of the goals targeted by an explainable ML model.</li> <li>ability to tweak and interact with the models is what ensures success</li> </ul>"},{"location":"KB/Interneuron/","title":"Interneuron","text":""},{"location":"KB/Interneuron/#interneuron","title":"Interneuron","text":"<ul> <li>Association neuron</li> <li>impulse moves between sensory and motor neurons</li> <li>mostly multipolar</li> </ul>"},{"location":"KB/Interpolation/","title":"Interpolation","text":""},{"location":"KB/Interpolation/#interpolation","title":"Interpolation","text":"<ul> <li>1D piecewise linear interpolation</li> <li>Bilinear Interpolation</li> <li>Barycentric Interpolation</li> </ul>"},{"location":"KB/Interpretability%20and%20Explainability%20A%20Machine%20Learning%20Zoo%20Mini-tour/","title":"Interpretability and Explainability A Machine Learning Zoo Mini-tour","text":""},{"location":"KB/Interpretability%20and%20Explainability%20A%20Machine%20Learning%20Zoo%20Mini-tour/#interpretability-and-explainability-a-machine-learning-zoo-mini-tour","title":"Interpretability and Explainability A Machine Learning Zoo Mini-tour","text":"<p>@marcinkevicsInterpretabilityExplainabilityMachine2023</p>"},{"location":"KB/Interpretability%20vs%20Neuroscience/","title":"Interpretability vs Neuroscience","text":""},{"location":"KB/Interpretability%20vs%20Neuroscience/#interpretability-vs-neuroscience","title":"Interpretability Vs Neuroscience","text":"<ul> <li>Interpretability vs Neuroscience (rough note) -- colah's blog%20--%20colah's%20blog)%20--%20colah's%20blog)</li> </ul>"},{"location":"KB/Interpretability%20vs%20Neuroscience/#you-can-get-the-responses-of-all-neurons-for-arbitrarily-many-stimuli","title":"You Can Get the Responses of All Neurons for Arbitrarily Many Stimuli","text":"<ul> <li>In neuroscience, one is limited in the number of neurons they can record from, their ability to select the neurons they record, and the number of stimuli they can record responses to.</li> <li>For artificial neural networks, we can record the responses of all neurons to arbitrarily many stimuli</li> <li>Turn arounds are much faster than biological experiments</li> <li>There's no recording noise, No synaptic fatigue.</li> </ul>"},{"location":"KB/Interpretability%20vs%20Neuroscience/#not-only-do-you-have-the-connectome-you-have-the-weights","title":"Not Only Do You Have the Connectome, You Have the Weights!","text":"<ul> <li>A major undertaking in neuroscience is the attempt to access the connectome</li> <li>Even if they succeed, they won\u2019t know the weights of those connections</li> <li>With artificial neural networks, all the connections and weights are simply there for us to look at.</li> <li>And since we also know how these artificial neurons are computed, in principle we have everything we need to just reason through and understand the neural network.</li> </ul>"},{"location":"KB/Interpretability%20vs%20Neuroscience/#weight-tying-massively-reduces-the-number-of-unique-neurons","title":"Weight-tying Massively Reduces the Number of Unique Neurons!","text":"<ul> <li>weight-tying,</li> <li>force many neurons to have the same weights</li> <li>he most common use of this is in convolutional neural networks, where each neuron has translated copies of itself with the same weights.</li> <li>in ImageNet conv nets, weight-tying often reduces the number of unique neurons in early vision by 10,000x or even more</li> <li>This results in artificial neural networks having many fewer neurons for early vision than their biological counterparts</li> <li>This means we can just literally study every single neuron.</li> </ul>"},{"location":"KB/Interpretability%20vs%20Neuroscience/#establishing-causality-by-optimizing-the-input","title":"Establishing Causality by Optimizing the Input","text":"<ul> <li>one of the thorniest issues in understanding neurons in artificial networks is separating correlation from causation.</li> <li>Does a neuron detect a dog head? Or does it just detect part of a dog head?</li> <li>There's a second very closely related problem: we don't know what the space of likely functions a neuron might perform is.</li> <li>this is also a challenge in neuroscience.</li> <li>We create stimuli \u201cfrom scratch\u201d to strongly activate neurons (or combinations of neurons) in artificial neural networks, by starting with random noise and optimizing the input.</li> <li>The key property of feature visualization is that anything in the resulting visualization there because it caused the neuron to fire more</li> <li>If feature visualization gives you a fully formed dog head with eyes and ears arranged appropriately, it must be detecting an entire dog head</li> <li>If it just gives an eye, it's probably only (or at least primarily) responding to that.</li> <li>Recent efforts in neuroscience have tried to develop similar methods [], by using an artificial neural network as a proxy for a biological one.</li> <li>unclear they give you the same ability to establish a causal link.</li> <li>It seems hard to exclude the possibility that the resulting stimulus might have content which causes the artificial neurons predicting the biological neuron to fire more, but aren't causally necessary for the biological neuron to fire.</li> </ul>"},{"location":"KB/Interpretability%20vs%20Neuroscience/#interventions-ablations-and-edits","title":"Interventions, Ablations, and Edits","text":"<ul> <li>Optogenetics has been a major methodological advance for neuroscience in allowing neuroscientists to temporarily ablate neurons, or to force them to activate.</li> <li>Artificial neural networks are trivial to manipulate at the level of neurons</li> <li>One can easily ablate neurons or set them to particular activations</li> <li>But one can also do more powerful \"circuit editing\" where one modifies parameters at a finer grained level.</li> <li>In image generation, Bau et al., 2018 show that you can ablate neurons to remove objects like tress and windows from generated images</li> <li>In RL, Hilton et al., 2020 show that you can ablate features to blind an agent to a particular enemy while leaving other competencies in tact</li> <li>More recently, Cammarata et al, 2021 reimplements a large chunk of neural network from scratch, and then splices it into a model.</li> </ul>"},{"location":"KB/Interpretability%20vs%20Neuroscience/#we-can-study-the-exact-same-model","title":"We Can Study the Exact Same Model.","text":"<ul> <li>Neuroscientists might study a model organism species, but each brain they study has different neurons</li> <li>If one neuroscientist reports on an interesting neuron they found, other neuroscientists can't directly study that same neuron</li> <li>In fact, the neuroscientists studying the original neuron will quickly lose access to it: probes can't be left in indefinitely, organisms die, human subjects leave, and even setting that aside neurons change over time.</li> <li>Studying artificial networks, we can collaboratively reverse engineer the same \u201cbrain\", building on each other.</li> <li>we have a shared web of thousands of \"footholds\" into InceptionV1, consisting of neurons we understand fairly well and know the connections between, which makes it massively easier to explore</li> </ul>"},{"location":"KB/Interpretability/","title":"Interpretability","text":""},{"location":"KB/Interpretability/#interpretability","title":"Interpretability","text":"<ul> <li>ability to explain or to provide the meaning in understandable terms to a human</li> </ul>"},{"location":"KB/Interpretation%20of%20Neural%20networks%20is%20fragile/","title":"Interpretation of Neural networks is fragile","text":""},{"location":"KB/Interpretation%20of%20Neural%20networks%20is%20fragile/#interpretation-of-neural-networks-is-fragile","title":"Interpretation of Neural Networks is Fragile","text":"<ul> <li>Ghorbani et al</li> <li>@ghorbaniInterpretationNeuralNetworks2018</li> </ul>"},{"location":"KB/Interpreting%20Attention/","title":"Interpreting Attention","text":""},{"location":"KB/Interpreting%20Attention/#interpreting-attention","title":"Interpreting Attention","text":"<ul> <li>Attention Interpretability Across NLP Tasks</li> <li>empirically prove the hypothesis that attention weights are interpretable and are correlated with feature importance measures</li> <li>n both single and pair sequence tasks, the attention weights in samples with original weights do make sense in general</li> <li>However, in the former case, the attention mechanism learns to give higher weights to tokens relevant to both kinds of sentiment.</li> <li>They show that attention weights in single sequence tasks do not provide a reason for the prediction, which in the case of pairwise tasks, attention do reflect the reasoning behind model output</li> <li>BertViz repo</li> </ul>"},{"location":"KB/Interpretive%20Labor/","title":"Interpretive Labor","text":""},{"location":"KB/Interpretive%20Labor/#interpretive-labor","title":"Interpretive Labor","text":"<ul> <li>There\u2019s a tradeoff between the energy put into explaining an idea, and the energy needed to understand it.</li> <li>On one extreme, the explainer can painstakingly craft a beautiful explanation, leading their audience to understanding without even realizing it could have been difficult</li> <li>On the other extreme, the explainer can do the absolute minimum and abandon their audience to struggle.</li> <li>That is, really outstanding tutorials, reviews, textbooks, and so on.</li> <li>we often have a group of researchers all trying to understand each other</li> <li>Just like before, the cost of explaining stays constant as the group grows, but the cost of understanding increases with each new member</li> <li>At some size, the effort to understand everyone else becomes too much.</li> <li>As a defense mechanism, people specialize, focusing on a narrower area of interest.</li> <li>The maintainable size of the field is controlled by how its members trade off the energy between communicating and understanding.</li> <li>Research debt is the accumulation of missing interpretive labor.</li> <li>It\u2019s extremely natural for young ideas to go through a stage of debt, like early prototypes in engineering.</li> <li>The problem is that we often stop at that point.</li> <li>Young ideas aren\u2019t ending points for us to put in a paper and abandon.</li> <li>When we let things stop there the debt piles up.</li> <li>It becomes harder to understand and build on each other\u2019s work and the field fragments.</li> </ul>"},{"location":"KB/Interview%20Tips/","title":"Interview Tips","text":""},{"location":"KB/Interview%20Tips/#interview-tips","title":"Interview Tips","text":""},{"location":"KB/Interview%20Tips/#intro","title":"Intro","text":"<ul> <li>Name</li> <li>Do some sleuthing about the interviewer</li> </ul>"},{"location":"KB/Interview%20Tips/#introduce","title":"Introduce","text":"<ul> <li>I have always been a creative technologist</li> <li>tinkering, building experiences and products either on my vision or someone elses. Sharing my knowledge, teaching is important too</li> <li>masters, specialization - AI, CV and analytics</li> <li>Artist!</li> </ul>"},{"location":"KB/Interview%20Tips/#what-makes-you-unique","title":"What Makes You Unique?","text":""},{"location":"KB/Interview%20Tips/#introduce-yourself","title":"Introduce Yourself","text":"<ul> <li>hiring managers are context switching to your interview. they probably dont know jack about you. so tell them</li> <li>Who you are professionally rn. One sentence</li> <li>Some sentences about your experience or education. start with recent and then go back in time</li> <li>Why is this the best next step for me. Aka why do I want this job</li> </ul>"},{"location":"KB/Interview%20Tips/#in-x-years","title":"In X Years?","text":"<ul> <li>long term goals - align with the company</li> <li>dont say a higher position</li> <li>how will this position help you grow in a direction you are proud of</li> <li>learning the industry, go to person with X skill, learn more skills, \"mentor others\", bigger projects</li> <li>know my strenghts, new opportunities to learn in the company and stuff</li> </ul>"},{"location":"KB/Interview%20Tips/#why-do-you-want-this-job","title":"Why Do You want This Job?","text":"<ul> <li>the motivation</li> <li>the job, the role, the team</li> </ul>"},{"location":"KB/Interview%20Tips/#what-questions-for-the-interviewer","title":"What Questions for the Interviewer?","text":"<ul> <li>I did read the job description, but from your perspective how would you describe the role?</li> <li>what makes this role available?</li> <li>what kind of additional responsibilites can be gained over time?</li> <li>what can be expected in say the first few months?</li> <li>how do you measure sucess for this role?</li> <li>what have been the biggest challenges for the role?</li> <li>what are some mistakes people have made in this role before?</li> </ul>"},{"location":"KB/Interview%20Tips/#send-a-thank-you-email-in-24-hours","title":"Send a Thank You Email in 24 Hours","text":""},{"location":"KB/Intra%20cluster%20variance/","title":"Intra Cluster Variance","text":""},{"location":"KB/Intra%20cluster%20variance/#intra-cluster-variance","title":"Intra Cluster Variance","text":"<ul> <li>$\\(J = \\Sigma_{j=1}^K \\Sigma_{x \\in S_j} ||x - \\mu_j||^2\\)</li> <li>Measure of how much the points in a given cluster spread</li> </ul>"},{"location":"KB/Intra-Class%20Part%20Swapping/","title":"Intra-Class Part Swapping","text":""},{"location":"KB/Intra-Class%20Part%20Swapping/#intra-class-part-swapping","title":"Intra-Class Part Swapping","text":"<ul> <li>@zhangIntraClassPartSwapping2021</li> <li>replaces most attentive regions of one image by the other</li> <li>Attentive regions are extracted using a classification activation map (CAM), thresholded for the most prominent region</li> <li>The attentive region in the source image is scaled and translated according to the attentive region of the target image for region replacement</li> <li>The label information of the output is similar to the target image as this approach relies on augmenting similar class images.</li> </ul>"},{"location":"KB/Intravenous/","title":"Intravenous","text":""},{"location":"KB/Intravenous/#intravenous","title":"Intravenous","text":"<ul> <li>Administration of medication or fluids by vein</li> </ul>"},{"location":"KB/Intubation/","title":"Intubation","text":""},{"location":"KB/Intubation/#intubation","title":"Intubation","text":"<ul> <li>Medical insertion of a tube into the body, for example, into the throat to assist with breathing</li> </ul>"},{"location":"KB/Intuitive%20Color%20spaces/","title":"Intuitive Color spaces","text":""},{"location":"KB/Intuitive%20Color%20spaces/#intuitive-color-spaces","title":"Intuitive Color Spaces","text":""},{"location":"KB/Invariant%20Distribution/","title":"Invariant Distribution","text":""},{"location":"KB/Invariant%20Distribution/#invariant-distribution","title":"Invariant Distribution","text":"<ul> <li>If g is the PDF. T(x|y) is the PDF of the transition kernel. Homogenous Markov Chain. Then g is PDF of an invariant distribution of T(x|y) if</li> <li> \\[g(x) = \\int_{\\mathbb{R}^{k}}T(x|y)g(y)dy\\] </li> <li>Atleast one invariant distribution</li> <li>Ergodic</li> </ul>"},{"location":"KB/Inverse%20Kinematics/","title":"Inverse Kinematics","text":""},{"location":"KB/Inverse%20Kinematics/#inverse-kinematics","title":"Inverse Kinematics","text":"<ul> <li>which joint movements (q) are needed achieve a particular robot end effector pose (\u03be)  </li> <li>q = \u03ba\u22121(\u03be) : q = {qi,i \u2208 [1,\u2026,n]}</li> </ul>"},{"location":"KB/Inverse%20Reinforcement%20Learning/","title":"Inverse Reinforcement Learning","text":""},{"location":"KB/Inverse%20Reinforcement%20Learning/#inverse-reinforcement-learning","title":"Inverse Reinforcement Learning","text":"<ul> <li>Basically, IRL is about studying from humans.</li> <li>Inverse reinforcement learning is the sphere of studying an agent\u2019s objectives, values, or rewards with the aid of using insights of its behavior.</li> <li>We can fit a reward function with the use of professional demonstrations. Once a reward feature is fitted, we are able to use Policy Gradient, Model-based RL or different RL to locate the ideal policy.</li> <li>For example, we are able to compute the policy gradient with the use of the reward feature as opposed to sampled rewards. With the policy gradient calculated, we optimize the policy closer to the finest rewards gain.</li> <li>As part of the IRL, the task is to collect a set of human-generated driving data and extract an approximation of that human's reward function for the task. Of course, this approximation necessarily relates to a simplified driving model.</li> <li>As Ng and Russell put it, \"the reward function, rather than the guideline, is the most concise, robust, and transferable definition of the task\" because it quantifies how good or bad certain actions are. Once we have the right reward function, the problem is finding the right guideline and can be solved using standard reinforcement learning methods.</li> <li>For our autonomous car example, we would use human driving data to automatically learn the correct functional weights for the reward. Since the task is fully described by the reward function, we don't even need to know the details of human politics as long as we have the right reward function to optimize.</li> </ul>"},{"location":"KB/Inverse%20Square%20Law/","title":"Inverse Square Law","text":""},{"location":"KB/Inverse%20Square%20Law/#inverse-square-law","title":"Inverse Square Law","text":"<ul> <li>for force on a charge in an electric field of another charge: Force is proportional to the product of the charges and inversely proportional to the square of the distance between them</li> <li> \\[F_{E}= \\frac{\\frac{1}{4pe_{0}}Q_{1}Q_{2}}{r^{2}}\\] </li> <li>force on a mass in a gravitational field of another mass: Force is proportional to the product of the masses and inversely proportional to the square of the distance between them</li> <li> \\[F_{G}= -G \\frac{m_{1}m_{2}}{r^{2}}\\] </li> </ul>"},{"location":"KB/Ion%20Channel/","title":"Ion Channel","text":""},{"location":"KB/Ion%20Channel/#ion-channel","title":"Ion Channel","text":"<ul> <li>A pore in the membrane of a neuron that allows ions to pass through, helping to shape action potentials.</li> </ul>"},{"location":"KB/Isolating%20words/","title":"Isolating words","text":""},{"location":"KB/Isolating%20words/#isolating-words","title":"Isolating Words","text":"<ul> <li>words do not divide into smaller units</li> </ul>"},{"location":"KB/Isoline/","title":"Isoline","text":""},{"location":"KB/Isoline/#isoline","title":"Isoline","text":"<ul> <li>2D</li> <li>Contour line</li> <li> \\[\\{(x,y|f(x,y)=c\\}\\] </li> <li>Curve along function has constant value c</li> <li></li> <li>Marching Squares</li> <li></li> <li>No isoline inside cells with same signs</li> <li>only consider cells with different signs</li> <li>access look-up table for respective case</li> </ul>"},{"location":"KB/Isosurface/","title":"Isosurface","text":""},{"location":"KB/Isosurface/#isosurface","title":"Isosurface","text":"<ul> <li>Marching Cubes</li> <li>Marching Tetrahedra</li> <li>Fractional Anisotropy</li> <li></li> </ul>"},{"location":"KB/Isotropic%20Architectures/","title":"Isotropic Architectures","text":""},{"location":"KB/Isotropic%20Architectures/#isotropic-architectures","title":"Isotropic Architectures","text":"<ul> <li>(of an object or substance) having a physical property which has the same value when measured in different directions.</li> <li>And precisely that is what an isotropic architecture is. Isotropic architectures do not produce pyramid shaped data transformations, but rather\u00a0fixed\u00a0ones where data does not change in shape and size</li> <li>In other (simpler) words, when you take a look at the value going through an\u00a0isotropic\u00a0network, it doesn't change in size.</li> <li>Like Transformer , MLP-Mixer</li> </ul>"},{"location":"KB/Issues/","title":"Issues","text":""},{"location":"KB/Issues/#issues","title":"Issues","text":"<ul> <li>Multiple Local Minima</li> <li>Saddle Points</li> <li>Vanishingexploding gradients</li> <li>Image Data</li> <li>Fitting</li> <li>Freedom</li> <li>Bias Variance Dilemma</li> <li>Complex Geometry</li> <li>Lack of information</li> </ul>"},{"location":"KB/Iterative%20Closest%20Point/","title":"Iterative Closest Point","text":""},{"location":"KB/Iterative%20Closest%20Point/#iterative-closest-point","title":"Iterative Closest Point","text":"<ul> <li>Start from initial guess</li> <li>Iterate</li> <li>For each point on M, find closest point on P</li> <li>Find best transform for this correspondence Transform M</li> <li>Good initial guess -&gt; Converges to global minimum</li> <li>The ICP is applicable when we have a relatively good starting point in advance.</li> <li>Otherwise, it will be trapped into the first local minimum and the solution will be useless.</li> <li>Without pose information, ICP-based approaches are unable to recover the proper transformations because of the ambiguity in surface matching.</li> <li></li> </ul>"},{"location":"KB/Jaccard%20Distance/","title":"Jaccard Distance","text":""},{"location":"KB/Jaccard%20Distance/#jaccard-distance","title":"Jaccard Distance","text":"<ul> <li> \\[D(x,y) = 1- \\frac{x\\cup y}{x\\cap y}\\] </li> <li>The Jaccard index (or Intersection over Union) is a metric used to calculate the similarity and diversity of sample sets. It is the size of the intersection divided by the size of the union of the sample sets.</li> <li>In practice, it is the total number of similar entities between sets divided by the total number of entities.</li> <li>To calculate the Jaccard distance we simply subtract the Jaccard index from 1</li> <li>highly influenced by the size of the dat</li> <li>Large datasets can have a big impact on the index as it could significantly increase the union whilst keeping the intersection similar</li> <li>The Jaccard index is often used in applications where binary or binarized data are used</li> <li>deep learning model predicting segments of an image</li> <li>text similarity analysis to measure how much word choice overlap there is between documents</li> </ul>"},{"location":"KB/Jensen%20Shannon%20Divergence%20Consistency%20Loss/","title":"Jensen Shannon Divergence Consistency Loss","text":""},{"location":"KB/Jensen%20Shannon%20Divergence%20Consistency%20Loss/#jensen-shannon-divergence-consistency-loss","title":"Jensen Shannon Divergence Consistency Loss","text":"<ul> <li> <p>@linDivergenceMeasuresBased</p> </li> <li> <p>enforces smother neural network responses</p> </li> <li>stable, consistent and insensitive across range of inputs</li> <li> \\[ \\mathcal{L}(p_{orig}, y)+ \\lambda JS(p_{orig};p_{augmix1}; p_{augmix2}) \\] </li> <li> \\[ M = \\frac{p_{orig}+p_{augmix1}+ p_{augmix2}}{3} \\] </li> <li> \\[ JS(p_{orig}; p_{augmix1};p_{augmix2}) = \\frac{1}{3}(KL[p_{orig}||M||]+KL[p_{augmix1}||M||]+KL[p_{augmix2}||M||]) \\] </li> </ul>"},{"location":"KB/Joint%20Factor%20Analysis/","title":"Joint Factor Analysis","text":""},{"location":"KB/Joint%20Factor%20Analysis/#joint-factor-analysis","title":"Joint Factor Analysis","text":"<ul> <li>Front-end Factor Analysis for Speaker Verification</li> <li>Joint Factor Analysis (JFA)</li> <li>eature extractor to learn a low-dimensional speaker representation for speaker verification, which is also used to model session and channel effects/variabilities</li> <li>In this new space, a given speech utterance is represented by a new vector named total factors (called the identity-vector or the \u201ci-vector\u201d)</li> <li>The i-vector is thus a feature that represents the characteristics of the frame-level features\u2019 distributive pattern</li> <li>dimensionality reduction of the GMM supervector (although the GMM supervector is not extracted when computing the i-vector)</li> <li>extracted in a similar manner with the eigenvoice adaptation scheme or the JFA technique</li> <li>extracted per sentence</li> <li>Support-Vector-Machine-based system that uses the cosine kernel to estimate the similarity between the input data</li> <li>cosine similarity as the final decision score</li> <li>removed the SVM from the decision proces</li> <li>no speaker enrollment</li> <li>EER</li> <li>MinDCF</li> <li>NIST 2008 Speaker Recognition Evaluation dataset</li> <li>Up until d-vectors, the state-of-the-art speaker verification systems were based on the concept of i-vectors</li> </ul>"},{"location":"KB/Joint%20Interpolated%20Motion/","title":"Joint Interpolated Motion","text":""},{"location":"KB/Joint%20Interpolated%20Motion/#joint-interpolated-motion","title":"Joint Interpolated Motion","text":"<ul> <li>A method of coordinating the movement of the joints, such that all joints arrive at the desired location simultaneously. This method of servo control produces a predictable path regardless of speed and results in the fastest pick and place cycle time for a particular move.</li> </ul>"},{"location":"KB/Joint%20Motion%20Type/","title":"Joint Motion Type","text":""},{"location":"KB/Joint%20Motion%20Type/#joint-motion-type","title":"Joint Motion Type","text":"<ul> <li>Also known as Point-to-Point Motion, Joint Motion Type is a method of path interpolation that commands the movement of the robot by moving each joint directly to the commanded position so that all axis arrive to the position at the same time. Although the path is predictable, it will not be linear.</li> </ul>"},{"location":"KB/Joint%20Space/","title":"Joint Space","text":""},{"location":"KB/Joint%20Space/#joint-space","title":"Joint Space","text":"<ul> <li>a. Joint Space (or Joint Coordinates) is just a method of defining the position of the robot in terms of the value of each axis instead of as a TCP position. For example, the Home Position of a robot is often defined in Joint Space as each axis being at 0 degrees.</li> <li>b. The set of joint positions.</li> </ul>"},{"location":"KB/Joint%20Velocity/","title":"Joint Velocity","text":""},{"location":"KB/Joint%20Velocity/#joint-velocity","title":"Joint Velocity","text":"<ul> <li>Joint space trajectory is generally smoother than task space trajectory</li> <li></li> </ul>"},{"location":"KB/Jukebox/","title":"Jukebox","text":""},{"location":"KB/Jukebox/#jukebox","title":"Jukebox","text":"<ul> <li>generates music with singing in the raw audio domain</li> <li>earlier models in the text-to-music genre generated music symbolically in the form of a pianoroll which specifies timing, pitch and velocity.</li> <li>The challenging aspect is the non-symbolic approach where music is tried to be produced directly as a piece of audio</li> <li>the space of raw audio is extremely high dimensional which makes the problem very challenging</li> <li>the key issue is that modelling that raw audio produces long-range dependencies, making it computationally challenging to learn the high-level semantics of music.</li> <li>hierarchical VQ-VAE architecture to compress audio into a discrete space [14], with a loss function designed to retain the most amount of information.</li> <li>This model produces songs from very diferent genres such as rock, hip-hop and jazz.</li> </ul>"},{"location":"KB/KITTI/","title":"KITTI","text":""},{"location":"KB/KITTI/#kitti","title":"KITTI","text":"<ul> <li>collected from driving a car around a city which equipped with various sensors including high-resolution RGB camera, grayscale stereo camera, a 3D laser scanner, and highprecision GPS measurements and IMU accelerations from a combined GPS/IMU system </li> <li>Videos with various modalities captured by these sensors are available in this dataset.</li> </ul>"},{"location":"KB/KL%20Divergence/","title":"KL Divergence","text":""},{"location":"KB/KL%20Divergence/#kl-divergence","title":"KL Divergence","text":"<ul> <li>Classification</li> <li>Entropy + Cross Entropy</li> <li>Distribution Based metric</li> <li>Measures difference between two PDF</li> <li>We first define xlogx for a weird edge case \\(\\(x \\cdot \\log\\left( x \\right)\\)\\)</li> </ul> <p>Then entropy \\(\\(\\mathrm{sum}\\left( \\mathrm{xlogx}\\left( y \\right) \\right) \\cdot \\mathrm{//}\\left( 1, \\mathrm{size}\\left( y, 2 \\right) \\right)\\)\\)</p> <p>Then cce as defined before $$ - \\mathrm{sum}\\left( y \\cdot \\log\\left( \u0177 \\right) \\right)$$</p> <p>Finally KLD \\(\\(entropy + crossentropyloss\\)\\)</p> <ul> <li> \\[KL(p,q) = \\Sigma_x p(x) log\\frac{p(x)}{q(x)}\\] </li> </ul>"},{"location":"KB/KMeans/","title":"K Means","text":""},{"location":"KB/KMeans/#k-means","title":"K Means","text":"<ul> <li>Codebook vectors. No manifolds.</li> <li>Given: \\(\\((x_i)_{i= 1,..,N} \\in \\mathbb{R}^n\\)\\)</li> <li>Need : K clusters \\(\\(C_1 , \u2026 , C_K\\)\\)</li> <li>Randomly assign training points to K sets : \\(\\(S_j (j = 1, \u2026, K)\\)\\)</li> <li>Repeat:<ul> <li>For each set (\\(S_j\\)\\)<ul> <li>Mean \\(\\(\\mu_j = |S_j|^{-1} \\Sigma_{x \\in S_j} x\\)\\)</li> <li>Create new sets by putting points into set where \\(||x_i-\\mu_j||\\) is minimal</li> <li>If empty, dismiss and reduce K to K'</li> </ul> </li> </ul> </li> <li>Error quantity does not increase<ul> <li>Intra cluster variance</li> <li>Clusters are bounded by line Decision Boundaries and forms a Voronoi Cell</li> </ul> </li> <li>Does not work for curved boundaries</li> </ul>"},{"location":"KB/KMeans/#codebook-vector","title":"Codebook Vector","text":"<ul> <li>Each cluster represented by it</li> <li>Vector pointing to the mean of all vectors in the cluster</li> <li>Center of Gravity</li> </ul>"},{"location":"KB/Kalman%20Filter/","title":"Kalman Filter","text":""},{"location":"KB/Kalman%20Filter/#kalman-filter","title":"Kalman Filter","text":"<ul> <li>The standard Kalman filter is the optimum estimator when your system is linear and the system noise is Gaussian.</li> <li>linear systems with Gaussian noise</li> </ul>"},{"location":"KB/KeepAugment/","title":"KeepAugment","text":""},{"location":"KB/KeepAugment/#keepaugment","title":"KeepAugment","text":"<ul> <li>KeepAugment identifies the salient area in an image and assures the image generated by the augmentation strategies, for example, [Cutout], [RandAugment] [14], [CutMix] [82] or AutoAugment [13], contains salient region in it.</li> <li>standard augmentation may introduce distribution shifts</li> <li>increase fidelity of the augmented data</li> <li>use saliency maps to identify the regions of interest, then make sure those regins are not affected by the augmentation</li> <li>Given image \\(x\\) and label logit value \\(l_{y}\\) , \\(g_{i,j}(x,y)\\) to be the vanilla gradient \\(|\\nabla_{x}l_{y}(s)|\\) </li> <li>For RGB, channel wise maximum to get single saliency value for each pixel \\((i,j)\\)</li> </ul>"},{"location":"KB/KeepAugment/#selective-cut","title":"Selective Cut","text":"<ul> <li>Randomly sample regions \\(S\\) to be cut until importance score \\(\\mathcal{I}(S, x, y)\\) is smaller than threshold \\(\\tau\\)  $$ \\tilde x= (1-M(S)) \\odot x$$</li> <li>where \\(M(S) = |M_{ij}(S)|_{ij}\\) is the binary mask for \\(S\\), \\(M_{ij} = \\mathbb{I}((i,j) \\in S)\\)</li> </ul>"},{"location":"KB/KeepAugment/#selective-paste","title":"Selective Paste","text":"<ul> <li>image level augmented data \\(x' = \\mathcal{A}(x)\\) , uniformly sample region \\(S\\) that satisfies \\(\\mathcal{I}(S,x,y) &gt; \\tau\\) for a threshold \\(\\tau\\) </li> <li>paste the region \\(S\\) of the original image  \\(x\\) to \\(x'\\) <ul> <li> \\[\\tilde x = M(S) \\odot x + (1-M(S)) \\odot x'\\] </li> <li>\\(M_{ij}(S) = \\mathbb{I}((i,j) \\in S)\\) is the binary mask of the region \\(S\\)</li> </ul> </li> <li>we choose our threshold \\(\\tau\\) in an adaptive way.</li> <li>given an image and consider an region size h \u00d7 w of interest, we first calculate the importance scores of all possible candidate regions, following Eq. 1; then we set our threshold to be the \\(\\tau - quantile\\) value of all the importance scores \\(\\mathcal{I}(S,x,y)\\) of all candidate regions. For selective-cut, we uniformly keep sampling a mask region S until its corresponding score \\(\\mathcal{I}(S,x,y)\\) is smaller than the threshold. For selective-paste, we uniformly sample a region S with importance score is greater than the threshold</li> </ul>"},{"location":"KB/KeepAugment/#efficient-implementation-of-keepaugment","title":"Efficient Implementation of KeepAugment","text":""},{"location":"KB/KeepAugment/#low-resolution-based-approximation","title":"Low Resolution Based Approximation","text":"<ul> <li>we proceed as follows: a) for a given image x, we first generate a lowresolution copy and then calculate its saliency map; b) we map the low-resolution saliency maps to their corresponding original resolution</li> <li>This allows us to speed up the saliency maps calculation significantly, e.g., on ImageNet, we achieve roughly 3\u00d7 computation cost reduction by reducing the resolution from 224 to 112.</li> </ul>"},{"location":"KB/KeepAugment/#early-classification-head-based-approximation","title":"Early Classification Head Based Approximation","text":"<ul> <li>In practice, we add an additional average pooling layer and a linear head after the first block of our networks evaluated</li> <li>We achieve about 3\u00d7 computation cost reduction in computing saliency maps</li> </ul>"},{"location":"KB/KeepAugment/#region-level-augmentation","title":"Region-Level Augmentation","text":"<ul> <li>including Cutout [8] and random erasing [45], work by randomly masking out or modifying rectangular regions of the input images</li> <li>This procedure could be conveniently formulated as applying randomly generated binary masks to the original inputs</li> <li>Precisely, consider an input image x of size H \u00d7 W, and a rectangular region S of the image domain. Let M(S) = [Mij (S)]ij be the binary mask of S with Mij (S) = I((i, j) \u2208 S)</li> <li>Then the augmented data can be generated by modifying the image on region S, yielding images of form x\u2032 = (1 \u2212 M(S)) \u2299 x + M(S) \u2299 \u03b4, where \u2299 is element-wise multiplication, and \u03b4 can be either zeros (for Cutout) or random numbers (for random erasing)</li> </ul>"},{"location":"KB/KeepAugment/#image-level-augmentation","title":"Image-Level Augmentation","text":"<ul> <li>Exploiting the invariance properties of natural images, image-level augmentation methods apply label-invariant transformations on the whole image, such as solarization, sharpness, posterization, and color normalization</li> <li>often manually designed and heuristically chosen</li> <li>Recently, AutoAugment [4] applies reinforcement learning to automatically search optimal compositions of transformations</li> <li>Several subsequent works, including RandAugment [5], Fast AutoAugment [18], alleviate the heavy computational burden of searching on the space of transformation policies by designing more compact search spaces</li> </ul>"},{"location":"KB/KeepAugment/#data-augmentation-and-its-trade-offs","title":"Data Augmentation and Its Trade-offs","text":"<ul> <li>Although data augmentation increases the effective size of data, it may inevitably cause loss of information and introduce noise and ambiguity if the augmentation is not controlled properly</li> <li>To study this phenomenon empirically, we plot the train and testing accuracy on CIFAR-10 [16] when we apply Cutout with increasingly large cutout length in Figure 2(a), and RandAugment with increasing distortion magnitude </li> <li>As typically expected, the generalization (the gap between the training and testing accuracy on clean data) improves as the magnitude of the transform increases in both cases</li> <li>However, when the magnitudes of the transform are too large (\u2265 16 for Cutout and \u2265 12 for RandAugment ), the training accuracy (blue line), and hence the testing accuracy (red line), starts to degenerate, indicating that augmented data no longer faithfully represent the clean training data in this case, such that the training loss on augmented data no longer forms a good surrogate of the training loss on the clean data.</li> </ul>"},{"location":"KB/KeepAugment/#images","title":"Images","text":""},{"location":"KB/Kernel%20Filters/","title":"Kernel Filters","text":""},{"location":"KB/Kernel%20Filters/#kernel-filters","title":"Kernel Filters","text":"<ul> <li>sharpen and blur images</li> <li>These filters work by sliding an n \u00d7 n matrix across an image with either a Gaussian blur filter, which will result in a blurrier image, or a high contrast vertical or horizontal edge filter which will result in a sharper image along edges</li> <li>Intuitively, blurring images for Data Augmentation could lead to higher resistance to motion blur during testing</li> <li>Additionally, sharpening images for Data Augmentation could result in encapsulating more details about objects of interest.</li> <li>Kang et al. experiment with a unique kernel filter that randomly swaps the pixel values in an n\u00d7n sliding window. They call this augmentation technique PatchShuffle Regularization</li> </ul>"},{"location":"KB/Kernel%20Support%20Vector%20Machines%20%28KSVMs%29/","title":"Kernel Support Vector Machines (KSVMs)","text":""},{"location":"KB/Kernel%20Support%20Vector%20Machines%20%28KSVMs%29/#kernel-support-vector-machines-ksvms","title":"Kernel Support Vector Machines (KSVMs)","text":"<ul> <li>A classification algorithm that seeks to maximize the margin between positive and negative classes by mapping input data vectors to a higher dimensional space. For example, consider a classification problem in which the input dataset has a hundred features. To maximize the margin between positive and negative classes, a KSVM could internally map those features into a million-dimension space. KSVMs uses a loss function called hinge loss.</li> </ul>"},{"location":"KB/Kernel%20Visualization/","title":"Kernel Visualization","text":""},{"location":"KB/Kernel%20Visualization/#kernel-visualization","title":"# Kernel Visualization","text":"<ul> <li>Qualitatively visualize the kernels of the first convolution layer learned with the pretext tasks and compare the kernels from supervised model </li> <li>similarity of the kernels learned by supervised and selfsupervised models are compared to indicate the effectiveness of self-supervised methods</li> </ul>"},{"location":"KB/Ketamine/","title":"Ketamine","text":""},{"location":"KB/Ketamine/#ketamine","title":"Ketamine","text":"<ul> <li>A powerful anesthetic drug, originally manufactured for veterinary use, that has been shown to be an effective treatment for major depressive disorder, especially in patients who do not respond well to traditional antidepressant medications.</li> </ul>"},{"location":"KB/Kickstart%20AI/","title":"Kickstart AI","text":""},{"location":"KB/Kickstart%20AI/#kickstart-ai","title":"Kickstart AI","text":"<p>It is not every day that you find an AI company that not only wants to make a real-world impact but also cares about responsible AI. I found out about Kickstart.AI and the hackathons from some classmates (who are from my course at the RUG) who interned with you recently. Their project was on \"Using Data to Predict Food Insecurity.\" (Shray Juneja,Chaoyi Wang, and Lonneke Pulles study AI at the RUG as well.) Looking at the projects that Kickstart is involved in, it is obvious just how much talent and hard work is behind each of them. I really want to take on the challenge and contribute to making some awesome ideas a reality while being mindful of the societal impact and explainability of each of the models used.</p> <p>My expertise is a combination of data analytics and computer vision, and as of a month ago, I also have a Master in Artificial Intelligence from the University of Groningen. I am familiar with the tools required for basic and advanced AI and analytics from internships, research projects, papers, freelance work, and many personal projects. I love hackathons, and truly think that they bring out the best in every member of a team. That being said, what I love the most is building prototypes of ideas. Be it an AI-powered credit scoring model, a model that converts between materials (e.g., glass to wood), or applications powered by LLMs. Any idea is fair game. But I also care about how any of the solutions that I am part of affect the end users. My master thesis was on XAI, and I firmly believe that an AI model needs a detailed understanding of biases before production, another aspect that I am familiar with.</p> <p>I have a lot to learn, but as an AI developer, we are always students. It is not every day you find a position that you enjoy and also think you can contribute something to, and I sincerely hope you give me a chance!</p>"},{"location":"KB/Kinesthetic%20Teaching/","title":"Kinesthetic Teaching","text":""},{"location":"KB/Kinesthetic%20Teaching/#kinesthetic-teaching","title":"Kinesthetic Teaching","text":"<ul> <li>H. Kasaei et al., \u201cInteractive open-ended object, affordance and grasp learning for robotic manipulation.\u201d ICRA 2019.</li> <li>Formulate object grasping as a supervised learning problem,  </li> <li>An appropriate grasp configuration can be learned from human demonstrations</li> <li>Primary assumption -&gt; familiar objects can be grasped in a similar way.</li> <li>Heightmaps Kinesthetic</li> <li>Familar Object Grasping Object Viiew recog</li> </ul>"},{"location":"KB/Kinetic%20Energy/","title":"Kinetic Energy","text":""},{"location":"KB/Kinetic%20Energy/#kinetic-energy","title":"Kinetic Energy","text":"<ul> <li>half x mass x (velocity squared)</li> <li> \\[E_{K}= \\frac{1}{2}mv^{2}\\] </li> </ul>"},{"location":"KB/Kinetic%20Friction/","title":"Kinetic Friction","text":""},{"location":"KB/Kinetic%20Friction/#kinetic-friction","title":"Kinetic Friction","text":"<ul> <li> \\[F_{k} \\leq \\mu _{k}F_{N}\\] </li> <li>\\(F_{k}\\) is kinetic friction</li> <li>\\(F_{N}\\) is normal force</li> <li>\\(\\mu _s\\) is coefficient of friction</li> </ul>"},{"location":"KB/Kinetics/","title":"Kinetics","text":""},{"location":"KB/Kinetics/#kinetics","title":"Kinetics","text":"<ul> <li>large-scale, highquality dataset for human action recognition in videos </li> <li>500, 000 video clips covering 600 human action classes with at least 600 video clips for each action class </li> <li>Each video clip lasts around 10 seconds and is labeled with a single action class.</li> </ul>"},{"location":"KB/Klue%20ML%20Engineer/","title":"Klue ML Engineer","text":"","tags":["jobs"]},{"location":"KB/Klue%20ML%20Engineer/#klue-ml-engineer","title":"Klue ML Engineer","text":"<ul> <li>We are looking for Machine Learning Engineers to work with our team to deliver high quality products in the most efficient way.  </li> </ul> <p>We build machine learning services and data pipelines to automatically extract insights about competitors from both public and internal data sources. Every day, our services process millions of data points, including news articles, press releases, webpage changes, Slack posts, emails, reviews, CRM opportunities, and user actions. We utilize a broad array of ML techniques, including classification, clustering, recommendation, summarization, prompt engineering, vector search, and retrieval augmented generation.  </p> <p>\ud83d\udca1Klue + You?  </p> <p>Q: Klue who?  </p> <p>A: We\u2019re Klue and from a technical perspective, Klue\u2019s mission is to descale huge amounts of data to the human level, so people can process it and make use of it. Klue is that trusted intermediary, right now it\u2019s proven for sales enablement, but tomorrow it\u2019s all teams enablement.  </p> <p>Q: What level of experience are we looking for?  </p> <p>A: Right now, we are looking for experienced senior-level Machine Learning Engineers.  </p> <p>Q: What are we working on?  </p> <p>A: Services for collecting, processing and generating timely, relevant intel that is accurately linked to competitors, products, industries, and people. Our Machine Learning Engineers are primarily focused on the training, evaluation, and deployment of models to label, score, cluster, and generate insights.  </p> <p>Q: What technologies do we use?  </p> <p>A: Python, Transformers, Pytorch, Hugging Face, Spacy, Sklearn, Pinecone, Kubeflow, Vertex AI, BentoML, Aporia, JS, PostgreSQL, Elasticsearch, Redis, GCP, BigQuery, Docker/Kubernetes, Github, GPT.  </p> <p>We believe in using whatever tools make sense to get the job done and support our game-changing innovation.  </p> <p>Q: What skills do you bring?  </p> <ul> <li>You are an expert on the landscape of transformer models and are proficient with popular ML frameworks such as PyTorch, Hugging Face, or Scikit-Learn.</li> <li>You stay up to date on recent advances with LLMs and you demonstrate astute judgment in deciding whether to train a model with a custom architecture or leverage GPT.</li> <li>You ensure your experiments are reproducible, balancing swift discovery with scientific rigor.</li> <li>You are proficient in designing, implementing, and deploying RESTful APIs and you have experience with (non)relational and vector databases.</li> <li>You demonstrate good judgment when making architectural decisions and you understand how those decisions fit into the bigger picture  </li> </ul> <p>Q: What about total compensation &amp; benefits?  </p> <ul> <li>Benefits. We currently have a pension plan for our EU team</li> <li>Time off. Take what you need. We want the team to prioritize wellness and avoid burnout. We want to also give individuals autonomy to choose how and when they take vacation. We understand and respect that everyone\u2019s needs for time off are different, just like our team</li> </ul>","tags":["jobs"]},{"location":"KB/Knowledge%20Component/","title":"Knowledge Component","text":""},{"location":"KB/Knowledge%20Component/#knowledge-component","title":"Knowledge Component","text":"<ul> <li>A knowledge component can be a principle, a concept, a rule, a procedure, a fact, an association or any other fragment of task-specific information.</li> <li>Despite the connotations of knowledge, a knowledge component can be incorrect, in that instructors would rather that students not apply this knowledge component while achieving a task.</li> </ul>"},{"location":"KB/Knowledge%20Distillation%20Survey%202021/","title":"Knowledge Distillation Survey 2021","text":""},{"location":"KB/Knowledge%20Distillation%20Survey%202021/#knowledge-distillation-survey-2021","title":"Knowledge Distillation Survey 2021","text":"<ul> <li>model compression and acceleration techniques</li> <li>Low-rank factorization</li> <li>Transferred compact convolutional filters</li> <li>To address this issue, Bucilua et al. (2006) first proposed model compression to transfer the information from a large model or an ensem- ble of models into training a small model without a significant drop in accuracy. The knowledge transfer between a fully-supervised teacher model and a stu- dent model using the unlabeled data is also intro- duced for semi-supervised learning (Urner et al., 2011).</li> <li>The learning of a small model from a large model is later formally popularized as knowledge distilla- tion (Hinton et al., 2015). In knowledge distillation, a small student model is generally supervised by a large teacher model (Bucilua et al., 2006; Ba and Caruana, 2014; Hinton et al., 2015; Urban et al., 2017).</li> <li>The main idea is that the student model mimics the teacher model in order to obtain a competitive or even a superior performance. The key problem is how to transfer the knowledge from a large teacher model to a small student model. Basically, a knowledge distillation system is composed of three key components: knowledge, dis- tillation algorithm, and teacher-student architecture.</li> <li>Successful distillation relies on data geometry, optimization bias of distillation objective and strong monotonicity of the student classifier</li> <li>quantified the extraction of visual concepts from the intermediate layers of a deep neural network, to explain knowledge distillation (Cheng et al., 2020). Ji &amp; Zhu theoretically explained knowledge distillation on a wide neural network from the respective of risk bound, data efficiency and imperfect teacher (Ji and Zhu., 2020).</li> <li>Knowledge distillation has also been explored for label smoothing, for assessing the accuracy of the teacher and for obtaining a prior for the optimal output layer geometry (Tang et al., 2020).</li> <li>Furthermore, the knowledge transfer from one model to another in knowledge distillation can be extended to other tasks, such as adversar- ial attacks (Papernot et al., 2016), data augmenta- tion (Lee et al., 2019a; Gordon and Duh, 2019), data privacy and security (Wang et al., 2019a).</li> <li>A vanilla knowledge distillation uses the logits of a large deep model as the teacher knowledge (Hinton et al., 2015; Kim et al., 2018; Ba and Caruana, 2014; Mirzadeh et al., 2020)</li> <li>Further- more, the parameters of the teacher model (or the connections between layers) also contain another knowl- edge (Liu et al., 2019c)</li> <li>Response Based Knowledge</li> <li>Feature Based Knowledge</li> </ul>"},{"location":"KB/Knowledge%20Distillation/","title":"Knowledge Distillation","text":""},{"location":"KB/Knowledge%20Distillation/#knowledge-distillation","title":"Knowledge Distillation","text":"<ul> <li>Teacher model to help train the student model</li> <li>Teacher is often pre trained</li> <li>Student tries to imitate teacher</li> <li>Distillation Loss</li> <li>Knowledge Distillation Survey 2021</li> <li>Distilling the Knowledge in a Neural Network</li> </ul>"},{"location":"KB/Kvasir%20Dataset/","title":"Kvasir Dataset","text":""},{"location":"KB/Kvasir%20Dataset/#kvasir-dataset","title":"Kvasir Dataset","text":"<ul> <li>Simula Datasets - Kvasir #Roam-Highlights</li> <li>dataset containing images from inside the gastrointestinal (GI) tract</li> <li>The collection of images are classified into three important anatomical landmarks and three clinically significant findings.</li> <li>two categories of images related to endoscopic polyp removal</li> <li>The dataset consist of the images with different resolution from 720x576 up to 1920x1072 pixels</li> <li>Some of the included classes of images have a green picture in picture illustrating the position and configuration of the endoscope inside the bowel, by use of an electromagnetic imaging system</li> </ul>"},{"location":"KB/LASER/","title":"LASER","text":""},{"location":"KB/LASER/#laser","title":"LASER","text":"<ul> <li>Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond</li> <li>joint multilingual sentence representations</li> <li>LASER</li> <li>Language-Agnostic SEntence Representations</li> <li>93 languages, belonging to more than 30 different families and written in 28 different scripts</li> <li>universal language agnostic sentence embeddings</li> <li>train a single encoder to handle multiple languages, so that semantically similar sentences in different languages are close in the embedding space</li> <li>single BiLSTM encoder with a shared BPE vocabulary for all languages</li> <li>coupled with an auxiliary decoder and trained on publicly available parallel corpora</li> <li>learn a classifier on top of the resulting embeddings using English annotated data only, and transfer it to any of the 93 languages without any modification</li> <li>XNLI</li> <li>MLDoc</li> <li>BUCC</li> <li>test set of aligned sentences in 112 languages</li> </ul>"},{"location":"KB/LASER/#laser_1","title":"Laser","text":"<ul> <li>Acronym for Light Amplification by Stimulated Emission of Radiation. A device that produces a coherent monochromatic beam of light which is extremely narrow and focused but still within the visible light spectrum. This is commonly used as a non-contact sensor for robots. Robotic applications include: distance finding, identifying accurate locations, surface mapping, bar code scanning, cutting, welding etc.</li> </ul>"},{"location":"KB/LDA/","title":"LDA","text":""},{"location":"KB/LDA/#lda","title":"LDA","text":""},{"location":"KB/LDA/#steps","title":"Steps","text":"<ul> <li>Compute the\u00a0dd-dimensional mean vectors for the different classes from the dataset.</li> <li>Compute the scatter matrices (in-between-class and within-class scatter matrix).</li> <li>Compute the eigenvectors \\((e_1,e_2,...,e_de_1,e_2,...,e_d)\\) and corresponding eigenvalues \\((\u03bb_1,\u03bb_2,...,\u03bb_d\u03bb_1,\u03bb_2,...,\u03bb_d)\\) for the scatter matrices.</li> <li>Sort the eigenvectors by decreasing eigenvalues and choose\u00a0\\(k\\)\u00a0eigenvectors with the largest eigenvalues to form a\u00a0\\(d\u00d7k\\)\u00a0dimensional matrix\u00a0\\(W\\)\u00a0(where every column represents an eigenvector).</li> <li>Use this\u00a0\\(d\u00d7k\\) eigenvector matrix to transform the samples onto the new subspace. This can be summarized by the matrix multiplication:\u00a0\\(Y=X\u00d7WY=X\u00d7W\\)\u00a0(where\u00a0\\(X\\)\u00a0is a\u00a0\\(n\u00d7d\\)-dimensional matrix representing the\u00a0\\(n\\)\u00a0samples, and\u00a0\\(y\\)\u00a0are the transformed\u00a0\\(n\u00d7k\\)-dimensional samples in the new subspace).</li> </ul>"},{"location":"KB/LIME/","title":"LIME","text":""},{"location":"KB/LIME/#lime","title":"LIME","text":"<ul> <li>@ribeiroWhyShouldTrust2016</li> <li>novel model-agnostic modular and extensible explanation technique that explains the predictions of any classifier in an interpretable and faithful manner</li> <li>learning an interpretable model locally around the prediction</li> <li>SP-LIME</li> <li>method to explain models by selecting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem and providing a global view of the model to users</li> <li>flexibility of these methods by explaining different models for text (e.g random forests) and image classification (e.g neural networks)</li> <li>usefulness of explanations is shown via novel experiments, both simulated and with human subjects</li> <li></li> </ul>"},{"location":"KB/LLM%20Guide/","title":"LLM Guide","text":"","tags":["llm"]},{"location":"KB/LLM%20Guide/#llm-guide","title":"LLM Guide","text":"<ul> <li>Refer to Complete AI Pipeline for extra steps</li> </ul>","tags":["llm"]},{"location":"KB/LLM%20Guide/#useful-types","title":"Useful Types","text":"","tags":["llm"]},{"location":"KB/LLM%20Guide/#training","title":"Training","text":"","tags":["llm"]},{"location":"KB/LLM%20Guide/#data-intake","title":"Data Intake","text":"","tags":["llm"]},{"location":"KB/LLM%20Guide/#deployment","title":"Deployment","text":"","tags":["llm"]},{"location":"KB/LLM%20Guide/#llm-metrics","title":"LLM Metrics","text":"","tags":["llm"]},{"location":"KB/LLM%20Guide/#bias","title":"Bias","text":"","tags":["llm"]},{"location":"KB/LLM%20Guide/#gui-tools","title":"GUI Tools","text":"<ul> <li>Azure AI Studio (PromptFlow)<ul> <li>PromptFlow</li> <li>PromptFlow RAG</li> </ul> </li> <li>Azure Open AI</li> <li>Azure Cognitive Search</li> <li>Azure Machine Learning</li> </ul>","tags":["llm"]},{"location":"KB/LRP/","title":"LRP","text":""},{"location":"KB/LRP/#lrp","title":"LRP","text":""},{"location":"KB/LaMDA/","title":"LaMDA","text":""},{"location":"KB/LaMDA/#lamda","title":"LaMDA","text":"<ul> <li>language model for dialog applications</li> <li>family of transformer-based neural language models specialized for dialog which have up to 137B parameters and are pre-trained on 1.56T words of public dialog data and web text.</li> <li>Fine-tuning can enable for safety and factual grounding of the model</li> <li>Only 0.001% of training data was used for fine-tuning, which is a great achievement of the model</li> <li>dialog modes take advantage of Transformers' ability to present long-term dependencies in text</li> <li>generally very well-suited for model scaling</li> <li>use of a single model to perform multiple tasks: it generates several responses, which are filtered for safety, grounded on an external knowledge source and reranked to find the highest-quality response.</li> </ul>"},{"location":"KB/Label%20Encoding/","title":"Label Encoding","text":""},{"location":"KB/Label%20Encoding/#label-encoding","title":"Label Encoding","text":"<ul> <li>also called Integer Encoding</li> <li>Each unique category is assigned an integer value</li> <li>e.g. \"red\" \u2192 0, \"blue\" \u2192 1, \u2026</li> <li>easy reversible</li> <li>can only be used when a ordinal relationship between the labels exist, e.g. winner ranking in string (\"first\", \"second\", \"third\")<ul> <li>if not and still used, can result in poor performance and unexpected results</li> </ul> </li> <li>numeric representations have a natural ordered relationship between each other and the models are able to understand that relationship</li> </ul>"},{"location":"KB/Label%20Smoothing/","title":"Label Smoothing","text":""},{"location":"KB/Label%20Smoothing/#label-smoothing","title":"Label Smoothing","text":"<ul> <li>Dense layer is generally the last one and combined with soft max leads to a Probability distribution</li> <li>Assume true label to be y, then a truth Probability distribution would be \\(p_i=1\\) If i=y and 0 otherwise</li> <li>During training, minimize negative Cross Entropy loss to make these distributions similar</li> <li>We know, \\(\\(\\mathscr{l}(p,q) = -log p_y = -z_y + log(\\Sigma^{K}_{i=1}exp(z_i))\\)\\)</li> <li>Where the optimal solution is \\(z^{\\ast}_{y}=\\inf\\)<ul> <li>The output scores are encouraged to be distinctive which leads to overfitting</li> <li>Leads to</li> </ul> </li> <li>Instead \\(\\(\\cases{1-\\epsilon&amp; if i=1\\\\\\frac{\\epsilon}{(K-1)} &amp; \\text{otherwise}}\\)\\)</li> <li>The optimal Solution is<ul> <li>\\(log((K-1)(1-\\epsilon)/ \\epsilon)+\\alpha\\) if \\(i=y\\)</li> <li>\\(\\alpha\\) otherwise<ul> <li>Any real number</li> <li>Finite output from the last layer that generalizes well</li> </ul> </li> </ul> </li> <li>If \\(\\epsilon =0\\) , \\(log((k-1)\\frac{1-\\epsilon}{\\epsilon})\\) is \\(\\infty\\)</li> <li>As \\(\\epsilon\\) increases, the gap decreases</li> <li>If \\(\\epsilon=\\frac{K-1}{K}\\), all optimizal \\(z^{\\ast}_{i}\\) are identical</li> </ul>"},{"location":"KB/Label%20bias/","title":"Label bias","text":""},{"location":"KB/Label%20bias/#label-bias","title":"Label Bias","text":"<ul> <li>This comes from the fact that semantic categories are often poorly defined, and different labellers may assign differing labels to the same type of object [11] (e.g. \"grass\" vs. \"lawn\", \"painting\" vs. \"picture\").</li> </ul>"},{"location":"KB/Labeled%20Faces%20in%20the%20Wild/","title":"Labeled Faces in the Wild","text":""},{"location":"KB/Labeled%20Faces%20in%20the%20Wild/#labeled-faces-in-the-wild","title":"Labeled Faces in the Wild","text":"<ul> <li>vis-www.cs.umass.edu/lfw/</li> </ul>"},{"location":"KB/Lack%20of%20information/","title":"Lack of Information","text":""},{"location":"KB/Lack%20of%20information/#lack-of-information","title":"Lack of Information","text":"<ul> <li>Data does not show how to extract optimal info</li> <li>Curse Of Dimensionality</li> </ul>"},{"location":"KB/Ladle%20Gripper/","title":"Ladle Gripper","text":""},{"location":"KB/Ladle%20Gripper/#ladle-gripper","title":"Ladle Gripper","text":"<ul> <li>An end-effector, which acts as a scoop. It is commonly used to scoop up liquids, transfer it to a mold and pour the liquid into the mold. Common for handling molten metal under hazardous conditions</li> </ul>"},{"location":"KB/Lagrangian%20Coherent%20Structure/","title":"Lagrangian Coherent Structure","text":""},{"location":"KB/Lagrangian%20Coherent%20Structure/#lagrangian-coherent-structure","title":"Lagrangian Coherent Structure","text":"<ul> <li>Lagrangian Grid</li> <li></li> </ul>"},{"location":"KB/Lagrangian%20Grid/","title":"Lagrangian Grid","text":""},{"location":"KB/Lagrangian%20Grid/#lagrangian-grid","title":"Lagrangian Grid","text":"<ul> <li>Focus on individual particles</li> <li>Attached are position, velocity, and other properties</li> <li>Explicit position</li> <li></li> </ul>"},{"location":"KB/Language%20Identification/","title":"Language Identification","text":""},{"location":"KB/Language%20Identification/#language-identification","title":"Language Identification","text":"<ul> <li>Identifying the language of the document</li> <li>Documents could be multilingual at the sentence level or paragraph level too</li> <li>Unique Character Set</li> <li>Shared Character Set</li> <li>Byte Range Distribution used for Character Set Identification</li> <li>sort the bytes in a \ufb01le by frequency count and use the sorted list as a signature vector for comparison via an n-gram model</li> </ul>"},{"location":"KB/Language%20dependence/","title":"Language dependence","text":""},{"location":"KB/Language%20dependence/#language-dependence","title":"Language Dependence","text":"<ul> <li>Range of orthographic conventions used in written languages to denote the boundaries between linguistic units such as syllables, words, or sentences</li> <li>Language Identification</li> </ul>"},{"location":"KB/Laplacian%20Grid%20Smoothing/","title":"Laplacian Grid Smoothing","text":""},{"location":"KB/Laplacian%20Grid%20Smoothing/#laplacian-grid-smoothing","title":"Laplacian Grid Smoothing","text":"<ul> <li>new position is based on neighbor positions</li> <li> \\[p_{i}=\\frac{1}{N}\\Sigma_{i\u2026j}p_{j}\\] </li> </ul>"},{"location":"KB/Large%20Batch%20Training/","title":"Large Batch Training","text":""},{"location":"KB/Large%20Batch%20Training/#large-batch-training","title":"Large Batch Training","text":"<ul> <li>Generally slows down training</li> <li>If convex, convergence rate decreases with increase in batch size</li> <li>Learning Rate Scheduling</li> <li>Modified Batch Normalization with \\(\\gamma=0\\) for all BNs at the end of a residual block that micmics networks with less Layers and is easier to train at the start</li> <li>No bias decay</li> </ul>"},{"location":"KB/Large%20Kernel%20in%20Attention/","title":"Large Kernel in Attention","text":""},{"location":"KB/Large%20Kernel%20in%20Attention/#large-kernel-in-attention","title":"Large Kernel in Attention","text":"<ul> <li>self-attention can be viewed as a global depth-wise kernel that enables each layer to have a global receptive field.</li> <li>Swin Transformer (Liu et al., 2021e) is a ViTs variant that adopts local attention with a shifted window manner</li> <li>greatly improve the memory and computation efficiency with appealing performance</li> <li>Since the size of attention windows is at least 7, it can be seen as an alternative class of large kernel</li> <li>recent work (Guo et al., 2022b) proposes a novel large kernel attention module that</li> <li>uses stacked depthwise, small convolution, dilated convolution as well as pointwise convolution to capture both local and global structure</li> </ul>"},{"location":"KB/Large%20Kernel%20in%20Convolution/","title":"Large Kernel in Convolution","text":""},{"location":"KB/Large%20Kernel%20in%20Convolution/#large-kernel-in-convolution","title":"Large Kernel in Convolution","text":"<ul> <li>Global Convolutional Network (GCNs) (Peng et al., 2017) enlarges the kernel size to 15 by employing a combination of 1\u00d7M + M\u00d71 and M\u00d71 + 1\u00d7M convolutions.</li> <li>However, the proposed method leads to performance degradation on ImageNet</li> <li>or the utilization of varying convolutional kernel sizes to learn spatial patterns at different scales. With the popularity of VGG (Simonyan &amp; Zisserman, 2014), it has been common over the past decade to use a stack of small kernels (1\u00d71 or 3\u00d73) to obtain a large receptive</li> <li>field</li> <li>However, the performance improvement plateaus when further expanding the kernel size</li> <li>Han et al. (2021b) find that dynamic depth-wise convolution (7x7) performs on par with the local attention mechanism if we substitute the latter with the former in Swin Transformer</li> <li>Liu et al. (2022b) imitate the design elements of Swin Transformer (Liu et al., 2021e) and design ConvNeXt employed with 7x7 kernels, surpassing the performance of the former</li> <li>Lately, Chen et al. (2022) reveal large kernels to be feasible and beneficial for 3D networks too.</li> <li>Prior works have explored the idea of paralleling (Peng et al., 2017; Guo et al., 2022a) or stacking (Szegedy et al., 2017) two complementary Mx1 and 1xM kernels</li> <li>However, they limit the shorter edge to 1 and do not scale the kernel size beyond 51x51</li> </ul>"},{"location":"KB/Latent%20Dirchlet%20Allocation/","title":"Latent Dirchlet Allocation","text":""},{"location":"KB/Latent%20Dirchlet%20Allocation/#latent-dirchlet-allocation","title":"Latent Dirchlet Allocation","text":"<ul> <li>Discovers topics into a collection of documents</li> <li>Tags each document with topics</li> <li></li> </ul>"},{"location":"KB/Latent%20Semantic%20Analysis/","title":"Latent Semantic Analysis","text":""},{"location":"KB/Latent%20Semantic%20Analysis/#latent-semantic-analysis","title":"Latent Semantic Analysis","text":"<ul> <li>Roughly speaking, a Learning Event is considered to be included in the student's step if the degree of semantic similarity is above a certain threshold.</li> </ul>"},{"location":"KB/Latitude%20Junior%20ML%20Engineer/","title":"Latitude Junior ML Engineer","text":""},{"location":"KB/Latitude%20Junior%20ML%20Engineer/#latitude-junior-ml-engineer","title":"Latitude Junior ML Engineer","text":"<p>As the days go by, Machine Learning and AI are slowly becoming terms that every company wants to have in their portfolio. While this drive leads to many innovations, most companies are not sure how to do AI \"well\". They want to use AI but need clarification on whether it is required, how to handle bias, how to create proper data, or even what models (ML vs. DL) to choose. I believe that the Latitude data-first approach is the way to go, and in the long run, this approach will help many companies achieve their vision of AI. I love solving problems with creative analytics, and this application is to get a chance to take part in Latitude's mission to make a difference to customers with data.</p> <p>My expertise is a combination of data analytics and computer vision, and as of a month ago, I also have a Master in Artificial Intelligence from the University of Groningen. I am familiar with the tools required for basic and advanced AI and analytics from internships, research projects, papers, freelance work, and many personal projects. That being the case, I can step aside from my experience with AI and decide if a project needs another solution in reality. I have experience finding proper KPIs and can phrase them in the context of an ML (or not) problem and provide a means to solve them.</p> <p>The customer is king, they say, and the first step in having happy clients is understanding what they truly want and then being able to give them a solution they can use. That being the case, in any team, it is essential that each of the members can contribute something to the overall development of the projects. Although I have a lot to learn, I genuinely enjoy developing solutions that have a positive impact, and I can contribute quite a bit to any team I get the chance to work with.</p>"},{"location":"KB/Law%20of%20large%20numbers/","title":"Law of Large Numbers","text":""},{"location":"KB/Law%20of%20large%20numbers/#law-of-large-numbers","title":"Law of Large Numbers","text":"<ul> <li>If one carries out an infinite seq of independantly repeating same the same numerical mesurement and gets a sequence of measurement values \\(x_{1}, .. , x_{n}\\) where \\(x_{i} \\in \\mathbb{R}\\), then the mean value of the inital seq upto N will almost always converge to the same number \\(\\(\\mu_{N} = \\frac{1}{N}\\Sigma_{i=1}^{N}x_{i}\\)\\) which is the EXPECTATION of X \\(\\(\\mu_{N}=E[X]\\)\\)</li> <li>Kolmogorov axioms</li> </ul>"},{"location":"KB/Layer%20Normalization/","title":"Layer Normalization","text":""},{"location":"KB/Layer%20Normalization/#layer-normalization","title":"Layer Normalization","text":"<ul> <li>For RNNs etc</li> <li>Mean and variance calculated independantly for each element of the batch by aggregating over the features dimensions.</li> <li> (Compared to Batch Normalization) $$  \\begin{align*}\\</li> </ul> <p>&amp;\\mu_{\\mathcal{B}} \\leftarrow \\frac{1}{m}\\Sigma_{i=1}^{m}x_{i}\\</p> <p>&amp;\\sigma^{2}{\\mathcal{B}} \\leftarrow \\frac{1}{m}\\Sigma{i=1}^{m}(x_{i}-\\mu_{\\mathcal{B}})^{2}\\</p> <p>&amp;\\hat x_{i} \\leftarrow \\frac{x_{i}-\\mu_{\\mathcal{B}}}{\\sqrt{\\sigma^{2}_{\\mathcal{B}} + \\epsilon}}\\</p> <p>&amp;y_{i}= \\gamma \\hat x_{i}+ \\beta</p> <p>\\end{align*} $$</p>"},{"location":"KB/Layer%20Normalization/#problem","title":"Problem","text":"<ul> <li>From Visualizing the Loss Landscape of Neural Nets,</li> <li></li> </ul>"},{"location":"KB/Layers/","title":"Layers","text":""},{"location":"KB/Layers/#layers","title":"Layers","text":""},{"location":"KB/Layers/#notation","title":"Notation","text":"<ul> <li>Grad of a function f wrt A : \\(\\(\\nabla_Af\\)\\)</li> <li>Neuron Pre activation : Z</li> <li>Activations : Y</li> <li>Tensor shape : (w,h,c)</li> <li>Matrix multi : \\(\\(A\\cdot B\\)\\)</li> <li>Hadmard prod (coeff wise) : \\(\\(A \\circ B\\)\\)</li> </ul>"},{"location":"KB/Layerwise%20Conservation%20Principle/","title":"Layerwise Conservation Principle","text":""},{"location":"KB/Layerwise%20Conservation%20Principle/#layerwise-conservation-principle","title":"Layerwise Conservation Principle","text":"<ul> <li>which says that \"a network's output activity is fully redistributed through the layers of a DNN onto the input variables, i.e., neither positive nor negative evidence is lost.\"</li> </ul>"},{"location":"KB/Layerwise%20Gradient%20Magnitude%20Based%20Pruning/","title":"Layerwise Gradient Magnitude Based Pruning","text":""},{"location":"KB/Layerwise%20Gradient%20Magnitude%20Based%20Pruning/#layerwise-gradient-magnitude-based-pruning","title":"Layerwise Gradient Magnitude Based Pruning","text":"<ul> <li>Finds the lowest absolute value per layer and removes them</li> </ul>"},{"location":"KB/Layerwise%20Magnitude%20Based%20Pruning/","title":"Layerwise Magnitude Based Pruning","text":""},{"location":"KB/Layerwise%20Magnitude%20Based%20Pruning/#layerwise-magnitude-based-pruning","title":"Layerwise Magnitude Based Pruning","text":"<ul> <li>Takes the lowest values per layer in the network and prunes.</li> <li>Modifying the global layerwise and applying it per layer instead.</li> <li>To do this, we first make a copy of the weights. Then for every layer in the array, we find the least n values, take the nth value and set all the others to 0.</li> <li>As an edge case, if the number of elements entered is greater than the total length of the layer, then the entire layer is set to 0.</li> </ul>"},{"location":"KB/Layerwise%20Relevance%20Propagation/","title":"Layerwise Relevance Propagation","text":""},{"location":"KB/Layerwise%20Relevance%20Propagation/#layerwise-relevance-propagation","title":"Layerwise Relevance Propagation","text":"<ul> <li>It relies on a conservation principle to propagate the outcome decision back without using gradients. The idea behind it is a decomposition of prediction function as a sum of layerwise relevance values. When LRP is applied to deep ReLU networks, LRP can be understood as a deep Taylor decomposition of the prediction. This principle ensures that the prediction activity is fully redistributed through all the layers onto the input variables</li> <li>suffers from the shattered gradients problem</li> </ul>"},{"location":"KB/Le%20Net/","title":"Le Net","text":""},{"location":"KB/Le%20Net/#le-net","title":"Le Net","text":"<ul> <li>Spatial dims reduce with depth, no of neurons increase</li> <li></li> </ul>"},{"location":"KB/LeCake/","title":"LeCake","text":""},{"location":"KB/LeCake/#lecake","title":"LeCake","text":"<ul> <li>relative importance of each learning paradigm by Yann LeCun</li> <li>At the end of the day, everything tied to Supervised Learning</li> <li></li> </ul>"},{"location":"KB/LeCun%20Init/","title":"LeCun Init","text":""},{"location":"KB/LeCun%20Init/#lecun-init","title":"LeCun Init","text":"<ul> <li> \\[\\frac{1}{fan_{in}}\\] </li> </ul>"},{"location":"KB/Lead%20Test/","title":"Lead Test","text":""},{"location":"KB/Lead%20Test/#lead-test","title":"Lead Test","text":"<ul> <li>A test to reveal the quantity of lead in the bloodstream</li> </ul>"},{"location":"KB/Leaky%20Relu/","title":"Leaky Relu","text":""},{"location":"KB/Leaky%20Relu/#leaky-relu","title":"Leaky Relu","text":"<ul> <li>Andrew L. Maas, Awni Y. Hannun, Andrew Y. Ng (2014). Rectifier Nonlinearities Improve Neural Network Acoustic Models.</li> <li>has a small slope for negative values instead of a flat slope. The slope coefficient is determined before training, i.e. it is not learnt during training. This type of activation function is popular in tasks where we we may suffer from sparse gradients, for example training generative adversarial networks.</li> <li>The reasons can be numerous, but in order to fight the situation when suddenly lot\u2019s of neurons in the network simply do nothing</li> <li> \\[max(0.01x,x)\\] </li> <li></li> </ul>"},{"location":"KB/Leap%20Data%20Scientist/","title":"Leap Data Scientist","text":""},{"location":"KB/Leap%20Data%20Scientist/#leap-data-scientist","title":"Leap Data Scientist","text":"<p>As I write this motivation letter, the temperatures in NL have hit yet another record for the hottest September ever. One of the biggest reasons for this is global warming, and fossil fuels are a massive component. Leap's mission to enable the shift to cleaner energy greatly resonates with me, so I am applying for this position as a Data Scientist. At the core of making the world a greener and healthier place is data that every company has collected for decades. Using that vast data pool to inform better decisions is quite challenging but equally rewarding.</p> <p>My expertise is a combination of data analytics and computer vision, and as of a month ago, I also have a Master in Artificial Intelligence from the University of Groningen. I am familiar with the tools required for basic and advanced AI (such as PyTorch, Tensorflow, scikit-learn, and many others) and analytics from internships, research projects, papers, freelance work, and many personal projects. In my time at KPMG and Emirates NBD, I have worked on massive data analytics pipelines across every level, from data preprocessing to feature engineering to deploying analytics solutions. Python is my language of choice for analytics as well as Deep Learning and Machine learning and I am familiar with the common libraries in each of these domains.</p> <p>In any team, it is essential that each of the members can contribute something to the overall development of the projects. Although I have a lot to learn, I genuinely enjoy developing solutions that have a positive impact, and this position will be the perfect next step for me. I will be able to contribute to any team I get to work with.</p> <p>I hope you give me a chance to contribute to the efforts that we as a race must make for our future generations in the fight against climate change.</p>"},{"location":"KB/Learning%20Component/","title":"Learning Component","text":""},{"location":"KB/Learning%20Component/#learning-component","title":"Learning Component","text":"<ul> <li>analyses the trace of activities and extracts and conceptualizes possibly interesting experiences.</li> </ul>"},{"location":"KB/Learning%20Event/","title":"Learning Event","text":""},{"location":"KB/Learning%20Event/#learning-event","title":"Learning Event","text":"<ul> <li>A learning event is the construction or application of a Knowledge Component, often while trying to achieve the task. Learning events are mental events, whereas steps are physical events. A learning event occurs in the mind of the student where it cannot be observed, whereas a step occurs on the user interface and the computer can observe it. In the algebra example mentioned earlier, the step x=18.46 can be considered to result from three learning events: \\(\\(2.3*x=42.45 (cid:198) x=42.45/2.3 (cid:198) x=18.4565\u2026 (cid:198) x=18.46\\)\\)</li> </ul>"},{"location":"KB/Learning%20L2%20German%20Vocabulary%20Through%20Reading/","title":"Learning L2 German Vocabulary Through Reading","text":""},{"location":"KB/Learning%20L2%20German%20Vocabulary%20Through%20Reading/#learning-l2-german-vocabulary-through-reading","title":"Learning L2 German Vocabulary Through Reading","text":"<ul> <li> <p>Elke Peters , Jan H. Hulstijn , Lies Sercu , Madeline Lutjeharms</p> </li> <li> <p>This study investigated three techniques designed to increase the chances that second language (L2) readers look up and learn unfamiliar words during and after reading an L2 text</p> </li> <li>They could look up the meaning of unfamiliar words in an online dictionary</li> <li>Test announcement and word relevance substantially prompted participants to use the online dictionary more.</li> <li>Only test announcement and vocabulary task (not word relevance) affected performance in the word recognition test positively</li> <li>oth word relevance and postreading vocabulary task substantially affected word retention in the recall posttests</li> <li>low incidence of vocabulary acquisition through reading (\"input only\") can be substantially boosted by techniques that make students look up the meaning of unknown words, process their form-meaning relationship elaborately, and process them again after reading (\"input plus\").</li> </ul>"},{"location":"KB/Learning%20Rate%20Decay%20tricks/","title":"Learning Rate Decay","text":""},{"location":"KB/Learning%20Rate%20Decay%20tricks/#learning-rate-decay-tricks","title":"Learning Rate Decay #tricks","text":"<ul> <li>Scale of loss landscape changes</li> <li>Reduce step size near optima</li> <li>Factor \\(\\(\\alpha_{i+1} = d\\cdot \\alpha_i\\)\\)</li> <li>Cosine Learning Rate Decay</li> </ul>"},{"location":"KB/Learning%20Rate%20Decay%20tricks/#_1","title":"\u2026","text":""},{"location":"KB/Learning%20Rate%20Range%20Test/","title":"Learning Rate Range Test","text":""},{"location":"KB/Learning%20Rate%20Range%20Test/#learning-rate-range-test","title":"Learning Rate Range Test","text":"<ul> <li>Smith, LN (2018) A disciplined approach to neural network hyper-parameters: Part 1--learning rate, batch size, momentum, and weight decay arXiv preprint arXiv:1803.09820</li> <li>It is relatively straight-forward: in a test run, one starts with a very small learning rate, for which one runs the model and computes the loss on the validation data. One does this iteratively, while increasing the learning rate exponentially in parallel. One can then plot their findings into a diagram representing loss at the y axis and the learning rate at the x axis. The x value representing the lowest y value, i.e. the lowest loss, represents the optimal learning rate for the training data.</li> <li>The learning rate at this extrema is the largest value that can be used as the learning rate for the maximum bound with cyclical learning rates but a smaller value will be necessary when choosing a constant learning rate or the network will not begin to converge.</li> <li>Smoothed loss changes</li> </ul> <pre><code>for i in range(moving_average, len(learning_rates)):\n    loss_changes.append((losses[i] - losses[i - moving_average]) / moving_average)\n</code></pre>"},{"location":"KB/Learning%20Rate%20Scheduling/","title":"Learning Rate Scheduling","text":""},{"location":"KB/Learning%20Rate%20Scheduling/#learning-rate-scheduling","title":"Learning Rate Scheduling","text":"<ul> <li>Learning Rate Decay tricks</li> <li>Gradient Descent gradients</li> <li>Increasing the batch size, reduces noise in the #gradients so a larger learning rate is okay</li> <li>Linear Learning Rate Scaling</li> <li>Learning Rate Warmup</li> </ul>"},{"location":"KB/Learning%20Rate%20Warmup/","title":"Learning Rate Warmup","text":""},{"location":"KB/Learning%20Rate%20Warmup/#learning-rate-warmup","title":"Learning Rate Warmup","text":"<ul> <li>Small learning rate at the start and then a larger learning rate when the training is stabilized</li> <li>Linearly from 0 to initial rate</li> <li>First m batches to warm up and if the initial learning rate is \\(\\eta\\) then at batch i, \\(1 \\leq i \\leq m\\) , learning rate is \\(\\(\\frac{i\\eta}{m}\\)\\)</li> </ul>"},{"location":"KB/Learning%20from%20RGB-Flow%20Correspondence/","title":"Learning from RGB-Flow Correspondence","text":""},{"location":"KB/Learning%20from%20RGB-Flow%20Correspondence/#learning-from-rgb-flow-correspondence","title":"Learning from RGB-Flow Correspondence","text":"<ul> <li>Optical flow encodes object motions between adjacent frames </li> <li>RGB frames contain appearance information </li> <li>The correspondence of the two types of data can be used to learn general features </li> <li>This type of pretext tasks include optical flow estimation [151], [152] and RGB and optical flow correspondence verification [23]. </li> <li>Sayed et al. proposed to learn video features by verifying whether the input RGB frames and the optical flow corresponding to each other </li> <li>Two networks are employed while one is for extracting features from RGB input and another is for extracting features from optical flow input [24] </li> <li>network needs to capture mutual information between the two modalities </li> <li>mutual information across different modalities usually has higher semantic meaning compared to information which is modality specific </li> <li>Optical flow estimation is another type of pretext tasks </li> <li>FlowNet</li> </ul>"},{"location":"KB/Learning%20from%20Video%20Colorization/","title":"Learning from Video Colorization","text":""},{"location":"KB/Learning%20from%20Video%20Colorization/#learning-from-video-colorization","title":"Learning from Video Colorization","text":"<ul> <li>Temporal coherence </li> <li>consecutive frames within a short time have similar coherent appearance </li> <li>The coherence of color can be used to design pretext tasks for self-supervised learning </li> <li>One way to utilize color coherence is to use video colorization as a pretext task for self-supervised video feature learning. </li> <li>Video colorization is a task to colorize gray-scale frames into colorful frames </li> <li>Vondrick et al. proposed to constrain colorization models to solve video colorization by learning to copy colors from a reference frame </li> <li>Given the reference RGB frame and a gray-scale image, the network needs to learn the internal connection between the reference RGB frame and gray-scale image to colorize it. </li> <li>tackle video colorization by employing a fully convolution neural network </li> <li>Tran et al. proposed an U-shape convolution neural network for video colorization [160] </li> <li>The color coherence in videos is a strong supervision signal</li> </ul>"},{"location":"KB/Learning%20from%20Video%20Prediction/","title":"Learning from Video Prediction","text":""},{"location":"KB/Learning%20from%20Video%20Prediction/#learning-from-video-prediction","title":"Learning from Video Prediction","text":"<ul> <li>Video prediction is a task of predicting future frame sequences based on a limited number of frames of a video </li> <li>To predict future frames, network must learn the change in appearance within a given frame sequence </li> <li>Un-LSTM</li> <li>MCnet</li> <li>Temporal order verification</li> <li>Temporal order recognition</li> <li>Misra et al. proposed to use the temporal order verification as the pretext task to learn image features from videos with 2DConvNet [40] which has two main steps: (1) The frames with significant motions are sampled from videos according to the magnitude of optical flow, (2) The sampled frames are shuffled and fed to the network which is trained to verify whether the input data is in correct order. </li> <li>successfully verify the order of the input frames, the network is required to capture the subtle difference between the frames such as the movement of the person </li> <li>semantic features can be learned through the process of accomplishing this task </li> <li>the methods usually suffer from a massive dataset preparation step </li> <li>The frame sequences that used to train the network are selected based on the magnitude of the optical flow, and the computation process of optical flow is expensive and slow</li> </ul>"},{"location":"KB/Learning%20from%20Visual-Audio%20Correspondence/","title":"Learning from Visual-Audio Correspondence","text":""},{"location":"KB/Learning%20from%20Visual-Audio%20Correspondence/#learning-from-visual-audio-correspondence","title":"Learning from Visual-Audio Correspondence","text":"<ul> <li>correspondence between visual and audio streams to design VisualAudio Correspondence learning task [25], [26], [93], [154]. </li> <li>two subnetworks </li> <li>vision </li> <li>audio subnetwork </li> <li>input of vision subnetwork is a single frame or a stack of image frames and the vision subnetwork learns to capture visual features of the input data </li> <li>audio network is a 2DConvNet </li> <li>input is the Fast Fourier Transform (FFT) of the audio from the video </li> <li>Positive data are sampled by extracting video frames and audio from the same time of one video, while negative training data are generated by extracting video frames and audio from different videos or from different times of one video </li> <li>networks are trained to discover the correlation of video data and audio data to accomplish this task. </li> <li>inputs of the ConvNets are two kinds of data, the networks are able to learn the two kinds of information jointly by solving the pretext task.</li> </ul>"},{"location":"KB/Learning%20to%20Detect%20Grasp%20Affordance/","title":"Learning to Detect Grasp Affordance","text":""},{"location":"KB/Learning%20to%20Detect%20Grasp%20Affordance/#learning-to-detect-grasp-affordance","title":"Learning to Detect Grasp Affordance","text":"<ul> <li>Yikun Li, et al., Learning to Detect Grasp Affordances of 3D Objects using Deep Convolutional Neural Networks, Task-Informed Grasping workshop (TIG-II), RSS2019, Germany 2019.</li> <li></li> </ul>"},{"location":"KB/Learning%20with%20Context%20Similarity/","title":"Learning with Context Similarity","text":""},{"location":"KB/Learning%20with%20Context%20Similarity/#learning-with-context-similarity","title":"Learning with Context Similarity","text":"<ul> <li>Clustering is a method of grouping sets of similar data in the same clusters </li> <li>powerful ability of grouping data by using the attributes of the data </li> <li>In the self-supervised scenario, the clustering methods mainly employed as a tool to cluster image data </li> <li>A naive method would be to cluster the image data based on the hand-designed feature such as HOG [140], SIFT [141], or Fisher Vector [49] </li> <li>After the clustering, several clusters are obtained while the image within one cluster has a smaller distance in feature space and images from different clusters have a larger distance in feature space </li> <li>The smaller the distance in feature space, the more similar the image in the appearance in the RGB space </li> <li>Then a ConvNet can be trained to classify the data by using the cluster assignment as the pseudo class label </li> <li>the ConvNet needs to learn the invariance within one class and the variance among different classes </li> <li>Therefore, the ConvNet is able to learn semantic meaning of images </li> <li>Firstly, the image is clustered into different clusters which the images from the same cluster have smaller distance and images from different clusters have larger distance </li> <li>Then a ConvNet is trained to recognize the cluster assignment [34], [44] or to recognize whether two imaged are from same cluster [43] </li> <li>DeepCluster iteratively clusters images with Kmeans and use the subsequent assignments as supervision to update the weights of the network</li> </ul>"},{"location":"KB/Learning%20with%20Labels%20Generated%20by%20Game%20Engines/","title":"Learning with Labels Generated by Game Engines","text":""},{"location":"KB/Learning%20with%20Labels%20Generated%20by%20Game%20Engines/#learning-with-labels-generated-by-game-engines","title":"Learning with Labels Generated by Game Engines","text":"<ul> <li>Given models of various objects and layouts of environments, game engines are able to render realistic images and provide accurate pixel-level labels </li> <li>Since game engines can generate large-scale datasets with negligible cost, var- ious game engines such as Airsim [142] and Carla [143] have been used to generate large-scale synthetic datasets with high-level semantic labels including depth, # contours, surface normal, segmentation mask, and optical flow for training deep networks.  </li> <li> </li> <li>However, due to the domain gap between synthetic and real-world images, the ConvNet purely trained on synthetic images cannot be </li> <li>directly applied to real-world images </li> <li>the ConvNet trained with the semantic labels of the synthetic dataset can be effectively applied to real-world images. </li> <li>Ren and Lee proposed an unsupervised feature space domain adaptation method based on adversarial learning [30] </li> <li>the network predicts surface normal, depth, and instance contour for the synthetic images and a discriminator network D is employed to minimize the difference of feature space domains between real-world and synthetic data </li> <li>the network is able to capture visual features for real-world images  </li> <li>Jing et al. proposed to learn features by training a ConvNet to predict relative scene depths while the labels are generated from optical flow [92]. </li> <li>No matter what kind of labels used to train ConvNets, the general idea of this type of methods is to distill knowledge from hard-code detector </li> <li>The hard-code detector can be edge detector, salience detector, relative detector, etc </li> <li>no human-annotations are involved </li> <li>one drawback is that the semantic labels generated by hard-code detector usually are very noisy which need to specifically cope with.</li> </ul>"},{"location":"KB/Learning%20with%20Labels%20Generated%20by%20Hard-code%20Programs/","title":"Learning with Labels Generated by Hard-code Programs","text":""},{"location":"KB/Learning%20with%20Labels%20Generated%20by%20Hard-code%20Programs/#learning-with-labels-generated-by-hard-code-programs","title":"Learning with Labels Generated by Hard-code Programs","text":"<ul> <li>Applying hard-code programs is another way to automatically generate semantic labels such as salience, foreground masks, contours, depth for images and videos </li> <li>very large-scale datasets with generated semantic labels can be used for self- supervised feature learning </li> <li>Various hard-code programs have been applied to generate labels for self- supervised learning methods include methods for foreground object segmentation [81], edge detection [47], and relative depth prediction [92] </li> <li>Pathak et al. proposed to learn features by training a ConvNet to segment foreground objects in each frame of a video while the label is the mask of moving objects in videos [81] </li> <li>Li et al. proposed to learn features by training a ConvNet for edge prediction while labels are motion edges obtained from flow fields   </li> <li>After GAN-based methods obtained breakthrough results in image generation, researchers employed GAN to generate videos [85], [86], [144] </li> <li>VideoGAN <ul> <li>To model the motion of objects in videos, a two-stream network is proposed for video generation while one stream is to model the static regions in in videos as background and another stream is to model moving object in videos as foreground </li> <li>Videos are generated by the combination of the foreground and background streams </li> <li>each random variable in the latent space represents one video clip </li> <li>Tulyakov et al. argues that this assumption increases difficulties of the generation </li> </ul> </li> <li>MocoGAN <ul> <li>use the combination of two subspace to represent a video by disentangling the # context and motions in videos [86] </li> <li>context space which each variable from this space represents one identity </li> <li>motion space while the trajectory in this space represents the motion of the identity </li> <li>With the two sub-spaces, the network is able to generate videos with higher inception score. </li> <li>The generator learns to map latent vectors from latent space into videos, while discriminator learns to distinguish the real world videos with generated videos. </li> <li>After the video generation training on large-scale unlabeled dataset finished, the parameters of discriminator can be transferred to other downstream tasks [85].</li> </ul> </li> </ul>"},{"location":"KB/Learning%20with%20Spatial%20Context%20Structure/","title":"Learning with Spatial Context Structure","text":""},{"location":"KB/Learning%20with%20Spatial%20Context%20Structure/#learning-with-spatial-context-structure","title":"Learning with Spatial Context Structure","text":"<ul> <li>Images contain rich spatial context information such as the relative positions among different patches from an image which can be used to design the pretext task for selfsupervised learning </li> <li>The pretext task can be to predict the relative positions of two patches from same image [41], or to recognize the order of the shuffled a sequence of patches from same image [20], [88], [89] </li> <li>The context of full images can also be used as a supervision signal to design pretext tasks such as to recognize the rotating angles of the whole images [36] </li> <li>ConvNets need to learn spatial context information such as the shape of the objects and the relative positions of different parts of an object.  </li> <li> </li> <li>Doersch et al. is one of the pi- (b) oneer work of using spatial context cues for self- supervised visual feature learning [41] </li> <li>Random pairs of image patches are extracted from each image, then a ConvNet is trained to recognize the relative positions of the two image patches </li> <li>ConvNets need to recognize objects in images and learn the relationships among different parts of objects </li> <li>To avoid the network learns trivial solutions such as simply using edges in patches to accomplish the task, heavy data augmentation is applied during the training phase </li> <li>Following this idea, more methods are proposed to learn image features by solving more difficult spatial puzzles [20], [27], [87], [88], [89] </li> <li>Noroozi et al. attempted to solve an image Jigsaw puzzle with ConvNet [20] </li> <li>The shuffled image patches are fed to the network which trained to recognize the correct spatial locations of the input patches by learning spatial context </li> <li>Given 9 image patches from an image, there are 362, 880 (9!) possible permutations and a network is very unlikely to recognize all of them because of the ambiguity of the task </li> <li>To limit the number of permutations, usually, hamming distance is employed to choose only a subset of permutations among all the permutations that with relative large hamming distance. </li> <li>Only the selected permutations are used to train ConvNet to recognize the permutation of shuffled image patches [20], [35], [88], [89]</li> </ul>"},{"location":"KB/Left%20psuedo%20inverse/","title":"Left psuedo inverse","text":""},{"location":"KB/Left%20psuedo%20inverse/#left-psuedo-inverse","title":"Left psuedo inverse","text":"<ul> <li> \\[(A'A)^{-1}A'\\] </li> </ul>"},{"location":"KB/Lemmatization/","title":"Lemmatization","text":""},{"location":"KB/Lemmatization/#lemmatization","title":"Lemmatization","text":"<ul> <li>Word-&gt; lemma</li> <li>saw : {see, saw}</li> <li>Morphological analysis : word-&gt; set of {lemma, tag}</li> </ul>"},{"location":"KB/Length%20Optimization/","title":"Length Optimization","text":""},{"location":"KB/Length%20Optimization/#length-optimization","title":"Length Optimization","text":""},{"location":"KB/Lesion/","title":"Lesion","text":""},{"location":"KB/Lesion/#lesion","title":"Lesion","text":"<ul> <li>An injury, area of disease, or surgical incision to body tissue. Much of what we know about the functions of brain structures or pathways comes from lesion mapping studies, where scientists observe the behavior of people with an injury to a distinct area of the brain or analyze the behavior of a laboratory animal resulting from a lesion made in the brain.</li> </ul>"},{"location":"KB/Lesion/#lesion_1","title":"Lesion","text":"<ul> <li>Damage or change to tissue, such as a cut, a wound or a sore</li> </ul>"},{"location":"KB/Lexical%20Ambiguity/","title":"Lexical Ambiguity","text":""},{"location":"KB/Lexical%20Ambiguity/#lexical-ambiguity","title":"Lexical Ambiguity","text":"<ul> <li>Lexical Disambiguation</li> <li>Will will Will\u2019s will</li> <li>Buffalo buffalo Buffalo buffalo</li> <li>Rose rose roes rows</li> </ul>"},{"location":"KB/Lexical%20Disambiguation/","title":"Lexical Disambiguation","text":""},{"location":"KB/Lexical%20Disambiguation/#lexical-disambiguation","title":"Lexical Disambiguation","text":"<ul> <li>process of determining the correct meaning of an individual word</li> <li>Word sense disambiguation</li> <li>Semantic Markers</li> </ul>"},{"location":"KB/Lexical%20Word%20Segmentation/","title":"Lexical Word Segmentation","text":""},{"location":"KB/Lexical%20Word%20Segmentation/#lexical-word-segmentation","title":"Lexical Word Segmentation","text":"<ul> <li>rule-based \u2013 syntax; semantics; morphological rules</li> </ul>"},{"location":"KB/Lexically%20Collective/","title":"Lexically Collective","text":""},{"location":"KB/Lexically%20Collective/#lexically-collective","title":"Lexically Collective","text":"<ul> <li>Each knight gathered at the castle.</li> </ul>"},{"location":"KB/Lexically%20Distributive/","title":"Lexically Distributive","text":""},{"location":"KB/Lexically%20Distributive/#lexically-distributive","title":"Lexically Distributive","text":"<ul> <li>Each girl smiled</li> </ul>"},{"location":"KB/Lexicon/","title":"Lexicon","text":""},{"location":"KB/Lexicon/#lexicon","title":"Lexicon","text":"<ul> <li>a module that tells what words there are and what properties they have</li> </ul>"},{"location":"KB/LibriSpeech/","title":"LibriSpeech","text":""},{"location":"KB/LibriSpeech/#librispeech","title":"LibriSpeech","text":""},{"location":"KB/Limbic%20system/","title":"Limbic system","text":""},{"location":"KB/Limbic%20system/#limbic-system","title":"Limbic System","text":"<ul> <li>is the center of our emotions, learning, and memory.</li> <li>Included in this system are the cingulate gyri, hypothalamus, amygdala (emotional reactions) and hippocampus (memory).</li> </ul>"},{"location":"KB/Limbic%20system/#limbic-system_1","title":"Limbic System","text":"<ul> <li>A group of evolutionarily older brain structures that encircle the top of the brain stem. The limbic structures play complex roles in emotions, instincts, and appetitive behaviors.</li> </ul>"},{"location":"KB/Limited%20features/","title":"Limited features","text":""},{"location":"KB/Limited%20features/#limited-features","title":"Limited features","text":"<ul> <li>Sample size disparities</li> <li>when using sensitive features, disparities between different subgroups can induce bias</li> </ul>"},{"location":"KB/Line%20Integral%20Convolution/","title":"Line Integral Convolution","text":""},{"location":"KB/Line%20Integral%20Convolution/#line-integral-convolution","title":"Line Integral Convolution","text":"<ul> <li>Mimic physical experiment: oil drops on surface, apply flow (wind)</li> <li>Intensity distribution along streamlines shows high correlation</li> <li>No correlation between neighboring streamlines</li> <li></li> <li></li> </ul>"},{"location":"KB/Linear%20Classifier%20Probes/","title":"Linear Classifier Probes","text":""},{"location":"KB/Linear%20Classifier%20Probes/#linear-classifier-probes","title":"Linear Classifier Probes","text":"<ul> <li>Understanding Intermediate Layers Using Linear Classifier Probes</li> <li>Black box</li> <li>monitor the features at every layer of a model and measure how suitable they are for classification</li> <li>\"Probes\"</li> <li>trained entirely independently of the model</li> <li>observe experimentally that the linear separability of features increase monotonically along the depth of the model</li> </ul>"},{"location":"KB/Linear%20Interpolated%20Motion/","title":"Linear Interpolated Motion","text":""},{"location":"KB/Linear%20Interpolated%20Motion/#linear-interpolated-motion","title":"Linear Interpolated Motion","text":"<ul> <li>Is a method of path interpolation that commands the movement of the robot by moving each joint in a coordinated motion so that all axis arrive to the position at the same time. The path of the Tool Control Point (TCP) is predictable and will be linear.</li> </ul>"},{"location":"KB/Linear%20Learning%20Rate%20Scaling/","title":"Linear Learning Rate Scaling","text":""},{"location":"KB/Linear%20Learning%20Rate%20Scaling/#linear-learning-rate-scaling","title":"Linear Learning Rate Scaling","text":"<ul> <li>If [He Initialization ] is used, 0.1 is a good learning rate for batch size 256 and for a larger b, \\(0.1\\times\\frac{\\mathrm{b}}{256}\\) is okay</li> </ul>"},{"location":"KB/Linear%20scale/","title":"Linear Scale Encoding","text":""},{"location":"KB/Linear%20scale/#linear-scale-encoding","title":"Linear Scale Encoding","text":"<ul> <li>Eg Likert scale</li> <li>A = {certainly not, rather not, dont know}</li> </ul>"},{"location":"KB/Linear%20scale/#_1","title":"\u2026","text":""},{"location":"KB/LinearRegression/","title":"Linear Regression","text":""},{"location":"KB/LinearRegression/#linear-regression","title":"Linear Regression","text":"<ul> <li>Minimization problem (\\((w,b) = argmin_{w^{\\ast} , b^{\\ast}} \\Sigma^N_{i-1}(w^{\\ast}x_{i} +b ^{\\ast} - y_{i})^2\\)\\)<ul> <li>Affine Function</li> <li> \\[w = argmin_{w^\\ast} || (\\Sigma^n_{j = 1} w^\\ast_j \\phi_j) - y || ^2\\] <ul> <li>w* is just \\(\\((w^\\ast_1 \u2026 w^\\ast_n)\\)\\)</li> <li> \\[u_j$$ of U forms orthonormal basis of $$\\mathscr{F}\\] </li> </ul> </li> </ul> </li> <li>X : nxN matrix , y : N dim vector</li> <li>Solution : \\(\\([w, b] \\in \\mathbb{R} ^{n+1}\\)\\)</li> <li> \\[w' = (XX')^{-1}X y\\] <ul> <li>If y is has vector data too (size k)<ul> <li> \\[W' = (XX')^{-1}XY\\] </li> <li>Y : N x k matrix</li> </ul> </li> </ul> </li> <li></li> <li>(\\(\\phi _1 , \\phi_2 \u2026\\)\\) form a subspace (\\(\\mathscr{F}\\)\\) with dim = n<ul> <li>linearly independant vectors. If not, drop as many as possible</li> </ul> </li> <li>The optimal solution y_opt is the projection of y on that subspace and has the smallest distance from y<ul> <li> \\[y_{opt} = w_1 \\phi_1 + w_2 \\phi_2\\] </li> </ul> </li> <li> \\[(\\Sigma^n_{j = 1} w^\\ast_j \\phi_j)$$ is a vector on $$\\mathscr{F}\\] </li> <li>Ridge Regression</li> <li>Window Based Regression</li> </ul>"},{"location":"KB/LinearRegression/#general-defination","title":"General Defination","text":"<ul> <li>Training data : \\(\\((x_i, y_i)_{i= 1,..,N}\\)\\) and \\(\\(\\in \\mathbb{R}^k\\)\\)</li> <li>Search space H<ul> <li>Candidate functions \\(\\(h: \\mathbb{R}^n \\rightarrow \\mathbb{R}^k\\)\\)</li> </ul> </li> <li>Loss function (\\(L : \\mathbb{R}^k \\times \\mathbb{R}^k \\rightarrow \\mathbb{R}^{n \\geq 0}\\)\\)<ul> <li>Quadratic Loss</li> </ul> </li> <li> <p>Solution : \\(\\(h_{opt} = argmin_{h \\in \\mathcal{H}}\\Sigma_{i=1}^N L(h(x_i), y_i)\\)\\)</p> <ul> <li> \\[\\mathcal{H}$$ is all linear functions from $$\\mathbb{R}^n$$ to $$\\mathbb{R}^k\\] </li> </ul> </li> <li> <p>Left psuedo inverse</p> </li> </ul>"},{"location":"KB/Linguistic%20details/","title":"Linguistic details","text":""},{"location":"KB/Linguistic%20details/#linguistic-details","title":"Linguistic Details","text":"<ul> <li>Phonetics</li> <li>Phonology</li> <li>Morphology</li> <li>Syntactic Analysis</li> <li>Semantic Analysis</li> <li>Pragmatics</li> </ul>"},{"location":"KB/Lisht/","title":"Lisht","text":""},{"location":"KB/Lisht/#lisht","title":"Lisht","text":"<ul> <li>Derivatives<ul> <li></li> </ul> </li> <li>blog #Roam-Highlights<ul> <li>Linearly Scaled Hyperbolic Tangent</li> <li>his activation function simply uses the Tanh function and scales it linearly, as follows</li> <li> \\[LiSHT(x) = x \\times tanh(x)\\] </li> <li>Essentially, LiSHT looks very much like Swish in terms of the first-order derivative. However, the range is expanded into the negative as well, which means that the vanishing gradient problem is reduced even further - at least in theory.</li> <li>In their work, Roy et al. (2019) report based on empirical testing that indeed, the vanishing gradient problems is reduced compared to Swish and traditional ReLU. Additional correlations between network learning and the shape of e.g. the LiSHT loss landscape were identified.</li> </ul> </li> </ul>"},{"location":"KB/Listen%20Attend%20Spell/","title":"Listen Attend Spell","text":""},{"location":"KB/Listen%20Attend%20Spell/#listen-attend-spell","title":"Listen Attend Spell","text":"<ul> <li>Listen, Attend and Spell</li> <li>LAS</li> <li>learns to transcribe speech utterances to characters</li> <li>nlike traditional DNN-HMM models, this model learns all the components of a speech recognizer jointly</li> <li>sequence-to-sequence framework</li> <li>trained end-to-end and has two main components: a listener (encoder) and a speller (decoder)</li> <li>listener is a pyramidal RNN encoder that accepts filter bank spectra as inputs, transforms the input sequence into a high level feature representation and reduces the number of timesteps that the decoder has to attend to.</li> <li>The speller is an attention-based RNN decoder that attends to the high level features and spells out the transcript one character at a time</li> <li>The proposed system does not use the concepts of phonemes, nor does it rely on pronunciation dictionaries or HMMs</li> <li>bypass the conditional independence assumptions of CTC, and show how they can learn an implicit language model that can generate multiple spelling variants given the same acoustics</li> <li>producing character sequences without making any independence assumptions between the characters is the key improvement of LAS over previous end-to-end CTC models</li> <li>used samples from the softmax classifier in the decoder as inputs to the next step prediction during training</li> <li>show how a language model trained on additional text can be used to rerank their top hypotheses</li> <li>Google voice search task</li> </ul>"},{"location":"KB/Load%20Cycle%20Time/","title":"Load Cycle Time","text":""},{"location":"KB/Load%20Cycle%20Time/#load-cycle-time","title":"Load Cycle Time","text":"<ul> <li>A manufacturing or assembly line process term, which describes the complete time to unload the last work piece and load the next one.</li> </ul>"},{"location":"KB/Load%20balancing/","title":"Load balancing","text":""},{"location":"KB/Load%20balancing/#load-balancing","title":"Load Balancing","text":"<ul> <li>divide the work equally among the available processors</li> </ul>"},{"location":"KB/Local%20Descriptor/","title":"Local Descriptor","text":""},{"location":"KB/Local%20Descriptor/#local-descriptor","title":"Local Descriptor","text":"<ul> <li>set of spin-images</li> <li>A spin-image feature is computed for every keypoint:</li> <li>The tangent plane is estimated</li> <li>A 2D histogram is computed along the a and b dimensions in the neighborhood of the keypoint</li> <li>Spin-image represents a small area of an object around a specific keypoints</li> <li></li> <li></li> </ul>"},{"location":"KB/Local%20Reference%20Frame/","title":"Local Reference Frame","text":""},{"location":"KB/Local%20Reference%20Frame/#local-reference-frame","title":"Local Reference Frame","text":"<ul> <li>Three principal axes of a given object's point cloud are firstly determined based on eigenvectors analysis (PCA)</li> <li></li> </ul>"},{"location":"KB/Local-LDA%20Object%20Representation/","title":"Local-LDA Object Representation","text":""},{"location":"KB/Local-LDA%20Object%20Representation/#local-lda-object-representation","title":"Local-LDA Object Representation","text":"<ul> <li>A variant of Latent Dirichlet Allocation (Local-LDA)</li> <li>learn structural semantic features (i.e. topics) from low-level feature cooccurrences for each category independently and incrementally.</li> <li></li> </ul>"},{"location":"KB/Localist%20units/","title":"Localist units","text":""},{"location":"KB/Localist%20units/#localist-units","title":"Localist Units","text":"<ul> <li>In a localist representation, a localist unit (neuron) is most active to one meaningful category</li> <li>In Input: when we build a network and let each input unit represent a a specific word</li> <li>In Output: when we allow outputs of single unit to be interpreted</li> <li>In the hidden units: is there evidence of localist encoding developing?</li> </ul>"},{"location":"KB/Locality/","title":"Locality","text":""},{"location":"KB/Locality/#locality","title":"Locality","text":"<ul> <li>Localist units</li> <li>In order to process an image, we start by capturing the local information. One way to do that is the use of a convolutional layer. It can capture the local relationship between the pixels of an image. Then, as we go deeper in the model, the local feature extractors help to extract the global features</li> <li></li> </ul>"},{"location":"KB/Location%20Aware%20Attention/","title":"Location Aware Attention","text":""},{"location":"KB/Location%20Aware%20Attention/#location-aware-attention","title":"Location Aware Attention","text":"<ul> <li>Chorowski et al., 2015</li> </ul>"},{"location":"KB/Location%20Base%20Attention/","title":"Location Base Attention","text":""},{"location":"KB/Location%20Base%20Attention/#location-base-attention","title":"Location Base Attention","text":"<ul> <li>Luong2015</li> <li>Attention Alignment score \\(\\alpha_{t,i} = softmax(W_{\\alpha}s_{t})\\)</li> </ul>"},{"location":"KB/Log%20Likelihood%20Loss/","title":"Log Likelihood Loss","text":""},{"location":"KB/Log%20Likelihood%20Loss/#log-likelihood-loss","title":"Log Likelihood Loss","text":"<ul> <li> \\[L(U) = \\Sigma_i log P(u_i| u_{i-k} ,\u2026, u_{i-1} )\\] </li> <li>k is size of context window of past tokens</li> </ul>"},{"location":"KB/Log-odds/","title":"Log odds","text":""},{"location":"KB/Log-odds/#log-odds","title":"Log-odds","text":"<ul> <li>The logarithm of the odds of some event.</li> <li>If the event refers to a binary probability, then odds refers to the ratio of the probability of success (p) to the probability of failure (1-p).</li> </ul>"},{"location":"KB/LogCosh/","title":"Log Cosh","text":""},{"location":"KB/LogCosh/#log-cosh","title":"Log Cosh","text":"<ul> <li>works like the MSE, but is smoothed towards large errors (presumably caused by outliers) so that the final error score isn\u2019t impacted thoroughly.</li> </ul> <p>We first define the Softplus function \\(\\(\\log\\left( e^{x} + 1 \\right)\\)\\)</p> <p>Then , \\(\\(x = \u0177 - y\\)\\)</p> <p>logcosh = \\(\\(\\mathrm{mean}\\left( x + \\mathrm{softplus}\\left( -2 \\cdot x \\right) - \\log\\left( 2.0 \\right) \\right)\\)\\)</p>"},{"location":"KB/LogCosh/#_1","title":"\u2026","text":""},{"location":"KB/Logarithm/","title":"Logarithm","text":""},{"location":"KB/Logarithm/#logarithm","title":"Logarithm","text":"<ul> <li>Logarithms are sort of a measure of the \u201cbigness\u201d of a number; 1\u201310 is small (say, 0..1), 10\u2013100 are medium (1..2), 100\u20131000 are big (2..3). But, it makes a pretty huge difference if we\u2019re thinking about\u00a0\\(log(x)\\)\u00a0with\u00a0\\(x\\)\u00a0between 1 and 10, or with\u00a0\\(x\\)\u00a0above 10, or with\u00a0\\(x\\)\u00a0less than 1. An\u00a0\\(x\\)\u00a0between zero and 1 turns into a negative number</li> </ul>"},{"location":"KB/Logits/","title":"Logits","text":""},{"location":"KB/Logits/#logits","title":"Logits","text":"<ul> <li>The vector of raw (non-normalized) predictions that a classification model generates, which is ordinarily then passed to a normalization function.</li> </ul>"},{"location":"KB/Long%20Short%20Term%20Memory%20%28LSTM%29/","title":"Long Short Term Memory (LSTM)","text":""},{"location":"KB/Long%20Short%20Term%20Memory%20%28LSTM%29/#long-short-term-memory-lstm","title":"Long Short Term Memory (LSTM)","text":"<ul> <li>Smaller chance of exploding or vanishing #gradients</li> <li>Better ability to model long term dependencies</li> <li>Gated connections</li> <li>Gates that learn to forget some aspects, and remember others better</li> <li>Splitting state into parts -&gt; output pred and feature learning</li> <li>At the end of the day, these could not handle too long sequences. Therefore -&gt; Transformer</li> </ul>"},{"location":"KB/Long%20Short%20Term%20Memory%20%28LSTM%29/#the-math","title":"The Math","text":"<ul> <li>Gates<ul> <li>Forget (\\(g_f = \\sigma(W_{hf}h_{t-1} + W_{xf}x_t + b_f)\\)\\)<ul> <li>How much of the previous cell state is used</li> </ul> </li> <li>Input (\\(g_i = \\sigma(W_{hi}h_{t-1} + W_{xi}x_t + b_i)\\)\\)<ul> <li>How proposal is added to the state</li> </ul> </li> <li>Output (\\(g_o = \\sigma(W_{ho}h_{t-1} + W_{xo}x_t + b_o)\\)\\)<ul> <li>Component wise products</li> </ul> </li> </ul> </li> <li>Hidden state<ul> <li>(\\(C_t\\)\\) to model cross timestep dependencies<ul> <li>Cell state proposal : \\(\\(\\hat C = tanh(W_{hc}h_{t-1} + W_{xc}x_t + b_c)\\)\\)</li> <li>Final cell state : \\(\\(C_t = g_f \\cdot C_{t-1} + g_i\\cdot \\hat C\\)\\)</li> </ul> </li> <li>(\\(h_t\\)\\) to predict output<ul> <li> \\[h_t = g_o \\cdot \\sigma_y(C_t)\\] </li> </ul> </li> </ul> </li> </ul>"},{"location":"KB/Long%20Term%20Potentiation%20%28LTP%29/","title":"Long Term Potentiation (LTP)","text":""},{"location":"KB/Long%20Term%20Potentiation%20%28LTP%29/#long-term-potentiation-ltp","title":"Long Term Potentiation (LTP)","text":"<ul> <li>The persistent strengthening of a synapse with increased use, thought to underlie learning and memory.</li> </ul>"},{"location":"KB/Longformer/","title":"Longformer","text":""},{"location":"KB/Longformer/#longformer","title":"Longformer","text":"<ul> <li>Longformer: the Long-Document Transformer</li> <li>Transformer</li> <li>Sliding Window Attention</li> <li>Dilated Sliding Window Attention</li> <li>Global and Sliding Window Attention</li> <li>attention mechanism that scales linearly with sequence length</li> <li>drop-in replacement for the standard self-attention</li> <li>local windowed attention with a task motivated global attention</li> <li>text8</li> <li>enwik8</li> <li>consistently outperforms RoBERTa on long document tasks and sets new state-of-the-art results on WikiHop and TriviaQA</li> <li>Longformer-Encoder-Decoder (LED), a Longformer variant for supporting long document generative sequence-to-sequence tasks, and demonstrate its effectiveness on the arXiv summarization dataset</li> </ul>"},{"location":"KB/Loop%20Tiling/","title":"Loop Tiling","text":""},{"location":"KB/Loop%20Tiling/#loop-tiling","title":"Loop Tiling","text":"<ul> <li>Hardware memory layout in consideration</li> </ul>"},{"location":"KB/Lost%20in%20the%20Middle%20How%20Language%20Models%20Use%20Long%20Contexts/","title":"Lost in the Middle How Language Models Use Long Contexts","text":"","tags":["llm"]},{"location":"KB/Lost%20in%20the%20Middle%20How%20Language%20Models%20Use%20Long%20Contexts/#lost-in-the-middle-how-language-models-use-long-contexts","title":"Lost in the Middle How Language Models Use Long Contexts","text":"","tags":["llm"]},{"location":"KB/Lost%20in%20the%20Middle%20How%20Language%20Models%20Use%20Long%20Contexts/#summary","title":"Summary","text":"<p>When we feed LLMs with a long context, they tend to overlook the documents placed in the middle. So, contrary to what one might think, placing the least similar documents at the bottom isn't the best strategy. So, we should put the least similar ones in the middle, not at the bottom.</p>","tags":["llm"]},{"location":"KB/Lost%20in%20the%20Middle%20How%20Language%20Models%20Use%20Long%20Contexts/#findings","title":"Findings","text":"<ul> <li>performance can degrade significantly when changing the position of relevant information, indicating that current language models do not robustly make use of information in long input contexts.</li> <li>performance is often highest when relevant information occurs at the beginning or end of the input context, and significantly degrades when models must access relevant information in the middle of long contexts, even for explicitly long-context models </li> <li>Encoder-decoder models are relatively robust to changes in the position of relevant information within their input context, but only when evaluated on sequences within its trainingtime sequence length. When evaluated on sequences longer than those seen during training, we observe a U-shaped performance curve</li> <li>Query-aware contextualization (placing the query before and after the documents or keyvalue pairs) enables near-perfect performance on the synthetic key-value task, but minimally changes trends in multi-document QA</li> <li>Even base language models (i.e., without instruction fine-tuning) show a U-shaped performance curve as we vary the position of relevant information in the input context.</li> <li>model performance saturates long before retriever recall saturates, indicating that current models fail to effectively use additional retrieved documents---using 50 documents instead of 20 retrieved documents only marginally improves performance (\u223c1.5% for GPT-3.5-Turbo and \u223c1% for claude-1.3).</li> </ul>","tags":["llm"]},{"location":"KB/Lost%20in%20the%20Middle%20How%20Language%20Models%20Use%20Long%20Contexts/#results","title":"Results","text":"<ul> <li>Our experimental setup is similar to the needlein-a-haystack experiments of Ivgi et al. (2023), who compare question answering performance when the relevant paragraph is placed (i) at the beginning of the input or (ii) a random position within the input. They find that encoder-decoder models have significantly higher performance when relevant information is placed at the start of the input context. In contrast, we study finer-grained changes in the position of relevant information.  </li> </ul>","tags":["llm"]},{"location":"KB/Low-rank%20factorization/","title":"Low-rank factorization","text":""},{"location":"KB/Low-rank%20factorization/#low-rank-factorization","title":"Low-rank Factorization","text":"<ul> <li>These methods identify re- dundant parameters of deep neural networks by em- ploying the matrix and tensor decomposition (Yu et al., 2017; Denton et al., 2014).</li> </ul>"},{"location":"KB/Lp%20Regularization/","title":"Lp Regularization","text":""},{"location":"KB/Lp%20Regularization/#lp-regularization","title":"Lp Regularization","text":"<ul> <li>Tikhonov</li> <li>Penalty considering weights</li> <li> \\[L^\\ast(\\theta) = L(\\theta) + \\lambda \\Sigma_i |\\theta_i|^p\\] <ul> <li>Lasso<ul> <li>p = 1</li> <li>Sparse</li> <li>With linear model : feature selection</li> </ul> </li> <li>Weight Decay<ul> <li>p = 2</li> <li>Bayesian</li> <li>Encourages optimization trajectory perpendicular to isocurves</li> <li></li> </ul> </li> </ul> </li> <li>Tune (\\(\\lambda\\)\\)<ul> <li>Grid search : log scale</li> <li>Too large : underfit, too small : overfit</li> <li>Cross Validation required</li> </ul> </li> </ul>"},{"location":"KB/Lumbar%20Puncture%20or%20Spinal%20Tap/","title":"Lumbar Puncture or Spinal Tap","text":""},{"location":"KB/Lumbar%20Puncture%20or%20Spinal%20Tap/#lumbar-puncture-or-spinal-tap","title":"Lumbar Puncture or Spinal Tap","text":"<ul> <li>Drawing of cerebrospinal fluid from the lumbar region of the back using a hollow needle</li> </ul>"},{"location":"KB/MAE/","title":"MAE","text":""},{"location":"KB/MAE/#mae","title":"MAE","text":"<ul> <li>loss converges to median of targets</li> <li>issues if gradient is close to 0</li> <li> \\[L(y, \\hat y) = n^{-1}\\Sigma_{i}|\\hat y _{i} -y_{i}|\\] </li> </ul>"},{"location":"KB/MAPE/","title":"MAPE","text":""},{"location":"KB/MAPE/#mape","title":"MAPE","text":"<ul> <li>mean absolute % error</li> </ul> \\[\\frac{1}{\\mathrm{length}\\left( y \\right)} \\cdot \\mathrm{sum}\\left( \\left\\|\\frac{y - \u0177}{y}\\right\\| \\right)\\]"},{"location":"KB/MCMC%20Sampling/","title":"MCMC Sampling","text":""},{"location":"KB/MCMC%20Sampling/#mcmc-sampling","title":"MCMC Sampling","text":"<ul> <li>Complex distribution with only a proto PDF \\(g_{0}\\) that is known</li> <li>Markov Chain</li> <li>Detailed Balance<ul> <li>Sufficient but not necessary for Markov Chain to be a Sampler for g</li> </ul> </li> <li>Factors for MC estimate</li> </ul>"},{"location":"KB/MCnet/","title":"MCnet","text":""},{"location":"KB/MCnet/#mcnet","title":"MCnet","text":"<ul> <li>Encoder-Decoder Convolutional Neural Network and Convolutional LSTM for video prediction </li> <li>two encoders, one is Content Encoder to capture the spatial layout of an image, and the other is Motion Encoder to model temporal dynamics within video clips. </li> <li>The spatial features and temporal features are concatenated to feed to the decoder to generate the next frame </li> <li>separately modeling temporal and spatial features, this model can effectively generate future frames recursively. </li> <li>Videos consist of various lengths of frames which have rich spatial and temporal information </li> <li>inherent temporal information within videos can be used as supervision signal for self-supervised feature learning </li> <li>pretext tasks have been proposed by utilizing temporal context relations including temporal order verification [29], [40], [90] and temporal order recognition [27], [39]</li> </ul>"},{"location":"KB/MILAN/","title":"MILAN","text":""},{"location":"KB/MILAN/#milan","title":"MILAN","text":"<ul> <li>Natural Language Descriptions of Deep Visual Features</li> <li>Some neurons in deep networks specialize in recognizing highly specific perceptual, structural, or semantic features of inputs</li> <li>identifying neurons that respond to individual concept categories</li> <li>richer characterization of neuron-level computation</li> <li>mutual-information-guided linguistic annotation of neurons</li> <li>generate open-ended, compositional, natural language descriptions of individual neurons in deep networks</li> <li>generates a description by searching for a natural language string that maximizes pointwise mutual information with the image regions in which the neuron is active</li> <li>MILANNOTATIONS</li> <li>fine-grained descriptions that capture categorical, relational, and logical structure in learned features</li> <li>characterizing the distribution and importance of neurons selective for attribute, category, and relational information in vision models.</li> <li>auditing, surfacing neurons sensitive to protected categories like race and gender in models trained on datasets intended to obscure these features</li> <li>editing, improving robustness in an image classifier by deleting neurons sensitive to text features spuriously correlated with class labels</li> </ul>"},{"location":"KB/MILANNOTATIONS/","title":"MILANNOTATIONS","text":""},{"location":"KB/MILANNOTATIONS/#milannotations","title":"MILANNOTATIONS","text":"<ul> <li>a dataset of fine-grained image annotations</li> </ul>"},{"location":"KB/MIMD/","title":"MIMD","text":""},{"location":"KB/MIMD/#mimd","title":"MIMD","text":"<ul> <li>Multiple instruction, multiple data</li> <li>Synchronous/Async , deterministic/non deterministic</li> <li>Most supercomputers</li> <li>Grids</li> <li>Multi processor SMP computers</li> <li>Also include SIMD sub components</li> <li></li> </ul>"},{"location":"KB/MISD/","title":"MISD","text":""},{"location":"KB/MISD/#misd","title":"MISD","text":"<ul> <li>Multiple instructions on single data</li> <li>Real time computers need to be fault tolerant where several processors execute the same data for producing the redundant data</li> <li>N-version programming</li> <li></li> </ul>"},{"location":"KB/MIT1003/","title":"MIT1003","text":""},{"location":"KB/MIT1003/#mit1003","title":"MIT1003","text":"<ul> <li>\"779 landscape images and 228 portrait images.\"</li> <li>The fixations were measured while 15 observers looked at an image for 3 s.</li> </ul>"},{"location":"KB/MIT300/","title":"MIT300","text":""},{"location":"KB/MIT300/#mit300","title":"MIT300","text":"<ul> <li>was the first data set with held-out human eye movements and is used as benchmark test data in MIT Saliency Benchmark</li> <li>\"300 natural\"</li> <li>The fixations were measured while 39 observers looked at an image for 3 s.</li> <li>\"indoor and outdoor scenes.\"</li> </ul>"},{"location":"KB/ML%20Production%20Flow/","title":"ML Production Flow","text":"","tags":["mlops"]},{"location":"KB/ML%20Production%20Flow/#ml-production-flow","title":"ML Production Flow","text":"<ul> <li>Project Setup</li> <li>Data Pipeline</li> <li>Modelling and training</li> <li>Serving</li> </ul>","tags":["mlops"]},{"location":"KB/MLCompany/","title":"MLCompany","text":""},{"location":"KB/MLCompany/#mlcompany","title":"MLCompany","text":"<ul> <li>Talent search : Rach\u00e8l Post : rpost@micompany.nl</li> </ul>"},{"location":"KB/MLCompany/#about-the-company","title":"About the Company","text":"<ul> <li>Accelerate and scale impact from AI.\u200b</li> <li>People and machines working together is already rocketing companies to new highs. This takes change and effort. But we\u2019re here to make it effortless for you.</li> <li>Build a globally defined and unified model production line. Enable model governance, in line with regulations.</li> <li>We\u2019ll help build up your team with AI skills in no time : train-the-trainer</li> <li>To achieve impact with Algorithms, we need to start with rethinking how you can change the way you do business. How more and better predictions can help changing the way you serve your customers, and run your operations. \u200b</li> <li>Predictions that can support or replace the decision making of your people. Through integrating these predictions into new digital applications, or into your existing system landscape.\u200b</li> <li>In both scenario\u2019s we go beyond the proof of concept and focus on AI that runs operational. Through connecting data, algorithms and applications we make your organization run smarter.\u200b</li> </ul>"},{"location":"KB/MLCompany/#inventory-management","title":"Inventory Management","text":"<ul> <li>AI in Supply Chain: A Novel Risk-based Approach to Inventory Management \u2013 MIcompany</li> <li>Inventory management, a critical component of the supply chain, involves ensuring that the right products are in the right place at the right time.</li> <li>In this article, we will present a novel approach to Inventory Management demand prediction which incorporates overstock costs and under-order costs into the decision-making process, as a complement to machine-learning time-series modeling</li> <li>While cost minimization lies at the core of this approach, supply chain managers may further customize this model to better address corporate goals and targets</li> <li>Inaccuracies in high-variance fast-moving items are understandable, and near-perfect accuracy is unattainable by even the best of models, so for a company whose inventory centers around fast-moving items, even generic trend predictions have the potential to make a sizable impact, and some AI-oriented startups claim to have made progress on that front.</li> <li>the forecast model with the highest possible accuracy is not necessarily that which is best for the business</li> <li>On the one hand, a business must have a comprehensive understanding of the possible costs it faces, which requires deep business and domain expertise.</li> <li>achieving near-optimal accuracy levels is nonetheless crucial, as a poor demand prediction model will impact all items alike</li> <li>The risk-based approach to inventory management utilizes over-ordering costs and under-ordering costs in the inventory level decision-making process.</li> <li>For instance, if an aircraft is sidelined due to engine failure and the airline does not have the exact engine model on hand, the airline will have no choice but to make an urgent shipment, often at a cost which may be 10-15% higher than the typical, non-urgent shipment; this is a prime example of an understock cost. Conversely, if the supplier orders too many engines which end up unused, they may be ultimately sold at a loss or written off entirely, in addition to the cost of capital incurred from ordering unnecessary items; both are considered over-ordering costs.</li> <li>By combining statistical methods and the industry\u2019s domain expertise regarding inventory costs, this system predicts the stock level which minimizes expected inventory costs.</li> </ul>"},{"location":"KB/MLCompany/#about","title":"About","text":"<ul> <li>About MIcompany \u2013 MIcompany</li> <li>ECG Analytics University</li> <li>Together with eBay, we are building the AI skills for a large and diverse group of employees to apply the power of AI and data</li> <li>KPN</li> <li>jointly built AI applications to optimize its network investments in DSL, fiber, and 5G.</li> <li>LeasePlan</li> <li>built a new AI platform and system that can value and price used cars more reliable than ever.</li> <li>change is not a cool AI-project or algorithm, but rather, it is about driving breakthroughs in directions that will last for many decades and leverage the potential of AI.</li> <li>We believe that to grasp the full potential of AI, a fundamental redesign of key processes is needed. This is a transformation that requires both a new way of working and new skill sets. We adopt a highly curious learning and highly practical doing mindset. Through our academy, we support our clients in building the skills required.</li> <li>MIcompany aims to push the good from AI by inspiring our people and clients. AI can make our life easier, more meaningful and healthier. We inspire our people and companies to capture these opportunities by identifying and capturing new application areas for AI.</li> </ul>"},{"location":"KB/MLCompany/#work","title":"Work","text":"<ul> <li>Diverse work with many different clients </li> <li>All-year coaching and trainings to really make you the best </li> <li>Nice people and an employee-centric organization</li> </ul>"},{"location":"KB/MLDoc/","title":"MLDoc","text":""},{"location":"KB/MLDoc/#mldoc","title":"MLDoc","text":""},{"location":"KB/MLIM/","title":"MLIM","text":""},{"location":"KB/MLIM/#mlim","title":"MLIM","text":"<ul> <li>MLIM: Vision-and-language Model Pre-training with Masked Language and Image Modeling</li> <li>Vision-and-Language Pre-training (VLP) improves model performance for downstream tasks that require image and text inputs</li> <li>Typically, in addition to the [Masked Language Modeling] (MLM) loss, alignment-based objectives are used for cross-modality interaction, and RoI feature regression and classification tasks for Masked ImageRegion Modeling (MIRM)</li> <li>Alignment-based objectives require pairings of image and text and heuristic objective functions</li> <li>Masking policies either do not take advantage of multi-modality or are strictly coupled with alignments generated by other models</li> <li>pre-trained using two pre-training tasks as a multi-loss objective given a mini-batch of image-text pairs: [Masked Language Modeling] (MLM) loss (as in BERT) for text, and image reconstruction (RECON) loss for image, coupled with Modality Aware Masking (MAM)</li> <li>determines the masking probability and applies masking to both word and image embedding</li> <li>based on BERT predict the masked words from available words and image regions</li> <li>follow BERT for this task: two-layer MLP MLM head outputting logits over the vocabulary</li> <li>MLM loss is negative log-likelihood for masked word</li> <li>RECON loss is an an average of pixel-wise sum of squared errors (SSE)</li> <li>Both image and word masking is realized by replacing an embedding with the embedding of <code>[MASK]</code></li> <li>transformer layers recognize <code>[MASK]</code></li> <li>\u2019s embedding as a special embedding that needs to be \u201cfilled in\u201d, independent of the modality, by attending to other vectors in the layer inputs</li> <li>unlike other architectures (LXMERT, UNiTER, ViLBERT, VLP, VL-BERT, VisualBERT, etc.), image masking is not based on image regions detected by the object detector, but a shallow CNN as an image embedder which is much more lightweight than deep models like ResNet and is designed to be masking friendly</li> <li>MLM + RECON losses apply only to the masked text/image areas and measure reconstructed text and image quality.</li> <li>no specific alignment loss</li> <li>[Modality] Aware Masking (MAM) to boost cross-modality interaction and take advantage of MLM and RECON losses that separately capture text and image reconstruction quality</li> <li>Since the the task of finding closely-matching (CM) item pairs requires a pair of image+text inputs, they exploit this multi-modality by employing Modality Dropout</li> <li>text-only, image-only, and image-text mode</li> <li>However, RECON instead of ITM loss offers better PR AUC</li> <li>Similarly, using the ITM loss together with MLM and RECON does not change the performance</li> </ul>"},{"location":"KB/MLM/","title":"MLM","text":""},{"location":"KB/MLM/#mlm-masked-language-modeling","title":"MLM (Masked Language Modeling)","text":"<ul> <li>from</li> <li>15% of the words in each sequence are replaced by\u00a0<code>[MASK]</code></li> <li>model tries to predict original values of the masked words</li> <li>uses the context provided by the other non-masked words in the sequences</li> <li>loss function only considers the predictions of the masked words, ignores non-masked ones<ul> <li>leads to slower convergence than with directional models</li> </ul> </li> <li>additions to standard architecture:<ul> <li>classification layer on top of the encoder output</li> <li>multiplying the encoders output vectors with the embedding matrix -&gt; transforms them into the vocabulary dimension</li> <li>calculating probability of each word in the vocabulary using\u00a0Softmax</li> </ul> </li> </ul>"},{"location":"KB/MLOps%20Learning/","title":"MLOps","text":"","tags":["mlops"]},{"location":"KB/MLOps%20Learning/#mlops-learning","title":"MLOps Learning","text":"","tags":["mlops"]},{"location":"KB/MLOps%20Learning/#list-of-things-i-want-to-learn","title":"List of Things I Want to Learn","text":"<ul> <li>This is as of 19th oct 2023 : 2023_10_19 </li> <li>More git commands that would be useful</li> <li>SQL + nosql </li> <li>REST API</li> <li>Kubernets/Airflow</li> <li>Unit testing in python</li> <li>https://fullstackdeeplearning.com/course/2022/</li> </ul>","tags":["mlops"]},{"location":"KB/MMLU/","title":"MMLU","text":""},{"location":"KB/MMLU/#mmlu","title":"MMLU","text":""},{"location":"KB/MNIST/","title":"MNIST","text":""},{"location":"KB/MNIST/#mnist","title":"MNIST","text":"<ul> <li>10 classes</li> <li>2 channels</li> <li>dataset consisting of handwritten digits</li> <li>28x28 pixels</li> <li>70'000 images</li> </ul>"},{"location":"KB/MRI/","title":"MRI","text":""},{"location":"KB/MRI/#mri","title":"MRI","text":"<ul> <li>Studies brain anatomy</li> <li>1 image</li> <li>1mm</li> <li>1) Put subject in big magnetic field (leave him there)  </li> <li>2) Transmit radio waves into subject [about 3 ms]  </li> <li>3) Turn off radio wave transmitter  </li> <li>4) Receive radio waves re-transmitted by subject  <ul> <li>Manipulate re-transmission with magnetic fields during this readout interval [10-100 ms: MRI is not a snapshot]  </li> </ul> </li> <li>5) Store measured radio wave data vs. time  <ul> <li>Now go back to 2) to get some more data  </li> </ul> </li> <li>Process raw data to reconstruct images  </li> <li>Allow subject to leave scanner</li> </ul>"},{"location":"KB/MSCOCO/","title":"MSCOCO","text":""},{"location":"KB/MSCOCO/#mscoco","title":"MSCOCO","text":""},{"location":"KB/MSE/","title":"MSE","text":""},{"location":"KB/MSE/#mse","title":"MSE","text":"<ul> <li> \\[L(x) = \\Sigma_i ||D(E(x_i))||^2\\] </li> <li> \\[MSE = \\frac{1}{N} \\Sigma^N_{i=1}(p(x_i) - y_i)^2\\] </li> <li>loss converges to mean of targets</li> </ul>"},{"location":"KB/MSLE/","title":"MSLE","text":""},{"location":"KB/MSLE/#msle","title":"MSLE","text":"<ul> <li>MSE log error</li> <li>Use MSLE when doing regression, believing that your target, conditioned on the input, is normally distributed, and you don\u2019t want large errors to be significantly more penalized than small ones, in those cases where the range of the target value is large.</li> </ul> \\[\\frac{1}{\\mathrm{length}\\left( y \\right)} \\cdot \\mathrm{sum}\\left( \\left( \\log\\left( y + 1 \\right) - \\log\\left( \u0177 + 1 \\right) \\right)^{2} \\right)\\]"},{"location":"KB/MUSAN/","title":"MUSAN","text":""},{"location":"KB/MUSAN/#musan","title":"MUSAN","text":"<ul> <li>which consists of over 900 noises, 42 hours of music from various genres and 60 hours of speech from twelve languages</li> </ul>"},{"location":"KB/MVCNN/","title":"MVCNN","text":""},{"location":"KB/MVCNN/#mvcnn","title":"MVCNN","text":"<ul> <li>Multi view CNN for 3D object recognition</li> <li>Limitations</li> <li>Generating multi-views is time consuming process</li> <li>Objects are partially visible due to (self) occlusion</li> <li>Number of categories should be defined in advance.</li> <li></li> </ul>"},{"location":"KB/MVGrasp/","title":"MVGrasp","text":""},{"location":"KB/MVGrasp/#mvgrasp","title":"MVGrasp","text":"<ul> <li>H. Kasaei, et al. \"MVGrasp: Real-Time Multi-View 3D Object Grasping in Highly Cluttered Environments.\" arXiv preprint arXiv:2103.10997 (2021).</li> <li>Render multiple views of objects and use a next best view view selection algorithm Generate pixel-wise grasp configuration for the given object view.  </li> <li>The gripper approaches the target object in an arbitrary direction.  </li> <li>Use a shallow network, and an eye-to-hand camera configuration.</li> <li></li> <li>Mixed autoencoder (CAE + DAE)  </li> <li>optimizer: RMSprop, learning_rate = 0.001  </li> <li>metrics: Intersection over Union (IoU) and reconstruction error loss: mean squared error</li> <li></li> <li>Which view is suitable?<ul> <li>Depends on the pose of the target object and other objects  </li> <li>Most objects are graspable from either top or side -&gt; orthographic setup</li> <li>View entropy is used as the metric for selecting the best view</li> </ul> </li> </ul>"},{"location":"KB/Machine%20Learning%20Tool%20Landscape/","title":"Machine Learning Tool Landscape","text":"","tags":["mlops"]},{"location":"KB/Machine%20Learning%20Tool%20Landscape/#machine-learning-tool-landscape","title":"Machine Learning Tool Landscape","text":"<ul> <li>https://huyenchip.com/2020/06/22/mlops.html</li> </ul>","tags":["mlops"]},{"location":"KB/Machine%20Learning%20Tool%20Landscape/#stages","title":"Stages","text":"<ul> <li>ML Production Flow</li> <li></li> <li>Pre Alex Net  (pre-2012)<ul> <li>Mostly modeling and training, small frameworks</li> </ul> </li> <li>(2012-2015)<ul> <li>Let's throw data at it</li> <li>Data Pipeline</li> <li></li> </ul> </li> <li>(2016-now)<ul> <li>Production</li> <li>Most companies cant' afford pure research</li> <li>Serving tools</li> </ul> </li> </ul>","tags":["mlops"]},{"location":"KB/Machine%20Learning%20Tool%20Landscape/#problems","title":"Problems","text":"<ul> <li>Problems facing MLOps</li> <li></li> </ul>","tags":["mlops"]},{"location":"KB/Macroadaptation/","title":"Macroadaptation","text":""},{"location":"KB/Macroadaptation/#macroadaptation","title":"Macroadaptation","text":"<ul> <li>Among four common designs for outer loops, the most complex is based on a pedagogy called macroadaptation (Corbett &amp; Anderson, 1995; Shute, 1993)</li> <li>For each task that the tutoring system can assign, it knows which knowledge components are exercised by the task. For each Knowledge Component, the tutor maintains an estimate of the student's degree of mastery of that Knowledge Component</li> <li>When a student has completed a task and the tutor needs to select the next one, it chooses one based on the overlap between the tasks' knowledge components and the student's mastered knowledge components</li> <li>For example, it might assign a task that requires many knowledge components that are already mastered by the student and just two components that are not yet mastered.</li> <li>Some tutoring systems represent not only correct and incorrect knowledge components, but also other stable traits of students. They might represent learning styles and preferences, such as a preference for visual or verbal explanations, so they can choose tasks that are marked as compatible with the student's style or preference.</li> <li>For the outer loop to function correctly across multiple tasks and sessions, the information about the student must be stored on a server or on the student's computer's disk. This persistent information is often called a student model. Exactly what it contains depends on the type of outer loop</li> </ul>"},{"location":"KB/Magic3D/","title":"Magic3D","text":""},{"location":"KB/Magic3D/#magic3d","title":"Magic3D","text":"<ul> <li>text to 3D model</li> <li>While the Dreamfusion model achieves remarkable results, the method has two problems</li> <li>long processing time</li> <li>low-quality of the generated images</li> <li>these problems are addressed by Magic3D using a two-stage optimization framework</li> <li>Magic3D builds a low-resolution difusion prior and, then, it accelerates with a sparse 3D hash grid structure</li> <li>a textured 3D mesh model is furthered optimized with an ecient diferentiable render</li> <li>higher quality 3D shapes in both geometry and texture compared to DreamFusion</li> </ul>"},{"location":"KB/Magical%20maybe/","title":"Magical maybe","text":"<p>toc: true title: Magical maybe</p> <p>categories: ['temp']</p>"},{"location":"KB/Magical%20maybe/#magical-maybe","title":"Magical Maybe","text":"<ul> <li>Robert Sapolsky</li> <li>According to this idea; the individual may or may not find a notification when looking on the phone. There is a large increase in Dopamine levels when the indication is seen.</li> </ul>"},{"location":"KB/Magnetic%20Detectors/","title":"Magnetic Detectors","text":""},{"location":"KB/Magnetic%20Detectors/#magnetic-detectors","title":"Magnetic Detectors","text":"<ul> <li>Robot sensors that can sense the presence of ferromagnetic material. Solid-state detectors with appropriate amplification and processing can locate a metal object to a high degree of precision.</li> </ul>"},{"location":"KB/Malignant/","title":"Malignant","text":""},{"location":"KB/Malignant/#malignant","title":"Malignant","text":"<ul> <li>Refers to the presence of cancerous cells in a tumor or growth</li> </ul>"},{"location":"KB/Mallows%20Cp%20Statistic/","title":"Mallows Cp Statistic","text":""},{"location":"KB/Mallows%20Cp%20Statistic/#mallows-cp-statistic","title":"Mallows Cp Statistic","text":"<ul> <li> \\[C_{p}= \\frac{1}{n}(RSS + 2 p \\hat \\sigma^{2})\\] </li> </ul>"},{"location":"KB/Manhattan%20Distance/","title":"Manhattan Distance","text":""},{"location":"KB/Manhattan%20Distance/#manhattan-distance","title":"Manhattan Distance","text":"<ul> <li>Taxicab distance or City Block distance, calculates the distance between real-valued vectors</li> <li> \\[D(x,y) = \\Sigma_{i=1}^{k}|x_{i}-y_{i}|\\] </li> <li>There is no diagonal movement involved in calculating the distance.</li> <li>Manhattan distance seems to work okay for high dim data, it is a measure that is somewhat less intuitive than euclidean distance, especially when using in high-dimensional data</li> <li>more likely to give a higher distance value than euclidean distance since it does not the shortest path possible.</li> <li>When your dataset has discrete and/or binary attributes, Manhattan seems to work quite well since it takes into account the paths that realistically could be taken within values of those attributes.</li> </ul>"},{"location":"KB/Manifold%20MixUp/","title":"Manifold MixUp","text":""},{"location":"KB/Manifold%20MixUp/#manifold-mixup","title":"Manifold MixUp","text":"<ul> <li>mixes feature values generated from intermediate neural network layers.</li> <li>feedforward up to k layer of the network where the output feature maps are mixed</li> <li>The mixed feature maps are given input to the next layer and forward propagated up to the last layer.</li> <li>After the forward propagation, backward propagation is performed in the standard way with updated labels</li> </ul>"},{"location":"KB/Manifold/","title":"Manifold","text":""},{"location":"KB/Manifold/#manifold","title":"Manifold","text":"<ul> <li>Data manifolds are an abstraction</li> <li>Only geometric insights are important</li> <li>Locally around some point c where the PDF is large -&gt; It will stay large only for a small fraction of directions<ul> <li>Those directions span a low dimensional hyperplane around c</li> <li>\"low dimensional sheets\"</li> <li>curved path</li> </ul> </li> <li>In an n dimensional real vector space \\(\\mathbb{R}^{n}\\) . Embedding space<ul> <li>\\(m \\leq n\\) is a positive integer</li> <li>An m dim manifold \\(\\mathcal{M}\\) is a subset of the vector space where one can smoothly map a neighborhood of that point to a neighborhood of the origin in m dim Euclidean space<ul> <li>Locally represents Euclidean space</li> </ul> </li> </ul> </li> <li>Only surface and not interior</li> <li>No sharp edges or spikes</li> <li>Can be exploited by Adversarial Learning</li> <li>Examples<ul> <li>1 dim -&gt; Lines in some high dim figure : B</li> <li>2 dim -&gt; Surfaces : A</li> <li></li> <li></li> <li></li> <li></li> </ul> </li> </ul>"},{"location":"KB/Manifold/#refs","title":"Refs","text":"<ul> <li>tds</li> <li>way more stuff : bjlkeng #todo</li> </ul>"},{"location":"KB/ManifoldMix/","title":"ManifoldMix","text":""},{"location":"KB/ManifoldMix/#manifoldmix","title":"ManifoldMix","text":"<ul> <li>improve the hidden representations and decision boundaries of neural networks at multiple layers by mixing hidden representations rather than input samples.</li> </ul>"},{"location":"KB/Manipulator/","title":"Manipulator","text":""},{"location":"KB/Manipulator/#manipulator","title":"Manipulator","text":"<ul> <li>Gripper, hand, arm or other part of the body that can effect and move objects in the robot\u2019s environment</li> <li>Is an End-effector</li> </ul>"},{"location":"KB/Mapping%20to%20Geometry/","title":"Mapping to Geometry","text":""},{"location":"KB/Mapping%20to%20Geometry/#mapping-to-geometry","title":"Mapping to Geometry","text":"<ul> <li>Height Plots</li> <li>Contour</li> </ul>"},{"location":"KB/Marching%20Cubes/","title":"Marching Cubes","text":""},{"location":"KB/Marching%20Cubes/#marching-cubes","title":"Marching Cubes","text":"<ul> <li>3D version of Marching Squares</li> <li>Cell consists of 8 node values: (i+{0,1}, j+{0,1}, k+{0,1})</li> <li> <ol> <li>Consider a cell</li> </ol> </li> <li> <ol> <li>Classify each vertex as inside or outside</li> </ol> </li> <li> <ol> <li>Build an index</li> </ol> </li> <li> <ol> <li>Get edge list from table[index]</li> </ol> </li> <li> <ol> <li>Interpolate the edge location</li> </ol> </li> <li> \\[x = i + \\frac{(c-v[i])}{(v[i+1]-v[i])}\\] </li> <li> <ol> <li>Compute gradients</li> </ol> </li> <li>Finite Differences Central</li> <li> <ol> <li>Consider ambiguous cases</li> </ol> </li> <li>Midpoint Decider</li> <li>Asymptotic Decider</li> <li> <ol> <li>Go to next cell</li> </ol> </li> <li></li> </ul>"},{"location":"KB/Marching%20Cubes/#limitations","title":"Limitations","text":"<ul> <li>Produces many triangles</li> <li>Cannot represent sharp edges</li> <li>Produces \u201cugly\u201d (thin) triangles</li> <li>Produces ringing artifacts!</li> </ul>"},{"location":"KB/Marching%20Squares/","title":"Marching Squares","text":""},{"location":"KB/Marching%20Squares/#marching-squares","title":"Marching Squares","text":"<ul> <li>Also uses Interpolation</li> <li>Symmetries</li> <li></li> <li>Asymptotic Decider</li> <li>Midpoint Decider</li> </ul>"},{"location":"KB/Marching%20Tetrahedra/","title":"Marching Tetrahedra","text":""},{"location":"KB/Marching%20Tetrahedra/#marching-tetrahedra","title":"Marching Tetrahedra","text":"<ul> <li>Unstructured Grids</li> <li>May split other cell types into tetrahedra, however, at the cost of introduced error</li> <li>One - and three + or Two - and two +</li> </ul>"},{"location":"KB/Margin%20Ranking/","title":"Margin Ranking","text":""},{"location":"KB/Margin%20Ranking/#margin-ranking","title":"Margin Ranking","text":"<ul> <li>Creates a criterion that measures the loss given inputs x1x1x1 , x2x2x2 , two 1D mini-batch Tensors, and a label 1D mini-batch tensor yyy (containing 1 or -1).</li> <li>If y=1y = 1y=1 then it assumed the first input should be ranked higher (have a larger value) than the second input, and vice-versa for y=\u22121y = -1y=\u22121 .</li> <li>take avg</li> </ul> \\[\\frac{1}{\\mathrm{length}\\left( y \\right)} \\cdot \\mathrm{sum}\\left( \\mathrm{max}\\left( 0, \\left( - y \\right) \\cdot x1 - x2 + margin \\right) \\right)\\]"},{"location":"KB/Markov%20Chain/","title":"Markov Chain","text":""},{"location":"KB/Markov%20Chain/#markov-chain","title":"Markov Chain","text":"<ul> <li>Sequence of random variables such as \\(X_{n+1}\\) only depends on \\(X_{n}\\)</li> <li>Discrete time</li> <li>Stochastic process without memory</li> <li>Finite interval : [0, 1, \u2026 n]</li> <li>Right infinite : n = 1, 2, 3, \u2026</li> <li>Left right infinite : Integers<ul> <li>No start</li> </ul> </li> <li>Markov Initial Distribution</li> <li>Markov Transition Kernel</li> <li>Markov for Continuous Distributions</li> </ul>"},{"location":"KB/Markov%20Initial%20Distribution/","title":"Markov Initial Distribution","text":""},{"location":"KB/Markov%20Initial%20Distribution/#markov-initial-distribution","title":"Markov Initial Distribution","text":"<ul> <li>\\(P_{X}\\)</li> <li>Not needed for left right infinite ones</li> </ul>"},{"location":"KB/Markov%20Property/","title":"Markov Property","text":""},{"location":"KB/Markov%20Property/#markov-property","title":"Markov Property","text":"<ul> <li>A property of certain environments, where state transitions are entirely determined by information implicit in the current state and the agent\u2019s action.</li> </ul>"},{"location":"KB/Markov%20Random%20Field/","title":"Markov Random Field","text":""},{"location":"KB/Markov%20Random%20Field/#markov-random-field","title":"Markov Random Field","text":"<ul> <li>Generalized Markov Chain</li> </ul>"},{"location":"KB/Markov%20Transition%20Kernel/","title":"Markov Transition Kernel","text":""},{"location":"KB/Markov%20Transition%20Kernel/#markov-transition-kernel","title":"Markov Transition Kernel","text":"<ul> <li>\\(\\(T_{n}(x|y) = P_{n}(X_{n+1}= x | X_{n}= y)\\)\\) for all \\(x,y \\in S\\)</li> <li>Homogenous if \\(\\(T_{n}(x|y) = T_{n'}(x|y)\\)\\) for all n,n'</li> <li>First get a value from a random drow from \\(P_{X_{1}}\\)</li> <li>Then get the next from the distribution which is specified by the transition kernel</li> <li></li> </ul>"},{"location":"KB/Markov%20for%20Continuous%20Distributions/","title":"Markov for Continuous Distributions","text":""},{"location":"KB/Markov%20for%20Continuous%20Distributions/#markov-for-continuous-distributions","title":"Markov for Continuous Distributions","text":"<ul> <li>Family of PDF</li> <li>If a Markov Chain with state set S, matrix M is executed m times . The transition probabilities transmit between states and then, \\(\\(P(X_{n+m}=s_{j}|X_{n}= s_{i}) = M^{m}(i, j)\\)\\)</li> <li>where \\(M^{m}= M \\cdot M \\cdot M \u2026 \\cdot M\\) (m times)</li> <li>To get the PDF \\(\\(g^{n+1}(x) = \\int_{\\mathbb{R}^{k}}T(x|y)g^{n}(y)dy\\)\\)</li> <li>Invariant Distribution</li> </ul>"},{"location":"KB/Masked%20Autoencoders/","title":"Masked Autoencoders","text":""},{"location":"KB/Masked%20Autoencoders/#masked-autoencoders","title":"Masked Autoencoders","text":"<ul> <li>Masked Autoencoders are Scalable Vision Learners</li> <li>simple Self Supervised</li> <li>ImageNet and in Transfer Learning that an Auto Encoders \u2014- a simple self-supervised method similar to techniques in NLP \u2013 provides scalable benefits</li> <li>mask random patches of the input image and reconstruct the missing pixels</li> <li>asymmetric encoder-decoder architecture, with an encoder that operates only on the visible subset of patches (without mask tokens), along with a lightweight decoder that reconstructs the original image from the latent representation and mask tokens</li> <li>images and languages are signals of a different nature</li> <li>Images are merely recorded light without a semantic decomposition into the visual analogue of words</li> <li>The word (or subword) analog for images are pixels</li> <li>But decomposing the image into patches (like Vision Transformer reduces the quadratic computation cost of transformers compared to operating at the pixel level</li> <li>remove random patches that most likely do not form a semantic segment</li> <li>Likewise, MAE reconstructs pixels, which are not semantic entities</li> <li>hey find that masking a high proportion of the input image, e.g., 75%, yields a nontrivial and meaningful self-supervisory task</li> <li>train and throw away the decoder and fine-tune the encoder for downstream tasks</li> <li>Vanilla ViT-Huge model (ViTMAE) achieves the best accuracy</li> <li>ImageNet</li> <li>Transfer performance in downstream tasks outperforms supervised pre-training and shows promising scaling behavior</li> <li>semantics</li> <li>Occurs by way of a rich hidden representation inside the MAE</li> <li></li> </ul>"},{"location":"KB/Masked%20Language%20Modeling/","title":"Masked Language Modeling","text":""},{"location":"KB/Masked%20Language%20Modeling/#masked-language-modeling","title":"Masked Language Modeling","text":"<ul> <li>In Masked Language Modeling, an input sequence of tokens is provided, but with some of these tokens masked. The goal of the model is then to learn to predict the correct tokens that are hidden by the mask. If it can do so, it can learn token-level information given the context of the token.</li> <li>In BERT, this is done as follows. 15% of all word embedded tokens is masked at random. From this 15%, 80% of the tokens is represented with a token called , 10% is replaced with a random token and 10% is left alone. This ensures that masking is both relatively random and that the model does not zoom in to the token, which is available during pretraining but not during fine-tuning.</li> <li>This model is also capable of predicting words using the two masked sentences. It concatenates two masked words and tries to predict.</li> <li>these models where we are required to predict the context of words. Since the words can have different meanings in different places the model needs to learn deep and multiple representations of words.</li> <li>These models have shown improved performance levels in the downstream tasks such as syntactic tasks that require lower layer representation of certain models in place of a higher layer representation.</li> <li>We may also find their use in learning the deep bidirectional representations of words. The model should be able to learn the context of words from the start of the sentence as well as from the behind.</li> </ul>"},{"location":"KB/Masked%20Language%20Modeling/#tokenizing-data-bert","title":"Tokenizing Data BERT","text":"<ul> <li>In the tokenizer method, text_lst is the text corpus, max_length suggests the maximum number of allowable input tokens (the maximum is 512 for BERT base), and truncation set to True indicates that if the input size is more than the max_length, then the token from index number equal to max_length would be truncated i.e., for our example input tokens from index 100 would be dropped, padding set to True indicates the input length shorter than the max_length are padded, with padding token 0 and lastly, return_tensors indicates in what format do we want the output tensor and tf suggests that we expect tensorflow tensor. The tokenizer here returns three fields, as we have mentioned earlier.</li> <li>Now if we look at the \u201cinputs\u201d with the code print(inputs), we can see that the input_ids tensor is of shape 1567\u00d7100, and each row starts with the token 101, which is the id for the Special token [CLS] and ends with 0 which is the padding token indicating that the sentence length is less than 100. Also, there is a Special token 102, the [SEP] token, which is not visible, indicating the end of a sentence. Secondly, the token_type_ids are all 0 as there is only a single sentence as input. Finally, the attention_mask has ones at locations for the actual input tokens and zeros for the padding tokens.</li> </ul>"},{"location":"KB/Masked%20Language%20Modeling/#masking-input-tokens-bert","title":"Masking Input Tokens BERT","text":"<ul> <li>In the original research paper, 15% of the input tokens were masked, of which 80% were replaced with [MASK] tokens, 10% were replaced with random tokens, and another 10% were left as is. However, in our fine-tuning task, we are replacing 15% of the input tokens except for the special ones with only [MASK] i.e., we will not replace token numbers 101,102, and 0 with mask token 103. In the following lines of codes, the same logic is implemented</li> </ul>"},{"location":"KB/Mastectomy/","title":"Mastectomy","text":""},{"location":"KB/Mastectomy/#mastectomy","title":"Mastectomy","text":"<ul> <li>Surgical procedure to remove part or all of the breast</li> </ul>"},{"location":"KB/Mastery%20learning/","title":"Mastery learning","text":""},{"location":"KB/Mastery%20learning/#mastery-learning","title":"Mastery Learning","text":"<ul> <li>The outer loop implements a pedagogy called mastery learning (Bloom, 1984).</li> <li>The curriculum is structured as a sequence of units or a sequence of difficulty levels. When a student is working on a unit (or level of difficulty), the tutoring system keeps assigning tasks from that unit until the student has mastered the unit's knowledge. Only then does it allow the student to proceed to the next unit</li> <li>Thus, some students finish the curriculum having done fewer tasks than other students.</li> <li>This design for the outer loop is mostly used in self-paced courses.</li> <li>It is seldom used for a class-paced course, where it is important that all students stay together as they move through the curriculum.</li> <li>A common mistake is to develop a tutoring system with a fancy outer loop, then discover that instructors cannot use its features due to the class-paced nature of the course.</li> </ul>"},{"location":"KB/Material%20Processing%20Robot/","title":"Material Processing Robot","text":""},{"location":"KB/Material%20Processing%20Robot/#material-processing-robot","title":"Material Processing Robot","text":"<ul> <li>A robot designed and programmed so that it can machine, cut, form or change the shape, function or properties of materials it handles between the time the materials are first grasped and the time they are released in a manufacturing process.</li> </ul>"},{"location":"KB/Max%20Margin%20Loss/","title":"Max Margin Loss","text":""},{"location":"KB/Max%20Margin%20Loss/#max-margin-loss","title":"Max Margin Loss","text":"<ul> <li>Makes sure only dissimilar pairs with minimum distance m contribute to the loss</li> <li>Spring mass system</li> <li>Hinge Loss probably ??</li> </ul>"},{"location":"KB/Maximum%20Distance%20Baseline/","title":"Maximum Distance Baseline","text":""},{"location":"KB/Maximum%20Distance%20Baseline/#maximum-distance-baseline","title":"Maximum Distance Baseline","text":"<ul> <li>This baseline is called the Maximum Distance baseline and creates a baseline by constructing an image with the largest value of the L1 distance from the original image</li> <li>The problem with the maximum distance is that it doesn\u2019t represent the \u201cabsence of feature\u201d. It contains the information about the original image, just in a different form.</li> </ul>"},{"location":"KB/Maximum%20Matching%20Algorithm/","title":"Maximum Matching Algorithm","text":""},{"location":"KB/Maximum%20Matching%20Algorithm/#maximum-matching-algorithm","title":"Maximum Matching Algorithm","text":"<ul> <li>Greedy</li> <li>Starts with first character</li> <li>Searches for the longest word in list starting with this character. If match is found, boundary is marked</li> </ul>"},{"location":"KB/Maxout/","title":"Maxout","text":""},{"location":"KB/Maxout/#maxout","title":"Maxout","text":"<ul> <li> \\[f(x) = max(x, x\\cdot a)\\] </li> </ul>"},{"location":"KB/Mean%20Diffusivity/","title":"Mean Diffusivity","text":""},{"location":"KB/Mean%20Diffusivity/#mean-diffusivity","title":"Mean Diffusivity","text":"<ul> <li> \\[\\mu = \\frac{\\lambda _{1}+ \\lambda_{2}+ \\lambda_{3}}{3}\\] </li> <li></li> </ul>"},{"location":"KB/Mean%20Observed%20Dissimilarity/","title":"Mean Observed Dissimilarity","text":""},{"location":"KB/Mean%20Observed%20Dissimilarity/#mean-observed-dissimilarity","title":"Mean Observed Dissimilarity","text":"<ul> <li>is the mean of the NISSIM dissimilarity over the adversarial test set for similar levels of attack.</li> <li>So for every adversarial set X \u2217, calculate NISSIM value for all samples in that set, and divide by the total number of samples.</li> <li>(0,1], such that 0 indicates total similarity while 1 indicates total dissimilarity</li> <li> \\[MOD_{advset}= \\frac{1}{N}\\Sigma (NISSIM_{i})\\] </li> </ul>"},{"location":"KB/Media%20Distillery/","title":"Media Distillery","text":""},{"location":"KB/Media%20Distillery/#media-distillery","title":"Media Distillery","text":""},{"location":"KB/Media%20Distillery/#contact","title":"Contact","text":"<ul> <li>jobs@mediadistillery.com</li> <li>Jacqueline@mediadistillery.com</li> </ul>"},{"location":"KB/Media%20Distillery/#about","title":"About","text":"<ul> <li>Keep your viewers engaged to your platform along with every step of their journey</li> <li>Create new value with automated content chaptering, appealing images and topic labelling</li> <li>Enable better and more valuable ad placements in line with the content displayed</li> </ul>"},{"location":"KB/Media%20Distillery/#epg-correction","title":"EPG Correction","text":"<ul> <li>manually detecting\u00a0the start and end times of your TV programs, ad breaks and shorter video segments!</li> <li>redefine the\u00a0Electronic Program Guide (EPG) correction, content navigation and TV advertising using\u00a0state-of-the-art AI and Machine Learning technologies.</li> <li>By identifying the exact start and end times of ad breaks in video content, Ad Break Distillery enables ad skipping, insertion or replacement in the replay and catchup environment.</li> <li>With Chapter Markers viewers can easily navigate through video content to the parts they are interested in, which leads to a higher user engagement and satisfaction.</li> <li>EPG Correction\u2122 ensures seamless and VoD-like experiences for catch-up and replay by fully automated and real-time correction of the difference between the scheduled and the actual air times of TV programs.</li> <li>Media Distillery\u2019s award-winning Deep Content UnderstandingTM\u00a0technology can analyze video content to determine relevant topics, events or specific time markers, all in real-time and cloud-based. NOS implemented Media Distillery\u2019s product EPG Correction Distillery\u2122 on their 70 most popular TV channels, to provide automatic adjustments to update the actual start time of television programmes as they are broadcast, so consumers can enjoy their favorite video content instantly.</li> <li>NOS (NOS is the biggest communications and entertainment group in Portugal.) is also using the automatically generated\u00a0correct time markers\u00a0to insert pre-roll advertisements in their replay platform. This results in a natural transition from the content to the ad-block\u00a0for the consumer, while the inserted ads create\u00a0a solid revenue stream for NOS.</li> </ul>"},{"location":"KB/Media%20Distillery/#image-distillery","title":"Image Distillery","text":"<ul> <li>image chosen to be displayed in the UI is crisp and blur-free, that the actors\u2019/presenters\u2019 eyes are open, and the characters\u2019 positioning in-frame is aesthetically pleasing.</li> <li>The Images are created directly out of a broadcast signal or video asset, in a real-time and fully automated fashion. This means that even for live-programming appealing images can be provided and used to boost catch-up and replay viewing.</li> <li>Images can be generated from the entire program, or from a specified time range, to prevent inadvertently showing spoilers in the UI.</li> </ul>"},{"location":"KB/Media%20Distillery/#email","title":"Email","text":""},{"location":"KB/MediaMonks/","title":"MediaMonks","text":""},{"location":"KB/MediaMonks/#media-monks-cover-letter","title":"Media Monks Cover Letter","text":"<p>As Rogier Bikker's article on your website says, AI is truly taking the world by storm, but perhaps infinite content generation is not the key to customer engagement. At the end of the pipeline, what matters is the humans who use and are affected by technology. There are so many terms that keep showing up every day - ML, Computer Vision, Mixed reality. To most people, they do not mean much, but they have such tremendous potential if used wisely and with an understanding of the technologies. My interest is to help customers bring their visions to reality while also guiding them towards using AI better. </p> <p>My expertise is a combination of data analytics and computer vision, and as of a month ago, I also have a Master in Artificial Intelligence from the University of Groningen. I am familiar with the tools required for basic and advanced AI and analytics from internships, research projects, papers, freelance work, and many personal projects. But aside from that, I am an artist (Instagram : www.instagram.com/aiexistentialart). That being the case, I am quite familiar with Photoshop, Blender, and some other design and illustration tools. I've played with VR, can cook up demos on an Arduino, and am familiar with the technology behind StableDiffusion, RunwayML, MidJourney etc. Although I am not yet familiar with ZBrush, I do use Nomad Sculpt, and can learn pretty much any technology given time and some mentorship.</p> <p>As for talking about technical stuff in simpler terms, I have taught plenty of people about AI in workshops, webinars, and through many events. I write articles regularly and have been freelancing as a content creator for many years now.</p> <p>I have always loved creating concepts, both in my art (as a concept artist) and in my AI work. While it is impossible to be familiar with all the tools, they all share a common thread. That being the case, I will be able to contribute to any team I get to work with. It is not every day you find a position that you enjoy and also think you can contribute something to, and I sincerely hope you give me a chance to be a Monk with you :)</p>"},{"location":"KB/MediaMonks/#interview-prep","title":"Interview Prep","text":"<ul> <li>Hiring manager : Jakub Pawe\u0142czak </li> <li>Team members : Fredrick Charles Papworth,\u00a0Suzanne Elmazi, and\u00a0Ben Major</li> <li>They bridge between ideas and technology. They curate\u00a0creative\u00a0ideas and translate them through innovative solutions that are technology-based.</li> </ul>"},{"location":"KB/Median%20Filter/","title":"Median Filter","text":""},{"location":"KB/Median%20Filter/#median-filter","title":"Median Filter","text":"<ul> <li>Values are replaced by the median in a local surrounding</li> <li>non linear</li> <li>preserves edges</li> </ul>"},{"location":"KB/Mediatic%20Behavior/","title":"Mediatic Behavior","text":"<p>toc: true title: Mediatic Behavior</p> <p>categories: ['temp']</p>"},{"location":"KB/Mediatic%20Behavior/#mediatic-behavior","title":"Mediatic Behavior","text":"<ul> <li>Many individuals tend to resemble a role model.</li> <li>For example, in order to resemble the character in a television series, he or she unintentionally wears clothes similar to those she wore and uses his or her lines in daily life.</li> <li>This is basic type of media behavior</li> </ul>"},{"location":"KB/Memory%20Coupling/","title":"Memory Coupling","text":""},{"location":"KB/Memory%20Coupling/#memory-coupling","title":"Memory Coupling","text":"<ul> <li>TIghtly coupled</li> </ul>"},{"location":"KB/Memory%20to%20Memory%20Architecture/","title":"Memory to Memory Architecture","text":""},{"location":"KB/Memory%20to%20Memory%20Architecture/#memory-to-memory-architecture","title":"Memory to Memory Architecture","text":"<ul> <li>For all vector operation, operands are fetched directly from main memory, then routed to the functional unit</li> <li>Results are written back to main memory</li> <li>Large startup time</li> </ul>"},{"location":"KB/Memory-based%20learning/","title":"Memory-based learning","text":""},{"location":"KB/Memory-based%20learning/#memory-based-learning","title":"Memory-based Learning","text":"<ul> <li>Lazy learning</li> <li>All encountered examples are stored in memory in a multi-dimensional array, positioned according to relevant features</li> <li>New items are classified (comprehension) or generated (production) by searching for an example in memory that is closest to the target</li> <li>Because examplars are represented by their features even novel forms can be classified</li> <li>A generalization of the knn (k-nearest neighbors) algorithm</li> <li>Don't remove any infrequent or even solo forms. You might need the info</li> <li>Don't trim down the number of examples of a frequent form you have in the model. This effects it.</li> <li>Learning is storing, classification is analogy</li> <li>multiple long-distance dependencies</li> </ul>"},{"location":"KB/Mental%20Fatigue/","title":"Mental Fatigue","text":""},{"location":"KB/Mental%20Fatigue/#mental-fatigue","title":"Mental Fatigue","text":"<ul> <li>Resource depletion occurs</li> <li>Drop in motivation does not really happen</li> </ul>"},{"location":"KB/Mental%20Model%20Matching/","title":"Mental Model Matching","text":""},{"location":"KB/Mental%20Model%20Matching/#mental-model-matching","title":"Mental Model Matching","text":"<ul> <li>A user's mental model [42] of a technology is their internal understanding of how a technology works.</li> <li>People rely heavily on their mental models of technology to make decisions</li> <li>It has been found that XAI stakeholders use their mental models of XAI to decide when to use the technology [10], to evaluate how much to trust the outputted explanations [10, 20, 22], and to make sense of any results [22, 30]</li> <li>While ML practitioners may have had access to specialized training on how LLMs work, this is decidedly not the case for the vast majority of the general population</li> <li>How a general user believes an LLM to work may be very different from how it actually works, and this mismatch can be dangerous</li> <li>It is not difficult to imagine frightening scenarios where users anthropomorphize or deify an LLM chatbot, understanding it to be a \"magical\" source of ground truth. This could very quickly lead to conspiracy theories and the legitimization of disinformation campaigns [see, e.g., 23]</li> </ul>"},{"location":"KB/Mesh%20Smoothing/","title":"Mesh Smoothing","text":""},{"location":"KB/Mesh%20Smoothing/#mesh-smoothing","title":"Mesh Smoothing","text":"<ul> <li>Noisy volume data leads to a noisy surface grid:</li> <li>Smooth the volume data first, or</li> <li>Smooth the grid in post-processing</li> <li>Eventually simplifies the grid</li> </ul>"},{"location":"KB/Mesh%20refinement/","title":"Mesh refinement","text":""},{"location":"KB/Mesh%20refinement/#mesh-refinement","title":"Mesh Refinement","text":""},{"location":"KB/Mesolimbic%20Pathway/","title":"Mesolimbic Pathway","text":""},{"location":"KB/Mesolimbic%20Pathway/#mesolimbic-pathway","title":"Mesolimbic Pathway","text":"<ul> <li>A specialized brain circuit implicated in the processing of risk and reward information.</li> </ul>"},{"location":"KB/Meta%20AI%20Speech%20from%20Brain/","title":"Meta AI Speech from Brain","text":""},{"location":"KB/Meta%20AI%20Speech%20from%20Brain/#my-favourite-obsidian-plugins-for-research-notes-2-bonus-tips","title":"My Favourite Obsidian Plugins for Research Notes + 2 Bonus Tips","text":"<p>Obsidian is my favourite program for taking notes. Be it for research, general things I learn, summaries from papers, lecture notes and the like. Out of the box, it does so many things really well. But, its real power lies in the vast number of plugins it has. Most of these are user created, and you can even make your own (or hack one together)! In this sea of functionality, these are the top few that I use. Grouped by the type of task for easier lookup.</p> <p>(Disclaimer : I am not sponsored by either Obsidian or any of the authors of the plugins mentioned here. These are personal preferences.)</p>"},{"location":"KB/Meta%20AI%20Speech%20from%20Brain/#the-use-case","title":"The use case","text":"<p>I am a student, researcher and programmer. I take lecture notes, read a lot of research papers, articles and books. These come down to a lot of information. Of course, there\u2019s no way I can remember all of these bits of fragmented information.  Therefore, drumroll\u2026, I use Obsidian to help me put these bits of information in a place I can easily access. Since I use this almost everyday, I want taking notes to be as painless and efficient as possible.  These plugins are a huge help in doing exactly that. (Ordered by the type of task)</p>"},{"location":"KB/Meta%20AI%20Speech%20from%20Brain/#how-to-install-these-plugins","title":"How to install these plugins?","text":"<p>This is a simple step. Simple open Obsidian Settings, Scroll down a bit and select \u201cCommunity plugins\u201d. Disable Restrictive mode, and then browse to your hearts content!</p>"},{"location":"KB/Meta%20AI%20Speech%20from%20Brain/#writing","title":"Writing","text":"<p>Writing notes is the major objective here. So how do we make it extra painless? Plugins of course! - Dynamic Table of Contents : Many times, I take notes for a long form text. Sometimes these notes end up pretty huge, and it becomes slightly harder to find something. What about adding a Table Of Contents to the start? Sounds great, but what if we update the note? In comes this plugin, with an automatically updating TOC. - Tags : Super simple, also built in. Adding \u201c#topic1, #topic2 etc\u201d to a file to make it easier to search and organise. - Frontmatter Tag Suggest : Tags are great, but who remembers which ones they used before? Nobody. This plugin autocompletes tags based on ones you have used in previous notes. You can create new ones the normal way of course.  - Note Refactor : Made a huge note with a lot of headings? Why not split them into individual topics and maintain links to them? This makes it easier for you to have one major idea per note. Here I have a bunch of test headings, you can see how after applying them they become new notes that link to the current file. - Paste URL into selection : The name says it all doesn\u2019t it? - Templater : Another plugin I use daily. I like starting my notes with \u201cdate_created\u201d, \u201cdate_modified\u201d, \u201ctags\u201d, \u201ctoc: true title\u201d and insert the file name as the header. Since I do this for every single note, why not automate it? This plugin lets you create blocks of dynamic text to be inserted with a keyboard shortcut. I use \u201cCmd+Shift+I\u201d (\u201cControl+Shift+I\u201d for Windows) - Typewriter Scroll : Zen Mode is a way of life. This lets me focus on what I am writing by automatically scrolling the page, and dimming the rest of the text apart from the line I am currently writing. I do disable it while reading though. - Command Palette : This one is pretty obvious, but this built in plugin is just a text search. You can quickly open files with a (Cmd/Control + O) that brings up a searchable menu, or use (Cmd/Control + P) to bring up a searchable list of quick actions. - Vim Mode : This little option is not for everyone honestly. If you have never heard of Vim, just skip this point. I use vim as my default text editor for everything else. And I can\u2019t live without its keybindings. This just lets me use the vim keys for everything.</p>"},{"location":"KB/Meta%20AI%20Speech%20from%20Brain/#research","title":"Research","text":"<p>For research (AI research in my case), we have three main objectives :  - Merge important information from a large number of sources. - Find links between ideas that you did not see. - Maintain a daily log as something of a lab notebook. There are 5 plugins that fulfil these criteria pretty decently.  - Daily Notes : This is a Core plugin and comes with Obsidian. Essentially it\u2019s a journal. You can add whatever you want to it and it is created every day. I use it to keep a time stamped log of what I did that day. It is also useful if you just want to dump a bunch of information but don\u2019t want to format and organise it just yet. - TimeStamper : In my daily notes, I like having timestamps (eg - 9:30 : I did xyz). This plugin lets me set a custom format and a keyboard shortcut. I have set it to \u201cCmd+T\u201d (for Mac or Control+T for Windows) - Backlinks : A real game changer and another built in plugin. This shows you every file that either is linked in the current file, or refers to the current one. Identifying links between concepts, and finding more of them is absolutely invaluable in research. - Quick LaTEX for Obsidian : LaTEX is probably the easiest way of writing professional looking math-y stuff, be it equations or formulae or anything similar. This plugin has a lot of options for autocomplete, formatting, and makes my job almost ridiculously easy. Here\u2019s how it looks. (Just typing a random equation)</p>"},{"location":"KB/Meta%20AI%20Speech%20from%20Brain/#organising","title":"Organising","text":"<p>What do you do once you have a lot of files, you organise them of course! Now Obsidian by default makes it pretty easy to do this. But these plugins make organising less of a chore and much more of a fun thing to do. - Local Images : To make my notes more informative, I sometimes paste images. Now many times these are links from some website, which makes it a little risky, because what if the website stops working? This plugin automatically downloads image links in your notes and saves them locally. (It also links to the correct downloaded file.) - Graph view : Oh the gift and curse of a pretty graph. I sometimes use this to navigate between my links either to or from a file. It also gives me a very useful overview of what I have. I generally use the \u201cLocal graph\u201d that shows me a graph for the current note, rather than the \u201cGlobal\u201d full one which shows me everything. (It\u2019s pretty, but unhelpful) - Linter : Maybe I have a bunch of empty lines, empty list items, my headers are not in sentence case, my text is not formatted, my paragraphs are weird. Or anything like that. I am lazy, so I use the Linter plugin to automatically perform a bunch of processing and clean up my files.  - Tag Wrangler : Have a lot of tags? View/Edit/Change them across every file that uses them in one place. Also useful for finding files that match a few criteria. - File Cleaner : Remove empty files, unreferenced images etc. Keeping your \u201cDigital Garden\u201d pruned and bug free. - Obsidian Link Converter : Because I host my Obsidian Vault on a personal website, sometimes the links that Obsidian uses don\u2019t work, this plugin lets me mass convert them to a format that does.</p>"},{"location":"KB/Meta%20AI%20Speech%20from%20Brain/#bonus-tips","title":"Bonus tips!!","text":"<ul> <li>Make sure every file has a single major idea. If you have too many, use the \u201cNote Refactor\u201d to put them in their own files. This will make it extremely easy to refer to the \u201cIdeas\u201d in the text somewhere else instead of linking to the whole text. </li> <li>Want pages that consolidate all the notes that have a particular tag together and save them automatically to a single file? Say you want a file that has links to all the notes that have the tag \u201c#apple\u201d. Here is a little script that I wrote which does just that.</li> </ul>"},{"location":"KB/Meta%20AI%20Speech%20from%20Brain/#fin","title":"Fin","text":"<p>This article is in the hopes that it will help someone out. Maybe have the help that I did not. I do not know who it will reach. But to whoever it does, best of luck :)</p> <p>Like these/Want more? Buy me a coffee! Kofi</p> <p>Want articles on something specific? Just ask!</p> <p>You can always contact me on LinkedIn, or drop me an Email</p> <p>toc: true title: Meta AI Speech from Brain categories: ['architecture']</p>"},{"location":"KB/Meta%20AI%20Speech%20from%20Brain/#meta-ai-speech-from-brain","title":"Meta AI Speech from Brain","text":"<ul> <li>help people unable to communicate through speech, typing or gestures</li> <li>tries to decode language directly from noninvasive brain recordings</li> <li>challenge with this proposed method come from noise and diferences in each person's brain and where the sensors are placed.</li> <li>contrastive learning and used to maximally align noninvasive brain recordings and speech sounds</li> <li>A self-supervised learning model called wave2vec 2.0. is used to identify the complex representations of speech in the brains of volunteers listening to audiobooks</li> <li>The two noninvasive technologies used to measure neuronal activity are electroencephalography and magnetoencephalography.</li> <li>Training data comes from four opensource datasets which represent 150 hours of recordings of 169 volunteers listening to audiobooks</li> <li>EEG and MEG recordings are inserted into a brain model, which consists of a standard deep convolutional network with residual connections</li> <li>These recordings are what comes from individuals' brains</li> <li>both a speech model for sound and a brain model for MEG data.</li> <li>several components of the algorithm were beneficial to decoding performance</li> <li>algorithm improves as EEG and MEG recordings increase</li> <li>self-supervised trained AI can decode perveived speech despite noise and variability in that data.</li> </ul>"},{"location":"KB/Meta%20Learning%20Data%20Augmentations/","title":"Meta Learning Data Augmentations","text":""},{"location":"KB/Meta%20Learning%20Data%20Augmentations/#meta-learning-data-augmentations","title":"Meta Learning Data Augmentations","text":"<ul> <li>The concept of meta-learning in Deep Learning research generally refers to the concept of optimizing neural networks with neural networks.</li> <li>This approach has become very popular since the publication of NAS</li> </ul>"},{"location":"KB/Methods%20for%20Feature%20Learning/","title":"Methods for Feature Learning","text":""},{"location":"KB/Methods%20for%20Feature%20Learning/#methods-for-feature-learning","title":"Methods for Feature Learning","text":"<ul> <li>Start with a random dict and rep. Update D while keeping r fixed -&gt; find best r while keeping D fixed. Repeat until convergence.</li> <li>Move D in a direction to minimize loss and project it back<ul> <li>Gradient Descent gradients or LinearRegression</li> </ul> </li> </ul>"},{"location":"KB/Microbiota/","title":"Microbiota","text":""},{"location":"KB/Microbiota/#microbiota","title":"Microbiota","text":"<ul> <li>The community of various microorganisms found in the digestive tract. Scientists are now learning that microbes found in the microbiota can influence brain development, mood, and behavior.</li> </ul>"},{"location":"KB/Microglia/","title":"Microglia","text":""},{"location":"KB/Microglia/#microglia","title":"Microglia","text":"<ul> <li>A small, specialized glial cell that operates as the first line of immune defense in the central nervous system.</li> </ul>"},{"location":"KB/Micromarriage/","title":"Micromarriage","text":""},{"location":"KB/Micromarriage/#micromarriage","title":"Micromarriage","text":"<ul> <li>Micromarriages -- colah's blog</li> <li>A micromarriage is a one in a million chance that an action will lead to you getting married, relative to your default policy.</li> <li>Note that some actions, such as dying, have a negative number of micromarriages associated with them.</li> <li>Most people do not include being coercively forced into a marriage when calculating micromarriages.</li> </ul>"},{"location":"KB/Midpoint%20Decider/","title":"Midpoint Decider","text":""},{"location":"KB/Midpoint%20Decider/#midpoint-decider","title":"Midpoint Decider","text":"<ul> <li>check value in cell center and decide accordingly</li> <li></li> </ul>"},{"location":"KB/Midpoint%20Method/","title":"Midpoint Method","text":""},{"location":"KB/Midpoint%20Method/#midpoint-method","title":"Midpoint Method","text":""},{"location":"KB/Milin%20et%20al/","title":"Milin et al.","text":""},{"location":"KB/Milin%20et%20al/#milin-et-al","title":"Milin Et Al.","text":"<ul> <li>Towards cognitively plausible data science in language research (2016), Milin, Divjak, Dimitrijevic and Baayen</li> <li>Identify difficult and easy forms (from lemma to plural form)</li> <li>Check if human participants also react differently to independently identified difficult and easy forms Compare NDL learning model to TiMBL and human results</li> <li>MDVM computes the distance between two values of a feature to reflect their patterns of co-occurrence with categories</li> <li>Using MDVM adds an unsupervised learning component to MBL Hoste (2005) because essentially it clusters feature values and uses that information</li> <li>Using larger values of k with MDVM is helpful</li> <li>Easy words that are frequent tokens (forms) are reacted to faster</li> <li>Maybe this interaction doesn't occur with difficult words because there is less variation in the frequency of the difficult words?</li> <li>This seems similar to results with regular past tense forms in English:</li> <li>Strikingly, TiMBL's inflectional class probabilities turn out to be predictive in production and comprehension, i. e., for lexical decision latencies.</li> <li>Two Grapheme to Lexeme Measures</li> <li>Diversity Sum of the absolute values of the activations of all possible outcomes, given a set of input cues.</li> <li>Input cues that activate many different outcomes give rise to a highly diverse activation vector, which in turn indicates a high degree of uncertainty about the intended outcome.</li> <li>G2L-Prior Sum of the absolute values of the weights on the connections from all cues to a given outcome.</li> <li>independent of the actual cues encountered in the input</li> <li>reflects the prior availability of an outcome, its entrenchment in the learning network</li> <li>TiMBL assigns higher probabilities to forms belonging to lemmas with letter trigraphs that yield more diverse activations</li> <li>Those trigraphs belong to a rich exemplar space in the memory</li> <li>it would be expected that higher probabilities would result in shorter response latencies</li> <li>However, NDL's G2L-Diversity was in fact positively correlated with RTs, indicating inhibition, i. e. slower recognition.</li> <li>TiMBL probabilities are intended to capture the likelihood of a form's occurrence in production.</li> <li>in comprehension (lexicality judgments) high trigraphs diversity may hurt results</li> <li>Spontaneous recovery from extinction</li> <li>After a CS is learned to associated with a given Conditioned Response (CR), this association is unlearned</li> <li>Theoretically, it can not arise again without retraining</li> <li>But in real life, sometimes seemingly completely forgotten associations are reactivated</li> <li>shows extinction is not unlearning</li> <li>responses that disappear are not necessarily forgotten</li> <li>Suggests loss of activation is not simply the mirror of acquiring associations</li> <li>Given two conditions stimuli, (CS) where one is more salient, the more salient CS will develop a strong association with the CR (Conditioned Response)</li> <li>Some linguistic things can be learned with NDL and this might show use something about the problem</li> <li>What made NDL so nice for animal learning might not scale up to linguistic phenomena</li> <li>Inductive approaches to cognition</li> </ul>"},{"location":"KB/Minerva/","title":"Minerva","text":""},{"location":"KB/Minerva/#minerva","title":"Minerva","text":"<ul> <li>Language model capable of solving mathematical and scientific questions using step-by-step reasoning</li> <li>very clear focus on the collection of training data for this purpose</li> <li>solves quantitative reasoning problems,</li> <li>makes models at scale and employs best-in-class inference techniques</li> <li>Concretely, Minerva solves these problems by generating solutions step-by-step</li> <li>this means including calculations and symbolic manipulation without having the need for external tools such a calculator.</li> </ul>"},{"location":"KB/Mini%20Batch%20GD/","title":"Mini Batch GD","text":""},{"location":"KB/Mini%20Batch%20GD/#mini-batch-gd","title":"Mini Batch GD","text":"<ul> <li> \\[\\theta= \\theta-\\eta \\cdot \\nabla_{\\theta}J(\\theta; x^{i:i+n};y^{i;i+n})\\] </li> </ul>"},{"location":"KB/Minimal%20Semantic%20Commitment/","title":"Minimal Semantic Commitment","text":""},{"location":"KB/Minimal%20Semantic%20Commitment/#minimal-semantic-commitment","title":"Minimal Semantic Commitment","text":"<ul> <li>(Frazier et al., 1999)</li> <li>The MSC hypothesis distinguishes between two types of mental representations the processor might entertain upon encountering an underdetermined semantic constituent: if the representation is ambiguous, the processor will commit to just one interpretation and later revise it if necessary, but if the representation is vague, the processor refrains from committing to an interpretation, leaving some features underdetermined until further information is made available.</li> </ul>"},{"location":"KB/Minimization%20and%20reporting%20of%20negative%20impacts/","title":"Minimization and reporting of negative impacts","text":""},{"location":"KB/Minimization%20and%20reporting%20of%20negative%20impacts/#minimization-and-reporting-of-negative-impacts","title":"Minimization and reporting of negative impacts","text":"<ul> <li>reporting actions or decisions that yield a certain outcome by the system</li> <li>assessment of those outcomes</li> <li>consider the identification, assessment, documentation and minimization of their potential negative impacts</li> </ul>"},{"location":"KB/Minimizing%20Communication/","title":"Minimizing Communication","text":""},{"location":"KB/Minimizing%20Communication/#minimizing-communication","title":"Minimizing Communication","text":"<ul> <li>Reduce the number of messages passed</li> <li>Reduce amount of data passed in messages</li> </ul>"},{"location":"KB/Minkowski%20Distance/","title":"Minkowski Distance","text":""},{"location":"KB/Minkowski%20Distance/#minkowski-distance","title":"Minkowski Distance","text":"<ul> <li> \\[D(x,y) = (\\Sigma_{i=1}^{n}|x_{i}-y_{i}|^{p})^{\\frac{1}{p}}\\] </li> <li>It is a metric used in Normed vector space (n-dimensional real space), which means that it can be used in a space where distances can be represented as a vector that has a length.<ul> <li>Zero Vector \u2014 The zero vector has a length of zero whereas every other vector has a positive length. For example, if we travel from one place to another, then that distance is always positive. However, if we travel from one place to itself, then that distance is zero.</li> <li>Scalar Factor \u2014 When you multiple the vector with a positive number its length is changed whilst keeping its direction. For example, if we go a certain distance in one direction and add the same distance, the direction does not change.</li> <li>Triangle Inequality \u2014 The shortest distance between two points is a straight line.</li> </ul> </li> <li>Most interestingly about this distance measure is the use of parameter p. We can use this parameter to manipulate the distance metrics to closely resemble others.</li> <li>Common values of p are:<ul> <li>p=1 \u2014 Manhattan Distance</li> <li>p=2 \u2014 Euclidean Distance</li> <li>p=\\(\\infty\\) \u2014 Chebyshev Distance</li> </ul> </li> <li>The upside to p is the possibility to iterate over it and find the distance measure that works best for your use case.</li> </ul>"},{"location":"KB/Mirman%20et%20al/","title":"Mirman et al.","text":""},{"location":"KB/Mirman%20et%20al/#mirman-et-al","title":"Mirman Et Al.","text":"<ul> <li>train syllables in words, predicting the next syllable</li> <li>use network to train on different types of individual words, matching them with one of five objects, simulating word learning</li> <li>75 epocs 1000 syllable sequence, then it predicted almost perfectly the next syllable (teaching phonotactics of the language)</li> <li>Model trained to recognize one of five objects for each of five different two-syllable input patterns of three types 1. words (100% transitional probability) 2. partwords (25% probability transitions) 3. nonwords (0% transitions)</li> <li>Model is better at mapping two-syllable sequences to words when it has already been exposed to those sequences and they had high probabilities</li> <li>Novel-sequence non-word labels initially learned nearly as fast as word up to intermediate point.</li> <li>exposure to familiarization input allowed network to created distinct hidden representations for each syllable</li> <li>SRN can show how statistical learning supports word learning, showing a link</li> <li>Humans are good at learning sequences, even when the data is presented implicitly and even when the relationships are non-adjacent</li> <li>We aren't just sensitive to frequency: we are sensitive to actual transitional probabilities</li> <li>SRNs with very simple assumptions model non-adjacent learning and transitional probabilities</li> <li>Biological arguments for distributed representations</li> <li>Makes more sense that neurons get randomly assigned to be active for different inputs</li> <li>We can start with randomness and with learning it will become structured</li> <li>concepts are just bundles of features, that together become something</li> <li>Prevents catastrophic failures</li> </ul>"},{"location":"KB/Mirror%20Shift%20Function/","title":"Mirror Shift Function","text":""},{"location":"KB/Mirror%20Shift%20Function/#mirror-shift-function","title":"Mirror Shift Function","text":"<ul> <li>With the Mirror Shift Function, a job is converted to the job in which the path is symmetrical to that of the original job.</li> </ul>"},{"location":"KB/Misyak%20et%20al%202010/","title":"Misyak et al 2010","text":""},{"location":"KB/Misyak%20et%20al%202010/#misyak-et-al-2010","title":"Misyak Et Al 2010","text":"<ul> <li>Does the ability to learn statistical non-adjacent dependencies correlate with the ability to process non-adjacent dependencies in language?</li> <li>Can we model non-adjacent dependency learning with simple SRNs?</li> <li>allows us to see the continuous timecourse of statistical processing</li> <li>Uses both linguistic stimulus tokens and auditory cues</li> <li>on-line non-adjacency learning</li> <li>Investigation of Individual differences in language processing and statistical learning</li> <li>Participants trained in blocks of three word sequence trials.</li> <li>First and second word were random, but the third word was dependent on the first word.<ul> <li>Intervening second word creates non-adjacency</li> </ul> </li> <li>After final block: Prediction task where participants had to say what the third word was from two word sequences</li> <li>People can learn non-adjacent sequences with only implicit exposure</li> <li>SRN can capture performance on AGL tasks</li> <li>SRNs can deal with temporal structures and associations</li> <li>Localist representations: 30 input and output units, each unique unit corresponding to each nonword</li> <li>Standard backpropagation with a learning rate of 0.1 and momentum at 0.8</li> <li>The higher the prediction task accuracy (x-axis) the shorter reading times for object relatives.</li> <li>Even the people who are bad at sequential learning are still fluent speakers and listeners</li> <li>Is it possible that sequential learning and language learning are unrelated</li> <li>Maybe children are better at sequential learning, which helps them acquire languag</li> <li>Adults then lose this ability</li> </ul>"},{"location":"KB/Mixed%20Effect%20Models/","title":"Mixed Effect Models","text":""},{"location":"KB/Mixed%20Effect%20Models/#mixed-effect-models","title":"Mixed Effect Models","text":"<ul> <li>Are able to combine fixed factors and multiple random factors in one analysis No longer necessary to do two ANOVAs</li> </ul>"},{"location":"KB/Mixed%20Example/","title":"Mixed Example","text":""},{"location":"KB/Mixed%20Example/#mixed-example","title":"Mixed Example","text":"<ul> <li>experimented with 14 different types of augmentation approaches. The output image is generated using the following techniques: vertical concatenation, horizontal concatenation, mixed concatenation, random 2x2, VH- mixup (vertical concatenation, horizontal concate- nation, and mixup), VH-BC+ (vertical concatena- tion, horizontal concatenation, and between-class), random square, random column interval, random row interval, random rows, random columns, ran- dom pixels, random elements, and noisy mixup.</li> <li>From all these approached, VHmixup has the best performance.</li> </ul>"},{"location":"KB/Mixed%20chunk%20attention/","title":"Mixed chunk attention","text":""},{"location":"KB/Mixed%20chunk%20attention/#mixed-chunk-attention","title":"Mixed Chunk Attention","text":"<ul> <li>an efficient linear approximation method that combines the benefits from partial and linear attention mechanisms, which is accelerator-friendly and highly competitive in quality.</li> <li>The method works on chunks of tokens and leverages local (within chunk) and global (between chunks) attention spans</li> </ul>"},{"location":"KB/Mixup/","title":"Mixup","text":""},{"location":"KB/Mixup/#mixup","title":"Mixup","text":"<ul> <li>@zhangMixupEmpiricalRisk2018</li> <li>Randomly sample two examples \\((x_{i}, y_{i})\\) and \\((x_{j}, y_{j})\\)</li> <li>New example by weighted 1D piecewise linear interpolation</li> <li> \\[ \\hat x = \\lambda x_{i}+(1-\\lambda)x_{j} \\] </li> <li> \\[ \\hat y = \\lambda y_{i}+(1-\\lambda)y_{j} \\] </li> <li>$\\lambda \\in 0,1</li> <li>New example \\((\\hat x, \\hat y)\\)</li> </ul>"},{"location":"KB/MoCO/","title":"MoCO","text":"<p>toc: true title: MoCO</p> <p>categories: ['temp']</p>"},{"location":"KB/MoCO/#moco","title":"MoCO","text":"<ul> <li>Momentum Contrast for Unsupervised Visual Representation Learning</li> <li>unsupervised visual representation learning</li> <li>contrastive learning as dictionary look-up, MoCo builds a dynamic dictionary with a queue and a moving-averaged encoder</li> <li>large and consistent dictionary on-the-fly</li> <li>ImageNet</li> <li>transfer well to downstream tasks.</li> <li>PASCAL VOC</li> <li>COCO</li> <li>visual representation encoder by matching an encoded query</li> <li>to a dictionary of encoded keys using a contrastive loss</li> <li>dictionary is built as a queue, with the current mini-batch enqueued</li> <li>oldest mini-batch dequeued</li> <li>slowly progressing encoder</li> <li>momentum update with the query encoder</li> <li></li> <li></li> </ul>"},{"location":"KB/Mobile%20Net/","title":"Mobile Net","text":""},{"location":"KB/Mobile%20Net/#mobile-net","title":"Mobile Net","text":"<ul> <li>@howardMobilenetsEfficientConvolutional2017</li> <li>@sandlerMobilenetv2InvertedResiduals2018</li> <li>Depthwise Separable</li> </ul>"},{"location":"KB/MobileOne/","title":"MobileOne","text":""},{"location":"KB/MobileOne/#mobileone","title":"MobileOne","text":"<ul> <li>An Improved One Millisecond Mobile Backbone</li> <li>extensive analysis of different metrics by deploying several mobile friendly networks on a mobile device</li> <li>identify and analyze architectural and optimization bottlenecks</li> <li>many times faster on mobile</li> <li>Inspired byRepVGG</li> <li>Either ReLU or SE-ReLU is used as activation. The trivial over-parameterization factor \\(k\\) is a hyperparameter which is tuned for every variant.</li> <li>better top-1 accuracy on ImageNet than EfficientNet at similar latency</li> <li></li> </ul>"},{"location":"KB/Modality%20Dropout/","title":"Modality Dropout","text":""},{"location":"KB/Modality%20Dropout/#modality-dropout","title":"Modality Dropout","text":"<ul> <li>MDO improves fine-tuning by randomly dropping one of the modalities</li> </ul>"},{"location":"KB/Modality/","title":"Modality","text":""},{"location":"KB/Modality/#modality","title":"Modality","text":"<ul> <li>A high-level data category. For example, numbers, text, images, video, and audio are five different modalities.</li> </ul>"},{"location":"KB/Mode%20Collapse/","title":"Mode Collapse","text":""},{"location":"KB/Mode%20Collapse/#mode-collapse","title":"Mode Collapse","text":"<ul> <li>Generator collapses and only predicts mean/median/mode of data instead of the prob distribution</li> </ul>"},{"location":"KB/Mode%20Switch/","title":"Mode Switch","text":""},{"location":"KB/Mode%20Switch/#mode-switch","title":"Mode Switch","text":"<ul> <li>As per safety standards, an industrial robot has three distinct modes of operation. These are Teach (also called Manual) and Play (also called Automatic) and Remote. Switching between these modes is performed using a key switch on the teach pendant and is called Mode Switch.</li> </ul>"},{"location":"KB/Modeling%20Driver%20Behavior%20with%20Cognitive%20Architecture/","title":"Modeling Driver Behavior with Cognitive Architecture","text":""},{"location":"KB/Modeling%20Driver%20Behavior%20with%20Cognitive%20Architecture/#modeling-driver-behavior-with-cognitive-architecture","title":"Modeling Driver Behavior with Cognitive Architecture","text":"<ul> <li>Salvucci, Dario D. \"Modeling driver behavior in a cognitive architecture.\" Human factors 48.2 (2006): 362-380.</li> </ul>"},{"location":"KB/Modeling%20Driver%20Behavior%20with%20Cognitive%20Architecture/#intro","title":"Intro","text":"<p>This paper explores the development of a rigorous computational model of driver behavior in a cognitive architecture \u2013 a computational framework with underlying psychological theories that incorporate basic properties and limitations of the human system</p> <p>An integrated driver model developed in the ACT-R (Adaptive Control of Thought-Rational) cognitive architecture is described that focuses on the component processes of control, monitoring, and decision making in a multilane highway environment</p> <p>This model accounts for the steering profiles, lateral position profiles, and gaze distributions of human drivers during lane keeping, curve negotiation, and lane changing.</p> <p>The model demonstrates how cognitive architectures facilitate understanding of driver behavior in the context of general human abilities and constraints and how the driving domain benefits cognitive architectures by pushing model development toward more complex, realistic tasks</p>"},{"location":"KB/Modeling%20Driver%20Behavior%20with%20Cognitive%20Architecture/#driving-and-integrated-driver-modeling","title":"Driving and Integrated Driver Modeling","text":"<p>useful to view driving and driver modeling in the context of the embodied cognition, task, and artifact (ETA) framework (Byrne, 2001; Gray, 2000; Gray &amp; Boehm-Davis, 2000).</p> <p>As the name suggests, this framework emphasizes three components of an integrated modeling effort: the task that a person attempts to perform, the artifact</p> <p>by which the person performs the task, and the embodied cognition by which the person perceives, thinks, and acts in the world through the artifact</p> <p>A sound understanding of each component is critical to developing rigorous integrated models of driver behavior.</p> <p>Michon (1985) identified three classes of task processes for driving: operational processes that involve manipulating control inputs for stable driving, tactical processes that govern safe interactions with the environment and other vehicles, and strategic processes for higher level reasoning and planning</p> <p>Some tasks are not continual but intermittent, arising in specific situations \u2013 for instance, parking a vehicle at a final destination.</p> <p>Between cognition and the vehicle lies the embodiment of the driver, namely the perceptual processes (visual, aural, vestibular, etc.) and motor processes (hands, feet) that provide the input from and output to the external world.</p> <p>Not surprisingly, there can be parallelism in this integrated system \u2013 for instance, moving the hand while visually encoding the lead car \u2013 but there are also capacity constraints and/or bottlenecks that sometimes result in degraded performance.</p>"},{"location":"KB/Modeling%20Driver%20Behavior%20with%20Cognitive%20Architecture/#pictures","title":"Pictures","text":""},{"location":"KB/Modeling%20Transfer/","title":"Modeling Transfer","text":""},{"location":"KB/Modeling%20Transfer/#modeling-transfer","title":"Modeling Transfer","text":"<ul> <li>given levels of mastery on a set of knowledge components, predict the performance on a new problem (Singley &amp; Anderson, 1989).</li> <li>For instance, suppose a student has mastered 15 of the 20 knowledge components required to do a task.</li> <li>This predicts the student's behavior on the task\u2014where the student will ask for help, how long it will take to do the task, which errors occur, etc</li> <li>However, these predictions can be inaccurate if the assumed knowledge components are not accurate reflections of how the student actually understands the task domain</li> </ul>"},{"location":"KB/Modeling%20motivation%20using%20goal%20competition%20in%20mental%20fatigue%20studies/","title":"Modeling motivation using goal competition in mental fatigue studies","text":""},{"location":"KB/Modeling%20motivation%20using%20goal%20competition%20in%20mental%20fatigue%20studies/#modeling-motivation-using-goal-competition-in-mental-fatigue-studies","title":"Modeling motivation using goal competition in mental fatigue studies","text":"<ul> <li> <p>Mega B. Herlambang a,b,\u2217, Niels A. Taatgen a, Fokie Cnossen</p> </li> <li> <p>Motivation can counteract the effects of mental fatigue</p> </li> <li>goal competition as a paradigm to understand the role of motivation and built three models of mental fatigue studies to demonstrate the mechanism in a cognitive architecture named PRIM</li> <li>model changes in performance levels by adjusting the value of the main task goals</li> <li>which controls the competition with distractions</li> <li>best model fits were obtained by a linear decrease in goal activation</li> <li>Modeling fatigue and motivation decline in PRIMs</li> <li>The assumption in this paper is that the decrease in task performance in mental fatigue is the result of a reduction in task motivation.</li> <li>reflected in a reduction in activation of the task goal over time</li> <li>As time progresses, individuals may experience an increase in the feeling of fatigue that reduces the subjective value of the main task, i.e., task motivation (Mu\u0308ller &amp; Apps, 2019) or goal activation (Agoal) in our models</li> <li>Consequently, goal activation is discounted by the feeling of fatigue</li> <li>perceived reward from doing the task (extrinsically or intrinsically) maintains the goal activation from declining.</li> <li>\\(\\(A_{goal(t)} = min(1 \\vee (P(t) - F(t)))\\)\\),</li> <li>Therefore, the relationship between the perceived reward (P), the feeling of fatigue (F), and goal activation (Agoal) at any given time (t) is</li> <li>goal activation value of one means that the model mainly focuses its attention on the main goal.</li> <li>The value P is influenced by previous perceived rewards. For example, when the previous incentive at t \u2212 1 is perceived as more valuable than the recent one at t, then the value Pt is smaller than Pt\u22121</li> <li>In contrast, the value of Pt is higher if the reward at t is perceived as more valuable than the previous one at t\u22121</li> <li>It is evident that motivation affects the ability to stay focused on a task and not be distracted by internal or external distractions (Herlambang et al., 2019)</li> <li>In the case of external distractions, task-unrelated stimuli may shift attention away from the main task, while internal distractions may manifest itself in the form of mind-wandering</li> </ul>"},{"location":"KB/Modeling%20motivation%20using%20goal%20competition%20in%20mental%20fatigue%20studies/#discussion","title":"Discussion","text":"<ul> <li>that goal competition is one of the key factors to understand the underlying mechanism of motivation in mental fatigue.</li> <li>decrease in performance is not due to a decrease in the capacity of the cognitive system (e.g., lower working memory capacity, slower motor system, less reliable long-term memory) but by a decrease in the ratio of cognitive ''cycles'' spent on the task as opposed to distractions.</li> <li>have modeled this by a decrease in the activation of the goal, which represents the level of motivation, which indirectly affects performance</li> <li>modeler can tune some parameters to obtain a good fit</li> <li>However, overdoing such parameter tuning may lead to overfitting, which makes the models difficult to generalize and does not represent the empirical data</li> </ul>"},{"location":"KB/Modeling%20motivation%20using%20goal%20competition%20in%20mental%20fatigue%20studies/#goal-activation-and-performance","title":"Goal activation and performance","text":"<ul> <li>To lower performance in the nonreward conditions in all tasks, we decreased task goal activation values over time</li> <li>The goal activation values in our models represent the subjective value of performing the tasks, with a high subjective value corresponds to a high level of motivation</li> <li>The reduction of goal activation was due to an increase in the feeling of fatigue (see Mu\u0308ller &amp; Apps, 2019) and a continuous decrease in the perceived reward from doing the tasks</li> <li>What our modeling efforts suggest is that over time, while the activation value of the main active goal is decreasing, which is due to an increase in the feeling of fatigue and a decrease in the perceived reward (see Eq. (3)), another future goal of an activity/stimulus, for example, a distraction, may start winning the competition with the main task, when the activation value of the distraction exceeds that of the main goal (i.e., it strongly attracts the individual), in which case the individual may start paying attention to the distraction. The distraction can become the new active goal, and the individual may forget the main goal, or choose to pay attention to both, but this will sacrifice performance.</li> <li>Goal competition is a continuous process that compares several future goals, and when the main task goal is perceived to be less valuable, another competing goal may start winning the competition, causing the individual to invest less mental effort in the main task and start investing in the competing goal</li> </ul>"},{"location":"KB/Modeling%20motivation%20using%20goal%20competition%20in%20mental%20fatigue%20studies/#limitation-challenge-and-future-research","title":"Limitation, challenge, and future research","text":"<ul> <li>solely adjusting goal activation levels may not be enough to model changes in performance.</li> <li>There are many parameters in PRIMs that can affect performance</li> <li>Although adjusting goal activation values as a way to model mental fatigue showed good results for the experiments we modeled, it is possible that this does not directly generalize to other studies</li> </ul>"},{"location":"KB/Modeling%20motivation%20using%20goal%20competition%20in%20mental%20fatigue%20studies/#images","title":"Images","text":""},{"location":"KB/Moment%20Exchange/","title":"Moment Exchange","text":""},{"location":"KB/Moment%20Exchange/#moment-exchange","title":"Moment Exchange","text":"<ul> <li>encouraging the models to utilize the moment information of latent features </li> <li>Specifically, the moments of the learned features of one training image are re- placed by those of another.</li> </ul>"},{"location":"KB/Moment%20in%20Time/","title":"Moment in Time","text":""},{"location":"KB/Moment%20in%20Time/#moment-in-time","title":"Moment in Time","text":"<ul> <li>large balanced and diverse dataset </li> <li>video under- </li> <li>standing </li> <li>1 million video clips that cover 339 classes, and each video lasts around 3 seconds </li> <li>average number of video clips for each class is 1, 757 with a median of 2, 775 </li> <li>videos that capturing visual and/or audible actions, produced by humans, animals, objects or nature</li> </ul>"},{"location":"KB/Momentum/","title":"Momentum","text":""},{"location":"KB/Momentum/#momentum","title":"Momentum","text":"<ul> <li>Momentum is the velocity of a body multiplied by its mass. A small force can quickly stop an object with low momentum, but a large or prolonged force is required to stop an object with high momentum.</li> <li> \\[p = mv\\] </li> <li>mass times velocity</li> </ul>"},{"location":"KB/Monk/","title":"Monk","text":""},{"location":"KB/Monk/#monk","title":"Monk","text":"<ul> <li>Hit list</li> <li></li> </ul>"},{"location":"KB/Moral%20Machine%20project/","title":"Moral Machine project","text":""},{"location":"KB/Moral%20Machine%20project/#moral-machine-project","title":"Moral Machine Project","text":"<ul> <li>MIT</li> <li>wisdom of the crowd to find resolutions for ethical dilemmas</li> <li>studying the perception of autonomous vehicles (AVs) which are controlled by AI and has the potential to harm pedestrians and/or passengers if they malfunction</li> <li>allows participants to judge various ethical dilemmas facing AVs which have malfunctioned, and select which outcomes they prefer.</li> <li>saving more lives</li> <li>protecting passengers</li> <li>upholding the law</li> <li>avoiding intervention</li> <li>gender preference</li> <li>species preference</li> <li>age</li> <li>social value preference.</li> <li>people generally prefer the AV to make sacrifices if more lives can be saved.</li> <li>self-reported preferences often do not align well with actual behaviours</li> </ul>"},{"location":"KB/Moral%20decision%20making%20frameworks%20for%20artificial%20intelligence/","title":"Moral decision making frameworks for artificial intelligence","text":""},{"location":"KB/Moral%20decision%20making%20frameworks%20for%20artificial%20intelligence/#moral-decision-making-frameworks-for-artificial-intelligence","title":"Moral Decision Making Frameworks for Artificial Intelligence","text":"<ul> <li>Vincent Conitzer, Walter Sinnott- Armstrong, Jana Schaich Borg, Yuan Deng, and Max Kramer.</li> <li>developing a general ethical decision making framework for AI based on game theory and machine learning</li> <li>For the game theory based framework, the authors suggest the extensive form (a generalization of game trees) as a foundation scheme to represent dilemmas</li> <li>current extensive form does not account for protected values in which an action can be treated as unethical regardless of its consequence</li> <li>extend the extensive form representation with passive actions for agents to select in order to be ethical</li> <li>machine learning based ethical decision-making</li> <li>classify whether a given action under a given scenario is morally right or wrong</li> <li>The main challenge in machine learning based moral decision-making is to design a generalizable representation of ethical dilemmas</li> <li>Game theory and machine learning can be combined into one framework in which game theoretic analysis of ethics is used as a feature to train machine learning approaches</li> </ul>"},{"location":"KB/MoralDM/","title":"MoralDM","text":""},{"location":"KB/MoralDM/#moraldm","title":"MoralDM","text":"<ul> <li>enables an agent to resolve ethical dilemmas by leveraging on two mechanisms</li> <li>1) first-principles reasoning, which makes decisions based on well-established ethical rules (e.g., protected values); and 2) analogical reasoning, which compares a given scenario to past resolved similar cases to aid decision-making.</li> <li>the exhaustive comparison approach by MoralDM is expected to become computationally intractable</li> <li>[Blass and Forbus, 2015], MoralDM is extended with structure mapping which trims the search space by computing the correspondences, candidate inferences and similarity scores between cases to improve the efficiency of analogical generalization</li> </ul>"},{"location":"KB/MoreMVCNN/","title":"MoreMVCNN","text":""},{"location":"KB/MoreMVCNN/#moremvcnn","title":"MoreMVCNN","text":""},{"location":"KB/Morpheme%20Generation/","title":"Morpheme Generation","text":""},{"location":"KB/Morpheme%20Generation/#morpheme-generation","title":"Morpheme Generation","text":"<ul> <li>See +past.verb = saw</li> </ul>"},{"location":"KB/Morpheme%20Segmentation/","title":"Morpheme Segmentation","text":""},{"location":"KB/Morpheme%20Segmentation/#morpheme-segmentation","title":"Morpheme Segmentation","text":"<ul> <li>De-nation-al-iz-ation</li> </ul>"},{"location":"KB/Morpheme/","title":"Morpheme","text":""},{"location":"KB/Morpheme/#morpheme","title":"Morpheme","text":"<ul> <li>words are built from smaller meaningful units called morphemes</li> <li>Allomorph</li> <li>Morphology Stem</li> <li>Morphology Affix</li> <li>Content Morpheme</li> <li>Functional Morpheme</li> <li>Morpheme Segmentation</li> <li>Morpheme Generation</li> <li>Morphotactic</li> </ul>"},{"location":"KB/Morphology%20Affix/","title":"Morphology Affix","text":""},{"location":"KB/Morphology%20Affix/#morphology-affix","title":"Morphology Affix","text":"<ul> <li>Bits and pieces that adhere to stems to change their meanings and grammatical functions</li> <li>Bound morpheme</li> <li>Prefix</li> <li>Suffix</li> <li>Infix</li> <li>Circumfix</li> </ul>"},{"location":"KB/Morphology%20Stem/","title":"Morphology Stem","text":""},{"location":"KB/Morphology%20Stem/#morphology-stem","title":"Morphology Stem","text":"<ul> <li>The core meaning bearing units \u2013 Main morpheme of the word</li> <li>Free morpheme</li> </ul>"},{"location":"KB/Morphology/","title":"Morphology","text":""},{"location":"KB/Morphology/#morphology","title":"Morphology","text":"<ul> <li>structure of words</li> <li>Morpheme</li> <li>It is concerned with inflection.</li> <li>It is also concerned with derivation of new words from existing ones, eg. lighthouse (formed from light &amp; house)</li> <li>Needs a Lexicon</li> <li>Inflectional Morphology</li> <li>Derivational Morphology</li> <li>Suppletion</li> <li>Word Compounding</li> <li>Word Blending</li> <li>Word Clipping</li> <li>Lemmatization</li> </ul>"},{"location":"KB/Morphotactic/","title":"Morphotactic","text":""},{"location":"KB/Morphotactic/#morphotactic","title":"Morphotactic","text":"<ul> <li>Which class of morphemes follow other class of morphemes</li> <li>Plural morphemes follow noun</li> <li>some endings go only on certain words not on everything.</li> <li>Do + er : doer</li> <li>Be + er :beer</li> </ul>"},{"location":"KB/Motor%20Memories/","title":"Motor Memories","text":""},{"location":"KB/Motor%20Memories/#motor-memories","title":"Motor Memories","text":"<ul> <li>motor memory is unique</li> <li>Some studies on Alzheimer\u2019s disease included participants who were previously musicians and couldn\u2019t remember their own families, but they could still play beautiful music. Clearly, there\u2019s a huge difference in the way that motor memories are formed</li> <li>Memories are thought to be encoded in the brain in the pattern of activity in networks of hundreds or thousands of neurons, sometimes distributed across distant brain regions</li> <li>memory trace</li> <li>When the researchers tested the animals\u2019 memory of this new skill weeks later, they found that those mice that still remembered the skill showed increased activity in the same neurons that were first identified during the learning period, showing that these neurons were responsible for encoding the skill</li> <li>two-photon microscopy</li> <li>\u201cengram neurons\u201d reprogram themselves as the mice learned</li> <li>Motor cortex engram cells took on new synaptic inputs \u2014 potentially reflecting information about the reaching movement \u2014 and themselves formed powerful new output connections in a distant brain region called the dorsolateral striatum \u2014 a key waystation through which the engram neurons can exert refined control over the animal\u2019s movements.</li> <li>These findings suggest that, in addition to being dispersed, motor memories are highly redundant.</li> <li>The researchers say that as we repeat learned skills, we are continually reinforcing the motor engrams by building new connections \u2014 refining the skill. It\u2019s what is meant by the term muscle memory \u2014 a refined, highly redundant network of motor engrams used so frequently that the associated skill seems automatic.</li> <li>Current thinking is that Parkinson\u2019s disease is the result of these motor engrams being blocked, but what if they\u2019re actually being lost and people are forgetting these skills?</li> </ul>"},{"location":"KB/Multi%20Head%20Attention/","title":"Multi Head Attention","text":""},{"location":"KB/Multi%20Head%20Attention/#multi-head-attention","title":"Multi Head Attention","text":"<ul> <li>ZihangDai et al., 2019</li> <li>which computes self-attention over the inputs, then adds back the residual and layer normalizes everything. The attention head can be split into multiple segments, hence the name\u00a0multi-head</li> <li>Multiple attention instances, each focusing on a different part of the input</li> <li>Words can mean different things in context<ul> <li>If using Self Attention, then this just gets summed up. Which is not very nice</li> <li>Several attention heads -&gt; different output vectors</li> <li>Concatenate them and pass through a linear transform -&gt; dimension back to k</li> </ul> </li> <li> \\[MultiHead(Q,K,V) = Concat(head_1, head_2, \u2026., head_h)W^O\\] <ul> <li> \\[head_i = Attention(QW_i^Q, KW_i^K , VW_i^V)\\] </li> </ul> </li> <li>W is learnable projections for attention params</li> <li></li> <li>To improve efficiency<ul> <li>Cut the incoming vector into chunks -&gt; no of attention heads</li> </ul> </li> </ul> <pre><code>class MultiHeadAttentionNew(nn.Module):\n    def __init__(self, n_head, d_model, d_k, d_v, dropout=0.1):\n        super().__init__()\n        self.n_head = n_head\n\n        self.w_qs = nn.Linear(d_model, n_head * d_k)\n        self.w_ks = nn.Linear(d_model, n_head * d_k)\n        self.w_vs = nn.Linear(d_model, n_head * d_v)\n\n        nn.init.normal_(self.w_qs.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_k)))\n        nn.init.normal_(self.w_ks.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_k)))\n        nn.init.normal_(self.w_vs.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_v)))\n\n        self.fc = nn.Linear(n_head * d_v, d_model)\n        nn.init.xavier_normal_(self.fc.weight)\n        self.dropout = nn.Dropout(p=dropout)\n        self.layer_norm = nn.LayerNorm(d_model)\n\n    def forward(self, q, k, v, mask=None):\n        residual = q\n        q = rearrange(self.w_qs(q), 'b l (head k) -&gt; head b l k', head=self.n_head)\n        k = rearrange(self.w_ks(k), 'b t (head k) -&gt; head b t k', head=self.n_head)\n        v = rearrange(self.w_vs(v), 'b t (head v) -&gt; head b t v', head=self.n_head)\n        attn = torch.einsum('hblk,hbtk-&gt;hblt', [q, k]) / np.sqrt(q.shape[-1])\n        if mask is not None:\n            attn = attn.masked_fill(mask[None], -np.inf)\n        attn = torch.softmax(attn, dim=3)\n        output = torch.einsum('hblt,hbtv-&gt;hblv', [attn, v])\n        output = rearrange(output, 'head b l v -&gt; b l (head v)')\n        output = self.dropout(self.fc(output))\n        output = self.layer_norm(output + residual)\n        return output, attn\n</code></pre>"},{"location":"KB/Multi%20Task%20Learning/","title":"Multi Task Learning","text":""},{"location":"KB/Multi%20Task%20Learning/#multi-task-learning","title":"Multi Task Learning","text":"<ul> <li>multiple outputs (as desired), and typically a shared trunk of weights can indirectly encode common or shared knowledge</li> <li>Can linearly combine loss for each task \\(L_{i}\\)</li> <li> \\[L(x,y, \\theta) = \\Sigma_{i}w_{i}L_{i}(f_{i}(x), y, \\theta_{i})\\] <ul> <li>\\(f_{i}(x)\\) is output head with weights \\(\\theta_{i}\\)</li> </ul> </li> <li>The exact scale of the weights does not matter as multiplying the loss by a positive scalar does not change the optimum.</li> <li>Hard Parameter Sharing</li> <li>Soft Parameter Sharing</li> <li>augment </li> <li>Attribute Selection</li> <li>Eavesdropping</li> <li>Representation Bias</li> </ul>"},{"location":"KB/Multi%20Teacher%20Distillation/","title":"Multi Teacher Distillation","text":""},{"location":"KB/Multi%20Teacher%20Distillation/#multi-teacher-distillation","title":"Multi Teacher Distillation","text":"<ul> <li>The multiple teacher networks can be individually and integrally used for distillation during the period of training a student network.</li> <li>To transfer knowledge from multiple teachers, the simplest way is to use the averaged response from all teachers as the supervision signal (Hinton et al., 2015)</li> <li>In addi- tion to the averaged logits from all teachers, You et al. (2017) further incorporated features from the inter- mediate layers in order to encourage the dissimilarity among different training samples.</li> <li>Fukuda et al. (2017) randomly selected one teacher from the pool of teacher networks at each it- eration. To transfer feature-based knowledge from mul- tiple teachers, additional teacher branches are added to the student networks to mimic the intermediate features of teachers (Park and Kwak, 2020; Asif et al., 2020). Born again networks address multiple teach- ers in a step-by-step manner, i.e., the student at the t step is used as the teacher of the student at the t+1 step (Furlanelloetal., 2018)</li> <li>To effi- ciently perform knowledge transfer and explore the power of multiple teachers, several alternative meth- ods have been proposed to simulate multiple teach- ers by adding different types of noise to a given teacher (Sau and Balasubramanian, 2016) or by us- ing stochastic blocks and skip connections (Lee et al., 2019c). Using multiple teacher models with feature ensembles, knowledge amalgamation is designed in (Shen et al., 2019a; Luo et al., 2019; Shen et al., 2019b; Luo et al., 2020). Through knowledge amalgamation, many public available trained deep models as teachers can be reused.</li> </ul>"},{"location":"KB/Multi%20Variate%20AR/","title":"Multi Variate AR","text":""},{"location":"KB/Multi%20Variate%20AR/#multi-variate-ar","title":"Multi Variate AR","text":"<ul> <li>predict future from past of another time series</li> </ul>"},{"location":"KB/MultiReader%20technique/","title":"MultiReader technique","text":""},{"location":"KB/MultiReader%20technique/#multireader-technique","title":"MultiReader Technique","text":"<ul> <li>which allows domain adaptation</li> <li>training a more accurate model that supports multiple keywords (i.e., \u201cOK Google\u201d and \u201cHey Google\u201d) as well as multiple languages/dialects</li> </ul>"},{"location":"KB/Multimodal%20Explanation/","title":"Multimodal Explanation","text":""},{"location":"KB/Multimodal%20Explanation/#multimodal-explanation","title":"Multimodal Explanation","text":"<ul> <li>The visual explanation was created by an attention mechanism that conveyed knowledge about what region of the image was important for the decision. This explanation guides the generation of the textual justification out of a LSTM feature, which is a prediction of a classification problem over all possible justifications.</li> </ul>"},{"location":"KB/Multinomial%20Distribution/","title":"Multinomial","text":""},{"location":"KB/Multinomial%20Distribution/#multinomial","title":"Multinomial","text":"<ul> <li> \\[P(D|\\theta) = \\frac{N!}{n_{1}!\u2026n_{l}!}\\Pi_{j=1}^{l}\\theta_{j}^{n_{j}}\\] </li> <li>\\(N = n_{1}+ \u2026.+ n_{l}\\)</li> <li>Generalized Binomial Distribution</li> <li>PMF</li> </ul>"},{"location":"KB/Multiple%20Local%20Minima/","title":"Multiple Local Minima","text":""},{"location":"KB/Multiple%20Local%20Minima/#multiple-local-minima","title":"Multiple Local Minima","text":""},{"location":"KB/Multiple%20Sclerosis/","title":"Multiple Sclerosis","text":""},{"location":"KB/Multiple%20Sclerosis/#multiple-sclerosis","title":"Multiple Sclerosis","text":"<ul> <li>A progressive neurodegenerative disease involving damage to the protective myelin sheaths of nerve cells in the brain and spinal cord. Symptoms include impaired movement, pain, and fatigue.</li> </ul>"},{"location":"KB/Multiple%20constraint-based%20theories/","title":"Multiple constraint-based theories","text":""},{"location":"KB/Multiple%20constraint-based%20theories/#multiple-constraint-based-theories","title":"Multiple Constraint-based Theories","text":"<ul> <li>describe language comprehension as an interactive process whereby all possible syntactic representations are simultaneously partially active and competing for more activation across time</li> <li>Unlike the syntax-first models, multiple sources of information, be they syntactic or non-syntactic, integrate immediately to determine the amount of activation provided to each of the competing alternatives</li> </ul>"},{"location":"KB/Multiplicative%20Attention/","title":"Multiplicative Attention","text":""},{"location":"KB/Multiplicative%20Attention/#multiplicative-attention","title":"Multiplicative Attention","text":"<ul> <li> \\[f_{att}(h_{i}, s_{j}) = h_{i}^{T}W_{a}s_{j}\\] </li> <li>Since Additive Attention performs better for scale, use a factor Scaled Dot Product Attention</li> </ul>"},{"location":"KB/Muse/","title":"Muse","text":""},{"location":"KB/Muse/#muse","title":"Muse","text":"<ul> <li>Text-to-image transformer model</li> <li>state-ofthe-art image generation while being more ecient than difusion or autoregressive models</li> <li>it is trained on a masked modelling task in discrete token space</li> <li>more ecient because of the use of discrete tokens and requiring fewer sampling iterations</li> <li>parallel decoding</li> <li>Muse is 10x faster at inference time than Imagen-3B or Parti-3B and 3x faster than Stable Difusion v 1.4</li> <li>Muse is also faster than than Stable Difusion in spite of both models working in the latent space of a VQGAN</li> </ul>"},{"location":"KB/Myelin/","title":"Myelin","text":""},{"location":"KB/Myelin/#myelin","title":"Myelin","text":"<ul> <li>The fatty substance that encases most nerve cell</li> <li>axons, helping to insulate and protect the nerve fiber and effectively speeding up the transmission of nerve impulses.</li> </ul>"},{"location":"KB/Myocardial%20Infarction/","title":"Myocardial Infarction","text":""},{"location":"KB/Myocardial%20Infarction/#myocardial-infarction","title":"Myocardial Infarction","text":"<ul> <li>Also known as a heart attack, where the heart is deprived of blood due to arterial blockage</li> </ul>"},{"location":"KB/N-dim%20Normal/","title":"N Dim Normal Distribution","text":""},{"location":"KB/N-dim%20Normal/#n-dim-normal-distribution","title":"N Dim Normal Distribution","text":"<ul> <li>Normal Distribution</li> <li>If data points are vectors \\(x = (x_{1}, \u2026, x_{n})'\\) and RVs X_i fulfill the Central Limit Theorem,</li> <li>PDF \\(\\(p(x) = \\frac{1}{(2\\pi)^{n/2}det(\\Sigma)^{\\frac{1}{2}}}exp\\left(-\\frac{1}{2}(x-\\mu)'\\Sigma^{-1}(x-\\mu)\\right)\\)\\)</li> <li>\\(\\mu\\) is expectation $EX_{1}, \u2026, X_{n})'x</li> <li> \\[\\Sigma(i,j) = E[(X_{i} - E[X_{i}])(X_{j}-E[X_{j}])]\\] </li> <li></li> <li> \\[\\hat \\mu = \\frac{1}{N}\\Sigma_{i}x_{i}$$ and $$\\hat \\Sigma = \\frac{1}{N-1}\\Sigma_{i}(x_{i}-\\hat\\mu)(x_{i}-\\hat\\mu)'\\] </li> </ul>"},{"location":"KB/NADAM/","title":"NADAM","text":""},{"location":"KB/NADAM/#nadam","title":"NADAM","text":"<ul> <li>extension of Adam that uses the Nesterov momentum technique to accelerate the optimization convergence further</li> <li>combines the momentum of Nesterov\u2019s method with the adaptive learning rates of Adam</li> <li> \\[ m_t = \\beta_1 * m_{(t-1)} + (1 - \\beta_1) * g_t $$ $$ v_t = \\beta_2 * v_{(t-1)} + (1 - \\beta_2) * g_t2$$ $$ \\hat{m_t} = \\frac{m_t}{1-\\beta_1t}\u00a0$$ $$ \\hat{v_t} = \\frac{v_t}{1-\\beta_2t}\u00a0$$ $$ \\text{parameter} = \\text{parameter} - learning\\_rate * \\frac{\\hat{m_t} + (1-\\beta_1) * g_t}{\\sqrt{\\hat{v_t}} + \\epsilon}\\] </li> <li>Where beta1 and beta2 are two hyperparameters, m_t and v_t are moving averages of the gradients, g_t is the gradient at time t, and learning_rate; epsilon is the same as before.</li> </ul>"},{"location":"KB/NCE/","title":"NCE","text":"<p>toc: true title: NCE</p> <p>categories: ['temp']</p>"},{"location":"KB/NCE/#nce","title":"NCE","text":"<ul> <li>Conditional Negative Sampling for Contrastive Learning of Visual Representations</li> <li>Contrastive Learning</li> <li>noise-contrastive estimation</li> <li>bound on mutual information between two views of an image</li> <li>randomly sampled negative examples to normalize the objective</li> <li>choosing difficult negatives, or those more similar to the current instance, can yield stronger representation</li> <li>Conditional Noise Contrastive Estimator</li> <li>sample negatives conditionally</li> <li>in a \u201cring\u201d around each positive, by approximating the partition function using samples from a class of conditional distributions</li> <li>hese estimators lower-bound mutual information</li> <li>higher bias but lower variance than NCE Bias Vs Variance</li> <li>Applying these estimators as objectives in contrastive representation learning</li> <li>transferring features to a variety of new image distributions from the meta-dataset collection</li> <li>Contrastive Loss</li> </ul>"},{"location":"KB/NIST%202008%20Speaker%20Recognition%20Evaluation%20dataset/","title":"NIST 2008 Speaker Recognition Evaluation dataset","text":""},{"location":"KB/NIST%202008%20Speaker%20Recognition%20Evaluation%20dataset/#nist-2008-speaker-recognition-evaluation-dataset","title":"NIST 2008 Speaker Recognition Evaluation Dataset","text":""},{"location":"KB/NIST%20SRE%202016%20Cantonese/","title":"NIST SRE 2016 Cantonese","text":""},{"location":"KB/NIST%20SRE%202016%20Cantonese/#nist-sre-2016-cantonese","title":"NIST SRE 2016 Cantonese","text":""},{"location":"KB/NLAIC%20Companies/","title":"NLAIC Companies","text":"","tags":["jobs"]},{"location":"KB/NLAIC%20Companies/#nlaic-companies","title":"NLAIC Companies","text":"","tags":["jobs"]},{"location":"KB/NLAIC%20Companies/#axveco","title":"Axveco","text":"<p>Open Sollicitatie - AI</p> <p>Hello!</p> <p>This is Subhaditya. I recently graduated with a masters in AI from the RUG (Groningen), and am looking for my next big challenge. While looking at your website, I found quite a lot of awesome projects (like the medical object recognition one) that made me quite interested in working at Axveco. I am currently looking for an AI role in the NL and I would love to discuss the possibility of any such roles with you.</p> <p>My experience is a combination of AI, Computer vision and Data Analytics. Over the past few years, I have worked with many clients (both freelance/part time and in internships) and helped them bring their AI projects to life. I am also quite familiar with the ins and outs of Deep Learning, NLP and image processing. Along with my technical knowledge, I enjoy helping clients define their vision and guiding them towards it. These are all tasks that you do, and so I think that I might be a good fit at Axveco.</p> <p>While I am not sure what kind of roles exist at the moment, I am open to any AI/Data Science related position. I am quite interested in working as part of a high performance team and the possibility of defining my own roles as well as growing my skills seems like a nice cherry on top as well. I\u2019ve attached my resume to this email as well.</p> <p>Looking forward to your reply,</p>","tags":["jobs"]},{"location":"KB/NLAIC%20Companies/#axelera","title":"Axelera","text":"<p>Open Sollicitatie - AI</p> <p>Hello!</p> <p>This is Subhaditya. I recently graduated with a masters in AI from the RUG (Groningen), and am looking for my next big challenge. While looking at your website, I found out about the Metis platform and some of the work your team is doing on Edge AI. Being a computer vision developer myself, I am obviously very interested in working at Axelera. I am currently looking for an AI role in the NL and I would love to discuss the possibility of any such roles with you.</p> <p>My experience is a combination of AI, Computer vision and Data Analytics. Over the past few years, I have worked with many clients (both freelance/part time and in internships) and helped them bring their AI projects to life. I am also quite familiar with the ins and outs of Deep Learning with a specialisation in Computer Vision. Along with my technical knowledge, what is more important is that I want to be part of your mission to democratise edge AI. I believe that this technology can lead to a lot of innovations in many fields, but without the right people, we will not be able to make AI for a green, fair and safe world. These are all tasks that you do, and so I think that I might be a good fit at Axelera.</p> <p>While I am not sure what kind of roles exist at the moment, I am open to any AI/Data Science related position. I\u2019ve attached my resume to this email as well.</p> <p>Looking forward to your reply,</p>","tags":["jobs"]},{"location":"KB/NLAIC%20Companies/#almende","title":"Almende","text":"<p>Hello Jan!</p> <p>This is Subhaditya. I recently graduated with a masters in AI from the RUG (Groningen), and am looking for my next big challenge. While looking at your website, I found quite a lot of awesome projects (FoodFriend and VARUS were my favourites) that made me very interested in working at the Health domain at Almende. I noticed that in many projects your team mentioned they wanted to test out neural networks but did not. I am currently looking for an AI role in the NL and I would love to discuss the possibility of any such roles with you.</p> <p>My experience is a combination of AI, Computer vision and Data Analytics. Over the past few years, I have worked with many clients (both freelance/part time and in internships) and helped them bring their AI projects to life. I am also quite familiar with the ins and outs of Deep Learning and how to apply them to a large variety of domains. Along with my technical skills, I love working on new projects, especially if they help people. These are all tasks that you do, and so I think that I might be a good fit at Almende.</p> <p>While I am not sure what kind of roles exist at the moment, I am open to any AI/Data Science related position. I\u2019ve attached my resume to this email as well.</p> <p>Looking forward to your reply,</p>","tags":["jobs"]},{"location":"KB/NLAIC%20Companies/#attendi","title":"Attendi","text":"<p>lennertjansen95@gmail.com</p> <p>Hello Lennert!</p> <p>This is Subhaditya. I recently graduated with a masters in AI from the RUG (Groningen), and am looking for my next big challenge. While looking at the Attendi website, I found out about some of the work your team is doing on Speech AI. Along with being a good cause to work on, it sounds like Attendi is a great place to work at. I am currently looking for an AI role in the NL and I would love to discuss the possibility of any such roles with you. (I got your email from your personal website haha)</p> <p>My experience is a combination of AI, and Data Analytics. Over the past few years, I have worked with many clients (both freelance/part time and in internships) and helped them bring their AI projects to life. I am also quite familiar with the ins and outs of Deep Learning and how to apply them to a large variety of domains. I have worked with LLMs and am also comfortable with PyTorch and Tensorflow. Along with my technical skills, I love working on new projects, especially if they help people. These are all tasks that you do, and so I think that I might be a good fit at Attendi.</p> <p>While I am not sure what kind of roles exist at the moment, I am open to any AI/Data Science related position. I\u2019ve attached my resume to this email as well.</p>","tags":["jobs"]},{"location":"KB/NLAIC%20Companies/#neolook-solutions","title":"Neolook Solutions","text":"<p>johan.thissen@gmail.com</p> <p>Hello Johan!</p> <p>Hope you are well.</p> <p>My name is Subhaditya, I recently graduated with a masters in AI from the RUG (Groningen), and am looking for my next big challenge. I heard about Neolook from one of my friends (she met you at a Hattrick event at the RUG) and found the premise very interesting. She mentioned that you also have ML/DL pipelines that you wanted to implement and research, which is why I thought I would drop you an email. I am currently looking for an AI position in the NL and I would love to discuss the possibility of any such roles with you.</p> <p>My experience is a combination of AI and Computer Vision. Over the past few years, I have worked with many clients (both freelance/part-time and in internships) and helped them bring their AI projects to life. I am quite familiar with DL libraries like PyTorch and Tensorflow along with implementing multi-modal models. Along with that, I am good at explaining concepts at a high level and have commercial experience in deploying ML applications.\u00a0</p> <p>I am quite interested in applying AI in healthcare, and when I saw that Neolook might give me a chance to do just that, I had to apply. While at the moment I have a lot to learn about neonatal healthcare, I am willing to do that. I am not queasy about walking through wards, and am comfortable with working alone and in teams as well.</p> <p>While I am not sure what kind of roles exist at Neolook at the moment, I am open to any AI-related positions. I\u2019ve attached my resume to this email as well. It would be awesome to have a chat with you Johan, I hope you give me a chance!</p>","tags":["jobs"]},{"location":"KB/NLAIC%20Companies/#atlasium-media","title":"Atlasium Media","text":"<p>Amin Gorti</p> <p>Hello Amin!</p> <p>My name is Subhaditya, I recently graduated with a masters in AI from the RUG (Groningen), and am looking for my next big challenge. I am quite interested in the AI consultancy role you just posted, and would love to talk to you about it :)</p>","tags":["jobs"]},{"location":"KB/NLAIC%20Companies/#valueblue","title":"ValueBlue","text":"<p>Dan Bersagui</p> <p>Hello Dan!</p> <p>My name is Subhaditya, I recently graduated with a masters in AI from the RUG (Groningen), and am looking for my next big challenge. I am quite interested in the AI role you just posted, and would love to talk to you and see if I could be a good fit for it.</p> <p>Best,</p> <p>SM</p> <p>Hello Dan!\u00a0</p> <p>My name is Subhaditya, I recently graduated with a masters in AI from the RUG (Groningen), and am looking for my next big challenge. I found this position on LinkedIn and the phrase \u201cArchitects of Change\u201d piqued my interest. I\u2019ve heard about BlueDolphin before, and imagine my surprise when I saw that you also wanted to implement AI algorithms as well! I am currently looking for an AI role in the NL and I would love to be the one to start the ML department at ValueBlue.</p> <p>My experience is a combination of AI and Data Analytics. I am proficient in setting up and tuning open source models across all levels. Over the past few years, I have worked with many clients (both freelance/part-time and in internships) and helped them bring their AI projects to life. I am quite familiar with AI libraries like PyTorch and Tensorflow along with MLOps tools. I have worked quite extensively with Neptune, Tensorboard and Docker for many years as well.\u00a0</p> <p>BlueDolphin has been around for a while and I\u2019m sure there is a lot of interesting data that was collected/obtained from public domains. This makes it all the more challenging and I am all for that.</p> <p>I am quite passionate about both the technical and human sides of AI. Being a new department working on a lot of cross functional teams requires this mentality, and I think that I do bring this and more to the table.\u00a0</p> <p>I hope you give me a chance!</p>","tags":["jobs"]},{"location":"KB/NLAIC%20Companies/#3d-universum","title":"3D Universum","text":"<p>info@3duniversum.com</p> <p>Hello!</p> <p>My name is Subhaditya, I recently graduated with a masters in AI from the RUG (Groningen), and am looking for my next big challenge. I found out about 3DUniversum from Dr.Sezer when I met him at an event last week. The work your team does is very much in line with my interests and experience and as I am currently looking for an AI position in the NL, I would love to discuss the possibility of any such roles at 3DUniversum.\u00a0</p> <p>I asked him if there were open roles, and he told me that the team was expanding and while most of your group is from UvA, I could give it a shot too.</p> <p>My experience is a combination of Computer Vision and AI. Over the past few years, I have worked with many clients (both freelance/part time and in internships) and helped them bring their AI projects to life. I am familiar with deep learning libraries like PyTorch and Tensorflow and am proficient in Python as well. I have worked with Synthetic media creation, Efficient Deep Learning, Mobile/Edge AI as well as 3D Segmentation and Detection.\u00a0</p> <p>Dr.Sezer told me quite a bit about projects like Deep Therapy, WeScan and FairFake and it somehow seemed like 3DUniversum would be the perfect place for me to go next. I do think that I bring something different to the table in the domains that your team works in, and I hope you give me a chance.</p> <p>My Github link is : http://github.com/SubhadityaMukherjee and I have attached my resume to this email as well.</p>","tags":["jobs"]},{"location":"KB/NLAIC%20Companies/#birdsai","title":"Birds.ai","text":"<p>info@birds.ai</p> <p>Hello!</p> <p>My name is Subhaditya. I recently graduated with a masters in AI from the RUG (Groningen), and am looking for my next big challenge. I found out about Birds.ai from the NLAIC website and found some of the projects your team has done (like the CV-based solar panel inspection project).\u00a0 The work your team does is very much in line with my interests and experience, and I would love to discuss the possibility of any such roles at Birds.ai.</p> <p>My experience is a combination of Computer Vision and Data Analytics. Over the past few years, I have worked with many clients (both freelance/part-time and in internships) and helped them bring their AI projects to life. I am familiar with deep learning libraries like PyTorch and TensorFlow. I have worked with drone image segmentation, vision-based analysis for parts of the manufacturing pipeline and similar projects.\u00a0</p> <p>Add in the consultancy work your team does, and somehow, it seems to be exactly what I want to do as the next step in my career. I do think that my skills fit the kind of projects Birds.ai does and that I bring something different to the table.\u00a0</p> <p>While I am not sure what kind of roles exist at the moment, I am open to any AI/Data Science related position. I\u2019ve also attached my resume to this email as a little more background if that helps.\u00a0</p>","tags":["jobs"]},{"location":"KB/NLAIC%20Companies/#bright-cape","title":"Bright Cape","text":"<p>Onno Hofstee, o.hofstee@brightcape.nl </p> <p>Hello Onno!</p> <p>My name is Subhaditya, I recently graduated with a masters in AI from the RUG (Groningen), and am looking for my next big challenge. I found out about BrightCape from the NLAIC website and the first thing that caught my eye was SARA, the health assistant. It seems like your team works on some very interesting projects and I would love to discuss the possibility of any AI/Data Analytics roles at BrightCape.\u00a0</p> <p>My experience is a combination of AI and Data Analytics. Over the past few years, I have worked with many clients (both freelance/part-time and in internships) and helped them bring their AI projects to life. I am familiar with deep learning libraries like PyTorch and TensorFlow along with the stack required to build Data Analysis pipelines and provide clients with the advice they need.</p> <p>Add in the consultancy work your team does, and somehow, it seems to be a nice fit with both what I can offer, and what I want to do as a next step. I do think that my skills fit the kind of projects BrightCape does and that I bring something different to the table.\u00a0</p> <p>While I am not sure what kind of roles exist at the moment, I am open to any AI/Data Science related position. I\u2019ve also attached my resume to this email as a little more background if that helps.\u00a0If you are hiring or will be soon, I would love to have a chat!</p> <p>PS: I am already excited about a potential ski trip. :)</p>","tags":["jobs"]},{"location":"KB/NLAIC%20Companies/#kepler-vision-internship","title":"Kepler Vision , Internship","text":"<p>info@keplervision.eu</p> <p>Hello!</p> <p>My name is Subhaditya, I recently graduated with a masters in AI from the RUG (Groningen), and am looking for my next big challenge. I found out about Kepler Vision from the NLAIC website, and saw that your team was looking for a software engineering intern. The Night Nurse software seems like a great project to start my career with and this email is my application for this position. I hope to get to learn a lot about how to be a good part of an engineering team, while also bringing my AI experience to the table.</p> <p>While I don\u2019t know what criteria you have in selecting an intern, this opportunity would be the absolute best next step for me. My main interests lie in Computer Vision, especially in using AI in healthcare. And somehow, this is exactly what this internship offers to teach? It would be such a miss if I did not try my best to get in.</p> <p>My experience is a combination of AI and Computer Vision. Over the past few years, I have worked with many clients (both freelance/part-time and in internships) and helped them bring their AI projects to life. But, what I now need to learn is how to work on larger scale projects such as Night Nurse. I am quite good with Python, FastAPI, and AI frameworks like PyTorch and Tensorflow, but am not very familiar with Terraform or Typescript. I definitely want to learn them though! And this internship would be absolutely perfect.</p> <p>I promise to put my best foot forward given a chance. I am quite a fast learning, and have a strong base in programming and AI. I hope you give me a shot.\u00a0</p> <p>PS. I have the Zuikjaar visa as well, valid for almost a year. So no issues there either.</p>","tags":["jobs"]},{"location":"KB/NLAIC%20Companies/#grwnxt","title":"Grwnxt","text":"<p>coen.hilbrands@grwnxt.com\u00a0, info@grwnxt.com </p> <p>Hello Coen!</p> <p>My name is Subhaditya, I recently graduated with a masters in AI from the RUG (Groningen), and am looking for my next big challenge. I found out about GrwNxt from the NLAIC website and was intrigued by the concept of GrwNxt Modules and how they could be used for reliably, combining Deep learning and plant science. I can imagine just how useful and scalable the technology would be, especially combined with AI and computer vision. The work your team does is very much in line with my interests and experience, and I would love to discuss the possibility of any such roles at GrwNxt.</p> <p>My experience is a combination of AI and Computer Vision, which is something I see that your team works on as well. Over the past few years, I have worked with many clients (both freelance/part-time and in internships) and helped them bring their AI projects to life. Now that I have a masters in AI, I\u2019m trying to find places I can contribute the most to, and I think GrwNxt fits quite well to that. From the presentation on your website, I see that the modules would use a lot of advanced data analytics combined with computer vision, which is what I am the most familiar with. I am proficient at using Deep learning libraries, such as PyTorch and Tensorflow and am comfortable with all stages of the AI pipeline. Since my main focus has always been Computer vision, I can help your team implement the advanced data analysis pipelines faster as well.\u00a0</p> <p>This project really interests me and while I am not sure what kind of roles you have at the moment, I am open to any AI/Data Science related position. Being able to contribute to the sustainable food revolution is such a good cause, and I would love to be a part of it.</p> <p>I\u2019ve also attached my resume to this email as a little more background if that helps.\u00a0If you are hiring or will be soon, I would love to have a chat!</p>","tags":["jobs"]},{"location":"KB/NLAIC%20Companies/#mindaffect","title":"MindAffect","text":"<p>careers@mindaffect.nl</p>","tags":["jobs"]},{"location":"KB/NLVR2%203/","title":"NLVR2","text":""},{"location":"KB/NLVR2%203/#nlvr2","title":"NLVR2","text":""},{"location":"KB/NUMA/","title":"NUMA","text":""},{"location":"KB/NUMA/#numa","title":"NUMA","text":"<ul> <li>Shared memory</li> <li>Often made by physically linking two or more SMP</li> <li>One SMP can directly access memory of another SMP</li> <li>Not all processors have equal access time to all memories</li> <li>Memory access across link is slower</li> <li>Cache Coherence</li> </ul>"},{"location":"KB/NaN%20Trap/","title":"NaN Trap","text":""},{"location":"KB/NaN%20Trap/#nan-trap","title":"NaN Trap","text":"<ul> <li>When one number in your model becomes a NaN during training, which causes many or all other numbers in your model to eventually become a NaN.</li> </ul>"},{"location":"KB/Names%20of%20individuals/","title":"Names of individuals","text":""},{"location":"KB/Names%20of%20individuals/#names-of-individuals","title":"Names of Individuals","text":"<ul> <li>Dan went to the movies.</li> <li>Dan should be understood to be some person named Dan. Although there are many, the speaker had one particular one in mind and the discourse context should tell us which.</li> </ul>"},{"location":"KB/Nasnet/","title":"Nasnet","text":""},{"location":"KB/Nasnet/#nasnet","title":"Nasnet","text":"<ul> <li>Neural Architecture Search</li> <li>Controller RNN (Basic RNN Architectures) produces architectures and evaluated until convergence</li> </ul>"},{"location":"KB/Nativists/","title":"Nativists","text":""},{"location":"KB/Nativists/#nativists","title":"Nativists","text":"<ul> <li>noun and verb and determiner phrase and various sentence constituents are not only real mental primitives, but are innately given inherently linguistic primitives of the mind.</li> </ul>"},{"location":"KB/Nearest%20Neighbor%20Retrieval/","title":"Nearest Neighbor Retrieval","text":""},{"location":"KB/Nearest%20Neighbor%20Retrieval/#nearest-neighbor-retrieval","title":"Nearest Neighbor Retrieval","text":"<ul> <li>images with similar appearance usually are closer in the feature space </li> <li>The nearest neighbor method is used to find the top K nearest neighbors from the feature space of the features learned by the self-supervised learned model [40], [41], [43]</li> </ul>"},{"location":"KB/Nebulizer/","title":"Nebulizer","text":""},{"location":"KB/Nebulizer/#nebulizer","title":"Nebulizer","text":"<ul> <li>A device used to deliver medication in an aerosol form through inhalation</li> </ul>"},{"location":"KB/Negative%20Log%20Likelihood/","title":"Negative Log Likelihood","text":""},{"location":"KB/Negative%20Log%20Likelihood/#negative-log-likelihood","title":"Negative Log Likelihood","text":"<ul> <li>Classification, Smaller quicker training, Simple tasks.</li> </ul> \\[ - \\mathrm{sum}\\left( \\log\\left( y \\right) \\right)\\] <ul> <li>Log Likelihood Loss</li> </ul>"},{"location":"KB/Negative%20Sampling/","title":"Negative Sampling","text":""},{"location":"KB/Negative%20Sampling/#negative-sampling","title":"Negative Sampling","text":"<ul> <li>introduce samples of words that are not neighbors</li> <li></li> <li></li> </ul>"},{"location":"KB/Negative%20Set%20Bias/","title":"Negative Set Bias","text":""},{"location":"KB/Negative%20Set%20Bias/#negative-set-bias","title":"Negative Set Bias","text":"<ul> <li>Datasets define a visual phenomenon (e.g. object, scene, event) not just by what it is (positive instances), but also by what it is not (negative instances)</li> <li>the space of all possible negatives in the visual world is astronomically large, so datasets are forced to rely on only a small sample</li> <li>ImageNet benefits from a large variability of negative examples and does not seem to be affected by a new external negative set, whereas Caltech and MSRC appear to be just too easy</li> <li>Unfortunately, it's not at all easy to stress-test the sufficiency of a negative set in the general case since it will require huge amounts of labelled (and unbiased) negative data.</li> <li>One remedy, proposed in this paper, is to add negatives from other datasets</li> <li>Another approach, suggested by Mark Everingham, is to use a few standard algorithms (e.g. bag of words) to actively mine hard negatives as part of dataset construction from a very large unlabelled set, and then manually going through them to weed out true positives. The down side is that the resulting dataset will be biased against existing algorithms.</li> </ul>"},{"location":"KB/Nesterov%20Momentum/","title":"Nesterov Momentum","text":""},{"location":"KB/Nesterov%20Momentum/#nesterov-momentum","title":"Nesterov Momentum","text":"<ul> <li>$$\\begin{align}</li> </ul> <p>&amp;v_{t}= \\gamma v_{t+1}+\\eta \\cdot \\nabla_{\\theta}J(\\theta - \\gamma v_{t-1}) \\</p> <p>&amp;\\theta = \\theta- v_{t}\\</p> <p>\\end{align}$$</p>"},{"location":"KB/Network%20Dissection%20Quantifying%20Interpretability%20of%20Deep%20Visual%20Representions/","title":"Network Dissection Quantifying Interpretability of Deep Visual Representions","text":""},{"location":"KB/Network%20Dissection%20Quantifying%20Interpretability%20of%20Deep%20Visual%20Representions/#network-dissection-quantifying-interpretability-of-deep-visual-representions","title":"Network Dissection Quantifying Interpretability of Deep Visual Representions","text":"<ul> <li> <p>David Bau\u2217, Bolei Zhou\u2217, Aditya Khosla, Aude Oliva, and Antonio Torralba</p> </li> <li> <p>Quantifying the interpretability of latent representations of CNNs by evaluating the alignment between individual hidden units and a set of semantic concepts</p> </li> <li>score the semantics of hidden units at each intermediate convolutional layer.</li> <li>The units with semantics are given labels across a range of objects, parts, scenes, textures, materials, and colors.</li> <li>interpretability of units is equivalent to random linear combinations of units</li> <li>analyze the effect of training iterations, compare networks trained with different initializations, examine the impact of network depth and width, and measure the effect of dropout and batch normalization on the interpretability of deep visual representations</li> </ul>"},{"location":"KB/Network%20Dissection%20Quantifying%20Interpretability%20of%20Deep%20Visual%20Representions/#introduction","title":"Introduction","text":"<ul> <li>The emergence of interpretable structure suggests that deep networks may be learning disentangled representations spontaneously.</li> <li>A disentangled representation aligns its variables with a meaningful factorization of the underlying problem structure</li> <li>Broden</li> </ul>"},{"location":"KB/Network%20Dissection%20Quantifying%20Interpretability%20of%20Deep%20Visual%20Representions/#network-dissection","title":"Network Dissection","text":"<ul> <li>Our measurement of interpretability for deep visual representations proceeds in three steps: 1. Identify a broad set of human-labeled visual concepts. 2. Gather hidden variables' response to known concepts. 3. Quantify alignment of hidden variableconcept pairs.</li> <li>In a fully interpretable local coding such as a one-hotencoding, each variable will match exactly with one humaninterpretable concept.</li> <li>Therefore we measure the alignment between single units and single interpretable concepts</li> <li>This does not gauge the discriminative power of the representation; rather it quantifies its disentangled interpretability.</li> <li>We then measure the alignment of each hidden unit of the CNN with each concept by evaluating the feature activation of each individual unit as a segmentation model for each concept</li> <li>To quantify the interpretability of a layer as a whole, we count the number of distinct visual concepts that are aligned with a unit in the layer</li> <li>Broden</li> </ul>"},{"location":"KB/Network%20Dissection%20Quantifying%20Interpretability%20of%20Deep%20Visual%20Representions/#scoring-unit-interpretability","title":"Scoring Unit Interpretability","text":"<ul> <li>evaluates every individual convolutional unit in a CNN as a solution to a binary segmentation task to every visual concept in Broden</li> <li>applied to any CNN using a forward pass without the need for training or backpropagation.</li> <li>For every input image x in the Broden dataset, the activation map \\(A_{k}(x)\\) of every internal convolutional unit k is collected.</li> <li>Then the distribution of individual unit activations ak is computed</li> <li>For each unit k, the top quantile level \\(T_{k}\\) is determined such that \\(P(a_{k} &gt; T_{k} = 0.005\\) over every spatial location of the activation map in the data set.</li> <li>input-resolution annotation mask \\(L_{c}\\) for some concept c</li> <li>the activation map is scaled up to the mask resolution \\(S_{k}(x)\\) from \\(A_{k}(x)\\) using bilinear interpolation, anchoring interpolants at the center of each unit's receptive field</li> <li>\\(S_{k}(x)\\) is then thresholded into a binary segmentation: \\(M_{k}(x) \\equiv S_{k}(x) \\leq T_{k}\\), selecting all regions for which the activation exceeds the threshold Tk. These segmentations are evaluated against every concept c in the data set by computing intersections \\(M_{k}(x) \\cap L_{c}(x)\\), for every (k, c) pair.</li> <li>The score of each unit k as segmentation for concept c is reported as a data-set-wide intersection over union score \\(\\(I_{o}U_{k,c}=\\frac{\\Sigma|M_{k}(x) \\cap L_{c}(x|}{\\Sigma|M_{k}(x) \\cup L_{c}(x)|}\\)\\)</li> <li>where | \u00b7 | is the cardinality of a set.</li> <li>The value of \\(IoU_{k,c}\\) is the accuracy of unit k in detecting concept c; we consider one unit k as a detector for concept c if IoUk,c exceeds a threshold</li> <li>Our qualitative results are insensitive to the IoU threshold: different thresholds denote different numbers of units as concept detectors</li> <li>For our comparisons we report a detector if IoUk,c &gt; 0.04.</li> <li>one unit might be the detector for multiple concepts; for the purpose of our analysis, we choose the top ranked label</li> <li>The IoU evaluating the quality of the segmentation of a unit is an objective confidence score for interpretability that is comparable across networks</li> <li>Note that network dissection works only as well as the underlying data set</li> <li>We conclude that interpretability is neither an inevitable result of discriminative power, nor is it a prerequisite to discriminative power.</li> <li>Instead, we find that interpretability is a different quality that must be measured separately to be understood.</li> </ul>"},{"location":"KB/Network%20Dissection%20Quantifying%20Interpretability%20of%20Deep%20Visual%20Representions/#measure-of-axis-aligned-interpretability","title":"Measure of Axis Aligned Interpretability","text":""},{"location":"KB/Network%20Dissection%20Quantifying%20Interpretability%20of%20Deep%20Visual%20Representions/#disentangled-concepts-by-layer","title":"Disentangled Concepts by Layer","text":"<ul> <li>Confirming intuition, color and texture concepts dominate at lower layers conv1 and conv2 while more object and part detectors emerge in conv5.</li> </ul>"},{"location":"KB/Network%20Dissection%20Quantifying%20Interpretability%20of%20Deep%20Visual%20Representions/#network-architectures-and-supervisions","title":"Network Architectures and Supervisions","text":"<ul> <li>In terms of network architecture, we find that interpretability of ResNet &gt; VGG &gt; GoogLeNet &gt; AlexNet</li> <li>Deeper architectures appear to allow greater interpretability. Places &gt; ImageNet.</li> <li>Self-supervised models create many texture detectors but relatively few object detectors; apparently, supervision from a self-taught primary task is much weaker at inferring interpretable concepts than supervised training on a large annotated data set</li> <li>The form of self-supervision makes a difference: for example, the colorization model is trained on colorless images, and almost no color detection units emerge</li> <li>We hypothesize that emergent units represent concepts required to solve the primary task.</li> </ul>"},{"location":"KB/Network%20Dissection%20Quantifying%20Interpretability%20of%20Deep%20Visual%20Representions/#training-conditions-vs-interpretability","title":"Training Conditions Vs. Interpretability","text":"<ul> <li>We can see that object detectors and part detectors begin emerging at about 10,000 iterations (each iteration processes a batch of 256 images)</li> <li>We do not find evidence of transitions across different concept categories during training</li> <li>For example, units in conv5 do not turn into texture or material detectors before becoming object or part detectors.</li> <li>Comparing different random initializations, the models converge to similar levels of interpretability, both in terms of the unique detector number and the total detector number; this matches observations of convergent learning</li> <li>For the network without dropout, more texture detectors emerge but fewer object detectors</li> <li>Batch normalization seems to decrease interpretability significantly.</li> <li>The batch normalization result serves as a caution that discriminative power is not the only property of a representation that should be measured.</li> <li>batch normalization 'whitens' the activation at each layer, which smooths out scaling issues and allows a network to easily rotate axes of intermediate representations during training</li> <li>While whitening apparently speeds training, it may also have an effect similar to random rotations analyzed in Sec. 3.2 which destroy interpretability</li> <li>interpretability is neither a prerequisite nor an obstacle to discriminative power</li> <li></li> <li></li> <li></li> </ul>"},{"location":"KB/Network%20Dissection%20Quantifying%20Interpretability%20of%20Deep%20Visual%20Representions/#discrimination-vs-interpretability","title":"Discrimination Vs. Interpretability","text":"<ul> <li>For each trained model, we extract the representation at the highest convolutional layer, and train a linear SVM with C = 0.001 on the training data for action40 action recognition task</li> <li>Thus the supervision tasks that encourage the emergence of more concept detectors may also improve the discrimination ability of deep features.</li> <li>accuracy on a representation when applied to a task is dependent not only on the number of concept detectors in the representation, but on the suitability of the set of represented concepts to the transfer task.</li> <li></li> </ul>"},{"location":"KB/Network%20Dissection%20Quantifying%20Interpretability%20of%20Deep%20Visual%20Representions/#layer-width-vs-interpretability","title":"Layer Width Vs. Interpretability","text":"<ul> <li>Depth has been shown to be important to high discrimination ability</li> <li>increasing the number of convolutional units at a layer significantly increases computational cost while yielding only marginal improvements in classification accuracy</li> <li>carefully designed wide residual network can achieve classification accuracy superior to the commonly used thin and deep counterparts.</li> <li>This may indicate a limit on the capacity of AlexNet to separate explanatory factors; or it may indicate that a limit on the number of disentangled concepts that are helpful to solve the primary task of scene classification.</li> <li></li> </ul>"},{"location":"KB/Neural%20Augmentation/","title":"Neural Augmentation","text":""},{"location":"KB/Neural%20Augmentation/#neural-augmentation","title":"Neural Augmentation","text":"<ul> <li>The Neural Style Transfer algorithm requires two parameters for the weights of the style and content loss. Perez and Wang presented an algorithm to meta-learn a Neural Style Transfer strategy called Neural Augmentation.</li> <li>e Neural Augmentation approach takes in two random images from the same class. The prepended augmentation net maps them into a new image through a CNN with 5 layers, each with 16 channels, 3\u00d73 filters, and ReLU activation functions. The image outputted from the augmentation is then transformed with another random image via Neural Style Transfer.</li> <li>This style transfer is carried out via the CycleGAN extension of the GAN framework</li> <li>These images are then fed into a classification model and the error from the classification model is backpropagated to update the Neural Augmentation net.</li> <li>The Neural Augmentation network uses this error to learn the optimal weighting for content and style images between different images as well as the mapping between images in the CNN</li> <li>The Neural Augmentation techniques tested consist of three levels based on the design of the loss function for the augmentation net (Content loss, Style loss via gram matrix, and no loss computer at this layer)</li> </ul>"},{"location":"KB/Neural%20Chimera/","title":"Neural Chimera","text":""},{"location":"KB/Neural%20Chimera/#neural-chimera","title":"Neural Chimera","text":"<ul> <li>A research model where human stem cells are transplanted into an animal embryo to follow the genetic, molecular, and functional processes of brain cells as they grow.</li> </ul>"},{"location":"KB/Neural%20Dynamics/","title":"Neural Dynamics","text":""},{"location":"KB/Neural%20Dynamics/#neural-dynamics","title":"Neural Dynamics","text":"<ul> <li>Continous -&gt; Discrete seq of words</li> <li>Use NN to generate hypothesis outputs vectors<ul> <li>As many components as possible target symbols</li> </ul> </li> </ul>"},{"location":"KB/Neural%20Induction/","title":"Neural Induction","text":""},{"location":"KB/Neural%20Induction/#neural-induction","title":"Neural Induction","text":"<ul> <li>A developmental process where ectodermal cells \u201cdecide\u201d to form the neural plate, the basis of what will eventually become the organism\u2019s nervous system.</li> </ul>"},{"location":"KB/Neural%20Network%20Architecture%20Cheat%20Sheet/","title":"Neural Network Architecture Cheat Sheet","text":""},{"location":"KB/Neural%20Network%20Architecture%20Cheat%20Sheet/#neural-network-architecture-cheat-sheet","title":"Neural Network Architecture Cheat Sheet","text":"<ul> <li>Spiking Networks</li> <li>Hidden Models</li> <li>Capsule Network</li> <li>Probability</li> <li>Recurrent</li> <li>Conv</li> </ul>"},{"location":"KB/Neural%20Probabilistic%20Model/","title":"Neural Probabilistic Model","text":""},{"location":"KB/Neural%20Probabilistic%20Model/#neural-probabilistic-model","title":"Neural Probabilistic Model","text":"<ul> <li>A Neural Probabilistic Language Model</li> <li>more compact and smoother representations based on distributed representations that can accommodate far more conditioning variables</li> <li>learning the joint probability function of sequences of words in a language was intrinsically difficult because of the curse of dimensionality</li> <li>learning a distributed representation for words which allows each training sentence to inform the model about an exponential/combinatorial number of semantically neighboring sentences</li> <li>The model learns simultaneously (i) a distributed representation for each word along with (ii) the probability function for word sequences, expressed in terms of these representations</li> <li>Generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar</li> <li>significantly improves on state-of-the-art n gram models</li> </ul>"},{"location":"KB/Neural%20Radiance%20Field/","title":"Neural Radiance Field","text":""},{"location":"KB/Neural%20Radiance%20Field/#neural-radiance-field","title":"Neural Radiance Field","text":"<ul> <li>NeRF: Representing Scenes As Neural Radiance Fields for View Synthesis<ul> <li>synthesizing novel views of complex scenes</li> <li>optimizing an underlying continuous volumetric scene function using a sparse set of input views</li> <li>single continuous 5D coordinate (spatial location (x,y,z) and viewing direction (\u03b8,\u03d5))</li> <li>output is the volume density and view-dependent emitted radiance at that spatial location</li> <li>querying 5D coordinates along camera rays</li> <li>volume rendering techniques to project the output colors and densities into an image</li> <li>volume rendering is naturally differentiable</li> <li>set of images with known camera poses</li> <li>They describe how to effectively optimize neural radiance fields to render photorealistic novel views of scenes</li> </ul> </li> </ul>"},{"location":"KB/Neural%20Text%20Degeneration/","title":"Neural Text Degeneration","text":""},{"location":"KB/Neural%20Text%20Degeneration/#neural-text-degeneration","title":"Neural Text Degeneration","text":"<ul> <li>The Curious Case of Neural Text Degeneration</li> <li>deep analysis into the properties of the most common decoding methods for open-ended language generation</li> <li>surprising distributional differences between human text and machine text</li> <li>decoding strategies alone can dramatically effect the quality of machine text, even when generated from exactly the same neural language model</li> <li>likelihood maximizing decoding causes repetition and overly generic language usage</li> <li>sampling methods without truncation risk sampling from the low-confidence tail of a model\u2019s predicted distribution</li> <li>Nucleus Sampling</li> </ul>"},{"location":"KB/Neuroaesthetics/","title":"Neuroaesthetics","text":""},{"location":"KB/Neuroaesthetics/#neuroaesthetics","title":"Neuroaesthetics","text":"<ul> <li>A field within cognitive neuroscience that examines the neural underpinnings of what humans find visually appealing or beautiful.</li> </ul>"},{"location":"KB/Neurogenesis/","title":"Neurogenesis","text":""},{"location":"KB/Neurogenesis/#neurogenesis","title":"Neurogenesis","text":"<ul> <li>The production of new, maturing neurons by neural stem and progenitor cells. Rapid and widespread neurogenesis obviously occurs in the fetal brain in humans and other animals, but neuroscientists long believed that neurogenesis essentially does not occur in the adult human brain.</li> <li>However, over the past two decades, research has shown that it does in fact occur in the dentate gyrus of the hippocampus and possibly other brain regions. This \u201cadult neurogenesis\u201d appears to be vital for normal learning and memory, and may help protect the brain against stress and depression.</li> </ul>"},{"location":"KB/Neuroplasticity/","title":"Neuroplasticity","text":""},{"location":"KB/Neuroplasticity/#neuroplasticity","title":"Neuroplasticity","text":"<ul> <li>Also referred to as brain plasticity or neural plasticity, this is the ability of the brain to change throughout the lifespan, forming new synapses and neural connections in response to the environment.</li> </ul>"},{"location":"KB/Newtons%20Laws/","title":"Newtons Laws","text":""},{"location":"KB/Newtons%20Laws/#newtons-laws","title":"Newtons Laws","text":"<ul> <li>Inertia</li> <li>Force</li> <li>Equal And Opposite Force Pairs</li> </ul>"},{"location":"KB/No%20bias%20decay/","title":"No bias decay","text":""},{"location":"KB/No%20bias%20decay/#no-bias-decay","title":"No Bias Decay","text":"<ul> <li>No Learning Rate Decay tricks</li> <li>Equivalent to Lp Regularization L2 to all parameters to drive the values towards 0</li> <li>Only apply Regularization to the weights</li> <li>Leave Batch Normalization Layers alone</li> <li>LARS</li> </ul>"},{"location":"KB/Node%20Distribution/","title":"Node Distribution","text":""},{"location":"KB/Node%20Distribution/#node-distribution","title":"Node Distribution","text":"<p>-</p>"},{"location":"KB/Node%20Link%20Diagram/","title":"Node LInk Diagram","text":""},{"location":"KB/Node%20Link%20Diagram/#node-link-diagram","title":"Node LInk Diagram","text":"<ul> <li>Vertices (Nodes) are mapped to graphical shapes circles, squares, triangles, etc.</li> <li>Edges (Links) are mapped to straight or curved lines</li> <li>Nodes can freely be positioned</li> <li>Cross Minimization</li> <li>Bend Minimization</li> <li>Area Minimization</li> <li>Cross angle Maximization</li> <li>Length Optimization</li> <li>Symmetries Node Link</li> <li>Node Distribution</li> <li>Force Directed Graph Layout</li> <li>Hierarchical Edge Bundling</li> </ul>"},{"location":"KB/Noise%20Injection/","title":"Noise Injection","text":""},{"location":"KB/Noise%20Injection/#noise-injection","title":"Noise Injection","text":"<ul> <li>injecting a matrix of random values usually drawn from a Gaussian distribution</li> <li>Adding noise to images can help CNNs learn more robust features.</li> </ul>"},{"location":"KB/Noise%20Suppression/","title":"Noise Suppression","text":""},{"location":"KB/Noise%20Suppression/#noise-suppression","title":"Noise Suppression","text":"<ul> <li>reduce the intensity variation in big structures (such as organs in medical imaging data) -improve the detectability of edges between big structures,</li> <li>preserve small scale structures - Conv Based Noise Reduction</li> <li>Average Filter</li> <li>Gaussian Filter</li> <li>Mesh Smoothing</li> <li>Laplacian Grid Smoothing</li> </ul>"},{"location":"KB/Noise%20Tunnel/","title":"Noise Tunnel","text":""},{"location":"KB/Noise%20Tunnel/#noise-tunnel","title":"Noise Tunnel","text":"<ul> <li>@kokhlikyanCaptumUnifiedGeneric2020</li> </ul>"},{"location":"KB/Noise%20Tunnel/#summary","title":"Summary","text":"<ul> <li>Combines [SmoothGrad Square] + [Smooth-Grad] + VarGrad </li> <li>not an attribution method</li> </ul>"},{"location":"KB/Noise%20Tunnel/#using-smooth-grad","title":"Using Smooth-Grad","text":"<ul> <li>technique that improves the accuracy of attribution methods</li> <li>problem with ReLU activation function and gradients producing noisy, often irrelevant attributions</li> <li>the partial derivative \\(\\frac{\\partial F_c}{\\partial x_i}\\) of the models\u2019 score \\(F_c\\)\u200b for a class c with respect to the value of the pixel \\(x_{i}\\) fluctuates</li> <li>adding a Gaussian noise \\(\\mathcal {N}(0, 0.01^2)\\) and calculating an average of sampled attributions is going to solve the problem</li> <li>calculates the attribution \\(M_{c}\\) using any available method by providing that method an input with Gaussian noise</li> <li>calculates a mean value from all the samples to reduce the importance of less frequent attributions</li> <li>when adding noise to the input image, important attributions are going to be visible most of the time, and noise might change between attributions</li> <li> \\[\\hat M_{c}(x) = \\frac{1}{n}\\Sigma_{1}^{n}M_{c}(x + \\mathcal{N}(0, \\sigma^{2}))\\] </li> </ul>"},{"location":"KB/Noise%20Tunnel/#using-smoothgrad-square","title":"Using SmoothGrad Square","text":"<ul> <li>changes only the way that the mean value is calculated by using the mean of squared attributions instead of just attributions</li> <li>less noisy results</li> <li>but often removes less important features, which are still valid features</li> <li> \\[\\hat M_{c}(x) = \\frac{1}{n}\\Sigma_{1}^{n}\\sqrt{M_{c}(x + \\mathcal{N}(0, \\sigma^{2}))}\\] </li> </ul>"},{"location":"KB/Noise%20Tunnel/#using-vargrad","title":"Using VarGrad","text":"<ul> <li>variance version of the SmoothGrad</li> <li>Using SmoothGrad (Fig. 1c) seems to detect more edges of the input image (in comparison with pure IG attribution in [Fig. 1b]), and that can be interpreted as detecting decision boundary. SmoothGrad-Square (Fig. 1d) and VarGrad (Fig. 1e) are removing a large amount of noise but usually also some of the important features visible on the attribution from SmoothGrad</li> <li> \\[\\hat M_{c}(x) = \\frac{1}{n}\\Sigma_{k=1}^{n}\\{M_{c}(x + \\mathcal{N}(0, \\sigma^{2}))\\}^{2}- \\{\\hat M_{c}(x)\\}^{2}\\] </li> </ul>"},{"location":"KB/Noise%20Tunnel/#drawbacks","title":"Drawbacks","text":"<ul> <li>Even if the Noise Tunnel method improves the accuracy of the XAI methods it adds a large amount of computational overhead</li> <li>Every sample generated by the method requires the rerun of the whole XAI method</li> <li>That is a linear increase of computation and to make the method efficient you should use at least 5 generated noise samples</li> </ul>"},{"location":"KB/Noise%20Tunnel/#images","title":"Images","text":""},{"location":"KB/Noisy%20Relu/","title":"Noisy Relu","text":""},{"location":"KB/Noisy%20Relu/#noisy-relu","title":"Noisy Relu","text":"<ul> <li> \\[f(x) = max(0, x+Y) $$ where $$Y\\in Normal(0,1)\\] </li> </ul>"},{"location":"KB/Non%20Relational%20Inductive%20Bias/","title":"Non Relational Inductive Bias","text":""},{"location":"KB/Non%20Relational%20Inductive%20Bias/#non-relational-inductive-bias","title":"Non Relational Inductive Bias","text":"<ul> <li>Activation Functions<ul> <li>allow the model to capture the non-linearity hidden in the data</li> </ul> </li> <li>Dropout<ul> <li>helps the network avoid memorizing the data by forcing random subsets of the network to each learn the data pattern. As a result, the obtained model, in the end, is able to generalize better</li> </ul> </li> <li>Weight Decay<ul> <li>puts constraints on the model\u2019s weights</li> </ul> </li> <li>Batch Normalization , Layer Normalization , Instance Normalization<ul> <li>Reduces Covariate Shift</li> </ul> </li> <li>Augmentation</li> <li>Optimizers</li> </ul>"},{"location":"KB/Non-adjacent%20dependencies/","title":"Non-adjacent dependencies","text":""},{"location":"KB/Non-adjacent%20dependencies/#non-adjacent-dependencies","title":"Non-adjacent Dependencies","text":"<ul> <li>Wh-dependencies</li> <li>Extra-position</li> <li>Object-relative clauses</li> <li>Subject relative</li> <li>Subject-verb agreement</li> </ul>"},{"location":"KB/Non-response%20Bias/","title":"Non response Bias","text":""},{"location":"KB/Non-response%20Bias/#non-response-bias","title":"Non-response Bias","text":"<ul> <li>(also called participation bias)</li> <li>Users from certain groups opt-out of surveys at different rates than users from other groups.</li> </ul>"},{"location":"KB/Nonstationarity/","title":"Nonstationarity","text":""},{"location":"KB/Nonstationarity/#nonstationarity","title":"Nonstationarity","text":"<ul> <li>A feature whose values change across one or more dimensions, usually time. For example, the number of swimsuits sold at a particular store demonstrates nonstationarity because that number varies with the season. As a second example, the quantity of a particular fruit harvested in a particular region typically shows sharp nonstationarity over time.</li> </ul>"},{"location":"KB/Nootropics/","title":"Nootropics","text":""},{"location":"KB/Nootropics/#nootropics","title":"Nootropics","text":"<ul> <li>Drugs or supplements that are marketed as ways to improve cognitive functions like memory, attention, or creativity.</li> </ul>"},{"location":"KB/Normal%20Distribution/","title":"Normal Distribution","text":""},{"location":"KB/Normal%20Distribution/#normal-distribution","title":"Normal Distribution","text":"<ul> <li> \\[p(x) = \\frac{1}{\\sqrt{2\\pi\\sigma}}e^{-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}}\\] </li> <li>Mean \\(\\mu\\) and std \\(\\sigma\\). \\(\\mu\\) is max and \\(\\mu \\pm \\sigma\\) is locations of zeros of second derivative</li> <li></li> <li>\\(\\mathcal{N}(0,1)\\)</li> <li>Central Limit Theorem</li> </ul>"},{"location":"KB/Normal%20Distribution/#properties","title":"Properties","text":"<ul> <li>Linear combinations of normal distributed independant RVs are normal distributed</li> <li>X,Y have means \\(\\mu\\) and v and variances \\(\\sigma^{2}\\) and \\(\\tau^{2}\\). Then \\(aX + bY\\) is normally distributed and has mean : \\(a\\mu + bv\\) and variance \\(\\alpha^{2}\\sigma^{2}+b^{2}\\tau^{2}\\)</li> </ul>"},{"location":"KB/Normal%20Distribution/#computing-the-value","title":"Computing the Value","text":"<ul> <li> \\[\\int_{a}^{b} \\frac{1}{\\sqrt{2\\pi\\sigma}}e^{-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}}dx\\] </li> <li>Transform \\(\\mathscr{N}(\\mu, \\sigma^{2})\\) to \\(\\mathscr{N}(0,1)\\)</li> <li> \\[Z = \\frac{X-\\mu}{\\sigma}\\] </li> <li> \\[\\int_{\\frac{a-\\mu}{\\sigma}}^{\\frac{b-\\mu}{\\sigma}}\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{(x)^{2}}{2}}dx\\] </li> <li>Compute by using Cumulative density function \\(\\phi\\)</li> <li>Iterative solvers</li> <li> \\[\\phi(\\frac{b-\\mu}{\\sigma})-\\phi(\\frac{a-\\mu}{\\sigma})\\] </li> <li> \\[\\hat \\mu = \\frac{1}{N}\\Sigma_{i}(x_{i})$$ $$\\hat \\sigma^{2}= \\frac{1}{N-1}\\Sigma_{i}(x_{i}-\\hat\\mu)^2\\] </li> </ul>"},{"location":"KB/Normalized%20Inverted%20Structural%20Similarity%20Index/","title":"Normalized Inverted Structural Similarity Index","text":""},{"location":"KB/Normalized%20Inverted%20Structural%20Similarity%20Index/#normalized-inverted-structural-similarity-index","title":"Normalized Inverted Structural Similarity Index","text":"<ul> <li>metric is calculated from Structural Similarity Index by inverting the range and then normalizing it.</li> <li>NISSIM bounds to (0, 1] where 0 means similar and 1 means dissimilar. Ideally we want this value as close to 0 as possible</li> <li> \\[NISSIM_{i}= \\frac{1-SSIM_{i}}{2}\\] </li> </ul>"},{"location":"KB/Norms%20as%20a%20basis%20for%20governing%20sociotechnical%20systems/","title":"Norms as a basis for governing sociotechnical systems","text":""},{"location":"KB/Norms%20as%20a%20basis%20for%20governing%20sociotechnical%20systems/#norms-as-a-basis-for-governing-sociotechnical-systems","title":"Norms as a Basis for Governing Sociotechnical Systems","text":"<ul> <li>Munindar P. Singh</li> <li>framework that uses social norms to govern autonomous entities' (e.g., AI agents' or human beings') behaviours</li> <li>inherently distributed rather than relying on a central authority</li> <li>Individuals maintain their autonomy through executing their own decision policies, but are subjected to social norms defined by the collective through roles</li> <li>Social norms are defined through a template containing codified commitment, authorization, prohibition, sanction and power</li> </ul>"},{"location":"KB/Notch%20filter/","title":"Notch filter","text":""},{"location":"KB/Notch%20filter/#notch-filter","title":"Notch Filter","text":"<ul> <li>A notch filter is a type of band-stop filter, which is a filter that attenuates frequencies within a specific range while passing all other frequencies unaltered</li> </ul>"},{"location":"KB/Nucleotide%20Sequence/","title":"Nucleotide Sequence","text":""},{"location":"KB/Nucleotide%20Sequence/#nucleotide-sequence","title":"Nucleotide Sequence","text":"<ul> <li>A specific and ordered array of nucleotides that make up a specific genetic variant or allele.</li> </ul>"},{"location":"KB/Nucleotide/","title":"Nucleotide","text":""},{"location":"KB/Nucleotide/#nucleotide","title":"Nucleotide","text":"<ul> <li>Sometimes referred to as a nucleic acid, these are the biological building blocks of DNA.</li> </ul>"},{"location":"KB/Nucleus%20Accumbens/","title":"Nucleus Accumbens","text":""},{"location":"KB/Nucleus%20Accumbens/#nucleus-accumbens","title":"Nucleus Accumbens","text":"<ul> <li>Part of the brain\u2019s reward circuitry, or mesolimbic pathway, this small region in the midbrain releases dopamine in response to rewarding experiences.</li> </ul>"},{"location":"KB/Nucleus%20Sampling/","title":"Nucleus Sampling","text":""},{"location":"KB/Nucleus%20Sampling/#nucleus-sampling","title":"Nucleus Sampling","text":"<ul> <li>Nucleus (or top-p) Sampling, a simple but effective method that captures the region of confidence of language models effectively to draw the best out of neural generation</li> <li>By sampling text from the dynamic nucleus of the probability distribution, which allows for diversity while effectively truncating the less reliable tail of the distribution, the resulting text better demonstrates the quality of human text, yielding enhanced diversity without sacrificing fluency and coherence.</li> </ul>"},{"location":"KB/Numerically%20Quantified%20Expressions/","title":"Numerically Quantified Expressions","text":""},{"location":"KB/Numerically%20Quantified%20Expressions/#numerically-quantified-expressions","title":"Numerically Quantified Expressions","text":"<ul> <li>NQEs express<ul> <li>Plurality</li> <li>Cardinality</li> </ul> </li> <li>Can be in scopal relations with other expressions</li> </ul>"},{"location":"KB/OPT/","title":"OPT","text":""},{"location":"KB/OPT/#opt","title":"OPT","text":"<ul> <li>OPT: Open Pre-trained Transformer Language Models</li> <li>Large language models, which are often trained for hundreds of thousands of compute days, have shown remarkable capabilities for zero- and few-shot learning</li> <li>collection of auto-regressive/decoder-only pre-trained transformer-based language models ranging in size from 125M to 175B parameters, which we aim to fully and responsibly share with interested researchers</li> <li>replicate the performance and sizes of the GPT-3 class of models, while also applying the latest best practices in data curation and training efficiency</li> <li>OPT-175B is comparable to GPT-3, while requiring only 1/7th the carbon footprint to develop</li> </ul>"},{"location":"KB/OSIE/","title":"OSIE","text":""},{"location":"KB/OSIE/#osie","title":"OSIE","text":"<ul> <li>700 natural indoor and outdoor scenes, aesthetic photographs from Flickr and Google.</li> <li>The fixations were measured while 15 observers looked at the image for 3 s.</li> <li>the fixations for all observers were collected and blurred using the Gaussian filter with the standard deviation equivalent to 1\u00b0 in the visual angle</li> </ul>"},{"location":"KB/Object%20Detection/","title":"Object Detection","text":""},{"location":"KB/Object%20Detection/#object-detection","title":"Object Detection","text":"<ul> <li>localizing the position of objects in images and recognizing the category of the objects </li> <li>MSCOCO [99] and OpenImage [14] </li> <li>When using object detection as downstream task to evaluate the quality of the self-supervised image features, networks that trained with the pretext task on unlabeled large data are served as the pre-trained model for the Fast-RCNN [2] and then fine-tuned on object detection datasets, then the performance on the object detection task is evaluated to demonstrate the generalization ability of self- supervised learned features.</li> </ul>"},{"location":"KB/Object-relative%20clauses/","title":"Object-relative clauses","text":""},{"location":"KB/Object-relative%20clauses/#object-relative-clauses","title":"Object-relative Clauses","text":"<ul> <li>[The report] that the senator attacked [] admitted the error.</li> <li>[The senator] that the report attacked [] admitted the error.</li> </ul>"},{"location":"KB/Oblique%20Slicing/","title":"Oblique Slicing","text":""},{"location":"KB/Oblique%20Slicing/#oblique-slicing","title":"Oblique Slicing","text":"<ul> <li>Resample the data on arbitrarily oriented slices</li> <li>Exploit 3D texture mapping functionality</li> <li>Store volume in 3D texture</li> </ul>"},{"location":"KB/Obsidian%20tutorial/","title":"Obsidian tutorial","text":"","tags":["scientificresearch"]},{"location":"KB/Obsidian%20tutorial/#obsidian-tutorial","title":"Obsidian Tutorial","text":"","tags":["scientificresearch"]},{"location":"KB/Obsidian%20tutorial/#hello-there","title":"Hello There","text":"","tags":["scientificresearch"]},{"location":"KB/Obsidian%20tutorial/#creating-a-file","title":"Creating a File","text":"<ul> <li>Markdown basics<ul> <li>Paste into links</li> <li>Images<ul> <li>Drag and Drop vs Paste</li> </ul> </li> <li>Headings</li> <li>Bullets</li> <li>and numbers</li> <li>Code   <code>python   import numpy as np   s = np.array([1])   print(s)</code></li> <li>Tables<ul> <li>(Cmd/Control P -&gt; insert table)</li> </ul> </li> </ul> </li> <li>Linking files (double bracket)</li> <li>Zen Mode (Cmd/Control P -&gt; search)</li> </ul>","tags":["scientificresearch"]},{"location":"KB/Obsidian%20tutorial/#organization","title":"Organization","text":"<ul> <li>Tags - SmoothMix</li> <li>Templates - toc: true titler</li> <li>Folders</li> </ul>","tags":["scientificresearch"]},{"location":"KB/Obsidian%20tutorial/#navigation","title":"Navigation","text":"<ul> <li>Links and Backlinks (GUI)</li> <li>Forward and Backward (Cmd/Control + Option + Left/Right) </li> <li>Auto TOC</li> </ul>","tags":["scientificresearch"]},{"location":"KB/Obsidian%20tutorial/#general-tips","title":"General Tips","text":"<ul> <li>Search (Cmd/Control P)</li> <li>Using the GUI is perfectly fine</li> </ul>","tags":["scientificresearch"]},{"location":"KB/Obsidian%20tutorial/#taking-notes-from-elsewhere","title":"Taking Notes from Elsewhere","text":"<ul> <li>Websites : Roam highlighter</li> <li>PDF annotation : 3544548.3581388</li> </ul>","tags":["scientificresearch"]},{"location":"KB/Obsidian%20tutorial/#zotero","title":"Zotero","text":"<ul> <li>Better BibTex<ul> <li>Export library -&gt; Better CSL/JSON</li> <li>Check keep updated and background export</li> </ul> </li> <li>Plugin : Citations<ul> <li>Enter path of better CSL/JSON</li> </ul> </li> <li>(Cmd/Control + Shift + M)</li> </ul>","tags":["scientificresearch"]},{"location":"KB/Obsidian%20tutorial/#advanced-options-that-are-super-useful","title":"Advanced Options that Are Super Useful","text":"<ul> <li> <p>Quick Latex</p> </li> <li> \\[ma=\\frac{\\frac{3\\lambda}{4}+34\\epsilon}{10}\\] </li> <li> \\[\\begin{equation}a+b\\end{equation}\\] </li> <li> <p>Local Graph View (No shortcut : Cmd + Shift + G)</p> <ul> <li>Time stamper (Cmd + T)</li> </ul> </li> <li>Linting (Cmd + S)</li> <li>File Preview (hold Cmd/Control) Docker Cheatsheet</li> <li>Note Refactoring</li> <li>Export to PDF</li> </ul>","tags":["scientificresearch"]},{"location":"KB/Obsidian%20tutorial/#extra-resources-if-you-care","title":"Extra Resources if You Care","text":"<ul> <li>Obsidian plugins for research</li> <li>Obsidian daily notes</li> <li>Browser extensions that are useful</li> <li>pdfannots</li> </ul>","tags":["scientificresearch"]},{"location":"KB/Occipital%20lobe/","title":"Occipital lobe","text":""},{"location":"KB/Occipital%20lobe/#occipital-lobe","title":"Occipital Lobe","text":"<ul> <li>Interprets vision (color, light, movement)</li> </ul>"},{"location":"KB/Occlusion/","title":"Occlusion","text":""},{"location":"KB/Occlusion/#occlusion","title":"Occlusion","text":"<ul> <li>occurs if a target object is hidden (occluded) by other objects Self-occlusion</li> <li>from a certain viewpoint, one part of an object is occluded by another part.</li> </ul>"},{"location":"KB/Occult%20Blood%20Screen/","title":"Occult Blood Screen","text":""},{"location":"KB/Occult%20Blood%20Screen/#occult-blood-screen","title":"Occult Blood Screen","text":"<ul> <li>Use of a chemically treated card or pad to test for blood hidden in a stool sample</li> </ul>"},{"location":"KB/Odido/","title":"Odido","text":"","tags":["jobs"]},{"location":"KB/Odido/#subhaditya-mukherjee-odido-data-scientist-application","title":"Subhaditya Mukherjee : Odido - Data Scientist Application","text":"<p>Hello Pauline,</p> <p>It's nice to meet you!\u00a0</p> <p>My name is Subhaditya, I recently graduated with a masters in AI from the RUG (Groningen), and am looking for my next big challenge. I found the position a good fit for what I can offer and what I want to do next, and so this is my formal application for the Data Scientist position.</p> <p>Over the past few years, I have worked with many clients (both freelance/part-time and in internships) and helped them bring their AI projects to life. I have a mix of experience - from ML (scikit-learn, xgboost, pandas) to advanced Gen AI (LLMs, Diffusion models) to the stack of Python, Git, Docker etc. I have been working with AI for a long time now, and am quite familiar with the stack, something that I think would be a good fit in this position.</p> <p>My main background is in R&amp;D, and so the Intelligence and Insights division is where I think I see myself in the most. I love a good challenge, and getting to work on a product that will affect so many people is such a nice opportunity.</p>","tags":["jobs"]},{"location":"KB/Offline%20Distillation/","title":"Offline Distillation","text":""},{"location":"KB/Offline%20Distillation/#offline-distillation","title":"Offline Distillation","text":"<ul> <li>The first stage in offline distillation is usually not discussed as part of knowledge distillation, i.e., it is assumed that the teacher model is pre-defined. Little at- tention is paid to the teacher model structure and its re- lationship with the student model</li> <li>The main advantage of offline methods is that they are simple and easy to be implemented. For example, the teacher model may contain a set of mod- els trained using different software packages, possibly located on different machines. The knowledge can be extracted and stored in a cache.</li> <li>The offline distillation methods usually employ one- way knowledge transfer and two-phase training pro- cedure. However, the complex high-capacity teacher model with huge training time can not be avoided, while the training of the student model in offline distillation is usually efficient under the guidance of the teacher model.</li> <li>Moreover, the capacity gap between large teacher and small student always exists, and student often largely relies on teacher.</li> </ul>"},{"location":"KB/Ogliodendrocytes/","title":"Ogliodendrocytes","text":""},{"location":"KB/Ogliodendrocytes/#ogliodendrocytes","title":"Ogliodendrocytes","text":"<ul> <li>Wrap and insulate, forms Myelin sheath</li> </ul>"},{"location":"KB/Ohms%20Law/","title":"Ohms Law","text":""},{"location":"KB/Ohms%20Law/#ohms-law","title":"Ohms Law","text":"<p>- Potential difference = current x resistance \u00a0- \\(\\(V= IR\\)\\) \u00a0- Ohm's Law applied to the full circuit: Electromotive force = current x (sum of the circuit resistance and the internal resistance of the cell) \u00a0- \\(\\(EMF = I(R+r)\\)\\)</p>"},{"location":"KB/On%20the%20Distinction%20Between%20Perceived%20Duration%20and%20Event%20Timing%20-%20Towards%20a%20Unified%20Model%20of%20Time%20Perception/","title":"On the Distinction Between Perceived Duration and Event Timing - Towards a Unified Model of Time Perception","text":""},{"location":"KB/On%20the%20Distinction%20Between%20Perceived%20Duration%20and%20Event%20Timing%20-%20Towards%20a%20Unified%20Model%20of%20Time%20Perception/#on-the-distinction-between-perceived-duration-and-event-timing-towards-a-unified-model-of-time-perception","title":"On the Distinction Between Perceived Duration and Event Timing - Towards a Unified Model of Time Perception","text":"<ul> <li> <p>Darren Rhodes</p> </li> <li> <p>neural and computational bases for the processing of time remains unknown</p> </li> <li>he distinction between perceived event timing and perceived duration provides the current for navigating a river of contemporary approaches to time perception</li> <li>Recent work has advocated a Bayesian approach to time perception</li> <li>This framework has been applied to both duration and perceived timing, where prior expectations about when a stimulus might occur in the future (prior distribution) are combined with current sensory evidence (likelihood function) in order to generate the perception of temporal properties (posterior distribution)</li> <li>these models predict that the brain uses temporal expectations to bias perception in a way that stimuli are 'regularized' i.e. stimuli look more like what has been seen before</li> </ul>"},{"location":"KB/On%20the%20Distinction%20Between%20Perceived%20Duration%20and%20Event%20Timing%20-%20Towards%20a%20Unified%20Model%20of%20Time%20Perception/#from-perceived-duration-to-perceived-timing","title":"From Perceived Duration to Perceived Timing","text":"<ul> <li>The word 'perceived' here, is used in the loosest sense \u2014 the above methods cannot demonstrably show changes in low-level sensory processing of time (Rhodes)</li> </ul>"},{"location":"KB/On%20the%20Distinction%20Between%20Perceived%20Duration%20and%20Event%20Timing%20-%20Towards%20a%20Unified%20Model%20of%20Time%20Perception/#a-bayesian-model-of-perceived-event-timing","title":"A Bayesian Model of Perceived Event Timing","text":"<ul> <li>based on the dynamic updating of temporal expectations</li> <li>explain the asymmetries in the detection of irregularity and also in the perceived event timing of stimuli (Di Luca &amp; Rhodes)</li> <li>Within a single trial, perceived timing (the posterior distribution) is the result of combining the probability of sensing a stimulus (likelihood) with the time it was expected (prior)</li> <li>key tenet of the model is the relaxation of the assumption of normality in the probability distribution</li> <li>Probability distributions in the temporal domain are asserted to be necessarily asymmetric due to the way time flows</li> <li>The anisotropic nature of time means that evidence accumulated about stimulus timing for the likelihood function can only start after a short delay</li> <li>due to neural processing</li> <li>a stimulus cannot be sensed before a stimulus is presented</li> <li>always the chance it could be perceived a bit later than average due to noise in the sensory system</li> <li>As such, the perceived timing of stimuli in an environment where trials are isochronous should exhibit the temporal regularization effect</li> <li>early stimuli should be delayed towards expectation whilst late stimuli should be accelerated</li> <li>Stimuli presented on time, in contrast are perceptually accelerated</li> <li>stimuli that are presented in a random sequence of irregular timings, should not have any temporal expectations built up</li> <li>Therefore, they should not have any modulation of their perceived timing, suggesting that a prior is not built</li> <li>An implicit assumption of the model is that noisier measurements should lead to broader likelihood functions that are captured more by the prior probability distributions</li> <li>the Bayesian model of perceived timing can explain the delay of early stimuli as well as the acceleration of on time and later than expected stimuli</li> <li>Interval models do not make any explicit predictions about changes in the perceived timing of stimuli and as such cannot account for this data.</li> </ul>"},{"location":"KB/On%20the%20Importance%20of%20Visual%20Context%20for%20Data%20Augmentation%20in%20Scene%20Understanding/","title":"On the Importance of Visual Context for Data Augmentation in Scene Understanding","text":""},{"location":"KB/On%20the%20Importance%20of%20Visual%20Context%20for%20Data%20Augmentation%20in%20Scene%20Understanding/#on-the-importance-of-visual-context-for-data-augmentation-in-scene-understanding","title":"On the Importance of Visual Context for Data Augmentation in Scene Understanding","text":"<ul> <li>Nikita Dvornik, Julien Mairal, Senior Member, IEEE, and Cordelia Schmid, Fellow, IEEE</li> </ul>"},{"location":"KB/On%20the%20Importance%20of%20Visual%20Context%20for%20Data%20Augmentation%20in%20Scene%20Understanding/#abstract","title":"Abstract","text":"<ul> <li>simple image transformations can already improve predictive performance in most vision tasks, larger gains can be obtained by leveraging task-specific prior knowledge</li> <li>blending objects in existing scenes</li> <li>using instance segmentation annotations</li> <li>that randomly pasting objects on images hurts the performance, unless the object is placed in the right context.</li> <li>explicit context model by using a convolutional neural network</li> <li>predicts whether an image region is suitable for placing a given object or not. In our experiments</li> </ul>"},{"location":"KB/On%20the%20Importance%20of%20Visual%20Context%20for%20Data%20Augmentation%20in%20Scene%20Understanding/#introduction","title":"Introduction","text":"<ul> <li>scene understanding</li> <li>context model based on a convolutional neural network.</li> <li>The model estimates the likelihood of a particular object category to be present inside a box given its neighborhood, and then automatically finds suitable locations on images to place new objects and perform data augmentation.</li> </ul>"},{"location":"KB/On%20the%20Importance%20of%20Visual%20Context%20for%20Data%20Augmentation%20in%20Scene%20Understanding/#explicit-context-modeling-by-cnn","title":"Explicit Context Modeling by CNN","text":"<ul> <li>to guess the category of an object just by looking at its visual surroundings</li> <li>modeling by a convolutional neural network,</li> <li>Contextual data generation</li> <li>dataset that comes with bounding box</li> <li>object class annotations</li> <li>Each ground-truth bounding box in the dataset is able to generate positive \"contextual images\" that are used as input to the system</li> <li>One box is able to generate multiple different context images,</li> <li>To prevent distinguishing between positive and background images only by looking at the box shape and to force true visual context modeling, we estimate the shape distribution of positive boxes and sample the background ones from it</li> <li>we estimate the joint distribution of scale s and aspect ratio a with a two-dimensional histogram</li> <li>draw a pair (s, a) from this distribution in order to construct a background box</li> <li>Since in natural images there is more background boxes than the ones actually containing an object, we address the imbalance by sampling more background boxes,</li> </ul>"},{"location":"KB/On%20the%20Importance%20of%20Visual%20Context%20for%20Data%20Augmentation%20in%20Scene%20Understanding/#model-training","title":"Model training","text":"<ul> <li>The input to the network are the \"contextual images</li> <li>300 \u00d7 300</li> <li>output of the network is a label in {0, 1, ..., C}</li> <li>0-th class represents background and corresponds to a negative \"context image</li> <li>ResNet50</li> <li>change the last layer to be a softmax with C + 1 activations</li> </ul>"},{"location":"KB/On%20the%20Importance%20of%20Visual%20Context%20for%20Data%20Augmentation%20in%20Scene%20Understanding/#context-driven-data-augmentation","title":"Context-driven Data Augmentation","text":"<ul> <li>Selection of candidate locations for object placement</li> <li>Since the model takes into account not only the visual surroundings but a box's geometry too, we need to consider all possible boxes inside an image to maximize the recall</li> <li>However this is too costly and using 200 candidates was found to provide good enough bounding boxes among the top scoring ones.</li> <li>if an object of category c is present in an image it is a confident signal for the model to place another object of this class nearby.</li> <li>This often happens when only 200 candidate locations are sampled; however, evaluating more locations would introduce a computational overhead</li> <li>simple heuristic</li> <li>consists of drawing boxes in the neighborhood of this object</li> <li>and adding them to the final candidate set. The added boxes have the same geometry (up to slight</li> <li>distortions) as the neighboring object's box.</li> <li>Candidate scoring process</li> <li>softmax output.</li> <li>generating a contextual image is not deterministic, predictions on two contextual images corresponding to the same box may differ substantially,</li> <li>After the estimation stage we retain the boxes where an object category has score greater than 0.7</li> <li>Blending objects in their environment</li> <li>blend an object at the corresponding location</li> <li>different types of blending techniques (Gaussian or linear blur, simple copy-pasting with no postprocessing, or generating blur on the whole image to imitate motion), and randomly choose one of them in order to introduce a larger diversity of blending artefacts</li> <li>We also do not consider Poisson blending in our approach, which was considerably slowing down the data generation procedure</li> <li>for our task than in [5]. As a consequence, we do not need to exploit external data to perform data augmentation</li> </ul>"},{"location":"KB/On%20the%20Importance%20of%20Visual%20Context%20for%20Data%20Augmentation%20in%20Scene%20Understanding/#updating-image-annotation","title":"Updating image annotation.","text":"<ul> <li>Once a new object is placed in the scene, we generate a bounding box for object detection by drawing the tightest box around that object</li> <li>In case where an initial object is too occluded by the blended one, i.e. the IoU between their boxes is higher than 0.8, we delete the bounding box of the original object from the annotations</li> <li>If a new instance occludes more than 80% of an object already present in the scene, we discard annotations for all pixels belonging to the latter instance.</li> <li>To obtain semantic segmentation masks from instance segmentations, each instance pixel is labeled with the corresponding objects class.</li> </ul>"},{"location":"KB/On%20the%20Importance%20of%20Visual%20Context%20for%20Data%20Augmentation%20in%20Scene%20Understanding/#why-is-random-placement-not-working","title":"Why is Random Placement not Working?","text":"<ul> <li>as violation of context constraints imposed by the dataset</li> <li>objects looking \"out of the scene\" due to different illumination conditions</li> <li>simply artifacts introduced due to blending techniques</li> </ul>"},{"location":"KB/On%20the%20Importance%20of%20Visual%20Context%20for%20Data%20Augmentation%20in%20Scene%20Understanding/#impact-of-blending-when-the-context-is-right","title":"Impact of blending when the context is right","text":"<ul> <li>lack of visual context and the presence of blending artefacts may explain the performance drop</li> <li>presence of difference in illumination and blending artefacts is not critical for the object detection task</li> <li>Reducing the need for pixel-wise object annotation</li> <li>Our data augmentation technique requires instance-level segmentations, which are not always available in realistic scenarios</li> <li>relax the annotation requirements for our approach and show that it is possible to use the method when only bounding boxes are available</li> <li>Semantic segmentation + bounding box annotation</li> <li>Instance segmentation masks provide annotations to each pixel in an image and specify (i) an instance a pixel belongs to and (ii) class of that instance</li> <li>If these annotations are not available</li> <li>one may approximate them with semantic segmentation and bounding boxes annotation</li> <li>Semantic segmentation annotations are also pixel-wise, however they annotate each pixel only with the object category.</li> <li>Instance-specific information could be obtained from object bounding boxes, however this type of annotation is not pixel-wise and in some cases is not sufficient to assign each pixel to the correct instanc</li> <li>as long as a pixel in semantic map is covered by only one bounding box, it uniquely defines the object it belong</li> <li>otherwise, if more than one box covers the pixel, it is not clear which object it comes from</li> <li>When deriving approximate instance masks from semantic segmentation and bounding boxes (see Figure 9, column 2), we randomly order the boxes and assign pixels from a semantic map to the corresponding instances</li> <li>Whenever a pixel could be assigned to multiple boxes we choose a box that comes first in the orderin</li> </ul>"},{"location":"KB/On%20the%20Importance%20of%20Visual%20Context%20for%20Data%20Augmentation%20in%20Scene%20Understanding/#importance-of-context-modeling-quality-for-scene-understanding","title":"Importance of Context Modeling Quality for Scene Understanding","text":"<ul> <li>quality of a context model is mainly influenced by the amount of data it has received for training</li> <li>we increase the data size used for context modeling, we can see how both detection and segmentation improve; however, this gain diminishes as the data size keeps growin</li> <li>to improve scene understanding, the context model has to get visual context \"approximately right\" and further improvement is most likely limited by other factors such as unrealistic generated scenes and limited number of instances that are being copy-pasted</li> <li>On the other hand, if the context model is trained with little data, as in the case of using only 5% of the full set, our augmentation strategy tends to the random one and shows little improvement</li> </ul>"},{"location":"KB/On%20the%20Importance%20of%20Visual%20Context%20for%20Data%20Augmentation%20in%20Scene%20Understanding/#images","title":"Images","text":""},{"location":"KB/On%20the%20overlap%20between%20Grad-CAM%20saliency%20maps%20and%20explainable%20visual%20features%20in%20skin%20cancer%20images/","title":"On the overlap between Grad-CAM saliency maps and explainable visual features in skin cancer images","text":""},{"location":"KB/On%20the%20overlap%20between%20Grad-CAM%20saliency%20maps%20and%20explainable%20visual%20features%20in%20skin%20cancer%20images/#on-the-overlap-between-grad-cam-saliency-maps-and-explainable-visual-features-in-skin-cancer-images","title":"On the Overlap Between Grad-CAM Saliency Maps and Explainable Visual Features in Skin Cancer Images","text":"<ul> <li>@nunnariOverlapGradCAMSaliency2021</li> <li>Nunnari, Fabrizio, Md Abdul Kadir, and Daniel Sonntag. 2021. \u201cOn the Overlap Between Grad-CAM Saliency Maps and Explainable Visual Features in Skin Cancer Images.\u201d Pp. 241\u201353 in Machine Learning and Knowledge Extraction. Vol. 12844, Lecture Notes in Computer Science, edited by A. Holzinger, P. Kieseberg, A. M. Tjoa, and E. Weippl. Cham: Springer International Publishing.</li> </ul>"},{"location":"KB/On%20the%20overlap%20between%20Grad-CAM%20saliency%20maps%20and%20explainable%20visual%20features%20in%20skin%20cancer%20images/#intro","title":"Intro","text":"<ul> <li>Dermatologists recognize melanomas by inspecting images in which they identify human-comprehensible visual features.</li> <li>investigate to what extent such features correspond to the saliency areas identified on CNNs trained for classification</li> <li>Saliency maps are images that indicate the pixels areas contributing to a certain classification decision. Saliency maps are normally encoded as greyscale images or converted to heatmaps for visual inspection.</li> <li>to what extent saliency maps can be used to identify visual features of skin lesions</li> </ul>"},{"location":"KB/On%20the%20overlap%20between%20Grad-CAM%20saliency%20maps%20and%20explainable%20visual%20features%20in%20skin%20cancer%20images/#related-work","title":"Related Work","text":"<ul> <li>ISIC 2018</li> <li>RISE</li> <li>Jahanifar et al. also propose a modified DRFI (Discriminative Regional Feature Integration) technique for a similar task for multi-level segmentation task</li> <li>By combining multiple segmentation masks, they produce a more accurate mask.</li> <li>During the generation of the mask, they use a threshold value of 0.5, but they did not provide a reason for which they choose this value.</li> </ul>"},{"location":"KB/On%20the%20overlap%20between%20Grad-CAM%20saliency%20maps%20and%20explainable%20visual%20features%20in%20skin%20cancer%20images/#classification-architectures-and-models","title":"Classification Architectures and Models","text":"<ul> <li>RESNET50</li> <li>VGG16</li> </ul>"},{"location":"KB/On%20the%20overlap%20between%20Grad-CAM%20saliency%20maps%20and%20explainable%20visual%20features%20in%20skin%20cancer%20images/#data-preparation","title":"Data Preparation","text":"<ul> <li>As an additional feature, we compute the pixels-wise union of all the features</li> <li>In our experiments, we ignore the skin lesion samples with no features.</li> <li>The generation of the saliency maps consists of running the Grad-CAM algorithm on each skin lesion picture with non-black union mask</li> <li>We repeat the procedure for both the VGG16 and the RESNET50 models, generating the SV and SR greyscale picture sets</li> <li>To compare the saliency maps with ground truth maps, we scaled up SV and SR to the resolution of the original images using a nearest neighbour filter.</li> <li>We can observe that all distributions are strongly right skewed, and all \\(J_{s}\\) are mostly below 0.2, with the exception of a peak in performance for the pigment network clas</li> </ul>"},{"location":"KB/On%20the%20overlap%20between%20Grad-CAM%20saliency%20maps%20and%20explainable%20visual%20features%20in%20skin%20cancer%20images/#first-experiment","title":"First Experiment","text":"<ul> <li>With the first experiment we aim at identifying the threshold value that leads to a maximization of the overlap between saliency maps and ground truth</li> <li>To do so, we converted each saliency map into 11 binary maps using thresholds from 0.0 to 1.0 with steps of 0.1</li> <li>Then, we proceed by computing the Jaccard indices J between the ground truth and all of the processed saliencies S x V and S x R.</li> <li>For VGG16, among the features classes, the best threshold ranges between 0.4 and 0.7. The minimum J index is 0.0 on all categories, meaning that among all samples there is always at least one map with zero-overlap with the ground truth. The highest average (J=0.141) and maximum (J=0.797) belong to the pigmented network class.</li> <li>When switching to RESNET50, the best thresholds range between 0.3 and 0.7. With respect to VGG16, pigmented network and streaks present the worse performance, while the average J increases for the other three classes</li> <li>Surprisingly, the Jaccard indices measured with the RESNET50 maps, which have a resolution limited to 8x8 pixels, are comparable to the ones extracted from the VGG16 models (24x24 pixels)</li> <li>The second hypothesis is that the lower resolution of the RESNET50 maps is compensated by the higher accuracy of the classification model, i.e., a better overall overlap.</li> </ul>"},{"location":"KB/On%20the%20overlap%20between%20Grad-CAM%20saliency%20maps%20and%20explainable%20visual%20features%20in%20skin%20cancer%20images/#second-experiment","title":"Second Experiment","text":"<ul> <li>diving the samples into Melanoma and Nevus, and into correctly vs. wrongly classified samples.</li> <li>Here, the Jaccard indices are calculated using the union feature and using the best threshold identified in the first experiment, hence on S 0.5 R V and S 0.3</li> <li>For VGG16, we can observe that the mean J for correctly classified melanomas (0.135) is similar to the union class average (0.132).</li> <li>However, when melanomas are wrongly classified, the Jaccard index drops to 0.086, meaning that the saliency maps diverges from the ground truth</li> </ul>"},{"location":"KB/On%20the%20overlap%20between%20Grad-CAM%20saliency%20maps%20and%20explainable%20visual%20features%20in%20skin%20cancer%20images/#observation","title":"Observation","text":"<ul> <li>This could effectively help doctors is spotting a wrong classification</li> <li>The idea is that: if the classifier tells the doctor that the sample is a melanoma, but then the reported saliency areas diverge a lot from what would be manually marked, then doctors can be more easily induced to think that the system is misclassifying the image</li> </ul>"},{"location":"KB/On%20the%20overlap%20between%20Grad-CAM%20saliency%20maps%20and%20explainable%20visual%20features%20in%20skin%20cancer%20images/#discussion","title":"Discussion","text":"<ul> <li>Among the five features, only Pigment Network reaches the same level of accuracy of the union class.</li> <li>maximum J=0.136</li> <li>This is a huge annotation overhead when compared to labeling images with their diagnose class.</li> <li>The value of the threshold to reach the best J index varies among datasets and features. Since it is not possible to analytically foresee the best threshold of a given dataset, we suggest the development of interactive exploratory visual interfaces, where dermatologists can autonomously control the saliency threshold value in an interactive fashion for exploration.</li> <li>However, from a decomposition between classes and correctness of classification, it appears that, for higher resolution maps (24x24 pixels on VGG16), saliency maps overlap much better with ground truth features when the classifier is correctly classifying a melanoma (J=0.135) and performance drops when the prediction is incorrect (J=0.086).</li> <li>Further, we would like to investigate on better options for thresholding. In this paper, a global threshold, in the range of 0.0 to 1.0, was simultaneously searched and applied to all the saliency map.</li> <li>This allows for an \"emersion\" of the most relevant region of interests of a global scale</li> <li>However, there might be regions of saliency below the global threshold which are relevant with respect to the local surrounding area</li> <li>To spot local maxima, we could split the maps into tiles, or super-pixels, and iteratively identify multiple local threshold values based on the range of saliency values of each region.</li> <li>Finally, the current implementation of Grad-CAM returns saliency maps whose range is filled by stretching the range of activation values of the target convolution layer.</li> <li>Each saliency map is forced to use the full activation range, independent of other samples.</li> <li>In so doing, regions of interests are \"forced\" to emerge, even when the activation values of the inner layer are lower when compared to other images.</li> </ul>"},{"location":"KB/On%20the%20overlap%20between%20Grad-CAM%20saliency%20maps%20and%20explainable%20visual%20features%20in%20skin%20cancer%20images/#future-work","title":"Future Work","text":"<ul> <li>As future work, we could consider performing saliency normalization according to global statistics (mean and variance) on the tested set.</li> </ul>"},{"location":"KB/On%20the%20overlap%20between%20Grad-CAM%20saliency%20maps%20and%20explainable%20visual%20features%20in%20skin%20cancer%20images/#images","title":"Images","text":""},{"location":"KB/One%20cycle%20policy/","title":"One cycle policy","text":""},{"location":"KB/One%20cycle%20policy/#one-cycle-policy","title":"One Cycle Policy","text":"<ul> <li>@smithSuperConvergenceVeryFast2018</li> </ul>"},{"location":"KB/One%20cycle%20policy/#step","title":"Step","text":"<ul> <li>recommends to do a cycle with two steps of equal lengths, one going from a lower learning rate to a higher one than go back to the minimumThe maximum should be the value picked with the Learning Rate Finder, and the lower one can be ten times lower</li> <li>Then, the length of this cycle should be slightly less than the total number of epochs, and, in the last part of training, we should allow the learning rate to decrease more than the minimum, by several orders of magnitude.</li> <li>The idea of starting slower isn't new: using a lower value to warm-up the training is ofen done, and this is exactly what the first part is achieving</li> <li>Leslie doesn't recommend to switch to a higher value directly, however, but to rather slowly go there linearly, and to take as much time going up as going down.</li> <li>the during the middle of the cycle, the high learning rates will act as regularization method, and keep the network from overfitting</li> <li>They will prevent the model to land in a steep area of the loss function, preferring to find a minimum that is flatteapproximates of the hessian were lower, indicating that the SGD was finding a wider flat area</li> <li>Then the last part of the training, with descending learning rates up until annihilation will allow us to go inside a steeper local minimum inside that smoother part</li> <li>Surprisingly, applying this policy even allows us to pick larger maximum learning rates, closer to the minimum of the plot we draw when using the learning rate finder</li> <li>Those trainings are a bit more dangerous in the sense that the loss can go too far away and make the whole thing diverge In those cases, it can be worth to try with a longer cycle before going to a slower learning rate, since a long warm-up seems to help</li> <li></li> </ul>"},{"location":"KB/One%20cycle%20policy/#cyclical-momentum","title":"Cyclical Momentum","text":"<ul> <li>To accompany the movement toward larger learning rates, Leslie found in his experiments that decreasing the momentum led to better results</li> <li>This supports the intuition that in that part of the training, we want the SGD to quickly go in new directions to find a flatter area, so the new gradients need to be given more weight</li> <li>According to Leslie, the exact best value of momentum chosen during the whole training can give us the same final results, but using cyclical momentums removes the hassle of trying multiple values and running several full cycles, losing precious time.</li> <li>In his opinion, the batch size should be set to the highest possible value to fit in the available memory. Then the other hyper-parameters we may have (dropout for instance) can be tuned the same way as weight decay, or just by trying on a cycle and see the results they give</li> <li>Training with the 1cycle policy at high learning rates is a method of regularization in itself, so we shouldn't be surprised if we have to reduce the other forms of regularization we were previously using when we put it in place</li> <li></li> </ul>"},{"location":"KB/One%20hot/","title":"One Hot Encoding","text":""},{"location":"KB/One%20hot/#one-hot-encoding","title":"One Hot Encoding","text":"<ul> <li>Given \\(A = {a_{1}, \u2026 , a_{k}}\\)</li> <li>Turn each \\(a_{v}\\) into k dim binary vector \\(v_{v} \\in {0,1}^{k}\\) which is 0 everywhere execpt at position v</li> <li>Symbolic input</li> <li>k dim one hot vector</li> <li></li> </ul>"},{"location":"KB/Opacity%20Correction/","title":"Opacity Correction","text":""},{"location":"KB/Opacity%20Correction/#opacity-correction","title":"Opacity Correction","text":"<ul> <li>Opacity component \\(o\\) in transfer function stored with respect to a standard step size \\(\\Delta t\\)</li> <li>Different step sizes \\(\\Delta t^{\\ast}\\)</li> <li>Dynamic step sizes</li> <li>generate pre-integrated function</li> <li> \\[o^{\\ast} = 1- (1-o)^{\\frac{\\Delta t^{\\ast}}{\\Delta t}}\\] </li> <li>evaluate after obtaining \\(o\\) from transfer function</li> <li>apply before compositing`</li> </ul>"},{"location":"KB/OpenML%20%3C%3E%20scikit-learn%20hackathon/","title":"OpenML <> scikit-learn hackathon","text":"","tags":["deeplearning"]},{"location":"KB/OpenML%20%3C%3E%20scikit-learn%20hackathon/#openml-scikit-learn-hackathon","title":"OpenML &lt;&gt; Scikit-learn Hackathon","text":"","tags":["deeplearning"]},{"location":"KB/OpenML%20%3C%3E%20scikit-learn%20hackathon/#logistics","title":"Logistics","text":"","tags":["deeplearning"]},{"location":"KB/OpenML%20%3C%3E%20scikit-learn%20hackathon/#location","title":"Location","text":"<p>27th Floor, ring at \u201cProbabl\u201d</p> <p>Montparnasse Tower\u00a033 Avenue du Maine, West Entrance (on your left when leaving the train station), 27th Floor, ring at \u201cProbabl\u201d</p> <p></p>","tags":["deeplearning"]},{"location":"KB/OpenML%20%3C%3E%20scikit-learn%20hackathon/#contact-persons","title":"Contact Persons","text":"<p>+33783822597 (Fran\u00e7ois Goupil)</p> <p>+33760407677 (Charl\u00e8ne Bizollon)</p>","tags":["deeplearning"]},{"location":"KB/OpenML%20%3C%3E%20scikit-learn%20hackathon/#communication-channel","title":"Communication Channel","text":"<p>Please join the OpenML slack server and the dedicated hackathon channel for easy communication and updates.</p> <p>Slack:\u00a0https://join.slack.com/t/openml/shared_invite/zt-2ktk2cj1c-r637o20pfCc0H7PS8OUGtA</p> <p>Channel: #hackathon-probabl</p>","tags":["deeplearning"]},{"location":"KB/OpenML%20%3C%3E%20scikit-learn%20hackathon/#wifi","title":"Wifi","text":"<p>SSD: :probabl.guest</p> <p>PWD: :probabl.</p> <p>Note: At some point be ready to use your own mobile data (we are experiencing some difficulties)</p> <p>SSD: :probabl.eiffel-2.4</p> <p>PWD: :probabl.</p> <p>Note: low bandwidth</p>","tags":["deeplearning"]},{"location":"KB/OpenML%20%3C%3E%20scikit-learn%20hackathon/#schedule","title":"Schedule","text":"","tags":["deeplearning"]},{"location":"KB/OpenML%20%3C%3E%20scikit-learn%20hackathon/#june-24-0900-1800","title":"June 24 - 09:00-18:00","text":"09:00-09:30 Welcome Coffee and Croissants 09:30-11:30 Introduction - Short presentation of the scikit-learn and OpenML projects + Probabl (Joaquin and Pieter for OpenML, Guillaume Lemaitre for scikit-learn, Yann Lechelle for Probabl)- Quick round where everyone introduces themselves.- Plan break-out sessions or suggest new ones. 10:30-11:30 Breakout (1) Organizing community events and Onboarding Contributors (Maren) 11:30-13:00 Lunch Bouillon Chartier 13:00-14:00 Breakout (2) Governance, Funding and Sponsorship (Adrin + Fran\u00e7ois) 14:00-15:00 Breakout (3) Future Collaboration between scikit-learn and OpenML (Guillaume) 15:00-18:00 Code Code: explore each other\u2019s projects. <p>After the official programme each day, there\u2019s a suggested bar and restaurant to go to</p> <p>Bar + Restaurant: Le Falstaff </p>","tags":["deeplearning"]},{"location":"KB/OpenML%20%3C%3E%20scikit-learn%20hackathon/#june-25-0900-1800","title":"June 25 - 09:00-18:00","text":"09:00-10:00 Coffee/croissants Croissant Talk by Joaquin 10:00-11:00 Breakout (6) Collaboration Ecosystem for Open-Source Machine Learning 11:00-12:00 Breakout (7) Academic and Industrial Scope of OpenML and Probabl\u00a0in AI - Collaboration 12:00-13:00 Lunch TranTranZai 13:00-14:00 Breakout (5) Probabl Product Technical Discussion (Camille) 14:00-17:00 Coding Coding 17:00-18:00 Breakout (4) Development Tooling and Workflows <p>Bar + Restaurant: Food Society Paris</p>","tags":["deeplearning"]},{"location":"KB/OpenML%20%3C%3E%20scikit-learn%20hackathon/#june-26-0900-1300","title":"June 26 - 09:00-13:00","text":"9:00-10:00 Breakout + coffee/croissants Joaquin et al.: we have a bit of a delay checking out of our Airbnb but will be there shortly. 10:00-12:00 TBD Open / Ad-hoc 12:00-13:00 Wrap-up 13:00-14:00 Lunch + end of the hackathon Subway in Montparnasse","tags":["deeplearning"]},{"location":"KB/OpenML%20%3C%3E%20scikit-learn%20hackathon/#breakout-sessions-ideas","title":"Breakout Sessions Ideas","text":"<p>This document contains the preliminary agenda and suggestion for breakout sessions. Breakout sessions are discussions where we can brainstorm or exchange our experiences on specific topics. Feel free to propose additional sessions.</p> <p>\ud83d\udca1 Feel free to add new session topics below, there is a template at the end.</p>","tags":["deeplearning"]},{"location":"KB/OpenML%20%3C%3E%20scikit-learn%20hackathon/#1-organizing-community-events-and-onboarding-contributors-day-1","title":"1. Organizing Community Events and Onboarding Contributors [Day 1]","text":"<p>leader:\u00a0Maren Westermann</p> <p>description:</p> <ul> <li>Share our experiences organizing hackathons. How do you attract attendees? How do you make sure that the work at a hackathon is fruitful? Where should you organize your hackathons, and how are they funded? Are online open-source sprints/hackathons an option for you?</li> <li>What process and documentation should be in place to help onboard new contributors? How to get them started effectively, and how do you make sure they stay with the project?</li> <li>How do we get our projects known to users?</li> </ul> <p></p> <p>notes:</p> <ul> <li>community sprints: everyone is invited to take part, in particular newcomers, to \u00a0contribute to an open source project</li> <li> <p>Important (FYI: we are a bit out of sync)</p> </li> <li> <p>Have a list of curated issues</p> </li> <li>Start with documentation issues for new contributors</li> <li> <p>Come up with issues before the sprint need a curated list for first time contributors (especially beginner friendly ones)</p> </li> <li> <p>meta-issues for a group of related issues: once one is fixed it can serve as a contribution template</p> </li> <li> <p>documentation issues: people start by reading the documentation around the issues</p> </li> <li>documentation about how to contribute was missing and is too long</li> <li>rewrote the contributors\u2019 guide to be more concise but more beginner friendly + some video tutorials to get started with github-based contributions</li> <li>keeping beginner issues away for the sprints (so other people don\u2019t jump on it before)</li> <li> <p>difference between OpenML Hackathon and Scikit-learn sprints</p> </li> <li> <p>OpenML Hackathons are 1 week and bigger</p> </li> <li>Core developer sprints vs. New contributors sprints</li> <li>Openml has 7 repositories with different programming languages (backend, APIs, frontend,...)</li> <li>Some documentation for first time contributors but not exhaustive</li> <li>One-to-one mentoring to get started with a working dev setup</li> <li> <p>Typically requires several days\u2019 investment</p> </li> <li> <p>onboarding new contributors online and in person are two different processes</p> </li> <li> <p>Hard to make people feel connected and stay long-term</p> </li> <li> <p>Social aspect is important: organizing recurrent events (every few months) to development a more long term engagement</p> </li> <li> <p>Joint Pyladies Paris / scikit-learn core contributors events</p> </li> <li> <p>near one-to-one mentoring</p> </li> <li>recurrent every few months</li> <li>a few hours in the evening</li> <li> <p>retention is low but allowed to developed social bounds</p> </li> <li> <p>Important to have maintainers be present to slowly build a connection.</p> </li> <li>Retention is low, be realistic on expectations - but the outliers are what matters</li> <li> <p>Personal connection: if they know you, people are more likely to contribute</p> </li> <li> <p>OpenML hackathons are useful for core maintainers to secure some time to contribute to the project for several solid hours in a row.</p> </li> <li> <p>0 full-time contributor.</p> </li> <li>part time engineers for academic projects</li> <li> <p>nice locations because thanks to EU funding</p> </li> <li> <p>Can OpenML use students to help contribute feature</p> </li> <li> <p>Hard to get high-quality submissions</p> </li> <li> <p>How to incentivize people?</p> </li> <li> <p>Build career: show of with sklearn contribution on a resume (less long-term contribution)</p> </li> <li>Sense of community</li> <li>Useful for your own research</li> <li> <p>Hard to have \u2018flashy results\u2019 (e.g. genAI apps), how can we solve that?</p> </li> <li> <p>How to scale time investment?</p> </li> <li> <p>PyLadies / sprints: only few hours in the evening (6-9pm)</p> </li> <li>Every 2 months, 15-30 (capped) people show up</li> <li> <p>How are sprints structured?</p> </li> <li> <p>Pre-sprint: online, so people have the right setup</p> </li> <li>At least one organizer (e.g. Maren for pyladies, supported by core devs)</li> <li> <p>Shortlist of issues for each sprint</p> </li> <li> <p>Paid internships: great way to find good people and build</p> </li> <li> <p>Requires funding</p> </li> <li> <p>Mentoring takes time, but helps people take over some tasks</p> </li> <li>Slack discussions</li> <li> <p>Generative AI? Bad quality, wastes time. SKlearn only allows human contributions.</p> </li> <li> <p>How to focus attention? E.g. key project this quarter?</p> </li> </ul> <p></p>","tags":["deeplearning"]},{"location":"KB/OpenML%20%3C%3E%20scikit-learn%20hackathon/#2-governance-funding-and-sponsorship","title":"2. Governance, Funding and Sponsorship","text":"<p>leader:\u00a0Adrin + Fran\u00e7ois</p> <p>description: What are our experiences with our governance structures?\u00a0What are opportunities for open source projects to make money to pay for e.g., server costs, organizing events, and so on? How do we argue the importance of our projects to motivate a funder/sponsor? Can we quantify our contribution?</p> <p>notes:</p> <ul> <li>Governance is a living document. It matters for the community.</li> <li> <p>How to combine an open-source library with a for-profit company</p> </li> <li> <p>Be clear about what parts are community-\u201downed\u201d and which parts are company-owned</p> </li> <li> <p>Keep discussions of the community aspect on community Slack. Decision processes must remain open.</p> </li> <li> <p>write public version of important decisions</p> </li> <li> <p>Still creates confusion (for users and contributors)</p> </li> <li>Keep people informed either through mailing lists, monthly meetings etc. (This takes a long time, but is worth it in the long run)</li> <li>communicate upcoming discussions in mailing list</li> <li>contributing to sklearn open doors to work at companies</li> <li> <p>INRIA foundation:</p> </li> <li> <p>50k EUR for 2 meetings yearly where company can state priorities</p> </li> <li>No requirement, only if useful for community</li> <li>Is it sustainable? For academic salaries. As long as sklearn stays useful companies will keep doing this. Requires that someone at the sponsoring company cares that sklearn doesn\u2019t decline.</li> <li>Also advertising (logo on website)</li> <li> <p>Modelled on Linux foundation.</p> </li> <li> <p>Probabl:</p> </li> <li> <p>Will put a RE to work on a certain issue, but for a lot more money</p> </li> <li> <p>Companies prefer this (they don\u2019t know how to hire a good sklearn engineer)</p> </li> <li> <p>Leadership by effort:</p> </li> <li> <p>Put your own time into the aspects that are important to you</p> </li> <li> <p>NVIDIA: Have people work at other companies to work on sklearn</p> </li> <li> <p>How much effort?</p> </li> <li> <p>For projects that need faster cycles, create a separate package (e.g. skops, hazardous,...) - but this creates maintenance work.</p> </li> <li>Hard to get new reviews in since it takes so long. Multiple rounds of reviews even for a simple spelling error.</li> <li>Library for putting sklearn models into prod -&gt; skops</li> <li> <p>Having documentation lead, community interaction lead,... does it help and how much?</p> </li> <li> <p>Lowers the bar (core dev is a really high bar)</p> </li> <li>Speeds up decisions</li> <li>Need more people in the different teams</li> </ul> <p></p>","tags":["deeplearning"]},{"location":"KB/OpenML%20%3C%3E%20scikit-learn%20hackathon/#3-future-collaboration-between-scikit-learn-and-openml-day-1-2-sessions","title":"3. Future Collaboration between Scikit-learn and OpenML [Day 1, 2 sessions]","text":"<p>leader:\u00a0Guillaume Lemaitre</p> <p>description: scikit-learn can fetch datasets from OpenML, users can automatically evaluate scikit-learn models on OpenML tasks. What other future collaborations are interesting to explore?</p> <ul> <li> <p>fetch_openml / download_openml improvements (parquet?)</p> </li> <li> <p>dataset upload via parquet -&gt; coming (not fully supported by python API yet)</p> </li> <li>croissant integration in scikit-learn openml data fetcher? -&gt; Tuesday morning</li> <li>provenance tracking and reproducibility for openml dataset (make it standard to provide a script, possibly hosted externally on GitHub or similar, to show how to reconstruct the openml hosted parquet file from the original dataset format/location.</li> <li>collaborative feedback (per dataset issue tracker) to report and discuss dataset related problems with dataset owner/uploader</li> <li>If fetch-openml fails, what to do?</li> <li>add support for benchmarking? : benchopt</li> </ul> <p>notes:</p> <ul> <li> <p>Fetch_openml</p> </li> <li> <p>ARFF parser is a headache</p> </li> <li>Logically, it makes sense to first download the data file localy and then load it with pandas or polars (pandas in rust)</li> <li>sklearn does not load parquet right now</li> <li> <p>Sparse datasets are still an issue (not supported by parquet)</p> </li> <li> <p>Make all sparse dataset dense and store them in parquet (will still compress nicely). Most sparse datasets aren\u2019t that large.</p> </li> <li> <p>Some of these datasets may be one-hot-encoded datasets</p> </li> <li> <p>Pyarrow is most supported (fastparquet is not). Polars can read parquet natively. Pyarrow does not support pyodide.</p> </li> <li> <p>Have an explanation for differences between versions</p> </li> <li> <p>Versions discussion</p> </li> <li> <p>Versions of dataset on openml very confusing</p> </li> <li>Version not related lineage of dataset, very confusing to user</li> <li>Versions of datasets not searchable</li> <li> <p>Use case: go on openml, search for a dataset, \u201cwhich version of the dataset to select?\u201d</p> </li> <li> <p>Benchmarking</p> </li> <li> <p>interesting for probabl.ai to share models and benchmarks on OpenML?</p> </li> <li> <p>Sklearn Pipeline Representation</p> </li> <li> <p>Use HTML widget for sklearn pipeline diagrams</p> </li> </ul> <p>todo:</p> <ul> <li>openml: check whether all parquet file can be read with polars and pandas</li> <li>openml: convert all sparse datasets to dense to store then in parquet</li> <li>openml: have an explanation for differences between versions. When people upload a new version of a dataset, ask for an explanation.</li> <li>openml: sort dataset by the quality of the datasheet. Show user/datasetname/id as the name on the webui, remove/rename \u201cversion\u201d</li> <li>openml website: implement a way to open an issue to contact the dataset owner</li> <li> <p>openml: datasheet has section on preprocessing, where people can point to a github link with preprocessing code, encourage users to do this (e.g. dataset quality score) and allow people to report problems</p> </li> <li> <p>sklearn: try to load parquet files from OpenML in fetch_openml</p> </li> <li>openml: visualization of the sklearn pipelines (flow)</li> </ul>","tags":["deeplearning"]},{"location":"KB/OpenML%20%3C%3E%20scikit-learn%20hackathon/#35-croissant-talk","title":"3.5 Croissant Talk","text":"<p>notes:</p> <ul> <li> <p>Github</p> </li> <li> <p>Croissant is a metadata description format</p> </li> <li>Ml datasets are a combination of structured and unstructured data, which make them complicated to manage</li> <li>Croissant was built on top of schema.org, and has more details relative to it</li> <li> <p>The format has 4 layers</p> </li> <li> <p>dataset level metadata</p> </li> <li>resource description</li> <li>content structure</li> <li> <p>ml semantics</p> </li> <li> <p>Croissant does not require any changes to underlying data</p> </li> <li>Analysis and visualization tools work out of the box for all datasets</li> <li>Using croissant, datasets can be exposed consistently throughout platforms</li> <li>Collaborations with google, hugging face, google dataset search also exist</li> <li>Openml has deeper dataset description by default, slightly lesser in HF and kaggle</li> <li>Once loaded, datasets can be imported elsewhere (torch, tf etc) easily</li> <li>Croissant editor - web app where you can use a GUI to enter the dataset descriptions</li> <li>NeurIPS also now recommends using the Croissant format</li> <li>Supports the Core RAI vocab for explainable AI</li> <li>If images/other files - points to the path</li> </ul> <p>todo:</p> <ul> <li>integer precision and more detailed dtypes</li> <li>How are uploaded files linked to each other?</li> <li>Lineage of datasets</li> </ul> <p></p>","tags":["deeplearning"]},{"location":"KB/OpenML%20%3C%3E%20scikit-learn%20hackathon/#4-development-tooling-and-workflows","title":"4. Development Tooling and Workflows","text":"<p>leader:\u00a0Pieter</p> <p>description: Automation is important to create more sustainable workloads and generally improves overall project quality. What tooling and workflows are employed in your projects to run tests, ensure code quality, help contributors, and so on? Which do you find most useful? Are there decisions have you come to regret? What are your major pain points? What are our responsibilities as open source projects, should we be embracing platforms such as e.g., CodeBerg/Forgejo more?</p> <p>Notes:</p> <ul> <li>Switch to open-source tools like CodeBerg once if offers more conveniences</li> <li>There is a GitHub maintainer org that you can apply to (if you are maintainer of an important enough package) that can give you more direct access to GH dev/projects.</li> <li>Use of Azure workflows in scikit-learn is largely historical, but also provides a spread over different (free) usage limits</li> <li>GPU actions with a limited budget</li> <li> <p>GitHub actions workflow problems</p> </li> <li> <p>testing is a pain and not really supported (easier on Azure)</p> </li> <li> <p>badish documentation but better than Azure</p> </li> <li> <p>run documentation examples that are linked to changes in PR diff - use Circle CI because it can easily render the generated HTML in the browser (as opposed to GH where you download the artifact)</p> </li> <li>bot for linter errors to post it as comment helped a lot</li> <li>aiming for 100% code coverage, including all validation though that is centralized. Disable coverage for certainly not tested parts of the code. Also test errors and types and warnings.</li> </ul>","tags":["deeplearning"]},{"location":"KB/OpenML%20%3C%3E%20scikit-learn%20hackathon/#5-probabl-product-technical-discussion","title":"5. Probabl Product Technical Discussion","text":"<p>leader:\u00a0 Camille Troillard</p> <p>description: Presentation/discussion of the Probabl technical product and potential collaboration.</p> <ul> <li>What to do to put sklearn in production, to make it commercially viable</li> <li> <p>Help data scientists do better ML</p> </li> <li> <p>Better understand their model\u2019s behavior</p> </li> <li> <p>Build something that we\u2019re proud of (and we\u2019re picky)</p> </li> <li> <p>Let people do what they do (don\u2019t interfere), but show interesting things along the way</p> </li> <li>You should not require a platform, but it should be very easy to switch to a platform</li> <li>Educate people. E.g. you\u2019re changing the metric but this metric doesn\u2019t make sense.</li> <li> <p>Interactive dashboard that shows results of your experiment</p> </li> <li> <p>code and outputs side by side</p> </li> <li> <p>Like Weights and Biases, but runs locally</p> </li> <li> <p>Outputs data in a portable DB, results are registered and predictions are shown when they are available</p> </li> <li> <p>unified API to the whole infrastructure stack (like MetaFlow)</p> </li> <li> <p>Button to \u2018push to production\u2019 or \u2018push to OpenML\u2019 depending on the user</p> </li> <li>\u201cWe\u2019ve been spoonfed microservices in order to become addicted to CSPs\u201d</li> </ul> <p>Feedback for OpenML</p> <ul> <li>Have a clear tagline, e.g. \u2018Frictionless ML resources\u2019</li> <li>Better search interface</li> <li>Nice visualizations for the run page</li> <li>Fast website</li> </ul> <p></p>","tags":["deeplearning"]},{"location":"KB/OpenML%20%3C%3E%20scikit-learn%20hackathon/#6-collaboration-ecosystem-for-open-source-machine-learning","title":"6. Collaboration Ecosystem for Open-Source Machine Learning","text":"<p>leader:\u00a0Lennart Purucker</p> <p>description: What other open-source frameworks are struggling with the same questions we are struggling with? Should we reach out to them? Is there a need for a collaboration ecosystem in open-source machine learning/AI? What are lessons learned from which others might benefit? What are lessons learned from others from which we might benefit?</p> <p>notes:</p> <ul> <li> <p>Struggles for Open Source</p> </li> <li> <p>Copying and learning from scikit-learn projects</p> </li> <li> <p>Bots, CI/CD, CI logic</p> </li> <li> <p>see https://scientific-python.org/, https://scipy.org/ </p> </li> <li> <p>https://learn.scientific-python.org/development/ </p> </li> <li> <p>helps with CI/CD setup and provide more documentation on how to setup a open source project</p> </li> <li> <p>Main issue is human traffic for open-source</p> </li> <li> <p>opening issues, PRs, \u2026</p> </li> <li> <p>What other open-source frameworks are struggling with the same questions we are struggling with?</p> </li> <li> <p>https://learn.scientific-python.org/contributors/setup/ecosystem/ </p> </li> <li> <p>ML Backbone</p> </li> <li> <p>Scikit-learn, PyTorch, TensorFlow, MLR, MLJ</p> </li> <li> <p>XGBoost, LightGBM, CatBoost</p> </li> <li> <p>OpenML, Pandas, NumPy, SciPy, Polars</p> </li> <li> <p>Python Backbone</p> </li> <li> <p>Pip / PyPi, Conda, vu</p> </li> <li> <p>Ray, Joblib</p> </li> <li> <p>ML Applications / AutoML / \u2026</p> </li> <li> <p>AMTLK, Auto-Sklearn, FLAML, AutoGluon, H2O \u2026</p> </li> <li> <p>Should we reach out to them?</p> </li> <li> <p>Company-driven open-source vs. community-driven open-source</p> </li> <li> <p>company-driven example</p> </li> <li> <p>tensorflow, (PyTorch)</p> </li> <li> <p>Internal CI vs. open-source CI</p> </li> <li> <p>community-driven</p> </li> <li> <p>scikit-learn</p> </li> <li> <p>Via GitHub</p> </li> <li> <p>Is there a need for a collaboration ecosystem in open-source machine learning/AI?</p> </li> <li> <p>Only if we have problems, otherwise unnecessary overhead.</p> </li> <li> <p>Are they my dependencies or am I there dependencies?</p> </li> <li> <p>What are lessons learned from which others might benefit? / What are lessons learned from others from which we might benefit?</p> </li> <li> <p>mostly the governance documents</p> </li> <li>document CI</li> <li>see https://scientific-python.org/ </li> <li>only start testing / maintaining other environments one request / when issues arise</li> <li>https://scikit-learn.org/stable/developers/minimal_reproducer.html </li> </ul> <p></p>","tags":["deeplearning"]},{"location":"KB/OpenML%20%3C%3E%20scikit-learn%20hackathon/#7-academic-and-industrial-scope-of-openml-and-probabl-in-ai","title":"7. Academic and Industrial Scope of OpenML and Probabl in AI","text":"<p>leader:\u00a0Lennart Purucker</p> <p>who else is joining?\u00a0Yann Lechelle</p> <p>description: Where do we see ourselves in the general field of AI/ML? Are we only tabular data? Are we connected to GenAI, Computer Vision, and NLP? How is our connection to industry applications? How do we effectively explain our position to stakeholders (who read too much about GenAI)?</p> <ul> <li> <p>Input Modalities</p> </li> <li> <p>Tabular (OpenML, Scikit-learn)</p> </li> <li>Time Series</li> <li>Vision (OpenML Soon)</li> <li>NLP</li> <li>Graphs</li> <li> <p>(Other)</p> </li> <li> <p>Output Modalities / Task</p> </li> <li> <p>Scalar Regression\u00a0(OpenML, Scikit-learn)</p> </li> <li>Quantile Regression (OpenML, Scikit-learn)</li> <li>Multiclass Classification (OpenML, Scikit-learn)</li> <li>No-target / Unsupervised / Data Insights \u00a0(OpenML, Scikit-learn)</li> <li>Survival Analysis (Scikit-learn)</li> <li>Forecasting</li> <li>Anomaly Classification</li> <li>Anomaly Detection (OpenML, Scikit-learn)</li> <li> <p>Generative AI: Structured Predictions</p> </li> <li> <p>ML Techniques in AI/ML</p> </li> <li> <p>Traditional ML Algorithms (SVM, RF, Boosting) (OpenML, Scikit-learn)</p> </li> <li>Traditional Deep Learning (OpenML)</li> <li> <p>Large Foundation Models</p> </li> <li> <p>What do Stakeholders Understand?</p> </li> <li> <p>Time Series</p> </li> <li> <p>GenAI</p> </li> <li> <p>Notes:</p> </li> <li> <p>scikit-learn limitation is the API definition</p> </li> <li> <p>probabl: \u201cown your data science\u201d</p> </li> <li> <p>border scope, may include other things besides scikit-learn</p> </li> <li>also deep learning and large foundation models</li> <li> <p>scope is wide around open-source technology</p> </li> <li> <p>can we connect OpenML to probabl scope</p> </li> <li>\u201cexporting\u201d the API?</li> <li>LLMs \u201cdo\u201d UX for ML</li> </ul>","tags":["deeplearning"]},{"location":"KB/OpenML%20%3C%3E%20scikit-learn%20hackathon/#_1","title":"OpenML <> scikit-learn hackathon","text":"<p>Aggregated To-Dos</p> <p>Openml</p> <ul> <li>check whether all parquet file can be read with polars and pandas</li> <li>convert all sparse datasets to dense to store then in parquet</li> <li>have an explanation for differences between versions. When people upload a new version of a dataset, ask for an explanation.</li> <li>sort dataset by the quality of the datasheet. Show user/datasetname/id as the name on the webui, remove/rename \u201cversion\u201d</li> <li>website: implement a way to open an issue to contact the dataset owner</li> <li>datasheet has section on preprocessing, where people can point to a github link with preprocessing code, encourage users to do this (e.g. dataset quality score) and allow people to report problems</li> <li>visualization of the sklearn pipelines (flow)</li> <li>data quality plots</li> <li>Does the UX of OpenML need work</li> </ul> <p>probabl</p> <ul> <li>try to load parquet files from OpenML in fetch_openml</li> </ul> <p>croissant</p> <ul> <li>integer precision and more detailed dtypes</li> <li>How are uploaded files linked to each other</li> </ul>","tags":["deeplearning"]},{"location":"KB/OpenML%20Software%20Engineer/","title":"OpenML Software Engineer","text":"","tags":["jobs"]},{"location":"KB/OpenML%20Software%20Engineer/#software-engineer-deep-learning-application","title":"Software Engineer - Deep Learning Application","text":"<p>Hello Joaquin,  </p> <p>My name is Subhaditya, it is nice to meet you :)</p> <p>I recently graduated with a masters in AI from the RUG (Groningen), and am now looking for a job in the Netherlands. I remember seeing the OpenML Github repo a while back and thinking it would be really cool to work with AI researchers with a love for open source. But I had just started my masters then, and somehow did not end up reaching out. So when I found this position while looking through Academic Transfer, I absolutely had to apply. I have been working with software engineering and AI for a few years now and I am very aware of the need for accurate benchmarks and sharing models efficiently. With so many people suddenly giving in to the AI hype, crafting tools that cater to the real problems of researchers trying to build AI, something like OpenML, is even more relevant now. Given that, I would love to bring my experience to this position, while also hopefully learning a lot from your team there too.</p> <p>Over the past few years, I have worked with many clients (both freelance/part-time and in internships) and helped them bring their AI and data projects to life. My experience includes working with large datasets, building ML/DL models and pipelines and also sharing my knowledge with my peers in technical and non technical fields. I am quite good at using PyTorch / TensorFlow / Keras and have some experience with Flux.jl and Max as well. I am also familiar with the Hugging Face API / PyTorch lightning and the ONNX format. More than anything though, I am a programmer at heart. I have been an avid believer in open source ever since I started using linux almost seven years ago, and although I have a lot to learn, I do think that I am a good fit for this position. (Here is my Github - http://github.com/subhadityamukherjee)</p> <p>This letter is getting a little long, but I did want to add that I would love to contribute to OpenML and bring about positive changes in the AI community going forward. So many people with not much AI experience are starting to enter this field, and perhaps we could help make their experience a lot smoother, while also promoting more open source research. I have no means of knowing how experienced the other candidates are, but I do hope you give me a shot!</p> <p>PS. I still have my Zoekjaar visa till September, so I can start ASAP as well.</p>","tags":["jobs"]},{"location":"KB/Operator%20Fusion/","title":"Operator Fusion","text":""},{"location":"KB/Operator%20Fusion/#operator-fusion","title":"Operator Fusion","text":"<ul> <li>Some DirectML operators support a concept known as fusion. Operator fusion is a way to improve performance by merging one operator (typically, an activation function) into a different operator so that they are executed together without requiring a roundtrip to memory.</li> <li>https://arxiv.org/abs/2108.13342</li> </ul>"},{"location":"KB/Ophthalmoscope/","title":"Ophthalmoscope","text":""},{"location":"KB/Ophthalmoscope/#ophthalmoscope","title":"Ophthalmoscope","text":"<ul> <li>An instrument used to examine the eye's fundus, retina and other structures</li> </ul>"},{"location":"KB/Opportunistic%20Learning/","title":"Opportunistic Learning","text":""},{"location":"KB/Opportunistic%20Learning/#opportunistic-learning","title":"Opportunistic Learning","text":"<ul> <li>apart from learning from a batch of labelled training data at predefined times or according to a predefined training schedule, the robot must be prepared to accept a new example when it is observed or becomes available.</li> </ul>"},{"location":"KB/Optical%20Encoder/","title":"Optical Encoder","text":""},{"location":"KB/Optical%20Encoder/#optical-encoder","title":"Optical Encoder","text":"<ul> <li>A detection sensor, which measures linear or rotary motion by detecting the movement of markings past a fixed beam of light. This can be used to count revolutions, identify parts, etc.</li> </ul>"},{"location":"KB/Optical%20Proximity%20Sensors/","title":"Optical Proximity Sensors","text":""},{"location":"KB/Optical%20Proximity%20Sensors/#optical-proximity-sensors","title":"Optical Proximity Sensors","text":"<ul> <li>Robot sensors which measure visible or invisible light reflected from an object to determine distance. Lasers are used for greater accuracy.</li> </ul>"},{"location":"KB/Optimizers/","title":"Optimization","text":""},{"location":"KB/Optimizers/#optimization","title":"Optimization","text":"<ul> <li>Gradient Descent gradients</li> <li>Adagrad</li> <li>Rmsprop</li> <li>Adam</li> <li>Learning Rate Decay tricks</li> <li>Early Stopping tricks</li> </ul>"},{"location":"KB/Optimizers/#_1","title":"\u2026","text":""},{"location":"KB/Optimizing%20Code/","title":"Optimizing Work","text":""},{"location":"KB/Optimizing%20Code/#optimizing-work","title":"Optimizing Work","text":"<ul> <li>Vectorization</li> <li>Parallelization</li> <li>Loop Tiling</li> <li>Operator Fusion</li> <li>Block Sparse Kernel</li> </ul>"},{"location":"KB/Optogenetics/","title":"Optogenetics","text":""},{"location":"KB/Optogenetics/#optogenetics","title":"Optogenetics","text":"<ul> <li>An innovative neuroscientific technique that uses light to turn genetically modified neurons on and off at will, in live animals.</li> </ul>"},{"location":"KB/Orbisk/","title":"Orbisk","text":""},{"location":"KB/Orbisk/#orbisk","title":"Orbisk","text":"<ul> <li>hannah@orbisk.com : Hannah Nesmith-Beck</li> </ul> <p>Growing up in Dubai and India, I've been seeing the effects of food waste almost every day. While many of us are taking steps to reduce personal food waste at the individual level, more is needed in industries. After I moved to the Netherlands, I started using the app TooGood2Go, and every time I went to any of the restaurants, they had so many bags of food to give away it was very disheartening. Orbi is a great product, from what information I could find on the website. Growing up, I could do nothing about food waste, but if my programming skills can contribute even a little to the fight, I'm definitely in.</p> <p>My expertise is a combination of data analytics and computer vision, and as of a month ago, I also have a Masters in Artificial Intelligence from the University of Groningen. I am familiar with the tools required for basic and advanced AI from internships, research projects, papers, freelance work, and many personal projects. From what I can gather, Orbi has an image classification algorithm at its heart. But perhaps the bigger problem is the data itself. This is a challenging problem, but tackling it even more efficiently with the proper steps should be possible. While I do have some ideas on improving the efficiency and performance of the system, I would be happy to work on any other task at hand as well. </p> <p>Above everything, having even a tiny positive impact on society is something that I am passionate about. Orbi is an excellent step forward in the fight against food waste, and I hope to get a chance to make it even more worthwhile for industries to adopt Orbi as part of their daily process.</p>"},{"location":"KB/Orbisk/#email","title":"Email","text":"<p>Hello Hannah,</p> <p>This is Subhaditya. I recently graduated with a masters in AI from the University of Groningen and am looking for my next big challenge. I found out about Orbisk while looking for positions that would let me use my skills for a good cause. While I am not sure what positions are open, I thought it would be great to reach out and see if I can, perhaps in some way, be part of the fight against food waste with Orbisk.</p> <p>As a summary - my expertise and interest is a combination of computer vision and data analytics. That being the case, I am looking for a junior role in an AI/ML position. I have attached my resume to this email as well, just in case we can discuss a potential match.</p> <p>A little bit about me: </p> <p>Growing up in Dubai and India, I've been seeing the effects of food waste almost every day. While many of us are taking steps to reduce personal food waste at the individual level, more is needed in industries. After I moved to the Netherlands, I started using the app TooGood2Go, and every time I went to any of the restaurants, they had so many bags of food to give away it was very disheartening. Orbi is a great product, from what information I could find on the website. Growing up, I could do nothing about food waste, but if my programming skills can contribute even a little to the fight, I'm definitely in.</p> <p>My expertise is a combination of data analytics and computer vision. I am familiar with the tools required for basic and advanced AI from internships, research projects, papers, freelance work, and many personal projects. From what I can gather, Orbi has an image classification algorithm at its heart. But perhaps the bigger problem is the data itself. This is a challenging problem, but tackling it even more efficiently with the proper steps should be possible. While I do have some ideas on improving the efficiency and performance of the system, I would be happy to work on any other task at hand as well. </p> <p>Thank you for your time and I hope to hear from you soon :) Best, Subhaditya Mukherjee</p>"},{"location":"KB/Organoid/","title":"Organoid","text":""},{"location":"KB/Organoid/#organoid","title":"Organoid","text":"<ul> <li>A research model that uses pluripotent stem cells (iPSCs) to grow structures made of organ-specific cell types.</li> </ul>"},{"location":"KB/Orthogonal%20Initialization/","title":"Orthogonal Initialization","text":""},{"location":"KB/Orthogonal%20Initialization/#orthogonal-initialization","title":"Orthogonal Initialization","text":"<ul> <li>simple approach to solving the problem Vanishingexploding gradients</li> <li>when applying repeated matrix multiplications, the eigenvalues are what dictate the growth or death of the result</li> <li>eigenvalues of orthogonal matrices have an absolute value of 1</li> <li>no matter how many matrix multiplications the result doesen't explode nor vanishes</li> </ul>"},{"location":"KB/Orthogonal%20Slicing/","title":"Orthogonal Slicing","text":""},{"location":"KB/Orthogonal%20Slicing/#orthogonal-slicing","title":"Orthogonal Slicing","text":"<ul> <li>Interactively resample the data on slices perpendicular to x-,y-,z-axis</li> <li>Use visualization techniques for Isoline, Height Plots</li> </ul>"},{"location":"KB/OrthographicNet/","title":"OrthographicNet","text":""},{"location":"KB/OrthographicNet/#orthographicnet","title":"OrthographicNet","text":"<ul> <li>Orthographic projection is used as a universal language among people in engineering professions:</li> <li>Projection lines are parallel to each other and are perpendicular to the plane, An accurate outline of the visible face of the object is obtained.</li> <li></li> <li></li> </ul>"},{"location":"KB/Ostension/","title":"Ostension","text":""},{"location":"KB/Ostension/#ostension","title":"Ostension","text":"<ul> <li>The notion of ostension in Relevance Theory and in Natural Pedagogy Ostension is a notion of the Relevance Theory of Sperber and Wilson</li> <li>Ostension is the behaviour when the communicator makes manifest his/her intention to make something manifest, i.e., perceptible or inferable, to the listener</li> <li>Ostensive Information</li> <li>Humans try to obtain from every item of information as great a contextual effect as possible for as small a processing effort as possible.</li> <li>Children tend to give more credit to information derived from ostensive communication than to information obtained via direct experience</li> </ul>"},{"location":"KB/Ostensive%20Information/","title":"Ostensive Information","text":""},{"location":"KB/Ostensive%20Information/#ostensive-information","title":"Ostensive Information","text":"<ul> <li>Ostensive communication provides two kinds of information<ul> <li>information changing the listener's cognitive state </li> <li>information communicating that the first layer of information is presented intentionally</li> </ul> </li> </ul>"},{"location":"KB/Otoscope%20or%20Auriscope/","title":"Otoscope or Auriscope","text":""},{"location":"KB/Otoscope%20or%20Auriscope/#otoscope-or-auriscope","title":"Otoscope or Auriscope","text":"<ul> <li>A device for examining the external ear cavity</li> </ul>"},{"location":"KB/Out%20of%20Order%20Execution/","title":"Out of Order Execution","text":""},{"location":"KB/Out%20of%20Order%20Execution/#out-of-order-execution","title":"Out of Order Execution","text":"<ul> <li>allow the processor to avoid a class of delays that occur when the data needed to perform an operation are unavailable</li> <li>Instruction fetch.</li> <li>Instruction dispatch to an instruction queue (also called instruction buffer)</li> <li>The instruction waits in the queue until its input operands are available.</li> <li>The instruction is issued to the appropriate functional unit and executed by that unit.</li> <li>The results are queued (Re-order Buffer).</li> <li>Only after all older instructions have their results written back to the register file, then this result is written back to the register.</li> </ul>"},{"location":"KB/Out-group%20Homogeneity%20Bias/","title":"Out group Homogeneity Bias","text":""},{"location":"KB/Out-group%20Homogeneity%20Bias/#out-group-homogeneity-bias","title":"Out-group Homogeneity Bias","text":"<ul> <li>The tendency to see out-group members as more alike than in-group members when comparing attitudes, values, personality traits, and other characteristics. In-group refers to people you interact with regularly; out-group refers to people you do not interact with regularly. If you create a dataset by asking people to provide attributes about out-groups, those attributes may be less nuanced and more stereotyped than attributes that participants list for people in their in-group.</li> </ul>"},{"location":"KB/Out-of-bag%20Evaluation%20%28OOB%20evaluation%29/","title":"Out of bag Evaluation (OOB evaluation)","text":""},{"location":"KB/Out-of-bag%20Evaluation%20%28OOB%20evaluation%29/#out-of-bag-evaluation-oob-evaluation","title":"Out-of-bag Evaluation (OOB evaluation)","text":"<ul> <li>A mechanism for evaluating the quality of a decision forest by testing each decision tree against the examples</li> <li>not used during training of that decision tree.</li> <li>Out-of-bag evaluation is a computationally efficient and conservative approximation of the cross-validation mechanism</li> </ul>"},{"location":"KB/Overhypotheses/","title":"Overhypotheses","text":""},{"location":"KB/Overhypotheses/#overhypotheses","title":"Overhypotheses","text":"<ul> <li>Parse trees for sentences,</li> <li>These can be explained related to grammar</li> <li>Grammars are structured according to general princples in Universal grammar</li> <li>Do children generalize learned object names as representing shape rather than other features? Yes!</li> <li>First order generalization</li> <li>Second order generalization</li> <li>Suggests that learning of overhypotheses can also be modeled with Bayesian learning</li> </ul>"},{"location":"KB/Oxytocin/","title":"Oxytocin","text":""},{"location":"KB/Oxytocin/#oxytocin","title":"Oxytocin","text":"<ul> <li>Sometimes referred to as the \u201ccuddle chemical,\u201d this hormone can work as a neurotransmitter in the brain and has been linked to social attachment and parental care. While there are \u201clove\u201d sprays on the market that are said to contain oxytocin, there is no evidence that these concoctions have any effect on social relationships.</li> </ul>"},{"location":"KB/PASCAL%20VOC/","title":"PASCAL VOC","text":""},{"location":"KB/PASCAL%20VOC/#pascal-voc","title":"PASCAL VOC","text":""},{"location":"KB/PASCAL-S/","title":"PASCAL-S","text":""},{"location":"KB/PASCAL-S/#pascal-s","title":"PASCAL-S","text":"<ul> <li>\"subset of the validation data in the PASCAL VOC 2010\"</li> <li>\"850 natural images\"</li> <li>The fixations were measured while eight observers looked at an image for 2 s.</li> </ul>"},{"location":"KB/PCA/","title":"PCA","text":""},{"location":"KB/PCA/#pca","title":"PCA","text":"<ul> <li>m dim affine hyperplace spanned by first m eigenvectors. Only manifolds and no codebook vectors</li> <li>Be able to reconstruct x from f(x) : decoding function \\(\\(x \\approx d \\circ f(x)\\)\\)</li> <li></li> </ul>"},{"location":"KB/PCA/#steps","title":"Steps","text":"<ol> <li>Center data (A)<ul> <li>Subtract their mean from each pattern.</li> <li> \\[\\mu = \\frac{1}{N}\\Sigma_{i}x_{i}$$ and getting patterns $$\\hat x_{i}=x_{i}-\\mu\\] </li> <li>Point cloud with center of Gravity : origin<ul> <li>Extend more in some \"directions\" characterized by unit norm direction vectors \\(u \\in \\mathbb{R}^n\\) .</li> <li>Distance of a point from the origin in the direction of u : projection of \\(\\bar x_i\\) on u aka inner product \\(u'\\bar x_i\\)</li> <li>Extension of cloud in direction u : Mean square dist to origin.</li> <li>Largest extension : \\(\\(u_{1}= argmax_{u_{1}, ||u|| = 1} \\frac{1}{N}\\Sigma_{i}(u '\\bar x_i)^2\\)\\)</li> <li>Since centered: mean is 0 and \\(\\frac{1}{N}\\Sigma_{i}(u'\\bar x_i)^2\\) is the variance</li> <li>\\(u_1\\) is the longest direction : First PC : PC1</li> </ul> </li> </ul> </li> <li>Project points (B)<ul> <li>Find orthogonal (90deg) subspace . (n-1) dim linear</li> <li>Map all points \\(\\bar x\\) to \\(\\(\\bar x ^{\\ast}=\\bar x- (u' \\bar x_i^\\ast)^2\\)\\)- Second PC : PC2</li> </ul> </li> <li>Rinse and repeat (C)</li> <li>New PCs plotted in original cloud (D)</li> <li>For featurres \\(f_{k}: \\mathbb{R}^{n}\\rightarrow \\mathbb{R}\\) , \\(x \\rightarrow u'_{k}\\bar x\\)</li> <li>Reconstruction : (\\(x= \\mu + \\Sigma_{k= 1, \u2026,n}f_{k}(x)u_{k}\\)\\)<ul> <li>First few PCs till index m<ul> <li>\\((f_{1}(x), \u2026, f_{m}(x))'\\)</li> <li>Decoding function \\(\\(d: (f_{1}(x), \u2026, f_{m}(x))' \\rightarrow \\mu + \\Sigma_{k= 1}f_{k}(x)u_{k}\\)\\)</li> </ul> </li> </ul> </li> <li>How good is the reconstruction<ul> <li> \\[\\Sigma_{k=m+1}^{n} (\\frac{1}{N}\\Sigma_if_{k}(x_i)^2)\\] </li> <li>Relative amount of dissimilarity to mean empirical variance of patterns - 1<ul> <li> \\[\\frac{\\Sigma_{k=m+1}^{n} (\\frac{1}{N}\\Sigma_if_{k}(x_i)^2)}{\\Sigma_{k=1}^{n} (\\frac{1}{N}\\Sigma_if_{k}(x_i)^2)}\\] </li> <li>Ratio very small as index k grows. Very little info lost by reducing dims. Aka good for very high dim stuff.</li> </ul> </li> </ul> </li> <li>Compute SVD<ul> <li>\\(u_{1,}\u2026u_{n}\\) form orthonormal, real eigenvectors</li> <li>variances \\(\\sigma_{1}^{2,}\u2026, \\sigma_{n}^2\\) are eigenvalues</li> <li>\\(C = U\\Sigma U'\\) to get PC vectors \\(u_k\\) lined up in U and variances \\(\\sigma_k^2\\) as eigenvalues in \\(\\Sigma\\)</li> <li>If we want to preserve 98% variance : Rhs of (1) st. ratio is (1-0.98)</li> </ul> </li> </ol>"},{"location":"KB/PDF/","title":"Probability Density Function","text":""},{"location":"KB/PDF/#probability-density-function","title":"Probability Density Function","text":"<ul> <li>If X is a random variable(RV) that takes values in \\(S \\subseteq \\mathbb{R}^{n}\\). PDF is a fn \\(f:S \\rightarrow \\mathbb{R}^{\\geq0}\\) that satisfies:<ul> <li>For every subvolume \\(A \\subseteq S\\) of S, the prob \\(P(X \\in A)\\) that X gives a value in A is \\(\\(P(X\\in A) = \\int_Af(x)dx\\)\\)</li> </ul> </li> <li>Function which maps from a random process to a quantified version<ul> <li>eg. 1 when heads and 0 when tails</li> </ul> </li> </ul>"},{"location":"KB/PEER/","title":"PEER","text":""},{"location":"KB/PEER/#peer","title":"PEER","text":"<ul> <li>trained on edit histories to cover the entire writing process</li> <li>Plan, Edit, Explain and Repeat</li> <li>These steps are repeated until the text is in a satisfactory state that requires no further updates</li> <li>The model allow to decompose the task of writing a paper into multiple easier subtasks</li> <li>the model allows humans to intervene at any time and steer the model in any direction</li> <li>Wikipedia edit histories</li> <li>The approach is a selftraining, using models to infill missing data and then train other models on this synthetic data</li> <li>The downside of this comes from comments being very noisy and a lack of citations, which tries to be compensated by a retrieval system which does not always work</li> <li>The entire process of formulating a plan, collecting documents, performing an edit and explaining it can be repeated multiple times until arriving at a sequence of text</li> <li>a DeepSpeed transformer is used</li> </ul>"},{"location":"KB/PIUQ/","title":"PIUQ","text":""},{"location":"KB/PIUQ/#piuq","title":"PIUQ","text":"<ul> <li>Problematic Internet Use Questionnaire (PIUQ)</li> <li>a validated self-report scale with good reliability and validity characteristics</li> <li>The questionnaire contains 18 items, each scored on a 5-point Likert-type scale ranging from 1 (never) to 5 (always)</li> </ul>"},{"location":"KB/PMF/","title":"Probability Mass Function","text":""},{"location":"KB/PMF/#probability-mass-function","title":"Probability Mass Function","text":"<ul> <li>pmf</li> <li>Given a discrete sample space S<ul> <li>S is a function \\(p : S \\rightarrow [0,1]\\) whos total mass is 1</li> <li>satisfies \\(\\Sigma_{s \\in S}p(s) = 1\\)</li> </ul> </li> </ul>"},{"location":"KB/PQ/","title":"PQ","text":""},{"location":"KB/PQ/#pq","title":"PQ","text":"<ul> <li>PQ is a vector compression and indexing method that quantizes high-dimensional vectors into compact binary codes</li> <li>enables efficient storage and retrieval of dense vectors while preserving their semantic properties.</li> </ul>"},{"location":"KB/PRelu/","title":"Parametric Relu","text":""},{"location":"KB/PRelu/#parametric-relu","title":"Parametric Relu","text":"<ul> <li> \\[max(\\alpha x,x)\\] </li> <li></li> </ul>"},{"location":"KB/PWC%20Data%20Analyst%20Junior/","title":"PWC Data Analyst Junior","text":"","tags":["jobs"]},{"location":"KB/PWC%20Data%20Analyst%20Junior/#associate-ai-specialist-application-subhaditya-mukherjee","title":"Associate AI Specialist Application - Subhaditya Mukherjee","text":"<p>As the days go by, Machine Learning and AI are slowly becoming terms that every company wants to have in their portfolio. While this drive leads to many innovations, most companies are not sure how to do AI \"well\". They want to use AI but need clarification on whether it is required, how to handle bias, how to create proper data, or even what models (ML vs. DL) to choose. The job of an AI specialist, then, is to provide the key information required to find and fulfil KPIs given any project. This job would be the perfect next step for me, and so I hope you give me a chance to work with you and your team.</p> <p>My interest is at the intersection of applied AI and explainability, and as of a month ago, I also have a Master in Artificial Intelligence from the University of Groningen. My masters thesis was on improving the explainability of vision models, which gave me quite a bit of experience in this domain. I am quite familiar with Python, deep learning frameworks such as PyTorch and Tensorflow and other tricks of the trade. But this would be my first job, and I have a lot to learn as well. I am willing to put time and effort into learning new technologies and enabling more efficient AI integration with future clients.</p> <p>The customer is king, they say, and the first step in having happy clients is understanding what they truly want and then being able to give them a solution they can use. I hope to be part of a team at PWC working on enabling stakeholders to implement responsible AI in their products. </p>","tags":["jobs"]},{"location":"KB/PaLM/","title":"PaLM","text":""},{"location":"KB/PaLM/#palm","title":"PaLM","text":"<ul> <li>PaLM: Scaling Language Modeling with Pathways</li> <li>single 540 billion parameter dense Transformer language model</li> <li>few-shot language understanding and generation</li> <li>drastically reduces the number of task-specific training examples needed to adapt the model to a particular application</li> <li>Pathways Language Model</li> <li>6144 TPU v4 chips</li> <li>breakthrough performance on reasoning tasks, which require multi-step logical inference</li> <li>combination of scale and chain-of-thought prompting, where the model is explicitly prompted to generate a natural language logical inference chain before making its predictio</li> <li>write explicit logical inference chains to both explain jokes and answer complex questions about scenarios</li> <li>Big-Bench</li> <li>suggest that the improvements from scale for few-shot language understanding have not yet plateaued</li> <li>When they compare results from PaLM 540B to our own identically trained 62B and 8B model variants, improvements are typically log-linear.</li> <li>certain capabilities of language models only emerge when trained at sufficient scale, and there are additional capabilities that could emerge from future generations of models</li> <li>demonstrating that prompting the model to generate explicit inference chains can drastically increase the quality of the predictions themselves</li> <li>model\u2019s generation (rather than just understanding) capabilities can be immensely beneficial even for tasks that are modeled as categorical prediction or regression, which typically do not require significant language generation</li> <li>comprehensive analysis on bias and toxicity, and study the extent of training data memorization with respect to model scale</li> <li>ethical considerations related to large language models and discuss potential mitigation strategies</li> </ul>"},{"location":"KB/Padded%20Conv/","title":"Padded Conv","text":""},{"location":"KB/Padded%20Conv/#padded-conv","title":"Padded Conv","text":"<ul> <li> \\[(N_i, N_o, C, F)\\] </li> <li>Filters transform from C -&gt; F channels</li> <li>Mirror, Reflect</li> </ul>"},{"location":"KB/Palletizing/","title":"Palletizing","text":""},{"location":"KB/Palletizing/#palletizing","title":"Palletizing","text":"<ul> <li>The process of stacking packages (i.e., boxes, bags, containers, etc.) in an organized fashion on a pallet.</li> </ul>"},{"location":"KB/Parallel%20Coordinate%20Plots/","title":"Parallel Coordinate Plots","text":""},{"location":"KB/Parallel%20Coordinate%20Plots/#parallel-coordinate-plots","title":"Parallel Coordinate Plots","text":"<ul> <li>Enhancement<ul> <li>Permute axes (horizontally) to and swap their direction (vertically) minimize crossings</li> <li>Add histograms on axes to show lines per unit data value</li> <li>Visually group/cluster polylines histograms</li> </ul> </li> </ul>"},{"location":"KB/Parallel%20Granularity/","title":"Parallel Granularity","text":""},{"location":"KB/Parallel%20Granularity/#parallel-granularity","title":"Parallel Granularity","text":"<ul> <li>Ration of computation to communication</li> <li>Coarse : Large computation between communication</li> <li>Fine : Small computation between communication</li> </ul>"},{"location":"KB/Parallel%20Processing/","title":"Parallel Processing","text":""},{"location":"KB/Parallel%20Processing/#parallel-processing","title":"Parallel Processing","text":"<ul> <li>Load balancing</li> <li>Minimizing Communication</li> <li>Overlap Communication</li> </ul>"},{"location":"KB/Parallel%20Runner/","title":"Parallel Runner","text":""},{"location":"KB/Parallel%20Runner/#parallel-runner","title":"Parallel Runner","text":"<pre><code>import random\nimport numpy as np\nimport concurrent\nfrom typing import *\nfrom concurrent.futures import ProcessPoolExecutor\nfrom types import SimpleNamespace\nimport os\nfrom pathlib import Path\n\ndef ifnone(a, b):\n    \"\"\"\n    Return if None\n    \"\"\"\n    return b if a is None else a\n\n\ndef listify(o):\n    \"\"\"\n    Convert to list\n    \"\"\"\n    if o is None:\n        return []\n    if isinstance(o, list):\n        return o\n    if isinstance(o, str):\n        return [o]\n    if isinstance(o, Iterable):\n        return list(o)\n    return [o]\n\n\ndef num_cpus() -&gt; int:\n    \"Get number of cpus\"\n    try:\n        return len(os.sched_getaffinity(0))\n    except AttributeError:\n        return os.cpu_count()\n\n\n_default_cpus = min(16, num_cpus())\ndefaults = SimpleNamespace(\n    cpus=_default_cpus, cmap=\"viridis\", return_fig=False, silent=False\n)\n\n\ndef parallel(func, arr: Collection, max_workers: int = None, leave=False):  # %t\n    \"Call `func` on every element of `arr` in parallel using `max_workers`.\"\n    max_workers = ifnone(max_workers, defaults.cpus)\n    if max_workers &lt; 2:\n        results = [\n            func(o, i)\n            for i, o in tqdm.tqdm(enumerate(arr), total=len(arr), leave=leave)\n        ]\n    else:\n        with ProcessPoolExecutor(max_workers=max_workers) as ex:\n            futures = [ex.submit(func, o, i) for i, o in enumerate(arr)]\n            results = []\n            for f in tqdm.tqdm(\n                concurrent.futures.as_completed(futures), total=len(arr), leave=leave\n            ):\n                results.append(f.result())\n    if any([o is not None for o in results]):\n        return results\n\n</code></pre>"},{"location":"KB/Parallel%20Shift%20Function/","title":"Parallel Shift Function","text":""},{"location":"KB/Parallel%20Shift%20Function/#parallel-shift-function","title":"Parallel Shift Function","text":"<ul> <li>Parallel Shift refers to the shifting of an object from a fixed position in such a way that all points within the object move an equal distance.</li> </ul>"},{"location":"KB/Parallelization/","title":"Parallel","text":""},{"location":"KB/Parallelization/#parallel","title":"Parallel","text":"<ul> <li>Independant work chunks -&gt; operate simultaneously</li> </ul>"},{"location":"KB/Parasympathetic/","title":"Parasympathetic","text":""},{"location":"KB/Parasympathetic/#parasympathetic","title":"Parasympathetic","text":"<ul> <li>Relaxes the body</li> </ul>"},{"location":"KB/Parent%20Approximations/","title":"Parent Approximations","text":""},{"location":"KB/Parent%20Approximations/#parent-approximations","title":"Parent Approximations","text":"<ul> <li>It learns a compact two-level decision set in which each rule explains parts of the model behavior unambiguously and is a combined objective function to optimize these aspects: high agreement between the explanation and the model; little overlap between the decision rules in the explanation; the explanation decision set is lightweight and small.</li> </ul>"},{"location":"KB/Parietal%20lobe/","title":"Parietal lobe","text":""},{"location":"KB/Parietal%20lobe/#parietal-lobe","title":"Parietal Lobe","text":"<ul> <li>Interprets language, words</li> <li>Sense of touch, pain, temperature (sensory strip)</li> <li>Interprets signals from vision, hearing, motor, sensory and memory</li> <li>Spatial and visual perception</li> </ul>"},{"location":"KB/Parietal%20lobe/#parietal-lobe_1","title":"Parietal Lobe","text":"<ul> <li>The area of the brain\u2019s cerebrum located just behind the central sulcus. It is concerned primarily with the reception and processing of sensory information from the body and is also involved in map interpretation and spatial orientation (recognizing one\u2019s position in space in relation to other objects or places).</li> </ul>"},{"location":"KB/Parkinson%E2%80%99s%20Disease/","title":"Parkinson\u2019s Disease","text":""},{"location":"KB/Parkinson%E2%80%99s%20Disease/#parkinsons-disease","title":"Parkinson\u2019s Disease","text":"<ul> <li>A neurodegenerative disorder characterized by tremor, slowed movement, and speech changes due to the death of dopamine</li> <li>neurons located in the substantia nigra.</li> </ul>"},{"location":"KB/Partial%20Dependence%20Plot/","title":"Partial Dependence Plot","text":""},{"location":"KB/Partial%20Dependence%20Plot/#partial-dependence-plot","title":"Partial Dependence Plot","text":"<ul> <li>Another approach [29] shows the marginal effect of one or two features on the prediction of learning techniques using Partial Dependence Plots</li> <li>The method gives a statement about the global relationship of a feature and whether its relation to the outcome is linear, monotonic, or more complex.</li> <li>The PDP is the average of Individual Conditional Expectation (ICE) over all features</li> <li>ICE [30] points to how the prediction changes if a feature changes.</li> <li>The PDP is limited to two features.</li> </ul>"},{"location":"KB/Participation%20Bias/","title":"Participation Bias","text":""},{"location":"KB/Participation%20Bias/#participation-bias","title":"Participation Bias","text":"<ul> <li>Synonym for non-response bias</li> </ul>"},{"location":"KB/Particle%20Filter/","title":"Particle Filter","text":""},{"location":"KB/Particle%20Filter/#particle-filter","title":"Particle Filter","text":"<ul> <li>Particle filter algorithm works for any arbitrary distribution and not just Gaussian. Particle filter is computationally more expensive than Kalman filter</li> <li>non linear systems.</li> </ul>"},{"location":"KB/Particle%20Visualization/","title":"Particle Visualization","text":""},{"location":"KB/Particle%20Visualization/#particle-visualization","title":"Particle Visualization","text":"<ul> <li>points with only a (3D) coordinate</li> <li>potentially enriched with attributes like radius, velocity, etc.</li> <li>scattered data Data Structures</li> <li>lack of topological information (neighborhood)</li> <li>typically many particles (e.g. atoms, galaxies)</li> <li>Atomistic visualization</li> <li>via glyphs (i.e. spheres)</li> <li>explicit (geometry) or implicit Raycasting</li> <li>Surface-based visualization</li> <li>extract surface geometry</li> <li>particles: point samples describing a surface (e.g. in fluids or molecules)</li> <li>Volume-based visualization</li> <li>particles: point samples of a volume</li> <li>Raycasting and hierarchical Data Structures</li> </ul>"},{"location":"KB/Parts%20of%20action/","title":"Parts of action","text":""},{"location":"KB/Parts%20of%20action/#parts-of-action","title":"Parts of Action","text":"<ul> <li>Lynn went on a business trip to New York.</li> <li>She left on an early morning flight.</li> <li>Taking a flight should be recognized as part of going on a trip.</li> </ul>"},{"location":"KB/Parts%20of%20entities/","title":"Parts of entities","text":""},{"location":"KB/Parts%20of%20entities/#parts-of-entities","title":"Parts of Entities","text":"<ul> <li>Tracy opened the book she just bought.</li> <li>The toc: true title page was torn.</li> <li>The phrase \u2018the toc: true title page\u2019 should be recognized as being part of the book tat was just bought.</li> </ul>"},{"location":"KB/PatchGAN/","title":"PatchGAN","text":""},{"location":"KB/PatchGAN/#patchgan","title":"PatchGAN","text":"<ul> <li>Type of discriminator</li> <li>only penalizes structure at the scale of local image patches</li> <li>tries to classify if each \\(N \\times N\\) patch in an image is real or fake</li> <li>discriminator is run convolutionally across the image, averaging all responses to provide the ultimate output of \\(D\\)</li> <li>effectively models the image as a Markov random field</li> <li>assuming independence between pixels separated by more than a patch diameter</li> <li>type of texture/style loss</li> <li>rather the regular GAN maps from a 256\u00d7256 image to a single scalar output, which signifies \u201creal\u201d or \u201cfake\u201d, whereas the PatchGAN maps from 256\u00d7256 to an NxN (here 70\u00d770) array of outputs X, where each \\(X_{ij}\\) signifies whether the patch ij in the image is real or fake.</li> <li></li> </ul>"},{"location":"KB/Pathlines/","title":"Pathlines","text":""},{"location":"KB/Pathlines/#pathlines","title":"Pathlines","text":""},{"location":"KB/Pearson%20Correlation/","title":"Pearson Correlation","text":"<p>toc: true title: Pearson Correlation</p> <p>categories: ['temp']</p>"},{"location":"KB/Pearson%20Correlation/#pearson-correlation","title":"Pearson Correlation","text":"<ul> <li>One type of Correlation</li> <li> \\[r = \\frac{n(\\Sigma xy) - (\\Sigma x)(\\Sigma y)}{\\sqrt{[n\\Sigma x^{2} - (\\Sigma x)^{2}][n\\Sigma y^{2} - (\\Sigma y)^{2}]}}\\] </li> </ul>"},{"location":"KB/Pendant%20Teaching/","title":"Pendant Teaching","text":""},{"location":"KB/Pendant%20Teaching/#pendant-teaching","title":"Pendant Teaching","text":"<ul> <li>The mapping and recording of the position and orientation of a robot and/or manipulator system as the robot is manually moved in increments from an initial state along a path to a final goal state. The position and orientation of each critical point (joints, robot base, etc.) is recorded and stored in a database for each taught position the robot passes through on its path toward its final goal. The robot may now repeat the path on its own by following the path stored in the database.</li> </ul>"},{"location":"KB/People%20Art%20Dataset/","title":"People Art Dataset","text":""},{"location":"KB/People%20Art%20Dataset/#people-art-dataset","title":"People Art Dataset","text":""},{"location":"KB/Perception%20Component/","title":"Perception Component","text":""},{"location":"KB/Perception%20Component/#perception-component","title":"Perception Component","text":"<ul> <li>processes all momentary information coming from sensors.</li> </ul>"},{"location":"KB/Perception/","title":"Perception","text":""},{"location":"KB/Perception/#perception","title":"Perception","text":"<ul> <li>Perception \u2014 process by which we interpret the things around us through sensory stimuli</li> <li>Cognition \u2014 mental processes assisting us to remember, think, know, judge, solve problems, etc.</li> <li>Preattentive Processing</li> <li>Gestalt Laws</li> <li>Postattentive Amnesia</li> <li>Change Blindness</li> <li>Inattentional Blindness</li> </ul>"},{"location":"KB/Perceptron/","title":"Perceptron","text":""},{"location":"KB/Perceptron/#perceptron","title":"Perceptron","text":"<ul> <li> \\[f(x)=sign(\\Sigma _i w_ix_i +b) = sign(\\mathbf{w^Tx}+b)\\] <ul> <li>\\(\\(sign(x) = \\begin{cases} 1 &amp; x\\geq0 \\\\ 0 &amp; otherwise\\end{cases}\\)\\) </li> </ul> </li> <li>computational graph</li> <li>Multi layer<ul> <li>Stack multiple perceptrons</li> <li> \\[\\begin{align} \\\\&amp; h_0 = x h1= sign(\\mathbf{w_1^T}+b_1) \\\\ &amp;\u2026\\\\&amp; h1= sign(\\mathbf{w_{L-1}^T}+b_L) \\end{align}\\] </li> </ul> </li> </ul>"},{"location":"KB/Perceptual%20Messages/","title":"Perceptual Messages","text":""},{"location":"KB/Perceptual%20Messages/#perceptual-messages","title":"Perceptual Messages","text":"<ul> <li>large (e.g., point cloud)</li> <li>data flows continuously at the sensor output frequency (30Hz).</li> </ul>"},{"location":"KB/Perceptually%20Uniform/","title":"Perceptually Uniform","text":""},{"location":"KB/Perceptually%20Uniform/#perceptually-uniform","title":"Perceptually Uniform","text":"<ul> <li>Euclidean distance corresponds to perceptual difference</li> <li>e.g., CIELUV,CIELAB, (L,a,b*).</li> </ul>"},{"location":"KB/Peripheral%20Nervous%20System/","title":"Peripheral Nervous System","text":""},{"location":"KB/Peripheral%20Nervous%20System/#peripheral-nervous-system","title":"Peripheral Nervous System","text":"<ul> <li>All the nerves that branch off from the brain</li> <li>Both directions</li> <li>Allow Central Nervous System to communicate with the body</li> <li>Afferent + Efferent</li> </ul>"},{"location":"KB/Perplexity/","title":"Perplexity","text":""},{"location":"KB/Perplexity/#perplexity","title":"Perplexity","text":"<ul> <li>Perplexity is defined as the exponentiated average negative log-likelihood of a sequence.</li> <li>If we have a tokenized sequence \\(X = (x_0, x_1, \\dots, x_t)\\), then the perplexity of \\(X\\) is, \\(\\(\\text{PPL}(X) = \\exp \\left\\{ {-\\frac{1}{t}\\sum_i^t \\log p_\\theta (x_i|x_{&lt;i}) } \\right\\}\\)\\)where \\(\\log p_\\theta (x_i|x_{&lt;i})\\) is the log-likelihood of the ith token conditioned on the preceding tokens \\(x_{&lt;i}\\) according to our model.</li> <li>Intuitively, it can be thought of as an evaluation of the model's ability to predict uniformly among the set of specified tokens in a corpus.</li> <li>Importantly, this means that the tokenization procedure has a direct impact on a model's perplexity which should always be taken into consideration when comparing different models.</li> <li>This is also equivalent to the exponentiation of the Cross Entropy between the data and model predictions</li> </ul>"},{"location":"KB/PhD%20vs%20Startup%20vs%20Big%20Company/","title":"PhD vs Startup vs Big Company","text":"","tags":["mlops"]},{"location":"KB/PhD%20vs%20Startup%20vs%20Big%20Company/#phd-vs-startup-vs-big-company","title":"PhD Vs Startup Vs Big Company","text":"<ul> <li>https://huyenchip.com/2018/10/08/career-advice-recent-cs-graduates.html</li> </ul>","tags":["mlops"]},{"location":"KB/PhD%20vs%20Startup%20vs%20Big%20Company/#phd-vs-no-phd","title":"PhD Vs no PhD","text":"<ul> <li> <p>Arguments supporting PhD include:</p> <ul> <li>You\u2019ll have time to immerse yourself in research.</li> <li>If you want to become a professor, you have to do a PhD.</li> <li>Many top research labs such as DeepMind only interview PhD candidates.</li> <li>You won\u2019t be too poor as AI internships pay well.</li> </ul> </li> <li> <p>Arguments supporting no-PhD include:</p> <ul> <li>There should be more people joining industry to bring research into production.</li> <li>By the time you finish your PhD, what you learn might no longer be relevant.</li> <li>Many professors have side gigs in the industry anyway so you can still work with them.</li> <li>You won\u2019t be poor for the next five years.</li> </ul> </li> <li> <p>Pursuing your passion, it turns out, is not legal in the US when you\u2019re an international student.</p> </li> </ul>","tags":["mlops"]},{"location":"KB/PhD%20vs%20Startup%20vs%20Big%20Company/#big-companies-vs-startups","title":"Big Companies Vs Startups","text":"","tags":["mlops"]},{"location":"KB/Pharmacotherapy/","title":"Pharmacotherapy","text":""},{"location":"KB/Pharmacotherapy/#pharmacotherapy","title":"Pharmacotherapy","text":"<ul> <li>The use of pharmaceutical drugs for therapeutic purposes.</li> </ul>"},{"location":"KB/Phases%20of%20Simulated%20User%20Experiments/","title":"Phases of Simulated User Experiments","text":""},{"location":"KB/Phases%20of%20Simulated%20User%20Experiments/#phases-of-simulated-user-experiments","title":"Phases of Simulated User Experiments","text":"<ul> <li>Evolution<ul> <li>The classification performance should be improved as the number of examples per category increases while NO new categories are introduced.</li> </ul> </li> <li>Recovery<ul> <li>By increasing the number of categories, it is expected that the prediction accuracy decreases. The time spent in system evolution until correcting and adjusting all current categories defines recovery.</li> </ul> </li> <li>Breakpoint<ul> <li>Eventually the learning agent reaches to a breakpoint where the agent is no longer able to learn more categories.</li> </ul> </li> </ul>"},{"location":"KB/Phenaki/","title":"Phenaki","text":""},{"location":"KB/Phenaki/#phenaki","title":"Phenaki","text":"<ul> <li>capable of performing realistic video synthesis, given a sequence of textual prompts</li> <li>Phenaki is the first model that can generate videos from open domain time variable prompts</li> <li>To address data issues, it performs joint training on a large image-text pairs dataset as well as a smaller number of video-text examples can result in generalization beyond what is available in the video datasets.</li> <li>image-text datasets having billions of inputs</li> <li>limitations come from computational capabilities for videos of variable length</li> <li>the C-ViViT encoder, the training transformer and the video generator</li> <li>The encoder gets a compressed representation of videos.</li> <li>First tokens are transformed into embeddings.</li> <li>This is followed by the temporal transformer, then the spatial transformer</li> <li>After the output of the spatial transformer, they apply a single linear projection without activation to map the tokens back to pixel space</li> <li>Consequently, the model generates temporally coherent and diverse videos conditioned on open domain prompts even when the prompt is a new composition of concepts</li> </ul>"},{"location":"KB/Phenotype/","title":"Phenotype","text":""},{"location":"KB/Phenotype/#phenotype","title":"Phenotype","text":"<ul> <li>A set of traits or characteristics resulting from the interaction of one\u2019s genes with the environment.</li> </ul>"},{"location":"KB/Phonetics/","title":"Phonetics","text":""},{"location":"KB/Phonetics/#phonetics","title":"Phonetics","text":"<ul> <li>deals with the physical building blocks of a language sound system.</li> <li>eg. sounds of \u2018k\u2019, \u2018t\u2019 and \u2018e\u2019 in \u2018kite</li> </ul>"},{"location":"KB/Phong%20Lighting/","title":"Phong Lighting","text":""},{"location":"KB/Phong%20Lighting/#phong-lighting","title":"Phong Lighting","text":""},{"location":"KB/Phonology/","title":"Phonology","text":""},{"location":"KB/Phonology/#phonology","title":"Phonology","text":"<ul> <li>organisation of speech sounds within a language.</li> <li>eg. (1) different \u2018k\u2019 sounds in \u2018kite\u2019 vs \u2018coat\u2019</li> <li>(2) different \u2018t\u2019 and \u2018p\u2019 sounds in \u2018top\u2019 vs \u2018pot\u2019</li> </ul>"},{"location":"KB/Phrase%20Representation%20Learning/","title":"Phrase Representation Learning","text":""},{"location":"KB/Phrase%20Representation%20Learning/#phrase-representation-learning","title":"Phrase Representation Learning","text":"<ul> <li>Learning Phrase Representations Using RNN Encoder\u2013Decoder for Statistical Machine Translation</li> <li>two recurrent neural networks Basic RNN Architectures that is together able to learn the mapping from a sequence of an arbitrary length to another sequence, possibly from a different set, of an arbitrary length.</li> <li>either score a pair of sequences (in terms of a conditional probability) or generate a target sequence given a source sequence</li> <li>jointly trained to maximize the conditional probability of a target sequence given a source sequence</li> <li>reset gate and an update gate that adaptively control how much each hidden unit remembers or forgets while reading/generating a sequenc</li> <li>RNN Encoder\u2013Decoder to score each phrase pair in the phrase table</li> <li>capture linguistic regularities in the phrase pairs well</li> <li>BLEU</li> </ul>"},{"location":"KB/Picasso%20Dataset/","title":"Picasso Dataset","text":""},{"location":"KB/Picasso%20Dataset/#picasso-dataset","title":"Picasso Dataset","text":""},{"location":"KB/Pick%20and%20Place%20Cycle/","title":"Pick and Place Cycle","text":""},{"location":"KB/Pick%20and%20Place%20Cycle/#pick-and-place-cycle","title":"Pick and Place Cycle","text":"<ul> <li>The amount of time it takes for a manipulator to pick up an object and place it in a desired location, then return to its rest position. This includes time during the acceleration and deceleration phases of a particular task. The robot movement is controlled from one point location in space to another in a Point-to-Point (PTP) motion system. Each point is programmed into the robot's control memory and then played back during the work cycle.</li> </ul>"},{"location":"KB/Picky%20Puppet%20Method/","title":"Picky Puppet Method","text":""},{"location":"KB/Picky%20Puppet%20Method/#picky-puppet-method","title":"Picky Puppet Method","text":"<ul> <li>For children</li> <li>Ask if a \"puppet\" would like it</li> </ul>"},{"location":"KB/Pinch%20Points/","title":"Pinch Points","text":""},{"location":"KB/Pinch%20Points/#pinch-points","title":"Pinch Points","text":"<ul> <li>A pinch point is any point at which it is possible for a person or part of a person\u2019s body to be caught between moving parts of a machine, or between the moving and stationary parts of a machine, or between material and any part of the machine. A pinch point does not have to cause injury to a limb or body part, although it might cause injury \u2013 it only has to trap or pinch the person to prevent them from escaping or removing the trapped part from the pinch point.</li> </ul>"},{"location":"KB/Pineal%20gland/","title":"Pineal gland","text":""},{"location":"KB/Pineal%20gland/#pineal-gland","title":"Pineal Gland","text":"<ul> <li>It is located behind the third ventricle.</li> <li>It helps regulate the body\u2019s internal clock and circadian rhythms by secreting melatonin.</li> <li>It has some role in sexual development.</li> </ul>"},{"location":"KB/Pipes/","title":"Pipes","text":""},{"location":"KB/Pipes/#pipes","title":"Pipes","text":"<ul> <li>Allows vector operation to be performed in parallel on multiple elements of the vector</li> </ul>"},{"location":"KB/Pituitary%20gland/","title":"Pituitary gland","text":""},{"location":"KB/Pituitary%20gland/#pituitary-gland","title":"Pituitary Gland","text":"<ul> <li>lies in a small pocket of bone at the skull base called the sella turcica.</li> <li>The pituitary gland is connected to the hypothalamus of the brain by the pituitary stalk.</li> <li>Known as the \u201cmaster gland,\u201d it controls other endocrine glands in the body.</li> <li>It secretes hormones that control sexual development, promote bone and muscle growth, and respond to stress.</li> </ul>"},{"location":"KB/Pituitary%20gland/#pituitary-gland_1","title":"Pituitary Gland","text":"<ul> <li>An endocrine organ at the base of the brain that is closely linked with the hypothalamus. The pituitary gland is composed of two lobes, the anterior and posterior lobes, and secretes hormones that regulate the activity of the other endocrine organs in the body.</li> </ul>"},{"location":"KB/Pix2Seq/","title":"Pix2Seq","text":""},{"location":"KB/Pix2Seq/#pix2seq","title":"Pix2Seq","text":"<ul> <li>Pix2seq: a Language Modeling Framework for Object Detection</li> <li>generic framework for object detection</li> <li>object detection as a language modeling task conditioned on the observed pixel inputs</li> <li>Object descriptions (e.g., bounding boxes and class labels) are expressed as sequences of discrete tokens, and we train a neural network to perceive the image and generate the desired sequence</li> <li>COCO</li> <li>output can be represented by a relatively concise sequence of discrete tokens (e.g., keypoint detection, image captioning, visual question answering)</li> <li>autoregressive</li> <li>stop inference when the ending token is produced</li> <li>applying it to offline inference, or online scenarios where the objects of interest are relatively sparse</li> <li>entirely based on human annotation</li> </ul>"},{"location":"KB/Places/","title":"Places","text":""},{"location":"KB/Places/#places","title":"Places","text":"<ul> <li>The Places dataset [107] is proposed for scene recognition and contains more than 2.5 million images covering more than 205 scene categories with more than 5, 000 images per category.</li> </ul>"},{"location":"KB/Places365/","title":"Places365","text":""},{"location":"KB/Places365/#places365","title":"Places365","text":"<ul> <li>2nd generation of the Places databas </li> <li>high-level visual understanding tasks, such as scene context, object recognition, action and event prediction, and theoryof-mind inference </li> <li>more than 10 million images covering more than 400 classes and 5, 000 to 30, 000 training images per class.</li> </ul>"},{"location":"KB/PlantCLEF/","title":"PlantCLEF","text":""},{"location":"KB/PlantCLEF/#plantclef","title":"PlantCLEF","text":"<ul> <li>PlantCLEF dataset is a collection of images of plants, with a total of around 57,000 images and over 200 different plant species.</li> </ul>"},{"location":"KB/Pluripotency/","title":"Pluripotency","text":""},{"location":"KB/Pluripotency/#pluripotency","title":"Pluripotency","text":"<ul> <li>The quality of certain undifferentiated cells that allows them to develop into one of many different cell types.</li> </ul>"},{"location":"KB/Point%20Cloud/","title":"Point Cloud Data","text":""},{"location":"KB/Point%20Cloud/#point-cloud-data","title":"Point Cloud Data","text":"<ul> <li>PointNet++</li> </ul>"},{"location":"KB/Point%20Distribution/","title":"Point Distribution","text":""},{"location":"KB/Point%20Distribution/#point-distribution","title":"Point Distribution","text":"<ul> <li>PDF is impossible to use</li> <li>Probability mass is concentrated in a few points</li> <li>Dirac Delta</li> <li>Hyperdistributions</li> </ul>"},{"location":"KB/Point-to-Point/","title":"Point to Point","text":""},{"location":"KB/Point-to-Point/#point-to-point","title":"Point-to-Point","text":"<ul> <li>Manipulator motion in which a limited number of points along a projected path of motion is specified. The manipulator moves from point to point rather than a continuous smooth path.</li> </ul>"},{"location":"KB/PointNet%2B%2B/","title":"PointNet++","text":""},{"location":"KB/PointNet%2B%2B/#pointnet","title":"PointNet++","text":""},{"location":"KB/PointNet%2B%2B/#todo","title":"todo","text":""},{"location":"KB/Poisson%20Distribution/","title":"Possion Distribution","text":""},{"location":"KB/Poisson%20Distribution/#possion-distribution","title":"Possion Distribution","text":"<ul> <li>Probability that an event occurs k times within a given time interval</li> <li>Eg:</li> <li>k meteors within 100 years</li> <li>k calls in an hour</li> <li>Also can count spatially circumscribed events</li> <li>no of dust particles in a mm of air</li> <li>no of diamons in ton of ore</li> <li>Expected no of events \\(E[X]\\) : rate \\(\\lambda\\)</li> <li>PMF : \\(\\(p(k) = \\frac{\\lambda^{k}e^{-k}}{k!}\\)\\)</li> <li></li> <li>Eg:</li> <li>N 1-hour protocols for calls : \\(n_{i} (i = 1, \u2026, N)\\)</li> <li> \\[\\hat\\lambda =\\frac{1}{N}\\Sigma_{i}n_{i}\\] </li> </ul>"},{"location":"KB/Poisson%20Loss/","title":"Poisson Loss","text":""},{"location":"KB/Poisson%20Loss/#poisson-loss","title":"Poisson Loss","text":"<ul> <li>When data is from Poisson Distribution</li> </ul> \\[\\frac{1}{\\mathrm{length}\\left( y \\right)} \\cdot \\mathrm{sum}\\left( \u0177 - \\log\\left( \u0177 \\right) \\right)\\]"},{"location":"KB/Poisson%20Process/","title":"Poisson Process","text":""},{"location":"KB/Poisson%20Process/#poisson-process","title":"Poisson Process","text":"<ul> <li>Waiting times between two consecutive spikes are Exponential Distribution</li> </ul>"},{"location":"KB/Poki%20Data%20Scientist/","title":"Poki Data Scientist","text":""},{"location":"KB/Poki%20Data%20Scientist/#poki-data-scientist","title":"Poki Data Scientist","text":""},{"location":"KB/Poki%20Data%20Scientist/#why-do-you-want-to-work-at-poki","title":"Why Do You want to Work at Poki?","text":"<ul> <li>grown up playing games on websites such as miniclip</li> <li>data science experience : interesting challenge</li> <li>sounds like a fun place to work</li> <li>perfect next step in my career, learn and grow with Poki and be a part of people enjoying games on the web </li> </ul> <p>Growing up, I used to spend countless hours playing games online on websites such as Miniclip (does anyone remember Club Penguin? :) ). Being a data scientist with a master in AI, finding ways to ensure players have a nice experience using Poki while also being able to make sure they find the games they want sounds like a great challenge. Poki sounds like a fun place to work, and this would be the perfect next step in my career. </p> <p>It is not every day that you find a position that you think you might enjoy and also know that you can contribute to upon being given a chance, and I did not want to let this opportunity slide.</p>"},{"location":"KB/Poki%20Data%20Scientist/#can-you-describe-a-time-where-you-identified-an-area-of-improvement-and-the-way-you-followed-up-on-that","title":"Can You Describe a time where You Identified an Area of Improvement and the way You Followed up on That?","text":"<ul> <li>In my work at Emirates NBD (one of the national banks of Dubai), we were building an analytics pipeline to identify fraud transactions. While the pipeline worked, they were using a Microsoft service to do the analytics and the performance was not great.</li> <li>In my time there I helped them build an analytics pipeline from scratch using Python + SQL. I contributed quite a bit to the feature engineering steps that would later be part of the final analytics program used across Emirates NBD.</li> </ul> <p>In my work at Emirates NBD (one of the largest banks in Dubai), the team was attempting to improve an analytics pipeline to identify fraudulent transactions. While the pipeline worked reasonably well, they were using a Microsoft service to do the analytics, and the performance was not great. In my time there, I helped them build an analytics pipeline from scratch using Python + SQL. I contributed quite a bit to the feature engineering steps that would later be part of the final analytics program used across Emirates NBD. Many of those changes led to improving the final accuracy by a decent amount and made it much easier for my coworkers to push the product to the upper management.</p>"},{"location":"KB/Poki%20Data%20Scientist/#when-you-look-at-the-presentation-of-content-on-our-platform-what-question-comes-to-mind","title":"When You Look at the Presentation of Content on Our Platform, what Question Comes to Mind?","text":"<ul> <li>Clustered, icons are similar</li> <li>Computer vision + analytics: Check for something like that. </li> <li>Given an example</li> </ul> <p>While Poki looks great, one thing that immediately comes to mind is that many of the icons are rather visually similar (eg : Apple Knight, Apple Knight mini dungeons ; Mekabolt, Day of Meat). There are also a lot of icons immediately, which is slightly overwhelming.  This is unintentional, of course, but might make it harder for a user to pick what they want. Using a computer vision similarity technique could be useful in identifying them and pushing them somewhere else on the grid. This would be something that I would love to discuss as well.</p>"},{"location":"KB/Polynomial%20Trajectories/","title":"Polynomial Trajectories","text":""},{"location":"KB/Polynomial%20Trajectories/#polynomial-trajectories","title":"Polynomial Trajectories","text":""},{"location":"KB/Polysynthetic%20words/","title":"Polysynthetic words","text":""},{"location":"KB/Polysynthetic%20words/#polysynthetic-words","title":"Polysynthetic Words","text":"<ul> <li>complex words that function as a sentence (Chukchi and Inuktitut)</li> </ul>"},{"location":"KB/Pooling/","title":"Pooling","text":""},{"location":"KB/Pooling/#pooling","title":"Pooling","text":"<ul> <li>Summarize low level features</li> <li>Reduce input dims</li> <li>Max/Avg</li> <li>Too much pooling reduces performance<ul> <li>Multiple convs first</li> </ul> </li> <li>Max pool + dilated/Strided convs control effective receptive field size</li> </ul>"},{"location":"KB/Population%20Based%20Augmentation/","title":"Population Based Augmentation","text":""},{"location":"KB/Population%20Based%20Augmentation/#population-based-augmentation","title":"Population Based Augmentation","text":"<ul> <li>PBA can match the performance of AutoAugment on multiple datasets with less computation time</li> </ul>"},{"location":"KB/Population%20Correlation/","title":"Population Correlation","text":"<p>toc: true title: Population Correlation</p> <p>categories: ['temp']</p>"},{"location":"KB/Population%20Correlation/#population-correlation","title":"Population Correlation","text":"<ul> <li> \\[\\rho_{xy}= \\frac{\\sigma_{xy}}{\\sigma_{x}\\sigma_{y}}\\] </li> <li>\\(\\sigma\\) is the Standard Deviation</li> <li>\\(\\sigma_{xy}\\) is the Covariance</li> </ul>"},{"location":"KB/Position%20Encoding/","title":"Position Encoding","text":""},{"location":"KB/Position%20Encoding/#position-encoding","title":"Position Encoding","text":"<ul> <li>Transformers are feed forward. So need a way to inject position into seq</li> <li> \\[PE(pos, 2i) = sin(\\frac{pos}{10000^\\frac{2i}{d_{model}}})\\] </li> <li> \\[PE(pos, 2i+1) = cos(\\frac{pos}{10000^\\frac{2i}{d_{model}}})\\] </li> <li>Conceptually, adding word order to a sentence<ul> <li>Something like (\"Hello\", 1) , (\"from\",2) , (\"me\", 3)</li> </ul> </li> </ul>"},{"location":"KB/Position%20Wise%20Feed%20Forward/","title":"Position Wise Feed Forward","text":""},{"location":"KB/Position%20Wise%20Feed%20Forward/#position-wise-feed-forward","title":"Position Wise Feed Forward","text":"<ul> <li> \\[FFN(x) = max(0, xW_{1}+b_{1})W_{2}+b_{2}\\] </li> <li>Dense Layers are applied along the last (512) dims</li> </ul>"},{"location":"KB/Positron%20Emission%20Tomography%20%28PET%29/","title":"Positron Emission Tomography (PET)","text":""},{"location":"KB/Positron%20Emission%20Tomography%20%28PET%29/#positron-emission-tomography-pet","title":"Positron Emission Tomography (PET)","text":"<ul> <li>An imaging technique, often used in brain imaging. For a PET scan of the brain, a radioactive \u201cmarker\u201d that emits, or releases, positrons (parts of an atom that release gamma radiation) is injected into the bloodstream. Detectors outside of the head can sense these \u201cpositron emissions,\u201d which are then reconstructed using sophisticated computer programs to create computer images. Since blood flow and metabolism increase in brain regions at work, those areas have higher concentrations of the marker, and researchers can see which brain regions activate during certain tasks or exposure to sensory stimuli. Ligands can be added to a PET scan to detect pathological entities such as amyloid or tau deposits.</li> </ul>"},{"location":"KB/Post%20Classification/","title":"Post Classification","text":""},{"location":"KB/Post%20Classification/#post-classification","title":"Post Classification","text":"<ul> <li>Interpolation of scalars at several vertices</li> <li>Classification via Transfer Function</li> <li></li> </ul>"},{"location":"KB/Post-processing%20Your%20Model%27s%20Output/","title":"Post processing Your Model's Output","text":""},{"location":"KB/Post-processing%20Your%20Model%27s%20Output/#post-processing-your-models-output","title":"Post-processing Your Model's Output.","text":"<ul> <li>Altering the loss function to incorporate a penalty for violating a fairness metric.</li> <li>Directly adding a mathematical constraint to an optimization problem.</li> <li>A synthetic feature formed by crossing (taking a Cartesian product of) individual binary features obtained from categorical data or from continuous features via bucketing. Feature crosses help represent nonlinear relationships.</li> </ul>"},{"location":"KB/Postattentive%20Amnesia/","title":"Postattentive Amnesia","text":""},{"location":"KB/Postattentive%20Amnesia/#postattentive-amnesia","title":"Postattentive Amnesia","text":"<ul> <li>No additional information is saved in the visual system between different scenes</li> </ul>"},{"location":"KB/Posterior%20Mean%20estimate/","title":"Posterior Mean Estimate","text":""},{"location":"KB/Posterior%20Mean%20estimate/#posterior-mean-estimate","title":"Posterior Mean Estimate","text":"<ul> <li>If need a single, definite model estimate -&gt; Get mean value of posterior \\(\\(\\hat \\theta = \\theta^{PME} = \\int_{\\mathbb{R}^{K}}\\theta h(\\theta|D)d\\theta\\)\\)</li> </ul>"},{"location":"KB/Postsynaptic%20Cell/","title":"Postsynaptic Cell","text":""},{"location":"KB/Postsynaptic%20Cell/#postsynaptic-cell","title":"Postsynaptic Cell","text":"<ul> <li>The neuron on the receiving end of a nerve impulse transmitted from another neuron.</li> </ul>"},{"location":"KB/Power%20and%20Force%20Limiting%20%28PFL%29/","title":"Power and Force Limiting (PFL)","text":""},{"location":"KB/Power%20and%20Force%20Limiting%20%28PFL%29/#power-and-force-limiting-pfl","title":"Power and Force Limiting (PFL)","text":"<ul> <li>Collaborative feature that allows both the operator and robot to work in proximity to one another by ensuring the robot will slow down and stop before a contact situation occurs. In order for this feature to be safely implemented, functional safety and additional detection hardware must be used. A risk assessment shall be used determine if any additional safeguarding is necessary to mitigate risks within the robot system.</li> </ul>"},{"location":"KB/Power/","title":"Power","text":""},{"location":"KB/Power/#power","title":"Power","text":"<ul> <li>current x potential difference</li> <li> \\[P = IV\\] </li> </ul>"},{"location":"KB/Pragmatics/","title":"Pragmatics","text":""},{"location":"KB/Pragmatics/#pragmatics","title":"Pragmatics","text":"<ul> <li>Important relationships that may hold between phrases and parts of their discourse context</li> <li>Parts of entities</li> <li>Parts of action</li> <li>Entities involving in actions</li> <li>Elements of sets</li> <li>Names of individuals</li> </ul>"},{"location":"KB/Pre%20Classification/","title":"Pre Classification","text":""},{"location":"KB/Pre%20Classification/#pre-classification","title":"Pre Classification","text":"<ul> <li>Classification of scalars at each sample via Transfer Function</li> <li>Interpolation of RGBA values</li> <li></li> </ul>"},{"location":"KB/Pre%20Integrated%20Volume%20Rendering/","title":"Pre Integrated Volume Rendering","text":""},{"location":"KB/Pre%20Integrated%20Volume%20Rendering/#pre-integrated-volume-rendering","title":"Pre Integrated Volume Rendering","text":"<ul> <li>Assume<ul> <li>Linear interpolations of scalar values in a ray segment</li> <li>Constant length of ray segment L</li> </ul> </li> <li>Pre computation from a slab</li> <li> \\[s_{L}(t) = s_{b}+ \\frac{t}{L}(s_{f}-s_{b})\\] </li> <li>becomes</li> <li> \\[c_{i}= \\int_{0}^{L}g(t)e^{-\\int_{t}^{L}{\\kappa(t')d_{t}}}dt' \\] </li> <li> \\[o_{i}= e^{\\int_{0}^{L}\\kappa(t)}d_{t} \\] </li> <li></li> </ul>"},{"location":"KB/Preattentive%20Processing/","title":"Preattentive Processing","text":""},{"location":"KB/Preattentive%20Processing/#preattentive-processing","title":"Preattentive Processing","text":"<ul> <li>some visual properties are detected very rapidly and in parallel by low level visual processes</li> <li></li> </ul>"},{"location":"KB/Precision%20Recall%20Curve/","title":"Precision Recall Curve","text":""},{"location":"KB/Precision%20Recall%20Curve/#precision-recall-curve","title":"Precision Recall Curve","text":"<ul> <li>Precision + Recall</li> <li>appropriate when dataset imbalanced</li> <li>no-skill line changes based on the distribution of the positive to negative classes<ul> <li>horizontal line with the value of the ratio of positive cases in the dataset</li> <li>balanced this is 0.5</li> </ul> </li> <li>skilful model is represented by a curve that bows towards (1,1) above the flat line of no skill</li> </ul>"},{"location":"KB/Precision/","title":"Precision","text":""},{"location":"KB/Precision/#precision","title":"Precision","text":"<ul> <li> \\[\\frac{TP}{TP+FP}\\] </li> <li>How many samples are actually positive out of the total number of predicted positive samples? -&gt; How precise is the model in predicting positive samples?</li> </ul>"},{"location":"KB/Predicate/","title":"Predicate","text":""},{"location":"KB/Predicate/#predicate","title":"Predicate","text":"<ul> <li>the part of a sentence or clause containing a verb and stating something about the subject (e.g.\u00a0went home\u00a0in\u00a0John went home\u00a0)</li> </ul>"},{"location":"KB/Predicting%20Student%20learning%20Curve/","title":"Predicting Student learning Curve","text":""},{"location":"KB/Predicting%20Student%20learning%20Curve/#predicting-student-learning-curve","title":"Predicting Student Learning Curve","text":"<ul> <li>(Croteau, Heffernan, &amp; Koedinger, 2004).</li> <li>The learning curve of a Knowledge Component graphs the durations of its learning events (or their probability of error).</li> <li>a learning curve should be a smoothly descending power-law or exponential curve</li> <li>For instance, the first Learning Event for a Knowledge Component may take 50 seconds, because the student is constructing the Knowledge Component by referring to the textbook and asking the tutoring system for help. The next Learning Event might take only 25 seconds because the student is reconstructing the Knowledge Component. On the third Learning Event, the student recalls the Knowledge Component after a brief struggle, so the event takes 12 seconds. The fourth event takes 6 seconds, the fifth takes 3 seconds, and so on. However, if the representation of knowledge is inaccurate, a Knowledge Component's learning curve may have a huge jump in the middle or be quite jagged</li> </ul>"},{"location":"KB/Prediction%20Difference%20Analysis/","title":"Prediction Difference Analysis","text":""},{"location":"KB/Prediction%20Difference%20Analysis/#prediction-difference-analysis","title":"Prediction Difference Analysis","text":"<ul> <li>Their goal was to improve and interpret DNNs. Their technique was based on the univariate approach of [94] and the idea that the relevance of an input feature with respect to a class can be estimated by measuring how the prediction changes if the feature is removed. Zintgraf et al. removed several features at one time using their knowledge about the images by strategically choosing patches of connected pixels as the feature sets. Instead of going through all individual pixels, they considered all patches of a special size implemented in a sliding window fashion. They visualized the effects of different window sizes and marginal versus conditional sampling and displayed feature maps of different hidden layers and top-scoring classes.</li> </ul>"},{"location":"KB/Prediction%20assumption/","title":"Prediction assumption","text":""},{"location":"KB/Prediction%20assumption/#prediction-assumption","title":"Prediction Assumption","text":"<ul> <li>every model that aims to predict an output Y from an input X makes the assumption that it's possible to predict Y based on X.</li> </ul>"},{"location":"KB/Predictive%20Parity/","title":"Predictive Parity","text":""},{"location":"KB/Predictive%20Parity/#predictive-parity","title":"Predictive Parity","text":"<ul> <li>A fairness metric that checks whether, for a given classifier, the precision rates are equivalent for subgroups under consideration.</li> </ul>"},{"location":"KB/Predictive%20Uncertainty/","title":"Predictive Uncertainty","text":""},{"location":"KB/Predictive%20Uncertainty/#predictive-uncertainty","title":"Predictive Uncertainty","text":""},{"location":"KB/Preferences%20and%20ethical%20principles%20in%20decision%20making/","title":"Preferences and ethical principles in decision making","text":""},{"location":"KB/Preferences%20and%20ethical%20principles%20in%20decision%20making/#preferences-and-ethical-principles-in-decision-making","title":"Preferences and Ethical Principles in Decision Making","text":"<ul> <li>Andrea Loreggia, Nicholas Mattei, Francesca Rossi, and Kristen Brent Venable.</li> <li>leverage the CP-net formalism to represent the exogenous ethics priorities and endogenous subjective preferences</li> <li>distance between CPnets so as to enable AI agents to make decisions using their subjective preferences if they are close enough to the ethical principles</li> </ul>"},{"location":"KB/Prefix/","title":"Prefix","text":""},{"location":"KB/Prefix/#prefix","title":"Prefix","text":"<ul> <li>precede the stem: do / undo</li> </ul>"},{"location":"KB/Prepositions/","title":"Prepositions","text":""},{"location":"KB/Prepositions/#prepositions","title":"Prepositions","text":"<ul> <li>relates phrases (at, on, of, about)</li> </ul>"},{"location":"KB/Presence-sensing%20Safeguarding%20Device/","title":"Presence sensing Safeguarding Device","text":""},{"location":"KB/Presence-sensing%20Safeguarding%20Device/#presence-sensing-safeguarding-device","title":"Presence-sensing Safeguarding Device","text":"<ul> <li>A device designed, constructed and installed to create a sensing field to detect an intrusion into such field by people, robots or objects</li> </ul>"},{"location":"KB/Pressure%20%3D%20ForceArea/","title":"Pressure = ForceArea","text":""},{"location":"KB/Pressure%20%3D%20ForceArea/#pressure-forcearea","title":"Pressure = Force/Area","text":"<ul> <li> \\[P = \\frac{F}{A}\\] </li> </ul>"},{"location":"KB/Presynaptic%20Cell/","title":"Presynaptic Cell","text":""},{"location":"KB/Presynaptic%20Cell/#presynaptic-cell","title":"Presynaptic Cell","text":"<ul> <li>In synaptic transmission, the neuron that sends a nerve impulse across the synaptic cleft to another neuron.</li> </ul>"},{"location":"KB/Pretext%20Task/","title":"Pretext Task","text":""},{"location":"KB/Pretext%20Task/#pretext-task","title":"Pretext Task","text":"<ul> <li>pre-designed tasks </li> <li>visual features are learned by learning objective functions of pretext tasks</li> </ul>"},{"location":"KB/Pretext%20Tasks/","title":"Pretext Tasks","text":""},{"location":"KB/Pretext%20Tasks/#pretext-tasks","title":"Pretext Tasks","text":"<ul> <li> <p>Image Generation</p> </li> <li> <p>Video Generation</p> </li> <li> <p>Context Similarity</p> </li> <li> <p>Spatial Context Structure</p> </li> <li> <p>Temporal Context Structure</p> </li> <li> <p>Free Semantic Label-based Method</p> </li> <li> <p>Cross Modal-based Methods</p> </li> <li> <p>Semantic Segmentation</p> </li> <li> <p>Object Detection</p> </li> <li> <p>Image Classification</p> </li> <li> <p>Human Action Recognition </p> </li> <li> <p>Kernel Visualization</p> </li> <li> <p>Feature Map Visualization</p> </li> <li> <p>Nearest Neighbor Retrieval</p> </li> </ul>"},{"location":"KB/Primary%20Capsule/","title":"Primary Capsule","text":""},{"location":"KB/Primary%20Capsule/#primary-capsule","title":"Primary Capsule","text":"<ul> <li>lowest layer of a capsule network </li> <li>processing the\u00a0raw input image</li> <li>Each capsule in the primary layer is sensitive to a specific feature of the input image, such as an edge or a particular shape.</li> </ul>"},{"location":"KB/Primary%20Capsule/#convolution","title":"Convolution","text":"<ul> <li>The primary capsules in a capsule network are created by applying a series of convolutional filters to the input image. Each filter is responsible for detecting a specific feature in the input image, such as an edge or a particular shape.</li> </ul>"},{"location":"KB/Primary%20Capsule/#reshape","title":"Reshape","text":"<ul> <li>The outputs of the convolutional filters are then reshaped into a grid of \u201ccapsules,\u201d each of which corresponds to a specific location in the input image.</li> </ul>"},{"location":"KB/Primary%20Capsule/#squash","title":"Squash","text":"<ul> <li>The outputs of the capsules are then \u201csquashed\u201d to ensure that they have a non-negative scalar value, which allows the network to learn more easily to differentiate between objects and background.</li> </ul>"},{"location":"KB/Prion/","title":"Prion","text":""},{"location":"KB/Prion/#prion","title":"Prion","text":"<ul> <li>A protein aggregate that can multiply itself, inducing the formation of new aggregates from individual copies of the protein it encounters. Prions have the potential to spread within the body and brain, and even from one organism to another\u2014\u201cinfectiously,\u201d like a virus. The first prions described were hardy aggregates of PrP, the prion protein. They are responsible for a set of rapid, fatal, and potentially transmissible neurodegenerative diseases including Creutzfeldt-Jakob disease and bovine spongiform encephalopathy (\u201cmad cow disease\u201d). Many researchers now argue that protein aggregates in other neurodegenerative diseases, such as the A\u03b2 and tau plaques of Alzheimer\u2019s, have such similar properties that they also deserve to be called prions.</li> </ul>"},{"location":"KB/Prismatic%20Joint/","title":"Prismatic Joint","text":""},{"location":"KB/Prismatic%20Joint/#prismatic-joint","title":"Prismatic Joint","text":"<ul> <li>Linear movement like a piston</li> </ul>"},{"location":"KB/Privacy%20awareness/","title":"Privacy awareness","text":""},{"location":"KB/Privacy%20awareness/#privacy-awareness","title":"Privacy awareness","text":"<ul> <li>ML models may have complex representations of their learned patterns</li> <li>the ability to explain the inner relations of a trained model by non-authorized third parties may also compromise the differential privacy of the data origin</li> </ul>"},{"location":"KB/Probability/","title":"Probability","text":""},{"location":"KB/Probability/#probability","title":"Probability","text":"<ul> <li>Frequentist</li> <li>Bayesian</li> </ul>"},{"location":"KB/Problems%20facing%20MLOps/","title":"Problems facing MLOps","text":"","tags":["mlops"]},{"location":"KB/Problems%20facing%20MLOps/#problems-facing-mlops","title":"Problems Facing MLOps","text":"","tags":["mlops"]},{"location":"KB/Problems%20facing%20MLOps/#general","title":"General","text":"<ul> <li>Coding is not the whole story</li> <li>It\u2019s easier for great engineers to pick up ML knowledge, but it\u2019s a lot harder for ML experts to become great engineers.</li> <li>Use \"off the shelf models\"</li> <li>Companies focus on improving data, but not model</li> <li>Model sizes are hard</li> <li>Dataset/model versioning is hard</li> <li>Experiment Tracking<ul> <li>Hyperparameter tuning is important and it\u2019s not surprising to find several that focus on it, </li> <li>none seems to catch on because the bottleneck for hyperparameter tuning is not the setup, but the computing power needed to run it.</li> </ul> </li> <li>Data monitoring<ul> <li>Distribution shift</li> </ul> </li> <li>Labelling<ul> <li>How often do we need to re-label</li> </ul> </li> <li>CI/CD<ul> <li>Testing</li> <li>Re-train model</li> </ul> </li> <li>Deployment<ul> <li>How often to package and deploy</li> <li>One reason for the lack of serving solutions is the lack of communication between researchers and production engineers.</li> <li>Small companies, whose employees can see the entire stack, are constrained by their immediate product needs</li> </ul> </li> <li>Model Compression<ul> <li>Compress ML Models</li> </ul> </li> <li>Optimizing Inference</li> <li>Edge devices</li> <li>Privacy<ul> <li>GDPR</li> </ul> </li> <li>OSS vs Open Core<ul> <li>Since OSS has become a standard, it\u2019s challenging for startups to figure out a business model that works.</li> <li>Any tooling company started has to compete with existing open-source tools.</li> </ul> </li> </ul>","tags":["mlops"]},{"location":"KB/Programmable%20Logical%20Controller%20%28PLC%29/","title":"Programmable Logical Controller (PLC)","text":""},{"location":"KB/Programmable%20Logical%20Controller%20%28PLC%29/#programmable-logical-controller-plc","title":"Programmable Logical Controller (PLC)","text":"<ul> <li>A solid-state control system, which has a user programmable memory for storage of instructions to implement specific functions such as: I/O control logic, timing, counting arithmetic and data manipulation</li> <li>A PLC consists of a central processor, input/output interface, memory and programming device, which typically uses relay equivalent symbols.</li> </ul>"},{"location":"KB/PromptIR/","title":"PromptIR","text":""},{"location":"KB/PromptIR/#promptir","title":"PromptIR","text":"<ul> <li>Summary : Summary : Uses a transformer network to prediction a \"prompt\" that says how degraded an image is. And based on that, decides what module to use. </li> <li>Deep learning-based methods have significantly improved image restoration performance, however, they have limited generalization ability to different degradation types and levels </li> <li>requires training individual models for each specific degradation and knowing the input degradation type to apply the relevant model. </li> <li>prompt-based learning approach, PromptIR, for All-In-One image restoration that can effectively restore images from various types and levels of degradation </li> <li>uses prompts to encode degradation-specific information </li> <li>generic and efficient plugin module with few lightweight prompts that can be used to restore images of various types and levels of degradation with no prior information on the corruptions present in the image  </li> <li> </li> <li>AirNet </li> <li>addresses the all-in-one restoration task by employing the contrastive learning paradigm. </li> <li>involves training an extra encoder to differentiate various types of image degradations </li> <li>Although AirNet [29] yields state-of-the-art results, it struggles to model fully disentangled representations of different corruption types </li> <li>Furthermore, the usage of an additional encoder for contrastive learning leads to a higher training burden due to the two-stage training approach. </li> </ul>"},{"location":"KB/PromptIR/#method","title":"Method","text":"<ul> <li>While the model is initially \"blind\" to the nature of degradation, its performance in recovering a clean image can be enhanced by providing implicit contextual information about the type of degradation  </li> <li> </li> <li>From a given degraded input image I \u2208 RH \u00d7W \u00d73 </li> <li>first extracts low-level features F0 \u2208 RH\u00d7W\u00d7C by applying a convolution operation; where H \u00d7 W is the spatial resolution and C denotes the channels. </li> <li>eature embeddings F0 undergo a 4-level hierarchical encoder-decoder, transforming into deep features Fr \u2208 RH \u00d7W \u00d72C </li> <li> </li> <li>Starting from the high-resolution input, the goal of the encoder is to progressively reduce the spatial resolution while . </li> <li>From the low-resolution latent features Fl, the aim of the decoder is to gradually recover the highresolution clean output </li> <li>ncorporate prompt block </li> <li>Prompt blocks are adapter modules that sequentially connect every two levels of the decoder. </li> </ul>"},{"location":"KB/PromptIR/#aim-to-learn-a-single-model-m-to-restore-an-image-i-from-a-degraded-image-i-that-has-been-degraded-using-a-degradation-d-while-having-no-prior-information-about-d","title":"aim to learn a single model M to restore an image I from a degraded image I, that has been degraded using a degradation D, while having no prior information about D.","text":""},{"location":"KB/PromptIR/#each-level-of-the-encoder-decoder-employs-several-transformer-blocks-with-the-number-of-blocks-gradually-increasing-from-the-top-level-to-the-bottom-level-to-maintain-computational-efficiency","title":"Each level of the encoder-decoder employs several Transformer blocks, with the number of blocks gradually increasing from the top level to the bottom level to maintain computational efficiency.","text":""},{"location":"KB/PromptIR/#prompt-block","title":"Prompt Block","text":""},{"location":"KB/PromptIR/#prompt-generation-module","title":"Prompt Generation Module","text":"<ul> <li>Prompt components Pc form a set of learnable parameters that interact with the incoming features to embed degradation information </li> <li>features-prompt interaction is to directly use the learned prompts to calibrate the features. </li> <li> </li> <li>shared space to facilitate correlated knowledge sharing among prompt components. </li> <li>To generate prompt-weights from the input features Fl </li> <li>first applies global average pooling (GAP) across spatial dimension to generate feature vector v 2 RC\u02c6 </li> <li>pass v through a channeldownscaling convolution layer to obtain a compact feature vector, followed by the softmax operation, thus yielding prompt-weights w 2 RN </li> <li>use these weights to make adjustments in prompt components, followed by a 3 x 3 convolution layer  </li> <li> </li> <li>Since at inference time, it is necessary for the restoration network to be able to handle images of different resolutions, we cannot use the prompt components Pc with a fixed size. </li> <li>bilinear upsampling operation to upscale the prompt components </li> </ul>"},{"location":"KB/PromptIR/#dynamically-predicts-attention-based-weights-from-the-input-features-and-apply-them-to-prompt-components-to-yield-input-conditioned-prompts-p","title":"dynamically predicts attention-based weights from the input features and apply them to prompt components to yield input-conditioned prompts P","text":""},{"location":"KB/PromptIR/#prompt-interaction-module","title":"Prompt Interaction Module","text":"<ul> <li>enable interaction between the input features Fl and prompts P for a guided restoration. </li> <li> </li> <li>pass the concatenated representations through a Transformer block that exploits degradation information encoded in the prompts and transforms the input features. </li> <li>The Transformer block is composed of two sequentially connected sub-modules: Multi-Dconv head transposed attention (MDTA), and Gated-Dconv feedforward network (GDFN). MDTA applies self-attention operation across channels rather than the spatial dimension and has linear complexity. </li> <li>The goal of GDFN is to transform features in a controlled manner, i.e., suppressing the less informative features and allowing only useful ones to propagate through the network  </li> <li> </li> <li> </li> </ul>"},{"location":"KB/PromptIR/#in-pim-we-concatenate-the-generated-prompts-with-the-input-features-along-the-channel-dimension","title":"In PIM, we concatenate the generated prompts with the input features along the channel dimension.","text":""},{"location":"KB/PromptIR/#_1","title":"PromptIR","text":"<ul> <li>Implementation Details </li> <li>end-to-end trainable and requires no pretraining of any individual component </li> <li>4-level encoder-decoder, with varying numbers of Transformer blocks at each level, specifically [4, 6, 6, 8] from level-1 to level-4. </li> <li>one prompt block between every two consecutive decoder levels, totaling 3 prompt blocks in the overall PromptIR network </li> <li>The total number of prompt components are 5 </li> <li>The model is trained with a batch size of 32 in the all-in-one setting, and with a batch of 8 in the single-task setting </li> <li>The network is optimized with an L1 loss, and we use Adam optimizer (1 = 0.9, 2 = 0.999) with learning rate 2e 4 for 200 epochs. </li> <li> </li> <li>BSD400 </li> <li>WED </li> <li>o </li> <li>BSD68 </li> <li>Urban100 </li> <li>Rain100L </li> <li>SOTS  </li> <li> </li> <li> </li> <li> </li> </ul>"},{"location":"KB/PromptIR/#cropped-patches-of-size-128-x-128","title":"cropped patches of size 128 x 128","text":""},{"location":"KB/Propose-but-verify/","title":"Propose-but-verify","text":""},{"location":"KB/Propose-but-verify/#propose-but-verify","title":"Propose-but-verify","text":"<ul> <li>Speakers guess a word-concept association</li> <li>Keep guess until they encounter contradicting information</li> <li>Seems to correctly model competitions between features/cues</li> </ul>"},{"location":"KB/Protein%20Folding/","title":"Protein Folding","text":""},{"location":"KB/Protein%20Folding/#protein-folding","title":"Protein Folding","text":"<ul> <li>The process by which the chain of amino acids that make up a protein assumes its functional shape. The protein clumps and tangles that occur in some neurodegenerative disorders are thought to be triggered when proteins \u201cmisfold.\u201d</li> </ul>"},{"location":"KB/Protein%20Modeling/","title":"Protein Modeling","text":""},{"location":"KB/Protein%20Modeling/#protein-modeling","title":"Protein Modeling","text":"<ul> <li>Using Bayesian models</li> <li>Task : Estimate Probability mass function(because discrete) for a finite, discrete distribution -&gt; given a histogram from a sample</li> <li>Large number of categories and small number of observations</li> <li><ul> <li>Estimate Probability distrib of amino acids in each column in a protein class. 20 dim PMF (one for each site)</li> <li>Can be aligned</li> <li>High chances of class not being present in data<ul> <li>MLE will assign 0 Probability to X</li> <li>Wrong decision made for a lot of them that were not in the training set</li> <li>Cannot use</li> </ul> </li> </ul> </li> <li>20 dim PMF for amnio acid distrib : \\(\\theta = (\\theta_{1}, \u2026 ,\\theta_{20})' = (P(X=A), \u2026, P(X=Y))'\\)<ul> <li>count vectors of amino acids found in a given site in training data D</li> <li>Distributed according to Multinomial Distribution with l = 20</li> </ul> </li> </ul>"},{"location":"KB/Protein%20Modeling/#using-prior","title":"Using Prior","text":"<ul> <li>0 probabilities should not occur. (\\(\\mathcal{H} = (\\theta_{1}, \u2026, \\theta_{20})' \\in \\mathbb{R}^{20}|\\theta_{j} \\in (0,1)\\)\\) and $$ \\Sigma_{j} \\theta_{j}=1$$<ul> <li>19 dim hypervolume</li> <li>Continuous space and so can use PDF</li> <li>Dirichlet Distribution is used to represent it because parameterized with l = 20</li> </ul> </li> <li></li> <li>\\(\\alpha\\)s fixed beforehand</li> </ul>"},{"location":"KB/Proto%20Distributions/","title":"Proto Distributions","text":""},{"location":"KB/Proto%20Distributions/#proto-distributions","title":"Proto Distributions","text":"<ul> <li>Distributions</li> <li>Occur in Bayesian</li> </ul>"},{"location":"KB/Proto%20Distributions/#continuous-spaces","title":"Continuous Spaces","text":"<ul> <li>Proto PDF</li> <li> \\[p(x|\\theta) = \\frac{1}{\\int_{\\mathbb{R}^{k}}p_{0}(x| \\theta)dx}p_{0}(x|\\theta)\\] </li> <li>\\(p_{0}\\) gives the shape of the PDF</li> <li>\\(\\frac{1}{\\int_{\\mathbb{R}^{k}}p_{0}(x| \\theta)dx}\\) is a normalization so it integrates to 1</li> <li></li> <li>Most of the time we dont know a distribution but only its proto distribution. This is actually enough sometimes</li> </ul>"},{"location":"KB/Proto%20Distributions/#discrete-spaces","title":"Discrete Spaces","text":"<ul> <li>Proto PMF</li> </ul>"},{"location":"KB/Proto%20PDF/","title":"Proto PDF","text":""},{"location":"KB/Proto%20PDF/#proto-pdf","title":"Proto PDF","text":"<ul> <li>Generalized PDF</li> <li>Proto PDF \\(g_{0}\\)</li> <li>Any non negative function \\(g_{0}: \\mathbb{R}^{n} \\rightarrow \\mathbb{R}\\) that has a finite integral \\(\\(\\int_{\\mathbb{R}^{n}}g_{0}(x)dx\\)\\)</li> <li>If we divide \\(g_{0}\\) by its integral -&gt; we get a normal PDF g</li> </ul>"},{"location":"KB/Proto%20PMF/","title":"Proto PMF","text":""},{"location":"KB/Proto%20PMF/#proto-pmf","title":"Proto PMF","text":"<ul> <li>Generalized PMF</li> <li> \\[p(x|\\theta) = \\frac{1}{\\Sigma_{x \\in S}p_{0}(s)}p_{0}(x)\\] </li> <li>S is huge if there are many random variables</li> </ul>"},{"location":"KB/Proximity%20Sensor/","title":"Proximity Sensor","text":""},{"location":"KB/Proximity%20Sensor/#proximity-sensor","title":"Proximity Sensor","text":"<ul> <li>A non-contact sensing device used to sense when objects are a short distance away, and it can determine the distance of the object.</li> </ul>"},{"location":"KB/Proxy%20Attention/","title":"Proxy Attention","text":""},{"location":"KB/Proxy%20Attention/#proxy-attention","title":"Proxy Attention","text":"<ul> <li>Let \\(I_{s} \\in \\mathbb{R}^{W \\times H \\times C}\\) be a random source image</li> <li>applied saliency map \\(I_{vs}\\) <ul> <li>\\(I_{vs} = f(I_{s}) \\in \\mathbb{R}^{W \\times H}\\)</li> <li>Augmented image \\(I_{a}\\)</li> <li>\\(\\odot\\) elementwise multi </li> <li>Mask \\(M \\in \\{0,1\\}^{W \\times H}\\) </li> </ul> </li> </ul>"},{"location":"KB/Proxy%20Objective/","title":"Proxy Objective","text":""},{"location":"KB/Proxy%20Objective/#proxy-objective","title":"Proxy Objective","text":"<ul> <li>Easier to change or measure than the actual objective</li> <li>Suppose we have some sample space \\(S\\) (such as the set of possible question-answer pairs), some Probability distribution \\(P\\) over \\(S\\), a true objective (or \u201creward\u201d) \\(R_{true}: S \\to \\mathbb{R}\\) , proxy objective \\(R_{proxy}:S \\to \\mathbb{R}\\) and we optimize \\(R_{proxy}\\) to get a new distribution \\(P'\\)</li> <li>\\(E_{x'\\sim P'}[Rtrue(x\u2032)]\\) is how well the true objective is optimized<ul> <li>Monte Carlo estimator used</li> <li>If \\(N \\geq n\\) samples from P, simultaneously consider every possible subset of these samples of size nnn, weight each sample by the number of subsets for which it is the best according to the proxy objective, and then take the weighted average true objective \\(\\(\\binom{k-1}{n-1}\\)\\) where k is the rank of the sample under the proxy objective, from 1 (worst) up to N (best)</li> <li>Can reuse samples of n</li> </ul> </li> <li>KL Divergence \\(P' || P\\) measures how much optimization is done<ul> <li>As long as Continous , \\(\\(n - \\frac{n-1}{n}\\)\\)</li> </ul> </li> </ul>"},{"location":"KB/Proxy%20Objective/#refs","title":"Refs","text":"<ul> <li>openai</li> </ul>"},{"location":"KB/Proxy%20features/","title":"Proxy features","text":""},{"location":"KB/Proxy%20features/#proxy-features","title":"Proxy Features","text":"<ul> <li>there may be correlated features with sensitive ones that can induce bias even when the sensitive features are not present in the dataset.</li> </ul>"},{"location":"KB/Pruning/","title":"Pruning","text":""},{"location":"KB/Pruning/#pruning","title":"Pruning","text":"<ul> <li>Mainly that of being able to reduce the size, cost and computational requirements of my models, all while maintaning the accuracy (sort of atleast).</li> <li>Generally this comes about by removing parameters in some form or fashion.</li> <li>Rather than taking a mask, we can prune certain parts of the network by setting them to 0 or by dropping them if required. (aka weights and biases)</li> <li>In most cases, the network is first trained for a while. Then pruned. Which reduces its accuracy and is thus trained again (fine tuning). This cycle is repeated until we get the results we require.</li> <li>Major Types of Pruning Methods</li> <li>Structure Based Pruning</li> <li>Scoring Pruning Approaches</li> <li>Scheduling</li> <li>Fine Tuning Based Pruning</li> <li>Global Magnitude Based Pruning</li> <li>Global Gradient Magnitude Based Pruning</li> <li>Layerwise Gradient Magnitude Based Pruning</li> <li>Random Pruning</li> <li>Layerwise Magnitude Based Pruning</li> </ul>"},{"location":"KB/Pseudo%20Label/","title":"Pseudo Label","text":""},{"location":"KB/Pseudo%20Label/#pseudo-label","title":"Pseudo Label","text":"<ul> <li>Pseudo labels are automatically generated labels based on data attributes for pretext tasks</li> </ul>"},{"location":"KB/Psycholinguistics/","title":"Psycholinguistics","text":""},{"location":"KB/Psycholinguistics/#psycholinguistics","title":"Psycholinguistics","text":"<ul> <li>The study of how the brain processes or produces language</li> <li>Linguistics proper is more concerned with what the structure of language is</li> <li>Also examines how linguistic processing interacts with executive functions, e.g. \u2022 Working memory \u2022 Inhibition</li> </ul>"},{"location":"KB/Psychosis/","title":"Psychosis","text":""},{"location":"KB/Psychosis/#psychosis","title":"Psychosis","text":"<ul> <li>A severe symptom of mental illness in which a person\u2019s thoughts and perceptions are so disordered that the individual loses touch with reality.</li> </ul>"},{"location":"KB/Pulse%20Coordinates/","title":"Pulse Coordinates","text":""},{"location":"KB/Pulse%20Coordinates/#pulse-coordinates","title":"Pulse Coordinates","text":"<ul> <li>Yaskawa robots define robot joint axes position in degrees for revolute joints. Pulse is also another way to specify robot joint position, and it does so in robot motor encoder pulse counts.</li> </ul>"},{"location":"KB/Pulse%20Oximeter/","title":"Pulse Oximeter","text":""},{"location":"KB/Pulse%20Oximeter/#pulse-oximeter","title":"Pulse Oximeter","text":"<ul> <li>A small device that clips to the finger, toe or earlobe used to measure blood oxygen saturation</li> </ul>"},{"location":"KB/Punctuation/","title":"Punctuation","text":""},{"location":"KB/Punctuation/#punctuation","title":"Punctuation","text":"<ul> <li>Punctuation characters are treated as separate tokens \u2013 usually</li> </ul>"},{"location":"KB/Pupil%20Dilation/","title":"Pupil Dilation","text":""},{"location":"KB/Pupil%20Dilation/#pupil-dilation","title":"Pupil Dilation","text":"<ul> <li>Pupil diameter responds to more than just light<ul> <li>When something was visually pleasing</li> <li>Harder problems - thinking time</li> <li>Reaches an asymptote when the task is too difficult , processing load</li> </ul> </li> <li>Measure of resource allocation</li> <li></li> <li>Light based response - parasympathetic</li> <li>Increases with emotional stimulation</li> <li></li> <li>Speech replacement</li> </ul>"},{"location":"KB/Puzzle%20Mix/","title":"Puzzle Mix","text":""},{"location":"KB/Puzzle%20Mix/#puzzle-mix","title":"Puzzle Mix","text":"<ul> <li>@kimPuzzleMixExploiting2020</li> <li>learns to augment two images optimally based on saliency.</li> <li>Images are divided into regions for the mixup</li> <li>The algorithm learns to transport the salient region of one image such that the output image has the maximized saliency from both images.</li> <li> \\[h(x_{0}, x_{1}) = (1-z) \\odot \\Pi_{0}^{T}x_{0} + z \\odot \\Pi_{1}^{T}x_{1}\\] </li> <li>where \\(z_{i}\\) is a binary mask, \\(\\lambda = \\frac{1}{n}\\Sigma_{i}z_{i}\\) is the mixing ratio and \\(\\Pi_{0}, \\Pi_{1}\\) are represent \\(n \\times n\\) grids that denote the amount of mass that is transported during transport of the image patch to another location. </li> </ul>"},{"location":"KB/Pyramidal%20cell/","title":"Pyramidal cell","text":""},{"location":"KB/Pyramidal%20cell/#pyramidal-cell","title":"Pyramidal Cell","text":"<ul> <li><ul> <li>Folds on sides have same charge</li> <li>Adds up so can be measured</li> <li>Equivalent Current Dipole</li> </ul> </li> </ul>"},{"location":"KB/Pytorch%20Tricks/","title":"Pytorch Tricks","text":""},{"location":"KB/Pytorch%20Tricks/#pytorch-tricks","title":"Pytorch Tricks","text":"<ul> <li>Also look at fastai</li> </ul>"},{"location":"KB/Pytorch%20Tricks/#get-params-of-a-layer","title":"Get Params of a Layer","text":"<pre><code>m = learn.model\nl = m.get_submodule('0.model.stem.1')\nlist(l.parameters())\n</code></pre>"},{"location":"KB/Pytorch%20Tricks/#interact","title":"Interact","text":"<pre><code>from ipywidgets import interact\n@interact(m=1.5, b=1.5)\ndef plot_relu(m,b):\n    plot_function(partial(relu, m, b), ylim = (-1, 4))\n</code></pre>"},{"location":"KB/Pytorch%20Tricks/#set-dataset-directory","title":"Set Dataset Directory","text":"<pre><code>import os\nos.environ[\"TORCH_HOME\"] = \"/media/hdd/Datasets/\"\nos.environ[\"FASTAI_HOME\"] = \"/media/hdd/Datasets/\"\n</code></pre>"},{"location":"KB/Quadratic%20Loss/","title":"Quadratic Loss","text":""},{"location":"KB/Quadratic%20Loss/#quadratic-loss","title":"Quadratic Loss","text":"<ul> <li>$\\(W = argmin_{W^{\\ast}}\\Sigma^N_{i=1} ||W^{\\ast} x_i - y_i||^2\\)</li> <li>\\(\\Delta : \\mathbb{R}^{n} \\rightarrow \\mathbb{R}, x \\rightarrow E[Y|X = x]\\) is the gold standard for minimizing this. But \\(\\Delta\\) is unknown</li> </ul>"},{"location":"KB/Quadratic%20Potential%20Field/","title":"Quadratic Potential Field","text":""},{"location":"KB/Quadratic%20Potential%20Field/#quadratic-potential-field","title":"Quadratic Potential Field","text":"<ul> <li>make attractive potential to the goal \\(\\(U_{att}(q)=\\frac{1}{2}D(q,q_{goal})\\)\\)</li> <li></li> </ul>"},{"location":"KB/Quantifier%20spreading%20children%20misled%20by%20ostensive%20cues/","title":"Quantifier spreading children misled by ostensive cues","text":""},{"location":"KB/Quantifier%20spreading%20children%20misled%20by%20ostensive%20cues/#quantifier-spreading-children-misled-by-ostensive-cues","title":"Quantifier Spreading Children Misled by Ostensive Cues","text":"<ul> <li> <p>Katalin \u00c9. Kiss and Tam\u00e1s Z\u00e9t\u00e9nyi</p> </li> <li> <p>TL;DR : Use real images instead of Drawings</p> </li> <li>economy of the stimulus employed in child language experiments may lend an increased ostensive effect to the message communicated to the child</li> <li>Thus, when the visual stimulus in a sentence-picture matching task is a minimal model abstracting away from the details of the situation, children often regard all the elements of the stimulus as ostensive clues to be represented in the corresponding sentence</li> <li>The use of such minimal stimuli is mistaken when the experiment aims to test whether or not a certain element of the stimulus is relevant for the linguistic representation or interpretation</li> <li>It is claimed that children find a universally quantified sentence like Every girl is riding a bicycle to be a false description of a picture showing three girls riding bicycles and a solo bicycle because they are misled to believe that all the elements in the visual stimulus are relevant, hence all of them are to be represented by the corresponding linguistic description.</li> <li>When the iconic drawings were replaced by photos taken in a natural environment rich in accidental details, the occurrence of quantifier spreading was radically reduced.</li> <li>It is shown that an extra object in the visual stimulus can lead to the rejection of the sentence also in the case of sentences involving no quantification, which gives further support to the claim that the source of the problem is not (or not only) the grammatical or cognitive difficulty of quantification but the unintended ostensive effect of the extra object.</li> <li>The reason for the unexpected reactions is that the experimental stimulus presented to the child is devoid of any episodic details; it merely contains a few iconic symbols, which suggests to the child that the irrelevant details have been omitted; hence every element of the stimulus, including the one whose relevance the experiment aims to test, is to be interpreted as an ostensive signal, i.e., every element of the stimulus is significant.</li> <li>Ostension</li> </ul>"},{"location":"KB/Quantifier%20spreading%20children%20misled%20by%20ostensive%20cues/#quantifier-spreading-as-an-ostensive-effect","title":"Quantifier Spreading as an Ostensive Effect","text":"<ul> <li>The phenomenon</li> <li>Every girl is riding a bicycle.</li> <li>Although every one of the three girls in the picture is riding a bicycle, many children find the sentence false</li> <li>When asked \"Why?\", they point at the solo bicycle, and say something like \"Not that bicycle\", i.e., they show 'Exhaustive Pairing' under an extra object condition.</li> <li>Quantifier spreading also has a somewhat less common variant, called \"Perfectionist Response\".1 It occurs when a universally quantified sentence like (2a) is to be matched with a picture like Figure 2, which contains an element that is neither identical with the referent of the subject, nor identical with the referent of the VP-internal complement.2 (2) a. Every dog is eating a bone. b. No, not that one.</li> </ul>"},{"location":"KB/Quantifier%20spreading%20children%20misled%20by%20ostensive%20cues/#theories-of-quantifier-spreading","title":"Theories of Quantifier Spreading","text":"<ul> <li>In fact, children are not fully consistent in assigning to universally quantified sentences interpretations of type (3b); the adult interpretation illustrated in (3a),</li> <li>too, appears to be accessible also to those favoring the spreading reading.</li> <li>The event quantification analysis of Philip (1995) has been criticized on several grounds. For example, it predicts that quantifier spreading is only attested in the case of eventive sentences. In fact, as shown by Philip (2011), it also occurs with sentences of type (4), which contain no event variable:</li> <li>Furthermore, as Crain et al. (1996) point out, the analysis of every as an event quantifier does not account for the \"perfectionist\" mistake, i.e., for the case when the sentence questioned in (1a) is found false in the presence of an extra participant that is neither a girl, nor a bicycle</li> <li>The fact that children have initially access to two interpretations of universally quantified sentences (those of type (3b) and (3a)), one of which is later eliminated, raises a learnability problem, as well \u2013 under the assumption that children acquiring their mother tongue only have access to positive evidence.</li> <li>Several experiments on quantifier spreading have shown that the rate of spreading is affected by pragmatic factors, e.g., a rich linguistic or visual context reduces spreading (cf. Crain et al. 1996</li> <li>However, some of the evidence concerning the role of extra elements appears to be contradictory; e.g., in the case of quantifier spreading, both the increasing of the number of extra objects (Freeman, Sinha &amp; Stedmon 1982), and the decreasing of the size of the extra object (Philip 2011: 377) have been found to reduce the proportion of spreading, which has not been given a principled explanation.</li> <li>Relevance Account</li> <li>Salient Object Strategy</li> <li>Quantifier spreading is due to the increased ostensive effect of iconic stimuli</li> <li>We hypothesized that quantifier spreading is elicited in experimental situations where the stimulus is not embedded in a context, and is devoid of episodic details, as a consequence of which it gains a \u2013 potentially misleading \u2013 concentrated ostensive effect</li> <li>Crucially, however, when the stimulus only contains a few iconic symbols, every one of its elements gains an ostensive effect.</li> </ul>"},{"location":"KB/Quantifier%20spreading%20children%20misled%20by%20ostensive%20cues/#experiment","title":"Experiment","text":""},{"location":"KB/Quantifier%20spreading%20children%20misled%20by%20ostensive%20cues/#participants","title":"Participants","text":"<ul> <li>We tested 82 children from 5 Budapest kindergartens, whose mean age was 5;3 years (SD=0.73).</li> <li>We also carried out the experiment with an adult control group consisting of 24 university students, whose mean age was 21 years (SD=1.61).</li> </ul>"},{"location":"KB/Quantifier%20spreading%20children%20misled%20by%20ostensive%20cues/#procedure","title":"Procedure","text":"<ul> <li>The child, the experimenter, and a helper were seated at a table in front of a laptop in a quiet room of the kindergarten.</li> <li>The helper held a teddy bear</li> <li>The experimenter told the child that they would look at pictures on the computer screen together.</li> <li>They would listen to what the bear said about each picture, and the experimenter would ask the subject whether or not it was true.</li> </ul>"},{"location":"KB/Quantifier%20spreading%20children%20misled%20by%20ostensive%20cues/#materials","title":"Materials","text":"<ul> <li>16 sentence\u2013picture pairs (8 fillers and 8 test pairs) were presented to the subjects Each test sentence involved the universal quantifier minden \u201bevery'</li> <li>Four sentence\u2013picture pairs were of the type which can elicit the Exhaustive Pairing mistake, i.e., they involved an extra object (see example (7) and Figures 3, 4), and four sentence\u2013picture pairs were of the type which can elicit the Perfectionist Response, i.e., they contained an extra element neither identical with the referent of the subject, nor identical with the referent of the VPinternal complement (see example (8) and Figures 5, 6)</li> </ul>"},{"location":"KB/Quantifier%20spreading%20children%20misled%20by%20ostensive%20cues/#results","title":"Results","text":"<ul> <li>The stimuli consisting of a quantified sentence and a drawing elicited quantifier spreading in 27% of the children's answers. In the case of the stimuli consisting of a quantified sentence and a photo, the rate of quantifier spreading dropped to 15%. Among the adults, the rate of quantifier spreading was 6% and 5%, respectively</li> </ul>"},{"location":"KB/Quantifier%20spreading%20children%20misled%20by%20ostensive%20cues/#discussion","title":"Discussion","text":"<ul> <li>In language acquisition experiments, experimenters tend to use iconic visual stimuli</li> <li>in order to eliminate irrelevant distractors, and to ensure that children only react to the controlled factor(s)</li> <li>Our results suggest that this method is mistaken when the experiment aims to test whether or not an element in the stimulus is relevant for the linguistic representation</li> <li>If the visual stimulus is a minimal model devoid of episodic details, children tend to interpret all of its elements as ostensive clues to be represented linguistically</li> <li>If the ostensive effect is diminished by the use of photos taken in natural environments, the proportion of QS is reduced by nearly 50%.</li> <li>The only photo which elicited a relatively high proportion (36%) of quantifier spreading answers (Figure 8) is a picture of a fairly artificial-looking setup with remarkably few details:</li> <li>Decreasing the size of the extra object makes the object less salient; but increasing the number of the extra objects does not necessarily decrease their salience, and what is more, it is not clear why an increase in the salience of the extra object should result in the increased frequency of quantifier spreading responses.</li> <li>Misleading ostensive effect in other types of acquisition experiments An example: A test of exhaustivity</li> <li>t has been tested in several experiments (e.g., Beaver &amp; Onea 2011; Kas &amp; Luk\u00e1cs 2013; Pint\u00e9r 2016) whether the exhaustivity of the preverbal focus of the Hungarian sentence (corresponding roughly to an English cleft constituent) is an inherent semantic property or a cancellable pragmatic implicature</li> <li>The tasks involved truth value judgements; experimenters aimed to find out whether children and adults accept a focus construction like (11) as a true description of a non-exhaustive situation like that in Figure 11 (both cited from Pint\u00e9r 2016):</li> </ul>"},{"location":"KB/Quantifier%20spreading%20children%20misled%20by%20ostensive%20cues/#results_1","title":"Results","text":"<ul> <li>The rate of rejection of the sentences as true descriptions of the visually represented situations significantly correlated with the type of the visual representation.</li> <li>The sentence\u2013 drawing pairs were rejected in 10.53% of the cases.</li> <li>n the case of the sentence\u2013photo pairs, the rate of rejection was a mere 3.51%.</li> <li>Just as in Pint\u00e9r's (2016) experiment, the rate of rejection (i.e., the rate of the exhaustive interpretation of the sentences) was slightly even higher in the adult control group: 13.33% in the case of sentence\u2013drawing pairs, and 8.88% in the case of sentence\u2013photo pairs (see Figure 18). When we asked the subjects giving</li> <li>negative answers why e.g. (14) was not true of Figure 14, they consistently gave answers of the following type: \"Because the woman is also feeding the ducks\".</li> <li>15 children (39%) gave at least one negative answer</li> </ul>"},{"location":"KB/Quantifier%20spreading%20children%20misled%20by%20ostensive%20cues/#discussion_1","title":"Discussion","text":"<ul> <li>The sentences tested in this experiment involved no special linguistic or cognitive difficulty; they were simple declarative sentences with no quantification, let alone universal quantification; nevertheless, 10.53% of the preschoolers evaluated them as false descriptions of the drawings intended to represent them visually.</li> <li>Since this rate is not high (though it is comparable to the 12% of partial rejection obtained by Pint\u00e9r 2016 in this age group), we might be tempted to attribute it to noise (children's failure to pay attention, etc.)</li> <li>However, if the 10.53% rate of rejection had been due to noise, it would not have dropped to 3.51% when the visual stimuli were represented by photos.</li> <li>The comments of the children giving negative answers made it clear that they rejected the given sentence\u2013picture pair because the picture contained extra objects that were not repre-</li> <li>sented linguistically</li> <li>Crucially, the photos contained many more extra agents and extra objects than the drawings, still they elicited significantly less rejections.</li> <li>What made the presence of extra objects in the drawings ostensive was the minimality of the drawings, suggesting that everything irrelevant had been eliminated from them.</li> </ul>"},{"location":"KB/Quantifier%20spreading%20children%20misled%20by%20ostensive%20cues/#pictures","title":"Pictures","text":""},{"location":"KB/Quantifiers/","title":"Quantifiers","text":""},{"location":"KB/Quantifiers/#quantifiers","title":"Quantifiers","text":"<ul> <li>how many are identified (all, some, none) A type of word that indicates quantity</li> <li>Nominal</li> <li>Each, Every, All, Many, Some, No, Few, Most</li> <li>Adverbial</li> <li>Quantify over time: Always, Usually, Never, Rarely</li> <li>Quantify over space: Everywhere, Somewhere, Nowhere</li> <li>Others</li> <li>Modals are used to show that we believe something is certain, probable or possible</li> <li>Modal verbs: Can, Could, May, Might, Must</li> <li>Modal quantifiers: Perhaps, Necessarily, Maybe</li> </ul>"},{"location":"KB/Quantifying%20Uncertainty/","title":"Quantifying Uncertainty","text":""},{"location":"KB/Quantifying%20Uncertainty/#quantifying-uncertainty","title":"Quantifying Uncertainty","text":""},{"location":"KB/Quantile%20Bucketing/","title":"Quantile Bucketing","text":""},{"location":"KB/Quantile%20Bucketing/#quantile-bucketing","title":"Quantile Bucketing","text":"<ul> <li>Distributing a feature's values into buckets so that each bucket contains the same (or almost the same) number of examples.</li> </ul>"},{"location":"KB/Quantized%20Distillation/","title":"Quantized Distillation","text":""},{"location":"KB/Quantized%20Distillation/#quantized-distillation","title":"Quantized Distillation","text":"<ul> <li>Network quantization reduces the computation com- plexity of neural networks by converting high-precision networks (e.g., 32-bit floating point) into low-precision networks (e.g., 2-bit and 8-bit). Meanwhile, knowledge distillation aims to train a small model to yield a performance comparable to that of a complex model.</li> <li>Specifically, Polino et al. (2018) proposed a quan- tized distillation method to transfer the knowledge to a weight-quantized student network. In (Mishra and Marr, 2018), the proposed quantized KD is called the \u201cap- prentice\u201d. A high precision teacher network transfers knowledge to a small low-precision student network. To ensure that a small student network accurately mim- ics a large teacher network, the full-precision teacher network is first quantized on the feature maps, and then the knowledge is transferred from the quantized teacher to a quantized student network (Wei et al., 2018).</li> </ul>"},{"location":"KB/Quasi-static%20Clamping/","title":"Quasi static Clamping","text":""},{"location":"KB/Quasi-static%20Clamping/#quasi-static-clamping","title":"Quasi-static Clamping","text":"<ul> <li>A type of contact between a person and part of a robot system where the body part can be clamped between the moving part of the robot system &amp; another fixed or moving part of the robot cell</li> </ul>"},{"location":"KB/RACE/","title":"RACE","text":""},{"location":"KB/RACE/#race","title":"RACE","text":""},{"location":"KB/RAGAS%20-%20automated%20evaluation%20of%20RAG/","title":"RAGAS - automated evaluation of RAG","text":"","tags":["llm"]},{"location":"KB/RAGAS%20-%20automated%20evaluation%20of%20RAG/#ragas-automated-evaluation-of-rag","title":"RAGAS - Automated Evaluation of RAG","text":"","tags":["llm"]},{"location":"KB/RAGAS%20-%20automated%20evaluation%20of%20RAG/#ragas-automated-evaluation-of-retrieval-augmented-generation","title":"RAGAS: Automated Evaluation of Retrieval Augmented Generation","text":"<ul> <li>(Note : Well. I am not convinced. They did come up with some ways of testing it. But all of those ways used the LLM to test itself, which is uh. Not very nice or representative. I am unsure of how accurate any of these are.</li> <li>Logically it seems slightly flawed, but I respect the hustle)</li> </ul>","tags":["llm"]},{"location":"KB/RAGAS%20-%20automated%20evaluation%20of%20RAG/#ragas-retrieval-augmented-generation-assessment","title":"RAGAS (Retrieval Augmented Generation Assessment)","text":"<ul> <li>framework for reference-free evaluation of Retrieval Augmented Generation (RAG) pipelines</li> <li>evaluate these different dimensions without having to rely on ground truth human annotations</li> <li>While the usefulness of retrieval-augmented strategies is clear, their implementation requires a significant amount of tuning, as the overall performance will be affected by the retrieval model, the considered corpus, the LM, or the prompt formulation, among others</li> </ul>","tags":["llm"]},{"location":"KB/RAGAS%20-%20automated%20evaluation%20of%20RAG/#evaluation-strategies","title":"Evaluation Strategies","text":"<ul> <li>standard RAG setting</li> <li>given a question q, the system first retrieves some context c(q) and then uses the retrieved context to generate an answer as(q)</li> <li>(Note : This seems like an interesting start so far)</li> <li>we usually do not have access to human-annotated datasets or reference answers</li> </ul>","tags":["llm"]},{"location":"KB/RAGAS%20-%20automated%20evaluation%20of%20RAG/#faithfulness","title":"Faithfulness","text":"<ul> <li>answer should be grounded in the given context</li> <li>important to avoid hallucinations, and to ensure that the retrieved context can act as a justification for the generated answer</li> <li>RAG systems are often used in applications where the factual consistency of the generated text w.r.t. the grounded sources is highly important</li> <li></li> <li>(Note : Basically they use an LLM to generate an answer and then check with the ground truth to see how closely it matched by comparing the number of matches/total number of statements)</li> </ul>","tags":["llm"]},{"location":"KB/RAGAS%20-%20automated%20evaluation%20of%20RAG/#answer-relevance","title":"Answer Relevance","text":"<ul> <li>generated answer should address the actual question that was provided</li> <li>(Note : Basically uses cosine similarity. I am unsure of how different it is to that usual llm but oh well) </li> </ul>","tags":["llm"]},{"location":"KB/RAGAS%20-%20automated%20evaluation%20of%20RAG/#context-relevance","title":"Context Relevance","text":"<ul> <li>retrieved context should be focused, containing as little irrelevant information as possible</li> <li>gpt-3.5-turbo-16k model</li> <li>penalise the inclusion of redundant information.</li> <li>(Note : -.-, they just asked the LLM to find the most important sentences and then divided it by the total number of sentences. I am now progressively getting more and more annoyed with this paper)</li> </ul>","tags":["llm"]},{"location":"KB/RAHP/","title":"RAHP","text":""},{"location":"KB/RAHP/#rahp","title":"RAHP","text":"<ul> <li>Recall at high precision</li> </ul>"},{"location":"KB/RANSAC/","title":"RANSAC","text":""},{"location":"KB/RANSAC/#ransac","title":"RANSAC","text":"<ul> <li>It is an iterative method to estimate parameters of a mathematical model from a set of observed data</li> <li>A simple example is fitting a line to a set of observations.</li> <li>Outliers are points that don't \"fit\" the model and points that do fit are called \"inliers\"</li> <li>Table detection<ul> <li>The algorithm starts by generating plane hypotheses based on three unique points.</li> <li>For each plane hypothesis, distances from all points in the point cloud to the plane are computed.</li> <li>The plane hypotheses are then scored based on counting the number of inlier points, e.g., distance to the plane \uf8ff 20mm.</li> <li></li> </ul> </li> <li>The RANSAC algorithm is repeated for a certain number of iterations, e.g., n = 200.</li> <li>Object detection<ul> <li>It is now possible to extract the points which lie directly above it.</li> <li>By removing the table, we have a point cloud where all the objects that are on top of the table are included.</li> <li>The obtained point cloud is then segmented into individual clusters Each small group of points will be treated as an object candidate.</li> <li></li> </ul> </li> <li></li> </ul>"},{"location":"KB/RETAIn/","title":"RETAIn","text":""},{"location":"KB/RETAIn/#retain","title":"RETAIn","text":"<ul> <li>REverse Time AttentIoN mechanism</li> <li>The approach mimics physician practice by attending to the EHR data. Two RNNs are trained in a reverse time order with the goal of efficiently generating the appropriate attention variables. It is based on a two-level neural attention generation process that detects influential past visits and significant clinical variables to improve accuracy and interpretability.</li> <li>for application to Electronic Health Record (EHR) data.</li> </ul>"},{"location":"KB/RETRO/","title":"RETRO","text":""},{"location":"KB/RETRO/#retro","title":"RETRO","text":"<ul> <li>Improving Language Models by Retrieving from Trillions of Tokens</li> <li>Retrieval-Enhanced Transformer</li> <li>RETRO</li> <li>enhances auto-regressive language models by conditioning on document chunks retrieved from a large corpus</li> <li>based on local similarity with preceding tokens</li> <li>comparable performance to GPT-3 and Jurassic-1 on the Pile, despite using 25x fewer parameters</li> <li>frozen BERT retriever, a differentiable encoder and a chunked cross-attention mechanism to predict tokens based on an order of magnitude more data than what is typically consumed during training</li> <li>Wikitext103</li> <li>Pile</li> <li>improving semi-parametric language models through explicit memory can provide an orthogonal, more efficient approach than raw parameter scaling as they seek to build more powerful language models</li> </ul>"},{"location":"KB/RICAP/","title":"RICAP","text":""},{"location":"KB/RICAP/#ricap","title":"RICAP","text":"<ul> <li>@takahashiDataAugmentationUsing2020</li> <li>Random image cropping and patching</li> <li>cropping four regions from randomly sampled images and augmenting them to create a new image.</li> <li>The generated image has mixed labels proportional to the pasted area</li> <li>The area of cropped regions in the output image is determined by sampling through uniform distribution</li> <li>anywhere-RICAP (origin can be anywhere), center-RICAP (origin can only be in the middle of the image), and corner-RICAP (origin can only be in corners</li> <li>Corner-RICAP has shown the best performance because a larger region of one image is visible to the network to learn</li> </ul>"},{"location":"KB/RISE/","title":"RISE","text":""},{"location":"KB/RISE/#rise","title":"RISE","text":"<ul> <li>@petsiukRISERandomizedInput2018</li> <li>based on a stochastic approach</li> <li>Input images are iteratively altered via random noise, and the final saliency map is composed by accumulating the partial estimations</li> <li>However, its application requires much more computational power, as it needs to run hundreds of thousands of prediction cycles</li> <li>it seems that RISE is not able to highlight regions of interest of skin lesion images with the same reliability as on pictures of real-world objects</li> <li>In the first step, it creates a segmentation mask and applies it to the dermoscopic image. Secondly, it creates a structure segmentation mask to identify the structure of the dermoscopic image. After masking, the original segmented image and some nonvisual metadata are fed into a convolutional neural network for classification</li> </ul>"},{"location":"KB/ROC%20Curve/","title":"ROC Curve","text":""},{"location":"KB/ROC%20Curve/#roc-curve","title":"ROC Curve","text":"<ul> <li>appropriate when the data is balanced</li> <li>x-axis : False Positive</li> <li>y-axis : True Positive</li> <li>area under the curve (AUC) can be used as a summary of the model performance<ul> <li>assign a higher probability to a randomly chosen real positive occurrence than a negative occurrence on average</li> </ul> </li> <li>Interpretation<ul> <li>Smaller values on the x-axis of the plot indicate lower false positives and higher true negatives.</li> <li>Larger values on the y-axis of the plot indicate higher true positives and lower false negatives.</li> </ul> </li> </ul>"},{"location":"KB/Rabobank/","title":"Rabobank","text":"","tags":["jobs"]},{"location":"KB/Rabobank/#subhaditya-mukherjee-rabobank-ai-strategist-application","title":"Subhaditya Mukherjee : Rabobank - AI Strategist Application","text":"<p>Hello Ante,</p> <p>It's nice to meet you!\u00a0 My name is Subhaditya, I recently graduated with a masters in AI from the RUG (Groningen), and am looking for my next big challenge. I found the position a good fit for what I can offer and what I want to do next, and so this is my formal application for the AI Strategist position.</p> <p>Over the past few years, I have worked with many clients (both freelance/part-time and in internships) and helped them bring their AI projects to life. I have a mix of experience, ranging from consulting to building technical AI projects across domains. I believe that this experience makes me a good fit for this position, as not only can I map out the steps needed to arrive at an AI based product, I can also break it down across multiple levels of understanding.\u00a0 I have been working with AI for a long time now, and am quite familiar with the stack - from LLMs to GenAI to other advanced AI models. I also have an understanding of reinforcement learning and am pretty proficient in Python.\u00a0</p> <p>I understand just how deeply important ethically future proofing the baking system is. The world is moving ahead with AI, and if we do not keep up with the trend, it will move ahead without us. I hope to be part of that change at Rabobank, and help co-create strategies that help the workforce in the long run.</p> <p>Hope to hear from you soon :)</p>","tags":["jobs"]},{"location":"KB/RadboudUMC/","title":"RadboudUMC","text":"","tags":["jobs"]},{"location":"KB/RadboudUMC/#fair-software-engineer-application","title":"FAIR Software Engineer Application","text":"<p>Hello! (I want to say James, but I am not sure)</p> <p>My name is Subhaditya, I recently graduated with a masters in AI from the RUG (Groningen), and am now looking for a job in the Netherlands. As a software engineer with an interest in healthcare and experience in AI, the FAIR RSE position seemed like the perfect next step for me, and I did not want to miss out on applying for it. Having been working on computer vision for a few years now, I am very aware of the need for better data management, especially for complex and privacy oriented workflows. I would love to bring this experience to DIAG, while also hopefully learning a lot from the team there too.</p> <p>Over the past few years, I have worked with many clients (both freelance/part-time and in internships) and helped them bring their AI and data projects to life. My experience includes working with large datasets, building ML/DL models and pipelines and also sharing my knowledge with my peers in technical and non technical fields. I have worked with AWS, Google Cloud and DICOM before as well. I am quite proficient in Python, CI/CD and integrating 3rd party APIs with existing codebases.\u00a0</p> <p>I have a masters in AI (with my thesis being on Explainable AI) and that also brought me\u00a0 experience with setting up training and also the FAIR principles. More importantly though, using AI in healthcare has been my motivation for many years now, and one of the reasons I got into the field in the first place. That being the case, I feel like I am in a better position compared to general software engineers in understanding what is required and why.</p> <p>This letter is getting a little long, but I did want to add that I would love to contribute to your team\u2019s mission of making Radboud UMC the best campus for AI research, and in turn helping a lot of researchers get their work done faster and more responsibly. I do hope you give me a shot :)</p> <p>Best,</p> <p>Subhaditya Mukherjee</p>","tags":["jobs"]},{"location":"KB/Radial%20Plot/","title":"Radial Plot","text":""},{"location":"KB/Radial%20Plot/#radial-plot","title":"Radial Plot","text":"<ul> <li>number of associated attributes limited  </li> <li>distinct distinguishable values per attribute limited  </li> <li>visual mappings must be learned for correct interpretation</li> </ul>"},{"location":"KB/Ramp%20up%20problem/","title":"Ramp up problem","text":""},{"location":"KB/Ramp%20up%20problem/#ramp-up-problem","title":"Ramp up Problem","text":"<ul> <li>No data for a user -&gt; picked one</li> <li>Broad generalization</li> </ul>"},{"location":"KB/RandAugment/","title":"RandAugment","text":""},{"location":"KB/RandAugment/#randaugment","title":"RandAugment","text":"<ul> <li>Randaugment: Practical automated data augmentation with a reduced search space</li> <li>Ekin D. Cubuk \u2217, Barret Zoph\u2217, Jonathon Shlens, Quoc V. Le</li> </ul>"},{"location":"KB/RandAugment/#chatgpt-summary","title":"ChatGPT Summary","text":"<ul> <li>Large-scale adoption of data augmentation methods is hindered by the need for a separate and expensive search phase.</li> <li>Commonly, a smaller proxy task is used to overcome the expense of the search phase, but it is not clear if the optimized hyperparameters found on the proxy task are also optimal for the actual task.</li> <li>The process of designing automated augmentation strategies is being rethought.</li> <li>It is proposed to only search for a single distortion magnitude that jointly controls all operations, which reduces computational expense and eliminates the need for a separate proxy task.</li> <li>The proposed method was tested on various datasets including [CIFAR]-10, CIFAR 100, SVHN, ImageNet, and COCO, and showed improvement in performance without the use of a proxy task.</li> <li>The proposed method, RandAugment, uses a parameter-free procedure of always selecting a transformation with uniform probability from a set of K=14 available transformations, and a single distortion magnitude that jointly controls all operations.</li> <li>RandAugment is able to achieve comparable or better performance compared to other automated augmentation methods, such as AutoAugment, without the need for a separate proxy task.</li> <li>The results suggest that the optimal data augmentation policies may depend on the specific model and dataset size, and a small proxy task may not provide the best indicator of performance on a larger task.</li> </ul>"},{"location":"KB/RandAugment/#abstract","title":"Abstract","text":"<ul> <li>An obstacle to a large-scale adoption of these methods is that they require a separate and expensive search phase</li> <li>A common way to overcome the expense of the search phase was to use a smaller proxy task.</li> <li>However, it was not clear if the optimized hyperparameters found on the proxy task are also optimal for the actual task.</li> <li>rethink the process of designing automated augmentation strategies</li> <li>it is sufficient to only search for a single distortion magnitude that jointly controls all operations</li> <li>propose a simplified search space that vastly reduces the computational expense of automated augmentation, and permits the removal of a separate proxy task.</li> <li>CIFAR-10</li> <li>CIFAR 100</li> <li>SVHN</li> <li>ImageNet</li> <li>COCO datasets</li> </ul>"},{"location":"KB/RandAugment/#systematic-failures-of-a-separate-proxy-task","title":"Systematic Failures of a Separate Proxy Task","text":"<ul> <li>A central premise of learned data augmentation is to construct a small, proxy task that may be reflective of a larger task</li> <li>Although this assumption is sufficient for identifying learned augmentation policies to improve performance, it is unclear if this assumption is overly stringent and may lead to sub-optimal data augmentation policies.</li> <li>two separate dimensions that are commonly restricted to achieve a small proxy task: model size and dataset size</li> <li>First, we train a family of Wide-ResNet architectures, where the model size may be systematically altered through the widening parameter governing the number of convolutional filters</li> <li>For each of these networks, we train the model on CIFAR-10 and measure the final accuracy compared to a baseline model trained with default data augmentations (i.e. horizontal flips and pad-and-crop)</li> <li>The Wide-ResNet models are trained with the additional K=14 data augmentations (see Section 3) over a range of global distortion magnitudes M parameterized on a uniform linear scale ranging from [0, 30]</li> <li>Namely, larger networks demand larger data distortions for regularization</li> <li>Conversely, a policy learned on a proxy task (such as AutoAugment) provides a fixed distortion magnitude (Figure 1b, dashed line) for all architectures that is clearly sub-optimal.</li> <li>A second dimension for constructing a small proxy task is to train the proxy on a small subset of the training data</li> <li>We first observe that models trained on smaller training sets may gain more improvement from data augmentation</li> <li>see that the optimal distortion magnitude is larger for models that are trained on larger datasets.</li> <li>optimal distortion magnitude increases monotonically with training set size</li> <li>One hypothesis for this counter-intuitive behavior is that aggressive data augmentation leads to a low signal-to-noise ratio in small datasets</li> <li>learned augmentation may learn an augmentation strength more tailored to the proxy task instead of the larger task of interest.</li> <li>The dependence of augmentation strength on the dataset and model size indicate that a small proxy task may provide a sub-optimal indicator of performance on a larger task.</li> </ul>"},{"location":"KB/RandAugment/#automated-data-augmentation-without-a-proxy-task","title":"Automated Data Augmentation without a Proxy Task","text":"<ul> <li>The reason we wish to remove the search phase is because a separate search phase significantly complicates training and is computationally expensive.</li> <li>In order to remove a separate search phase, we aspire to fold the parameters for the data augmentation strategy into the hyper-parameters for training a model.</li> <li>Indeed, previous work enumerated a policy in terms of choosing which transformations to apply out of K=14 available transformations, and probabilities for applying each transformation:</li> <li>age diversity, we replace the learned policies and probabilities for applying each</li> <li>transformation with a parameter-free procedure of always selecting a transformation with uniform probability \\(\\frac{1}{K}\\) </li> <li>Given N transformations for a training image, RandAugment may thus express \\(K^{N}\\) potential policies.</li> <li>magnitude of the each augmentation distortion.</li> <li>Briefly, each transformation resides on an integer scale from 0 to 10 where a value of 10 indicates the maximum scale for a given transformation</li> <li>A data augmentation policy consists of identifying an integer for each augmentation.</li> <li>and postulate that a single global distortion M may suffice for parameterizing all transformations</li> <li>We experimented with four methods for the schedule of M during training: constant magnitude, random magnitude, a linearly increasing magnitude, and a random magnitude with increasing upper bound</li> <li>The resulting algorithm contains two parameters N and M</li> <li>Both parameters are human-interpretable such that larger values of N and M increase regularization strength</li> <li>In order to reduce the parameter space but still maintain imInvestigating the dependence on the included transformations</li> <li>RandAugment is largely insensitive to the selection of transformations for different datasets.</li> <li>We see that while geometric transformations individually make the most difference, some of the color transformations lead to a degradation of validation accuracy on average</li> <li>Surprisingly, rotate can significantly improve performance and lower variation even when included in small subsets of RandAugment transformations, while posterize seems to hurt all subsets of all sizes.</li> </ul>"},{"location":"KB/RandAugment/#learning-the-probabilities-for-selecting-image-transformations","title":"Learning the Probabilities for Selecting Image Transformations","text":"<ul> <li>For K=14 image transformations and N =2 operations, \u03b1ij constitutes 28 parameters. We initialize all weights such that each transformation is equal probability (i.e. RandAugment), and update these parameters based on how well a model classifies a held out set of validation images distorted by \u03b1ij.</li> <li>This approach was inspired by density matching [19], but instead uses a differentiable approach in lieu of Bayesian optimization.</li> <li>We label this method as a 1st-order density matching approximation.</li> <li>The 1st -order method improves accuracy by more than 3.0% for both models on reduced CIFAR-10 compared to the baseline of flips and pad-and-crop</li> <li>Although the density matching approach is promising, this method can be expensive as one must apply all K transformations N times to each image independently.</li> <li>Hence, because the computational demand of KN transformations is prohibitive for large images, we reserve this for future exploration.</li> <li>learning the probabilities through density matching may improve the performance on small-scale tasks and reserve explorations to larger-scale tasks for the future.</li> <li>RandAugment selects all image transformations with equal probability</li> <li>This opens up the question of whether learning K probabilities may improve performance further.</li> <li>Most of the image transformations (except posterize, equalize, and autoContrast) are differentiable, which permits backpropagation to learn the K probabilities</li> </ul>"},{"location":"KB/RandAugment/#discussion","title":"Discussion","text":"<ul> <li>not tailoring the number of distortions and the distortion magnitude to the dataset size nor the model size leads to sub-optimal performance</li> <li>In previous work, scaling learned data augmentation to larger dataset and models have been a notable obstacle. For example, [AutoAugment] and Fast AutoAugment could only be optimized for small models on reduced subsets of data</li> <li>The proposed method scales quite well to datasets such as ImageNet and COCO while incurring minimal computational cost (e.g. 2 hyper-parameters), but notable predictive performance gains.</li> </ul>"},{"location":"KB/RandAugment/#images","title":"Images","text":""},{"location":"KB/Random%20Directions/","title":"Random Directions","text":""},{"location":"KB/Random%20Directions/#random-directions","title":"Random Directions","text":"<ul> <li>1D<ul> <li> \\[ f(\\alpha, \\beta) = L(\\theta^{*}+ \\alpha \\delta) \\] </li> </ul> </li> <li>2D<ul> <li> \\[ f(\\alpha, \\beta) = L(\\theta^{*}+ \\alpha \\delta + \\beta \\eta) \\] </li> </ul> </li> <li>\\(\\theta, \\eta\\) are random direction vector and \\(\\theta^{*}\\) is optimal weights vector</li> </ul>"},{"location":"KB/Random%20Distortion/","title":"Random Distortion","text":""},{"location":"KB/Random%20Distortion/#random-distortion","title":"Random Distortion","text":"<ul> <li>The parameters of this distortion are given in terms of grid width, grid height, and magnitude. The granularity of the distortion is controlled by the grid width and height, representing the number of horizontal and vertical divisions to apply distortion to. Both values are chosen as 6, and the magnitude of the distortion is chosen as 5. As images are only 32\u00d732 pixels, distortion is expected to produce unrealistic examples.</li> </ul>"},{"location":"KB/Random%20Erasing/","title":"Random Erasing","text":""},{"location":"KB/Random%20Erasing/#random-erasing","title":"Random Erasing","text":"<ul> <li>@zhongRandomErasingData2020</li> <li>deletes contiguous rectangular image regions similar to cutout with minor differences in region selection procedure.</li> <li>Opposite to cutout, where deletion is applied on all the images, here it is performed with a probability of either applying it or not</li> <li>In every iteration, region size is defined randomly with upper and lower limits on region area and aspect ratio.</li> <li>Additional to this, random erasing provides region-aware deletion for object detection and person identification tasks</li> <li>Regions inside the object bounding boxes are randomly erased to generate occlusions</li> </ul>"},{"location":"KB/Random%20Factors/","title":"Random Factors","text":""},{"location":"KB/Random%20Factors/#random-factors","title":"Random Factors","text":"<ul> <li>These are factors that can affect the outcome that we do not design, and cannot control</li> <li>Two common types</li> <li>Participant<ul> <li>People differ. Some people are very strict. Some people accept everything.</li> </ul> </li> <li>Item<ul> <li>Some sentences are weird with monkeys. Some situations are hard to draw so the picture is a bit odd.</li> </ul> </li> <li>When we analyze the data we have to take into account that there will be variation present because of these random factors.</li> </ul>"},{"location":"KB/Random%20Pruning/","title":"Random Pruning","text":""},{"location":"KB/Random%20Pruning/#random-pruning","title":"Random Pruning","text":"<ul> <li>Each weight independantly considered and dropped with a fraction of network required</li> <li>For this we first take the number of values to prune by identifying the total size of the weights and then multiplying it by the fraction of values to remove.</li> </ul>"},{"location":"KB/Rank%20%28Tensor%29/","title":"Rank (Tensor)","text":""},{"location":"KB/Rank%20%28Tensor%29/#rank-tensor","title":"Rank (Tensor)","text":"<ul> <li>The number of dimensions in a Tensor. For instance, a scalar has rank 0, a vector has rank 1, and a matrix has rank 2.</li> </ul>"},{"location":"KB/Rapid%20Eye%20Movement%20%28REM%29%20Sleep/","title":"Rapid Eye Movement (REM) Sleep","text":""},{"location":"KB/Rapid%20Eye%20Movement%20%28REM%29%20Sleep/#rapid-eye-movement-rem-sleep","title":"Rapid Eye Movement (REM) Sleep","text":"<ul> <li>A stage of sleep occurring approximately 90 minutes after sleep onset characterized by increased brain activity, rapid eye movements, and muscle relaxation.</li> </ul>"},{"location":"KB/Rational%20inference/","title":"Rational inference","text":""},{"location":"KB/Rational%20inference/#rational-inference","title":"Rational Inference","text":"<ul> <li>Uses all Available cues</li> </ul>"},{"location":"KB/Raycasting/","title":"Raycasting","text":""},{"location":"KB/Raycasting/#raycasting","title":"Raycasting","text":"<ul> <li>Volume Rendering Equation</li> <li>Back To Front Raycasting</li> <li>Color Compositing</li> <li>Front to Back Raycasting</li> <li>Sampling Ray Casting</li> <li>Classification Ray Casting</li> <li>Slice Based Volume Rendering</li> <li>Voxel Projection</li> </ul>"},{"location":"KB/ReMix/","title":"ReMix","text":""},{"location":"KB/ReMix/#remix","title":"ReMix","text":"<ul> <li>@caoReMixImagetoImageTranslation2021</li> <li>addresses the issue of class imbalance by generating mixed images for minority classes.</li> <li>in the case of label assignment, it sets the label of the output image to the minority class.</li> </ul>"},{"location":"KB/Real%20Time%20Image%20Saliency%20for%20Black%20Box%20Classifiers/","title":"Real Time Image Saliency for Black Box Classifiers","text":""},{"location":"KB/Real%20Time%20Image%20Saliency%20for%20Black%20Box%20Classifiers/#real-time-image-saliency-for-black-box-classifiers","title":"Real Time Image Saliency for Black Box Classifiers","text":"<ul> <li>Piotr Dabkowski</li> <li>Yarin Gal</li> <li>@dabkowskiRealTimeImage2017</li> </ul>"},{"location":"KB/Real%20Time%20Image%20Saliency%20for%20Black%20Box%20Classifiers/#tldr","title":"TL;DR","text":"<ul> <li>New metric to judge how good a saliency map is using the largest rectangle that can define it. Training to reduce adversarial artefacts introduced due to masking with non smooth masks</li> </ul>"},{"location":"KB/Real%20Time%20Image%20Saliency%20for%20Black%20Box%20Classifiers/#abstract","title":"Abstract","text":"<ul> <li>fast saliency detection method that can be applied to any differentiable image classifier</li> <li>masking model</li> <li>manipulate the scores of the classifier by masking salient parts of the input image</li> <li>requires a single forward pass to perform saliency detection</li> <li>CIFAR</li> <li>ImageNet</li> <li>new metric for saliency</li> </ul>"},{"location":"KB/Real%20Time%20Image%20Saliency%20for%20Black%20Box%20Classifiers/#image-saliency-and-introduced-evidence","title":"Image Saliency and Introduced Evidence","text":"<ul> <li>no single obvious metric that could measure the quality of the produced map</li> <li>In simple terms, the saliency map is defined as a summarised explanation of where the classifier \"looks\" to make its prediction.</li> <li></li> <li>SSR</li> <li>SDR</li> <li>In order to be as informative as possible we would like to find a region that performs well as both SSR and SDR.</li> <li>Both SDR and SSR remove some evidence from the image</li> <li>there are few ways of removing evidence, for example by blurring the evidence, setting it to a constant colour, adding noise, or by completely cropping out the unwanted parts</li> <li>Unfortunately, each one of these methods introduces new evidence that can be used by the classifier as a side effec</li> </ul>"},{"location":"KB/Real%20Time%20Image%20Saliency%20for%20Black%20Box%20Classifiers/#fighting-the-introduced-evidence","title":"Fighting the Introduced Evidence","text":"<ul> <li>by manipulating the image we always introduce some extra evidence applying a mask M to the image X to obtain the edited image E</li> <li>the simplest case we can simply multiply X and M element-wise:</li> <li> \\[E = X \\odot M\\] </li> <li>This operation sets certain regions of the image to a constant \"0\" colour</li> <li>While setting a larger patch of the image to \"0\" may sound rather harmless (perhaps following the assumption that the mean of all colors carries very little evidence), we may encounter problems when the mask M is not smooth</li> <li>in the worst case, can be used to introduce a large amount of additional evidence by generating adversarial artifacts</li> <li>Adversarial artifacts generated by the mask are very small in magnitude and almost imperceivable for humans, but they are able to completely destroy the original prediction of the classifier</li> <li>we may change the way we apply a mask to reduce the amount of unwanted evidence due to specifically-crafted masks</li> <li> \\[E = X \\odot M + A \\odot (1-M)\\] </li> <li>where A is an alternative image</li> <li>A can be chosen to be for example a highly blurred version of X</li> <li>In such case mask M simply selectively adds blur to the image X and therefore it is much harder to generate high-frequency-high-evidence artifacts</li> <li>Unfortunately, applying blur does not eliminate existing evidence very well, especially in the case of images with low spatial frequencies like a seashore or mountains.</li> <li>Another reasonable choice of A is a random constant colour combined with highfrequency noise. This makes the resulting image E more unpredictable at regions where M is low and therefore it is slightly harder to produce a reliable artifact.</li> <li>encourage smoothness of the mask M for example via a total variation (TV) penalty</li> <li>We can also directly resize smaller masks to the required size as resizing can be seen as a smoothness mechanism.</li> </ul>"},{"location":"KB/Real%20Time%20Image%20Saliency%20for%20Black%20Box%20Classifiers/#a-new-saliency-metric","title":"A New Saliency Metric","text":"<ul> <li>In order to make sure that the preserved region is free from adversarial artifacts instead of masking we can crop the image.</li> <li>We propose to find the tightest rectangular crop that contains the entire salient region and to feed that rectangular region to the classifier to directly verify whether it is able to recognise the requested class</li> <li> \\[s(a,p) = log(\\overset{\\sim}a)- log(p)\\] </li> <li>\\(\\overset{\\sim}a = max(a, 0.05)\\)</li> <li>Here a is the area of the rectangular crop as a fraction of the total image size and p is the probability of the requested class returned by the classifier based on the cropped region.</li> <li>The metric is almost a direct translation of the SSR</li> <li>We threshold the area at 0.05 in order to prevent instabilities at low area fractions.</li> <li>Good saliency detectors will be able to significantly reduce the crop size without reducing the classification probability, and therefore a low value for the saliency metric is a characteristic of good saliency detectors.</li> <li>this measure can be seen as the relative amount of information between an indicator variable with probability p and an indicator variable with probability a\u2014or the concentration of information in the cropped region.</li> <li>Because most image classifiers accept only images of a fixed size and the crop can have an arbitrary size, we resize the crop to the required size disregarding aspect ratio</li> </ul>"},{"location":"KB/Real%20Time%20Image%20Saliency%20for%20Black%20Box%20Classifiers/#the-saliency-objective","title":"The Saliency Objective","text":"<ul> <li>want to find a mask M that is smooth and performs well at both SSR([SSR].md) and SDR</li> <li>given class c of interest, and an input image X, to find a saliency map M for class c, our objective function L is given by</li> <li> \\[L(M) = \\lambda_{1}TV(M) + \\lambda_{2}AV(M) - log(f_{c}(\\Phi(X,M)))+\\lambda_{3}f_{c}(\\Phi(X, 1-M))^{\\lambda_{4}}\\] </li> <li>fc is a softmax probability of the class c of the black box image classifier and TV(M) is the total variation of the mask defined simply as</li> <li> \\[TV(M) = \\Sigma_{i,j}(M_{ij}-M_{ij+1})^{2}+ \\Sigma_{ij}(M_{ij}-M_{i+1j})^{2}\\] </li> <li>AV(M) is the average of the mask elements, taking value between 0 and 1, \\(\\lambda_{i}\\) are regularisers</li> <li>function \\(\\Phi\\) removes the evidence from the image as introduced in the previous section</li> <li> \\[\\Phi(X, M) = X \\odot M + A \\odot (1-M)\\] </li> <li>In total, the objective function is composed of 4 terms. The first term enforces mask smoothness, the second term encourages that the region is small. The third term makes sure that the classifier is able to recognise the selected class from the preserved region. Finally, the last term ensures that the probability of the selected class, after the salient region is removed, is low</li> <li>Setting \\(\\lambda_{4}\\) to a value smaller than 1 (e.g. 0.2) helps reduce this probability to very small values.</li> </ul>"},{"location":"KB/Real%20Time%20Image%20Saliency%20for%20Black%20Box%20Classifiers/#masking-model","title":"Masking Model","text":"<ul> <li>The mask can be found iteratively for a given image-class pair by directly optimising the objective function</li> <li>Unfortunately, iteratively finding the mask is not only very slow, as normally more than 100 iterations are required, but it also causes the mask to greatly overfit to the image and a large TV penalty is needed to prevent adversarial artifacts from forming</li> <li>Therefore, the produced masks are blurry, imprecise, and overfit to the specific</li> <li>image rather than capturing the general behaviour of the classifie</li> <li>develop a trainable masking model that can produce the desired masks in a single forward pass without direct access to the image classifier after training</li> <li>The masking model receives an image and a class selector as inputs and learns to produce masks that minimise our objective function</li> <li>In order to succeed at this task, the model must learn which parts of the input image are considered salient by the black box classifier</li> <li>n theory, the model can still learn to develop adversarial masks that perform well on the objective function, but in practice it is not an easy task, because the model itself acts as some sort of a \"regulariser\" determining which patterns are more likely and which are less.</li> <li>Unet Architecture</li> <li>so that the masking model can use feature maps from multiple resolutions</li> <li>The ResNet-50 model contains feature maps of five different scales, where each subsequent scale block downsamples the input by a factor of two</li> <li>The purpose of the feature filter is to attenuate spatial locations which contents do not correspond to the selected class.</li> <li>Therefore, the feature filter performs the initial localisation, while the following upsampling blocks fine-tune the produced masks</li> <li>The output of the feature filter Y at spatial location i, j is given by:</li> <li> \\[Y_{ij}= X_{ij}\\sigma(X_{ij}^T C_{s})\\] </li> <li>Xij is the output of the Scale 5 block at spatial location i, j; Cs is the embedding of the selected class s and \\(\\sigma(\\cdot)\\) is the sigmoid nonlinearity. Class embedding C can be learned as part of the overall objective.</li> <li>The upsampler blocks take the lower resolution feature map as input and upsample it by a factor of two using transposed convolution</li> <li>afterwards they concatenate the upsampled map with the corresponding feature map from ResNet and follow that with three bottleneck blocks</li> <li>Finally, to the output of the last upsampler block (Upsampler Scale 2) we apply 1x1 convolution to produce a feature map with with just two channels</li> <li>The mask Ms is obtained from</li> <li> \\[M_{s}= \\frac{abs(C_{o})}{abs(C_{o})+ abs(C_{1})}\\] </li> <li>We use this nonstandard nonlinearity because sigmoid and tanh nonlinearities did not optimise properly and the extra degree of freedom from two channels greatly improved training</li> </ul>"},{"location":"KB/Real%20Time%20Image%20Saliency%20for%20Black%20Box%20Classifiers/#training-process","title":"Training Process","text":"<ul> <li>train the masking model to directly minimise the objective function</li> <li>he weights of the pre-trained ResNet encoder (red blocks in figure 4) are kept fixed</li> <li>during the training.</li> <li>sometimes supply a class selector for a fake class and to apply only the area penalty term of the objective function.</li> <li>Under this setting the model must pay attention to the class selector, as the only way it can reduce loss in case of a fake label is by setting the mask to zero</li> <li>During training, we set the probability of the fake label occurrence to 30%</li> <li>One can also greatly speed up the embedding training by ensuring that the maximal value of \\(\\sigma(X_{ij}^{T}C_{s})\\) from equation 7 is high in case of a correct label and low in case of a fake label.</li> <li>evidence removal function \\(\\Phi(X,M)\\)</li> <li>In order to prevent the model from adapting to any single evidence removal scheme the alternative image A is randomly generated every time the function is called</li> <li>In 50% of cases the image A is the blurred version of X (we use a Gaussian blur with = \\(\\sigma=10\\) to achieve a strong blur) and in the remainder of cases, A is set to a random colour image with the addition of a Gaussian noise.</li> <li>Such a random scheme greatly improves the quality of the produced masks as the model can no longer make strong assumptions about the final look of the image.</li> <li>ImageNet</li> <li>three different black-box classifiers: AlexNet [6], GoogLeNet [15] and ResNet-50 [4]</li> <li>These models are treated as black boxes</li> <li>The selected parameters of the objective function are \\(\\lambda_{1} = 10, \\lambda_{2} = 103, \\lambda_{3} = 5, \\lambda_{4} = 0.3\\)</li> <li>The first upsampling block has 768 output channels and with each subsequent upsampling block we reduce the number of channels by a factor of two. We train each masking model as described in section 4.1 on 250,000 images from the ImageNet training set.</li> <li>The masks produced by models trained on GoogLeNet and ResNet are sharp and precise and would produce accurate object segmentations. The saliency model trained on AlexNet produces much stronger and slightly larger saliency regions, possibly because AlexNet is a less powerful model which needs more evidence for successful classification.</li> </ul>"},{"location":"KB/Real%20Time%20Image%20Saliency%20for%20Black%20Box%20Classifiers/#results","title":"Results","text":""},{"location":"KB/Real%20Time%20Image%20Saliency%20for%20Black%20Box%20Classifiers/#future-research","title":"Future Research","text":"<ul> <li>modifying the approach to produce high quality, weakly supervised, image segmentations</li> <li>Moreover, because our model can be run in real-time, it can be used for video saliency detection to instantly explain decisions made by black-box classifiers such as the ones used in autonomous vehicles</li> <li>Lastly, our model might have biases of its own \u2014 a fact which does not seem to influence the model performance in finding biases in other black boxes according to the various metrics we used</li> </ul>"},{"location":"KB/Real%20Time%20Image%20Saliency%20for%20Black%20Box%20Classifiers/#images","title":"Images","text":""},{"location":"KB/Reasoning%20Component/","title":"Reasoning Component","text":""},{"location":"KB/Reasoning%20Component/#reasoning-component","title":"Reasoning Component","text":"<ul> <li>updates the world model and determines plans to achieve goals.</li> </ul>"},{"location":"KB/Recall/","title":"Recall","text":""},{"location":"KB/Recall/#recall","title":"Recall","text":"<ul> <li> \\[\\frac{TP}{TP+FN}\\] </li> <li>Model needs to remember the features such that it does not miss-classify a positive case as a negative one. -&gt; How many positive samples does the model remember?</li> <li># positive classes correctly predicted / total # positive classes</li> </ul>"},{"location":"KB/Receptive%20field/","title":"Receptive field","text":""},{"location":"KB/Receptive%20field/#receptive-field","title":"Receptive Field","text":"<ul> <li>Not for Dense, only local connected layers like Conv, Pooling</li> <li>A neuron's receptive field is the patch of the total field of view that a single neuron has access to</li> <li>Almost a logarithmic relationship between classification accuracy and receptive field size<ul> <li>Large fields are almost necessary for high level recognition tasks, but with diminishing rewards</li> </ul> </li> <li> \\[r(i-1) = s_{i}\\times r_{i} + (k_{i}-s_{i})\\] </li> <li></li> <li>Recursive<ul> <li> \\[r_{0} = \\Sigma^{L}_{i=1}((k_{i}-1)\\Pi_{j=1}^{l-1}s_{j})+1\\] </li> </ul> </li> <li>How to increase receptive field<ul> <li>Add more Conv</li> <li>Add pooling or higher stride</li> <li>Causal Dilated Conv</li> <li>Depthwise Separable</li> </ul> </li> </ul>"},{"location":"KB/Recessive/","title":"Recessive","text":""},{"location":"KB/Recessive/#recessive","title":"Recessive","text":"<ul> <li>A genetic trait or disease that appears only in patients who have received two copies of a mutant gene, one from each parent.</li> </ul>"},{"location":"KB/Recommender%20System/","title":"Recommender System","text":""},{"location":"KB/Recommender%20System/#recommender-system","title":"Recommender System","text":"<ul> <li>Group Modeling Approach</li> <li>Individual Modeling</li> <li>Collaborative Recommender</li> <li>Content Based Recommender</li> </ul>"},{"location":"KB/Reconstruction%20loss/","title":"Reconstruction loss","text":""},{"location":"KB/Reconstruction%20loss/#reconstruction-loss","title":"Reconstruction loss","text":"<ul> <li>The second loss function in capsule networks is called \u201creconstruction loss.\u201d This loss function ensures the network can reconstruct an object from its lower-level features. </li> <li>This is accomplished by training the network to reconstruct an image from the output of the capsule layers.</li> </ul>"},{"location":"KB/Recurrent/","title":"Recurrent","text":""},{"location":"KB/Recurrent/#recurrent","title":"Recurrent","text":"<ul> <li>Sequences as inputs/outputs</li> <li>Sequential processing</li> <li>Turing complete</li> <li>memory through state persisted between timesteps<ul> <li>operation invariant to the sequence</li> <li>reduces no of params needed</li> </ul> </li> <li>Output comes back as input<ul> <li></li> </ul> </li> <li>variable sized inputs and outputs : encoder decoder</li> <li>Three weight matrices and two bias vectors.</li> <li> \\[h_t = \\sigma_h(W_{hh}h_{t-1} + W_{xh}x_t + b_h)\\] </li> <li> \\[y_t = \\sigma_y(W_{hy}h_t + b_y)\\] </li> <li>Stateful : hidden state kept across batches of inputs</li> <li>Activation usually Sigmoid or Tanh</li> <li>BPTT<ul> <li></li> <li> </li> </ul> </li> <li>Training stuff<ul> <li>Softmax but on every output vector simultaneously<ul> <li>If  is lower (eg between 0 and 0.5). It becomes more confident and hence more conservative</li> <li>Near 0 is very diverse and less confident</li> </ul> </li> <li>Feed a char into the RNN -&gt; distribution over characters that comes next -&gt; Sample from it -&gt; Feed it back</li> </ul> </li> <li>Some basic patterns from here<ul> <li>The model first discovers the general word-space structure and then rapidly starts to learn the words.</li> <li>First starting with the short words and then eventually the longer ones.</li> <li>Topics and themes that span multiple words (and in general longer-term dependencies) start to emerge only much later.</li> </ul> </li> </ul>"},{"location":"KB/Recurrent/#gradients","title":"gradients","text":"<ul> <li>If eigen decomposition \\(\\(W = Q\\wedge^tQ\\)\\), then \\(\\(h_t = Q^T\\wedge^tQ\\)\\)</li> <li>If less than 0 then will converge to 0 or if bigger then will explore to infinity -&gt; long sequences</li> <li>Element wise clipping #tricks<ul> <li>Clip if bigger than value</li> </ul> </li> <li>Norm clipping<ul> <li>Clip if $\\(||g|| &gt;v\\) set \\(g = \\frac{gv}{||g||}\\)</li> <li>v can be decided by trial and error</li> </ul> </li> </ul>"},{"location":"KB/Redress/","title":"Redress","text":""},{"location":"KB/Redress/#redress","title":"Redress","text":"<ul> <li>includes mechanisms that ensure an adequate redress for situations when unforeseen unjust adverse impacts take place.</li> <li>Guaranteeing a redress for those non-predicted scenarios is a key to ensure trust. Special attention should be paid to vulnerable persons or groups.</li> </ul>"},{"location":"KB/Reflex%20Hammer/","title":"Reflex Hammer","text":""},{"location":"KB/Reflex%20Hammer/#reflex-hammer","title":"Reflex Hammer","text":"<ul> <li>A specially designed hammer used to test deep tendon or motor reflexes</li> </ul>"},{"location":"KB/RegNet/","title":"RegNet","text":""},{"location":"KB/RegNet/#regnet","title":"RegNet","text":"<ul> <li>network design paradigm</li> <li>discover design principles that generalize across settings</li> <li>arrives at a low-dimensional design space consisting of simple, regular networks</li> <li>widths and depths of good networks can be explained by a quantized linear function</li> <li>outperforms EfficientNet</li> </ul>"},{"location":"KB/Regex%20cheatsheet/","title":"Regex cheatsheet","text":"","tags":["cheatsheets"]},{"location":"KB/Regex%20cheatsheet/#regex-cheatsheet","title":"Regex Cheatsheet","text":"","tags":["cheatsheets"]},{"location":"KB/Regex%20cheatsheet/#dictionary-replace","title":"Dictionary Replace","text":"","tags":["cheatsheets"]},{"location":"KB/Regex%20cheatsheet/#match-before-or-after-a-character","title":"Match before or after a Character","text":"","tags":["cheatsheets"]},{"location":"KB/Regex%20cheatsheet/#specific-types","title":"Specific Types","text":"","tags":["cheatsheets"]},{"location":"KB/Regex%20cheatsheet/#ranges-of-characters","title":"Ranges of Characters","text":"","tags":["cheatsheets"]},{"location":"KB/Regex%20cheatsheet/#repetition","title":"Repetition","text":"","tags":["cheatsheets"]},{"location":"KB/Regex%20cheatsheet/#capture-parts-of-strings","title":"Capture Parts of Strings","text":"","tags":["cheatsheets"]},{"location":"KB/Regex%20cheatsheet/#before-or-after-the-match","title":"Before or after the Match","text":"<ul> <li>No space before, No space after, space before and after<ul> <li></li> </ul> </li> </ul>","tags":["cheatsheets"]},{"location":"KB/Regex%20cheatsheet/#change-matching-start-to-finish-case-whitespace-single_line","title":"Change Matching - Start to Finish, Case, Whitespace, single_line","text":"","tags":["cheatsheets"]},{"location":"KB/Regex%20cheatsheet/#unicode","title":"Unicode","text":"","tags":["cheatsheets"]},{"location":"KB/Regex%20cheatsheet/#complicated-examples","title":"Complicated Examples","text":"","tags":["cheatsheets"]},{"location":"KB/Regex%20cheatsheet/#find-all-sentences-that-ends-with-and-replace-with-or-newline-and-not","title":"Find All Sentences that Ends with [! , . ?] and Replace with . or Newline and not .","text":"","tags":["cheatsheets"]},{"location":"KB/Regex%20cheatsheet/#find-all-emails-and-replace-with-at-and-with-dot","title":"Find All Emails and Replace @ with [at] and . with [dot]","text":"","tags":["cheatsheets"]},{"location":"KB/Regex%20cheatsheet/#find-all-phone-numbers","title":"Find All Phone Numbers","text":"","tags":["cheatsheets"]},{"location":"KB/Region%20Growing/","title":"Region Growing","text":""},{"location":"KB/Region%20Growing/#region-growing","title":"Region Growing","text":"<ul> <li>Automatic Segmentation</li> <li>Requires seed point</li> <li>Leakage through holes in Contour</li> <li></li> </ul>"},{"location":"KB/Region%20Proposal/","title":"Region Proposal","text":""},{"location":"KB/Region%20Proposal/#region-proposal","title":"Region Proposal","text":"<ul> <li>region proposal generation that shares full-image convolutional features with the detection network,</li> <li>nearly cost-free region proposals</li> <li>haring convolutional features with the down-stream detection network</li> <li>simultaneously predicts object bounds and objectness scores at each position</li> </ul>"},{"location":"KB/Register%20Renaming/","title":"Register Renaming","text":""},{"location":"KB/Register%20Renaming/#register-renaming","title":"Register Renaming","text":"<ul> <li>used to avoid unnecessary serialization of program operations caused by the reuse of registers by those operations, in order to enable out-of-order execution</li> <li></li> </ul>"},{"location":"KB/Register%20to%20Register%20Architecture/","title":"Register to Register Architecture","text":""},{"location":"KB/Register%20to%20Register%20Architecture/#register-to-register-architecture","title":"Register to Register Architecture","text":"<ul> <li>All vector operations occur between vector registers</li> <li>If necessary, operands are fetched from main memory into a set of vector registers (load-store unit)</li> <li>SIMD based on this</li> <li></li> </ul>"},{"location":"KB/Regularization%20Rate/","title":"Regularization Rate","text":""},{"location":"KB/Regularization%20Rate/#regularization-rate","title":"Regularization Rate","text":"<ul> <li>A scalar value, represented as lambda, specifying the relative importance of the regularization function.</li> <li>Raising the regularization rate reduces overfitting but may make the model less accurate.</li> <li> </li> <li>The final stage of a recommendation system, during which scored items may be re-graded according to some other (typically, non-ML) algorithm. Re-ranking evaluates the list of items generated by the scoring phase, taking actions such as<ul> <li>Eliminating items that the user has already purchased.</li> <li>Boosting the score of fresher items.</li> </ul> </li> </ul>"},{"location":"KB/Regularization%20Rate/#re-ranking","title":"re-ranking","text":""},{"location":"KB/Regularization%20Term/","title":"Term","text":""},{"location":"KB/Regularization%20Term/#term","title":"Term","text":"<ul> <li>Penalty term</li> <li>Cost function that penalizes model params \\(\\theta\\) with a high degree of flexibility</li> <li> \\[h_{opt} = argmin_{h \\in \\mathcal{H}} \\frac{1}{N}\\Sigma_{i=1}^N L(h(x_i), y_i)+ \\alpha^{2}R(\\theta_h)\\] </li> <li>\\(\\alpha^2\\) determines how much regularizer affects the model<ul> <li>Larger : soft models</li> <li>Increasing -&gt; Down regulating flexibility</li> <li>0 = overfitting and unregularized risk</li> <li>\\(\\infty\\) does not care about training data at all. Only cares about minimal penalty<ul> <li>Dead model</li> </ul> </li> </ul> </li> </ul>"},{"location":"KB/Regularization%20Term/#types","title":"Types","text":"<ul> <li>Lp Regularization for p =2<ul> <li>Soft models</li> <li>Squared sum of model params</li> </ul> </li> </ul>"},{"location":"KB/Regularization/","title":"Regularization","text":""},{"location":"KB/Regularization/#regularization","title":"Regularization","text":"<ul> <li>Regularization Term</li> <li>Dropout</li> <li>VariationalRecurrent Dropout</li> <li>Batch Normalization</li> <li>Layer Normalization</li> <li>Augmentation</li> <li>Lp Regularization</li> <li>Pruning</li> <li>Effects of Regularization</li> </ul>"},{"location":"KB/Reinforcement%20Learning/","title":"Reinforcement Learning","text":""},{"location":"KB/Reinforcement%20Learning/#reinforcement-learning","title":"Reinforcement Learning","text":""},{"location":"KB/Reinforcement%20Learning/#anchor","title":"anchor","text":""},{"location":"KB/Rejection%20Sampling/","title":"Rejection Sampling","text":""},{"location":"KB/Rejection%20Sampling/#rejection-sampling","title":"Rejection Sampling","text":"<ul> <li>Also called Best-of-n sampling</li> <li>No CDF with a simple inverse</li> <li>Importance sampling</li> <li>Use a simpler distribution which is somewhat related to the target PDF<ul> <li>Sample by transformation</li> </ul> </li> <li>Now if we can take a Proto PDF \\(g_{0} \\geq f\\) where we can sample from the PDF g</li> <li>Take a point from g with Probability \\(f(\\tilde x)/g_{0}(\\tilde x)\\)<ul> <li>Either accept or reject if satisfies Probability</li> <li>If accepted then return the sample</li> </ul> </li> <li>Drop a point from \\(g_{0}(x)\\) with that Probability</li> <li>Depends on how close g is to f of course</li> <li><ul> <li>If the ratio \\(\\frac{f}{g_{0}}\\) is small. (aka f is bigger), then there are many rejections and the algo will be slow. Impossible to not do in high dim spaces</li> </ul> </li> </ul>"},{"location":"KB/Relational%20Inductive%20Bias/","title":"Relational Inductive Bias","text":""},{"location":"KB/Relational%20Inductive%20Bias/#relational-inductive-bias","title":"Relational Inductive Bias","text":"<ul> <li>Weak Relation Bias</li> <li>Locality</li> <li>Sequential Relation Bias</li> <li>Arbitrary Relation Bias</li> </ul>"},{"location":"KB/Relative%20Multi%20Head%20Self%20Attention/","title":"Relative Multi Head Self Attention","text":""},{"location":"KB/Relative%20Multi%20Head%20Self%20Attention/#relative-multi-head-self-attention","title":"Relative Multi Head Self Attention","text":"<ul> <li>ZihangDai et al., 2019</li> </ul>"},{"location":"KB/Relevance%20Account/","title":"Relevance Account","text":""},{"location":"KB/Relevance%20Account/#relevance-account","title":"Relevance Account","text":"<ul> <li>(Philip 2011)</li> <li>pragmatic extension of the theory of Drozd and Loosbroek (2006)</li> <li>Philip claims that the problem that children have to solve when assigning a domain to a universal quantifier is which objects in the context should be taken as relevant.</li> <li>Adults rely on their world knowledge in identifying the presupposed set</li> <li>As formulated in the Normal World Constraint, \"if an object is contextually relevant, then there is a normal situation that it is part of.\"</li> </ul>"},{"location":"KB/Relevance%20Theory/","title":"Relevance Theory","text":""},{"location":"KB/Relevance%20Theory/#relevance-theory","title":"Relevance Theory","text":"<ul> <li>Relevance Theory is built on the assumption that attention and thought processes automatically turn toward information that seems relevant, capable of yielding cognitive effects</li> <li>As the Principle of Relevance states, communicated information comes with a guarantee of relevance.</li> <li>The higher the cognitive effect of the information, and/or the more economically it is communicated, the greater its relevance.</li> </ul>"},{"location":"KB/Relu/","title":"Relu","text":""},{"location":"KB/Relu/#relu","title":"Relu","text":"<ul> <li> \\[ReLU(x) = max(0,x)\\] </li> <li> \\[\\frac{d}{d_x}ReLU(X) = \\begin{cases}0 &amp; x \\geq 0 \\\\ 1 &amp; otherwise \\end{cases}\\] </li> <li>He init</li> <li>MLP, CNN : Hidden</li> <li></li> <li>Leaky Relu</li> <li>PRelu</li> <li>Noisy Relu</li> </ul>"},{"location":"KB/Remission/","title":"Remission","text":""},{"location":"KB/Remission/#remission","title":"Remission","text":"<ul> <li>Describes a disease that is not getting worse</li> </ul>"},{"location":"KB/RepLKNet/","title":"RepLKNet","text":""},{"location":"KB/RepLKNet/#replknet","title":"RepLKNet","text":"<ul> <li>impressively manages to scale the kernel size to 31\u00d731 with improved performance</li> <li>the performance starts to saturate as the kernel size continues growing, compared to the scaling trend of ad- vanced ViTs such as Swin Transformer</li> <li>explore the possibility of training extreme convolutions larger than 31\u00d731 and test whether the performance gap can be eliminated by strategically enlarging convolutions.</li> </ul>"},{"location":"KB/RepVGG/","title":"RepVGG","text":"<p>toc: true title: RepVGG</p> <p>categories: ['temp']</p>"},{"location":"KB/RepVGG/#repvgg","title":"RepVGG","text":"<ul> <li>RepVGG: Making Vgg-style ConvNets Great Again<ul> <li>stack of \\(3\\times3\\) Conv and Relu during inference time</li> <li>training-time model has a multi-branch topology</li> <li>decoupling of the training-time and inference-time architecture is realized by a structural re-parameterization technique</li> <li>5 stages and conducts down-Sampling via stride-2 convolution at the beginning of a stage</li> <li>identity and 1 \\times 1 branches, but only for training</li> <li>ImageNet</li> <li>higher accuracy and show favorable accuracy-speed trade-off compared to the state-of-the-art models like EfficientNet and RegNet</li> <li></li> </ul> </li> </ul>"},{"location":"KB/Representation%20Bias/","title":"Representation Bias","text":""},{"location":"KB/Representation%20Bias/#representation-bias","title":"Representation Bias","text":"<ul> <li>As multitask is performed, introduces bias to learn Features and generalizing for other tasks</li> <li>increases chances that more general features are learned</li> </ul>"},{"location":"KB/Res%20Net%20D/","title":"Res Net D","text":""},{"location":"KB/Res%20Net%20D/#res-net-d","title":"Res Net D","text":""},{"location":"KB/Res%20Net/","title":"Res Net","text":""},{"location":"KB/Res%20Net/#res-net","title":"Res Net","text":"<ul> <li>@heDeepResidualLearning2016</li> <li>Deep Residual Learning for Image Recognition</li> <li>Deeper Networks have Issues because of vanishing #gradients</li> <li>Propagate gradients forward for deeper networks</li> <li>Skip connections</li> <li>output of F(x) has the same dims as x -&gt; add</li> <li>If only spatial dims match (aka not channels) -&gt; concat</li> <li>less params than VGG</li> <li>Skip Connection</li> <li>Sadly, one of the creators Jian Sun passed away yesterday. (16-6-22)</li> </ul> <pre><code>def make_layer(inplanes, planes, block, n_blocks, stride=1):\n    downsample = None\n    if stride != 1 or inplanes != planes * block.expansion:\n        # output size won't match input, so adjust residual\n        downsample = nn.Sequential(\n            nn.Conv2d(inplanes, planes * block.expansion,\n                      kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(planes * block.expansion),\n        )\n    return nn.Sequential(\n        block(inplanes, planes, stride, downsample),\n        *[block(planes * block.expansion, planes) for _ in range(1, n_blocks)]\n    )\n\ndef ResNetNew(block, layers, num_classes=1000):    \n    e = block.expansion\n\n    resnet = nn.Sequential(\n        Rearrange('b c h w -&gt; b c h w', c=3, h=224, w=224),\n        nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n        nn.BatchNorm2d(64),\n        nn.ReLU(inplace=True),\n        nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n        make_layer(64,      64,  block, layers[0], stride=1),\n        make_layer(64 * e,  128, block, layers[1], stride=2),\n        make_layer(128 * e, 256, block, layers[2], stride=2),\n        make_layer(256 * e, 512, block, layers[3], stride=2),\n        # combined AvgPool and view in one averaging operation\n        Reduce('b c h w -&gt; b c', 'mean'),\n        nn.Linear(512 * e, num_classes),\n    )\n\n    # [initialization](./Initialization.md)\n    for m in resnet.modules():\n        if isinstance(m, nn.Conv2d):\n            n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n            m.weight.data.normal_(0, math.sqrt(2. / n))\n        elif isinstance(m, nn.BatchNorm2d):\n            m.weight.data.fill_(1)\n            m.bias.data.zero_()\n    return resnet\n</code></pre>"},{"location":"KB/Rescorla-Wagner%20Algorithm/","title":"Rescorla-Wagner Algorithm","text":""},{"location":"KB/Rescorla-Wagner%20Algorithm/#rescorla-wagner-algorithm","title":"Rescorla-Wagner Algorithm","text":"<ul> <li>Rescorla &amp; Wagner (1972): animals and humans also learn associations by paying attention to what is not associated.</li> <li> \\[\\Delta V = \\alpha \\beta_{1}\\beta_{2}(\\lambda = \\Sigma V)\\] </li> <li>\u25b6 V = association strength \u25b6 \u2206 V : Change in association strength \u25b6 \u03bb = maximum values of the unconditional stimulus \u25b6 Set to 1: when US is present (food) \u25b6 Set to 0: when not present \u25b6 \u03b1 = learning rate \u25b6 \u03b2 = varies the effects of negative or positive evidence \u25b6 \u03a3V = sum of associated strengths for all cues/features/conditions stimuli</li> <li>negative instances are also useful to learning</li> <li>Logical Problem of Lang Acquisition</li> <li>Children don't get negative evidence = must be innate</li> <li>Cross-situational learning</li> <li>Propose-but-verify</li> <li>Rescorla-Wagner Blocking</li> <li>Rescorla-Wagner = error-driven</li> <li>After a strong association is made, as long as it is confirmed by data, no new learning will occur</li> <li>The model only learns when the predicted outcome differs from actual outcome</li> </ul>"},{"location":"KB/Rescorla-Wagner%20Blocking/","title":"Rescorla-Wagner Blocking","text":""},{"location":"KB/Rescorla-Wagner%20Blocking/#rescorla-wagner-blocking","title":"Rescorla-Wagner Blocking","text":"<ul> <li>If an outcome is already strongly associated with a stimuli (cue or feature), the presence of other features, regardless of how consistent they are, will not lead to a new association</li> </ul>"},{"location":"KB/Research%20Debt/","title":"Research Debt","text":""},{"location":"KB/Research%20Debt/#research-debt","title":"Research Debt","text":"<ul> <li>Research Debt</li> <li>Achieving a research-level understanding of most topics is like climbing a mountain.</li> <li>Aspiring researchers must struggle to understand vast bodies of work that came before them, to learn techniques, and to gain intuition</li> <li>Upon reaching the top, the new researcher begins doing novel work, throwing new stones onto the top of the mountain and making it a little taller for whoever comes next.</li> <li>People expect the climb to be hard</li> <li>It reflects the tremendous progress and cumulative effort that\u2019s gone into mathematics</li> <li>The climb is seen as an intellectual pilgrimage, the labor a rite of passage</li> <li>But the climb could be massively easier</li> <li>It\u2019s entirely possible to build paths and staircases into these mountains.</li> <li>That is, really outstanding tutorials, reviews, textbooks, and so on.</li> <li>technical debt</li> <li>institutional debt</li> <li>Poor Exposition</li> <li>Interpretive Labor</li> <li>Clear Thinking</li> <li>Research Distillation</li> </ul>"},{"location":"KB/Research%20Distillation/","title":"Research Distillation","text":""},{"location":"KB/Research%20Distillation/#research-distillation","title":"Research Distillation","text":"<ul> <li>It can be incredibly satisfying, combining deep scientific understanding, empathy, and design to do justice to our research and lay bare beautiful insights.</li> <li>Distillation is also hard</li> <li>It\u2019s tempting to think of explaining an idea as just putting a layer of polish on it, but good explanations often involve transforming the idea.</li> <li>This kind of refinement of an idea can take just as much effort and deep understanding as the initial discovery.</li> <li>We can\u2019t solve research debt by having one person write a textbook</li> </ul>"},{"location":"KB/Research%20Engineer%20in%20Human%20Modeling%20for%20Automated%20Driving%20delft/","title":"Research Engineer in Human Modeling for Automated Driving delft","text":"","tags":["mlops"]},{"location":"KB/Research%20Engineer%20in%20Human%20Modeling%20for%20Automated%20Driving%20delft/#research-engineer-in-human-modeling-for-automated-driving-subhaditya-mukherjee","title":"Research Engineer in Human Modeling for Automated Driving - Subhaditya Mukherjee","text":"<p>As AI gets more advanced, applications such as automated driving become more feasible. But the real challenge is ensuring responsible and reliable implementations of algorithms with a safety-first mindset. That being the case, I am quite interested in contributing to research in this domain. I remember working on a similar project in my bachelors with a startup for a little bit, but sadly, COVID-19 put a halt to their operations, and I could not continue with them. The work was quite interesting though, and I was sad about losing the opportunity back then. So, when this position showed up in my search, I did not want to miss out again.</p> <p>As of a month ago, I have a masters in AI from the University of Groningen, which now also puts me in a better position to tackle the challenges faced in developing these models. My interest is at the intersection of applied AI and explainability, and I am quite familiar with Python, deep learning frameworks such as PyTorch and Tensorflow and other tricks of the trade. Interestingly enough, I also enjoy teaching and was a TA for three courses in my masters as well. While I bring programming, AI and computer vision skills to the table, I am willing to learn whatever else is required for the project. I firmly believe in human-in-the-loop solutions to life-critical problems such as this one, and I can also contribute to the explainability and fairness of the system. </p> <p>I believe that this position would be the perfect next step for me as it not only is a project with real-world impact, but also involves quite a bit of interdisciplinary research. I hope you give me a chance, and I look forward to hearing back from you.</p> <p>Thank you, Subhaditya Mukherjee</p>","tags":["mlops"]},{"location":"KB/Research%20Intimacy/","title":"Research Intimacy","text":""},{"location":"KB/Research%20Intimacy/#research-intimacy","title":"Research Intimacy","text":"<ul> <li>Internalizing obscure knowledge, equations, relationships, and ways of thinking related to a research topic.</li> <li>link</li> </ul>"},{"location":"KB/Resistance/","title":"Resistance","text":""},{"location":"KB/Resistance/#resistance","title":"Resistance","text":"<ul> <li>resistance =\u00a0resistivity x length\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 cross sectional area</li> <li> \\[R = r/A\\] </li> </ul>"},{"location":"KB/ResizeMix/","title":"ResizeMix","text":""},{"location":"KB/ResizeMix/#resizemix","title":"ResizeMix","text":"<ul> <li>@qinResizeMixMixingData2020</li> <li>performs random image cropping and pasting</li> <li>ResizeMix solves the random region cropping problem that misallocates the output image label in certain cases where the pasted region does not contain any object informa- tion</li> <li>scaling down (scale rate is sampled from a uniform dis- tribution) the selected image completely and past- ing it randomly on the target image</li> <li>modified labels of the output image are always accurate and proportionate to the mixing.</li> </ul>"},{"location":"KB/Response%20Based%20Knowledge/","title":"Response Based Knowledge","text":""},{"location":"KB/Response%20Based%20Knowledge/#response-based-knowledge","title":"Response Based Knowledge","text":"<ul> <li>neural response of the last output layer of the teacher model. The main idea is to directly mimic the final prediction of the teacher model.</li> <li>Given a vector of logits z as the outputs of the last fully connected layer of a deep model, the Distillation Loss for response-based knowledge can be formulated as</li> <li>response in object detection task may contain the logits together with the offset of a bounding box (Chen et al., 2017). In semantic landmark localization tasks, e.g., human pose estimation, the response of the teacher model may include a heatmap for each landmark (Zhang et al., 2019a)</li> </ul>"},{"location":"KB/Restricted%20Boltzmann%20Machine/","title":"Restricted Boltzmann Machine","text":""},{"location":"KB/Restricted%20Boltzmann%20Machine/#restricted-boltzmann-machine","title":"Restricted Boltzmann Machine","text":"<ul> <li>Start of Deep learning</li> </ul>"},{"location":"KB/RetinaNet/","title":"RetinaNet","text":""},{"location":"KB/RetinaNet/#retinanet","title":"RetinaNet","text":"<ul> <li>Simple dense detector for Focal Loss</li> </ul>"},{"location":"KB/Reuptake/","title":"Reuptake","text":""},{"location":"KB/Reuptake/#reuptake","title":"Reuptake","text":"<ul> <li>A process by which released neurotransmitters are absorbed for subsequent re-use.</li> </ul>"},{"location":"KB/Revisiting%20variable%20foreperiod%20effects%20evaluating%20the%20repetition%20priming%20account/","title":"Revisiting variable foreperiod effects evaluating the repetition priming account","text":""},{"location":"KB/Revisiting%20variable%20foreperiod%20effects%20evaluating%20the%20repetition%20priming%20account/#revisiting-variable-foreperiod-effects-evaluating-the-repetition-priming-account","title":"Revisiting variable foreperiod effects evaluating the repetition priming account","text":"<ul> <li>Tianfang Han &amp; Robert W. Proctor</li> </ul>"},{"location":"KB/Revisiting%20variable%20foreperiod%20effects%20evaluating%20the%20repetition%20priming%20account/#abstract","title":"Abstract","text":"<ul> <li>A warning signal preceding an imperative stimulus by a certain foreperiod can accelerate responses (foreperiod effect)</li> <li>When foreperiod is varied within a block, the foreperiod effect on reaction time (RT) is modulated by both the current and the prior foreperiod</li> <li>The multiple-trace theory of Los et al. (Frontiers in Psychology, 5, Article 1058, 2014) attributes the slope of the foreperiod-RT function to the foreperiod distribution</li> <li>with a non-aging foreperiod distribution, the variableforeperiod paradigm yields unequal sequential-effect sizes at the different foreperiods, consistent with the multiple-trace theory but contrary to Capizzi et al.'s repetition-priming account</li> <li>The foreperiod-RT functions are similar to those of the fixedforeperiod paradigm, which is not predicted by the multiple trace theory</li> </ul>"},{"location":"KB/Revisiting%20variable%20foreperiod%20effects%20evaluating%20the%20repetition%20priming%20account/#experiment-1","title":"Experiment 1","text":"<ul> <li>Both the foreperiods and foreperiod distribution were the same, but a choice-reaction task</li> <li>Responses were faster when the current foreperiod was 400 ms compared to 1,400 ms</li> <li>was also a main effect of Foreperiod Sequence,</li> <li>Responses were faster when the current foreperiod was the same as the previous one compared to when they were different.</li> <li>the interaction of Current Foreperiod \u00d7 Foreperiod Sequence indicated that the SFP effect was larger at the short foreperiod than at the long foreperiod</li> <li>This result is inconsistent with the repetition priming account of Capizzi et al., according to which the SFP effects should be of similar sizes at short and long foreperiods</li> <li>The larger SFP effect at short than long foreperiods is consistent with Los et al.'s (2014) multiple trace theory</li> <li>This is because it assumes that a long previous foreperiod produces inhibition to the critical moment of the short foreperiod but a short previous foreperiod does not affect the preparation at the critical moment of the long foreperiod</li> <li>symmetric sequential effects are more likely to be found in choicereaction tasks compared to a simple reaction scenario.</li> <li>the larger proportion of shorter foreperiod trials could be the basis of that foreperiod's advantage in terms of response speed by having more previous memory traces contributing to the activation at the shorter foreperiod's critical moment</li> <li>Alternatively, the increasing foreperiod-RT function in Experiment 1 shared the same direction as in a fixedforeperiod paradigm</li> <li>without the effect from the additional processes in a variable-foreperiod paradigm, the foreperiod-RT relation in the two foreperiod paradigms will be in the same direction</li> </ul>"},{"location":"KB/Revisiting%20variable%20foreperiod%20effects%20evaluating%20the%20repetition%20priming%20account/#experiment-2","title":"Experiment 2","text":"<ul> <li>two very short foreperiods (50 ms and 200 ms) were used</li> <li>This prediction means that the shorter preceding foreperiod should produce faster responses regardless of the length of the current foreperiod</li> <li>Based on the current assumptions of MTP, the preparation at any foreperiod is determined by the activationinhibition states (strengths of activation and inhibition) stored in each [memory trace], the strength of each [memory trace] (memory trace, and the total number of previous memory traces with each foreperiod</li> <li>Participants were more likely to make errors when encountering foreperiod repetition compared to alternation</li> <li>main effect of Current Foreperiod was not significant</li> <li>The interaction between Foreperiod Sequence and Current Foreperiod was not significant</li> <li>First, the main effect of Current Foreperiod was found, indicating a decreasing foreperiod-RT function in the short-foreperiod scenario</li> <li>This direction is consistent with the prediction based on the fixed-foreperiod effect but this foreperiod-RT function, especially its opposite direction from that observed in Experiment 1, cannot be predicted from the current assumptions of the MTP</li> <li>A small interaction was found between Current Foreperiod and Foreperiod Sequence</li> <li>It is worth noting that participants were more likely to make errors when the current foreperiod matched the previous one compared to when it did not</li> </ul>"},{"location":"KB/Revisiting%20variable%20foreperiod%20effects%20evaluating%20the%20repetition%20priming%20account/#experiment-3","title":"Experiment 3","text":"<ul> <li>The main effect of Current Foreperiod was not significant</li> <li>neither was the interaction between Current Foreperiod and Foreperiod Sequence</li> <li>With regard to the variable-foreperiod effect, although a significant main effect was not detected (p = .085), the numerical difference in RT at the two foreperiods pointed in the same direction as the significant fixedforeperiod effect</li> </ul>"},{"location":"KB/Revisiting%20variable%20foreperiod%20effects%20evaluating%20the%20repetition%20priming%20account/#discussion","title":"Discussion","text":"<ul> <li>Los et al. (2017) used a visual warning signal and a visual imperative stimulus and found that blocks with the same foreperiod distribution (exponential or antiexponential) induced a short-term carryover effect on the foreperiod-RT function in subsequent blocks with a uniform distribution</li> <li>Crowe and Kent (2019) used an auditory pair of stimuli and found a similar but more limited carryover effect (lasting for only one block)</li> <li>imply that having the fixed-foreperiod blocks performed immediately after the variable-foreperiod blocks could have made it more difficult to measure the fixed-foreperiod effect precisely, which could be a potential limitation of the current design</li> <li>The key step of reconnecting the two foreperiod paradigms was taken by Los et al. (2014), in which a simplified version of the MTP without the activation-inhibition ratio was used to account for the fixedforeperiod effect</li> <li>A lower maximum and greater temporal dispersion as the imperative moment is moved further from the warning signal were added to predict a shorter RT at the short foreperiod</li> <li>by using a non-aging foreperiod distribution, the variableforeperiod effect would get back to its baseline, which is the foreperiod-RT function in a fixed-foreperiod paradigm</li> </ul>"},{"location":"KB/Revisiting%20variable%20foreperiod%20effects%20evaluating%20the%20repetition%20priming%20account/#conclusion","title":"Conclusion","text":"<ul> <li>The results of this study suggest that the SFP effect reflects a benefit of repetition, which can be attributed to the memory of prior trials</li> <li>SFP effect was larger at the shorter foreperiod, which is consistent with MTP</li> <li>On the other hand, we showed that in a variable foreperiod paradigm, when the conditional probability of the imperative stimulus appearing at the next foreperiod stays constant over time, the foreperiodRT function follows the foreperiod-RT relation in a fixed foreperiod paradigm.</li> <li>This consistency between different foreperiod paradigms is not predicted by the MTP, which attributes the foreperiod-RT function to the proportions of foreperiods</li> </ul>"},{"location":"KB/Revisiting%20variable%20foreperiod%20effects%20evaluating%20the%20repetition%20priming%20account/#images","title":"Images","text":""},{"location":"KB/Revolute%20Joint/","title":"Revolute Joint","text":""},{"location":"KB/Revolute%20Joint/#revolute-joint","title":"Revolute Joint","text":"<ul> <li>The joints of a robot, which are capable of rotary motion.</li> </ul>"},{"location":"KB/Ridge%20Regression/","title":"Ridge Regression","text":""},{"location":"KB/Ridge%20Regression/#ridge-regression","title":"Ridge Regression","text":"<ul> <li>LinearRegression</li> <li>\\(\\((XX')\\)\\) suffers from numerical instability when almost singular (real world data. sparse I think)</li> <li>Add a tiny term<ul> <li> \\[w'_{opt} = (XX' + \\alpha ^2 I_{nxn})^{-1}XY\\] </li> <li>Solution to overfitting</li> </ul> </li> </ul>"},{"location":"KB/Risk%20Mitigation/","title":"Risk Mitigation","text":""},{"location":"KB/Risk%20Mitigation/#risk-mitigation","title":"Risk Mitigation","text":"<ul> <li>A secondary step in the risk assessment process that involves reducing the level of risk for the identified tasks, by applying risk reduction measures in order to eliminate or mitigate the hazards.</li> </ul>"},{"location":"KB/Rmsprop/","title":"Rmsprop","text":""},{"location":"KB/Rmsprop/#rmsprop","title":"Rmsprop","text":"<ul> <li>RL</li> <li>More stable than Adagrad</li> <li>Moving exponential avg : older grads given less weight</li> <li>$$\\begin{align}\\</li> </ul> <p>&amp; E[g^{2}]{t}= 0.9E[g^{2}]{t-1}+ 0.1g^{2}_{t}\\</p> <p>&amp; \\theta_{t+1}= \\theta_{t}- \\frac{\\eta}{\\sqrt{E[g^{2}]){t}+\\epsilon}}g{t}</p> <p>\\end{align}</p> <p>$$ - Suggested \\(\\gamma=0.9\\) and \\(\\eta= 0.001\\)</p>"},{"location":"KB/RoBERTa/","title":"RoBERTa","text":""},{"location":"KB/RoBERTa/#roberta","title":"RoBERTa","text":"<ul> <li>RoBERTa: a Robustly Optimized BERT Pretraining Approach</li> <li>evaluates a number of design decisions when pretraining BERT models</li> <li>They find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it.</li> <li>performance can be substantially improved by training the model longer, with bigger batches over more data; removing the next sentence prediction objective; training on longer sequences; and dynamically changing the masking pattern applied to the training data</li> <li>GLUE</li> <li>RACE</li> <li>SQuAD</li> <li>only the masked language model objective</li> </ul>"},{"location":"KB/Robot%20Range%20Limit%20Monitoring/","title":"Robot Range Limit Monitoring","text":""},{"location":"KB/Robot%20Range%20Limit%20Monitoring/#robot-range-limit-monitoring","title":"Robot Range Limit Monitoring","text":"<ul> <li>Monitors the manipulator arm or its tool to be in the designated safety area</li> </ul>"},{"location":"KB/Robotic%20Joints/","title":"Robotic Joints","text":""},{"location":"KB/Robotic%20Joints/#robotic-joints","title":"Robotic Joints","text":"<ul> <li>Joints connect the manipulator links</li> <li>A joint normally provides one Controllable Degree of Freedom (CDOF)</li> <li>For each CDOF one separate actuator is needed</li> <li>An endeffector with many (C)DOFs needs a lot of actuators!</li> <li>Rotary Joint , Prismatic Joint</li> </ul>"},{"location":"KB/Robust%20RegNet/","title":"Robust RegNet","text":"<p>toc: true title: Robust RegNet</p> <p>categories: ['temp']</p>"},{"location":"KB/Robust%20RegNet/#robust-regnet","title":"Robust RegNet","text":"<ul> <li>Vision Models are More Robust and Fair When Pretrained on Uncurated Images Without Supervision</li> <li>Unsupervised Learning</li> <li>Discriminative Self Supervised learning allows training models on any random group of internet images, and possibly recover salient information that helps differentiate between the images</li> <li>ImageNet</li> <li>object-centric features that perform on par with supervised features on most object-centric downstream tasks</li> <li>learn any salient and more representative information present in diverse unbounded set of images from across the globe</li> <li>without any data pre-processing or prior assumptions about what we want the model to learn</li> <li>RegNet</li> <li>scaled to a dense 10 billion parameters</li> <li>pre-trained using the SwaV self-supervised method on a large collection of 1 billion randomly selected public images from Instagram with a diversity of gender, ethnicity, cultures, and locations</li> <li>captures well semantic information</li> <li>captures information about artistic style and learns salient information such as geo-locations and multilingual word embeddings based on visual content only.</li> <li>large-scale self-supervised pre-training yields more robust, fair, less harmful, and less biased results than supervised models or models trained on object centric datasets such as ImageNet</li> </ul>"},{"location":"KB/Rod/","title":"Rod","text":""},{"location":"KB/Rod/#rod","title":"Rod","text":"<ul> <li>A type of photoreceptor, usually found on the outer edges of the retina, that helps facilitate peripheral vision.</li> </ul>"},{"location":"KB/Roll/","title":"Roll","text":""},{"location":"KB/Roll/#roll","title":"Roll","text":"<ul> <li>Rotation of the robot end effector in a plane perpendicular to the end of the manipulator arm.</li> </ul>"},{"location":"KB/Rotary%20Joint/","title":"Rotary Joint","text":""},{"location":"KB/Rotary%20Joint/#rotary-joint","title":"Rotary Joint","text":""},{"location":"KB/Rotary%20Vector%20Drive%20%28RV%29/","title":"Rotary Vector Drive (RV)","text":""},{"location":"KB/Rotary%20Vector%20Drive%20%28RV%29/#rotary-vector-drive-rv","title":"Rotary Vector Drive (RV)","text":"<ul> <li>A brand name for a speed reduction device that converts high speed low torque to low speed high torque, usually used on the major (larger) axis . See Cyclo Drive and Harmonic Drive.</li> </ul>"},{"location":"KB/Rotational%20Invariance/","title":"Rotational Invariance","text":""},{"location":"KB/Rotational%20Invariance/#rotational-invariance","title":"Rotational Invariance","text":"<ul> <li>In an image classification problem, an algorithm's ability to successfully classify images even when the orientation of the image changes. For example, the algorithm can still identify a tennis racket whether it is pointing up, sideways, or down. Note that rotational invariance is not always desirable; for example, an upside-down 9 should not be classified as a 9.</li> </ul>"},{"location":"KB/Routing%20by%20Agreement/","title":"Routing by Agreement","text":""},{"location":"KB/Routing%20by%20Agreement/#routing-by-agreement","title":"Routing by Agreement","text":"<ul> <li>The outputs of the higher-layer capsules are determined by a process called \u201crouting by agreement,\u201d</li> <li>determines the strength of the connection between capsules in different layers.</li> </ul>"},{"location":"KB/Runge%20Kutta/","title":"Runge Kutta","text":""},{"location":"KB/Runge%20Kutta/#runge-kutta","title":"Runge Kutta","text":"<ul> <li>Fourth Order</li> <li></li> <li></li> </ul>"},{"location":"KB/S2ST/","title":"S2ST","text":""},{"location":"KB/S2ST/#s2st","title":"S2ST","text":"<ul> <li>Direct Speech-to-speech Translation with Discrete Units</li> <li>direct speech-to-speech translation (S2ST) model that translates speech from one language to speech in another language without relying on intermediate text generation</li> <li>self-supervised discrete speech encoder on the target speech</li> <li>training a sequence-to-sequence speech-to-unit translation</li> <li>model to predict the discrete representations of the target speech</li> <li>When target text transcripts are available, they design a joint speech and text training framework that enables the model to generate dual modality output (speech and text) simultaneously in the same inference pass</li> <li>Fisher Spanish-English</li> </ul>"},{"location":"KB/SAM-ResNet/","title":"SAM-ResNet","text":""},{"location":"KB/SAM-ResNet/#sam-resnet","title":"SAM-ResNet","text":"<ul> <li>@corniaPredictingHumanEye2018</li> <li>uses LSTM to compute an attention map. The feature map extracted by ResNet is input to attentive convolutional LSTM that focuses on the most salient regions of the input image to iteratively refine the predicted saliency map.</li> <li>We recently proposed a Saliency Attentive Model (SAM) which, in contrast, incorporates attentive mechanisms to iteratively refine saliency predictions. Overall, it is composed by three main components: a Dilated Convolutional Network that extracts feature maps from the input image, an Attentive Convolutional LSTM which recurrently enhances saliency features and a learned prior module that incorporates the human-gaze center bias in the final predictions</li> </ul>"},{"location":"KB/SAM-ResNet/#attentive-convolutional-lstm","title":"Attentive Convolutional LSTM","text":"<ul> <li>The feature maps coming from the dilated network are then input to an Attentive Convolutional model, which recurrently process saliency features at different locations.</li> <li>Moreover, we exploit the sequential nature of LSTM to process features in an iterative way. The input of the LSTM is computed, at each step, through an attentive mechanism which focuses on different regions of the image.</li> <li>An attention map is generated by convolving the previous hidden state and the input (i.e. a stack of feature maps); once normalized through the softmax operator, this is applied to the input with an element-wise product</li> <li>After a fixed number of iterations, the last hidden state is taken as the output of this module.</li> </ul>"},{"location":"KB/SAM-ResNet/#learned-priors","title":"Learned Priors.","text":"<ul> <li>Finally, the output of the Attentive LSTM is combined with multiple learned priors which are used to model the center bias present in the human-eye fixations. Differently from existing works, which included predefined priors, we let the network learn its own priors. To reduce the number of parameters and facilitate the learning, we constraint that each prior should be a 2d Gaussian function, whose mean and covariance matrix are freely learnable. In this manner, priors are inferred purely from data,</li> <li>Thanks to this strategy, the predicted saliency maps are rescaled, for both versions, by a factor of 8 instead of 32 as in the original CNNs.</li> <li>In our work, we go beyond classical feed-forward networks to predict saliency maps and</li> <li>propose a Saliency Attentive Model which incorporates neural attention mechanisms to iteratively refine predictions</li> <li>Here, we provide experimental results on other popular saliency datasets to confirm the effectiveness and the generalization capabilities of our model, which enable us to reach the state of the art on all considered datasets.</li> </ul>"},{"location":"KB/SAM-ResNet/#loss-function","title":"Loss Function","text":"<ul> <li>linear combination of three saliency evaluation metrics: the Normalized Scanpath Saliency (NSS), the Linear Correlation Coefficient (CC) and the KullbackLeibler Divergence (KL-Div)</li> <li>SALICON</li> <li>omposed by 20, 000 images with corresponding saliency maps computed from mouse movements</li> </ul>"},{"location":"KB/SAM-ResNet/#images","title":"Images","text":""},{"location":"KB/SBU%20Captions/","title":"SBU Captions","text":""},{"location":"KB/SBU%20Captions/#sbu-captions","title":"SBU Captions","text":""},{"location":"KB/SDR/","title":"SDR","text":""},{"location":"KB/SDR/#sdr","title":"SDR","text":"<ul> <li>Smallest destroying region</li> <li>smallest region of the image that when removed, prevents a confident classification.</li> </ul>"},{"location":"KB/SELU/","title":"SELU","text":""},{"location":"KB/SELU/#selu","title":"SELU","text":"<ul> <li> \\[selu(x) = \\lambda x , \\text{if } x &gt;0 , \\text{else }, \\alpha(e^{x}-1)\\] </li> </ul>"},{"location":"KB/SELU/#information","title":"Information","text":"<ul> <li>Paper:\u00a0https://arxiv.org/pdf/1706.02515.pdf</li> <li>scaled variant of the\u00a0Elu\u00a0function</li> <li>does internal normalization (\"self-normalizing\")<ul> <li>each layer preserves the mean and the variance from the previous one</li> <li>normalization happens within the activation function</li> <li>to work:<ul> <li>input features must be standardized</li> <li>architecture must be sequential<ul> <li>self-normalizing not guaranteed otherwise</li> </ul> </li> <li>SELU as activation\u00a0</li> <li>custom\u00a0Initialization<ul> <li>zero mean</li> <li>standard deviation:\u00a0\\(\\sqrt{\\frac{1}{ \\#inputs}}\\)</li> </ul> </li> <li>if all layers are dense (in paper), but other research showed that it also works for CNNs</li> </ul> </li> </ul> </li> <li>has two fixed parameters\u00a0\u03b1\u00a0and\u00a0\u03bb<ul> <li>not hyperparameters nor learnt parameters</li> <li>derived from the inputs (\u03bc=0,\u00a0std=1)</li> <li>\u03b1\u22481.6732,\u00a0\u03bb\u22481.0507</li> </ul> </li> <li>Pros:<ul> <li>no\u00a0Vanishingexploding gradients</li> <li>cannot die as\u00a0Relu</li> <li>converges faster and to a better result than other activation functions</li> <li>significantly outperformed other activation functions for deep networks</li> </ul> </li> <li>Cons:<ul> <li>Computational heavier</li> </ul> </li> </ul>"},{"location":"KB/SGD%20Momentum/","title":"SGD Momentum","text":""},{"location":"KB/SGD%20Momentum/#sgd-momentum","title":"SGD Momentum","text":"<ul> <li>$$\\begin{align}</li> </ul> <p>&amp;v_{t}= \\gamma v_{t+1}+\\eta \\cdot \\nabla_{\\theta}J(\\theta) \\</p> <p>&amp;\\theta = \\theta- v_{t}\\</p> <p>\\end{align}$$</p>"},{"location":"KB/SGD/","title":"SGD","text":""},{"location":"KB/SGD/#sgd","title":"SGD","text":"<ul> <li>instead of taking the whole dataset for each iteration, we randomly select the batches of data</li> <li>The procedure is first to select the initial parameters w and learning rate n. Then randomly shuffle the data at each iteration to reach an approximate minimum.</li> <li>full of noise</li> <li>Due to an increase in the number of iterations, the overall computation time increases.</li> <li> \\[\\theta = \\theta - \\eta \\cdot \\nabla_{\\theta} J(\\theta ; x^{i}; y^{i} )\\] <ul> <li>For each example \\(x^{i}\\) and label \\(y^{i}\\)</li> </ul> </li> </ul>"},{"location":"KB/SHAP/","title":"SHAP","text":""},{"location":"KB/SHAP/#shap","title":"SHAP","text":"<ul> <li>@lundbergUnifiedApproachInterpreting2017</li> <li>help users interpret the predictions of complex models</li> <li>unclear how these methods are related and when one method is preferable over another</li> <li>unified framework for interpreting predictions</li> <li>SHAP</li> <li>SHapley Additive exPlanations</li> <li>game theoretic approach to explain the output of any machine learning model</li> <li>connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions</li> <li>assigns each feature an importance value for a particular prediction</li> <li>identification of a new class of additive feature importance measures</li> <li>theoretical results showing there is a unique solution in this class with a set of desirable properties</li> <li>notable because several recent methods in the class lack the proposed desirable properties</li> <li>present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches</li> </ul>"},{"location":"KB/SIMD/","title":"SIMD","text":""},{"location":"KB/SIMD/#simd","title":"SIMD","text":"<ul> <li>Single instruction on multiple data</li> <li>Graphics, Image processing</li> <li>Synchronous, Deterministic</li> <li>GPU</li> <li></li> <li>Vector Processor</li> <li>Limited by Amdahl's Law</li> <li>More energy efficient than MIMD</li> <li>Time space duality</li> </ul>"},{"location":"KB/SISD/","title":"SISD","text":""},{"location":"KB/SISD/#sisd","title":"SISD","text":"<ul> <li>Single Instruction, Single Data</li> <li>Deterministic</li> <li>-</li> </ul>"},{"location":"KB/SLAK/","title":"SLAK","text":""},{"location":"KB/SLAK/#slak","title":"SLAK","text":"<ul> <li>MORE CONVNETS IN THE 2020S: SCALING UP KERNELS BEYOND 51 \u00d7 51 USING SPARSITY</li> <li> <p>Shiwei Liu, Tianlong Chen, Xiaohan Chen, Xuxi Chen, Qiao Xiao, Boqian Wu, Tommi Ka \u0308 rkka \u0308 inen, Mykola Pechenizkiy, Decebal Constantin Mocanu, Zhangyang Wang</p> </li> <li> <p>The dominant role of convolutional neural networks (CNNs) seems to be challenged by increasingly effective transformer-based models.</p> </li> <li>advanced convolutional models strike back with large ker- nels motivated by the local-window attention mechanism, showing appealing perfor- mance and efficiency</li> <li>RepLKNet</li> <li>This study ends up with a recipe for applying extremely large kernels from the perspective of sparsity, which can smoothly scale up kernels to 61\u00d761 with better performance</li> <li>Built on this recipe, we propose Sparse Large Kernel Network (SLaK), a pure CNN architec- ture equipped with sparse factorized 51\u00d751 kernels that can perform on par with or better than state-of-the-art hierarchical Transformers and modern ConvNet architec- tures like ConvNeXt and RepLKNet</li> </ul>"},{"location":"KB/SLAK/#related-work","title":"RELATED WORK","text":"<ul> <li>Large Kernel in Attention</li> <li>Large Kernel in Convolution</li> <li>Dynamic Sparsity</li> <li>Sparse Evolutionary Training</li> </ul>"},{"location":"KB/SLAK/#failures-of-existing-approaches-to-go-beyond-31x31-kernels","title":"FAILURES OF EXISTING APPROACHES TO GO BEYOND 31x31 KERNELS","text":"<ul> <li>It is important to note that all models are trained for a reduced length of 120 epochs in this section, just to sketch the scaling trends of large kernel sizes.</li> <li>Following the design in RepLKNet, we set the kernel size of each stage as [51, 49, 47, 13] and [61, 59, 57, 13],</li> <li>naively enlarging kernel size from 7x7 to 31x31 decreases the performance although the receptive field may be enlarged by using extremely large kernels, it</li> <li>might fail to maintain the desirable property of locality.</li> <li>Since the stem cell in standard ResNet (He et al., 2016) and ConvNeXt results in a</li> <li>4x downsampling of the input images, extreme kernels with</li> </ul>"},{"location":"KB/SLAK/#a-recipe-for-extremely-large-kernels-beyond-31x31","title":"A RECIPE FOR EXTREMELY LARGE KERNELS BEYOND 31x31","text":"<ul> <li>Decomposing a large kernel into two rectangular, parallel kernels smoothly scales the kernel size up to 61x61</li> <li>Although using convolutions with medium sizes (e.g., 31x31) seemingly can directly avoid this problem, we want to investigate if we can further push the performance of CNNs by using (global) extreme convolutions</li> <li>approximate the large MxM kernel with a combination of two parallel and rectangular convolutions whose kernel size is MxN and NxM (where N &lt; M), respectively, as shown in Figure 1. Following Ding et al. (2022), we keep a 5x5 layer parallel to the large kernels and summed up their outputs after a batch norm layer.</li> <li>This decomposition balances between capturing long-range dependencies and extracting local detail features</li> <li>In stark contrast, the overhead of our method increases just linearly with the kernel size</li> <li>As the decomposition reduces learnable parameters and FLOPs, it is no surprise to observe our network to initially sacrifice accuracy slightly compared to the original RepLKNet at medium kernel sizes i.e. 31x31</li> <li>However, as the convolution size continues to increase, our method can scale kernel size up to 61x61 with improved performance.</li> </ul>"},{"location":"KB/SLAK/#use-sparse-groups-expand-more-width","title":"Use Sparse Groups, Expand More Width","text":"<ul> <li>significantly boosts the model capacity.</li> <li>Instead of using the standard group convolution, ConvNeXt simply employs depthwise convolutions with an increased width to achieve the goal of \"use more groups, expand width\". In this paper, we attempt to extend this principle from a sparsity-inspired perspective \u2013 \"use sparse groups, expand more width\".</li> <li>replace the dense convolutions with sparse convolutions, where the sparse kernels are randomly constructed based on the layer-wise sparsity ratio of SNIP (Lee et al., 2019)</li> <li>After construction, we train the sparse model with dynamic sparsity (Mocanu et al., 2018; Liu et al., 2021b), where the sparse weights are dynamically adapted during training by pruning the weights with the lowest magnitude and growing the same number of weights randomly.</li> <li>Doing so enables dynamic adaptation of sparse weights, leading to better local features.</li> <li>As kernels are sparse throughout training, the corresponding parameter count and training/inference FLOPs are only proportional to the dense models.</li> <li>dynamic sparsity notably reduces more than 2.0 GFLOPs, despite causing temporary performance degradation.</li> <li>Dynamic sparsity allows us to computation-friendly scale the model size up</li> <li>For example, using the same sparsity (40%), we can expand the model width by 1.3x while keeping the parameter count and FLOPs roughly the same as the dense model</li> </ul>"},{"location":"KB/SLAK/#large-kernels-generalize-better-than-small-kernels-with-our-recipe","title":"Large Kernels Generalize Better Than Small Kernels with Our Recipe","text":"<ul> <li>performance consistently increases with kernel size, up to 51x51</li> <li>Applying each part of our proposed recipe to 7x7 kernels leads to either no gain or marginal gains compared to our 51x51 kernels. This break-down experiment justifies our claim: large kernel is the root of power, and our proposed recipe helps unleash such power from large kernels.</li> </ul>"},{"location":"KB/SLAK/#slak_1","title":"SLAK","text":"<ul> <li>SLaK is built based on the architecture of ConvNeXt</li> <li>The design of the stage compute ratio and the stem cell are inherited from ConvNeXt</li> <li>The number of blocks in each stage is [3, 3, 9, 3] for SLaK-T and [3, 3, 27, 3] for SLaK-S/B</li> <li>The stem cell is simply a convolution layer with 4x4 kernels and 4 strides. Page 6</li> <li>We first directly increase the kernel size of ConvNeXt to [51, 49, 47, 13] for each stage, and replace each MxM kernel with a combination of Mx5 and 5xM kernels</li> <li>We find that adding a BatchNorm layer directly after each decomposed kernel is crucial before summing the output up</li> <li>urther sparsify the whole network and expand the width of stages by 1.3x, ending up with SLaK</li> </ul>"},{"location":"KB/SLAK/#evaluation-of-slak-imagenet-1k","title":"EVALUATION OF SLAK ImageNet-1K","text":"<ul> <li>ADE20K</li> <li>PASCAL VOC 2007</li> <li>COCO</li> <li>SLaK is not only able to capture long-range dependence but also the local context features.</li> <li>In comparison, high-contribution pixels of SLaK spread in a much larger ERF, and some high-contribution pixels emerge in non-center areas.</li> <li>SLaK balances between capturing long-range dependencies and focusing on the local details.</li> <li>SLaK seems to automatically recover the inductive bias of peripheral vision (Lettvin et al., 1976; Min et al., 2022) in the human vision system: the entire visual field is partitioned into multiple regions from near the gaze center to distant areas; humans have high- resolution processing near the gaze center (central and para-central regions), and decrease the resolution of processing for mid and far peripheral regions.</li> </ul>"},{"location":"KB/SLAK/#kernel-scaling-efficiency","title":"KERNEL SCALING EFFICIENCY","text":"<ul> <li>We simply replace all the kernels in stages of ConvNeXt-T with a set of kernel sizes from 7 to 151 and report the required GFLOPs and the number of parameters</li> <li>One can clearly see the big gap between full-kernel scaling (yellow lines) and kernel decomposition (green lines) as the kernel size increases beyond 31x31.</li> <li>Even using the ultra-large 151x151 kernels, using our methods would require fewer FLOPs and parameters, compared to full-kernel scaling with 51x51 kernel</li> <li>EFFECTIVE RECEPTIVE FIELD (ERF)</li> </ul>"},{"location":"KB/SLAK/#experiment","title":"Experiment","text":""},{"location":"KB/SLAK/#settings-imagenet-1k","title":"SETTINGS IMAGENET-1K","text":"<ul> <li>We share the (pre-)training settings of SLaK on ImageNet-1K in this section. We train SLaK for 300 epochs (Section 5.1) and 120 epochs (Section 4) using AdamW (Loshchilov &amp; Hutter, 2019) with a batch size of 4096, and a weight decay of 0.05. The only differnce between models training for 300 epochs and 120 epochs is the training time. The learning rate is 4e-3 with a 20-epoch linear warmup followed by a cosine decaying schedule. For data augmentation, we use the default setting of [RandAugment] (Cubuk et al., 2020) in Timm (Wightman, 2019) \u2013 \"rand-m9-mstd0.5- inc1\", Label Smoothing (Szegedy et al., 2016) coefficient of 0.1, Mixup (Zhang et al., 2017) with \u21b5 = 0.8, [Cutmix] (Yun et al., 2019) with \u21b5 = 1.0, Random Erasing.</li> </ul>"},{"location":"KB/SLAK/#semantic-segmentation-on-ade20k","title":"SEMANTIC SEGMENTATION ON ADE20K","text":"<ul> <li>We follow the training setting used in Ding et al. (2022); Liu et al. (2022b) using UperNet (Xiao et al., 2018) implemented by MMSegmentation (Contributors, 2020) with the 80K/160K-iteration training schedule. We conduct experiments with both short and long training procedures. The backbones are pre-trained on ImageNet-1K with 224x224 input for 120/300 epochs and then are finetuned with UperNet (Xiao et al., 2018) for 80K/160K iterations, respectively. We report the mean Intersection over Union (mIoU) with single-scale. All the hyperparameters are the exactly the same as the ones used in the official GitHub repository of ConvNeXt (con, 2021).</li> </ul>"},{"location":"KB/SLAK/#object-detection-and-segmentation-on-coco","title":"OBJECT DETECTION AND SEGMENTATION ON COCO","text":"<ul> <li>For COCO experiments, we follow the training settings used in BEiT, Swin, and ConvNeXt using MMDetection (Chen et al., 2019) and MMSegmentation (Contributors, 2020) toolboxes. The final model weights are adopted (instead of EMA weights) from ImageNet-1K pre-training with 224x224 input. We also conduct experiments with both short and long training procedures. The backbones are pre- trained on ImageNet-1K with 224x224 input for 120/300 epochs and then are finetuned with Cascade Mask R-CNN (Cai &amp; Vasconcelos, 2018) for 12/36 epochs, respectively. All the hyperparameters are the exactly the same as the ones used in the official GitHub repository of ConvNeXt (con, 2021).</li> </ul>"},{"location":"KB/SLAK/#object-detection-on-pascal-voc-2007","title":"OBJECT DETECTION ON PASCAL VOC 2007","text":"<ul> <li>We follow (Liu et al., 2021e) and finetune Faster-RCNN on PASCAL VOC dataset with SLaK-T as the backbone. We use multi-scale setting (Carion et al., 2020; Sun et al., 2021) which leads to the length of the shorter side between 480 and 800 and the ones of the longer side at most 1333. The model is trained with AdamW for 36 epochs with a learning rate of 0.0001, a weight decay of 0.05, and a batch size of 16.</li> </ul>"},{"location":"KB/SLAK/#some-more-effects","title":"Some More Effects","text":""},{"location":"KB/SLAK/#trade-off-between-sparsity-and-width","title":"TRADE-OFF BETWEEN SPARSITY AND WIDTH","text":"<ul> <li>As we expected, the model's performance keeps increasing as model width</li> <li>increases until the width factor reaches 1.5x, after which increasing width further starts to hurt the performance apparently due to the training difficulties associated with highly sparse neural networks.</li> </ul>"},{"location":"KB/SLAK/#effect-of-the-shorter-edge-n-on-slak","title":"EFFECT OF THE SHORTER EDGE N ON SLAK","text":"<ul> <li>We vary the shorter edge N 2 [3, 5, 7] and report the accuracy. All models were trained with AdamW on ImageNet-1K for 120 epochs. We empirically find that N=5 give us the best results, whereas N = 3 and N = 7 has slightly lower accuracy. We hence think it reasonable to choose N = 5 as the default option.</li> </ul>"},{"location":"KB/SLAK/#erf-quantitation-of-models-with-different-kernel-sizes","title":"ERF QUANTITATION OF MODELS WITH DIFFERENT KERNEL SIZES","text":"<ul> <li>Larger r suggests a smoother distribution of high-contribution pixels. We can see that with global kernels, SLaK naturally considers a larger range of pixels to make decisions than ConvNeXt and RepLKNet.</li> </ul>"},{"location":"KB/SLAK/#configurations-of-dynamic-sparsity","title":"CONFIGURATIONS OF DYNAMIC SPARSITY","text":"<ul> <li>Following Liu et al. (2021c), we specifically tune two factors for SLaK-T that control the strength of weight adaptation, adaptation frequency f and adaptation rate p. Adaptation frequency determines after how many training iterations we adjust the sparse weights, and the latter controls the ratio of the weight that we adjust at each adaptation</li> <li>f = 2000</li> <li>and p = 0.5 works best for SLak-T. For SLak-S/B, we directly choose f = 100 and p = 0.3 without careful tuning.</li> </ul>"},{"location":"KB/SLAK/#limitations","title":"LIMITATIONS","text":"<ul> <li>sparse architecture is implemented with binary masks due to the limited support of sparse neural networks by the commonly used hardware such as GPU and TPU</li> <li>Therefore, the inference FLOPs reported in the main paper are the theoretical values.</li> <li>Once this great potential is supported in the future, it can have a significant positive impact on our planet by saving a huge amount of energy and reducing overall total carbon emissions.</li> <li>Although not the focus of this current work, it would be interesting for future work to examine the speedup of sparse large kernels, using such specialized hardware accelerators, as we see much improvement room of promise here.</li> </ul>"},{"location":"KB/SMOTE/","title":"SMOTE","text":""},{"location":"KB/SMOTE/#smote","title":"SMOTE","text":"<ul> <li>@SMOTESyntheticMinority</li> <li>is a popular augmentation used to alleviate problems with class imbalance. This technique is applied to the feature space by joining the k nearest neighbors to form new instances.</li> </ul>"},{"location":"KB/SMP/","title":"SMP","text":""},{"location":"KB/SMP/#smp","title":"SMP","text":"<ul> <li>Architecture where multiple processors share a single address space and access to all resources</li> <li>Shared memory computing</li> <li>Connected by a bus</li> </ul>"},{"location":"KB/SOMs/","title":"Self Organizing Maps","text":""},{"location":"KB/SOMs/#self-organizing-maps","title":"Self Organizing Maps","text":"<ul> <li>Kohonen maps</li> <li>Crumbled up grid of SOM neurons</li> <li> </li> <li>Essentially : need to map a high dim space to a grid of neurons while trying to preserve the neighborhood relations from the high dim space. This is technically impossible so compromise.</li> <li>First initialized with small random values</li> <li>For each new pattern, identify Best Maching Unit based on current vectors. Reduce the value of r. And pull the point to the part of the grid with similar weight vectors.<ul> <li>Update weights \\(\\(w(v_{kl}) \\leftarrow w(v_{kl}) + \\lambda f_r(d(v_{kl}, v_{BMU}))(x-w(v_{kl}))\\)\\)</li> <li>\\(\\lambda\\) is learning rate</li> <li>d is Euclidean Distance between two neurons in grid.</li> <li>\\(f_{r}(0)=1\\). Tends to 0 as argument grows. r is radius. Greater values, will spread it out.</li> <li>Regulated by \\(f_r(d(v_{kl}, v_{BMU}))\\)</li> </ul> </li> <li>Eventually this will lead to an organization. Covered evenly after a while. Eventually neighbors of \\(v_0\\) would have weights towards \\(w(v_0)\\) . And \\(w(v_{0)} \\approx mean(all patterns x)\\)</li> <li>Repeat until response stops. Each members BMU rate is too low to expand.</li> <li>Start with large r and then slow down.</li> </ul>"},{"location":"KB/SOMs/#neuromorphic","title":"neuromorphic","text":""},{"location":"KB/SP-LIME/","title":"SP-LIME","text":""},{"location":"KB/SP-LIME/#sp-lime","title":"SP-LIME","text":"<ul> <li> <p>@ribeiroWhyShouldTrust2016a</p> </li> <li> <p>model judges whether you can trust the whole model or not. It selects a picked diverse set of representative instances with LIMEs via submodular optimization. The user should evaluate the black box by regarding the feature words of the selected instances. It is conceivable that it also recognizes bias or systematic susceptibility to adversarial examples. With this knowledge, it is also possible to improve a bad model. SP-LIME was researched with text data, but the authors claimed that it can be transferred to models for any data type.</p> </li> <li>This was inspired by CAM and Grad-CAM and tested the explanator on randomly chosen images from the COCO dataset [91], applied to the pre-trained neural network VGG-16 using the Kullback\u2013Leibler (KL) divergence</li> </ul>"},{"location":"KB/SQL-Tutor/","title":"SQL-Tutor","text":""},{"location":"KB/SQL-Tutor/#sql-tutor","title":"SQL-Tutor","text":"<ul> <li>Outer loop: SQL-Tutor (http://www.aw-bc.com/databaseplacedemo/sqltutor.html) teaches students how to write a query to a relational database (B. Martin &amp; Mitrovic, 2002; Mitrovic, 2003; Mitrovic &amp; Ohlsson, 1999). Each task consists of a database and information to be retrieved from it. In Figure 5, for instance, the student has been given a database of movie information and has been asked to write a query that will List the toc: true titles and numbers of all movies that have won at least one Academy Award and have been made in or after 1988.</li> <li>Inner loop: Students write a query in the SQL language by clicking on buttons and filling in blanks. This may take several minutes. At any point, they can press the Submit Answer button. The tutor, which has been completely silent up until now, analyzes the student's query to find its flaws. It gives a variety of levels of feedback and hints.</li> <li>One way to think of SQL-Tutor's inner loop is that the student takes multiple steps, each comprised of filling in a blank in the query</li> <li>Unlike tutors that give feedback as soon as a student had taken a step, SQL-Tutor delays its feedback until the student requests it.</li> <li>Step analysis: In order to analyze steps, SQL-Tutor has a set of constraints, where a constraint consists of a relevance condition and a satisfaction condition. If the relevance condition is false of the students' step, then the constraint is irrelevant, so the tutor says nothing about it. If the constraint has a true relevance condition and a true satisfaction condition, then the constraint is satisfied and the tutor says nothing about it.</li> <li>If the relevance condition is true, and the satisfaction condition is false, then the student's step violates the constraint and the tutor has identified a topic worth talking about. In particular, every constraint has two messages.</li> <li>Depending on the feedback level selected by the tutor or the student, one of them may be presented to the student when the constraint is violated. One message describes the constraint and its violation briefly. The other presents more details.</li> <li>Although the constraints are task independent, many of them refer to a correct solution of the problem, which is stored in the tutoring system.</li> <li>The relationship between steps, learning events and constraints is quite simple in the SQL-Tutor. Each constraint corresponds to a Knowledge Component.</li> </ul>"},{"location":"KB/SQuAD/","title":"SQuAD","text":""},{"location":"KB/SQuAD/#squad","title":"SQuAD","text":""},{"location":"KB/SRN/","title":"SRN","text":""},{"location":"KB/SRN/#srn","title":"SRN","text":"<ul> <li>Just a simple RNN Cell</li> <li></li> <li></li> <li>Vanishingexploding gradients , in Backprop, they break down when sequences are long.</li> <li>Distance between the relevant words are too long</li> <li>Followed up [LSTM)](Long Short Term Memory (LSTM|Long Short Term Memory (LSTM|LSTM)](LSTM)](Long Short Term Memory (LSTM|Long Short Term Memory (LSTM|LSTM).md).md)</li> </ul>"},{"location":"KB/SSR/","title":"SSR","text":""},{"location":"KB/SSR/#ssr","title":"SSR","text":"<ul> <li>Smallest sufficient region</li> <li>smallest region of the image that alone allows a confident classification</li> </ul>"},{"location":"KB/STL-10/","title":"STL-10","text":""},{"location":"KB/STL-10/#stl-10","title":"STL-10","text":"<ul> <li>specifically designed for developing unsupervised feature learning </li> <li>500 labeled training images, 800 testing images, and 100, 000 unlabeled images # covering 10</li> <li>classes which include airplane, bird, car, cat, deer, dog, horse, monkey, ship, and truck. </li> </ul>"},{"location":"KB/SUNCG/","title":"SUNCG","text":""},{"location":"KB/SUNCG/#suncg","title":"SUNCG","text":"<ul> <li>UNCG dataset is a large synthetic 3D scene repository for indoor scenes which con- sists of over 45, 000 different scenes with manually created realistic room and furniture layouts </li> <li>The synthetic depth, object level semantic labels, and volumetric ground truth are available</li> </ul>"},{"location":"KB/SVHN/","title":"SVHN","text":"<p>toc: true title: SVHN</p> <p>categories: ['temp']</p>"},{"location":"KB/SVHN/#svhn","title":"SVHN","text":"<p>toc: true title: SVHN categories: ['temp']</p>"},{"location":"KB/SVHN/#svhn_1","title":"SVHN","text":"<ul> <li>recognizing digits and numbers in natural scene images which obtained from house numbers from Google Street View images </li> <li>600,000 images and all digits have been resized to a fixed resolution of 32 x 32 pixel</li> </ul>"},{"location":"KB/SYNTHIA/","title":"SYNTHIA","text":""},{"location":"KB/SYNTHIA/#synthia","title":"SYNTHIA","text":""},{"location":"KB/Saddle%20Points/","title":"Saddle Points","text":""},{"location":"KB/Saddle%20Points/#saddle-points","title":"Saddle Points","text":"<ul> <li>Points where the gradient is zero but it is at the same a local minima and maxima (both relative)</li> <li></li> </ul>"},{"location":"KB/Safeguard/","title":"Safeguard","text":""},{"location":"KB/Safeguard/#safeguard","title":"Safeguard","text":"<ul> <li>A barrier guard, device or safety procedure designed for the protection of personnel</li> </ul>"},{"location":"KB/Safety%20Integrity%20Level/","title":"Safety Integrity Level","text":""},{"location":"KB/Safety%20Integrity%20Level/#safety-integrity-level","title":"Safety Integrity Level","text":"<ul> <li>Safety Integrity Level (SIL) is IEC\u2019s method for determining the performance level of a safety system. SIL 2 corresponds to ISO Performance Level \u201cd\u201d, and SIL 3 corresponds to ISO Performance Level \u201ce\u201d. ISO 10218 allows for the use of either.</li> </ul>"},{"location":"KB/Safety%20Logic%20Circuit/","title":"Safety Logic Circuit","text":""},{"location":"KB/Safety%20Logic%20Circuit/#safety-logic-circuit","title":"Safety Logic Circuit","text":"<ul> <li>The safety logic circuit monitors safety critical external devices such as the light curtains and FSU generated signals. The safety logic circuit is programmed via an intuitive user interface that is supported on the Yaskawa programming pendant. It enables to set up the logical operations, such as stopping the manipulator or outputting a signal if the servos are on.</li> </ul>"},{"location":"KB/Saffran%2C%20Aslin%20and%20Newport/","title":"Saffran, Aslin and Newport","text":""},{"location":"KB/Saffran%2C%20Aslin%20and%20Newport/#saffran-aslin-and-newport","title":"Saffran, Aslin and Newport","text":"<ul> <li>8-month-olds can segment a continuous stream of speech syllables, containing no acoustic or prosodic cues to word boundaries, into wordlike units after only 2 min of listening experience</li> </ul>"},{"location":"KB/Salemi%20and%20Zamani%20-%202024%20-%20Evaluating%20Retrieval%20Quality%20in%20Retrieval-Augmente/","title":"Salemi and Zamani - 2024 - Evaluating Retrieval Quality in Retrieval-Augmente","text":"","tags":["llm"]},{"location":"KB/Salemi%20and%20Zamani%20-%202024%20-%20Evaluating%20Retrieval%20Quality%20in%20Retrieval-Augmente/#salemi-and-zamani-2024-evaluating-retrieval-quality-in-retrieval-augmente","title":"Salemi and Zamani - 2024 - Evaluating Retrieval Quality in Retrieval-Augmente","text":"<ul> <li>@salemiEvaluatingRetrievalQuality2024</li> </ul>","tags":["llm"]},{"location":"KB/Salemi%20and%20Zamani%20-%202024%20-%20Evaluating%20Retrieval%20Quality%20in%20Retrieval-Augmente/#evaluating-retrieval-quality-in-retrieval-augmented-generation-evaluatingretrievalqualityinretrieval-augmentedgeneration","title":"Evaluating Retrieval Quality in Retrieval-Augmented Generation {#evaluatingretrievalqualityinretrieval-augmentedgeneration}","text":"","tags":["llm"]},{"location":"KB/Salemi%20and%20Zamani%20-%202024%20-%20Evaluating%20Retrieval%20Quality%20in%20Retrieval-Augmente/#note-something-is-fishy-about-this-paper","title":"Note: Something is Fishy about This Paper.","text":"<ul> <li>Instead of passing end to end, they want to pass documents one by one for evaluation. That seems slightly suspicious how they got so much improvement by doing that :/</li> <li>All the part about correlation also seems a little weird.</li> <li>Something does not add up about this paper.</li> <li>eRAG</li> <li>each document in the retrieval list is individually utilized by the large language model within the RAG system</li> <li>improvements in Kendall's g correlation ranging from 0.168 to 0.494</li> </ul>","tags":["llm"]},{"location":"KB/Salemi%20and%20Zamani%20-%202024%20-%20Evaluating%20Retrieval%20Quality%20in%20Retrieval-Augmente/#introduction","title":"INTRODUCTION","text":"<ul> <li>end-to-end evaluation lacks transparency regarding which retrieved document contributed to the generated output, hindering interpretability of the system's behavior</li> <li>resource- intensive, consuming signifcant time and computational power, particularly when dealing with a large set of retrieval results con- sumed by the LLM</li> <li>many ranking systems rely on interleaving (i.e., replacing one or more documents in the result list) for evaluation and optimization, which further complicates the evaluation, as slight variations in retrieval results necessitate re-computation of the RAG pipeline</li> <li>optimizing ranking models often requires document-level feedback, such as user clicks</li> </ul>","tags":["llm"]},{"location":"KB/Salemi%20and%20Zamani%20-%202024%20-%20Evaluating%20Retrieval%20Quality%20in%20Retrieval-Augmente/#evaluating-retrievers-in-rag","title":"EVALUATING RETRIEVERS IN RAG","text":"<ul> <li>human judgment to assess the relevance of a query to documents within a corpus</li> <li>human annotation can be costly and is often impractical for evaluating all documents in a corpus</li> <li>downstream ground truth out- put associated with the query to provide weak relevance labels</li> <li>eRAG, a novel approach that involves utilizing the LLM in RAG system itself as the arbiter for generating labels to evaluate the retrieval model. </li> </ul>","tags":["llm"]},{"location":"KB/Salemi%20and%20Zamani%20-%202024%20-%20Evaluating%20Retrieval%20Quality%20in%20Retrieval-Augmente/#using-downstream-large-language-model-in-rag-as-doc-ument-annotator","title":"Using Downstream Large Language Model in RAG as Doc- Ument Annotator","text":"","tags":["llm"]},{"location":"KB/Salemi%20and%20Zamani%20-%202024%20-%20Evaluating%20Retrieval%20Quality%20in%20Retrieval-Augmente/#retrieval-evaluation-metrics","title":"Retrieval Evaluation Metrics","text":"","tags":["llm"]},{"location":"KB/Salemi%20and%20Zamani%20-%202024%20-%20Evaluating%20Retrieval%20Quality%20in%20Retrieval-Augmente/#main-findings","title":"Main Findings","text":"<ul> <li>How do different retrieval evaluation methods correlate with the end-to-end downstream performance in RAG?.</li> <li>Interestingly, the most common approaches, KILT Provenance and Annotation with LLMs, that are, document-level relevance labels and using LLMs to assign a relevance label to each retrieved document, have the lowest correlation with the down- stream performance of the LLM</li> <li>How do different retrieval evaluation methods in RAG per- form as the size of retrieval results increases?</li> <li>varied the number of retrieved documents and computed the correlation between the metric with highest correlation for each method in Table 1 at each specifed number of retrieved documents and the downstream performance of the LLM given that number of retrieved documents </li> </ul>","tags":["llm"]},{"location":"KB/Salicon%20dataset/","title":"Salicon dataset","text":""},{"location":"KB/Salicon%20dataset/#salicon-dataset","title":"Salicon Dataset","text":"<ul> <li>\"10,000 images for training and 5000 images for validation\"</li> <li>\"Each image was viewed by 60 observers\"</li> <li>this dataset Different from other fixation datasets, is large-scale mouse-tracking data through Amazon Mechanical Turk</li> <li>Although this dataset is not the fixation dataset, it is well known that the distribution of mouse tracking points is similar to the distribution of fixations and that the parameters of the model trained on Salicon dataset are useful for saliency map estimation</li> </ul>"},{"location":"KB/Salience%20Map/","title":"Salience Map","text":""},{"location":"KB/Salience%20Map/#salience-map","title":"Salience Map","text":""},{"location":"KB/Salience%20Map/#explained","title":"Explained","text":"<ul> <li>Specifies parts of the image that contribute the most to the activity of a specific layer or the entire decision</li> <li>\\(Y_{c}=\\text{score of class c}\\) : value of output before softmax</li> <li> \\[saliency = max_{r,g,b}(|\\frac{\\partial Y_{c}}{\\partial I}|)\\] </li> <li>grad of \\(Y_{c}\\) wrt input - matrix with shape similiar to input</li> <li>if value close to 0 : small changes in input have no effect on output</li> <li>if high magnitude : small changes can have a major impact</li> <li>positive : roughly the location of the target object</li> <li>negative : competing class objects : background or instance</li> <li>Abs value for heatmap</li> <li>grads : backprop on \\(Y_{c}\\) instead of loss</li> </ul>"},{"location":"KB/Salience%20Map/#three-approaches","title":"Three Approaches","text":""},{"location":"KB/Salience%20Map/#dencov","title":"Dencov","text":"<ul> <li>Use DeconvNet</li> <li>Use backprop to compute the gradients of logits wrt input : Deep Inside Convolutional Networks</li> <li>Guided BackProp</li> </ul>"},{"location":"KB/Salience%20Map/#features","title":"Features","text":"<ul> <li>One of the oldest interpretation methods</li> <li>Salience maps of important features are calculated, and they show superpixels that have influenced the prediction most, for example</li> <li>To create a map of important pixels, one can repeatedly feed an architecture with several portions of inputs and compare the respective output, or one can visualize them directly by going rearwards through the inverted network from an output of interest;</li> <li>Grouped in this category as well is exploiting neural networks with activation atlases through feature inversion. This method can reveal how the network typically represents some concepts</li> <li>Considering image or text portions that maximize the activation of interesting neurons or whole layers can lead to the interpretation of the responsible area of individual parts of the architecture.</li> </ul>"},{"location":"KB/Saliency%20using%20natural%20statistics/","title":"Saliency using natural statistics","text":""},{"location":"KB/Saliency%20using%20natural%20statistics/#saliency-using-natural-statistics","title":"Saliency Using Natural Statistics","text":"<ul> <li>applies a Bayesian framework using local feature maps to estimate saliency maps.</li> <li>The probability distribution of features is learned not from each individual test image but from statistics calculated over the training set of natural images.</li> </ul>"},{"location":"KB/Saliency%20vs%20Attention/","title":"Saliency vs Attention","text":""},{"location":"KB/Saliency%20vs%20Attention/#saliency-vs-attention","title":"Saliency Vs Attention","text":"<ul> <li>Input saliency methods are addressing the goal head-on: they reveal why one particular model prediction was made in terms of how relevant each input word was to that prediction</li> <li>input saliency methods typically take the entire computation path into account, all the way from the input word embeddings to the target output prediction value</li> <li>Attention weights do not: they reflect, at one point in the computation, how much the model attends to each input representation, but those representations might already have mixed in information from other inputs</li> <li>Ironically, attention-as-explanation is sometimes evaluated by comparing it against gradient-based measures, which again begs the question why we wouldn't use those measures in the first place</li> <li>In terms of efficiency, it is true that for attention only a forward pass is required, but many other methods discussed at most require a forward and then a backward pass, which is still extremely efficient.</li> </ul>"},{"location":"KB/SaliencyMix/","title":"SaliencyMix","text":""},{"location":"KB/SaliencyMix/#saliencymix","title":"SaliencyMix","text":"<ul> <li>@uddinSaliencyMixSaliencyGuided2021</li> <li>extracts salient regions and pastes them on the corresponding location in the target image</li> <li>The salient region is extracted around the maximum intensity pixel location in the saliency map</li> <li>Regional dropout is one of the popular solutions that guides the model to focus on less discriminative parts by randomly removing image regions, resulting in improved regularization</li> <li>however, such information removal is undesirable.</li> <li>On the other hand, recent strategies suggest to randomly cut and mix patches and their labels among training images, to enjoy the advantages of regional dropout without having any pointless pixel in the augmented images.</li> <li>selects a representative image patch with the help of a saliency map and mixes this indicative patch with the target image</li> <li>Furthermore, models that are trained with SaliencyMix help to improve the object detection performance</li> <li>we cut a source patch and mix it to the target image and also mix their labels proportionally to the size of the mixed patches</li> <li>But in order to prevent the model from learning any irrelevant feature representation, the proposed method enforces to select a source patch in a way so that it must contains information about the source object</li> <li>It first extracts a saliency map of the source image to highlight the objects of interest and then selects a patch surrounding the peak salient region to mix with the target image.</li> </ul>"},{"location":"KB/SaliencyMix/#algorithm","title":"Algorithm","text":"<ul> <li>If \\(I_{s} \\in \\mathbb{R}^{W \\times H \\times C}\\) is randomly selected training source with label \\(y_{s}\\). Saliency map is \\(I_{vs}= f(I_{s})\\) where \\(I_{vs}\\) is the visual saliency. \\(f(\\cdot)\\) is a saliency model. </li> <li>Search for a pixel \\(I_{vs}^{i,j}\\) with maximum intensity</li> <li>$$</li> </ul> <p>i,j = argmax(I_{vs}) $$ - Patch selected by centering on the \\(I_{vs}^{i,j}\\) pixel or with this pixel in the patch - Patch determined on a ration \\(\\lambda\\) chosen from Uniform Distribution </p>"},{"location":"KB/SaliencyMix/#mixing-patches-and-labels","title":"Mixing Patches and Labels","text":"<ul> <li>Another image \\(I_{s} \\in \\mathbb{R}^{W \\times H \\times C}\\)</li> <li>\\(I_{a} = M \\odot I_{s} + M' \\odot I_{t}\\)<ul> <li>\\(M \\in \\{0,1\\}^{W, H}\\)</li> </ul> </li> <li>labels \\(y_{a} = \\lambda y_{t}+ (1-\\lambda)y_{s}\\)</li> </ul>"},{"location":"KB/SaliencyMix/#different-ways-of-selecting-and-mixing-the-source-patch","title":"DIFFERENT WAYS OF SELECTING AND MIXING THE SOURCE PATCH","text":"<ul> <li>schemes: (i) Salient to Corresponding, that selects the source patch from the most salient region and mix it to the corresponding location of the target image; (ii) Salient to Salient, that selects the source patch from the most salient region and mix it to the salient region of the target image; (iii) Salient to Non-Salient, that selects the source patch from the most salient region but mix it to the non-salient region of the target image; (iv) Non-Salient to Salient, that selects the source patch from the non-salient region of the source image but mix it to the salient region of the target image; and (v) Non-Salient to NonSalient, that selects the source patch from the non-salient region of the source image and also mix it to the non-salient region of the target image.</li> <li>To find out the non-salient region, we use the least important pixel of an image.</li> </ul>"},{"location":"KB/SaliencyMix/#images","title":"Images","text":""},{"location":"KB/Salient%20Object%20Strategy/","title":"Salient Object Strategy","text":""},{"location":"KB/Salient%20Object%20Strategy/#salient-object-strategy","title":"Salient Object Strategy","text":"<ul> <li>\"if an object is contextually relevant, then it is salient\" (Philip 2011: 370\u2013371)</li> </ul>"},{"location":"KB/Sample%20Correlation/","title":"Sample Correlation","text":"<p>toc: true title: Sample Correlation</p> <p>categories: ['temp']</p>"},{"location":"KB/Sample%20Correlation/#sample-correlation","title":"Sample Correlation","text":"<ul> <li>A type of Correlation</li> <li> \\[r_{xy}= \\frac{s_{xy}}{s_{x}s_{y}}\\] </li> <li>\\(s_{x}\\), \\(s_y\\) are the sample Standard Deviation</li> <li>\\(s_y\\) is the sample Covariance</li> </ul>"},{"location":"KB/Sample%20Pairing/","title":"Sample Pairing","text":""},{"location":"KB/Sample%20Pairing/#sample-pairing","title":"Sample Pairing","text":"<ul> <li>@inoueDataAugmentationPairing2018</li> <li>merges two images by averaging their pixel intensities</li> <li>The new image has the same training image label opposite to MixUp and other approaches where labels are updated according to the proportion of image mixing.</li> <li>one epoch on ImageNet and 100 epochs on other datasets are completed without SamplePairing before mixed image data is added to the training</li> <li>Once the SamplePairing images are added to the training set, they run in cycles between 8:2 epochs, 8 with SamplePairing images, 2 without.</li> </ul>"},{"location":"KB/Sampler/","title":"Sampler","text":""},{"location":"KB/Sampler/#sampler","title":"Sampler","text":"<ul> <li>Given :<ul> <li>\\(P_{X}\\) is a distribution on a measure space (E,B)</li> <li>A seq of \\(X_{1}, X_{2}, \u2026\\) of random variables is a sampler if for all \\(A \\in B\\)</li> <li> \\[P_{X}(A) = lim_{N \\rightarrow \\infty} \\frac{1}{N}\\Sigma_{i=1}^{N}1_{A}\\circ X_{i}\\] </li> <li>\\(1_A\\) is an indicator function for A</li> </ul> </li> <li>\\(X_{1}, X_{2}, \u2026\\) need not have the same distribution or need to be independant</li> <li>Dream : All \\(X_{i}\\) are uniformly distributed on [0,1]. (Impossible)</li> </ul>"},{"location":"KB/Sampling%20Bias/","title":"Sampling Bias","text":""},{"location":"KB/Sampling%20Bias/#sampling-bias","title":"Sampling Bias","text":"<ul> <li>Data is not collected randomly from the target group.</li> </ul>"},{"location":"KB/Sampling%20Ray%20Casting/","title":"Sampling Ray Casting","text":""},{"location":"KB/Sampling%20Ray%20Casting/#sampling-ray-casting","title":"Sampling Ray Casting","text":"<ul> <li>selection of positions along the ray</li> <li>Early Ray Termination</li> <li></li> </ul>"},{"location":"KB/Sanity%20Checks%20for%20Saliency%20Maps/","title":"Sanity Checks for Saliency Maps","text":""},{"location":"KB/Sanity%20Checks%20for%20Saliency%20Maps/#sanity-checks-for-saliency-maps","title":"Sanity Checks for Saliency Maps","text":"<ul> <li>@adebayoSanityChecksSaliency2020</li> <li>whether saliency methods are insensitive to model and data</li> <li>Insensitivity is highly undesirable, because it would mean that the \"explanation\" isunrelated to model and data</li> <li>Methods that are insensitive to model and training data are similar to edge detectors</li> <li>Edge detectors simply highlight strong pixel color changes in images and areunrelated to a prediction model or abstract features of the image, and require no training</li> <li>The methods tested were Vanilla Gradient, Gradient x Input, Integrated Gradients,Guided Backpropagation, Guided Grad-CAM and SmoothGrad (with VanillaGradient).</li> <li>Vanilla Gradient and Grad-CAM passed the insensitivity check, while GuidedBackpropagation and Guided Grad-CAM failed</li> <li>However, the sanity checks paper itself has found some criticism from Tomsett et al.(2020) 89 with a paper called \"Sanity checks for caliency metrics\" (of course</li> <li>They found that there is a lack of consistency for evaluation metrics</li> <li>So we are back to where we started ... It remains difficult to evaluate the visual explanations. This makes it very difficult for a practitioner.</li> </ul>"},{"location":"KB/Satellite%20Cell/","title":"Satellite Cell","text":""},{"location":"KB/Satellite%20Cell/#satellite-cell","title":"Satellite Cell","text":"<ul> <li>Surround neuron cell bodies</li> <li>Similar to Astrocyte</li> </ul>"},{"location":"KB/Satisficing%20Heuristic/","title":"Satisficing Heuristic","text":""},{"location":"KB/Satisficing%20Heuristic/#satisficing-heuristic","title":"Satisficing Heuristic","text":"<ul> <li>Good enough</li> <li>Less time</li> <li>Less knowledge</li> </ul>"},{"location":"KB/Scalar%20Articles/","title":"Scalar Articles","text":""},{"location":"KB/Scalar%20Articles/#scalar-articles","title":"Scalar Articles","text":""},{"location":"KB/Scalar%20Articles/#done","title":"Done","text":"<ul> <li>[Word2Vec] with gensim</li> <li>CycleGAN</li> <li>[Masked Language Modeling] with BERT</li> <li>DCGAN</li> <li>Conditional GAN</li> <li>Stack GAN</li> <li>Basic GAN</li> </ul>"},{"location":"KB/Scalar%20Articles/#in-progress","title":"In Progress","text":"<ul> <li>Generative vs Discriminative Models</li> </ul>"},{"location":"KB/Scalar%20Color%20Coding/","title":"Scalar Color Coding","text":""},{"location":"KB/Scalar%20Color%20Coding/#scalar-color-coding","title":"Scalar Color Coding","text":"<ul> <li>Mean Diffusivity</li> <li>Fractional Anisotropy</li> <li>Eigenvector</li> </ul>"},{"location":"KB/Scalar%20Register/","title":"Scalar Register","text":""},{"location":"KB/Scalar%20Register/#scalar-register","title":"Scalar Register","text":"<ul> <li>Single elements for interconnecting Vector Functional Units, Vector Load Store Units, and registers</li> </ul>"},{"location":"KB/Scaled%20Dot%20Product%20Attention/","title":"Scaled Dot Product Attention","text":""},{"location":"KB/Scaled%20Dot%20Product%20Attention/#scaled-dot-product-attention","title":"Scaled Dot Product Attention","text":"<ul> <li>Vaswani et al., 2017</li> <li>Q is query, K is key V is value. Same dims</li> <li>\\(q_{i}= W_{q}x_i\\) , \\(k_{i}= W_{k}x_{i}\\) , \\(v_{i}= W_{v}x_{i}\\)<ul> <li>\\(w_{ij}' = q_{i}^{T}k_{j}\\)</li> <li>\\(y_{i}= \\Sigma_{j}w_{ij}v_{j}\\)</li> </ul> </li> <li>Softmax is sensitive to large values. Which sucks for the #gradients</li> <li>The avg value of the dot product grows with embedding dimension k. So scale back.<ul> <li>\\(\\sqrt{k}\\) . Vector in \\(\\mathbb{R}^{k}\\) with all values as c</li> <li>Euclidean length is \\(\\sqrt{kc}\\)</li> </ul> </li> <li> \\[Attention(Q, K,V) = softmax(\\frac{QK^T}{\\sqrt{d_{k}}})V\\] </li> <li>Generalization of Soft Attention</li> <li></li> <li>Attention Alignment score \\(\\(\\alpha_{t,i} = \\frac{s_{t}^{T}h_{i}}{\\sqrt{n}}\\)\\)</li> </ul>"},{"location":"KB/Scaled%20benefits/","title":"Scaled benefits","text":""},{"location":"KB/Scaled%20benefits/#scaled-benefits","title":"Scaled Benefits","text":"<ul> <li>The more prepared - the more benefits</li> </ul>"},{"location":"KB/Scatter%20and%20Gather/","title":"Scatter and Gather","text":""},{"location":"KB/Scatter%20and%20Gather/#scatter-and-gather","title":"Scatter and Gather","text":"<ul> <li>Retrieves data elements scattered thorughout memory and packs them into sequential vectors in vector registers</li> <li>Promotes data locality and reduces data pollution</li> </ul>"},{"location":"KB/Scene%20based%20text%20to%20image%20generation/","title":"Scene based text to image generation","text":""},{"location":"KB/Scene%20based%20text%20to%20image%20generation/#scene-based-text-to-image-generation","title":"Scene Based Text to Image Generation","text":"<ul> <li>Make-A-Scene: Scene-Based Text-to-Image Generation with Human Priors</li> <li>text-to-image generation</li> <li>enabling a simple control mechanism complementary to text in the form of a scene</li> <li>introducing elements that substantially improve the tokenization process by employing domain-specific knowledge over key image regions</li> <li>adapting classifier-free guidance for the transformer use case</li> <li>They attempt to progress text-to-image generation towards a more interactive experience, where people can perceive more control over the generated outputs, thus enabling real-world applications such as storytelling</li> <li>focus on improving key image aspects that are significant in human perception, such as faces and salient objects, resulting in higher favorability of their method in human evaluations and objective metrics</li> <li>Through scene controllability, they introduce several new capabilities: (i) scene editing, (ii) text editing with anchor scenes, (iii) overcoming out-of-distribution text prompts, and (iv) story illustration generation</li> </ul>"},{"location":"KB/SceneNet%20RGB-D/","title":"SceneNet RGB-D","text":""},{"location":"KB/SceneNet%20RGB-D/#scenenet-rgb-d","title":"SceneNet RGB-D","text":"<ul> <li>large indoor synthetic video dataset which consists of 5 million rendered RGB-D images from over 15K trajectories in synthetic layouts with random but physically simulated object poses </li> <li>pixel level annotations for scene understanding problems such as semantic segmentation, instance segmentation, and object detection, and also for geometric computer vision problems such as optical flow, depth estimation, camera pose estimation, and 3D reconstruction</li> </ul>"},{"location":"KB/Scheduling/","title":"Scheduling","text":""},{"location":"KB/Scheduling/#scheduling","title":"Scheduling","text":"<ul> <li>Some prune all the weights at once</li> <li>Others prune iteratively using loops or some other condition</li> </ul>"},{"location":"KB/Schipol%20Data%20Scientist/","title":"Schipol Data Scientist","text":""},{"location":"KB/Schipol%20Data%20Scientist/#schipol-data-scientist","title":"Schipol Data Scientist","text":"<ul> <li>Bonus:<ul> <li>Have experience with computer vision.</li> <li>Have knowledge about cloud computing</li> </ul> </li> <li>Work on scaling up our DeepTurnaround product to a multi-airport product.</li> <li>Continuous monitoring, development and optimization of our state-of-the-art Computer Vision model.</li> <li>Develop and implement new technical features.</li> <li>Work within a skilled development product team consisting of multiple data scientists, data engineers and full stack developers.</li> <li>And\u2026 work at a cool location where you will see aircrafts passing by your window.\u00a0</li> <li>By leveraging our AI systems, we generate detections from camera images in real-time to capture events occurring around the aircraft. Ultimately, our aim is to enhance the decision-making process in operations, leading to a reduction in delays and CO2 emissions.</li> </ul>"},{"location":"KB/Schipol%20Data%20Scientist/#motivation","title":"Motivation","text":"<ul> <li>DeepTurnaround <ul> <li>The turnaround process is a series of tasks that need to be completed from the time an aircraft arrives at the assigned gate until it is ready for departure - A large scale optimization process</li> <li>Useful tech, saves time, money and makes the Schipol experience even better for travellers</li> <li>Impact of work</li> <li>Guess how it works <ul> <li>Object detection for individual cases</li> <li>combined data from two cameras</li> </ul> </li> <li>Potential ideas for improvement<ul> <li>In the future, we expect to include features which can benefit safety and sustainability officers/managers as well. - Thesis on XAI</li> <li>Perhaps a third camera/ for more personell focused view, even more fine grained control. (Eg. Uniforms, crowd density )</li> </ul> </li> <li>Computer Vision + Datascience<ul> <li>Perfect mix of things where I can contribute to</li> <li>experience</li> </ul> </li> </ul> </li> </ul>"},{"location":"KB/Schipol%20Data%20Scientist/#recruiter-email","title":"Recruiter Email","text":"<ul> <li>Resume sent through the process</li> <li>Is this position still open?</li> <li>Just finished a masters in AI from RUG.</li> <li>DeepTurnaround - have many ideas to contribute and work with implementing for a better airport experience at either Schipol or other customers</li> </ul>"},{"location":"KB/Schipol%20Data%20Scientist/#motivation-letter","title":"Motivation Letter","text":"<p>Hello!</p> <p>This is Subhaditya Mukherjee. I graduated from the University of Groningen with a masters in Artificial Intelligence last month and just started looking for a job here in the Netherlands. My area of expertise and interest is a combination of Computer Vision and Data Analytics, which is what this position is about. </p> <p>I enjoy traveling and am familiar with how frustrating airports can be on a long journey. But there are hundreds of moving parts, and even finding analytics for the same can be a challenge. Deep Turnaround is a very interesting project to me for this reason. The website does not state many technical details, but it seems that the system is a combination of custom data collection, fine-grained object detection networks, and data analytics, each of which must be quite challenging, given the scope of the task. </p> <p>That being said, I have some ideas that could make Deep Turnaround even more useful to our stakeholders, and I would love to discuss and work on them to help make the airport experience a little more streamlined. Of course, I would be willing to work on any other feature that is proposed. These are just some ideas. (These might be already implemented, but I did not see these labels in the video on the website). One of the first ideas that comes to mind is using the two existing cameras to also analyze crowd information to make the passenger experience more streamlined and avoid chaos while boarding. Or perhaps, collecting pictures of worker uniforms would enable Deep Turnaround to log more specific events. Neither of these would require any extra infrastructure costs, which is probably also one of your constraints. </p> <p>My previous internships and projects (both personal and freelance) have included Deep Object Detection, Computer Vision, Data warehousing and analytics, and Dashboarding. These experiences will let me contribute to any AI team, and I am willing to learn whatever else is necessary for any future projects.</p> <p>I have a lot to learn, and I want to work with a team that is making a real-world impact in a sector close to my heart like this one. It is not every day you find a position that you enjoy and also think you can contribute something to, and I sincerely hope you give me a chance!</p> <p>Thank you, Subhaditya Mukherjee</p>"},{"location":"KB/Schipol%20Data%20Scientist/#email-to-recruiter","title":"Email to Recruiter","text":""},{"location":"KB/Schipol%20Data%20Scientist/#cold-email","title":"Cold email","text":"<p>fhoogenboom@schiphol.com - Floris Hoogenboom - Head of Data and AI products</p>"},{"location":"KB/Schwann%20Cell/","title":"Schwann Cell","text":""},{"location":"KB/Schwann%20Cell/#schwann-cell","title":"Schwann Cell","text":"<ul> <li>Insulate , helps form Myelin</li> <li>Similar to Ogliodendrocytes</li> </ul>"},{"location":"KB/ScoreCAM/","title":"ScoreCAM","text":""},{"location":"KB/ScoreCAM/#scorecam","title":"ScoreCAM","text":"<ul> <li>@wangScoreCAMScoreWeightedVisual2020</li> <li>In Score-Cam, we use the weights of the score obtained for a specific target class.</li> <li>The first step involved is passing images to a CNN model and performing a forward_pass. After the forward pass, the activations are extracted from last convolutional layer in the network. </li> <li>Each Activation Map obtained from the last layer having shape \\(1\\times m \\times n\\) is then upsampled using bilinear-interpolation to the same size as the Input Image. </li> <li>After Upsampling the activation maps, the resultant activation maps are normalized with each pixel within the range of [0,1] to maintain the relative intensities between the pixels <ul> <li> \\[A_{i,j}^{k}= \\frac{A_{i,j}^{k}}{max A^{k}- min A^{k}}\\] </li> </ul> </li> <li>After the Normalization of the Activation Maps is complete, the highlighted areas of the activation maps are projected on the input space by multiplying each normalized activation map(1 x W x H) with the Original Input Image(3 x W x H) to obtain a masked image M with shape 3 x W x H<ul> <li> \\[M^{k}= A^{k} \\cdot I\\] </li> </ul> </li> <li>The Masked Images M thus obtained are then passed to Convolutional Neural Network with SoftMax output<ul> <li> \\[S_{k} = Softmax(F(M^{k}))\\] </li> </ul> </li> <li>After getting the scores for each class we extract the score of the target class to represent the importance of the kth activation map.<ul> <li> \\[w_{k}^{c}= S_{k}^{c}\\] </li> </ul> </li> <li>compute the sum across all the activation maps for the linear combination between the target class score and each activation map</li> <li>apply pixel-wise ReLU to the final activation map<ul> <li> \\[L^{c}_{ScoreCAM} = ReLU(\\underset{k}\\Sigma w_{k}^{c}A^{k})\\] </li> </ul> </li> <li>ReLU because we are interested only in the features that have a positive influence on the class of interest</li> </ul>"},{"location":"KB/ScoreCAM/#advantages","title":"Advantages","text":"<ul> <li>can be used in any Convolutional Neural Network architecture and don't require retraining of the model to produce saliency maps like CAM</li> <li>class discriminative</li> <li>removes irrelevant noise to produce a meaningful saliency map</li> <li>Softmax scores as weights and removes the dependence on unstable gradients</li> </ul>"},{"location":"KB/Scoring%20Pruning%20Approaches/","title":"Scoring Pruning Approaches","text":""},{"location":"KB/Scoring%20Pruning%20Approaches/#scoring-pruning-approaches","title":"Scoring Pruning Approaches","text":"<ul> <li>Like all networks, scoring becomes essential when we try to choose which parameter to get rid of.</li> <li>Some authors suggest removing based on absolute values, others decide to prune based on the contributions of that parameter to the entire network.</li> <li>Others remove based on a score given.</li> <li>Some perform Pruning locally, while others perform it globally across the network.</li> </ul>"},{"location":"KB/Second%20Language%20Vocabulary%20Learning%20%2C%20The%20role%20of%20context%20%20versus%20translation/","title":"Second Language Vocabulary Learning , The role of context  versus translation","text":""},{"location":"KB/Second%20Language%20Vocabulary%20Learning%20%2C%20The%20role%20of%20context%20%20versus%20translation/#second-language-vocabulary-learning-the-role-of-context-versus-translation","title":"Second Language Vocabulary Learning , The Role of Context Versus Translation","text":"<ul> <li> <p>PETER PRINCE</p> </li> <li> <p>A widespread view of vocabulary learning is that it is advisable to make the shift away from learning words with their translations and to rely on second language (L2) context as soon as possible</p> </li> <li>Such faith in context learning has not always received experimental support, however, nor is it commonly shared by L2 learners</li> <li>An experiment in which subjects were tested on their recall of newly learned words was conducted to determine the relative advantages and disadvantages of both context learning and translation learning as a function of learner proficiency</li> </ul>"},{"location":"KB/Second%20Language%20Vocabulary%20Learning%20%2C%20The%20role%20of%20context%20%20versus%20translation/#results","title":"Results","text":"<ul> <li>reveal a superiority of translation learning in terms of quantity, but an inability on the part of weaker learners to transfer their knowledge into L2 contexts</li> <li>suggested that alternative learning strategies that combine the advantages of the two techniques should be explored.</li> </ul>"},{"location":"KB/Second%20order%20generalization/","title":"Second order generalization","text":""},{"location":"KB/Second%20order%20generalization/#second-order-generalization","title":"Second Order Generalization","text":"<ul> <li>Present model with novel example (not seen in training)</li> </ul>"},{"location":"KB/SegNet/","title":"Seg Net","text":""},{"location":"KB/SegNet/#seg-net","title":"Seg Net","text":"<ul> <li>Precursor to Unet</li> <li>No Skip connections</li> </ul>"},{"location":"KB/Selection%20Bias/","title":"Selection Bias","text":""},{"location":"KB/Selection%20Bias/#selection-bias","title":"Selection Bias","text":"<ul> <li>Errors in conclusions drawn from sampled data due to a selection process that generates systematic differences between samples observed in the data and those not observed. The following forms of selection bias exist</li> <li>datasets often prefer particular kinds of images</li> <li>However, getting images from the Internet does not in itself guarantee a fair sampling, since keyword-based searches will return only particular types of images</li> <li>Obtaining data from multiple sources</li> <li>even better to start with a large collection of unannotated images and label them by crowd-sourcing</li> </ul>"},{"location":"KB/Self%20Attention%20GAN/","title":"Self Attention GAN","text":""},{"location":"KB/Self%20Attention%20GAN/#self-attention-gan","title":"Self Attention GAN","text":"<ul> <li>Self Attention + Generative Models</li> </ul> <pre><code>class Self_Attn_New(nn.Module):\n    \"\"\" Self attention Layer\"\"\"\n    def __init__(self, in_dim):\n        super().__init__()\n        self.query_conv = nn.Conv2d(in_dim, out_channels=in_dim//8, kernel_size=1)\n        self.key_conv = nn.Conv2d(in_dim, out_channels=in_dim//8, kernel_size=1)\n        self.value_conv = nn.Conv2d(in_dim, out_channels=in_dim, kernel_size=1)\n        self.gamma = nn.Parameter(torch.zeros([1]))\n\n    def forward(self, x):\n        proj_query = rearrange(self.query_conv(x), 'b c h w -&gt; b (h w) c')\n        proj_key = rearrange(self.key_conv(x), 'b c h w -&gt; b c (h w)')\n        proj_value = rearrange(self.value_conv(x), 'b c h w -&gt; b (h w) c')\n        energy = torch.bmm(proj_query, proj_key)\n        attention = F.softmax(energy, dim=2)\n        out = torch.bmm(attention, proj_value)\n        out = x + self.gamma * rearrange(out, 'b (h w) c -&gt; b c h w',\n                                         **parse_shape(x, 'b c h w'))\n        return out, attention\n</code></pre>"},{"location":"KB/Self%20Attention/","title":"Self Attention","text":""},{"location":"KB/Self%20Attention/#self-attention","title":"Self Attention","text":"<ul> <li>paper</li> <li>Basically Scaled Dot Product Attention</li> <li>Q,K,V all from same module but prev layer</li> <li>Weighted average over all input vectors (\\(y_{i}= \\Sigma_{j}w_{ij}x_{j}\\)\\)<ul> <li>j is over the sequence</li> <li>weights sum to 1 over j</li> <li>\\(w_{ij}\\) is derived \\(w^{'}_{ij}=x_{i}^{T}x_{j}\\)<ul> <li>Any value between -inf to +inf so Softmax is applied</li> </ul> </li> <li>\\(x_i\\) is the input vector at the same pos as the current output vector \\(y_i\\)</li> </ul> </li> <li>Propagates info between vectors</li> <li></li> <li>The process<ul> <li>Assign every word t in the vocabular an Embedding</li> <li>Feeding this into a self attention layer we get another seq of vectors \\(y_{the}\\) , \\(y_{cat}\\) etc</li> <li>each of the \\(y_{something}\\) is a weighted sum over all the embedding vectors in the first seq weighted by their normalized dot product with \\(v_{something}\\)</li> <li>the dot product shows how related the vectors are in the sequence<ul> <li>weights determined by them</li> <li>Self-Attention layer may give more weights to those input vectors that are more similar to each other when generating the output vectors</li> </ul> </li> </ul> </li> <li>Properties<ul> <li>Inputs are a set (not sequence)</li> <li>If input seq is permuted, the output is too</li> <li>Ignores the sequential nature of input by itself</li> </ul> </li> <li>Code</li> </ul> <pre><code>def attention(K, V, Q):\n    _, n_channels, _ = K.shape\n    A = torch.einsum('bct,bcl-&gt;btl', [K, Q])\n    A = F.softmax(A * n_channels ** (-0.5), 1)\n    R = torch.einsum('bct,btl-&gt;bcl', [V, A])\n    return torch.cat((R, Q), dim=1)\n</code></pre>"},{"location":"KB/Self%20Attention/#ref","title":"Ref","text":"<ul> <li>perterbloem</li> </ul>"},{"location":"KB/Self%20Distillation/","title":"Self Distillation","text":""},{"location":"KB/Self%20Distillation/#self-distillation","title":"Self Distillation","text":"<ul> <li>To be specific, Yuan et al. proposed teacher-free knowledge distillation meth- ods based on the analysis of label smoothing reg- ularization (Yuan et al., 2020). Hahn and Choi pro- posed a novel self-knowledge distillation method, in which the self-knowledge consists of the predicted probabilities instead of traditional soft probabilities (Hahn and Choi, 2019).</li> <li>These predicted probabilities are defined by the feature representations of the train- ing model. They reflect the similarities of data in feature embedding space. Yun et al. proposed class- wise self-knowledge distillation to match the output distributions of the training model between intra- class samples and augmented samples within the same source with the same model (Yun et al., 2020).</li> <li>In addition, the self-distillation proposed by Lee et al. (2019a) is adopted for data augmentation and the self- knowledge of augmentation is distilled into the model itself. Self distillation is also adopted to optimize deep models (the teacher or student networks) with the same architecture one by one (Furlanello et al., 2018; Bagherinezhad et al., 2018)</li> <li>both self-distillation and online distillation are properly in- tegrated via the multiple knowledge transfer frame- work (Sun et al., 2021).</li> </ul>"},{"location":"KB/Self%20Supervised%20Survey/","title":"Self Supervised Survey","text":""},{"location":"KB/Self%20Supervised%20Survey/#self-supervised-survey","title":"Self Supervised Survey","text":""},{"location":"KB/Self%20Supervised%20Survey/#abstract","title":"Abstract","text":"<ul> <li>Large-scale labeled data are generally required to train deep neural networks in order to obtain better performance in visual feature learning from images or videos for computer vision applications </li> <li>as a subset of unsupervised learning methods, self-supervised learning methods are proposed to learn general image and video features from large-scale unlabeled data without using any human-annotated labels </li> </ul>"},{"location":"KB/Self%20Supervised%20Survey/#motivation","title":"Motivation","text":"<ul> <li>The performance of deep convolutional neural networks (ConvNets) greatly depends on their capability and the amount of training data. </li> <li>collection and annotation of large-scale datasets are time-consuming and expensive </li> <li>Compared to image datasets, collection and annotation of video datasets are more expensive due to the temporal dimension </li> <li>To avoid time-consuming and expensive data annotations, many self-supervised methods were proposed to learn visual features from large-scale unlabeled images or videos without using any human annotations </li> <li>During the self-supervised training phase, a predefined pretext task is designed for ConvNets to solve, and the pseudo labels for the pretext task are automatically generated based on some attributes of data </li> <li>Then the ConvNet is trained to learn object functions of the pretext task </li> <li>After the self-supervised training finished, the learned visual features can be further transferred to downstream tasks (especially when only relatively small data available) as pretrained models to improve performance and overcome over- fitting. </li> <li> <p>shallow layers capture general low-level features like edges, corners, and textures while deeper layers capture task related high-level features </p> </li> <li> <p>Pseudo Label</p> </li> <li> <p>Pretext Task</p> </li> <li> <p>Downstream Task</p> </li> <li> <p>Weakly-supervised Learning</p> </li> </ul>"},{"location":"KB/Self%20Supervised%20Survey/#formulation-of-different-learning-schemas","title":"FORMULATION OF DIFFERENT LEARNING SCHEMAS","text":"<ul> <li> <p>Supervised Learning Formulation</p> </li> <li> <p>Semi-Supervised Learning Formulation</p> </li> <li> <p>Weakly Supervised Learning Formulation</p> </li> <li>Self-supervised Learning</li> </ul>"},{"location":"KB/Self%20Supervised%20Survey/#nn","title":"NN","text":"<ul> <li>Spatiotemporal Convolutional Neural Network</li> </ul>"},{"location":"KB/Self%20Supervised%20Survey/#pretext-tasks","title":"Pretext Tasks","text":"<ul> <li>Pretext Tasks</li> </ul>"},{"location":"KB/Self%20Supervised%20Survey/#datasets","title":"Datasets","text":"<ul> <li> <p>Places</p> </li> <li> <p>Places365</p> </li> <li> <p>SUNCG</p> </li> <li> <p>SVHN</p> </li> <li> <p>STL-10</p> </li> <li> <p> </p> </li> <li> <p>YFCC100M</p> </li> <li> <p>SceneNet RGB-D</p> </li> <li> <p>Moment in Time</p> </li> <li> <p>Kinetics</p> </li> <li> <p>AudioSet</p> </li> <li> <p>KITTI</p> </li> <li> <p>UCF101</p> </li> <li> <p>HMDB51 </p> </li> </ul>"},{"location":"KB/Self%20Supervised%20Survey/#other-tasks","title":"Other Tasks","text":"<ul> <li> <p>Image Generation with Inpainting</p> </li> <li> <p>Image Generation with Super Resolution</p> </li> <li> <p>Image Generation with Colorization</p> </li> <li> <p>Learning with Context Similarity</p> </li> <li> <p>Learning with Spatial Context Structure</p> </li> <li> <p>Learning with Labels Generated by Game Engines</p> </li> <li> <p>Learning with Labels Generated by Hard-code Programs</p> </li> <li> <p>Learning from Video Colorization</p> </li> <li> <p>Learning from Video Prediction</p> </li> <li> <p>Learning from RGB-Flow Correspondence</p> </li> <li> <p>Learning from Visual-Audio Correspondence</p> </li> <li> <p>Ego-motion</p> </li> </ul>"},{"location":"KB/Self%20Supervised%20Vision%20Transformers/","title":"Self Supervised Vision Transformers","text":"<p>toc: true title: Self Supervised Vision Transformers</p> <p>categories: ['temp']</p>"},{"location":"KB/Self%20Supervised%20Vision%20Transformers/#self-supervised-vision-transformers","title":"Self Supervised Vision Transformers","text":"<ul> <li>An Empirical Study of Training Self-Supervised Vision Transformers<ul> <li>recipes for Vision Transformer are yet to be built</li> <li>Self Supervised</li> <li>instability is a major issue that degrades accuracy, and it can be hidden by apparently good results</li> <li>improved when training is made more stable</li> <li>MoCO v3, a framework which offers an incremental improvement of MoCO</li> <li></li> </ul> </li> </ul>"},{"location":"KB/Self%20Supervised/","title":"Self Supervised","text":""},{"location":"KB/Self%20Supervised/#self-supervised","title":"Self Supervised","text":"<ul> <li>Subset of Unsupervised Learning</li> <li>ConvNet trained with supervisory signals that are generated from data itself</li> <li>Uses source task only based on input data</li> <li>No human biases, less discriminative</li> </ul>"},{"location":"KB/Self%20Supervised/#anchor","title":"anchor","text":""},{"location":"KB/Self-supervised%20Learning/","title":"Self-supervised Learning","text":""},{"location":"KB/Self-supervised%20Learning/#self-supervised-learning","title":"Self-supervised Learning","text":"<ul> <li>Compared to supervised learning methods which require a data pair Xi and Yi while Yi is annotated by human labors, self-supervised learning also trained with data Xi along with its pseudo label Pi while Pi is automatically generated for a pre-defined pretext task without involving any human annotation </li> <li>The pseudo label Pi can be generated by using attributes of images or videos such as the context of images [18], [19], [20], [36], or by traditional hand-designed methods [49], [50], [51].  </li> <li> </li> <li>As long as the pseudo labels P are automatically generated without involving human annotations, then the methods belong to self-supervised learning.</li> </ul>"},{"location":"KB/Semantic%20Analysis/","title":"Semantic Analysis","text":""},{"location":"KB/Semantic%20Analysis/#semantic-analysis","title":"Semantic Analysis","text":"<ul> <li>Meaning of the language</li> <li>Meanings of the word to extend and perhaps disambiguate the result returned by the syntactic parse</li> <li>Look up the individual words in a dictionary (or Lexicon) and extract their meanings</li> <li>But many words have several meanings<ul> <li>Lexical Disambiguation</li> </ul> </li> <li>Sentence level processing</li> </ul>"},{"location":"KB/Semantic%20Data/","title":"Semantic Data","text":""},{"location":"KB/Semantic%20Data/#semantic-data","title":"Semantic Data","text":"<ul> <li>represents the world by a set of subject-predicate-object triple Therefore, the size of the messages is small.</li> </ul>"},{"location":"KB/Semantic%20Grammar/","title":"Semantic Grammar","text":""},{"location":"KB/Semantic%20Grammar/#semantic-grammar","title":"Semantic Grammar","text":"<ul> <li>combine syntactic, semantic and pragmatic knowledge into a single set of rules in the form of a grammar</li> </ul>"},{"location":"KB/Semantic%20Markers/","title":"Semantic Markers","text":""},{"location":"KB/Semantic%20Markers/#semantic-markers","title":"Semantic Markers","text":"<ul> <li>PHYSICAL-OBJECT</li> <li>ANIMATE-OBJECT</li> <li>ABSTRACT-OBJECT</li> <li>Unfortunately, to solve Lexical Disambiguation problem complete, it becomes necessary to introduce more and more finely grained semantic markers</li> </ul>"},{"location":"KB/Semantic%20Segmentation/","title":"Semantic Segmentation","text":""},{"location":"KB/Semantic%20Segmentation/#semantic-segmentation","title":"Semantic Segmentation","text":"<ul> <li>task of assigning semantic labels to each pixel in images </li> <li>autonomous driving, human-machine interaction, and robotic </li> <li>Fully Convolutional Network (FCN) [4], DeepLab [5], PSPNet [6] and datasets such as PASCAL VOC [96], CityScape [97], ADE20K [98]. </li> <li>FCN [4] is a milestone work for semantic segmentation since it started the era of applying fully convolution network (FCN) to solve this task </li> <li>When using semantic segmentation as downstream task to evaluate the quality of image features learned by selfsupervised learning methods, the FCN is initialized with the parameters trained with the pretext task and fine-tuned on the semantic segmentation dataset, then the performance on the semantic segmentation task is evaluated and compared with that of other self-supervised methods.</li> </ul>"},{"location":"KB/Semantics%20influences%20form/","title":"Semantics influences form","text":""},{"location":"KB/Semantics%20influences%20form/#semantics-influences-form","title":"Semantics Influences Form","text":"<ul> <li>Past tense choices mediated by perceived semantic similarity to neighbors, e.g. drank</li> <li>Adults under time pressure also make overgeneralization errors at rates from 6% to 31%</li> </ul>"},{"location":"KB/Semi%20Supervised/","title":"Semi Supervised","text":""},{"location":"KB/Semi%20Supervised/#semi-supervised","title":"Semi Supervised","text":"<ul> <li>Obtain weak labels instead of class labels</li> <li>Eg: \"similar\"</li> <li>Contrastive Loss</li> <li>Triplet Loss</li> <li>Max Margin Loss</li> </ul>"},{"location":"KB/Semi%20Supervised/#anchor","title":"anchor","text":""},{"location":"KB/Semi-Supervised%20Learning%20Formulation/","title":"Semi-Supervised Learning Formulation","text":""},{"location":"KB/Semi-Supervised%20Learning%20Formulation/#semi-supervised-learning-formulation","title":"Semi-Supervised Learning Formulation","text":"<ul> <li>given a small labeled dataset X and a large unlabeled dataset Z, for each data Xi in X, there is a corresponding human-annotated label Yi  </li> <li> </li> <li>For a set of N labeled training data</li> </ul>"},{"location":"KB/Sense-Plan-Act%20Model/","title":"Sense-Plan-Act Model","text":""},{"location":"KB/Sense-Plan-Act%20Model/#sense-plan-act-model","title":"Sense-Plan-Act Model","text":"<ul> <li>Deliberative planning has three main steps that are performed in sequence: Sensing,</li> <li>Planning</li> <li>Acting (executing the plan)</li> </ul>"},{"location":"KB/Sensitivity/","title":"Sensitivity","text":""},{"location":"KB/Sensitivity/#sensitivity","title":"Sensitivity","text":"<ul> <li> \\[TPR = \\frac{TP}{TP + FN}\\] </li> </ul>"},{"location":"KB/Sensory%20Feedback/","title":"Sensory Feedback","text":""},{"location":"KB/Sensory%20Feedback/#sensory-feedback","title":"Sensory Feedback","text":"<ul> <li>Variable data measured by sensors and relayed to the controller in a Closed-loop System. If the controller receives feedback that lies outside an acceptable range, then an error has occurred. The controller sends an error signal to the robot. The robot makes the necessary adjustments in accordance with the error signal.</li> </ul>"},{"location":"KB/Sentence%20Segmentation/","title":"Sentence Segmentation","text":""},{"location":"KB/Sentence%20Segmentation/#sentence-segmentation","title":"Sentence Segmentation","text":"<ul> <li>identify the processing unit, consists of one or more words</li> <li>Sentence boundary detection</li> <li>Sentence boundary disambiguation</li> <li>Sentence boundary recognition</li> </ul>"},{"location":"KB/Sentence%20level%20processing/","title":"Sentence level processing","text":""},{"location":"KB/Sentence%20level%20processing/#sentence-level-processing","title":"Sentence Level Processing","text":"<ul> <li>Semantic Grammar</li> <li>Case Grammar</li> <li>Conceptual Parsing</li> <li>Approximately Compositional Semantic Parsing</li> </ul>"},{"location":"KB/Sentiment%20Neuron/","title":"Sentiment Neuron","text":""},{"location":"KB/Sentiment%20Neuron/#sentiment-neuron","title":"Sentiment Neuron","text":"<ul> <li>Linear model + L1 Lp Regularization</li> <li>Uses very few learned units</li> <li>Single sentiment neuron that predicts the sentiment value</li> <li></li> <li>Can be useful for Unsupervised Learning</li> </ul>"},{"location":"KB/Sentiment%20Neuron/#refs","title":"Refs","text":""},{"location":"KB/SentimentAnalysis/","title":"SentimentAnalysis","text":""},{"location":"KB/SentimentAnalysis/#sentimentanalysis","title":"SentimentAnalysis","text":"<ul> <li>Sentiment Neuron</li> <li>Block Sparse Kernel</li> </ul>"},{"location":"KB/Separation/","title":"Separation","text":""},{"location":"KB/Separation/#separation","title":"Separation","text":"<ul> <li>model predictions are independent of the sensitive feature given the target variable</li> <li>Equalized Odds</li> <li>in classification models, the True Positive (TP) rate and the False Positive (FP) rate are the same in all the subgroups within the sensitive feature</li> </ul>"},{"location":"KB/Sepsis/","title":"Sepsis","text":""},{"location":"KB/Sepsis/#sepsis","title":"Sepsis","text":"<ul> <li>An imbalance in the body's response to infection that injures the body's tissues and organs</li> </ul>"},{"location":"KB/Seq2Seq/","title":"Seq2Seq","text":""},{"location":"KB/Seq2Seq/#seq2seq","title":"Seq2Seq","text":"<ul> <li>Basic RNN Architectures</li> <li>Long term dependency Issues</li> <li>Even if hidden state vector has a high dimensionality, cannot hold all info</li> <li>Sequence to Sequence Learning with Neural Networks</li> <li>encoder-decoder learning to map sequences to sequences</li> <li>multilayered Long Short-Term Memory [LSTM)](Long Short Term Memory (LSTM|Long Short Term Memory (LSTM|LSTM)](LSTM)](Long Short Term Memory (LSTM|Long Short Term Memory (LSTM|LSTM).md).md)</li> <li>large deep LSTM with a limited vocabulary can outperform a standard statistical machine translation (SMT)-based system whose vocabulary is unlimited on a large-scale MT task</li> <li>WMT14</li> <li>BLEU score</li> <li>reversing the order of the words in all source sentences (but not target sentences) improved the LSTM\u2019s performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier</li> </ul>"},{"location":"KB/Sequential%20Relation%20Bias/","title":"Sequential Relation Bias","text":""},{"location":"KB/Sequential%20Relation%20Bias/#sequential-relation-bias","title":"Sequential Relation Bias","text":"<ul> <li>Sometimes our data has a sequential characteristic. For instance, time series and sentences consist of sequential elements that appear one after another. To model this pattern, we can introduce a Recurrent layer to our network:</li> <li></li> </ul>"},{"location":"KB/Sequential%20effects%20within%20a%20short%20foreperiod%20context%20Evidence%20for%20the%20conditioning%20account%20of%20temporal%20preparation/","title":"Sequential effects within a short foreperiod context Evidence for the conditioning account of temporal preparation","text":""},{"location":"KB/Sequential%20effects%20within%20a%20short%20foreperiod%20context%20Evidence%20for%20the%20conditioning%20account%20of%20temporal%20preparation/#sequential-effects-within-a-short-foreperiod-context-evidence-for-the-conditioning-account-of-temporal-preparation","title":"Sequential effects within a short foreperiod context Evidence for the conditioning account of temporal preparation","text":"<ul> <li>Michael B. Steinborn , Bettina Rolke, Daniel Bratzke, Rolf Ulrich</li> </ul>"},{"location":"KB/Sequential%20effects%20within%20a%20short%20foreperiod%20context%20Evidence%20for%20the%20conditioning%20account%20of%20temporal%20preparation/#abstract","title":"Abstract","text":"<ul> <li>Responses to an imperative stimulus (IS) are especially fast when they are preceded by a warning signal (WS).</li> <li>When the interval between WS and IS (the foreperiod, FP) is variable, reaction time (RT) is not only influenced by the current FP but also by the FP of the preceding trial</li> <li>sequential effects originate from a trace conditioning process, in which the individuals learn the temporal WS\u2013IS relationship in a trial-by-trial manner</li> <li>that trace conditioning is maximal when the temporal interval between the conditioned and unconditioned stimulus is between 0.25 and 0.60 s</li> <li>, one would predict that sequential effects occur especially within short FP contexts.</li> <li>However, this prediction is contradicted by Karlin [Karlin, L. (1959)]</li> <li>investigate temporal preparation for short FPs</li> <li>The results provide strong evidence for sequential effects within a short FP context and thus support the trace conditioning account of temporal preparation.</li> </ul>"},{"location":"KB/Sequential%20effects%20within%20a%20short%20foreperiod%20context%20Evidence%20for%20the%20conditioning%20account%20of%20temporal%20preparation/#experiment-1","title":"Experiment 1","text":"<ul> <li>Anticipatory responding was controlled by using a choice RT task</li> <li>There was a main effect of the factor FP-set on RT, F(1,21) = 219.3, partial g2 = .91, p &lt; .001, indicating that RT was shorter in the short FP-set (366 ms) than in the long FP-set</li> <li>RT benefit for the short FP-set might be attributable to a better general ability to process short time intervals than long ones (e.g., Klemmer, 1957; Na\u0308a\u0308ta\u0308nen et al., 1974).</li> <li>main effect of FPn on RT,</li> <li>RT decreased as \\(FP_n\\) increased</li> <li>FP in the preceding trial also influenced RT in the current trial as revealed by a main effect of \\(FP_{n-1}\\) on RT</li> <li>increased as \\(FP_{n-1}\\) decreased</li> <li>\\(FP_{n-1}\\) \\(FP_n\\) interaction effect on RT</li> <li>when the preceding FP was long, RT in a current trial decreased with increasing FP and this effect was</li> <li>weaker when a short FP preceded a current trial</li> <li>asymmetry of the sequential FP effect was smaller for the short FP-set than for the long FP-set.</li> <li>Most important, however, the sequential FP effect was not restricted to the long FP-set but was also present for the short FP-set of FP-durations below 0.6 s</li> </ul>"},{"location":"KB/Sequential%20effects%20within%20a%20short%20foreperiod%20context%20Evidence%20for%20the%20conditioning%20account%20of%20temporal%20preparation/#experiment-2","title":"Experiment 2","text":"<ul> <li>assessed sequential FP effects in a simple RT task employing only the short FP-set</li> <li>catch trial technique</li> <li>compared the asymmetrical sequential FP effect in a condition with 0% catch trials (referred to as no-CT condition) to a condition with 25% catch trials (referred to as CT condition)</li> <li>RT was prolonged in the CT condition</li> <li>main effect of FPn on RT</li> <li>decrease of RT with increasing FPn</li> <li>\\(FP_{n-1}\\) influenced RT</li> <li>influence of the preceding FP was unaffected by CT</li> <li>asymmetrical sequential FP effect again showed up in the \\(FP_{n-1}\\) \\(FP_n\\) interaction on RT</li> <li>anticipatory responses also increased with decreasing preceding FP</li> <li>There was a significant \\(FP_{n-1}\\) \\(FP_n\\) interaction on RT for the no-CT condition</li> <li>weak CT \\(FP_n\\) interaction effect on RT</li> </ul>"},{"location":"KB/Sequential%20effects%20within%20a%20short%20foreperiod%20context%20Evidence%20for%20the%20conditioning%20account%20of%20temporal%20preparation/#experiment-3","title":"Experiment 3","text":"<ul> <li>FP-range employed in Karlin's study was too dense and therefore did not produce sufficient temporal uncertainty</li> <li>simple RTs were much faster (220 ms) than choice RTs</li> <li>RT pattern differed between the task conditions,</li> <li>In contrast to Experiment 2, an upwardsloping FP-RT effect was observed</li> <li>RT increased from the shortest towards the longest \\(FP_n\\)</li> <li>RT decreased with increasing \\(FP_{n-1}\\)</li> <li>responses in short \\(FP_n\\) trials were always fast irrespective of \\(FP_{n-1}\\).</li> <li>In contrast, responses in long FPn trials were on average slower and showed a sequential modulation.</li> <li>Precisely, in long FPn trials, responses were relatively fast when \\(FP_{n-1}\\) was also long compared to when \\(FP_{n-1}\\) was short.</li> <li>In sum, the simple RT condition revealed especially fast responses and an extraordinary high percentage of anticipatory responses in short FPn trials, even though FPn1 was long</li> <li>is consistent with the results of Karlin (1959) and suggests that participants mainly prepared for an early imperative moment without re-preparing in long FPn trials</li> <li>the RT pattern in the simple RT condition clearly indicates that Karlin's (1959) finding was not an anomalous result but a reliable empirical phenomenon that occurs when average FPs are small and the FPrange is very dense</li> <li>The overall pattern of results (simple and choice RT condition) is consistent with the view that participants already attained maximal preparation at the short \\(FP_n\\) and were not able to re-prepare when the IS did not occur at the short \\(FP_n\\).</li> <li>Instead, they may have relied on residual preparatory activity from the early imperative moment (Alegria, 1974; Alegria, 1975b).</li> <li>instance, they may have shifted a single moment of peak preparation in a rather analog way, that is, after a short \\(FP_n\\) they expected the IS somewhat earlier, after a long FPn1 \\(FP_{n-1}\\) somewhat later</li> </ul>"},{"location":"KB/Sequential%20effects%20within%20a%20short%20foreperiod%20context%20Evidence%20for%20the%20conditioning%20account%20of%20temporal%20preparation/#general-discussion","title":"General discussion","text":"<ul> <li>when the FP-range is too dense, the typical asymmetrical sequential FP effect does not occur.</li> <li>Hence, the RT pattern observed in the simple RT condition demonstrates that Karlin's (1959) finding of a reversed sequential FP effect is a robust phenomenon that occurs in simple RT tasks when the FP-range is very dense.</li> <li>We suggest that when the FP-range is very dense, the individuals may not represent three distinct imperative moments but a single relatively noisy one to which they attain preparation</li> <li>The result pattern of the simple RT condition indicates that participants attained preparation at an early imperative moment because responses were especially fast and a high amount of anticipatory responses were observed in short FPn trials</li> <li>The observation of a reversed sequential effect, however, shows that the moment of peak preparation was still influenced by the preceding trial.</li> <li>In particular, participants may have expected the IS after a short FPn1 somewhat earlier, but after a long</li> <li>\\(FP_{n-1}\\) somewhat later in time</li> <li>Critically, when the small FP-range does not enable a sharpedged representation of three distinct critical moments but only a noisy representation of a single critical moment, then the process that produces the asymmetrical sequential FP effects at short FP</li> <li>no sequential FP effect in short \\(FP_n\\) trials should be expected in this situation</li> <li>Importantly, a rather analog sequential adjustment of a single but early preparatory peak should result in a sequential modulation at later imperative moments, as is exactly observed in the simple RT condition of Experiment 3</li> <li>If temporal preparation had increased with \\(FP_n\\)-length, this should have resulted in more efficient performance</li> </ul>"},{"location":"KB/Sequential%20effects%20within%20a%20short%20foreperiod%20context%20Evidence%20for%20the%20conditioning%20account%20of%20temporal%20preparation/#images","title":"Images","text":""},{"location":"KB/Serious%20Games/","title":"Serious Games","text":""},{"location":"KB/Serious%20Games/#serious-games","title":"Serious Games","text":"<ul> <li>Support learning</li> <li>Simulators of real world tasks</li> <li>Eg: response simulator, kerbal space program, sustainable energy management</li> </ul>"},{"location":"KB/Serotonin/","title":"Serotonin","text":""},{"location":"KB/Serotonin/#serotonin","title":"Serotonin","text":"<ul> <li>A neurotransmitter believed to play many roles, including, but not limited to, temperature regulation, sensory perception, and the onset of sleep. Neurons using serotonin as a transmitter are found in the brain and in the gut. A number of antidepressant medications are targeted to brain serotonin systems.</li> </ul>"},{"location":"KB/Servo%20Control/","title":"Servo Control","text":""},{"location":"KB/Servo%20Control/#servo-control","title":"Servo Control","text":"<ul> <li>The process by which the control system of the robot checks if the attained pose of the robot corresponds to the pose specified by the motion planning with required performance and safety criteria.</li> </ul>"},{"location":"KB/Servo%20Motor/","title":"Servo Motor","text":""},{"location":"KB/Servo%20Motor/#servo-motor","title":"Servo Motor","text":"<ul> <li>An electrical power mechanism used to effect motion or maintains position of the robot</li> </ul>"},{"location":"KB/Servo%20Pack/","title":"Servo Pack","text":""},{"location":"KB/Servo%20Pack/#servo-pack","title":"Servo Pack","text":"<ul> <li>An alternating, current electrical power mechanism that is controlled through logic to convert electrical supply power that is in a sine wave form to a Pulse Width Modulated (PWM) square form, delivered to the motors for motor control: speed, direction, acceleration, deceleration and braking control.</li> </ul>"},{"location":"KB/Servo-controlled%20Robot/","title":"Servo controlled Robot","text":""},{"location":"KB/Servo-controlled%20Robot/#servo-controlled-robot","title":"Servo-controlled Robot","text":"<ul> <li>The control of a robot through the use of a Closed-loop Servo-system, in which the position of the robot axis is measured by feedback devices and is stored in the controller's memory</li> </ul>"},{"location":"KB/Servo-system/","title":"Servo system","text":""},{"location":"KB/Servo-system/#servo-system","title":"Servo-system","text":"<ul> <li>A system in which the controller issues commands to the motors, the motors drive the arm, and an encoder sensor measures the motor rotary motions and signals the amount of the motion back to the controller.</li> </ul>"},{"location":"KB/Shading/","title":"Shading","text":""},{"location":"KB/Shading/#shading","title":"Shading","text":""},{"location":"KB/Shapes%20Dataset/","title":"Shapes Dataset","text":""},{"location":"KB/Shapes%20Dataset/#shapes-dataset","title":"Shapes Dataset","text":"<ul> <li>Convention is that the first dimension of the dataset belongs to the features and the second to the number of samples. The operations can then be systematically applied from the left.  </li> <li>Exception!, in TensorFlow and PyTorch it is the other way around!</li> <li>\\((\\#features, \\#samples)\\)</li> </ul>"},{"location":"KB/Shared%20Character%20Set/","title":"Shared Character Set","text":""},{"location":"KB/Shared%20Character%20Set/#shared-character-set","title":"Shared Character Set","text":"<ul> <li>helps in narrowing down to a small set of languages</li> <li>Arabic &amp; Persian<ul> <li>Share same characters but one has supplemental characters</li> </ul> </li> <li>Russian &amp; Ukrainian<ul> <li>Same Character Set - Different Frequencies</li> </ul> </li> <li>Norwegian &amp; Swedish</li> </ul>"},{"location":"KB/Sharpness%20and%20Flatness/","title":"Sharpness and Flatness","text":""},{"location":"KB/Sharpness%20and%20Flatness/#sharpness-and-flatness","title":"Sharpness and Flatness","text":"<ul> <li>Three 1D loss surfaces of a VGG-9 network with layer normalization instead of filter normalization, sorted from flattest to sharpest minimum, according to the authors</li> <li></li> </ul>"},{"location":"KB/Shear/","title":"Shear","text":""},{"location":"KB/Shear/#shear","title":"Shear","text":"<ul> <li>Stretches the image in one of the axial planes, i.e. shear occurs along the x-axis or y-axis. A maximum shear of \u00b120\u25e6 is used to ensure class preservation.</li> </ul>"},{"location":"KB/Shepard%20Interpolation/","title":"Shepard Interpolation","text":""},{"location":"KB/Shepard%20Interpolation/#shepard-interpolation","title":"Shepard Interpolation","text":"<ul> <li>$$</li> </ul> <p>\\begin{cases}\\Sigma^{N}{i=1}w{i}(x)f_{i}&amp; \\text{if } d(x,x_{i}) \\neq 0 \\forall i\\f_{i}&amp; \\text{if } d(x, x_{i})=0\\</p> <p>\\end{cases}</p> <p>$$ - \\(w_{i}(x) = \\frac{1}{d(x,x_{i})^{p}}\\) - Neighborhood N determines points aka radius</p>"},{"location":"KB/Sherlock/","title":"Sherlock","text":""},{"location":"KB/Sherlock/#sherlock","title":"Sherlock","text":"<ul> <li>Outer loop: Sherlock (Katz et al., 1998) tutors the troubleshooting of a large piece of simulated electrical equipment, an avionics test station.</li> <li>It provides many views on the equipment and its schematics, so no screenshots are included here.</li> <li>Inner loop: Troubleshooting the equipment requires taking many steps, such as measuring voltages and replacing suspect parts. Sherlock gives unsolicited feedback only if a step is unsafe, that is, if the step would cause serious damage to the equipment or the student if it were done in the real world</li> <li>Sherlock also makes extensive feedback available after the student has solved the problem. Sherlock's default post-solution feedback is to display a side-by-side summary of the student's solution and Sherlock's ideal solution.</li> </ul>"},{"location":"KB/Shock%20Detection%20Function/","title":"Shock Detection Function","text":""},{"location":"KB/Shock%20Detection%20Function/#shock-detection-function","title":"Shock Detection Function","text":"<ul> <li>Shock detection is a function supported by the Yaskawa robot controller that reduces the impact of a robot collision by stopping the manipulator without any external sensor when the tool or the manipulator collide with a peripheral device.</li> </ul>"},{"location":"KB/Shortcuts%20to%20Quantifier%20Interpretation%20in%20Children%20and%20Adults/","title":"Shortcuts to Quantifier Interpretation in Children and Adults","text":""},{"location":"KB/Shortcuts%20to%20Quantifier%20Interpretation%20in%20Children%20and%20Adults/#shortcuts-to-quantifier-interpretation-in-children-and-adults","title":"Shortcuts to Quantifier Interpretation in Children and Adults","text":"<ul> <li>Patricia J. Brooks &amp; Irina Sekerina</li> </ul>"},{"location":"KB/Shortcuts%20to%20Quantifier%20Interpretation%20in%20Children%20and%20Adults/#intro","title":"Intro","text":"<ul> <li>Summarized in 2022-10-10</li> <li>Errors involving universal quantification are common in contexts depicting sets of individuals in partial, one-to-one correspondence</li> <li>quantifier-spreading errors are more common with distributive quantifiers each and every than with all.</li> <li>pairs of pictures</li> <li>selected one corresponding to a sentence containing a universal quantifier</li> <li>not in correspondence, with correct sentence interpretation requiring their attention</li> <li>Children younger than 9 years made numerous errors</li> <li>with poorer performance in distributive contexts than collective ones</li> <li>21 native, English-speaking adults, given a similar task with the distributive quantifier every, also made childlike errors undermines accounts positing immature syntactic structures as the error source</li> <li>errors seemingly reflect inaccurate syntax to semantics mapping, with adults and children alike resorting to processing shortcuts.</li> <li>Quantificational terms such as all, usually, and most are a crucial type of linguistic device used to indicate which sets of individuals or events have which properties and relationships</li> <li>acquisition may be delayed relative to other sorts of lexical items (e.g., nouns and verbs) because their complex patterns of usage often result in interpretive ambiguities</li> <li>96 children (5- to 9-year-olds)</li> <li>Both pictures showed extra objects</li> <li>In spoken language, however, the intensifier interpretation is predominant in which it is conventional to say all even when it does not imply exhaustivity</li> <li>I left all my money at home would not preclude their having money in the bank</li> <li>all is used primarily as an adverbial intensifier in both child language and child-directed speech</li> <li>every and each involve additional lexical complexity</li> <li>Every appears inside compounds\u2014for example, everybody\u2014and it vacillates between collective and distributive interpretations when used as a quantifier</li> <li>Each is more uniformly distributive but has the further conceptual requirement that the individuals modified by each be successively scanned</li> <li>Every and each both occur only rarely in either childdirected or child speech, which limits opportunities for children to acquire their patterns of usage.</li> <li>overexhaustive search</li> <li>involves failure to properly restrict the domain of the universal quantifier to the</li> <li>exhaustive pairing</li> <li>classic spreading</li> <li>noun phrase (NP) it modifies</li> <li>complementary error referred to as underexhaustive search</li> <li>Very young children occasionally make other, more surprising errors in interpreting universal quantifiers, such as answering no to the question Is every bunny eating a carrot? when shown, for example, a picture of three rabbits, each eating a carrot, along with a dog eating a bone. This error is referred to as bunny spreading</li> <li>Children's errors with universal quantification have led to controversies with respect to how to explain them. One view is that the errors stem from children's deficient syntactic representations (Kang (2001), Philip (1995; 1996), Roeper and de Villiers (1993), Roeper and Matthei (1975), Roeper et al. (2005)). Philip (1995; 1996), following Roeper and Matthei (1975) suggested that the classic spreading error is due to the fact that children syntactically misinterpret distributive universal quantifiers (e.g., each or every in English, cada in Spanish or Portuguese) as sentential adverbials that range over events as opposed to individuals. Roeper et al. (2005) described a sequence of steps of how children start with a general syntactic representation of every as an adverbial intensifier that gets progressively more specific as every changes its position in the syntactic representation.</li> <li>Rather, the errors are presumed to involve shallow processing, resulting in inaccurate mapping between syntactic and semantic representations</li> <li>First, Crain et al. (1996) did not systematically vary the position of the universal quantifier in the test questions or statements while holding constant the introductory story and scenario</li> <li>prototypical scenario</li> <li>This feature of their design provided children with unambiguous cues as to which set of entities was the focus of attention.</li> <li>Crain et al.'s (1996) claim that preschoolers have full competence with universal quantifiers would seem to be undermined by the fact that even older school-age children make errors identifying the domain of a universal quantifier.</li> <li>First, there have been great discrepancies in error rates across the many studies that have almost exclusively utilized the Truth Value Judgment Task, ranging from near perfect performance in Crain et al. (1996) to extremely high error rates in Kang (2001), that is, over 80% errors in 6- to 7-year-olds</li> <li>Our sentence\u2013picture matching task does not have the same demand characteristics as the Truth Value Judgment Task, and in our opinion, it provides a more accurate way of evaluating whether children's interpretations of sentences with universal quantifiers vary systematically as a function of the position of the</li> <li>quantifier in the sentence and the type of scene</li> <li>examine whether there is an asymmetry in the distribution of errors as a function of the syntactic position of the universal quantifier</li> <li>address the controversy as to whether children perform better in tasks with collective universal quantifiers (cf. Brooks and Braine (1996)) or with distributive ones (cf. Drozd (1996))</li> <li>Finally, because accounts positing syntactic deficits as the source of quantifierspreading errors (e.g., Kang (2001), Philip (1996), Roeper et al. (2005)) generally assume that adults are essentially error free in their comprehension of basic sentences containing universal quantifiers (i.e., their syntax is perfect), we tested a group of adults on a version of our task (Experiment 3) to evaluate this claim and to allow a more complete investigation of the developmental trajectory of quantifier acquisition from 5-year-olds to adults.</li> </ul>"},{"location":"KB/Shortcuts%20to%20Quantifier%20Interpretation%20in%20Children%20and%20Adults/#experiment-1","title":"EXPERIMENT 1","text":""},{"location":"KB/Shortcuts%20to%20Quantifier%20Interpretation%20in%20Children%20and%20Adults/#participants","title":"Participants","text":"<ul> <li>We recruited and tested twelve 5-year-olds (M = 5;5, range = 5;2\u20135;11), twelve 6-year-olds (M = 6;6, range = 6;2\u20136;10), twelve 7-yearolds (M = 7;6, range = 7;1\u20137;11), twelve 8-year-olds (M = 8;6, range = 8;0\u20138;11), and twelve 9-year-olds (M = 9;6, range = 9;1\u20139;11) at private elementary schools and after-school programs in Atlanta, Georgia.</li> <li>24 pairs of pictures depicting people involved in various activities such as carrying boxes, washing pets, or watering plants.</li> <li>Four types of picture pairs were constructed.</li> <li>three people individually engaged in an activity with three distinct objects or animals</li> <li>three people engaged in an activity with three objects</li> <li>Collective picture pair types 3 and 4 were variations of collective picture pair type 2, with new foils created to match the distributive pairs in terms of target\u2013foil similarity</li> <li>Across picture pairs, a variety of contexts with transitive actional verbs were used so that each sentence type could be presented multiple times without repeating any pictures</li> <li>All of the contexts involved humans acting on animate or inanimate objects</li> <li>Six sentence types were used</li> <li> <ul> <li>(1) Each of the (people) is (verb)ing an (object), for example, Each of the men is washing a bear. (2) There is a (person) (verb)ing each of the (objects), for example, There is a man washing each of the bears. (3) Every (person) is (verb)ing an (object), for example, Every man is washing a bear. (4) There is a (person) (verb)ing every (object), for example, There is a man washing every bear. (5) All of the (people) are (verb)ing an (object), for example, All of the men are washing a bear.</li> </ul> </li> <li> <ul> <li>(6) There is a (person) (verb)ing all of the (objects), for example, There is a man washing all of the bears.</li> </ul> </li> <li>Twelve additional pairs of pictures served as filler items.</li> </ul>"},{"location":"KB/Shortcuts%20to%20Quantifier%20Interpretation%20in%20Children%20and%20Adults/#procedure","title":"Procedure","text":"<ul> <li>single, 20-min session conducted in a quiet room of their school</li> <li>We showed children two pictures at a time and asked them to point to the picture that went best with a sentence read aloud</li> <li>After the child looked at both pictures, the experimenter read the corresponding sentence and asked the child to point to the picture that went best with the sentence.</li> <li>without providing any corrective feedback</li> <li>Across trials, we randomized the position of the correct picture</li> <li>Children made no errors on filler sentences, and these trials were not examined further.</li> <li>mixed-design analysis of variance</li> <li>The dependent variable was the proportion of correct picture choices for Sentence Types 1 through 4</li> <li>arcsine transformed these proportions and all others</li> </ul>"},{"location":"KB/Shortcuts%20to%20Quantifier%20Interpretation%20in%20Children%20and%20Adults/#analysis","title":"Analysis","text":"<ul> <li>The analysis showed significant main effects of syntactic position, F(1, 55) = 19.03, p &lt; .001, and age, F(4, 55) = 7.22, p &lt; .001. No other main effects or interactions were significant</li> <li>As shown in Table 1, comparisons against chance performance (50%) revealed that only the 9-year-olds as a group were above chance in selecting the correct pictures (Figure 1b) for sentences with the universal quantifier modifying the direct object.</li> <li>At this criterion, one 5-year-old (8%), two 6-year-olds (17%), five 7- year-olds (42%), five 8-year-olds (42%), and nine 9-year-olds (75%) performed above chance.</li> <li>Overall, children were correct in 95.8% of their picture selections when the original collective pictures of Brooks and Braine were used (see Figure 2) but only 83.1% of trials with the modified collective pictures (see Figures 3 and 4).</li> <li>children's responses became more consistently correct with age, with only children 7 years and older performing above chance as a group in the modified task when the quantifier modified the direct object.</li> <li>To examine whether individual children were above chance in selecting the appropriate collective picture on the modified task with all, we again used the binomial distribution ( p &lt; .05), with above-chance performance requiring 6 out of 6 correct responses</li> <li>At this criterion, zero 5-year-olds (0%), five 6-year-olds (42%), seven 7-year-olds (58%), seven 8-year-olds (58%), and seven 9-year-olds (58%) performed above chance.</li> <li>f we adopt a more lenient criterion (5 of 6), which is proportionally comparable to the 10 of 12 required for above-chance performance with sentences containing each or every, then six 5-year-olds (50%), eight 6-yearolds (67%), ten 7-year-olds (83%), eight 8-year-olds (67%), and ten 9-year-olds (83%) showed consistently strong individual performance.</li> <li>we conducted one additional mixed-design ANOVA with Quantifier (all, each, every) and Syntactic Position as within-subjects factors and Age as a between-subjects factor.</li> <li>The main effect of syntactic position was significant, F(1, 55) = 16.38, p &lt; .001, but was qualified by an interaction of quantifier and age, F(1, 55) = 7.13, p &lt; .01</li> <li>comprehension performance was more accurate when the universal quantifier modified the subject of the sentence.</li> <li>This effect of syntactic position, however, was highly significant for sentences with each or every but only marginally significant for sentences with all (see above for F tests for main effects of syntactic position in separate analyses by quantifier). No other interactions were significant.</li> <li>In general, their picture selections were more accurate for sentences with a universal quantifier modifying the subject in comparison to the direct object of a transitive actional verb.</li> <li>Although the Philip (1996) and Kang studies have shown a similar pattern of subject/object asymmetry to this study and Brooks and Braine (1996), we note that children performed at much higher levels of accuracy in our sentence\u2013picture matching task compared to the Truth Value Judgment Task. In none of our conditions, at any age, were children significantly below chance in their picture selections. This contrasts especially with Kang, who reported error rates over 80% in both English-speaking and Korean-speaking 6- and 7-year-olds</li> <li>However, by age 7, children were consistently correct in their picture choices regardless of the syntactic position of all in the sentence.</li> <li>This suggests that the collective groupings may have helped focus their at</li> <li>tention on the relevant set of entities modified by the quantifier.</li> <li>More generally, the Truth Value Judgment Task allows children to reject a picture for a variety of reasons (and it is often hard to discern the basis for children's pattern of responding)</li> <li>In Experiment 1, we used a sentence\u2013picture matching procedure in which children needed only to find the picture that matched the sentence. This task eliminated opportunities for participants to consider whether a collective versus distributive interpretation of the sentence was preferred and furthermore allowed us to carefully match our collective and distributive pictures with respect to the composition of the foils.</li> </ul>"},{"location":"KB/Shortcuts%20to%20Quantifier%20Interpretation%20in%20Children%20and%20Adults/#experiment-2","title":"Experiment 2","text":"<ul> <li>We designed Experiment 2 to eliminate this interpretive confound through the use of locative scenes.</li> <li>locative pictures with animals and other entities shown in containers of various sorts (e.g., bananas in baskets, bears in beds).</li> <li>universal quantifiers in three syntactic constructions that support distributive interpretations in a locative context</li> <li>Across constructions, we systematically varied both the syntactic position of the universal quantifier and whether the subject of the sentence referred to the containers or the entities in them</li> </ul>"},{"location":"KB/Shortcuts%20to%20Quantifier%20Interpretation%20in%20Children%20and%20Adults/#method","title":"Method","text":"<ul> <li>Participants. Twelve 7-year-olds (M = 7;6, range = 7;1\u20137;10), twelve 8-year-olds (M = 8;6, range = 8;0\u20138;11), and twelve 9-year-olds (M = 9;5, range = 9;0\u20139;10) took part in the experiment. We recruited and tested these children at the same schools as in Experiment 1. None of the children in Experiment 2 participated in the previous experiment.</li> </ul>"},{"location":"KB/Shortcuts%20to%20Quantifier%20Interpretation%20in%20Children%20and%20Adults/#materials","title":"Materials","text":"<ul> <li>27 pairs of pictures depicting various entities arranged in containers (e.g., alligators in bathtubs, turtles in tanks, apples in bowls)</li> <li>The pictures showed distributive arrangements with the entities and containers in partial, one-to-one correspondence with each other.</li> <li>Both pictures depicted three entities each located in a unique container. One picture showed two extra empty containers (see Figure 5a), and the other picture showed two objects that were not in containers (see Figure 5b).</li> <li>nine sentence types</li> <li> <ul> <li>(7) All of the (objects) are in a (container), for example, All of the alligators are in a bathtub. (8) All of the (containers) have an (object) in them, for example, All of the bathtubs have an alligator in them.</li> </ul> </li> <li>There is an (object) in all of the (containers), for example, There is an alligator in all of the bathtubs. Each of the (objects) is in a (container), for example, Each of the alligators is in a bathtub. Each of the (containers) has an (object) in it, for example, Each of the bathtubs has an alligator in it. There is an (object) in each of the (containers), for example, There is an alligator in each of the bathtubs. Every (object) is in a (container), for example, Every alligator is in a bathtub. Every (container) has an (object) in it, for example, Every bathtub has an alligator in it. There is an (object) in every (container), for example, There is an alligator in every bathtub.</li> </ul>"},{"location":"KB/Shortcuts%20to%20Quantifier%20Interpretation%20in%20Children%20and%20Adults/#analysis_1","title":"Analysis","text":"<ul> <li>The main effect of quantifier and all of the interactions involving quantifiers were not significant.</li> <li>Across syntactic constructions, 7-year-olds preferred the picture with the extra animals or objects as opposed to the picture with the extra containers.</li> <li>Both the 7- and 8-year-olds made correct picture selections at an above-chance level only for sentences with the universal quantifier modifying the noun correspond</li> <li>ing to the containers irrespective of the syntactic construction.</li> <li>n contrast, the majority of 9-year-olds correctly varied their picture selections in accordance with the varying syntactic constructions and performed above chance as a group for all sentence types.</li> <li>Experiment 2 replicated one of the main findings of Experiment 1: Only 9-yearolds as a group consistently identified the domain of the universal quantifier and selected the appropriate picture at above-chance levels for distributive events in which sets of objects were in partial, one-to-one correspondence.</li> <li>Rather, irrespective of the syntactic construction, they showed better performance on sentences with the quantifier modifying the containers</li> <li>The observed bias to prefer locative scenes in which all of the containers were filled (the so-called garage-centered bias) has been observed many times; see Drozd (2001) for a review</li> <li>These results are difficult to reconcile with Kang's</li> <li>Moreover, all of the age groups failed to show any effect of quantifier in Experiment 2 in contrast to Experiment 1</li> <li>That is, the children failed to show a familiarity effect with better performance for sentences with all.</li> <li>he differing results for the two experiments indicate that the collective scenes used with all in Experiment 1 were easier than the distributive ones used in Experiment 2 (see also Brinkmann et al. (1996)).</li> <li>It appears that these scenarios involving partial, one-toone correspondence pose considerable challenges for children.</li> <li>Although Experiment 2 provided no evidence that children distinguished the quantifier all from each or every, we emphasize that previous work (Brooks et al. (2001), Brooks et al. (1998)) has shown that children do readily distinguish these quantifiers on semantic grounds</li> </ul>"},{"location":"KB/Shortcuts%20to%20Quantifier%20Interpretation%20in%20Children%20and%20Adults/#experiment-3","title":"Experiment 3","text":"<ul> <li>In Experiment 3, we examined whether adults would make errors restricting the domain of a universal quantifier in a similar picture-selection task with distributive, locative scenes.</li> <li>Testing adults is important because syntactic accounts do not readily predict errors in syntactically competent adults</li> <li>Brooks and Braine (1996, Experiment 1) tested adults with actional scenes and found no errors. Their data, however, came from 10 undergraduates at a highly selective private university (Carnegie Mellon) and thus may not be representative of adults in general.</li> <li>Here we tested monolingual English-speaking undergraduates at a highly diverse public university. This experiment constituted pilot work to establish a paradigm suitable for an eye-tracking study.</li> <li>First, we included two filler pictures along with each target and foil picture, and second, we presented sentences with the quantifier every but did not test each or all.</li> <li>Participants. We recruited 22 monolingual, adult native speakers of English (16 women, 6 men; M age = 26 years, range = 18\u201349) from introductory psychology classes at the College of Staten Island, City University of New York, who received extra credit for their participation.</li> <li>We created PowerPoint\u00ae slides comprising four pictures that were presented simultaneously (see Figure 6 for an example). These slides depicted two sets of objects in partial, one-to-one correspondence</li> <li>Each array contained two pictures similar to those used in Experiment 2 (compare Figures 5 and 6), along with two filler pictures</li> <li>We presented each sentence type six times, in randomized order, for a total of 12 trials</li> <li>To permit naming, we numbered the pictures from 1 to 4, with the position of the target randomized across trials. We used a tape recorder to record participants' responses.</li> </ul>"},{"location":"KB/Shortcuts%20to%20Quantifier%20Interpretation%20in%20Children%20and%20Adults/#observations","title":"Observations","text":"<ul> <li>Across all participants, no errors were made on filler sentences indicating that the participants were generally compliant with the task instructions</li> <li>performance on the task was not at ceiling, with adults making errors on an average of 21% of the trials</li> <li>This error rate, which is numerically higher than the rate observed with the 9-year-olds of Experiments 1 and 2, is likely due to the added complexity of the task involving four pictures as opposed to two.</li> <li>Across the trials involving sentences with every, adult participants never selected either of the filler pictures. This indicates that their response set was effectively the same as that of the children in Experiment 2.</li> <li>Thus, unlike the children in Experiment 2, the adults did not show a preference for locative scenes in which all of the containers were filled.</li> <li>A further examination of data indicated that two adults selected the same picture on 12 of 12 trials indicating no sensitivity to the position of the quantifier in the sentence</li> <li>The fact that half of our adult participants made considerable numbers of errors in restricting every to its domain is not readily explicated by syntactic accounts positing immature syntactic representations as the source of children's quantifier-spreading errors</li> <li>Our findings that both children and adults make errors in quantifier interpretation are more readily explained by the underspecification account of Sanford and Sturt (2002).</li> <li>The crucial step involves deficient mapping from syntactic structure to a semantic representation,</li> <li>Although grammatically competent adults are capable of construing correct and fully specified semantic representations of utterances with quantifiers, it does not always happen</li> <li>The results demonstrate that many school-age children and adults had considerable difficulty in restricting the domain of a universal quantifier, especially when two sets of entities were in partial, one-to-one correspondence. This result contrasts most dramatically with the near perfect performance of preschool children in Crain et al. (1996)</li> <li>This suggests that the problem does not reside in the child's syntax, given the similarities in sentence structures used across studies, but in</li> <li>stead has to do with the difficulty of selecting the appropriate set of entities and avoiding distraction by salient objects.</li> <li>Taken together, the experiments suggest that it was the collective scenes as opposed to the use of all that improved children's performance in Experiment 1. Collective scenes were easier presumably because the group depiction aided the child in isolating one set of entities relative to the other</li> <li>Conversely, the distributive scenes were more difficult because the pictures were more visually symmetric. The observed difference in performance for collective versus distributive scenes seems to undermine syntactic accounts of children's errors given that the structures of the corresponding sentences were essentially the same.</li> <li>The fact that children's errors in Experiment 2 were not randomly distributed indicates that they noticed the extra objects and/or containers in the distributive pictures</li> <li>Again, only 9-yearolds consistently varied their picture selections in accordance with the varying syntactic constructions and did not show a strong preference for one picture configuration at the expense of the other.</li> <li>Their performance on a modified version of the sentence\u2013picture matching task was not only below ceiling, but their error rate was numerically higher than that of the 9-year-olds of Experiments 1 and 2. Note, however, that in contrast to the 7- and 8-year-olds' patterns, the adults' errors were equally distributed between the locative pictures with extra animals or objects versus extra containers.</li> <li>We suspect that both children and adults make errors in comprehension because they engage in shallow processing that causes inaccurate mapping between syntactic and semantic representations.</li> <li>In interpreting universal quantifiers, children construct underspecified representations using simpler processing strategies and then rely on pragmatics to solve the task.</li> <li>Adults also may construct underspecified representations as a first step that may or may not be followed by the application of algorithm. We speculate that adults stop at an underspecified representation when there are other demands on attention under conditions of working memory load, fatigue, or lack of cognitive effort.</li> <li>Another possibility with respect to the results of Experiment 2 is that the children may have gradually picked up on the fact that the universal quantifier modified the noun corresponding to the containers in two of three of the sentences.</li> <li>In either case, once children were fixated on a particular picture configuration, they perseverated and were reluctant to consider a competing picture as a possible alternative, even in the face of a conflicting sentence structure</li> <li>The suggestion that the children processed the sentences deterministically is not a new one.</li> <li>have indicated that children tend not to revise their initially incorrect interpretations of temporary syntactic or referential ambiguities even when disambiguating information becomes available.</li> <li>Shallow processing also provides a straightforward explanation of the errors made by adults in Experiment 3. Their high error rates suggest that adult listeners often do not tax their limited information-processing capacities by conducting exhaustive syntactic analyses of sentences but rather make use of simpler strategies in generating reasonable guesses</li> <li>These findings led Ferreira et al. (2002) to conclude that the meaning people obtain for a sentence is often not a reflection of its true content (p. 11) and that language processing often yields a merely good enough representation of a sentence's meaning</li> <li>This statement is an apt characterization of the performance of many school-age children and adults in our experiments. More generally, the comprehension of universal quantifiers seems an ideal domain for exploring the dynamics of attention allocation, and cognitive effort, in language processing.</li> </ul>"},{"location":"KB/Shrinkage/","title":"Shrinkage","text":""},{"location":"KB/Shrinkage/#shrinkage","title":"Shrinkage","text":"<ul> <li>A hyperparameter in gradient boosting that controls overfitting. Shrinkage in gradient boosting is analogous to learning rate in gradient descent. Shrinkage is a decimal value between 0.0 and 1.0. A lower shrinkage value reduces overfitting more than a larger shrinkage value.</li> </ul>"},{"location":"KB/ShuffleNet/","title":"ShuffleNet","text":""},{"location":"KB/ShuffleNet/#shufflenet","title":"ShuffleNet","text":"<ul> <li>Channel Shuffle</li> </ul> <pre><code>def channel_shuffle_new(x, groups):\n    return rearrange(x, 'b (c1 c2) h w -&gt; b (c2 c1) h w', c1=groups)\n</code></pre> <pre><code>class ShuffleUnitNew(nn.Module):\n    def __init__(self, in_channels, out_channels, groups=3, \n                 grouped_conv=True, combine='add'):\n        super().__init__()\n        first_1x1_groups = groups if grouped_conv else 1\n        bottleneck_channels = out_channels // 4\n        self.combine = combine\n        if combine == 'add':\n            # ShuffleUnit Figure 2b\n            self.left = Rearrange('...-&gt;...') # identity\n            depthwise_stride = 1\n        else:\n            # ShuffleUnit Figure 2c\n            self.left = nn.AvgPool2d(kernel_size=3, stride=2, padding=1)\n            depthwise_stride = 2\n            # ensure output of concat has the same channels as original output channels.\n            out_channels -= in_channels\n            assert out_channels &gt; 0\n\n        self.right = nn.Sequential(\n            # Use a 1x1 grouped or non-grouped convolution to reduce input channels\n            # to bottleneck channels, as in a ResNet bottleneck module.\n            conv1x1(in_channels, bottleneck_channels, groups=first_1x1_groups),\n            nn.BatchNorm2d(bottleneck_channels),\n            nn.ReLU(inplace=True),\n            # channel shuffle\n            Rearrange('b (c1 c2) h w -&gt; b (c2 c1) h w', c1=groups),\n            # 3x3 depthwise convolution followed by batch \n            conv3x3(bottleneck_channels, bottleneck_channels,\n                    stride=depthwise_stride, groups=bottleneck_channels),\n            nn.BatchNorm2d(bottleneck_channels),\n            # Use 1x1 grouped convolution to expand from \n            # bottleneck_channels to out_channels\n            conv1x1(bottleneck_channels, out_channels, groups=groups),\n            nn.BatchNorm2d(out_channels),\n        )        \n\n    def forward(self, x):\n        if self.combine == 'add':\n            combined = self.left(x) + self.right(x)\n        else:\n            combined = torch.cat([self.left(x), self.right(x)], dim=1)\n        return F.relu(combined, inplace=True)\n</code></pre>"},{"location":"KB/Shuffled-AUC/","title":"Shuffled-AUC","text":""},{"location":"KB/Shuffled-AUC/#shuffled-auc","title":"Shuffled-AUC","text":"<ul> <li>FPR is calculated based on the negatives which are determined by fixation points of all the other images in the dataset.</li> <li>\"AUC for the curve is calculated as sAUC.\"</li> </ul>"},{"location":"KB/Sigmoid/","title":"Sigmoid","text":""},{"location":"KB/Sigmoid/#sigmoid","title":"Sigmoid","text":"<ul> <li> \\[\\sigma(x) = \\frac{1}{1+exp(-x)}\\] </li> <li> \\[\\frac{d\\sigma}{dx}(x) = \\sigma(x)(1-\\sigma(x))\\] <ul> <li>max : 0.25</li> </ul> </li> <li>Logistic</li> <li>Xavier/Glorot init</li> <li>RNN : Hidden</li> <li>Bernoulli Distribution over a binary variable</li> <li></li> </ul>"},{"location":"KB/SimCLR/","title":"SimCLR","text":"<p>toc: true title: SimCLR</p> <p>categories: ['temp']</p>"},{"location":"KB/SimCLR/#simclr","title":"SimCLR","text":"<ul> <li>A Simple Framework for Contrastive Learning of Visual Representations<ul> <li>contrastive learning of visual representations</li> <li>without requiring specialized architectures or a memory bank</li> <li>composition of data augmentations plays a critical role in defining effective predictive tasks</li> <li>introducing a learnable nonlinear transformation between the representation and the contrastive loss substantially improves the quality of the learned representations</li> <li>contrastive learning benefits from larger batch sizes and more training steps compared to supervised learning</li> <li>use of a nonlinear head at the end of the network, and the loss function</li> <li>Res Net</li> <li>Two separate data augmentation operators are sampled from the same family of augmentations</li> <li>applied to each data example to obtain two correlated views</li> <li>After training is completed, they throw away the projection head and use the encoder for downstream tasks</li> <li>head \\(g(\\cdot)\\)</li> <li>encoder \\(f(\\cdot)\\)</li> <li>representation \\(h\\)</li> <li></li> </ul> </li> </ul>"},{"location":"KB/Simple%20Gradient%20Descent/","title":"Simple Gradient Descent","text":""},{"location":"KB/Simple%20Gradient%20Descent/#simple-gradient-descent","title":"Simple Gradient Descent","text":"<ul> <li> \\[\\theta = \\theta - \\eta \\cdot \\nabla_{\\theta} J(\\theta)\\] </li> <li>It starts with some coefficients, sees their cost, and searches for cost value lesser than what it is now.</li> <li>It moves towards the lower weight and updates the value of the coefficients.</li> <li>The process repeats until the local minimum is reached. A local minimum is a point beyond which it can not proceed.</li> </ul>"},{"location":"KB/Simulations%20Of%20language/","title":"Mirman Et Al","text":"<p>Basic RNN Architectures - Simple rnn performed like human learners     - sensitive to transitional prob and freq</p>"},{"location":"KB/Simulations%20Of%20language/#mirman-et-al","title":"Mirman Et Al","text":""},{"location":"KB/Single%20unit%20recording/","title":"Single unit recording","text":"<ul> <li>Authors predictions: units will either be on or off (no activation or nearly fully activated)</li> </ul>"},{"location":"KB/Single%20unit%20recording/#single-unit-recording","title":"Single Unit Recording","text":""},{"location":"KB/Singularity/","title":"Singularity","text":""},{"location":"KB/Singularity/#singularity","title":"Singularity","text":"<ul> <li>A configuration where two joints of the robot arm become co-axial (aligned along a common axis). In a singular configuration, smooth path following is normally impossible and the robot may lose control. The term originates from the behavior of the Jacobian matrix, which becomes singular (i.e., has no inverse) in these configurations.</li> </ul>"},{"location":"KB/Sketched%20Update/","title":"Sketched Update","text":""},{"location":"KB/Sketched%20Update/#sketched-update","title":"Sketched Update","text":"<ul> <li>Learn a full model update, then compress it before sending to the server.</li> <li>First computes the full Hit during local training without any constraints, and then approximates, or encodes, the update in a (lossy) compressed form before sending to the server. The server decodes the updates before doing the aggregation.</li> <li>Subsampling - Instead of sending Hit , each client only communicates matrix H\u0302it which is formed from a random subset of the (scaled) values of Hit.</li> <li>Quantize the weights -Improving the quantization by structured random rotations. The above 1-bit and multi-bit quantization approach work best when the scales are approximately equal across different dimensions.</li> <li>In the decoding phase, the server needs to perform the inverse rotation before aggregating all the updates.</li> </ul>"},{"location":"KB/Sketching/","title":"Sketching","text":""},{"location":"KB/Sketching/#sketching","title":"Sketching","text":"<ul> <li>In unsupervised machine learning, a category of algorithms that perform a preliminary similarity analysis on examples. Sketching algorithms use a locality-sensitive hash function</li> <li>to identify points that are likely to be similar, and then group them into buckets.</li> <li>Sketching decreases the computation required for similarity calculations on large datasets. Instead of calculating similarity for every single pair of examples in the dataset, we calculate similarity only for each pair of points within each bucket.</li> </ul>"},{"location":"KB/Skew%20Tilt/","title":"Skew Tilt","text":""},{"location":"KB/Skew%20Tilt/#skew-tilt","title":"Skew Tilt","text":"<ul> <li>The image is tilted forwards, backwards, left, or right a maximum of 22.5\u00b0. This gives the illusion that the image is being viewed from a different perspective than originally seen and creates realistic examples.</li> </ul>"},{"location":"KB/Skewed%20data/","title":"Skewed data","text":""},{"location":"KB/Skewed%20data/#skewed-data","title":"Skewed data","text":"<ul> <li>bias within the data acquisition process.</li> </ul>"},{"location":"KB/Skip%20Connection/","title":"Skip Connection","text":""},{"location":"KB/Skip%20Connection/#skip-connection","title":"Skip Connection","text":"<ul> <li> \\[x_i = F(x_{i-1}) + x_{i-1}\\] </li> <li>Effect Of Depth</li> <li>Previous layer gradient carried to next module untouched -&gt; loss surface is smoother</li> <li>Transfer #gradients to prevent Vanishingexploding gradients</li> <li>Learns the difference (residual) \\(\\(F(x) = H(x)-x\\)\\)</li> </ul>"},{"location":"KB/Skip%20Gram/","title":"Skip Gram","text":""},{"location":"KB/Skip%20Gram/#skip-gram","title":"Skip Gram","text":"<ul> <li>the distributed representation of the input word is used to predict the context.</li> <li>tries to predict the neighbors of a word</li> <li>works well with a small amount of the training data, represents well even rare words or phrases.</li> <li>Skip-gram rely on single words input, it is less sensitive to overfit frequent words, because even if frequent words are presented more times that rare words during training, they still appear individually</li> <li>tends to study different contexts separately</li> <li>needs more data to be trained contains more knowledge about the context.</li> <li>takes in pairs (word1, word2) generated by moving a window across text data, and trains a 1-hidden-layer neural network based on the synthetic task of given an input word, giving us a predicted probability distribution of nearby words to the input. </li> <li>A virtual one hot encoding of words goes through a \u2018projection layer\u2019 to the hidden layer; these projection weights are later interpreted as the word embeddings. </li> <li>So if the hidden layer has 300 neurons, this network will give us 300-dimensional word embeddings.</li> <li>also uses Negative Sampling</li> </ul>"},{"location":"KB/Slice%20Based%20Volume%20Rendering/","title":"Slice Based Volume Rendering","text":""},{"location":"KB/Slice%20Based%20Volume%20Rendering/#slice-based-volume-rendering","title":"Slice Based Volume Rendering","text":"<ul> <li>assign transparency inversely proportional to the number of slices</li> <li></li> </ul>"},{"location":"KB/Sliding%20Window%20Attention/","title":"Sliding Window Attention","text":""},{"location":"KB/Sliding%20Window%20Attention/#sliding-window-attention","title":"Sliding Window Attention","text":"<ul> <li>Given the importance of local context, the sliding window attention pattern employs a fixed-size window attention surrounding each token<ul> <li>multiple stacked layers of such windowed attention results in a large receptive field, where top layers have access to all input locations and have the capacity to build representations that incorporate information across the entire input</li> <li>But a model with typical multiple stacked transformers will have a large receptive field. This is analogous to CNNs where stacking layers of small kernels leads to high level features that are built from a large portion of the input (receptive field)</li> <li>Depending on the application, it might be helpful to use different values of \\(w\\) for each layer to balance between efficiency and model representation capacity.</li> </ul> </li> <li>Given a fixed window size \\(w\\), each token attends to \\(\\frac{1}{2}w\\) tokens on each size</li> <li>Complexity is \\(O(n \\times w)\\)<ul> <li>\\(w\\) should be small compared to \\(n\\)</li> </ul> </li> <li>With \\(l\\) layers, receptive field size is \\(l \\times w\\)</li> <li></li> </ul>"},{"location":"KB/SlimStampen/","title":"SlimStampen","text":""},{"location":"KB/SlimStampen/#slimstampen","title":"SlimStampen","text":"<ul> <li>Predicting University Students' Exam Performance Using a Model-Based Adaptive Fact-Learning System</li> </ul>"},{"location":"KB/SlimStampen/#literature","title":"Literature","text":"<ul> <li>Digital learning systems allow learners to track their progress and make study decisions informed by data1.</li> <li>For example, Duolingo, a language- learning tool, shows learners an overview of their mastery of each lesson in a dashboard (Figure 1(a) in Settles &amp; Meeder, 2016). Rosetta Stone, another language-learning tool, has a similar dashboard and includes a suggested next study activity (Ridgeway, Mozer, &amp; Bowles, 2017).</li> <li>Adaptive learning systems take this a step further by assuming control over some study choices that might otherwise be made by learners. Using an internal model of the learner that is informed by the learner\u2019s performance, such systems can adapt the learning experience in real time (VanLehn, 2006).</li> <li>The adaptation can include changing the difficulty of the problems presented to the learner, changing the amount of feedback that the learner receives, and changing the scheduling of repetitions within and between learning sessions</li> <li>What type and degree of adaptivity are most beneficial is an empirical question and depends on whether the adaptive system accurately traces the acquisition and forgetting of knowledge over time. If implemented well, adaptive learning systems can help students achieve more effective study behaviour by facilitating spaced repetition, active study, and other effective techniques.</li> </ul>"},{"location":"KB/SlimStampen/#slimstampen-a-model-based-adaptive-fact-learning-system-app","title":"SlimStampen: A Model-Based Adaptive Fact-Learning System App","text":"<ul> <li>Following correct answers, the next trial commenced after one second. For incorrect answers, feedback remained on the screen until the learner pressed the \u201cNext\u201d button at the bottom of the screen (see Figures 1b and 1d), making the feedback similar to the study trials.</li> </ul>"},{"location":"KB/SlimStampen/#scheduling-algorithm","title":"Scheduling Algorithm","text":"<ul> <li>extension of the adaptive item-learning model by Pavlik and Anderson (2005; 2008) and has been tested in laboratory settings (van Rijn, van Maanen, &amp; van Woudenberg, 2009; Sense, Behrens, Meijer, &amp; van Rijn, 2016; Sense, Meijer, &amp; van Rijn, 2018) but has not been deployed in a university course before.</li> <li>his model capitalizes on the spacing effect (see Dempster, 1988, for a review) within a single session by scheduling repetitions as far apart as possible, while also</li> <li>optimizing for the testing effect (see van den Broek et al., 2016, for a review) by repeating items soon enough that most responses are correct.</li> <li>The model represents every encountered item by a unique memory chunk, based on the ACT-R theory of declarative memory (Anderson, 2007).</li> <li>Each chunk has an activation\u2014a representation of the ease with which that item could be retrieved\u2014that receives a boost whenever an item is re-encoded and that decays over time</li> <li>The activation A of a chunk i at time t, given n previous encounters at t1,\u2026,tn seconds ago, is<ul> <li> \\[A_{i}(t) = ln(\\Sigma_{j=1}^{n}t_{j}^{-d_{i}(t)}\\] </li> <li> \\[d_{i}(t)=c \\ast e^{A_{i}(t_{n-1})}+\\alpha_{i} \\] </li> </ul> </li> <li>When a new trial commences, the model determines the activation of all items 15 seconds in the future, and if the item with the lowest activation has an activation value below a retrieval threshold, that item will be scheduled for presentation</li> <li>If all predicted activations are above the retrieval threshold, the model will introduce a new item</li> <li>y selecting items on the basis of their activation, items will be repeated with as much spacing as possible, while ensuring that, theoretically, a correct response can still be given.</li> <li>The decay of the activation (parameter d in Equation (1)) varies between items to account for differences in difficulty. The higher this decay, the faster a chunk\u2019s activation will decrease, causing it to be repeated sooner than an item with a lower decay.</li> <li>The decay d of a chunk i at time t depends on the activation of the chunk at the time of its previous encounter, as well as an offset that we label the rate of forgetting, \u03b1</li> <li>The model assumes that each item has a standard initial rate of forgetting when it is first presented. However, this value is updated during learning</li> <li>At each presentation, the model calculates an expected response time, E(RT ), based on the activation at the time of the presentation (e\u2212Ai , based on Equation (5) in Anderson, Bothell, Lebiere, &amp; Matessa, 1998) and an estimated reading time of the prompt (based on the number of characters in the prompt; see Section 2.2.1 in Nijboer, 2011, for details).</li> <li>The accuracy of the response and the mismatch between expected and observed response time are used to update the value of the rate-of-forgetting parameter.</li> <li>Using both accuracy and response time to update the model allows for adjustment of the parameter estimate after any response, not just after an incorrect response.</li> <li>A correct but slower-than-expected response signals that the memory trace has decayed further than assumed, meaning that the item\u2019s true rate of forgetting is higher than the current estimate.</li> <li>That is, when a learner arrives at the right answer but takes longer than anticipated, they likely struggled to recall the information</li> <li>Conversely, an incorrect or missing response suggests that the activation of the</li> <li>item\u2019s [memory trace] actually dropped below the retrieval threshold, which means that the true rate of forgetting should be higher because this item\u2019s activation was expected to be above the threshold (which was fixed at ACT-R.</li> <li>An unexpectedly fast correct response, on the other hand, indicates a stronger- than-expected memory trace and implies that the estimated rate of forgetting should be adjusted downward.</li> <li>Since interruption or distraction can cause disproportionately large response times, observed response times are capped before their mismatch with the expected response time is calculated.</li> <li>To update the rate of forgetting after each trial, the model uses a binary search in a small window around the previous value to identify the rate of forgetting that minimizes the mismatch between E(RT) and RT\u2032</li> </ul>"},{"location":"KB/SlimStampen/#usage-of-the-system","title":"Usage of the System","text":"<ul> <li>Most students exhibited strong \u201ccramming\u201d behaviour, with much higher SlimStampen usage in the days leading up to the exam: in both cohorts, we observed a sharp increase in activity starting around 10 days before the exam and peaking on the last day. As the exam neared, usage intensified throughout the day and extended into the night.</li> </ul>"},{"location":"KB/SlimStampen/#exam-performance","title":"Exam Performance","text":"<ul> <li>In both cohorts, students that used SlimStampen (92.6% of students) obtained higher grades than those that did not\u2014averaging 6.91 compared to 5.86, respectively</li> <li>a direct comparison of these groups is problematic due to selection effects and the imbalanced distributio</li> </ul>"},{"location":"KB/SlimStampen/#amount-of-practice","title":"Amount of Practice","text":"<ul> <li>number of study trials completed was positively correlated with the final grade completing more trials was associated with higher grades on the exam</li> <li>The number of unique days on which a learner engaged with the tool\u2014an index of spaced practice\u2014was also positively correlated with exam grades (r = 0.27, t(283) = 4.81, p &lt; 0.001)</li> <li>the two measures of engagement were strongly and positively correlated (r = 0.75, t(283) = 18.78, p &lt; 0.001).</li> </ul>"},{"location":"KB/SlimStampen/#studied-versus-non-studied-items","title":"Studied Versus Non-studied Items","text":"<ul> <li>We observed a large difference between exam questions that learners had used the system to study and questions that they had not3: students\u2019 accuracy was 83.7% on studied items but only 53.6% on unstudied items</li> <li>A mixed-effects logistic regression (with random intercepts for learners and items) confirmed that encountering an item during SlimStampen rehearsal considerably increased the chances of a correct answer on the exam (bstudied/not studied = 1.70, SE = 0.18, z = 9.06, p &lt; 0.001).</li> </ul>"},{"location":"KB/SlimStampen/#rates-of-forgetting-and-grades","title":"Rates of Forgetting and Grades","text":"<ul> <li>The rate of forgetting, which was initially estimated for each learner\u2013item combination, was converted into a learner-specific rate of forgetting by averaging over all studied items</li> <li>The negative correlation shows that a learner who was estimated to forget material more slowly also tended to obtain higher grades.</li> <li>In practice, a possible relationship between someone\u2019s rate of forgetting and eventual exam performance would be most useful if it could be detected ahead of time rather than on the day of the exam\u2014when it is too late to potentially help struggling students, for example</li> <li>This pattern could be driven by additional learners that start at the last minute and demonstrate poor learning performance and poor grades</li> </ul>"},{"location":"KB/SlimStampen/#predicting-performance-on-individual-exam-questions","title":"Predicting Performance on Individual Exam Questions","text":"<ul> <li>The results reported so far confirm that the expected patterns emerged in the aggregate: a learner\u2019s average rate of forgetting was strongly related to their average performance on the exam</li> <li>A step-wise backward elimination procedure was used to find the best model: starting with the full model, the term with the lowest absolute z-value was removed until the simpler model was no longer preferred on the basis of BIC and AIC (Gelman &amp; Hill, 2006).</li> <li>Additionally, the estimated rate of forgetting modulated the effect such that learner\u2013 item combinations with very low rates of forgetting have a higher chance of yielding a correct answer.</li> <li>The differences in rates of forgetting are especially pronounced at a low number of repetitions due to the non-linear mapping between the predictors and the predicted probability introduced by the logit function</li> </ul>"},{"location":"KB/SlimStampen/#predicting-performance-on-the-exam","title":"Predicting Performance on the Exam","text":"<ul> <li>We used lasso regression (Tibshirani, 1996) to predict grades using nine predictors: a student\u2019s accuracy during study, their cohort, their cumulative usage time, the number of days on which they used the system, the number of items they studied, the number of sessions they recorded, the number of trials they completed, their estimated rate of forgetting, and their median response time</li> <li>The advantage of lasso regression is that the shrinkage term handles multicollinearity between the predictors by shrinking their coefficients</li> <li>The shrinkage is achieved by imposing a cost function on the magnitude of the</li> <li>coefficients themselves: the best fit is achieved by the model that minimizes the OLS with the smallest coefficients. In fact, coefficients are shrunk entirely if they do not explain sufficient variance to justify inclusion in the model. In lasso regression, predictors must be normalized to ensure that the shrinkage term affects all predictors equally. A convenient consequence of normalized predictors is that their post-shrinkage</li> <li>coefficients directly indicate their importance: since all predictors are on the same scale, the most important predictor retains the largest (absolute) coefficient.</li> <li>250-fold cross-validation procedure</li> </ul>"},{"location":"KB/SlimStampen/#comparing-self-reported-and-recorded-study-times","title":"Comparing Self-Reported and Recorded Study Times","text":"<ul> <li>This means that students who used SlimStampen more did not necessarily self- report studying more overall. Thus, the positive association between more SlimStampen usage and higher grades was unlikely to be a consequence of higher motivation alone.</li> <li>This suggests, unsurprisingly, that general studiousness led to higher exam performance</li> <li>More interestingly, time spent studying with SlimStampen was time well spent, as the expected gain in grades associated with additional hours of study was 0.11 points, compared to only 0.03 points gained by an hour of unspecified study time.</li> </ul>"},{"location":"KB/SlimStampen/#discussion","title":"Discussion","text":"<ul> <li>Students\u2019 rates of forgetting, estimated by the system during use, were correlated with exam performance up to two weeks before the exam (Figure 2), even though &lt; 5% of the data were available at that point</li> <li>Furthermore, rate-of-forgetting estimates for individual facts were predictive of learners\u2019 performance on the associated exam questions, along with the number of times these facts were repeated during study</li> <li>One limitation of the sample was that we did not know what other study methods students may have used alongside the system. It is possible that the spike in activity in the days preceding the exam was caused by students verifying that they had retained the knowledge obtained through other study activities</li> </ul>"},{"location":"KB/SlimStampen/#implications","title":"Implications","text":"<ul> <li>controlling within-session study decisions through the adaptive fact-learning system, leaving other study decisions\u2014when to study, which chapter to study, how long to study, and whether to study with open response or multiple-choice questions\u2014to the learner</li> <li>students still made sub-optimal decisions about when to repeat a lesson that they had studied previously.</li> <li>Alternatively, the system could suggest the lesson that would yield the largest learning gain at the moment a student decides to start a session</li> </ul>"},{"location":"KB/SlimStampen/#pictures","title":"Pictures","text":""},{"location":"KB/Small%20World%20graphs/","title":"Small World graphs","text":""},{"location":"KB/Small%20World%20graphs/#small-world-graphs","title":"Small World Graphs","text":"<ul> <li>Any two nodes in the graph are connected via a smalll number of steps</li> </ul>"},{"location":"KB/Smart%20Augmentation/","title":"Smart Augmentation","text":""},{"location":"KB/Smart%20Augmentation/#smart-augmentation","title":"Smart Augmentation","text":"<ul> <li>utilizes a similar concept as the Neural Augmentation technique</li> <li>However, the combination of images is derived exclusively from the learned parameters of a prepended CNN, rather than using the Neural Style Transfer algorithm.</li> <li>another approach to meta-learning augmentations</li> <li>This is done by having two networks, Network-A and Network-B. Network-A is an augmentation network that takes in two or more input images and maps them into a new image or images to train Network-B. The change in the error rate in Network-B is then</li> <li>backpropagated to update Network-A.</li> <li>Additionally another loss function is incorporated into Network-A to ensure that its outputs are similar to others within the class. Network-A uses a series of convolutional layers to produce the augmented image</li> <li>The conceptual framework of Network-A can be expanded to use several Networks trained in parallel. Multiple Network-As could be very useful for learning class-specific augmentations via meta-learning</li> </ul>"},{"location":"KB/Smooth-Grad/","title":"Smooth-Grad","text":""},{"location":"KB/Smooth-Grad/#smooth-grad","title":"Smooth-Grad","text":"<ul> <li>@smilkovSmoothGradRemovingNoise2017</li> <li>reduces visual noise and, hence, improves visual explanations about how a DNN is making a classification decision. Comparing their work to several gradient-based sensitivity map methods such as LRP, [DeepLift], and Integrated Gradients (IG) [96], which estimate the global importance of each pixel and create saliency maps, showed that Smooth-Grad focuses on local sensitivity and calculates averaging maps with a smoothing effect made from several small perturbations of an input image. The effect is enhanced by further training with these noisy images and finally having an impact on the quality of sensitivity maps by sharpening them.</li> <li>a local, post hoc approach gave visual and textual justifications of the predictions with the help of two novel explanation datasets through crowd sourcing.</li> <li>involves adding random noise to the input and computing the attribution maps multiple times with the noisy inputs. </li> <li>The final attribution map is obtained by averaging the maps obtained from the noisy inputs. The idea behind this technique is that the noise added to the input image will cause the model to activate different features in the input, resulting in a more stable and interpretable attribution map.</li> </ul>"},{"location":"KB/Smooth-Grad/#technical-details","title":"Technical Details","text":"<ul> <li>Consider an image classification task where an input image \\(x\\) is to be classified as a single class from a set \\(C\\). For every class \\(c \\in C\\), the output class is represented as \\(class(x) = argmax_{c \\in C}S_{c}(x)\\). Using this \\(class\\), a sensitivity map \\(M_{c}(x)\\) can be generated by differentiating with respect to \\(x\\), \\(M_{c}(x) = \\frac{\\partial S_{c}}{\\partial x}\\) . \\(M_{c}\\), being a sensitivity map, thus represents the influential regions of the image used to make the prediction. Since these maps are noisy in nature, Smilkov et al. propose SmoothGrad, a modification of the previous method where instead of using \\(\\partial S_{c}\\), a smoothing is applied using a Gaussian kernel to \\(\\partial S_{c}\\). The authors also find that it is not possible to directly compute the smoothing due to high dimensionality, and thus approximate the calculation by averaging multiple maps computed in the neighborhood of \\(x\\) using random sampling. The final SmoothGrad equation then becomes \\(\\hat M_{c}(x) = \\frac{1}{n}\\Sigma_{1}^{n}M_{c}(x + \\mathcal{N}(0, \\sigma^{2}))\\), where \\(\\mathcal{N}(0, \\sigma^{2})\\) is the Gaussian noise and \\(\\sigma\\) is the standard deviation.</li> </ul>"},{"location":"KB/SmoothGrad%20Square/","title":"SmoothGrad Square","text":""},{"location":"KB/SmoothGrad%20Square/#smoothgrad-square","title":"SmoothGrad Square","text":"<ul> <li> smoothgrad squre</li> </ul>"},{"location":"KB/SmoothMix/","title":"SmoothMix","text":""},{"location":"KB/SmoothMix/#smoothmix","title":"SmoothMix","text":"<ul> <li>@leeSmoothMixSimpleEffective2020</li> <li>mask-based approach</li> <li>matching closely with the [Cutout] and CutMix techniques</li> <li>the mask has soft edges with gradually decreasing intensity</li> <li>the mixing strategy is the same</li> <li>The augmented image has mixed pixel values depending on the strength of the mask</li> <li> \\[\\lambda= \\frac{\\Sigma_{i=1}^{W}\\Sigma_{j=1}^{H}G_{ij}}{WH}\\] </li> <li>Gij is the pixel value of mask G, H is height, and W is width</li> <li>xnew = G.xa + (1 \u2212 G).xb</li> <li>ynew = \u03bb.ya + (1 \u2212 \u03bb).yb</li> </ul>"},{"location":"KB/Smoothness/","title":"Smoothness","text":""},{"location":"KB/Smoothness/#smoothness","title":"Smoothness","text":"<ul> <li>Every supervised machine learning method assumes that there's a set of functions that can transform inputs into outputs such that similar inputs are transformed into similar outputs. If an input X produces an output Y, then an input close to X would produce an output proportionally close to Y.</li> </ul>"},{"location":"KB/SnapMix/","title":"SnapMix","text":""},{"location":"KB/SnapMix/#snapmix","title":"SnapMix","text":"<ul> <li>@huangSnapMixSemanticallyProportional2021</li> <li>augments training images by ex- tracting and merging random image regions of dif- ferent sizes, where the region size is drawn through the beta distribution for both the images.</li> <li>Gen- erated image label is assigned based on semantic composition from normalized (sum to one) CAMs.</li> <li>However, the summation of label coefficients can exceed beyond one depending on the semantic composition of the output image.</li> </ul>"},{"location":"KB/Social%20Construction%20of%20XAI%2C%20do%20we%20need%20one%20definition%20to%20rule%20them%20all/","title":"Social Construction of XAI, do we need one definition to rule them all","text":""},{"location":"KB/Social%20Construction%20of%20XAI%2C%20do%20we%20need%20one%20definition%20to%20rule%20them%20all/#social-construction-of-xai-do-we-need-one-definition-to-rule-them-all","title":"Social Construction of XAI, Do We Need One Definition to Rule Them All","text":"<ul> <li>@ehsanSocialConstructionXAI2022</li> </ul>"},{"location":"KB/Social%20Construction%20of%20XAI%2C%20do%20we%20need%20one%20definition%20to%20rule%20them%20all/#abstract","title":"Abstract","text":"<ul> <li>In this paper, we argue why a singular definition of XAI is neither feasible nor desirable at this stage of XAI's development</li> <li>We view XAI through the lenses of Social Construction of Technology (SCOT) to explicate how diverse stakeholders (relevant social groups) have different interpretations (interpretative flexibility) that shape the meaning of XAI. Forcing a standardization (closure) on the pluralistic interpretations too early can stifle innovation and lead to premature conclusions.</li> </ul>"},{"location":"KB/Social%20Construction%20of%20XAI%2C%20do%20we%20need%20one%20definition%20to%20rule%20them%20all/#of-bicycles-explainable-ai","title":"Of Bicycles &amp; Explainable AI","text":"<ul> <li>As we reflect on the evolution of the bicycle, why and how did things evolve the way they did?</li> <li>We will address this question using three concepts from SCOT. First, we have relevant social groups\u2014stakeholders with skin in the game such as bikers, families of bikers, mechanics fixing bikes, etc. These are the ones who are involved in or affected by a technological development</li> <li>Different relevant social groups have their own interpretive flexibility\u2014 interpretations of what it means to be a bicycle.</li> <li>ifferent interpretive flexibilities can give rise to different types of bicycles such as mountain bikes, electric bikes, BMX bikes, etc</li> <li>Finally, we have the notion of closure\u2013 over time, some interpretations of the bicycle achieved stability while others withered out (e.g., equal sized wheels won out over differently-sized wheels</li> <li>Just like bicycles, XAI has its relevant social groups</li> <li>Let's consider two relevant social groups: the Natural Language Processing (NLP) and Computer Visions (CV) communitie</li> <li>Given each group has its own ways of knowing (epistemology), there is interpretive flexibility on how they operationalize the notion of explainability</li> <li>in NLP question-answering, explanations are often of the form of additional text that justifies the ground truth answer</li> <li>In CV, object recognition can consider saliency maps that show how visual features correlate to a predicted label</li> <li>This is to be expected because, unlike bicycles, we don't have 200+ years of development to reach clusters of closures yet.</li> <li>olving XAI challenges may require more than just \"opening the black-box\" [6]</li> <li>Human-centered XAI (HCXAI) advocates to tackle XAI problems through a sociotechnical view (vs. a purely technical one) [7]</li> <li>We need to consider who is opening the box just as much as the algorithmic mechanisms of opening it</li> <li>Whereas a lot of initial focus was on developers and data scientists as end-users of XAI systems, there is a growing recognition that we need to accommodate a diverse set of end-users, especially non-AI experts [10, 11]</li> </ul>"},{"location":"KB/Social%20Construction%20of%20XAI%2C%20do%20we%20need%20one%20definition%20to%20rule%20them%20all/#making-progress-in-xai","title":"Making Progress in XAI","text":"<ul> <li>XAI is pluralistic</li> <li>Given the different epistemic cultures co-existing in the space,we cannot expect monolithic conformity at this stage.</li> <li>Pluralism, however, does not mean that anything goes; in fact, it's the opposite\u2014we need to be precise in our articulation of what we mean by explainability when we communicate.</li> <li>Thus, instead of using the term at face value, whenever we write a paper, we should strive to justify how our conception of explainability satisfies some of the shared goals we have in the space.</li> <li>who is saying what, when, and why. To grasp the flavor of explainability in a given context, we need to pay attention to a relevant social group's interpretation of it and how that informs their operationalization.</li> <li>While the notion of XAI is in flux, we are fortunate to join the conversation at this stage. We have substantial agency in steering the discourse, a privilege we need to exercise responsibly.</li> </ul>"},{"location":"KB/Soft%20Attention/","title":"Soft Attention","text":""},{"location":"KB/Soft%20Attention/#soft-attention","title":"Soft Attention","text":"<ul> <li>For a simple Seq2Seq, all hidden state vectors \\(h_t\\) across timesteps are linearly combined</li> <li> \\[c_i = \\Sigma_{j=1}^T \\alpha_{ij} h_j\\] </li> <li> \\[a_{ij} = \\frac{exp(e_{ij})}{\\Sigma_{k=1}^T exp(e_{ij})}\\] </li> <li></li> </ul>"},{"location":"KB/Soft%20Parameter%20Sharing/","title":"Soft Parameter Sharing","text":""},{"location":"KB/Soft%20Parameter%20Sharing/#soft-parameter-sharing","title":"Soft Parameter Sharing","text":"<ul> <li>Constrain weights by adding terms to loss function<ul> <li> \\[||W_{A}-W_{B}||^{2} + ||W_{A}-W_{C}||^{2}\\] </li> </ul> </li> </ul>"},{"location":"KB/Softlimit%20Setting%20Function/","title":"Softlimit Setting Function","text":""},{"location":"KB/Softlimit%20Setting%20Function/#softlimit-setting-function","title":"Softlimit Setting Function","text":"<ul> <li>The Softlimit Setting Function is a function to set the axis travel limit range of the manipulator motion in software.</li> </ul>"},{"location":"KB/Softmax/","title":"Softmax","text":""},{"location":"KB/Softmax/#softmax","title":"Softmax","text":"<ul> <li>Output : probabilities</li> <li> \\[p = \\frac{1}{\\Sigma_{i = 1, .., n}e^{\\frac{\\alpha y_{i}}{T}}}(e^{\\frac{\\alpha y_{1}}{T}} , e^{\\frac{\\alpha y_{2}}{T}} , \u2026, e^{\\frac{\\alpha y_{n}}{T}})'\\] </li> <li>Softer argmax (0,1)</li> <li>Multinoulli</li> </ul>"},{"location":"KB/Softmax/#entropy","title":"Entropy","text":"<ul> <li>\\(\\alpha\\) determines entropy</li> <li>If it is 0, and Uniform Distribution and limit to infinity -&gt; binary vector which is 0 everywhere except at position i when y is maximal</li> </ul>"},{"location":"KB/Softmax/#temperature","title":"Temperature","text":"<ul> <li>Higher the T -&gt; Softer it the distribution. Aka less confident about distribution</li> <li>Lower -&gt; Harder. More confident</li> <li></li> </ul>"},{"location":"KB/Softplus/","title":"Softplus","text":""},{"location":"KB/Softplus/#softplus","title":"Softplus","text":"<ul> <li> \\[\\ln(1+e^x)\\] </li> </ul>"},{"location":"KB/Somatic/","title":"Somatic","text":""},{"location":"KB/Somatic/#somatic","title":"Somatic","text":"<ul> <li>Voluntary</li> <li>Skeletal movement</li> </ul>"},{"location":"KB/Somatosensory%20Cortex/","title":"Somatosensory Cortex","text":""},{"location":"KB/Somatosensory%20Cortex/#somatosensory-cortex","title":"Somatosensory Cortex","text":"<ul> <li>Located in the parietal lobe, this region of the brain processes touch, pressure, and pain information.</li> </ul>"},{"location":"KB/Sono-stimulation/","title":"Sono stimulation","text":""},{"location":"KB/Sono-stimulation/#sono-stimulation","title":"Sono-stimulation","text":"<ul> <li>The activation of neural networks using ultrasound.</li> </ul>"},{"location":"KB/Sonogenetics/","title":"Sonogenetics","text":""},{"location":"KB/Sonogenetics/#sonogenetics","title":"Sonogenetics","text":"<ul> <li>A novel investigative approach that turns genetically modified neurons on and off using ultrasonic waves.</li> </ul>"},{"location":"KB/Soundify/","title":"Soundify","text":""},{"location":"KB/Soundify/#soundify","title":"Soundify","text":"<ul> <li>In video editing, sound in half of the story</li> <li>for professional video editing, the problems come from finding suitable sounds, aligning sounds, video and tuning parameters</li> <li>matches sound efects to video - uses quality sound efects libraries and CLIP - Concretely, the system has three parts: classification, synchronization, and mix</li> <li>The classification matches efects to a video by classifying sound emitters within - To reduce the distinct sound emitters, the video is split based on absolute color histogram distances</li> <li>In the synchronization part, intervals are identified comparing efects label with each frame and pinpointing consecutive matches above a threshold</li> <li>In the mix part, efects are split into around one-second chunks - chunks are stitched via crossfades.</li> </ul>"},{"location":"KB/Sparse%20Dictionary%20Learning%20Loss/","title":"Sparse Dict Learning Loss","text":""},{"location":"KB/Sparse%20Dictionary%20Learning%20Loss/#sparse-dict-learning-loss","title":"Sparse Dict Learning Loss","text":"<ul> <li>$\\(L(X) = n^{-1}\\Sigma_i^n ||x_i - Dr_i ||^2 + \\lambda \\Sigma_i |r_i|\\)</li> <li>\\(\\lambda \\Sigma_i |r_i|\\) is Lasso/L1 Lp Regularization</li> <li>Predictions : \\(r = argmin_r ||x- Dr_i ||^2 + \\lambda \\Sigma_i |r_i|\\)</li> </ul>"},{"location":"KB/Sparse%20Encoder%20Indexes/","title":"Sparse Encoder Indexes","text":""},{"location":"KB/Sparse%20Encoder%20Indexes/#sparse-encoder-indexes","title":"Sparse Encoder Indexes","text":"<ul> <li>efficiently handle large-scale knowledge bases with diverse data formats and structures.</li> <li>For semantic search, one may compare different approaches of combining dense vector indexes and sparse encoder indexes to traditional keyword-based retrieval.</li> </ul>"},{"location":"KB/Sparse%20Evolutionary%20Training/","title":"Sparse Evolutionary Training","text":""},{"location":"KB/Sparse%20Evolutionary%20Training/#sparse-evolutionary-training","title":"Sparse Evolutionary Training","text":"<ul> <li>(Mocanu et al., 2018; Liu et al., 2021b)</li> <li>which randomly initializes the sparse connectivity between layers randomly and dynamically adjusts the sparse connectivity via a parameter prune-and-grow scheme during the course of training</li> <li>The parameter prune-and-grow scheme allows the model's sparse structure to gradually evolve, achieving better performance than naively training a static sparse network</li> </ul>"},{"location":"KB/Sparse%20Transformer/","title":"Sparse Transformer","text":""},{"location":"KB/Sparse%20Transformer/#sparse-transformer","title":"Sparse Transformer","text":"<ul> <li>paper</li> <li>Uses Strided Attention</li> </ul>"},{"location":"KB/Sparsity/","title":"Sparsity","text":""},{"location":"KB/Sparsity/#sparsity","title":"Sparsity","text":"<ul> <li>The number of elements set to zero (or null) in a vector or matrix divided by the total number of entries in that vector or matrix. For example, consider a 10x10 matrix in which 98 cells contain zero.</li> </ul>"},{"location":"KB/Spatial%20Context%20Structure/","title":"Spatial Context Structure","text":""},{"location":"KB/Spatial%20Context%20Structure/#spatial-context-structure","title":"Spatial Context Structure","text":"<ul> <li>based on the spatial relations among image patches </li> <li>image jigsaw puzzle </li> <li>context prediction </li> <li>geometric transformation recognition</li> </ul>"},{"location":"KB/Spatial%20Transformer/","title":"Spatial Transformer","text":""},{"location":"KB/Spatial%20Transformer/#spatial-transformer","title":"Spatial Transformer","text":"<ul> <li>Transformer</li> </ul> <pre><code>class SpacialTransformNew(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        # Spatial [Transformer|[transformer](./Transformer.md) localization-network\n        linear = nn.Linear(32, 3 * 2)\n        # Initialize the weights/bias with identity transformation\n        linear.weight.data.zero_()\n        linear.bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n\n        self.compute_theta = nn.Sequential(\n            nn.Conv2d(1, 8, kernel_size=7),\n            nn.MaxPool2d(2, stride=2),\n            nn.ReLU(True),\n            nn.Conv2d(8, 10, kernel_size=5),\n            nn.MaxPool2d(2, stride=2),\n            nn.ReLU(True),\n            Rearrange('b c h w -&gt; b (c h w)', h=3, w=3),\n            nn.Linear(10 * 3 * 3, 32),\n            nn.ReLU(True),\n            linear,\n            Rearrange('b (row col) -&gt; b row col', row=2, col=3),\n        )\n\n    # Spatial transformer network forward function\n    def stn(self, x):\n        grid = F.affine_grid(self.compute_theta(x), x.size())\n        return F.grid_sample(x, grid)\n</code></pre>"},{"location":"KB/Spatiotemporal%20Convolutional%20Neural%20Network/","title":"Spatiotemporal Convolutional Neural Network","text":""},{"location":"KB/Spatiotemporal%20Convolutional%20Neural%20Network/#spatiotemporal-convolutional-neural-network","title":"Spatiotemporal Convolutional Neural Network","text":"<ul> <li>3D convolution operation was first proposed in 3DNet [62] for human action recognition </li> <li>Compared to 2DConvNets which individually extract the spatial information of each frame and then fuse them together as video features, 3DConvNets are able to simultaneously extract both spatial and temporal features from multiple frames. </li> <li>VGG-like 11-layer 3DConvNet designed for human action recognition </li> <li>The network contains 8 convolutional layers, and 3 fully connected layers. All the kernels have the size of 3 x 3 x 3, the convolution stride is fixed to 1 pixel </li> <li>The input of C3D is 16 consecutive RGB frames where the appearance and temporal cues from 16-frame clips are extracted </li> <li>However, the paper of long-term temporal convolutions (LTC) [67] argues that, for # the long-lasting actions, 16 frames are insufficient to represent whole actions which last longer.</li> </ul>"},{"location":"KB/Speaker%20Verification/","title":"Speaker Verification","text":""},{"location":"KB/Speaker%20Verification/#speaker-verification","title":"Speaker Verification","text":"<ul> <li>Deep Neural Networks for Small Footprint Text-dependent Speaker Verification</li> <li>nvestigates the use of deep neural networks (DNNs) to train speaker embeddings for a small footprint text-dependent speaker verification task</li> <li>stacked filterbank features as input</li> <li>During speaker enrollment, the trained DNN is used to extract speaker-specific features/embeddings by averaging the activations from the last hidden layer (called deep-vectors or \u201cd-vectors\u201d for short), which is taken as the speaker model</li> <li>d-vector is extracted for each utterance and compared to the enrolled speaker model to make a verification decision by calculating the cosine distance between the test d-vector and the claimed speaker\u2019s d-vector, similar to the i-vector framework</li> <li>A verification decision is made by comparing the distance to a threshold</li> <li>DNN based speaker verification system achieves good performance compared to a popular i-vector system on a small footprint text-dependent speaker verification task</li> </ul>"},{"location":"KB/Speakers%20in%20the%20Wild/","title":"Speakers in the Wild","text":""},{"location":"KB/Speakers%20in%20the%20Wild/#speakers-in-the-wild","title":"Speakers in the Wild","text":""},{"location":"KB/SpecAugment/","title":"SpecAugment","text":""},{"location":"KB/SpecAugment/#specaugment","title":"SpecAugment","text":"<ul> <li>SpecAugment: a Simple Data Augmentation Method for Automatic Speech Recognition</li> <li>simple data augmentation method for speech recognition</li> <li>applied directly to the feature inputs of a neural network</li> <li>warping the features, masking blocks of frequency channels, and masking blocks of time steps</li> <li>apply SpecAugment on Listen, Attend and Spell (LAS) networks for end-to-end speech recognition tasks</li> <li>LibriSpeech</li> <li>Swichboard</li> <li>end-to-end LAS networks by augmenting the training set using simple handcrafted policies</li> <li>converts ASR from an over-fitting to an under-fitting problem, and they are able to gain performance by using bigger networks and training longer</li> </ul>"},{"location":"KB/Specificity/","title":"Specificity","text":""},{"location":"KB/Specificity/#specificity","title":"Specificity","text":"<ul> <li> \\[Specificity = \\frac{TN}{TN+FP}\\] </li> </ul>"},{"location":"KB/Spectrogram/","title":"Spectrogram","text":""},{"location":"KB/Spectrogram/#spectrogram","title":"Spectrogram","text":""},{"location":"KB/Speculative%20Execution/","title":"Speculative Execution","text":""},{"location":"KB/Speculative%20Execution/#speculative-execution","title":"Speculative Execution","text":"<ul> <li>Allow the execution of complete instructions or parts of instructions before being sure whether this execution is required</li> </ul>"},{"location":"KB/Speculum/","title":"Speculum","text":""},{"location":"KB/Speculum/#speculum","title":"Speculum","text":"<ul> <li>An instrument used when examining body orifices to help widen the opening</li> </ul>"},{"location":"KB/Speech%20Emotion%20Recognition/","title":"Speech Emotion Recognition","text":""},{"location":"KB/Speech%20Emotion%20Recognition/#speech-emotion-recognition","title":"Speech Emotion Recognition","text":"<ul> <li>GAN-based Data Generation for Speech Emotion Recognition</li> <li>form of speech emotion spectrograms</li> <li>used for training speech emotion recognition networks</li> <li>nvestigate the usage of GANs for capturing the data manifold when the data is eyes-off, i.e., where they can train networks using the data but cannot copy it from the clients</li> <li>CNN-based GAN with spectral normalization on both the generator and discriminator, both of which are pre-trained on large unlabeled speech corpora</li> <li>even after the data on the client is lost, their model can generate similar data that can be used for model bootstrapping in the future</li> </ul>"},{"location":"KB/Speech%20Recognition/","title":"Speech Recognition","text":""},{"location":"KB/Speech%20Recognition/#speech-recognition","title":"Speech Recognition","text":"<ul> <li>Recurrent Neural Network Based Language Model<ul> <li>50% reduction of Perplexity</li> <li>mixture of several Basic RNN Architectures</li> <li>Wall Street Journal task</li> <li>connectionist language models are superior to standard n gram techniques, except their high computational (training) complexity</li> <li>break the myth that language modeling is just about counting n-grams, and that the only reasonable way how to improve results is by acquiring new training dat</li> </ul> </li> <li>Towards End-To-End Speech Recognition with Recurrent Neural Networks<ul> <li>character-level speech recognition system that directly transcribes audio data with text using a recurrent neural network</li> <li>combination of the deep bidirectional LSTM recurrent neural network architecture and a modified Connectionist Temporal Classification (CTC) objective function</li> <li>word error rate</li> <li>Wall Street Journal task</li> </ul> </li> </ul>"},{"location":"KB/Speech%20Resynthesis/","title":"Speech Resynthesis","text":""},{"location":"KB/Speech%20Resynthesis/#speech-resynthesis","title":"Speech Resynthesis","text":"<ul> <li>Speech Resynthesis from Discrete Disentangled Self-Supervised Representations</li> <li>self-supervised discrete representations for the task of speech resynthesis</li> <li>separately extract low-bitrate representations for speech content, prosodic information, and speaker identity</li> <li>This allows to synthesize speech in a controllable manner</li> <li>evaluate the F0 reconstruction, speaker identification performance (for both resynthesis and voice conversion), recordings\u2019 intelligibility, and overall quality using subjective human evaluation</li> <li>ultra-lightweight speech codec</li> </ul>"},{"location":"KB/Spiking%20Networks/","title":"Spiking Networks","text":""},{"location":"KB/Spiking%20Networks/#spiking-networks","title":"Spiking Networks","text":"<ul> <li>Poisson Process</li> </ul>"},{"location":"KB/Spirometer/","title":"Spirometer","text":""},{"location":"KB/Spirometer/#spirometer","title":"Spirometer","text":"<ul> <li>A device that measures the amount of air breathed in and out by the lungs</li> </ul>"},{"location":"KB/Spline%20Motion%20Type/","title":"Spline Motion Type","text":""},{"location":"KB/Spline%20Motion%20Type/#spline-motion-type","title":"Spline Motion Type","text":"<ul> <li>A calculated path that the robot executesthat may be parabolic in shape. A spline motion may also accomplish a free form curve with mixtures of circular and parabolic shapes.</li> </ul>"},{"location":"KB/Spline/","title":"Spline","text":""},{"location":"KB/Spline/#spline","title":"Spline","text":"<ul> <li>A smooth, continuous function used to approximate a set of functions that are uniquely defined on a set of sub-intervals. The approximating function and the set of functions being approximated intersect at a sufficient number of points to insure a high degree of accuracy in the approximation. The purpose for the smooth function is to allow a robot manipulator to complete a task without jerky motion.</li> </ul>"},{"location":"KB/Square%20Integrable/","title":"Square Integrable","text":""},{"location":"KB/Square%20Integrable/#square-integrable","title":"Square Integrable","text":"<ul> <li>Real valued RV with PDF p is square integrable if the Uncentered Second moment is finite</li> <li>\\(\\(E[X^{2}] = \\int_\\mathbb{R} x^{2}p(x)dx\\)\\) is finite</li> </ul>"},{"location":"KB/Squared%20Error/","title":"Squared Error","text":""},{"location":"KB/Squared%20Error/#squared-error","title":"Squared Error","text":"<ul> <li> \\[(y- f(x))^2\\] </li> <li>Regression</li> </ul>"},{"location":"KB/Squared%20Hinge/","title":"Squared Hinge","text":""},{"location":"KB/Squared%20Hinge/#squared-hinge","title":"Squared Hinge","text":"<ul> <li>Hinge Loss</li> <li>problems involving yes/no (binary) decisions and when you\u2019re not interested in knowing how certain the classifier is about the classification</li> <li>Tanh for last layer</li> <li>maximum margin</li> </ul> \\[\\mathrm{sum}\\left( \\left( \\mathrm{max}\\left( 0, 1 - y \\cdot \u0177 \\right) \\right)^{2} \\right)\\]"},{"location":"KB/Stable%20Difusion/","title":"Stable Difusion","text":""},{"location":"KB/Stable%20Difusion/#stable-difusion","title":"Stable Difusion","text":"<ul> <li>latent-difusion model - The main diference of this model with respect to the other ones is the use of a latent difusion model and that it performs image modification as it can perform operations in its latent space</li> <li>Stable Difusion consists of two parts: the text encoder and the image generator - The image information creator works completely in the latent space</li> <li>This property makes it faster than previous difusion models that worked in a pixel space</li> </ul>"},{"location":"KB/Stack%20GAN/","title":"Stack GAN","text":""},{"location":"KB/Stack%20GAN/#stack-gan","title":"Stack GAN","text":"<ul> <li> <p>Text to Image synthesis</p> </li> <li>StackGAN decomposes the hard problem into more manageable sub-problems through a sketch-refinement process.</li> <li>The Stage-I GAN sketches the primitive shape and colors of the object based on the given text description, yielding Stage-I low-resolution images.</li> <li>The Stage-II GAN takes Stage-I results and text descriptions as inputs and generates high-resolution images with photo-realistic details. It is able to rectify defects in Stage-I results and add compelling details with the refinement process</li> <li>Multi Modal. Large no of ims that fit the given text</li> </ul>"},{"location":"KB/Stack%20GAN/#todo","title":"todo","text":""},{"location":"KB/Stack%20GAN/#architecture","title":"Architecture","text":"<ul> <li> <p>256\u00d7256 photo-realistic images conditioned on text descriptions. sketch-refinement process.</p> </li> <li>Conditioning Augmentation technique that encourages smoothness in the latent conditioning manifold.</li> </ul>"},{"location":"KB/Stack%20GAN/#introduction","title":"Introduction","text":"<ul> <li>Generating photo-realistic images from text is an important problem and has tremendous applications, including photo-editing, computer-aided design, etc</li> <li>very difficult to train GAN to generate high-resolution photo-realistic images from text descriptions</li> <li>Simply adding more upsampling layers in state-ofthe-art GAN models for generating high-resolution (e.g., 256\u00d7256) images generally results in training instability</li> <li>supports of natural image distribution and implied model distribution may not overlap in high dimensional pixel space</li> <li>more severe as the image resolution increases In analogy to how human painters draw</li> <li>By conditioning on the Stage-I result and the text again, Stage-II GAN learns to capture the text information that is omitted by Stage-I GAN and draws more details for the object.</li> </ul>"},{"location":"KB/Stack%20GAN/#conditioning-augmentation","title":"Conditioning Augmentation","text":"<ul> <li>Conditioning Augmentation technique to produce additional conditioning variables c\u02c6</li> <li>we randomly sample the latent variables c\u02c6 from an independent Gaussian distribution \\(\\mathcal{N}(\\mu(\\varphi_{t}), \\Sigma(\\varphi_{t}))\\), where the mean \\(\\mu(\\varphi_{t})\\) and diagonal covariance matrix \\(\\Sigma(\\varphi_{t})\\) are functions of the text embedding \\(\\varphi_{t}\\)</li> <li>The proposed Conditioning Augmentation yields more training pairs given a small number of imagetext pairs, and thus encourages robustness to small perturbations along the conditioning manifold</li> <li>regularization term to the objective of the generator during training \\(\\(D_{KL}(\\mathcal{N}(\\mu(\\varphi_{t}), \\Sigma(\\varphi_{t})) || \\mathcal{N}(0,I))\\)\\)</li> <li>KL Divergence between the standard Gaussian distribution and the conditioning Gaussian distribution</li> <li>The randomness introduced in the Conditioning Augmentation is beneficial for modeling text to image translation as the same sentence usually corresponds to objects with various poses and appearances.</li> </ul>"},{"location":"KB/Stack%20GAN/#stage-i-gan","title":"Stage-I GAN","text":"<ul> <li>\\(\\varphi_{t}\\) be the text embedding of the given description</li> <li>The Gaussian conditioning variables \\(\\hat c_{0}\\) for text embedding are sampled from N(\u03bc0(\u03c6t),\u01a90(\u03c6t)) to capture the meaning of \\(\\varphi_{t}\\) with variations</li> <li>Conditioned on c\u02c60 and random variable z, Stage-I GAN trains the discriminator D0 and the generator G0 by alternatively maximizing \\(\\mathcal{L}_{D_{0}}\\) in Eq. (3) and minimizing \\(\\mathcal{L}_{G_{0}}\\)</li> <li> \\[\\mathcal{L}_{D_{0}} = \\mathbb{E}_{(I_{0},t)\\sim p_{data}}[log D_{0}(I_{0}, \\varphi_{t})]+\\mathbb{E}_{z \\sim p_{z}, t \\sim p_{data}}[log(1- D_{0}(G_{0}(z , \\hat{c_{0}}, \\varphi_{t})))]\\] </li> <li> \\[\\mathcal{L}_{G_{0}}= \\mathbb{E}_{z \\sim p_{z}, t \\sim p_{data}}[log(1- D_{0}(G_{0}(z, \\hat{c_{0}}),\\varphi_{t}))] + \\lambda D_{KL}(\\mathcal{N}(\\mu_{0}(\\varphi_{t}), \\Sigma_{0}(\\varphi_{t}))|| \\mathcal{N}(0, I))\\] </li> <li>where the real image I0 and the text description t are from the true data distribution pdata</li> <li>z is a noise vector randomly sampled from a given distribution pz (Gaussian distribution in this paper</li> <li>\u03bb is a regularization parameter that balances the two terms</li> <li>\u03bb = 1 for all the exps.</li> <li>both \\(\\mu_{0}(\\varphi_{t})\\) and \\(\\Sigma_{0}(\\varphi_{t})\\) are learned jointly with the rest of the network.</li> <li>For the generator G0, to obtain text conditioning variable c\u02c60, the text embedding \u03c6t is first fed into a fully connected layer to generate \u03bc0 and \u03c30 (\u03c30 are the values in the diagonal of \u01a90) for the Gaussian distribution N(\u03bc0(\u03c6t),\u01a90(\u03c6t)</li> <li>\u02c60 are then sampled from the Gaussian distribution c\u02c6 = \u03bc +\u03c3 \u2299\u03b5</li> <li>trained by alternatively maximizing LD in Eq. (5) and minimizing LG in Eq. (6),</li> <li>concatenated with a Nz dimensional noise vector to generate a W0 \u00d7 H0 image by a series of up-sampling blocks</li> <li>the text embedding \u03c6t is first compressed to Nd dimensions using a fully-connected layer</li> <li>and then spatially replicated to form a Md \u00d7 Md \u00d7 Nd tensor.</li> <li>the image is fed through a series of down-sampling blocks until it has Md \u00d7 Md spatial dimension</li> <li>Then, the image filter map is concatenated along the channel dimension with the text tensor</li> <li>The resulting tensor is further fed to a 1\u00d71 convolutional layer to jointly learn features across the image and the text.</li> <li>Finally, a fullyconnected layer with one node is used to produce the decision score.</li> </ul>"},{"location":"KB/Stack%20GAN/#stage-ii-gan","title":"Stage-II GAN","text":"<ul> <li>Low-resolution images generated by Stage-I GAN usually lack vivid object parts and might contain shape distortions.</li> <li>is conditioned on low-resolution images and also the text embedding again to correct defects in Stage-I results</li> <li>The Stage-II GAN completes previously ignored text information to generate more photo-realistic details.</li> <li>Conditioning on the low-resolution result s0 = G0(z, c\u02c60) and Gaussian latent variables c\u02c6</li> <li>Different from the original GAN formulation, the random noise z is not used in this stage with the assumption that the randomness has already been preserved by s0</li> <li>Gaussian conditioning variables c\u02c6 used in this stage and c\u02c60 used in Stage-I GAN share the same pre-trained text encoder, generating the same</li> <li></li> <li>text embedding \u03c6t.</li> <li>StageI and Stage-II Conditioning Augmentation have different fully connected layers for generating different means and standard deviations</li> <li>In this way, Stage-II GAN learns to capture useful information in the text embedding that is omitted by Stage-I GAN.</li> </ul>"},{"location":"KB/Stack%20GAN/#model-architecture","title":"Model Architecture.","text":"<ul> <li>Stage-II generator as an encoder-decoder network with residual blocks</li> <li>text embedding \u03c6t is used to generate the Ng dimensional text conditioning vector c\u02c6</li> <li>spatially replicated to form a Mg \u00d7Mg \u00d7Ng tensor</li> <li>Stage-I result s0 generated by Stage-I GAN is fed into several downsampling blocks (i.e., encoder) until it has a spatial size of Mg \u00d7 Mg</li> <li>The image features and the text features are concatenated along the channel dimension</li> <li>The encoded image features coupled with text features are fed into several residual blocks, which are designed to learn multi-modal representations across image and text feature</li> <li> <p>series of up-sampling layers</p> </li> <li> <p>are used to generate a W \u21e5H high-resolution</p> </li> <li>Such a generator is able to help rectify defects in the input image while add</li> <li>more details to generate the realistic high-resolution image.</li> <li>For the discriminator, its structure is similar to that of Stage-I discriminator with only extra down-sampling blocks since the image size is larger in this stage</li> <li>To explicitly enforce GAN to learn better alignment between the image and the conditioning text, rather than using the vanilla discriminator, we adopt the matching-aware discriminator</li> <li>During training, the discriminator takes real images and their corresponding text descriptions as positive sample pairs, whereas negative sample pairs consist of two groups</li> <li>Implementation details</li> <li>up-sampling blocks consist of the nearest-neighbor upsampling followed by a 3\u21e53 stride 1 convolution</li> <li></li> <li>Batch normalization [11] and ReLU activation are applied after every convolution except the last one</li> <li>The residual blocks consist of 3\u21e53 stride 1 convolutions, Batch normalization and ReLU. Two residual blocks are used in 128\u21e5128 StackGAN models while four are used in 256\u21e5256 models. The down-sampling blocks consist of 4\u21e54 stride 2 convolutions, Batch normalization and LeakyReLU, except that the first one does not have Batch normalization.</li> <li>Bydefault,Ng =128,Nz =100,Mg =16,Md =4, Nd = 128, W0 = H0 = 64 and W = H = 256</li> <li>For training, we first iteratively train D0 and G0 of Stage-I GAN for 600 epochs by fixing Stage-II GAN</li> <li>Then we iteratively train D and G of Stage-II GAN for another 600 epochs by fixing Stage-I GAN.</li> <li>All networks are trained using ADAM solver with batch size 64 and an initial learning rate of 0.0002. The learning rate is decayed to 1/2 of its previous value every 100 epochs.</li> </ul>"},{"location":"KB/Stack%20GAN/#datasets-and-evaluation-metrics-cub","title":"Datasets and evaluation metrics CUB","text":"<ul> <li>Oxford-102</li> <li>MS COCO</li> <li>Evaluation metrics</li> <li>inception score</li> <li>I = exp(ExDKL(p(y|x) || p(y))),</li> <li>where x denotes one generated sample, and y is the label predicted by the Inception model</li> <li>he intuition behind this metric is that good models should generate diverse but meaningful images.</li> <li>Therefore, the KL divergence between the marginal distribution p(y) and the conditional distribution p(y|x) should be larg</li> </ul>"},{"location":"KB/Stack%20GAN/#conclusions","title":"Conclusions","text":"<ul> <li>The proposed method decomposes the text-to-image synthesis to a novel sketch-refinement process.</li> <li></li> <li>Stage-I GAN sketches the object following basic color and shape constraints from given text descriptions. Stage-II GAN corrects the defects in Stage-I results and adds more details, yielding higher resolution images with better image quality</li> <li>Compared to existing text-to-image generative models, our method generates higher resolution images (e.g., 256\u21e5256) with more photo-realistic details and diversity. *</li> </ul>"},{"location":"KB/Stacking%20RNN/","title":"Stacking RNN","text":""},{"location":"KB/Stacking%20RNN/#stacking-rnn","title":"Stacking RNN","text":"<ul> <li>Deeper</li> <li>Each level -&gt; output is seq of features that is input at next set of Layers in the hierarchy</li> <li></li> </ul>"},{"location":"KB/Staged%20Training/","title":"Staged Training","text":""},{"location":"KB/Staged%20Training/#staged-training","title":"Staged Training","text":"<ul> <li>A tactic of training a model in a sequence of discrete stages. The goal can be either to speed up the training process, or to achieve better model quality.</li> </ul>"},{"location":"KB/Standard%20Deviation/","title":"Standard Deviation","text":"<p>toc: true title: Standard Deviation</p> <p>categories: ['temp']</p>"},{"location":"KB/Standard%20Deviation/#standard-deviation","title":"Standard Deviation","text":"<ul> <li>measure of dispersement</li> <li>how much your data is spread out around the mean</li> <li>Normal Distribution</li> <li> \\[std = \\sqrt{\\frac{\\Sigma(x-\\bar x)^{2}}{n-1}}\\] </li> </ul>"},{"location":"KB/Stanford%20Dogs/","title":"Stanford Dogs","text":""},{"location":"KB/Stanford%20Dogs/#stanford-dogs","title":"Stanford Dogs","text":"<ul> <li>@khoslaNovelDatasetFineGrained</li> <li>This dataset contains images of 120 breeds of dogs, with a total of 20,580 images.</li> </ul>"},{"location":"KB/StarGAN%20v2/","title":"StarGAN v2","text":""},{"location":"KB/StarGAN%20v2/#stargan-v2","title":"StarGAN V2","text":"<ul> <li>generate diverse images across multiple domains </li> <li>define the domain and style of images as visually distinct category groups and the specific appearance of each image, respectively</li> </ul>"},{"location":"KB/StarGAN/","title":"StarGAN","text":""},{"location":"KB/StarGAN/#stargan","title":"StarGAN","text":"<ul> <li>improve the scalability and robustness in handling more than two domains </li> <li>builds only one model to perform image-to-image translation among multiply domains </li> <li>In the generation phase, we just need to provide the generator with the source image and an attribute label which indicates the target domain </li> <li>takes the domain label as an additional input and learns a deterministic mapping per each domain, which may result in the same output per each domain given an input image</li> </ul>"},{"location":"KB/Static%20Friction/","title":"Static Friction","text":""},{"location":"KB/Static%20Friction/#static-friction","title":"Static Friction","text":"<ul> <li> \\[F_{s} \\leq \\mu _{s}F_{N}\\] </li> <li>\\(F_{s}\\) is static friction</li> <li>\\(F_{N}\\) is normal force</li> <li>\\(\\mu _s\\) is coefficient of friction</li> </ul>"},{"location":"KB/Static%20Graph%20Execution/","title":"Static Graph Execution","text":""},{"location":"KB/Static%20Graph%20Execution/#static-graph-execution","title":"Static Graph Execution","text":"<ul> <li>Computational Graph is first built then is executed</li> <li>less readable code and more difficult to debug</li> <li>better performance</li> <li>once compiled the graph architecture is static</li> </ul>"},{"location":"KB/Stationarity/","title":"Stationarity","text":""},{"location":"KB/Stationarity/#stationarity","title":"Stationarity","text":"<ul> <li>A property of data in a dataset, in which the data distribution stays constant across one or more dimensions. Most commonly, that dimension is time, meaning that data exhibiting stationarity doesn't change over time. For example, data that exhibits stationarity doesn't change from September to December.</li> </ul>"},{"location":"KB/Statistical%20Word%20Segmentation/","title":"Statistical Word Segmentation","text":""},{"location":"KB/Statistical%20Word%20Segmentation/#statistical-word-segmentation","title":"Statistical Word Segmentation","text":"<ul> <li>use mutual information between characters from a corpus</li> </ul>"},{"location":"KB/Stem%20Cells/","title":"Stem Cells","text":""},{"location":"KB/Stem%20Cells/#stem-cells","title":"Stem Cells","text":"<ul> <li>Cells that have the potential to differentiate, to develop into many different specific cell types with specialized functions.</li> </ul>"},{"location":"KB/Steve/","title":"Steve","text":""},{"location":"KB/Steve/#steve","title":"Steve","text":"<ul> <li>Outer loop: Steve is a tutoring system that teaches hierarchical, multi-step procedures, such as how to start a large air compressor</li> <li>take Inner loop: Students steps by manipulating graphical widgets, such as clicking on a valve icon to open it or on a dipstick to check the oil level</li> <li>Steve can give immediate feedback</li> <li>Steve can also execute a step for the student. In fact, it can demonstrate the whole procedure for a student, explaining each step as it goes.</li> <li>Step analysis: Steve interprets the student's step by matching it to a set of anticipated steps. In particular, after each student step, Steve computes all possible correct next steps (usually there is just one).</li> <li>Notice that there is a one-to-one relationship between the step, the Learning Event and the Knowledge Component. This is a major contributor to the simplicity of Steve's analysis.</li> <li>Step generation: The student's most recent correct step is, by definition, part of the procedure being taught</li> <li>Steve uses immediate feedback to block incorrect steps, so Steve always knows where in the procedure the student is.</li> <li>When it needs to give hints on what to do next, it merely picks the next step. If there are multiple steps that could follow the student's most recent correct step, then Steve lists them and lets the student choose.</li> </ul>"},{"location":"KB/Stochastic%20ensemble%20learning/","title":"Stoch Ensemble Learning","text":""},{"location":"KB/Stochastic%20ensemble%20learning/#stoch-ensemble-learning","title":"Stoch Ensemble Learning","text":"<ul> <li>Stochastic algo repeatedly executed with random seeds</li> <li>Stronger the randomness -&gt; more members included -&gt; stronger reg</li> </ul>"},{"location":"KB/Stochastic%20ensemble%20learning/#maybe-related-to","title":"Maybe related to","text":"<ul> <li>Ensemble Distillation</li> <li>Ensemble of Shape Functions</li> </ul>"},{"location":"KB/Stratified%20Random%20Sampling/","title":"Stratified Random Sampling","text":""},{"location":"KB/Stratified%20Random%20Sampling/#stratified-random-sampling","title":"Stratified Random Sampling","text":"<ul> <li>Divides the population into relatively homogeneous groups (strata) and samples each stratum at random</li> </ul>"},{"location":"KB/Stream%20Ribbons/","title":"Stream Ribbons","text":""},{"location":"KB/Stream%20Ribbons/#stream-ribbons","title":"Stream Ribbons","text":""},{"location":"KB/Stream%20Surfaces/","title":"Stream Surfaces","text":""},{"location":"KB/Stream%20Surfaces/#stream-surfaces","title":"Stream Surfaces","text":""},{"location":"KB/Streamline%20Stopping%20Criterion/","title":"Streamline Stopping Criterion","text":""},{"location":"KB/Streamline%20Stopping%20Criterion/#streamline-stopping-criterion","title":"Streamline Stopping Criterion","text":"<ul> <li>distance to neighboring streamline too small</li> <li>streamline leaves domain  </li> <li>after maximum number of integration steps</li> </ul>"},{"location":"KB/Streamlines/","title":"Streamlines","text":""},{"location":"KB/Streamlines/#streamlines","title":"Streamlines","text":"<ul> <li>Streamline Stopping Criterion</li> </ul>"},{"location":"KB/Striatum/","title":"Striatum","text":""},{"location":"KB/Striatum/#striatum","title":"Striatum","text":"<ul> <li>A small group of subcortical structures, including the caudate nucleus, putamen, and nucleus accumbens, located in the midbrain. These regions are implicated in both movement and reward-related behaviors</li> </ul>"},{"location":"KB/Strided%20Attention/","title":"Strided Attention","text":""},{"location":"KB/Strided%20Attention/#strided-attention","title":"Strided Attention","text":"<ul> <li>paper</li> <li>Sparse factorizations of the attention matrix</li> <li>Reduce to \\(O(n\\sqrt{n})\\)</li> <li>Recompute attention matrices to save memory</li> <li>Fast attention kernels</li> <li>Works nicely for images, music etc with a periodic structure</li> <li>Otherwise with the strided pattern , the spatial coordinates do not correlate with the positions the elements might be more relevant in the future</li> <li></li> </ul>"},{"location":"KB/Strided/","title":"Strided","text":""},{"location":"KB/Strided/#strided","title":"Strided","text":"<ul> <li>Normally S = 1</li> <li>S&gt;1 -&gt; Downsampling</li> <li>Dilated</li> <li>Spaces in the filter kernel</li> <li>D = 1 : normal Conv aka D-1 spaces</li> <li>Effective Filter size : \\(\\(\\hat F = F + (F-1)(D-1)\\)\\)</li> <li></li> </ul>"},{"location":"KB/Strip%20Mining/","title":"Strip Mining","text":""},{"location":"KB/Strip%20Mining/#strip-mining","title":"Strip Mining","text":"<ul> <li>Generates code to allow vector operands whose size is less than or greater than size of vector registers</li> </ul>"},{"location":"KB/Stroke/","title":"Stroke","text":""},{"location":"KB/Stroke/#stroke","title":"Stroke","text":"<ul> <li>A neurological event that occurs when the blood supply to the brain is blocked, depriving the tissue of oxygen, or when there is a bleed into the brain due to the rupturing of an artery.</li> </ul>"},{"location":"KB/Stroop%20Task/","title":"Stroop Task","text":"<p>toc: true title: Stroop Task</p> <p>categories: ['temp']</p>"},{"location":"KB/Stroop%20Task/#stroop-task","title":"Stroop Task","text":"<ul> <li>Verbal<ul> <li>The Stroop phenomenon demonstrates that it is difficult to name the ink color of a color word if there is a mismatch between ink color and word. For example, the word GREEN printed in red ink</li> </ul> </li> <li>Non Verbal<ul> <li>A series of white arrows pointing either left or right was displayed against a black background either on the left or right side of a centered fixation cross. Half of the stimuli were pointing in the same direction as their position on the screen</li> </ul> </li> </ul>"},{"location":"KB/Structural%20Risk%20Minimization/","title":"Structural Risk Minimization","text":""},{"location":"KB/Structural%20Risk%20Minimization/#structural-risk-minimization","title":"Structural Risk Minimization","text":"<ul> <li>An algorithm that balances two goals<ul> <li>The desire to build the most predictive model (for example, lowest loss).</li> <li>The desire to keep the model as simple as possible (for example, strong regularization).</li> <li>or example, a function that minimizes loss+regularization on the training set is a structural risk minimization algorithm.</li> </ul> </li> </ul>"},{"location":"KB/Structural%20Similarity%20Index/","title":"Structural Similarity Index","text":""},{"location":"KB/Structural%20Similarity%20Index/#structural-similarity-index","title":"Structural Similarity Index","text":"<ul> <li>method for predicting the perceived quality of digital television and cinematic pictures, as well as other kinds of digital images and videos. SSIM is used for measuring the similarity between two images</li> <li> \\[\\hbox{SSIM}(x,y) = \\frac{(2\\mu_x\\mu_y + c_1)(2\\sigma_{xy} + c_2)}{(\\mu_x^2 + \\mu_y^2 + c_1)(\\sigma_x^2 + \\sigma_y^2 + c_2)}\\] </li> <li>\\(\\mu_x\\) the pixel sample mean of \\(x\\);</li> <li>\\(\\mu_y\\) the pixel sample mean of \\(y\\);</li> <li>\\(\\sigma_x^2\\) the variance of \\(x\\);</li> <li>\\(\\sigma_y^2\\) the variance of \\(y\\);</li> <li>\\(\\sigma_{xy}\\) the covariance of \\(x\\) and \\(y\\);</li> <li>\\(c_1 = (k_1L)^2\\), \\(c_2 = (k_2L)^2\\) two variables to stabilize the division with weak denominator;</li> <li>\\(L\\) the dynamic range of the pixel-values (typically this is \\(2^{\\#bits\\ per\\ pixel}-1\\));</li> <li>\\(k_1 = 0.01\\) and \\(k_2 = 0.03\\) by default.</li> </ul>"},{"location":"KB/Structure%20Based%20Pruning/","title":"Structure Based Pruning","text":""},{"location":"KB/Structure%20Based%20Pruning/#structure-based-pruning","title":"Structure Based Pruning","text":"<ul> <li>Regarding structural choices, some authors choose to prune individual parameters which produces a sparse network (lots of 0s). This might not be very ideal for storing efficiently.</li> <li>Some others consider methods where they group certain parameters and remove them as groups. This is more optimized.</li> </ul>"},{"location":"KB/Structured%20Update/","title":"Structured Update","text":""},{"location":"KB/Structured%20Update/#structured-update","title":"Structured Update","text":"<ul> <li>Directly learn an update from a restricted space that can be parametrized using a smaller number of variables.</li> <li>We train directly the updates of this structure</li> <li>Random mask. We restrict the update Hit to be a sparse matrix, following a pre-defined random sparsity pattern</li> </ul>"},{"location":"KB/Style%20GAN/","title":"Style GAN","text":""},{"location":"KB/Style%20GAN/#style-gan","title":"Style GAN","text":"<ul> <li>builds the picture layer after layer, where the layers get bigger and more accurate</li> <li>For example, the first layer is 4 by 4 pixels, the second 8 by 8, and so on</li> <li>every new layer can benefit from the less granular results of the previous ones</li> <li>better separate the generator and the discriminator, which ensures less dependence of the generator on the training set</li> <li>his allows one to, for example, reduce discrimination in the generated pictures</li> </ul>"},{"location":"KB/Subgenual%20Cortex/","title":"Subgenual Cortex","text":""},{"location":"KB/Subgenual%20Cortex/#subgenual-cortex","title":"Subgenual Cortex","text":"<ul> <li>The region in the back of the frontal lobes, found below the corpus callosum, which has been implicated in mood states.</li> </ul>"},{"location":"KB/Subject%20relative/","title":"Subject relative","text":""},{"location":"KB/Subject%20relative/#subject-relative","title":"Subject Relative","text":"<ul> <li>The judge that ignored the doctor watched the movie about Colombian drug dealers</li> <li>Object relative The judge that the doctor ignored watched the movie about Colombian drug dealers.</li> <li>Subjects with higher working memory were significantly better at interpreting object relatives than subjects with lower working memory</li> </ul>"},{"location":"KB/Subject-verb%20agreement/","title":"Subject-verb agreement","text":""},{"location":"KB/Subject-verb%20agreement/#subject-verb-agreement","title":"Subject-verb Agreement","text":"<ul> <li>John almost always reads the course papers before the lecture. I almost always forget to buy cat food.</li> <li>Relations with inflectional morphemes</li> <li>La femme est belle. L'homme est beau.</li> </ul>"},{"location":"KB/Substantia%20Nigra/","title":"Substantia Nigra","text":""},{"location":"KB/Substantia%20Nigra/#substantia-nigra","title":"Substantia Nigra","text":"<ul> <li>This small region in the midbrain is part of the brain\u2019s reward system. In Parkinson\u2019s disease, the dopamine neurons in this region die off, leading to the disorder\u2019s movement-related and cognitive symptoms.</li> </ul>"},{"location":"KB/Subthalamic%20Nucleus/","title":"Subthalamic Nucleus","text":""},{"location":"KB/Subthalamic%20Nucleus/#subthalamic-nucleus","title":"Subthalamic Nucleus","text":"<ul> <li>A small brain structure, located in the basal ganglia, that plays an important role in coordinating movement. It is the most common target for neuromodulation techniques, like deep brain stimulation, to help diminish the symptoms of Parkinson\u2019s disease.</li> </ul>"},{"location":"KB/Sufficiency/","title":"Sufficiency","text":""},{"location":"KB/Sufficiency/#sufficiency","title":"Sufficiency","text":"<ul> <li>the Positive Predictive Value is the same for all subgroups within the sensitive feature. This criteria is also known as Predictive Rate Parity.</li> </ul>"},{"location":"KB/Suffix/","title":"Suffix","text":""},{"location":"KB/Suffix/#suffix","title":"Suffix","text":"<ul> <li>follow the stem: eat / eats</li> </ul>"},{"location":"KB/Sugar%20Factory%20Task/","title":"Sugar Factory Task","text":""},{"location":"KB/Sugar%20Factory%20Task/#sugar-factory-task","title":"Sugar Factory Task","text":"<ul> <li>Berry and Broadbent ; Wallach</li> <li>Set no of workers per day</li> <li> \\[P_{t}=2W_{t}-P_{t-1}+ RandomFactor(-1/0/1)\\] <ul> <li>P: Production value</li> <li>W : No of workers</li> </ul> </li> </ul>"},{"location":"KB/Sulcus/","title":"Sulcus","text":""},{"location":"KB/Sulcus/#sulcus","title":"Sulcus","text":"<ul> <li>A shallower groove on the brain\u2019s cerebrum (deeper grooves are called fissures).</li> </ul>"},{"location":"KB/Summit/","title":"Summit","text":""},{"location":"KB/Summit/#summit","title":"Summit","text":"<ul> <li>@hohmanSummitScalingDeep2019</li> <li>combines two scalable tools: (1) activation aggregation discovers important neurons; (2) neuron-influenced aggregation identifies relationships among such neurons. An attribution graph that reveals and summarizes crucial neuron associations and substructures that contribute to a model's outcomes is created. Summit combines famous methods such as computing synthetic prototypes of features and showing examples from the dataset that maximize special neurons of different layers. Deeper in the graph, it is examined how the low-level features combine to create high-level features. Novel as well is that it exploits neural networks with activation atlases [63]</li> <li>This method uses feature inversion to visualize millions of activations from an image classification network to create an explorable activation atlas of features the network has learned. Their approach is able to reveal visual abstractions within a model and even high-level misunderstandings in a model that can be exploited. Activation atlases are a novel way to peer into convolutional vision networks and represents a global, hierarchical, and human-interpretable overview of concepts within the hidden layers.</li> <li>To quantify how much a layer influences the next, the authors aggregate the influences by creating a tensor \\(I^{l}\\) for all the layers of the network (\\(l\\)). How important channel \\(i\\) of the layer \\(l-1\\) is determined by the aggregate tensor \\(I^{l}_{cij}\\) where \\(j\\) represents the output channel and \\(c\\) is the class of the image. Considering the \\(j^{th}\\) kernel of the layer \\(K^{(j)} \\in \\mathbb{R}^{H \\times W \\times C_{l-1}}\\), a single channel \\(Y\\) can be represented using the 3D convolution operation by \\(Y_{:,:,j}= X \\ast K^{(j)}\\). This is equivalent to it's representation by the 2D convolution \\(Y_{:,:,j}= \\Sigma_{i=1}^{C_{l-1}} X_{:,:,i} \\ast K^{(j)}_{:,:,i}\\). </li> <li>\\(X_{:,:,i} \\ast K^{(j)}_{:,:,i}\\) is the contribution of the current channel from the previous layer and the maximum of this value is used to generate the influence map.</li> </ul>"},{"location":"KB/Super%20Resolution/","title":"Super Resolution","text":""},{"location":"KB/Super%20Resolution/#super-resolution","title":"Super Resolution","text":"<pre><code>def SuperResolutionNetNew(upscale_factor):\n    return nn.Sequential(\n        nn.Conv2d(1, 64, kernel_size=5, padding=2),\n        nn.ReLU(inplace=True),\n        nn.Conv2d(64, 64, kernel_size=3, padding=1),\n        nn.ReLU(inplace=True),\n        nn.Conv2d(64, 32, kernel_size=3, padding=1),\n        nn.ReLU(inplace=True),\n        nn.Conv2d(32, upscale_factor ** 2, kernel_size=3, padding=1),\n        Rearrange('b (h2 w2) h w -&gt; b (h h2) (w w2)', h2=upscale_factor, w2=upscale_factor),\n    )\n</code></pre>"},{"location":"KB/SuperQuadrics/","title":"SuperQuadrics","text":""},{"location":"KB/SuperQuadrics/#superquadrics","title":"SuperQuadrics","text":""},{"location":"KB/SuperScalar/","title":"SuperScalar","text":""},{"location":"KB/SuperScalar/#superscalar","title":"SuperScalar","text":"<ul> <li>A superscalar CPU architecture implements Instruction level programming inside a single processor which allows faster CPU throughput at the same clock rate.</li> <li>A superscalar processor executes more than one instruction during a clock cycle</li> <li>Simultaneously dispatches multiple instructions to multiple redundant functional units built inside the processor.</li> </ul>"},{"location":"KB/Superposition%20Catastrophe/","title":"Superposition Catastrophe","text":""},{"location":"KB/Superposition%20Catastrophe/#superposition-catastrophe","title":"Superposition Catastrophe","text":"<ul> <li>Bowers et al. (2014)</li> <li>Common claim of connnectionist models: they learn the best representations for a given task</li> <li>Learned representations are emergent, not stipulated</li> <li>If a PDP model learns localist codes when coding for multiple things at the same time, strongly suggests that the superposition problem pressures models to learn selective (e.g. localist) coding.</li> <li>Recurrent network</li> <li>Simple task, given vocabulary of 30 words</li> <li>Banding/selective responses do not appear with distributed letter coding when chance of ambiguity is null</li> <li>This means: when ambiguity/superposition catastrophe is very possible, hidden units learn selective responses</li> <li>Selective responses 'emerge' as a response to the potential for superposition catastrophe</li> <li>Recurrent networks trained to store multiple things at the same time over the same set of units learn highly selective (localist) representations</li> </ul>"},{"location":"KB/Supervised%20Learning%20Formulation/","title":"Supervised Learning Formulation","text":""},{"location":"KB/Supervised%20Learning%20Formulation/#supervised-learning-formulation","title":"Supervised Learning Formulation","text":"<ul> <li>given a dataset X, for each data Xi in X, there is a corresponding human-annotated label Yi </li> <li>For a set of N labeled training data D = {Xi}Ni=0, the training loss function is defined as </li> <li>data collection and annotation usually are expensive and may require special skills</li> </ul>"},{"location":"KB/Suppletion/","title":"Suppletion","text":""},{"location":"KB/Suppletion/#suppletion","title":"Suppletion","text":"<ul> <li>word is completely replaced by something that has no connection at the surface label</li> <li>Go to went.</li> <li>Good to better</li> </ul>"},{"location":"KB/Swichboard/","title":"Swichboard","text":""},{"location":"KB/Swichboard/#swichboard","title":"Swichboard","text":""},{"location":"KB/Swin%20Transformer/","title":"Swin Transformer","text":"<p>toc: true title: Swin Transformer</p> <p>categories: ['temp']</p>"},{"location":"KB/Swin%20Transformer/#swin-transformer","title":"Swin Transformer","text":"<ul> <li>Swin Transformer: Hierarchical Vision Transformer Using Shifted Windows<ul> <li>Vision Transformer</li> <li>general-purpose backbone for computer vision</li> <li>hierarchical feature representation</li> <li>linear computational complexity with respect to input image size</li> <li>shifted window based Self Attention</li> <li>address the challenges in adapting Transformer from language to vision</li> <li>limiting self-attention computation to non-overlapping local windows while also allowing for cross-window connection</li> <li>flexibility to model at various scales</li> <li>linear computational complexity with respect to image size</li> <li>ImageNet</li> <li>COCO</li> <li>ADE20K</li> <li>The hierarchical design and the shifted window approach also prove beneficial for all Perception Architectures.</li> <li>Ratio of 1:1:3:1</li> </ul> </li> </ul>"},{"location":"KB/Swish/","title":"Swish","text":""},{"location":"KB/Swish/#swish","title":"Swish","text":"<ul> <li> \\[x\\cdot sigmoid(x)\\] </li> <li>While Swish reportedly improves model performance (Ramachandran et al., 2017), it still does not allow you to avoid Vanishingexploding gradients</li> <li>Even though the vanishing gradients problem is much less severe in case of Swish, only inputs of \\(x &gt;= 2\\) result in gradients of 1 and (sometimes) higher. In any other case, the gradient will still cause the chain to get smaller with increasing layers.</li> <li>Move to Lisht</li> <li>non monotonic</li> <li>First, it is bounded below. Swish therefore benefits from sparsity similar to ReLU. Very negative weights are simply zeroed out.</li> <li>Second, it is unbounded above. This means that for very large values, the outputs do not saturate to the maximum value (i.e., to 1 for all the neurons). According to the authors of the Swish paper, this is what set ReLU apart from the more traditional activation functions.</li> <li>Third, separating Swish from ReLU, the fact that it is a smooth curve means that its output landscape will be smooth. This provides benefits when optimizing the model in terms of convergence towards the minimum loss.</li> <li>Fourth, small negative values are zeroed out in ReLU (since f(x) = 0 for x &lt; 0). However, those negative values may still be relevant for capturing patterns underlying the data, whereas large negative values may be zeroed out (for reasons of sparsity, as we saw above). The smoothness property and the values of f(x) &lt; 0 for x \u2248 0 yield this benefit. This is a clear win over ReLU.</li> <li></li> </ul>"},{"location":"KB/Symbolic%20learning%20model/","title":"Symbolic learning model","text":""},{"location":"KB/Symbolic%20learning%20model/#symbolic-learning-model","title":"Symbolic Learning Model","text":"<ul> <li>Verb tokens are used instead of verb types.</li> <li>No sharp discontinuities in the supply of regular and irregular verb tokens in 'parental speech'</li> <li>Verb tokens sampled randomly with replacement according to the Francis-Kucera frequency estimates for English verbs</li> </ul>"},{"location":"KB/Symbolic%20models/","title":"Symbolic models","text":""},{"location":"KB/Symbolic%20models/#symbolic-models","title":"Symbolic Models","text":"<ul> <li>Code letters separately from order</li> <li>This type of model does make transposition errors \u25ee Can because B is a 'thing' on its own, separate from order</li> <li>Botvinick, M. M., &amp; Plaut, D. C. (2006). Short-term memory for serial order: a recurrent neural network model. Psychological review, 113(2), 201.</li> <li>Model could later correctly reproduce novel sequences</li> <li>But all letters had occurred in each position</li> </ul>"},{"location":"KB/Symmetries%20Node%20Link/","title":"Symmetries Node Link","text":""},{"location":"KB/Symmetries%20Node%20Link/#symmetries-node-link","title":"Symmetries Node Link","text":""},{"location":"KB/Sympathetic/","title":"Sympathetic","text":""},{"location":"KB/Sympathetic/#sympathetic","title":"Sympathetic","text":"<ul> <li>Mobilizes body into action</li> </ul>"},{"location":"KB/Synaptic%20Pruning/","title":"Synaptic Pruning","text":""},{"location":"KB/Synaptic%20Pruning/#synaptic-pruning","title":"Synaptic Pruning","text":"<ul> <li>A process by which specialized cells called microglia eliminate unnecessary synapses as part of normal and healthy brain development.</li> </ul>"},{"location":"KB/Synaptic%20Transmission/","title":"Synaptic Transmission","text":""},{"location":"KB/Synaptic%20Transmission/#synaptic-transmission","title":"Synaptic Transmission","text":"<ul> <li>The process of nerve-to-nerve communication in the central nervous system, whereby one neuron sends a chemical signal across the synaptic cleft to another neuron.</li> </ul>"},{"location":"KB/Syntactic%20Ambiguity/","title":"Syntactic Ambiguity","text":""},{"location":"KB/Syntactic%20Ambiguity/#syntactic-ambiguity","title":"Syntactic Ambiguity","text":"<ul> <li>Flying plane is very dangerous</li> <li>The man saw a boy with binoculars</li> <li>The teacher wears sunglasses</li> <li>Becase students are bright</li> </ul>"},{"location":"KB/Syntactic%20Analysis/","title":"Syntactic Analysis","text":""},{"location":"KB/Syntactic%20Analysis/#syntactic-analysis","title":"Syntactic Analysis","text":"<ul> <li>concerned with the construction of sentences.</li> <li>Syntactic structure indicates how the words are related to each other</li> <li>Syntax tree is assigned by a grammer and a Lexicon</li> <li>Context Free Grammar</li> </ul>"},{"location":"KB/Syntactic%20Bootstrapping/","title":"Syntactic Bootstrapping","text":""},{"location":"KB/Syntactic%20Bootstrapping/#syntactic-bootstrapping","title":"Syntactic Bootstrapping","text":"<ul> <li>\"John wugged Mary yesterday\" vs \"John wugged Marry\"</li> </ul>"},{"location":"KB/Syntax%20First%20models/","title":"Syntax First models","text":""},{"location":"KB/Syntax%20First%20models/#syntax-first-models","title":"Syntax First Models","text":"<ul> <li>Syntax-first models (e.g., Ferreira &amp; Clifton, 1986; Frazier &amp; Clifton, 1996) have traditionally proposed that, at a point of syntactic ambiguity, syntactic heuristics alone select a single structure to pursue</li> <li>recovery from a misanalysis is achieved via a separate reanalysis mechanism that uses semantic and contextual information</li> <li>propose that only one representation is active at any given time and that nonsyntactic information only influences interpretation at a later reanalysis stage.</li> </ul>"},{"location":"KB/S%C3%B8rensen-Dice%20Index/","title":"S\u00f8rensen-Dice Index","text":""},{"location":"KB/S%C3%B8rensen-Dice%20Index/#srensen-dice-index","title":"S\u00f8rensen-Dice Index","text":"<ul> <li>very similar to Jaccard index</li> <li>Although they are calculated similarly the S\u00f8rensen-Dice index is a bit more intuitive because it can be seen as the percentage of overlap between two sets, which is a value between 0 and 1</li> <li>overstate the importance of sets with little to no ground truth positive sets</li> <li>As a result, it could dominate the average score taken over multiple sets</li> <li>It weights each item inversely proportionally to the size of the relevant set rather than treating them equally.</li> <li>$\\(D(x,y) = \\frac{2|x\\cap y|}{|x|+|y|}\\)</li> <li></li> </ul>"},{"location":"KB/T.%20B.%20Macaulay/","title":"T. B. Macaulay","text":"","tags":["indianhistory"]},{"location":"KB/T.%20B.%20Macaulay/#t-b-macaulay","title":"T. B. Macaulay","text":"<ul> <li>Macaulay came from a deeply religious Protestant family, so his motivation was to convert numerous Hindus to Christianity, which he thought would also help the administrative problems that the English were facing</li> <li>His plan was to create an educational system that would make an educated elite that would naturally be English by their own choice, and thus give up their own Hindu traditions</li> <li>Then they would also work and cooperate more efficiently with the English administration.</li> <li>facilitate the British colonialism by making Indians, especially the Brahmanas, collaborators loyal to their new masters</li> <li>\"Our English schools are flourishing wonderfully. The effect of this education on the Hindus is prodigious... It is my belief that if our plans of education are followed up, there will not be a single idolater among the respectable classes in Bengal thirty years hence. And this will be effected without any efforts to proselytize, without the smallest interference with religious liberty, by natural operation of knowledge and reflection. I heartily rejoice in the project.\"</li> <li>\"It is, I believe, no exaggeration to say, that all the historical information which has been collected from all the books written in Sanskrit language is less valuable than what may be found in the most paltry abridgements used at preparatory schools in England. In every branch of physical or moral philosophy, the relative position of the two nations is nearly the same.\"</li> <li>\"In one point I fully agree with the gentlemen to whose general views I am opposed. I feel with them, that it is impossible for us, with our limited means, to attempt to educate the body of the people. We must at present do our best to form a class who may be interpreters between us and the millions whom we govern; a class of persons, Indian in blood and colour, but English in taste, in opinions, in morals, and in intellect. To that class we may leave it to refine the vernacular dialects of the country, to enrich those dialects with terms of science borrowed from the Western nomenclature, and to render them by degrees fit vehicles for conveying knowledge to the great mass of the population.\"</li> <li>This is in reference that Macaulay figured that the British would not be able to educate all Indians in the ways of the British, but could indeed create a class of them who would be English in taste, opinions, morals and intellect, and then engage them in influencing the rest of India, thus helping the English in their job of overseeing the rest of India, and, of course, converting them.</li> <li>\"Through the whole Hindoo Pantheon you will look in vain for anything resembling those beautiful and majestic forms which stood in the shrines of ancient Greece. All is hideous, and grotesque, and ignoble. As this superstition is of all superstitions the most inelegant, so is it of all superstitions the most immoral. Emblems of vice are objects of public worship. Acts of vice are acts of public worship. The courtesans are as much a part of the establishment of the temple, as much ministers of the god, as the priests. Crimes against life, crimes against property, are not only permitted but enjoined by this odious theology.\"</li> </ul>","tags":["indianhistory"]},{"location":"KB/TIghtly%20coupled/","title":"TIghtly coupled","text":""},{"location":"KB/TIghtly%20coupled/#tightly-coupled","title":"TIghtly Coupled","text":"<ul> <li>UMA</li> <li>NUMA</li> </ul>"},{"location":"KB/TIme%20Series/","title":"Time Series Prediction","text":""},{"location":"KB/TIme%20Series/#time-series-prediction","title":"Time Series Prediction","text":"<ul> <li>Task:<ul> <li>discrete time, equidistant timesteps</li> <li>Approximate teacher signal</li> <li>Input signal : \\(\\(u(t)_{t \\in \\mathcal{T}}\\)\\)</li> <li>Desired output : \\(\\((y(t))_{t \\in \\mathcal{T}} = u(t+h))_{t \\in \\mathcal{T}}\\)\\)</li> <li>Dynamical system state : \\(\\(x(t) \\in \\mathbb{R}^n\\)\\)</li> <li>Temporal evolution governed by<ul> <li>State update map<ul> <li>Governs how \\(\\(x(t)\\)\\) develops over time</li> <li> \\[x(t+1) = f(x(t) , u(t+1))\\] </li> </ul> </li> <li>Observation function<ul> <li>What output can be observed when in state \\(\\(x(t)\\)\\)</li> <li> \\[y(t) = g(x(t))\\] </li> </ul> </li> </ul> </li> </ul> </li> <li>Short range<ul> <li>PDE , ODE</li> </ul> </li> <li>Long range<ul> <li>HMM</li> <li>Recurrent</li> </ul> </li> </ul>"},{"location":"KB/TO%20LOOK%20AT/","title":"To Look at","text":""},{"location":"KB/TO%20LOOK%20AT/#to-look-at","title":"To Look at","text":"<ul> <li>http://karpathy.github.io/2019/04/25/recipe/</li> <li>https://arxiv.org/abs/1311.2901</li> <li>http://torch.ch/blog/2015/09/07/spatial_transformers.html</li> <li>http://dpmd.ai/Ithaca-blog</li> <li>https://notesonai.com/Layer+Normalization</li> </ul>"},{"location":"KB/TPU%20Node/","title":"TPU Node","text":""},{"location":"KB/TPU%20Node/#tpu-node","title":"TPU Node","text":"<ul> <li>A TPU resource on Google Cloud Platform with a specific TPU type.</li> </ul>"},{"location":"KB/TPU%20Pod/","title":"TPU Pod","text":""},{"location":"KB/TPU%20Pod/#tpu-pod","title":"TPU Pod","text":"<ul> <li>A specific configuration of TPU devices in a Google data center.</li> </ul>"},{"location":"KB/TPU%20Slice/","title":"TPU Slice","text":""},{"location":"KB/TPU%20Slice/#tpu-slice","title":"TPU Slice","text":"<ul> <li>A TPU slice is a fractional portion of the TPU devices in a TPU Pod</li> </ul>"},{"location":"KB/TREEQN/","title":"TREEQN","text":""},{"location":"KB/TREEQN/#treeqn","title":"TREEQN","text":"<pre><code>def transition(zl):\n  # -- [batch_size x num_actions x hidden_dimension]\n  return zl.unsqueeze(1) + F.tanh(torch.einsum(\"bk,aki-&gt;bai\", [zl, W]) + b)\n</code></pre>"},{"location":"KB/TREPAN/","title":"TREPAN","text":""},{"location":"KB/TREPAN/#trepan","title":"TREPAN","text":"<ul> <li>or DeepRED</li> <li>TREPAN is an algorithm for extracting comprehensible, symbolic representations from trained neural networks</li> <li>The authors demonstrated that TREPAN is able to produce Decision Trees that are accurate and comprehensible and maintain a high level of fidelity to the networks from which they were extracted.</li> <li>According to the authors of DeepRED, their method is the first attempt to extract rules and make a DNN's decision more transparent.</li> </ul>"},{"location":"KB/TSDF/","title":"TSDF","text":""},{"location":"KB/TSDF/#tsdf","title":"TSDF","text":"<ul> <li>Truncated Signed Distance Function</li> </ul>"},{"location":"KB/Tacotron/","title":"Tacotron","text":""},{"location":"KB/Tacotron/#tacotron","title":"Tacotron","text":"<ul> <li>CBHG<ul> <li>[Conv](Gated Recurrent Unit (GRU|Gated Recurrent Unit (GRU|Conv](Conv](Gated Recurrent Unit (GRU|Gated Recurrent Unit (GRU|Conv.md).md)</li> </ul> </li> </ul> <pre><code>class CBHG_Old(nn.Module):\n    \"\"\"CBHG module: a [recurrent](./Recurrent.md) neural network composed of:\n        - 1-d convolution banks\n        - Highway networks + residual connections\n        - Bidirectional gated [recurrent](./Recurrent.md) units\n    \"\"\"\n\n    def __init__(self, in_dim, K=16, projections=[128, 128]):\n        super(CBHG, self).__init__()\n        self.in_dim = in_dim\n        self.relu = nn.ReLU()\n        self.conv1d_banks = nn.ModuleList(\n            [BatchNormConv1d(in_dim, in_dim, kernel_size=k, stride=1,\n                             padding=k // 2, activation=self.relu)\n             for k in range(1, K + 1)])\n        self.max_pool1d = nn.MaxPool1d(kernel_size=2, stride=1, padding=1)\n\n        in_sizes = [K * in_dim] + projections[:-1]\n        activations = [self.relu] * (len(projections) - 1) + [None]\n        self.conv1d_projections = nn.ModuleList(\n            [BatchNormConv1d(in_size, out_size, kernel_size=3, stride=1,\n                             padding=1, activation=ac)\n             for (in_size, out_size, ac) in zip(\n                 in_sizes, projections, activations)])\n\n        self.pre_highway = nn.Linear(projections[-1], in_dim, bias=False)\n        self.highways = nn.ModuleList(\n            [Highway(in_dim, in_dim) for _ in range(4)])\n\n        self.gru = nn.GRU(\n            in_dim, in_dim, 1, batch_first=True, bidirectional=True)\n\ndef forward_new(self, inputs, input_lengths=None):\n    x = rearrange(inputs, 'b t c -&gt; b c t')\n    _, _, T = x.shape\n    # Concat conv1d bank outputs\n    x = rearrange([conv1d(x)[:, :, :T] for conv1d in self.conv1d_banks], \n                 'bank b c t -&gt; b (bank c) t', c=self.in_dim)\n    x = self.max_pool1d(x)[:, :, :T]\n\n    for conv1d in self.conv1d_projections:\n        x = conv1d(x)\n    x = rearrange(x, 'b c t -&gt; b t c')\n    if x.size(-1) != self.in_dim:\n        x = self.pre_highway(x)\n\n    # Residual connection\n    x += inputs\n    for highway in self.highways:\n        x = highway(x)\n\n    # (B, T_in, in_dim*2)\n    outputs, _ = self.gru(self.highways(x))\n\n    return outputs\n</code></pre>"},{"location":"KB/Tainted%20data/","title":"Tainted data","text":""},{"location":"KB/Tainted%20data/#tainted-data","title":"Tainted data","text":"<ul> <li>errors in the data modelling definition, wrong feature labelling, and other possible causes.</li> </ul>"},{"location":"KB/Taking%20on%20semantic%20commitments%2C%20II%20collective%20versus%20distributive%20readings/","title":"Taking on semantic commitments, II collective versus distributive readings","text":""},{"location":"KB/Taking%20on%20semantic%20commitments%2C%20II%20collective%20versus%20distributive%20readings/#taking-on-semantic-commitments-ii-collective-versus-distributive-readings","title":"Taking on Semantic Commitments, II Collective Versus Distributive Readings","text":"<ul> <li>Lyn Frazier, Jeremy M. Pacht, Keith Raynerb</li> </ul> <ul> <li>Minimal Semantic Commitment</li> <li>Given ambiguous representations, the MSC hypothesis predicts that the processor will commit to one interpretation</li> <li>In an experiment designed to evaluate these hypotheses with respect to the representation of distributivity, participants' eye movements were recorded as they read sentences containing distributive or collective predicates that were either disambiguated by a preceding adverb or left locally ambiguous by delaying the disambiguating adverb until the end of the predicate</li> <li>The results suggested that a semantic commitment is made in locally indeterminate cases as evidenced by a significant interaction of ambiguity and distributivity in first pass times, total times, and regressions</li> <li>Hence we argue that the distributive/collective distinction is treated as a matter of ambiguity rather than as one of vagueness</li> <li>In the absence of evidence for a distributive reading, the processor commits itself to a collective reading sometime during the processing of the predicate (before the disambiguation in our late disambiguation examples)</li> <li>By the MSC hypothesis, this will predict that a premature decision, one made early on the basis of little information, should not occur during immediate processing</li> <li>The point is that no commitment will be made in the absence of supporting evidence</li> <li>By contrast, given the MSC hypothesis, the notion that a string is grammatically ambiguous predicts that the processor encounters a choice point on initial analysis, adopting one representation rather than another</li> <li>In our experiment we only examined collective/distributive subjects in single clause sentences</li> <li>The ambiguity hypothesis predicts an interaction</li> <li>the vagueness hypothesis doesn't</li> <li>T</li> <li>In order to test for possible pragmatic biases in the predicate, participants were asked to rate the 'naturalness' of the locally ambiguous collective or distributive predicates contained in the experimental sentences</li> <li>when the actual conjoined NP subject in the experimental materials was replaced by a pronominal subject</li> <li>Thirty-two students native English speakers</li> <li>Each version of the questionnaire contained eight sentences in which the locally ambiguous predicate was subsequently disambiguated towards a distributive interpretation using each and eight sentences in which the predicate was subsequently disambiguated towards a collective interpretation using together</li> <li>7-point scale</li> <li>They were told that there were no right or wrong answers and that we were only interested in their opinions of the naturalness of the sentences</li> <li>another rating study was conducted using truncated versions of the locally ambiguous items such that each item ended after the word each or together</li> <li>examined first pass reading times, total reading times, and the pattern of regressions for different regions of the target sentences</li> <li>Sixty undergraduate students bite bar</li> </ul>"},{"location":"KB/Taking%20on%20semantic%20commitments%2C%20II%20collective%20versus%20distributive%20readings/#experiment","title":"Experiment","text":"<ul> <li>dealt with where readers look during reading and that they should read each sentence for comprehension</li> <li>Sixteen experimental sentences were embedded in 107 filler sentences</li> <li>Each sentence appeared in one of four versions, as in (7) above: in two versions (a and c), the predicate received a distributive interpretation, and in the other two (b and d) the predicate received a collective interpretation</li> <li>region</li> <li>he first region consisted of the words preceding the predicate (a conjoined NP)</li> <li>the second region consisted of the predicate itself</li> <li>the third region comprised the next three words, or next two words if the third word was the last word in the sentence</li> <li>and the fourth region was the remainder of the sentence</li> <li>The fourth region was created solely so that results from the third region would be free of sentence wrapup effects</li> <li>In the first region, none of the effects were significant</li> <li>In the second region, there was an effect of ambiguity, wherein the locally ambiguous versions were read faster than unambiguous versions, possibly due to a preference for adverbs to appear in verb-phrase final position</li> <li>he raw reading times analyses and analyses of residuals were consistent in</li> <li>indicating that the interaction did not approach significance</li> <li>In the third region, the different versions of any given sentence were once again identical</li> <li>Here, locally ambiguous versions were read somewhat slower overall than unambiguous versions</li> <li>However, this difference failed to approach significance in the subjects analysis (F1(1,59) = 1</li> <li>91, P \u0000 0</li> <li>16) and was only marginally significant by items</li> <li>Crucially, each of these marginally significant main effects was qualified by a highly robust interaction between ambiguity and predicate type, suggesting that distributive predicates were read more slowly than collective predicates in the locally ambiguous versions</li> <li>Pairwise comparisons confirmed that while distributives were read more slowly in the ambiguous versions (F1(1,59) = 10</li> <li>84, P \u0000 0</li> <li>01</li> <li>F2(1,14) =20</li> <li>48, P \u0000 0</li> <li>001), there was no reliable predicate effect in the unambiguous versions</li> <li>The results of this analysis for first pass times revealed striking differences between ambiguous and unambiguous forms</li> <li>In the residuals analyses, distributives (each) were read slower than collectives (together) in both ambiguous and unambiguous forms</li> <li>However, the effect was much larger in ambiguous forms than unambiguous forms (223 ms vs</li> <li>43 ms), and while in ambiguous forms the effect was significan</li> <li>Distributives were significantly faster than collectives in unambiguous forms (means: 844 ms vs</li> <li>925 ms</li> <li>F1(1,59) = 4</li> <li>72, P \u0000 0</li> <li>05, F2 (1,14) = 10</li> <li>39, P \u0000 0</li> <li>01), but significantly slower than collectives in ambiguous forms</li> <li>n the third region, where the different versions were again identical, there was a main effect of ambiguity, with ambiguous versions being read slower overall than unambiguous versions</li> <li>There was also a robust predicate effect (F1(1,59) = 9</li> <li>53, P \u0000 0</li> <li>01</li> <li>F2(1,14) = 10</li> <li>88, P \u0000 0</li> <li>01), which indicated that distributives were read more slowly overall</li> <li>In the second region, there were no significant differences across conditions in the percentages of trials on which regressions occurred out of the region (Fs \u0000 1)</li> <li>In the third region, the mean percentage of trials on which regressions occurred out of the region was 19%, 8%, 4% and 4% for the ambiguous-distributive, ambiguouscollective, unambiguous-distributive, and unambiguous-collective conditions, respectively</li> <li>There were significantly more trials involving regressions out of the third region in the ambiguous than the unambiguous versions</li> <li>The predictions of the vagueness hypothesis were clearly disconfirmed</li> <li>Given the MSC hypothesis, the vagueness hypothesis predicts no interaction between ambiguity and sentence form: in both the ambiguous distributive (7a) and the unambiguous distributive (7c) the processor should postulate a distributive operator when each is encountered</li> <li>ounter to this prediction, the ambiguous distributive form was substantially more difficult to understand than the other sentence forms</li> <li>This may be seen in the significant interaction of ambiguity and sentence form in first pass and total times in region three, as well as in the regressions out of region three and regressions into region two</li> <li>Readers clearly exhibited a preference for the collective reading of the ambiguous portion of the sentences in our experiment</li> <li>These results make it difficult to maintain the assumptions needed to salvage the vagueness hypothesis</li> <li>Instead, given the MSC hypothesis, they support the assumption that the correct grammatical account of collective/distributive differences treats the distinction as one of ambiguity rather than as one of vagueness, at least in cases like those tested, where subject-predicate relations are involved</li> <li>We turn now to alternative interpretations of our results</li> <li>The question is whether the results can be attributed directly to the complexity of the distributive reading</li> <li>We think not</li> <li>It may be true that distributive readings, even unambiguous ones, are slightly more complex than collective readings</li> <li>This suggests that readers may not simply add information to the current representation of these locally ambiguous forms when each is encountered</li> <li>Similarly the results are difficult to reconcile with a parallel processing view unless the processor has computed both a collective and a distributive representation and then abandoned the distributive representation before each is encountered</li> </ul>"},{"location":"KB/Tanh/","title":"Tanh","text":""},{"location":"KB/Tanh/#tanh","title":"Tanh","text":"<ul> <li> \\[\\frac{e^x-e^{-x}}{e^x+e^{-x}}\\] </li> <li>RNN : Hidden</li> <li>Xavier/Glorot init</li> <li></li> </ul>"},{"location":"KB/Task%20%28endeffector%29%20Space%20Vs%20Joint%20Space/","title":"Task (endeffector) Space Vs. Joint Space","text":""},{"location":"KB/Task%20%28endeffector%29%20Space%20Vs%20Joint%20Space/#task-endeffector-space-vs-joint-space","title":"Task (endeffector) Space Vs. Joint Space","text":""},{"location":"KB/Tau%20Protein/","title":"Tau Protein","text":""},{"location":"KB/Tau%20Protein/#tau-protein","title":"Tau Protein","text":"<ul> <li>A type of protein abundantly found in neurons. When this protein is not adequately cleared from the brain, it can form tangles that are a key pathology of several neurodegenerative disorders including frontotemporal degeneration, CTE, and Alzheimer\u2019s disease.</li> </ul>"},{"location":"KB/Teach%20Lock/","title":"Teach Lock","text":""},{"location":"KB/Teach%20Lock/#teach-lock","title":"Teach Lock","text":"<ul> <li>While the Teach Lock is set, the mode of operation is tied to the Teach Mode and the machines cannot be played back using either START to \u201cTEACH\u201d before beginning to teach.</li> </ul>"},{"location":"KB/Teacher%20Forcing/","title":"Teacher Forcing","text":""},{"location":"KB/Teacher%20Forcing/#teacher-forcing","title":"Teacher Forcing","text":"<ul> <li>from</li> <li>Technique where the target word (ground truth word) is passed as the next input to the decoder instead of its last prediction.</li> <li>common technique to train\u00a0Basic RNN Architectures\u00a0or\u00a0Transformer<ul> <li>used in imageCaptioning\u00a0, Machine Translation</li> <li>but also in Time Series forecasting</li> </ul> </li> <li>intuition<ul> <li>math exam with dependent questions, e.g. a) depends on b), b) on c) and so on</li> <li>if a) is wrong, all subsequent questions are also wrong</li> <li>teacher forcing: after answering question a), the teacher compares it to the correct solution and grades it and then gives us the correct answer for a) to continue with</li> </ul> </li> <li>for example in sequence generation with\u00a0RNN\u00a0the situation is similar<ul> <li>each prediction depends on the last one, thus when one is wrong all subsequent will be wrong as well</li> </ul> </li> <li>no memorization can happen<ul> <li>the network can not look into the future</li> <li>ground truth is only fed as last \\(y_{t-1}\\) prediction not as the current \\(y_{t}\\)</li> </ul> </li> <li>loss does not need to be updated at each timestep, only needs to have a list with the true predictions of the model from which then the loss is calculated</li> <li>pros<ul> <li>training converges faster, because early predictions are very bad</li> </ul> </li> <li>cons<ul> <li>no ground truth label during inference, thus no teacher forcing</li> <li>discrepancy between training and inference scores<ul> <li>can lead to poor model performance and instability</li> <li>known as\u00a0Exposure Bias</li> </ul> </li> </ul> </li> </ul>"},{"location":"KB/Teacher%20Student%20Architecture/","title":"Teacher Student Architecture","text":""},{"location":"KB/Teacher%20Student%20Architecture/#teacher-student-architecture","title":"Teacher Student Architecture","text":"<ul> <li>The gap is further reduced by residual learning, i.e., the assistant structure is used to learn the residual error (Gao et al., 2021).</li> </ul>"},{"location":"KB/Telomere/","title":"Telomere","text":""},{"location":"KB/Telomere/#telomere","title":"Telomere","text":"<ul> <li>The protective cap found at the end of a chromosome. Research studies suggest these caps may be shortened in neurodegenerative diseases.</li> </ul>"},{"location":"KB/Temporal%20Context%20Structure/","title":"Temporal Context Structure","text":""},{"location":"KB/Temporal%20Context%20Structure/#temporal-context-structure","title":"Temporal Context Structure","text":"<ul> <li>The temporal order from videos is used as supervision signal </li> <li>verify whether the input frame sequence in correct order </li> <li>recognize the order of the frame sequence</li> </ul>"},{"location":"KB/Temporal%20Conv/","title":"Temporal Conv","text":""},{"location":"KB/Temporal%20Conv/#temporal-conv","title":"Temporal Conv","text":"<ul> <li>FCN + Causal 1D Conv + Residual</li> <li>Outperforms Basic RNN Architectures such as Long Short Term Memory (LSTM)).md) and Gated Recurrent Unit (GRU)).md)</li> </ul>"},{"location":"KB/Temporal%20lobe/","title":"Temporal lobe","text":""},{"location":"KB/Temporal%20lobe/#temporal-lobe","title":"Temporal Lobe","text":"<ul> <li>Understanding language (Wernicke Area)</li> <li>Memory</li> <li>Hearing</li> <li>Sequencing and organization</li> <li>Long-term memory is processed in the hippocampus of the temporal lobe and is activated when you want to memorize something for a longer time.</li> </ul>"},{"location":"KB/Temporal%20order%20recognition/","title":"Temporal order recognition","text":""},{"location":"KB/Temporal%20order%20recognition/#temporal-order-recognition","title":"Temporal order recognition","text":"<ul> <li>recognize the order of a sequence of input frames.</li> </ul>"},{"location":"KB/Temporal%20order%20verification/","title":"Temporal order verification","text":""},{"location":"KB/Temporal%20order%20verification/#temporal-order-verification","title":"Temporal order verification","text":"<ul> <li>verify whether a sequence of input frames is in correct temporal order</li> </ul>"},{"location":"KB/TemporalLearning/","title":"Temporal Learning","text":""},{"location":"KB/TemporalLearning/#temporal-learning","title":"Temporal Learning","text":"<ul> <li>Recurrent</li> <li>Online Learning</li> <li>Causal Systems</li> </ul>"},{"location":"KB/Tensor%20Processing%20Unit/","title":"Tensor Processing Unit","text":""},{"location":"KB/Tensor%20Processing%20Unit/#tensor-processing-unit","title":"Tensor Processing Unit","text":"<ul> <li>An application-specific integrated circuit (ASIC) that optimizes the performance of machine learning workloads.</li> </ul>"},{"location":"KB/Test-time%20Augmentation/","title":"Test-time Augmentation","text":""},{"location":"KB/Test-time%20Augmentation/#test-time-augmentation","title":"Test-time Augmentation","text":"<ul> <li>augmenting data at test-time as well</li> <li>This can be seen as analogous to ensemble learning techniques in the data space.</li> <li>By taking a test image and augmenting it in the same way as the training images, a more robust prediction can be derived.</li> <li>restrict the speed of the model</li> <li>promising practice for applications such as medical image diagnosis</li> <li>Radosavovic et al. denote test-time augmentation as data distillation to describe the use of ensembled predictions to get a better representation of the image.</li> <li>They also found better uncertainty estimation when using test-time augmentation, reducing highly confident but incorrect predictions.</li> <li>Matsunaga et al. also demonstrate the effectiveness of test-time augmentation on skin lesion classification, using geometric transformations such as rotation, translation, scaling, and Flipping.</li> <li>A robust classifier is thus defined as having a low variance in predictions across augmentations</li> <li>In their experiments searching for augmentations with Reinforcement Learning, Minh et al. measure robustness by distorting test images with a 50% probability and contrasting the accuracy on un-augmented data with the augmented data.</li> <li>Some classification models lie on the fence in terms of their necessity for speed. This suggests promise in developing methods that incrementally upgrade the confidence of prediction. This could be done by first outputting a prediction with little or no testtime augmentation and then incrementally adding test-time augmentations to increase the confidence of the prediction.</li> <li>However, it is difficult to aggregate predictions on geometrically transformed images in object detection and semantic segmentation. Curriculum learning</li> <li>strategy for selecting training data that beats random selection</li> <li>best to initially train with the original data only and then finish training with the original and augmented data, although there is no clear consensus</li> </ul>"},{"location":"KB/Text%20Normalization/","title":"Text Normalization","text":""},{"location":"KB/Text%20Normalization/#text-normalization","title":"Text Normalization","text":"<ul> <li>Merging di\ufb00erent written forms of a token into a canonical normalized form</li> </ul>"},{"location":"KB/Text%20Preprocessing/","title":"Text Preprocessing","text":""},{"location":"KB/Text%20Preprocessing/#text-preprocessing","title":"Text Preprocessing","text":"<ul> <li>Document Triage</li> <li>Text Segmentation</li> </ul>"},{"location":"KB/Text%20Segmentation/","title":"Text Segmentation","text":""},{"location":"KB/Text%20Segmentation/#text-segmentation","title":"Text Segmentation","text":"<ul> <li>Word Segmentation</li> <li>Text Normalization</li> <li>Sentence Segmentation</li> <li>Character-set dependence</li> <li>Language dependence</li> <li>Corpus dependence</li> <li>Application dependence</li> </ul>"},{"location":"KB/Textbooks%20are%20all%20you%20need/","title":"Textbooks are all you need","text":""},{"location":"KB/Textbooks%20are%20all%20you%20need/#textbooks-are-all-you-need","title":"Textbooks Are All You Need","text":"<ul> <li>Summary : This paper proposes a new code assisting model that uses Python text books to train as textbooks have more curated knowledge. There are quite a few limitations such as not learning, maths and being specific to the type of textbooks used. </li> </ul>"},{"location":"KB/Textbooks%20are%20all%20you%20need/#abstract","title":"Abstract","text":"<ul> <li>phi-1 </li> <li>new large language model for code, </li> <li>significantly smaller size than competing models: </li> <li>Transformer-based model with 1.3B parameters, trained for 4 days on 8 A100s, using a selection of \"textbook quality\" data from the web (6B tokens) </li> <li>synthetically generated textbooks and exercises with GPT-3.5 </li> <li>surprising emergent properties compared to phi-1-base, our model before our finetuning stage on a dataset of coding exercises, and phi-1-small, a smaller model with 350M parameters trained with the same pipeline as phi-1 that still achieves 45% on HumanEval.  </li> <li> </li> </ul>"},{"location":"KB/Textbooks%20are%20all%20you%20need/#training-details-and-the-importance-of-high-quality-data","title":"Training Details and the Importance of High-quality Data","text":"<ul> <li>training data. Unli+ke previous work that used standard sources of text data for code generation, such as The Stack [KLA 22] (which contains sourcecode from repositor+ies with permissive licenses) and other not optimal for teaching the model how to reason and plan algorithmically. </li> <li>The standard code datasets [KLA+22, LCC+22] form a large and diverse corpus covering broad range of topics and use cases. </li> <li>sufer from several drawbacks: </li> <li>samples are not self-contained, meaning that they depend on other modules or files that are external to the snippet, making them hard to understand without additional context. </li> <li>Typical examples do not involve any meaningful computation, but rather consist of trivial or boilerplate code, such as defining constants, setting parameters, or configuring GUI element </li> <li>Samples that do contain algorithmic logic are often buried inside complex or poorly documented functions, making them dicult to follow or learn from. </li> <li>examples are skewed towards certain topics or use cases, resulting in an unbalanced distribution of coding concepts and skills across the dataset. </li> <li>language models would benefit from a training set that has the same qualities as what a human would perceive as a good \"textbook\": it should be clear, self-contained, instructive, and balanced. </li> <li>three main datasets: </li> <li>filtered code-language dataset </li> <li>subset of The Stack and StackOverflow, obtained by using a language model-based classifier (consisting of about 6B tokens). </li> <li>synthetic textbook dataset </li> <li>&lt;1B tokens of GPT-3.5 generated Python textbooks. </li> <li>small synthetic exercises dataset </li> <li>\u223c180M tokens of Python exercises and solutions. </li> <li>s of Python exercises and solutions. contain less than 7B tokens </li> <li>CodeTextbook </li> </ul>"},{"location":"KB/Textbooks%20are%20all%20you%20need/#the-central-ingredient-our-model-relies-on-textbook-quality-training-data","title":"the central ingredient our model relies on textbook-quality training data.","text":""},{"location":"KB/Textbooks%20are%20all%20you%20need/#filtering-of-existing-code-datasets-using-a-transformer-based-classifier","title":"Filtering of Existing Code Datasets Using a Transformer-based Classifier","text":"<ul> <li>Python subset of the deduplicated version of The Stack and the StackOverflow, which together contain over 35 million files/samples, totalling over 35B tokens. </li> <li>annotate the quality of a small subset of these files (about 100k samples) using GPT- 4: given a code snippet, the model is prompted to \"determine its educational value for a student whose goal is to learn basic coding concepts\". </li> <li>use this annotated dataset to train a random forest classifier that predicts the quality of a file/sample using its output embedding from a pretrained codegen model as features. </li> <li>unlike GPT-3.5, which we use extensively to generate synthetic content (discussed below), we use GPT-4 minimally only for annotations on the quality of a small subset of The Stack and StackOverflow  </li> <li> </li> </ul>"},{"location":"KB/Textbooks%20are%20all%20you%20need/#creation-of-synthetic-textbook-quality-datasets","title":"Creation of Synthetic Textbook-quality Datasets","text":"<ul> <li>main challenges in creating a high-quality dataset for code generation is ensuring that the examples are diverse and non-repetitive. </li> <li>the examples should cover a wide range of coding concepts, skills, and scenarios, and that they should vary in their level of diculty, complexity, and style. </li> <li>exposes the language model to diferent ways of expressing and solving problems in code, it reduces the risk of overfitting or memorizing specific patterns or solutions, and it increases the generalization and robustness of the model to unseen or novel tasks </li> <li>not trivial, especially when using synthetic data generated by another language model. </li> <li>Simply prompting the model to produce a coding textbook or a set of exercises, even with some variation in the instructions or the parameters, will likely result in a very homogeneous and redundant dataset, where the same concepts and solutions are repeated over and over with minor changes. </li> <li>language models tend to follow the most probable or common paths given their training data and their priors, and they lack the creativity or the incentive to explore alternative or novel ways of generating code. </li> <li>one needs to find the right \"trick\" </li> <li>The synthetic textbook dataset </li> <li>diversity is obtained by providing constraints on topics and target audience of the generated textbook  </li> <li> </li> <li>The CodeExercises dataset </li> <li>conduct explicit decontamination and alternative evaluations in the following sections to ensure that problems similar to those from HumanEval benchmark are not seen during finetuning.  </li> <li> </li> </ul>"},{"location":"KB/Textbooks%20are%20all%20you%20need/#model-architecture-and-training","title":"Model Architecture and Training","text":"<ul> <li>some recent models like CodeGen [NPH+22], PaLM [CND+22], and GPT-NeoX [BBH+22]. The architecture for our 1.3B parameter phi-1 model consists of 24 layers, hidden dimension of 2048, MLP-inner dimension of 8192, and 32 attention heads of dimension 64 each. The smaller 350M parameter phi- 1-small model consists of 20 layers, hidden dimension of 1024, MLP-inner dimension+of 4096, and 16 attention heads of dimension 64 each. We also use a rotary position+embedding [SLP 21] with rotary </li> <li>could further boost performance and eciency [LAZ 23]. </li> <li>For both pretraining and finetuning, we concatenate our respective datasets into a single dimensional </li> <li>array with </li> <li>array with \"\u0000\u0000endoftext\u0000\u0000\" token used for separating the files. We train our models on sequence length of optimizer, linear-warmup-linear-decay learning rate schedule, and attention and residual dropout of 0.1. </li> <li>Pretraining </li> <li>phi-1-base was trained on the CodeTextbook dataset </li> <li>phi-1 is obtained by finetuning phi-1-base on the CodeExercises dataset. </li> </ul>"},{"location":"KB/Textbooks%20are%20all%20you%20need/#spikes-of-model-capability-after-finetuning-on-codeexercises","title":"Spikes of Model Capability after Finetuning on CodeExercises","text":"<ul> <li>the model after finetuning also exhibits a substantial improvement in executing tasks that are not featured in the finetuning dataset. </li> <li>This includes managing intricate algorithmic tasks and using external libraries. </li> <li>suggests that our finetuning process might have helped the model in reorganizing and consolidating the knowledge acquired during pretraining, even if such knowledge is not explicitly present in our CodeExercises dataset </li> <li>Finetuning improves the model's understanding </li> <li>Finetuning improves the model's ability to use external libraries </li> </ul>"},{"location":"KB/Textbooks%20are%20all%20you%20need/#evaluation-on-unconventional-problems-with-llm-grading","title":"Evaluation on Unconventional Problems with LLM Grading","text":"<ul> <li>A potential concern with the surprisingly good performance of phi-1 on HumanEval (see Table 1 and Figure 2.1) is that there might be memorization stemming from contamination of the CodeExercises dataset1 </li> <li>To minimize bias and leakage, the new evaluation problems were created by a dedicated team in our group that did not access the CodeExercises dataset or the final model. </li> <li>They created 50 new problems in the same format as HumanEval with instructions to design problems that are unlikely to appear in real-world code bases or as coding exercises. </li> <li>To evaluate candidate solutions, we therefore adopt the approach of using GPT-4 to grade the solution </li> <li>This approach has two distinct advantages: (1) by using GPT-4 as a grader, we can leverage its knowledge and generative abilities to obtain a more fine-grained and meaningful signal of the student model's coding capabilities, and (2) it obviates the need for tests </li> <li>Our prompt instructs the LLM to evaluate a student's solution first in a short verbal evaluation followed by grades from 0 to 10 </li> </ul>"},{"location":"KB/Textbooks%20are%20all%20you%20need/#data-pruning-for-unbiased-performance-evaluation","title":"Data Pruning for Unbiased Performance Evaluation","text":"<ul> <li>training on CodeExercises leads to a substantial boost in the performance of the model on the HumanEval benchmark </li> <li>To investigate this boost, we propose to prune the CodeExercises dataset by removing files that are \"similar\" to those in HumanEval. </li> <li>\"strong form\" of data decontamination. </li> <li>retrain our model on such pruned data, and still observe strong performance on HumanEval. </li> <li>such data pruning experiment is a fair way to evaluate performance </li> </ul>"},{"location":"KB/Textbooks%20are%20all%20you%20need/#n-gram-overlap","title":"N-gram Overlap","text":"<ul> <li>N-gram measures the similarity of text segments based on the shared n-word sequences. </li> <li>n-gram overlap between the docstrings of each humaneval question and each exercise in the CodeExercises dataset that was generated </li> <li>found 4 humaneval questions with 13-gram overlap with at least one of the entries in our dataset </li> <li>all the 4 overlap cases in the 13-gram are all false positives such as the example # below. </li> <li>Our n-gram overlap analysis shows that our dataset has minimal letter-by-letter overlap with HumanEval. </li> </ul>"},{"location":"KB/Textbooks%20are%20all%20you%20need/#embedding-and-syntax-based-similarity-analysis","title":"Embedding and Syntax-based Similarity Analysis","text":"<ul> <li>now turn to the pruning experiments </li> <li>n-gram analysis is not refined enough to find similar code snippets between HumanEval and CodeExercises </li> <li>combination of embedding and syntax-based distances. </li> <li>For the embedding distance we compute the L2 distance </li> <li>between the embedding of+the code snippets where the embedding is derived from a pre-trained CodeGenMono 350M model [NPH 23]. </li> <li>For the syntax-based distance we calculate the (string) edit distance between the abstract syntax trees (ASTs) of two given code snippets.  </li> <li> </li> </ul>"},{"location":"KB/Textbooks%20are%20all%20you%20need/#conclusion","title":"Conclusion","text":"<ul> <li>Just as a comprehensive, well-crafted textbook can provide a student with the necessary knowledge to master a new subject, our work demonstrates the remarkable impact of high-quality data in honing a language model's proficiency in code- generation tasks. </li> <li>By crafting \"textbook quality\" data we were able to train a model that surpasses almost all open-source models on coding benchmarks such as HumanEval and MBPP despite being 10x smaller in model size and 100x smaller in dataset size. </li> <li>phi-1 is specialized in Python coding </li> <li>phi-1 lacks the domain-specific knowledge of larger models such as programming with specific APIs or using less common packages. </li> <li>due to the structured nature of the datasets and the lack of diversity in terms of language and style, phi-1 is less robust to stylistic variations or errors in the </li> </ul>"},{"location":"KB/Textbooks%20are%20all%20you%20need/#limitation-of-phi-1","title":"Limitation of Phi-1","text":"<ul> <li>Our model is sensitive to various perturbations of prompts. </li> <li>First, its performance drops significantly as the length of the prompt increases, as it tends to ignore, forget or misinterpret parts of the prompt when it is too long </li> <li>phi-1 demonstrates less robustness in handling natural language compared to ChatGPT or StarCoder, particularly with ambiguous prompts. </li> <li>This may be because we filter out certain types of data from the training process to guarantee textbook-level quality. </li> <li>A primary constraint of our model, particularly when contrasted with alternatives like StarCoder, lies in its performance on tasks involving counting and spatial reasoning </li> </ul>"},{"location":"KB/Textless%20Speech%20Emotion%20Conversion/","title":"Textless Speech Emotion Conversion","text":""},{"location":"KB/Textless%20Speech%20Emotion%20Conversion/#textless-speech-emotion-conversion","title":"Textless Speech Emotion Conversion","text":"<ul> <li>Textless Speech Emotion Conversion Using Discrete and Decomposed Representations</li> <li>Speech emotion conversion</li> <li>modifying the perceived emotion of a speech utterance while preserving the lexical content and speaker identity</li> <li>spoken language translation task</li> <li>decomposition of the speech signal into discrete learned representations, consisting of phonetic-content units, prosodic features, speaker, and emotion</li> <li>modify the speech content by translating the phonetic-content units to a target emotion, and then predict the prosodic features based on these units</li> <li>speech waveform is generated by feeding the predicted representations into a neural vocoder</li> <li>beyond spectral and parametric changes of the signal</li> <li>model non-verbal vocalizations, such as laughter insertion, yawning removal, etc</li> </ul>"},{"location":"KB/Thalamus/","title":"Thalamus","text":""},{"location":"KB/Thalamus/#thalamus","title":"Thalamus","text":"<ul> <li>Serves as a relay station for almost all information that comes and goes to the cortex.</li> <li>It plays a role in pain sensation, attention, alertness and memory.</li> </ul>"},{"location":"KB/The%20Behavior%20of%20Tutoring%20Systems/","title":"The Behavior of Tutoring Systems","text":""},{"location":"KB/The%20Behavior%20of%20Tutoring%20Systems/#the-behavior-of-tutoring-systems","title":"The Behavior of Tutoring Systems","text":"<ul> <li>Kurt VanLehn</li> </ul>"},{"location":"KB/The%20Behavior%20of%20Tutoring%20Systems/#intro","title":"Intro","text":"<ul> <li>Tutoring systems are described as having two loops.</li> <li>The outer loop executes once for each task, where a task usually consists of solving a complex, multi-step problem</li> <li>The inner loop executes once for each step taken by the student in the solution of a task. The inner loop can give feedback and hints on each step. The inner loop can also assess the student's evolving competence and update a student model, which is used by the outer loop to select a next task that is appropriate for the student.</li> <li>A task usually takes several minutes to an hour or so. Most tutors assume that the student is working alone on a task, but some (e.g., Zachary et al., 1999) have the student work as one member of a multi-student team.</li> <li>The tasks and the tutor's user interface are usually designed so that completing a task requires multiple steps, where a step is a user interface action that the student takes in order to achieve a task.</li> <li>Let us use knowledge for the information possessed by students that determines their behavior on task. Let us also assume that knowledge can be decomposed, and let us use the term Knowledge Component for the units into which it is decomposed.</li> <li>Knowledge Component</li> <li>Learning Event</li> <li>Modeling Transfer</li> <li>Predicting Student learning Curve</li> <li>Tutor</li> </ul>"},{"location":"KB/The%20Behavior%20of%20Tutoring%20Systems/#the-outer-loop","title":"THE OUTER LOOP","text":"<ul> <li>The main responsibility of the outer loop is to decide which task the student should do next. Its other responsibilities, such as presenting the task to the student, are more mundane and will not be mentioned again. The main design issues are (1) selecting a task intelligently and (2) obtaining a rich set of tasks to select from.</li> </ul>"},{"location":"KB/The%20Behavior%20of%20Tutoring%20Systems/#task-selection","title":"Task Selection","text":"<ul> <li>The outer loop displays a menu and lets the student select the next task.</li> <li>The outer loop assigns tasks in a fixed sequence</li> <li>Mastery learning</li> <li>Macroadaptation</li> <li>In addition to selecting a task, some tutoring systems also select a mode for the task. For instance, Steve can either (1) demonstrate how to do the task by taking each step itself and explaining it, or (2) hint each step before the student attempts it, or (3) let the student try to solve the task without such unsolicited hints.</li> <li>In addition to providing some kind of mechanism for selecting tasks, the designer must provide a set of tasks for the outer loop to select from. It is often surprising how many problems are necessary in order to field a tutoring system. For a 13 week semester at 10 problems per week, the tutoring system needs 130 problems at minimum</li> <li>Ideally, the tutor can generate its own tasks when given a specification of the desired characteristics.</li> <li>For instance, given a specification of a Knowledge Component to be taught, the SQL- Tutor (Martin &amp; Mitrovic, 2002) generates a database query, written in SQL, that involves the Knowledge Component. A human author then writes text for a problem that has this database query as its solution. Using this technique, a human author was able to create 200 problems in about 3 hours\u2014 enough for a 6 week instructional module in an SQL course. Such programs are called problem generators.</li> </ul>"},{"location":"KB/The%20Behavior%20of%20Tutoring%20Systems/#the-inner-loop","title":"THE INNER LOOP","text":"<ul> <li>Whereas the outer loop is about tasks, the inner loop is about steps within a task</li> </ul>"},{"location":"KB/The%20Behavior%20of%20Tutoring%20Systems/#minimal-feedback","title":"MINIMAL FEEDBACK","text":"<ul> <li>Minimal feedback usually indicates whether a step is correct or incorrect, although other categories are sometimes used as well.</li> </ul>"},{"location":"KB/The%20Behavior%20of%20Tutoring%20Systems/#categories-of-minimal-feedback","title":"Categories of Minimal Feedback","text":"<ul> <li>Although most tutoring systems use just two categories, correct and incorrect, it is possible to use others.</li> <li>Suppose a step is not part of an ideal solution to the problem, but it might be part of a non-ideal solution. The instructors might wish to consider this as a third category for minimal feedback\u2014correct but non-optimal</li> <li>For instance, when students solve physics problems on Andes, they can enter an equation that is true of the given physical situation but is not necessary for solving the problem.</li> <li>If instructors sometimes disagree on what makes for the best solution to the problem, it might be wise to subcategorize non-optimal. For instance, because some Sherlock instructors emphasize reducing time and others emphasize reducing costs, Sherlock could subcategorize non-optimal steps as wastes time or wastes parts. In short, the categories used for minimal feedback should reflect the pedagogical policies of the instructors.</li> <li>If a step cannot be classified as into one of the minimal feedback categories (correct, incorrect, non-optimal, etc.), then it lands in an unrecognizable classification.</li> <li>There are basically just three ways to treat such unrecognizable steps. (1) Some tutoring systems, such as the Algebra Cognitive Tutor, assume that they can recognize all correct steps, so they treat unrecognizable steps as incorrect. (2) Other tutoring systems, such as the SQL-Tutor, assume that students will sometimes produce novel, correct solutions, so they treat unrecognized steps as correct. (3) Lastly, the tutoring system could simply tell the student that the step is unrecognizable. In this case, unrecognizable is yet another category for minimal feedback. When to give minimal feedback</li> <li>Immediate feedback: Andes, Algebra Cognitive Tutor, Steve and AutoTutor give feedback immediately after each student step. They vary considerably in how the feedback is presented.</li> <li>Delayed feedback: Only if the step violates a safety regulation will Sherlock give immediate feedback as the student solves a problem. However, after the problem is solved, the student can request a reviewing mode where minimal feedback is given. In particular, as Sherlock replays the student's solution step-by-step, it indicates which steps did not contribute any diagnostic information.</li> <li>Demand feedback: The SQL-Tutor gives feedback only when the student clicks on the Submit button. Because the student can continue working on their solution after receiving such feedback, this does not count as delayed feedback.</li> <li>The feedback policy can be a function of the student's competence. For instance, if the student is nearing mastery, then the feedback is delayed whereas a less competent student would be given the same task with immediate feedback</li> <li>This policy has been observed in human tutoring, and is one instance of fading the scaffolding, (Collins et al., 1989), because feedback is a kind of scaffolding (pedagogically useful help).</li> </ul>"},{"location":"KB/The%20Behavior%20of%20Tutoring%20Systems/#next-step-hints","title":"NEXT-STEP HINTS","text":"<ul> <li> <ol> <li>When should the tutor give a hint about the next step? Should it wait for the student to ask? Should it give unsolicited hints when it detects guessing or floundering? 2. What step should the tutor suggest? For instance, if there are multiple paths to a solution, and the student appears to be following a long complex one, should the tutor suggest starting over? 3. How can the tutor give hints that maximize learning, keep frustration under control, and allow the student to finish the problem?</li> </ol> </li> <li>The common wisdom is that a tutor should give a hint on the next step only if the student really needs it. If the student can enter a correct step by thinking hard enough, then the system should refuse to give a hint even if the student asks for one</li> <li>On the other hand, if the student is likely to waste time and get frustrated by trying in vain to enter a correct step, or if the student is making repeated guesses instead of trying to figure out the next step, then the tutoring system should probably give a hint even if the student doesn't ask for one.</li> <li>DT Tutor</li> <li>Help Abuse</li> <li>Help Refusal</li> </ul>"},{"location":"KB/The%20Behavior%20of%20Tutoring%20Systems/#which-step-to-hint","title":"Which Step to Hint","text":"<ul> <li>The step must be correct.</li> <li>The hinted step should not have been done already by the student.</li> <li>Instructors' preferences should be honored.</li> <li>If the student has a plan for solving the problem or even for just the next step, then the tutor should hint the step that the student is trying to complete.</li> <li>A somewhat more complex case occurs when the student has just made an incorrect step and received minimal negative feedback.</li> <li>In AI, this is called the plan recognition problem</li> </ul>"},{"location":"KB/The%20Behavior%20of%20Tutoring%20Systems/#how-to-hint-the-next-step","title":"How to Hint the Next Step","text":"<ul> <li>Perhaps the most common policy is to construct a short sequence of hints for the next step.</li> <li>The first hints are weak\u2014they divulge little information so that students are encouraged to do most of the thinking themselves. Later hints are stronger.</li> <li>If the step requires only one Knowledge Component, then a standard hint sequence is Point, Teach and Bottom-out (Hume, Michael, Rovick, &amp; Evens, 1996)</li> <li>Pointing hints mention problem conditions that should remind the student of the Knowledge Component's relevance.</li> <li>Teaching hints describe the Knowledge Component briefly and show how to apply it.</li> <li>Bottom-out hints tell the student the step</li> </ul>"},{"location":"KB/The%20Behavior%20of%20Tutoring%20Systems/#error-specific-feedback","title":"ERROR-SPECIFIC FEEDBACK","text":"<ul> <li>The service consists of analyzing an incorrect step in order to determine the incorrect Learning Event(s) that led to it, then giving instruction that is aimed at preventing that incorrect Learning Event(s) from occurring again</li> <li>There are many techniques for diagnosing errors. Most require that authors observe student errors, figure out what is causing a common error, write an appropriate error type for it, and implement some way to recognize such errors.</li> <li>FOIL: First, Outer, Inner and Last</li> </ul>"},{"location":"KB/The%20Behavior%20of%20Tutoring%20Systems/#how-to-give-error-specific-feedback","title":"How to Give Error-specific Feedback","text":"<ul> <li>The main purpose of error-specific feedback is to get the student to change their knowledge so that they will not make this mistake again</li> <li>Correcting one's knowledge is sometimes compared to debugging a piece of software (Ohlsson, 1996). A programmer must first find evidence that the bug exists, then find out what the bug is, and then fix the bug. When tutees are not working with a tutor, they must do the whole self-debugging process themselves. They must first notice that a step is incorrect, then find the flaw in their reasoning and knowledge, then figure out what the correct learning events and knowledge components should be</li> <li>Many tutors present feedback as a sequence of hints that are loosely associated with the stages of self-debugging. When the student enters an incorrect step, the tutor begins the sequence by simply giving minimal feedback. This is like providing the student with evidence of a knowledge bug but giving no further help toward identifying the bug or correcting it.</li> </ul>"},{"location":"KB/The%20Behavior%20of%20Tutoring%20Systems/#when-to-give-error-specific-feedback","title":"When to Give Error-specific Feedback","text":"<ul> <li>Students sometimes make careless errors, called slips in psychology (Norman, 1981), but fail to notice that they have made them, which can cause them to waste time looking for deep, potential misconceptions.</li> <li>To ameliorate into slips and potential this, Andes divides error misunderstandings. types</li> <li>Slips are often made by the experts, including the instructors.</li> <li>A potential misunderstanding is an error type that could be due to many factors, including incorrect beliefs, but it is almost never seen in expert's work</li> <li>When a student enters an incorrect step that is classified as a slip, then Andes gives the error specific remediation immediately, e.g., You forgot to include a unit on a number. If the error is classified as a potential misunderstanding, then Andes merely turns the incorrect step red, and lets the student ask for an error-specific hint if they want one.</li> <li>Some student steps contain two or more errors. In order to keep the communication simple, the tutoring system should probably respond to only one of them. Students typically fix that error only, so the tutoring system can then mention the second error</li> </ul>"},{"location":"KB/The%20Behavior%20of%20Tutoring%20Systems/#what-kind-of-assessment-is-required","title":"What Kind of Assessment is Required?","text":"<ul> <li>A fundamental issue is the grain-size or granularity of the assessment.</li> <li>The granularity of an assessment refers to the degree of aggregation over the task domain's knowledge. An assessment is fine-grained if it provides, for instance, a probability of mastery for each Knowledge Component in the task domain. An assessment is coarse-grained if it provides a single number that indicates the student's overall competence.</li> <li>Assessments are decision aids, and as a general heuristic, the bigger the decision, the coarser the required assessment. If a decision affects a whole semester, e.g., whether the student needs to retake a</li> <li>required course, then the assessment should cover the whole semester and lead ultimately to a yes-no decision, so a single number per student is appropriate.</li> <li>If a decision affects only, say, whether the tutor starts at the beginning of a hint sequence or in the middle, then only a small part of a fine-grained assessment is relevant</li> <li>The general idea is that if the decision is small, in that it affects only a small amount of instructional time, then only a small amount of the domain's knowledge can be accessed during that time and thus the relevant decision aid is the student's competence on just that knowledge.</li> <li>Tutors make many small decisions, so they are the main customers for fine-grained assessments.</li> <li>Coarse-grained assessment</li> <li>Fine Grained assesment</li> </ul>"},{"location":"KB/The%20Behavior%20of%20Tutoring%20Systems/#issues-with-assesment","title":"Issues with Assesment","text":"<ul> <li>There are many other issues involved with assessment. Here are a few:</li> <li>There is a big difference between little evidence and mixed evidence. If one merely takes the frequency of success relative to opportunities, then 0.5 can mean both 1 success and 1 failure (little evidence) or 20 successes and 20 failures (mixed evidence).</li> <li>Students should be learning, so their knowledge should be changing. When should old evidence be ignored?</li> <li>Should help given by the tutoring system be counted as evidence of learning or of lack of knowledge?</li> <li>Are all learning events equally difficult? If not, then item response theory (IRT) can be used so that success on easy learning events provides less evidence of competence than success on difficult learning events.</li> <li>If the tutoring system includes error-specific feedback based on error types, should it somehow include the frequency of occurrence of the error types in its assessments?</li> <li>Prior probabilities of mastery are not independent. If a student has not mastered a Knowledge Component that is taught early in the course, then it is less likely that the student has mastered.</li> <li>Knowledge components that appear later.</li> </ul>"},{"location":"KB/The%20Behavior%20of%20Tutoring%20Systems/#examples-of-tutoring-systems","title":"Examples of Tutoring Systems","text":"<ul> <li>Steve</li> <li>Algebra Cognitive Tutor</li> <li>Andes</li> <li>Sherlock</li> <li>AutoTutor</li> <li>SQL-Tutor</li> </ul>"},{"location":"KB/The%20Differentiation%20Condition/","title":"The Differentiation Condition","text":""},{"location":"KB/The%20Differentiation%20Condition/#the-differentiation-condition","title":"The Differentiation Condition","text":"<ul> <li>A sentence containing a quantified phrase headed by each can only be true of event structures which are totally distributive. Each individual object in the restrictor set of the quantified phrase must be associated with its own subevent, in which the predicate applies to that object, and which can be differentiated in some way from the other subevents.</li> </ul>"},{"location":"KB/The%20Effect%20of%20Three%20Consecutive%20Context%20Sentences%20on%20EFL%20Vocabulary-Learning/","title":"The Effect of Three Consecutive Context Sentences on EFL Vocabulary-Learning","text":""},{"location":"KB/The%20Effect%20of%20Three%20Consecutive%20Context%20Sentences%20on%20EFL%20Vocabulary-Learning/#the-effect-of-three-consecutive-context-sentences-on-efl-vocabulary-learning","title":"The Effect of Three Consecutive Context Sentences on EFL Vocabulary-Learning","text":"<ul> <li> <p>Sasan Baleghizadeh and Mohammad Naseh Nasrollahy Shahry</p> </li> <li> <p>effect of three consecutive context sentences instead of one</p> </li> <li>Thirty-three Iranian EFL learners were asked to learn 20 challenging English words in two conditions</li> <li>The results of both immediate and delayed post-tests revealed a positive role for context sentences in vocabulary learning</li> <li>It is proposed that successful vocabulary learning through context sentences could be attributed to the mixed effects of both context and frequency of occurrence.</li> </ul>"},{"location":"KB/The%20Effect%20of%20Three%20Consecutive%20Context%20Sentences%20on%20EFL%20Vocabulary-Learning/#results","title":"Results","text":"<ul> <li>seven students knew at least one of the target words, so their scores on the posttests were excluded</li> <li>data were analyzed by using a paired sample t-test because it was a within-subjects comparison and the scores on both learning conditions were related</li> <li>the participants' performance on words that had appeared in context sentences plus their L1 equivalents was significantly better than their performance on words paired only with their L1 equivalent</li> <li>Discussion</li> <li>Learners exposed to context sentences did better in terms retaining words, and they were also able to compose more correct sentences with them</li> <li>The learners who were exposed to context sentences had three sentences on which to draw as models, and it is plausible that part of their better sentence-making scores could be accounted for by their exposure to these sentences.</li> <li>frequency and context have an important place in vocabulary-learnin</li> <li>lthough learning new words through context-free activities such as working on word pairs might be a powerful tool to enhance one's breadth of vocabulary knowledge, this study provides strong evidence that adding a minimum of three contextually appropriate sentences to L1 glosses results in a significant improvement in vocabulary-learning</li> <li>need to furnish learners with more sample sentences when it comes to presenting vocabulary</li> <li>authors of textbooks seem to have a propensity for presenting isolated words either in designated boxes or in the context of a passage, which essentially provides only one context for the given word</li> <li>It appears that students would be in a better position to learn and retain new words if they were provided with repeated contexts through exposure to more sample sentences</li> <li>In other words, is it the elaborative nature of the context, or is it the frequency of occurrence that promotes better vocabulary learning? Future research is warranted to unravel this issue.</li> </ul>"},{"location":"KB/The%20Programmers%20Brain/","title":"The Programmers Brain","text":"","tags":["deeplearning"]},{"location":"KB/The%20Programmers%20Brain/#the-programmers-brain","title":"The Programmers Brain","text":"<ul> <li>Short + long term memory - problem + software knowledge</li> <li>reading complicated/new code<ul> <li>chunking : words vs letters</li> </ul> </li> <li>Programmers to reproduce code<ul> <li></li> <li>experts rely on a bunch of things to \"do well\"</li> </ul> </li> </ul>","tags":["deeplearning"]},{"location":"KB/The%20Repulsive%20Potential/","title":"The Repulsive Potential","text":""},{"location":"KB/The%20Repulsive%20Potential/#the-repulsive-potential","title":"The Repulsive Potential","text":"<ul> <li>The robot is pushed away from obstacles and attracted to the goal</li> <li> \\[U_{rep}(q)=\\frac{\\eta}{D(q,Q)}\\] </li> <li></li> </ul>"},{"location":"KB/The%20Reward%20Experiment/","title":"The Reward Experiment","text":""},{"location":"KB/The%20Reward%20Experiment/#the-reward-experiment","title":"The Reward Experiment","text":"<ul> <li>\u201cWhy aren\u2019t we always prepared?\u201d  <ul> <li>Is it a matter of motivation?  </li> <li>Reward bocks: flat(ter) preparation curves?</li> </ul> </li> <li>Reward blocks: more memory effects<ul> <li>Cognition Hazard Rates</li> </ul> </li> <li>Reward blocks: less memory effects<ul> <li>Cognitive fMTP</li> </ul> </li> <li></li> <li>Fanning<ul> <li>smaller if reward</li> <li>less effects of previous trial</li> </ul> </li> </ul>"},{"location":"KB/The%20Reward%20Experiment/#findings","title":"Findings","text":"<ul> <li> <p>The effects of reward and brightness on preparation</p> <ul> <li>Additive effects : neither affects the slope</li> <li>even when motivated, preparation depends on FP</li> <li> <p>Stimulus visibility does not interact with preparation</p> <ul> <li>Maybe not a visual attention process</li> </ul> </li> <li> <p></p> </li> <li>Reward has more effects when targets are highly visible</li> <li>Interaction : Reward * Brightness</li> <li></li> <li>Effects on accuracy</li> <li>Reward blocks\u2192 higher accuracy  </li> <li>High visibility \u2192 higher accuracy  </li> <li>More errors with longer foreperiod\u2026.  <ul> <li>\u2026But only when rewarded/motivated  </li> <li>\u2026And mainly when visibility low</li> </ul> </li> <li></li> <li>Effects on memory from past trials</li> <li>Past trial effects \\(\\(fp \\ast fp(n-1)\\)\\)</li> <li>This effect (the fanning) is essentially constant across target visibility and reward  </li> <li>If anything: a little bit larger when there is no reward.</li> <li></li> <li>Effects on memory</li> <li>Up to n-5</li> <li>When there is reward, there is slightly \u2018faster forgetting\u2019</li> <li>Faster forgetting when rewarded slightly</li> <li></li> </ul> </li> </ul>"},{"location":"KB/The%20Self%20Organization%20of%20Explicit%20Attitudes/","title":"The Self Organization of Explicit Attitudes","text":""},{"location":"KB/The%20Self%20Organization%20of%20Explicit%20Attitudes/#the-self-organization-of-explicit-attitudes","title":"The Self Organization of Explicit Attitudes","text":"<ul> <li>Michael T. Wojnowicz, Melissa J. Ferguson, Rick Dale, and Michael J. Spivey</li> </ul>"},{"location":"KB/The%20Self%20Organization%20of%20Explicit%20Attitudes/#abstract","title":"ABSTRACT","text":"<ul> <li>How do minds produce explicit attitudes over several hundred milliseconds?</li> <li>implicit biases beyond cognitive control and subjective awareness, yet mental processing may culminate in an explicit attitude that feels personally endorsed and corroborates voluntary intentions</li> <li>self-reported explicit attitudes derive from a continuous, temporally dynamic process, whereby multiple simultaneously conflicting sources of information selforganize into a meaningful mental representation</li> <li>While our participants reported their explicit (like vs. dislike) attitudes toward White versus Black people by moving a cursor to a ''like'' or ''dislike'' response box, we recorded streaming xand y-coordinates from their hand-movement trajectories</li> <li>participants' hand-movement paths exhibited greater curvature toward the ''dislike'' response when they reported positive explicit attitudes toward Black people than when they reported positive explicit attitudes toward White people</li> <li>these trajectories were characterized by movement disorder and competitive velocity profiles that were predicted under the assumption that the deliberate attitudes emerged from continuous interactions between multiple simultaneously conflicting constraints.</li> <li>For example, an implicit attitude toward a stimulus can be unintentionally activated by the mere presence of that stimulus.</li> <li>Given that many people demonstrate spontaneous initial biases toward traditionally stigmatized groups, how do they overcome these biases to explicitly report positive attitudes toward the same groups?</li> <li>coexistence of multiple attitudes and an emphasis on the temporal dynamics of how they influence evaluative responses</li> <li>Rather than selecting among the specific theories, we invoked the encompassing theoretical framework of self-organization to guide an exploration of those temporal dynamics, and made specific predictions for what should result from multiple attitudes interacting over time.</li> <li>In early moments of processing, distributed representations are partially consistent with multiple interpretations because of their proximity to multiple neural population codes.</li> <li>However, a continuous accrual of information causes the distributed pattern to dynamically ''sharpen'' into a confident (selected) interpretation, forcing other, partially activated, competing alternative representations, decisions, or actions to gradually die out.</li> <li>The latter attitude will eventually activate other subsystems, such as language and memory, thus making the attitude seem explicit</li> <li>What makes the first attitude implicit is not necessarily that it was generated in a different subsystem, but simply that it did not hold sway long enough to activate those language and memory subsystems.</li> <li>Mental processing generically involves recurrent processing loops (or cyclic feedback) between higher-order integrative regions and lower-level informational sources (Lamme &amp; Roelfsema, 2000; O'Reilly, 1998; Spivey, 2007)</li> <li>These higher-order integrative regions enforce representational competition, in which increasing the activation of one particular interpretation inhibits alternatives.</li> <li>The unfolding cognitive dynamics may be revealed in continuous motor output</li> <li>Because mental processing is recurrent, motor representations begin specifying movement parameters probabilistically, rather than waiting for a perfectly completed cognitive command</li> <li>If the phrase ''Black people'' evokes elevated dynamic competition between simultaneously active ''like'' and ''dislike'' representations, movement trajectories for ''Black people'' should exhibit evidence of nonlinear dynamics in their velocity profiles, as well as increased spatial disorder in the curviness of the trajectories.</li> </ul>"},{"location":"KB/The%20Self%20Organization%20of%20Explicit%20Attitudes/#experiment-1","title":"EXPERIMENT 1","text":""},{"location":"KB/The%20Self%20Organization%20of%20Explicit%20Attitudes/#method","title":"Method","text":"<ul> <li>Streaming xand y-coordinates of mouse-cursor movements were recorded from 68 Cornell University undergraduates (43 female and 25 male) as they performed a simple explicit-attitude task.</li> <li>2 s for participants to view the evaluative response options</li> <li>Participants then clicked on a small box at the bottom of the screen to reveal a stimulus word or phrase and dragged the mouse toward their selected evaluative response to that stimulus</li> <li>Responses to the two stimulus repetitions were averaged together to yield a single measurement for each participant for all statistical analyses.</li> </ul>"},{"location":"KB/The%20Self%20Organization%20of%20Explicit%20Attitudes/#results-and-discussion","title":"Results and Discussion","text":"<ul> <li>Compared with the trajectories for ''White people,'' the trajectories for ''Black people'' curved significantly more toward the ''dislike'' response option observed differential motor curvatures could have been generated by a stage-based sequence of decisional commands, rather than by continuous motor attraction to the ''dislike'' response.</li> <li>If motor execution required the complete prespecification of a unique target destination, rather than tracking of motor trajectory parameters that continuously evolved midflight, then a mean trajectory could look differentially curved because of the effect of averaging in replanned trajectories</li> <li>To accommodate the empirical mean trajectory, which initially moved upward rather than actually toward ''dislike,'' such an account would need to predict a bimodal distribution of curvatures that included some trajectories that were very curved and others that were not curved.</li> <li>However, the distribution of trajectory curvatures shows no evidence of bimodality The standard cutoff for inferring bimodality in a distribution is b &gt; 0.55</li> <li>Neither the ''Black people'' nor the ''White people'' trajectories had distributions that met this cutoff, and in fact, the ''Black people'' trajectories formed a distribution of movement curvature that was closer to normal (b 5 0.24, skewness 5 0.613, kurtosis 5 2.57) than the ''White people'' trajectories (b 5 0.301, skewness 5 0.98, kurtosis 5 3.44).</li> <li>Velocity profiles were constructed by analyzing the temporal derivatives of motion toward the ''like'' response box along the x-coordinate.</li> <li>Our velocity predictions came from Usher and McClelland's (2003) differential equations for modeling the dynamics of competition between mental representations</li> <li>where, in this case, x1 and x2 represent the activations of the mental representations for ''like'' and ''dislike,'' dx1 and dx2 represent the change in the activation of the two mental representations in a time step of size dt, I1 and I2 represent excitatory input to the representations from informational sources, bf1 and bf2 represent the inhibitory input from each mental representation to the other (lateral inhibition), and fi (where i 5 1 or 2) is equal to xi if xi is greater than zero.</li> <li>differential equations for competition dynamics, a strong evaluative competitor (dislike, x2) sends intensified and prolonged lateral inhibition (bf2) to the ''like'' evaluation (x1)</li> <li>Thus, strong competition alters the velocity profile of the movement toward the evaluative attractor (dx1/dt), reducing velocity toward the attractor early on in processing</li> <li>as the more active alternative begins to win the competition, this lateral inhibition is gradually lifted, thus increasing velocity later in processing to produce greater acceleration</li> <li>Moreover, this particular dynamic pattern (reduced early velocity and greater later acceleration) should lead to greater peak velocity, if jerk is minimized as the system achieves equivalent integral under the curve (where the integral represents net change in activation or location)</li> <li>The spatial-disorder analysis investigated the regularity of change in x-coordinate location over time</li> <li>To investigate whether the ''Black people'' trajectories had more wiggles, blips, and other irregularities than the ''White people'' trajectories, we analyzed x-coordinate location over time, but only after the trajectory began moving in the positive x direction</li> <li>The ''Black people'' trajectories had significantly greater deviation from the sigmoidal fit</li> <li>indicated disorderly variation around the x dimension in those trajectories.</li> </ul>"},{"location":"KB/The%20Self%20Organization%20of%20Explicit%20Attitudes/#experiment-2","title":"EXPERIMENT 2","text":"<ul> <li>our claim is that multiple, partially active mental representations compete for the privilege of driving evaluative responses, imposing a set of response options that are not particularly competitive should change the motor dynamics</li> </ul>"},{"location":"KB/The%20Self%20Organization%20of%20Explicit%20Attitudes/#method_1","title":"Method","text":"<ul> <li>Sixty-six Cornell University undergraduates (40 female and 26 male) were asked to classify words (e.g., ''ice cream,'' ''sunshine,'' ''boron'') as something they liked (''like'') or as the name of a chemical element (''chemical'')</li> <li>We analyzed data only from the 63 participants who consistently chose the ''like'' response for both ''Black people'' and ''White people'' on both repetitions of these trials, and who reported in a poststudy questionnaire that they were not forced into selecting ''like'' by the paradigm.</li> </ul>"},{"location":"KB/The%20Self%20Organization%20of%20Explicit%20Attitudes/#results","title":"Results","text":"<ul> <li>According to statistical analyses on maximum deviation and distance traveled, the ''Black people'' and ''White people'' trajectories no longer differed in their curvature toward the competing respons</li> <li>Thus, the results of Experiment 1 are not attributable merely to responses to ''Black people'' involving a longer latency to settle on a positive evaluation</li> <li>thereby drifting for longer in empty regions of movement space before curving</li> <li>toward the ''like'' response box</li> <li>Rather, the ''dislike'' response option in Experiment 1 was actively pulling movement trajectories toward it, in a way that the ''chemical'' response option in Experiment 2 did not.</li> </ul>"},{"location":"KB/The%20Self%20Organization%20of%20Explicit%20Attitudes/#experiment-3","title":"EXPERIMENT 3","text":"<ul> <li>Experiment 1 may have diverged because of subtle confounds that do not refer to people at all.</li> </ul>"},{"location":"KB/The%20Self%20Organization%20of%20Explicit%20Attitudes/#method_2","title":"Method","text":"<ul> <li>Seventy-one Cornell University undergraduates (37 female and 34 male) were asked to classify stimuli as something they liked (''like'') or disliked (''dislike'')</li> <li>The crucial stimuli in this experiment were ''African Americans'' and ''Caucasians. Results</li> <li>The trajectories for ''African Americans'' curved significantly more toward the ''dislike'' response than the trajectories for ''Caucasians,</li> <li>The motor trajectories evolved over time in accordance with the competitive velocity predictions, as reported in Experiment</li> <li>The ''African Americans'' trajectories, compared with the ''Caucasians'' trajectories, had significantly greater maximum xcoordinate acceleration</li> <li>Moreover, as we found for ''Black people'' trajectories in Experiment 1, the ''African Americans'' trajectories exhibited greater spatial disorder than the ''Caucasians'' trajectories, even after moving toward the ''like'' response, as indicated by significantly greater mean deviation from the sigmoidal fi</li> </ul>"},{"location":"KB/The%20Self%20Organization%20of%20Explicit%20Attitudes/#general-discussion","title":"GENERAL DISCUSSION","text":"<ul> <li>People's hand-movement trajectories for explicitly evaluating ''Black people'' and ''White people'' were distinct as measured by three properties of movement dynamics: shape, time, and order.</li> <li>explicit attitudes evolve through continuous temporal dynamics during real-time mental processing, with graded motor curvature revealing the influence of tendencies toward dislike</li> <li>evidence for cleanly separated (i.e., discrete, rather than continuous) explicit decisions, in which an initial response was executed solely toward the ''dislike'' response box and then a corrective response was executed midflight toward the ''like'' response box.</li> <li>Rather, the results suggest that a dynamic competition process may be what allows a single explicit attitude choice to emerge from multiple, potentially conflicting evaluative influences (e.g., Busemeyer &amp; Townsend, 1993; Usher &amp; McClelland, 2003)</li> <li>the mind may host a continuously evolving blend of (implicit) evaluative decisions from which the eventual (explicit) behavioral choice emerges.</li> </ul>"},{"location":"KB/The%20Self%20Organization%20of%20Explicit%20Attitudes/#pictures","title":"Pictures","text":""},{"location":"KB/The%20Unreliability%20of%20Saliency%20Methods/","title":"The Unreliability of Saliency Methods","text":""},{"location":"KB/The%20Unreliability%20of%20Saliency%20Methods/#the-unreliability-of-saliency","title":"The Unreliability of Saliency","text":"<ul> <li>@kindermansReliabilitySaliencyMethods2017</li> <li> unreliable</li> <li>Pieter-Jan Kindermans, Sara Hooker, Julius Adebayo, Maximilian Alber, Kristof T. Sch\u00fctt, Sven D\u00e4hne, Dumitru Erhan, Been Kim <code>toc</code></li> </ul>"},{"location":"KB/The%20elephant%20in%20the%20interpretability%20room/","title":"The elephant in the interpretability room","text":""},{"location":"KB/The%20elephant%20in%20the%20interpretability%20room/#the-elephant-in-the-interpretability-room","title":"The Elephant in the Interpretability Room","text":"<ul> <li>@bastingsElephantInterpretabilityRoom2020</li> </ul>"},{"location":"KB/The%20elephant%20in%20the%20interpretability%20room/#intro","title":"Intro","text":"<ul> <li>While attention conveniently gives us one weight per input token and is easily extracted, it is often unclear toward what goal it is used as explanation.</li> <li>that often that goal, whether explicitly stated or not, is to find out what input tokens are the most relevant to a prediction, and that the implied user for the explanation is a model developer</li> <li>For this goal and user, we argue that input saliency methods are better suited, and that there are no compelling reasons to use attention, despite the coincidence that it provides a weight for each input.</li> <li></li> </ul>"},{"location":"KB/The%20elephant%20in%20the%20interpretability%20room/#the-attention-debate","title":"The Attention Debate","text":"<ul> <li>summarize the debate on whether attention is explanation</li> <li>mostly features simple BiLSTM text classifiers</li> <li>Unlike Transformers (Vaswani et al., 2017), they only contain a single attention mechanism, which is typically MLP-based (Bahdanau et al., 2015)</li> <li></li> </ul>"},{"location":"KB/The%20elephant%20in%20the%20interpretability%20room/#is-attention-not-explanation","title":"Is Attention (not) Explanation?","text":"<ul> <li>Jain and Wallace (2019) show that attention is often uncorrelated with gradientbased feature importance measures, and that one can often find a completely different set of attention weights that results in the same prediction</li> <li>Serrano and Smith (2019) find, by modifying attention weights, that they often do not identify those representations that are most most important to the prediction of the model</li> <li>Finally, Pruthi et al. (2020) propose a method to produce deceptive attention weights. Their method reduces how much weight is assigned to a set of 'impermissible' tokens, even when the models demonstratively rely on those tokens for their predictions.</li> </ul>"},{"location":"KB/The%20elephant%20in%20the%20interpretability%20room/#was-the-right-task-analyzed","title":"Was the Right Task Analyzed","text":"<ul> <li>the performance of an NMT model degrades substantially if uniform weights are used, while random attention weights affect the text classification performance minimally.</li> <li>even for the task of MT, the first case where attention was visualized to inspect a model (\u00a71), Ding et al. (2019) find that saliency methods (\u00a73) yield better word alignments.</li> </ul>"},{"location":"KB/The%20elephant%20in%20the%20interpretability%20room/#can-attention-be-improved","title":"Can Attention Be Improved","text":"<ul> <li>Mohankumar et al. (2020) observe high similarity between the hidden representations of LSTM states and propose a diversity-driven training objective that makes the hidden representations more diverse across time steps</li> <li>using representation erasure that the resulting attention weights result in decision flips more easily as compared to vanilla attention</li> <li>Deng et al. (2018) propose variational attention as an alternative to the soft attention of Bahdanau et al. (2015), arguing that the latter is not alignment, only an approximation thereof</li> <li> <p>additional benefit of allowing posterior alignments, conditioned on the input and the output sentences.</p> </li> <li> <p>Saliency vs Attention</p> </li> </ul>"},{"location":"KB/The%20elephant%20in%20the%20interpretability%20room/#attention-is-not-not-interesting","title":"Attention is not not Interesting","text":"<ul> <li>Voita et al. (2019) and Michel et al. (2019) analyze the role of attention heads in the Transformer architecture and identify a few distinct functions they have, and Strubell et al. (2018) train attention heads to perform dependency parsing, adding a linguistic bias</li> <li>Strout et al. (2019) demonstrate that supervised attention helps humans accomplish a task faster than random or unsupervised attention</li> </ul>"},{"location":"KB/The%20elephant%20in%20the%20interpretability%20room/#beyond-saliency","title":"Beyond Saliency","text":"<ul> <li>counterfactual analysis might lead to insights, aided by visualization tools (Vig, 2019; Hoover et al., 2020; Abnar and Zuidema, 2020)</li> <li>The DiffMask method of DeCao et al. (2020) adds another dimension: it not only reveals in what layer a model knows what inputs are important, but also where important information is stored as it flows through the layers of the mode</li> </ul>"},{"location":"KB/The%20elephant%20in%20the%20interpretability%20room/#limitations-of-saliency","title":"Limitations of Saliency","text":"<ul> <li>changes in the predicted probabilities may be due to the fact that the corrupted input falls off the manifold of the training data (Hooker et al., 2019)</li> <li>a drop in probability can be explained by the input being OOD and not by an important feature missing</li> <li>at least some of the saliency methods are not reliable and produce unintuitive results (Kindermans et al.</li> <li>2017) or violate certain axioms (Sundararajan et al., 2017).</li> <li>A more fundamental limitation is the expressiveness of input saliency methods</li> <li>Obviously, a bag of per-token saliency weights can be called an explanation only in a very narrow sense</li> <li>One can overcome some limitations of the flat representation of importance by indicating dependencies between important features (for example, Janizek et al. (2020) present an extension of IG which explains pairwise feature interactions) but it is hardly possible to fully understand why a deep non-linear model produced a certain prediction by only looking at the input tokens</li> </ul>"},{"location":"KB/The%20warning%20stimulus%20as%20retrieval%20cue%20The%20role%20of%20associative%20memory%20in%20temporal%20preparation/","title":"The warning stimulus as retrieval cue The role of associative memory in temporal preparation","text":""},{"location":"KB/The%20warning%20stimulus%20as%20retrieval%20cue%20The%20role%20of%20associative%20memory%20in%20temporal%20preparation/#the-warning-stimulus-as-retrieval-cue-the-role-of-associative-memory-in-temporal-preparation","title":"The warning stimulus as retrieval cue The role of associative memory in temporal preparation","text":"<ul> <li>Sander A. Los a,* , Jurre Nieuwenstein a , Anass Bouharab a , David J. Stephens a , Martijn Meeter a , Wouter Kruijne b</li> </ul>"},{"location":"KB/The%20warning%20stimulus%20as%20retrieval%20cue%20The%20role%20of%20associative%20memory%20in%20temporal%20preparation/#abstract","title":"Abstract","text":"<ul> <li>warned reaction time task</li> <li>the warning stimulus (S1) initiates a process of temporal preparation, which promotes a speeded response to the impending target stimulus (S2)</li> <li>participants learn the timing of S2 by storing a memory trace on each trial, which contains a temporal profile of the events on that trial.</li> <li>On each new trial, S1 serves as a retrieval cue that implicitly and associatively activates memory traces created on earlier trials, which jointly drive temporal preparation for S2</li> <li>two different S1s were associated with two different distributions of S1-S2 intervals: one with predominantly short and one with predominantly long intervals</li> <li>Experiments differed regarding the S1 features that made up a pair, ranging from highly distinct (e.g., tone and flash) to more similar (e.g., red and green flash) and verbal (i.e., \"short\" vs \"long\").</li> <li>This cueing effect persisted in a subsequent transfer phase, in which the contingency between S1 and the timing of S2 was broken \u2013 a fact participants were informed of in advance</li> <li>these findings support the role of S1 as an implicit retrieval cue, consistent with MTP.</li> <li>A multiple trace theory of temporal preparation</li> <li>In this paradigm, the researcher varies, within a block of trials, the duration of the foreperiod between a warning stimulus (S1) and a target stimulus (S2), and measures the participant's response time (RT) with respect to S2.</li> <li>as the foreperiod increases, mean RT decreases toward an asymptote (e.g., Niemi &amp; N \u0308 aat  \u0308 anen,  \u0308 1981; Woodrow, 1914), indicating a gradual growth of temporal preparation toward a maximum</li> <li>exponential (\"nonageing\") distribution</li> <li>frequency of consecutive foreperiods decreases according to a fixed rate</li> <li>and the RT \u2013 foreperiod function has been shown to be approximately flat</li> <li>MTP, which makes three main assumptions.</li> <li>within-trial processing dynamics</li> <li>detection of S1 prompts a preactivation of task relevant effectors, which is counteracted throughout the foreperiod by a process of continuous inhibition</li> <li>Inhibition is lifted when S2 is presented, allowing activation to drive response execution</li> <li>when transcranial magnetic stimulation is applied to human motor cortex, the motor evoked potential measured at the corresponding effector has been shown to be smaller during the foreperiod than at baseline, prior to S1 onset</li> <li>Since this reduced activation has been found for all potential effectors in a choice reaction task, it has been argued to reflect a general mechanism of impulse control that prevents premature response</li> </ul>"},{"location":"KB/The%20warning%20stimulus%20as%20retrieval%20cue%20The%20role%20of%20associative%20memory%20in%20temporal%20preparation/#trace-formation","title":"trace formation","text":"<ul> <li>unique memory trace is created on each trial, which contains the temporal profile of inhibition (during the foreperiod) and activation (after S2 occurrence) experienced on that trial, along with representations of S1, S2, and the response to S2</li> <li>each new memory trace is added to an accumulating pool of memory traces created on earlier trials</li> <li>these traces vary in strength</li> <li>strength of each trace is maximal upon its formation and gradually reduces toward an asymptotic value as it grows older</li> </ul>"},{"location":"KB/The%20warning%20stimulus%20as%20retrieval%20cue%20The%20role%20of%20associative%20memory%20in%20temporal%20preparation/#trace-expression","title":"trace expression","text":"<ul> <li>previously formed memory traces jointly determine the state of temporal preparation during the ongoing foreperiod</li> <li>process is initiated on each trial by the presentation of S1</li> <li>as the foreperiod elapses, each retrieved trace contributes to preparation in accordance with its strength and its momentary value of activation or inhibition</li> <li>at each moment during the foreperiod the state of preparation is determined by the ratio of the weighted activation over inhibition values aggregated across memory traces</li> <li>we assume that the state of temporal preparation reached at the moment of S2 presentation determines RT according to an inversely proportional function</li> <li>This relationship can be appreciated by conceiving the state of temporal preparation as the distance of potential neural excitability relative to a fixed motor-action limit</li> <li>the consecutive foreperiods occur with a ratio of 1:2:4:8, temporal preparation is very low just after the presentation of S1 in view of the low ratio of activation over inhibition across memory traces.</li> <li>These dynamics thus give rise to the typically observed steep RT \u2013 foreperiod functio</li> <li>In the case of an exponential distribution (Fig. 1B), where consecutive foreperiods occur with a ratio of 8:4:2:1, activation starts to dominate inhibition quickly after the presentation of S1.</li> <li>Thus, preparation is already close to ceiling by the time the shortest foreperiod has elapsed and it remains at that level if the foreperiod lengthens (Fig. 1D), yielding the characteristically flat RT \u2013 foreperiod function</li> </ul>"},{"location":"KB/The%20warning%20stimulus%20as%20retrieval%20cue%20The%20role%20of%20associative%20memory%20in%20temporal%20preparation/#images","title":"Images","text":""},{"location":"KB/There%20and%20back%20again/","title":"There and back again","text":""},{"location":"KB/There%20and%20back%20again/#there-and-back-again","title":"There and back again","text":"<ul> <li>@rebuffiThereBackAgain2020</li> </ul>"},{"location":"KB/Thesis%20Flow/","title":"Thesis Flow","text":""},{"location":"KB/Thesis%20Flow/#augmentation","title":"Augmentation","text":""},{"location":"KB/Thesis%20Flow/#methods","title":"Methods","text":"<ul> <li>Attentive CutMix </li> <li>AttributeMix</li> <li>AugMix</li> <li>GridMask</li> <li>Hide and Seek </li> <li>Image Mixing and Deletion </li> <li>Intra-Class Part Swapping </li> <li>Puzzle Mix </li> <li>KeepAugment</li> <li>RICAP</li> <li>RandAugment</li> <li>Random Distortion </li> <li>Random Erasing </li> <li>ReMix</li> <li>ResizeMix</li> <li>SMOTE</li> <li>SaliencyMix</li> <li>Sample Pairing </li> <li>Visual Context Augmentation </li> <li>SmoothMix</li> <li>SnapMix</li> <li>SpecAugment</li> <li>Co-Mixup</li> <li>Cut and Mix </li> <li>Data Augmentation via Latent Space Interpolation for Image Classification </li> <li>Data Augmentation with Curriculum Learning </li> </ul>"},{"location":"KB/Thesis%20Flow/#disadvantages","title":"Disadvantages","text":""},{"location":"KB/Thesis%20Flow/#xai","title":"XAI","text":""},{"location":"KB/Thesis%20Flow/#methods_1","title":"Methods","text":"<ul> <li>Adaptive Whitening Saliency </li> <li>Bayesian Rule List </li> <li>CAM</li> <li>Conductance</li> <li>DeconvNet</li> <li>Deep Inside Convolutional Networks </li> <li>Deep Visual Explanation </li> <li>DeepFool</li> <li>DeepLIFT</li> <li>Dynamic visual attention </li> <li>Embedding Human Knowledge into Deep Neural Network via Attention Map </li> <li>Generalizing Adversarial Explanations with Grad-CAM </li> <li>Graph-based visual saliency </li> <li>Guided BackProp </li> <li>Guided GradCAM </li> <li>Influence of image classification accuracy on saliency map estimation </li> <li>Integrated Gradients </li> <li>Interpretation of Neural networks is fragile </li> <li>Noise Tunnel </li> <li>On the overlap between Grad-CAM saliency maps and explainable visual features in skin cancer images </li> <li>RISE</li> <li>Real Time Image Saliency for Black Box Classifiers </li> <li>SAM-ResNet</li> <li>SDR</li> <li>SP-LIME</li> <li>Salience Map </li> <li>Smooth-Grad</li> <li>SmoothGrad Square </li> <li>Summit</li> <li>VarGrad</li> <li>ScoreCAM</li> </ul>"},{"location":"KB/Thesis%20Flow/#disadvantages_1","title":"Disadvantages","text":"<ul> <li>Beware of Inmates Running the Asylum </li> <li>The Unreliability of Saliency Methods </li> </ul>"},{"location":"KB/Thesis%20Flow/#architectures","title":"Architectures","text":"<ul> <li>Res Net </li> <li>Vision Transformer </li> <li>ConvNeXt</li> <li>Mobile Net </li> <li>Vgg</li> <li>Xception</li> </ul>"},{"location":"KB/Theta%20Waves/","title":"Theta Waves","text":""},{"location":"KB/Theta%20Waves/#theta-waves","title":"Theta Waves","text":"<ul> <li>4-9 Hz theta</li> <li>Memory/Decision</li> <li></li> </ul>"},{"location":"KB/Threaded%20Cognition/","title":"Threaded Cognition","text":""},{"location":"KB/Threaded%20Cognition/#threaded-cognition","title":"Threaded Cognition","text":"<ul> <li>Aka no real \"switch\" between one task to next but bottlenecks</li> <li>Cognition is Threaded but overlaps in the sense that different areas can not be accessed if it uses same areas as the other task at the same time</li> <li>If no expertise, consult Declarative memory all the time. Until it's not required anymore if in long term store.</li> </ul>"},{"location":"KB/Thrombosis/","title":"Thrombosis","text":""},{"location":"KB/Thrombosis/#thrombosis","title":"Thrombosis","text":"<ul> <li>A blood clot that forms inside a blood vessel restricting blood flow</li> </ul>"},{"location":"KB/Through-beam/","title":"Through beam","text":""},{"location":"KB/Through-beam/#through-beam","title":"Through-beam","text":"<ul> <li>An object detection system used within a robot's imaging sensor system. A finely focused beam of light is mounted at one end and a detector at the other. When the beam of light is broken, an object is sensed.</li> </ul>"},{"location":"KB/Time%20Dependant%20Vector%20Field/","title":"Time Dependant Vector Field","text":""},{"location":"KB/Time%20Dependant%20Vector%20Field/#time-dependant-vector-field","title":"Time Dependant Vector Field","text":"<ul> <li>Lagrangian Coherent Structure</li> </ul>"},{"location":"KB/Time%20Measuring%20Function/","title":"Time Measuring Function","text":""},{"location":"KB/Time%20Measuring%20Function/#time-measuring-function","title":"Time Measuring Function","text":"<ul> <li>Time measuring function measures the execution time for the specified section in the job or the signal output time of the specified signal.</li> </ul>"},{"location":"KB/Time%20space%20duality/","title":"Time space duality","text":""},{"location":"KB/Time%20space%20duality/#time-space-duality","title":"Time Space Duality","text":"<ul> <li>Array : Instruction operates on multiple data elements at the same time</li> <li>Vector : Instruction operates on multiple data elements in consecutive time steps</li> </ul>"},{"location":"KB/Time/","title":"Time","text":""},{"location":"KB/Time/#time","title":"Time","text":"<ul> <li> \\[\\Delta t = t_{f}-t_{i}\\] </li> </ul>"},{"location":"KB/TinyBERT/","title":"TinyBERT","text":""},{"location":"KB/TinyBERT/#tinybert","title":"TinyBERT","text":"<ul> <li>TinyBERT: Distilling BERT for Natural Language Understanding</li> <li>novel Transformer distillation method to accelerate inference and reduce model size while maintaining accuracy</li> <li>specially designed for knowledge distillation (KD) of the Transformer-based models</li> <li>plenty of knowledge encoded in a large teacher BERT can be effectively transferred to a small student Tiny-BERT</li> <li>GLUE</li> </ul>"},{"location":"KB/Token%20Embedding/","title":"Token Embedding","text":""},{"location":"KB/Token%20Embedding/#token-embedding","title":"Token Embedding","text":"<ul> <li>WordPiece Tokenizer</li> </ul>"},{"location":"KB/Tokenizer/","title":"Tokenizer","text":""},{"location":"KB/Tokenizer/#tokenizer","title":"Tokenizer","text":"<ul> <li>Tokenizer expands the contraction to recover the essential grammatical features of the pronoun and the Verb.</li> <li>Space-delimited languages</li> <li>White space delimited tokens may not be the valid token</li> <li>Chinese and Thai<ul> <li>Words are written in succession with no indication of word boundaries</li> </ul> </li> <li>Word Structure</li> <li>Punctuation</li> </ul>"},{"location":"KB/Top%20Down%20Parsing/","title":"Top Down Parsing","text":""},{"location":"KB/Top%20Down%20Parsing/#top-down-parsing","title":"Top Down Parsing","text":""},{"location":"KB/Tourette%E2%80%99s%20Syndrome/","title":"Tourette\u2019s Syndrome","text":""},{"location":"KB/Tourette%E2%80%99s%20Syndrome/#tourettes-syndrome","title":"Tourette\u2019s Syndrome","text":"<ul> <li>A neurological disorder, beginning in childhood, characterized by repetitive, involuntary movements or vocalizations, called tics.</li> </ul>"},{"location":"KB/Towards%20A%20Rigorous%20Science%20of%20Interpretable%20Machine%20Learning/","title":"Towards A Rigorous Science of Interpretable Machine Learning","text":""},{"location":"KB/Towards%20A%20Rigorous%20Science%20of%20Interpretable%20Machine%20Learning/#towards-a-rigorous-science-of-interpretable-machine-learning","title":"Towards A Rigorous Science of Interpretable Machine Learning","text":"<ul> <li>@doshi-velezRigorousScienceInterpretable2017</li> </ul>"},{"location":"KB/Tower/","title":"Tower","text":""},{"location":"KB/Tower/#tower","title":"Tower","text":"<ul> <li>A component of a deep neural network that is itself a deep neural network without an output layer. Typically, each tower reads from an independent data source. Towers are independent until their output is combined in a final layer.</li> </ul>"},{"location":"KB/Traces%20of%20times%20past%20Representations%20of%20temporal%20intervals%20in%20memory/","title":"Traces of times past Representations of temporal intervals in memory","text":""},{"location":"KB/Traces%20of%20times%20past%20Representations%20of%20temporal%20intervals%20in%20memory/#traces-of-times-past-representations-of-temporal-intervals-in-memory","title":"Traces of times past Representations of temporal intervals in memory","text":"<ul> <li> <p>Niels Taatgen &amp; Hedderik van Rijn</p> </li> <li> <p>The results show that the adjustment of one interval carried over to the other interval, indicating that subjects were not able to completely separate the two representations</p> </li> <li>assumes that the representation of an interval is based on a pool of recent experiences</li> </ul>"},{"location":"KB/Traces%20of%20times%20past%20Representations%20of%20temporal%20intervals%20in%20memory/#representations-of-time","title":"Representations of time","text":"<ul> <li>The distinction between a solid memory representation for both durations, on the one hand, and a \"pool of experiences,\" on the other, does not need to be problematic for the comparison process, if one assumes that both approaches eventually result in the retrieval of a single representation that can be compared to the current clock value.</li> </ul>"},{"location":"KB/Traces%20of%20times%20past%20Representations%20of%20temporal%20intervals%20in%20memory/#bayesian-modeling-approach-by-jazayeri-and-shadlen-2010","title":"Bayesian modeling approach by Jazayeri and Shadlen (2010)","text":"<ul> <li>The assumption of their model is that humans take two factors into account when estimating the duration of an interval</li> <li>One of these factors is the temporal context: What is the range of possible durations for an interval? The second factor is the (self-)knowledge about the imprecision involved in estimating this interval</li> <li>Visual inspection of the results suggests, indeed, that in the FF condition the short interval was estimated as longer and the long interval as shorter, consistent with earlier findings (e.g., Grondin, 2005), and suggesting that both estimates influence each other.</li> <li>estimates of the short interval were influenced by changes in the duration of the long interval, because the short interval's estimations resemble a dampened pattern of the long interval</li> <li>clear interaction between condition and range</li> <li>Linear mixed-effect models provided information about the contributions of individual factors to a dependent variable and about the reliability of the estimates.</li> <li>Previous feedback also modifies the interval: If the feedback on the previous short interval was \"too short,\" the estimate is increased by 92 ms, but when it was \"too long,\" it is decreased the current estimate by 106 ms</li> <li>representation of an interval is the result of a pool of recent experiences and not of a single representation</li> <li>This is indicated by the relatively small intercepts of the regression formula and the susceptibility of the estimates to changes in the other interval</li> </ul>"},{"location":"KB/Traces%20of%20times%20past%20Representations%20of%20temporal%20intervals%20in%20memory/#general-discussion","title":"General discussion","text":"<ul> <li>The results not only show that the representations of two intervals tend to shift toward each other, but also that a change in the duration of one interval not only affects the representation of that interval, but also the representation of the unchanged interval.</li> <li>These findings support a model in which the representation of a time interval is not a single memory trace, but a pool of experiences in which recency and match to the current request determine the impact of single experiences.</li> <li>The main specific choice we made in this model was to treat every experience with each of the intervals as a separate memory trace</li> <li>However, we could not come up with a modification of the perturbation system that could (1) produce relatively stable performance for both durations, (2) adjust itself to changes in the standard, and (3) show influences of the changed long interval on the short interval.</li> <li>As already mentioned in the introduction, the fit to the data does not hinge on the linear or nonlinear representation of time in the clock component\u2014as long as a clock component produces temporal information, the pool model would be able to produce new temporal estimates</li> <li>a combination of a memory system and a time estimation system can explain the data discussed in this study, despite the fact that neither system was specifically designed for these experiments.</li> </ul>"},{"location":"KB/Traces%20of%20times%20past%20Representations%20of%20temporal%20intervals%20in%20memory/#images","title":"Images","text":""},{"location":"KB/Tracking%20the%20Continuity%20of%20Language%20Comprehension%20Computer%20Mouse%20Trajectories%20Suggest%20Parallel%20Syntactic%20Processing/","title":"Tracking the Continuity of Language Comprehension Computer Mouse Trajectories Suggest Parallel Syntactic Processing","text":""},{"location":"KB/Tracking%20the%20Continuity%20of%20Language%20Comprehension%20Computer%20Mouse%20Trajectories%20Suggest%20Parallel%20Syntactic%20Processing/#tracking-the-continuity-of-language-comprehension-computer-mouse-trajectories-suggest-parallel-syntactic-processing","title":"Tracking the Continuity of Language Comprehension Computer Mouse Trajectories Suggest Parallel Syntactic Processing","text":"<ul> <li>Thomas A. Farmera, Sarah A. Cargilla, Nicholas C. Hindya, Rick Daleb, Michael J. Spiveya</li> </ul>"},{"location":"KB/Tracking%20the%20Continuity%20of%20Language%20Comprehension%20Computer%20Mouse%20Trajectories%20Suggest%20Parallel%20Syntactic%20Processing/#abstract","title":"Abstract","text":"<ul> <li>Although several theories of online syntactic processing assume the parallel activation of multiple syntactic representations, evidence supporting simultaneous activation has been inconclusive</li> <li>continuous and non-ballistic properties of computer mouse movements are exploited</li> <li>procure evidence regarding parallel versus serial processing</li> <li>Participants heard structurally ambiguous sentences while viewing scenes with properties either supporting or not supporting the difficult modifier interpretation</li> <li>The curvatures of the elicited trajectories revealed both an effect of visual context and graded competition between simultaneously active syntactic representations</li> </ul>"},{"location":"KB/Tracking%20the%20Continuity%20of%20Language%20Comprehension%20Computer%20Mouse%20Trajectories%20Suggest%20Parallel%20Syntactic%20Processing/#introduction","title":"Introduction","text":"<ul> <li>Sentences such as, \"The adolescent hurried through the door tripped,\" are difficult to process because, at least temporarily, multiple possible structural representations exist</li> <li>garden-path effect</li> <li>Syntax First models</li> <li>Multiple constraint-based theories</li> <li>what feel like garden-path effects are due to the incorrect syntactic alternative winning much of the competition during the early portion of the sentence, and then nonconforming information from the latter portion of the sentence inducing a laborious reversal of that activation pattern</li> <li>As a result, one can expect that some garden-path events may be very mild, some moderate, and some extreme such that a wide variety of sentence readings should all belong to one population of events with a relatively continuous distribution.</li> <li>Unrestricted Race Model</li> <li>When ambiguous sentences like 1a are heard in the presence of visual scenes where only one possible referent is present (an apple already on a towel), along with an incorrect destination (an empty towel), and a correct destination (a box), as in the top portion of Fig. 1, about 50% of the time participants fixate the incorrect destination after hearing the first PP.</li> <li>After the second disambiguating PP is heard, eye movements tend to be redirected to the correct referent and then to the correct destination</li> <li>This garden-path effect can, however, be modulated by contextual information contained within the visual scene</li> <li>it seems that when two possible referents are present, an expectation is created that they will be discriminated amongst, thus forcing a modifier interpretation of the</li> <li>ambiguous PP</li> <li>The attenuation of looks to the incorrect destination by the presence of two possible referents, then, is evidence for an early influence of non-syntactic (even nonlinguistic) information on the parsing process and is problematic for traditional syntax-first accounts discussed earlier.</li> <li>However, because saccadic eye movements are generally ballistic, they either send the eyes to fixate an object associated with a garden-path interpretation or they do not.</li> <li>The evidence from this paradigm, therefore, is also consistent with the Unrestricted Race model, where the various constraints are combined immediately, but on any given trial only one syntactic representation is initially pursued</li> <li>across experimental trials, distributions of eye-movement patterns are almost always bimodal because the fixations are coded as binomial</li> <li>There are saccades to locations on the display corresponding to either one of the possible representations, but almost never to a blank region in between those two potential targets</li> <li>In the following experiment, we examined the dynamics of hand movement in the same sentence comprehension scenario with the goal of determining whether the non-ballistic, continuous nature of computer mouse trajectories can serve to tease apart these two remaining theoretical accounts.</li> </ul>"},{"location":"KB/Tracking%20the%20Continuity%20of%20Language%20Comprehension%20Computer%20Mouse%20Trajectories%20Suggest%20Parallel%20Syntactic%20Processing/#experiment","title":"Experiment","text":"<ul> <li>computer mouse movements can serve as an informative indicator of the cognitive processes underlying spoken-word recognition (Spivey, Grosjean, &amp; Knoblich, 2005)</li> <li>In addition, whereas self-paced reading affords 2 to 3 data points (button presses) per second, and eye-movement data allow for approximately 3 to 4 data points (saccades) per second, \"mouse tracking\" yields somewhere between 30 and 60 data points per second, depending on the sampling rate of the software used.</li> <li>The context and garden-path effects reported in the visual world paradigm are highly replicable when tracking eye movements</li> <li>As such, recording mouse movements in the visual world paradigm can serve as a strong test case by which to evaluate the efficacy of the mouse-tracking procedure for the study of language processing in real time.</li> </ul>"},{"location":"KB/Tracking%20the%20Continuity%20of%20Language%20Comprehension%20Computer%20Mouse%20Trajectories%20Suggest%20Parallel%20Syntactic%20Processing/#expected-prediction","title":"Expected Prediction","text":"<ul> <li>1) Averaged trajectories recorded in response to ambiguous sentences in the onereferent context should show significantly more curvature toward the incorrect destination than the averaged trajectories elicited by unambiguous sentences\u2014a pattern corresponding to the garden-path effect. 2)</li> <li>The curvature of averaged trajectories in the two referent condition should not differ statistically between ambiguous and unambiguous sentences, thus demonstrating an influence of referential context on the garden-path effect.</li> <li>The second purpose of this study, then, was to exploit the continuity of the mousemovement trajectories to discriminate between these two remaining theoretical accounts</li> <li>a measure of curvature magnitude was used to determine the amount of spatial attraction toward the incorrect destination that was exhibited by the ambiguousand unambiguous-sentence trajectories in the one-referent context.</li> <li>If only one representation were active at any one time, as the unrestricted race account predicts, then the trial-by-trial distribution of trajectory curvatures in the ambiguous-sentence condition should be either (a) bimodal\u2014comprised of highly curved garden-path movements and noncurved, correct-interpretation movements, or (b) uniformly in the more extreme curved range, indicating that almost every trial exhibited a garden-path effect</li> </ul>"},{"location":"KB/Tracking%20the%20Continuity%20of%20Language%20Comprehension%20Computer%20Mouse%20Trajectories%20Suggest%20Parallel%20Syntactic%20Processing/#method","title":"Method","text":""},{"location":"KB/Tracking%20the%20Continuity%20of%20Language%20Comprehension%20Computer%20Mouse%20Trajectories%20Suggest%20Parallel%20Syntactic%20Processing/#participants","title":"Participants","text":"<ul> <li>Forty right-handed, native English-speaking undergraduates from Cornell University participated in the study for extra credit in psychology courses</li> <li>only right-handed individuals to avoid variability associated with subtle kinematic differences in leftward and rightward movement of the left versus the right arms.</li> </ul>"},{"location":"KB/Tracking%20the%20Continuity%20of%20Language%20Comprehension%20Computer%20Mouse%20Trajectories%20Suggest%20Parallel%20Syntactic%20Processing/#materials-and-procedures","title":"Materials and Procedures","text":"<ul> <li>Sixteen experimental items 102 filler sentences</li> <li>The unambiguous version (1b) of each of the 16 experimental items was recorded first, and then the \"that\" was removed to produce the ambiguous (1a) sentence condition</li> <li>Each visual context corresponding to the 16 experimental items was varied to produce a oneand two-referent condition</li> <li>The one-referent visual context (illustrated in Fig. 1, top) contained the target referent (an apple on a towel), an incorrect destination (a second towel), the correct destination (a box), and a distracter object (a flower). In the two-referent context, all items were the same except that the distracter object was replaced with a second possible referent (such as an apple on a napkin). Twenty-four filler scenes, designed to accompany filler sentences, were also constructed.</li> <li>In critical trials for both the oneand two-referent conditions, the target referent always appeared in the top left corner of the screen, the incorrect destination always appeared in the top right corner of the screen, and the correct destination</li> <li>was always located at the bottom right portion of the screen.</li> <li>Given that the scene layout was held constant across all items in each experimental condition, a left-to-right movement was always necessary</li> <li>Although there could exist a systematic bias toward specific locations in the display when moving rightward, this was viewed as unproblematic given that the bias would be held constant across both the ambiguous and unambiguous sentences, which were directly compared in all statistical analyses, for each context.</li> <li>In each scene, participants saw four to six color images, depending on how many objects were needed for the scene</li> </ul>"},{"location":"KB/Tracking%20the%20Continuity%20of%20Language%20Comprehension%20Computer%20Mouse%20Trajectories%20Suggest%20Parallel%20Syntactic%20Processing/#results","title":"Results","text":""},{"location":"KB/Tracking%20the%20Continuity%20of%20Language%20Comprehension%20Computer%20Mouse%20Trajectories%20Suggest%20Parallel%20Syntactic%20Processing/#data-screening-and-coding","title":"Data Screening and Coding","text":"<ul> <li>A trajectory was considered valid and submitted to further analysis if it was initiated at the top left quadrant of the display and terminated in the bottom right quadrant, indicating that the correct referent had been picked up and then placed at the correct destination. This screening procedure resulted in 27 deleted trials, accounting for less than 5% of all experimental trials.</li> <li>To make sure that trajectories in one condition were not initiated (or that objects were not grabbed) at a systematically different region of the display than in the other conditions, we conducted two 2 (Context) \u00d7 2 (Ambiguity) ANOVAs on the x and y coordinates, separately.</li> <li>There was no significant main effect or interaction for either the x or the y coordinates (all ps were nonsignificant) indicating that, across conditions, the trajectories were initiated at approximately the same location of the display</li> <li>Subsequently, all analyzable trajectories were \"time normalized\" to 101 timesteps by a procedure described in Spivey et al. (2005) and Dale et al. (2007).</li> </ul>"},{"location":"KB/Tracking%20the%20Continuity%20of%20Language%20Comprehension%20Computer%20Mouse%20Trajectories%20Suggest%20Parallel%20Syntactic%20Processing/#context-and-garden-path-effects","title":"Context and Garden-path Effects","text":"<ul> <li>The mean trajectories from ambiguous and unambiguous sentences in the onereferent context, illustrated in Fig. 1 (top), demonstrate that the average ambiguoussentence trajectory was more curved toward the incorrect destination than the average trajectory elicited by the unambiguous sentences</li> <li>Thus, in the presence of the garden-path effect, it seems clear that there exists more spatial attraction toward the incorrect destination for the ambiguous sentences.</li> <li>In addition, in line with the time-normalized analyses presented above, none of the</li> <li>eight time bins in the two-referent context showed the ambiguousand unambiguous-sentence trajectories significantly diverging for either the x or the y coordinates.</li> </ul>"},{"location":"KB/Tracking%20the%20Continuity%20of%20Language%20Comprehension%20Computer%20Mouse%20Trajectories%20Suggest%20Parallel%20Syntactic%20Processing/#serial-versus-parallel-activation","title":"Serial Versus Parallel Activation","text":"<ul> <li>garden-path trials and some non-garden-path trials, the majority of the trajectories elicited in this condition fell somewhere in between those two extremes, forming a single population of non-, somewhat-, and highly curved responses.</li> <li>To determine whether any bimodality is present in the distribution of responses, we computed the area under the curve on a trial-by-trial basis</li> <li>The b value for each distribution is less than .555, indicating no presence of bimodality within the distributions.</li> <li>Notably, with regard to the distribution of responses in the one-referent, ambiguous-sentence condition, b &lt; .555 indicates that the graded spatial attraction effects elicited in this condition came not from two different types of trials but from a single population of trials.</li> <li>Finally, one might argue that bimodality was not detected (thus, b &lt; .555) in the crucial one-referent, ambiguous-sentence condition due to a lack of statistical power resulting from the relatively small number of trials in the garden-path distribution.</li> <li>To address this concern, we created an artificial distribution with a sample size almost identical to our crucial gardenpath distribution by randomly sampling 50% of the trials from the one-referent, ambiguoussentence condition (where garden pathing was observed) and 50% of the trials from the onereferent, unambiguoussentence condition.</li> <li>By examining the distributional properties of the area-under-the-curve values produced by the garden-path and non-garden-path trials together, we can thus determine whether the bimodality statistic (b) we used to assess the bimodality of the garden-path distribution (above) is capable of detecting bimodality in a case where the response distribution should clearly be bimodal</li> </ul>"},{"location":"KB/Tracking%20the%20Continuity%20of%20Language%20Comprehension%20Computer%20Mouse%20Trajectories%20Suggest%20Parallel%20Syntactic%20Processing/#general-discussion","title":"General Discussion","text":"<ul> <li>In the one-referent context, participants' mouse movements in response to the ambiguous sentences curved significantly closer to the top right of the screen (toward the incorrect destination) than in response to unambiguous sentences.</li> <li>Thus, it would seem that when only one referent was present, the incorrect destination (e.g., the towel) was partially considered relevant, until disambiguating information was processed\u2014a trend corresponding to the garden-path effect associated with this condition.</li> <li>The fact that most mouse trajectories began while the speech file was still being heard suggests that the effect of visual context modulating the garden path took place during early moments of processing the linguistic input, not during a second stage of syntactic reanalysis.</li> <li>In addition, by capitalizing on the continuous, non-linear, and non-ballistic properties of trajectories produced by computer mouse movements, mouse tracking has the potential to answer questions that have been difficult to answer with more traditional methodologies.</li> <li>What does distinguish between these two accounts is the gradiency observed in the curvature of the trajectories in the garden-path condition</li> <li>If the Unrestricted Race model posits that only one syntactic representation is pursued at any one time, then it must predict that mouse movements in a gardenpath condition should initially move either in the direction of the correct destination or in the direction of the incorrect destination (producing either a bimodal distribution or an all-curved distribution)</li> <li>In contrast, because the constraintbased account posits simultaneous graded activation of multiple syntactic alternatives, it predicts that mouse movements can move in directions that are dynamically weighted combinations of the two competing destinations (producing a unimodal distribution of moderate curvatures).</li> <li>Fig. 4 shows that although approximately 5% of the trajectories moved all the way to the incorrect destination before changing direction, the vast majority of the trajectories responsible for the mean curvature were unmistakably graded in their degree of spatial attraction toward the incorrect destination.</li> <li>The lack of bimodality in the distribution of trial-by-trial trajectory curvatures suggests that the garden-path effect so frequently associated with this manipulation is not an all-or-none phenomenon\u2014that is, the activation of one structural representation does not forbid simultaneous activation of other possible representations</li> <li>Through a large-scale survey of children's computer use, for example, Calvert, Rideout, Woolard, Barr, and Strouse (2005) found that the mean age at which a child was able to point and click a computer mouse was 3.5 years, and that the mean age of the onset of autonomous computer use was 3.7 years</li> <li>we believe mouse tracking can serve as \"the poor man's eye tracker,\" providing detailed indices of cognitive processing to laboratories that cannot afford expensive eye-tracking equipment.</li> </ul>"},{"location":"KB/Tracking%20the%20Continuity%20of%20Language%20Comprehension%20Computer%20Mouse%20Trajectories%20Suggest%20Parallel%20Syntactic%20Processing/#pictures","title":"Pictures","text":""},{"location":"KB/Tractability/","title":"Tractability","text":""},{"location":"KB/Tractability/#tractability","title":"Tractability","text":"<ul> <li>Let X be the input and Z be the latent representation of X. Every generative model makes the assumption that it's tractable to compute the probability P(Z | X).</li> </ul>"},{"location":"KB/Training%20Trajectories/","title":"Training Trajectories","text":""},{"location":"KB/Training%20Trajectories/#training-trajectories","title":"Training Trajectories","text":""},{"location":"KB/Training-serving%20Skew/","title":"Training serving Skew","text":""},{"location":"KB/Training-serving%20Skew/#training-serving-skew","title":"Training-serving Skew","text":"<ul> <li>The difference between a model's performance during training and that same model's performance during serving.</li> </ul>"},{"location":"KB/Trajectory%20Planning/","title":"Trajectory Planning","text":""},{"location":"KB/Trajectory%20Planning/#trajectory-planning","title":"Trajectory Planning","text":"<ul> <li>Scheduled motion to follow, including time information</li> <li>After finding a path, the trajectory definition is completed by the choice of a timing law</li> </ul>"},{"location":"KB/Trajectory%20Plotting%20with%20PCA/","title":"Trajectory Plotting with PCA","text":""},{"location":"KB/Trajectory%20Plotting%20with%20PCA/#trajectory-plotting-with-pca","title":"Trajectory Plotting with PCA","text":"<ul> <li>The problem: the path lies in a low-dimensional space.</li> <li>The solution: PCA</li> <li>Construct a matrix $$ M = [\\theta_{0}- \\theta_{n};...;\\theta_{n-1}-\\theta_{n}] $$</li> <li>where,</li> <li>\\(\\theta_{i}\\) is the model params during epoch i</li> <li>n is number of epochs</li> <li>apply PCA to M and use 2 most explanatory directions</li> <li></li> </ul>"},{"location":"KB/Trajectory/","title":"Trajectory","text":""},{"location":"KB/Trajectory/#trajectory","title":"Trajectory","text":"<ul> <li>In reinforcement learning, a sequence of tuples that represent a sequence of state transitions of the agent, where each tuple corresponds to the state, action, reward, and next state for a given state transition.</li> </ul>"},{"location":"KB/Transcranial%20Electrical%20Stimulation%20%28tDCS%20and%20tACS%29/","title":"Transcranial Electrical Stimulation (tDCS and tACS)","text":""},{"location":"KB/Transcranial%20Electrical%20Stimulation%20%28tDCS%20and%20tACS%29/#transcranial-electrical-stimulation-tdcs-and-tacs","title":"Transcranial Electrical Stimulation (tDCS and tACS)","text":"<ul> <li>A non-invasive procedure that applies electrical stimulation to the scalp to increase or decrease neural signaling. The two main types are direct current stimulation (tDCS) and alternating current stimulation (tACS). They are used for therapeutic purposes as well as to study cognitive processing.</li> </ul>"},{"location":"KB/Transcranial%20Magnetic%20Stimulation%20%28TMS%29/","title":"Transcranial Magnetic Stimulation (TMS)","text":""},{"location":"KB/Transcranial%20Magnetic%20Stimulation%20%28TMS%29/#transcranial-magnetic-stimulation-tms","title":"Transcranial Magnetic Stimulation (TMS)","text":"<ul> <li>A non-invasive procedure that uses the energy from a strong magnet to stimulate changes in neural processing from above the scalp. It is used as a treatment for depression as well as a research method to investigate cognitive processes.</li> </ul>"},{"location":"KB/Transducer/","title":"Transducer","text":""},{"location":"KB/Transducer/#transducer","title":"Transducer","text":"<ul> <li>A device that converts energy from one form to another. Generally, a device that converts an input signal into an output signal of a different form. It can also be thought of as a device which converts static signals detected in the environment (such as pressure) into an electrical signal that is sent to a robot's control system.</li> </ul>"},{"location":"KB/Transfer%20Function/","title":"Transfer Function","text":""},{"location":"KB/Transfer%20Function/#transfer-function","title":"Transfer Function","text":"<ul> <li>Map a scalar to color and opacity</li> <li>Determines which features of the data are visible / highlighted</li> <li>Can be stored inside a color lookup table (LUT)</li> <li></li> <li></li> <li>Opacity Correction</li> </ul>"},{"location":"KB/Transfer%20Learning%20or%20%20Self-supervised%20Learning%3F%20A%20Tale%20of%20%20Two%20Pretraining%20Paradigms/","title":"Transfer Learning or  Self-supervised Learning? A Tale of  Two Pretraining Paradigms","text":""},{"location":"KB/Transfer%20Learning%20or%20%20Self-supervised%20Learning%3F%20A%20Tale%20of%20%20Two%20Pretraining%20Paradigms/#transfer-learning-or-self-supervised-learning-a-tale-of-two-pretraining-paradigms","title":"Transfer Learning or Self-supervised Learning? A Tale of Two Pretraining Paradigms","text":"<ul> <li>@yangTransferLearningSelfsupervised2020</li> <li>[Transfer Learning]  vs Self Supervised </li> </ul>"},{"location":"KB/Transfer%20Learning%20or%20%20Self-supervised%20Learning%3F%20A%20Tale%20of%20%20Two%20Pretraining%20Paradigms/#comparison-using","title":"Comparison Using","text":"<ul> <li>5 different image-based source domains</li> <li>4 target tasks<ol> <li>from daily-life objects</li> <li>general scenes</li> <li>nature</li> <li>medical pictures areas.</li> </ol> </li> <li> <p>Four different experimental setups </p> </li> <li> <p>Effect of domain difference between source and target task</p> </li> <li>Effect of amount of pretraining data</li> <li>Effect of class imbalance in source data</li> <li>Effect of using target data for additional pretraining</li> <li>ResNet-50</li> </ul>"},{"location":"KB/Transfer%20Learning%20or%20%20Self-supervised%20Learning%3F%20A%20Tale%20of%20%20Two%20Pretraining%20Paradigms/#results","title":"Results","text":""},{"location":"KB/Transfer%20Learning%20or%20%20Self-supervised%20Learning%3F%20A%20Tale%20of%20%20Two%20Pretraining%20Paradigms/#domain-difference","title":"Domain Difference","text":"<ul> <li>Large<ul> <li>SSL outperforms TL</li> </ul> </li> <li>Small<ul> <li>TL outperforms SSL</li> <li>SSL is less sensitive to domain difference than TL.</li> </ul> </li> </ul>"},{"location":"KB/Transfer%20Learning%20or%20%20Self-supervised%20Learning%3F%20A%20Tale%20of%20%20Two%20Pretraining%20Paradigms/#amount-of-pretraining-data","title":"Amount of Pretraining Data","text":"<ul> <li>Small(for same source task)<ul> <li>SSL outperforms TL</li> </ul> </li> <li>Large(for same source task)<ul> <li>TL outperforms SSL</li> <li>SSL is less sensitive to amount of pretraining data than TL, when domain difference is small</li> </ul> </li> </ul>"},{"location":"KB/Transfer%20Learning%20or%20%20Self-supervised%20Learning%3F%20A%20Tale%20of%20%20Two%20Pretraining%20Paradigms/#class-imbalance-source-data","title":"Class Imbalance (Source Data)","text":"<ul> <li>SSL is more robust to class imbalance than TL</li> </ul>"},{"location":"KB/Transfer%20Learning%20or%20%20Self-supervised%20Learning%3F%20A%20Tale%20of%20%20Two%20Pretraining%20Paradigms/#additional-pretraining","title":"Additional Pretraining","text":"<ul> <li>For SSL, using target task for additional pretraining works better vs using only source data, but not for TL.</li> </ul>"},{"location":"KB/Transfer%20Learning%20or%20%20Self-supervised%20Learning%3F%20A%20Tale%20of%20%20Two%20Pretraining%20Paradigms/#what-is-left","title":"What is Left","text":"<ul> <li>can be extended to other forms of data including speech, signals and text</li> <li>Only used ResNet architecture, need to investigate other architectures</li> <li>Image Transformers etc. are not considered</li> <li>Correlation between performance and factors is studied and potential reasons behind it are discussed, a deeper investigation of these potential reasons might be beneficial</li> </ul>"},{"location":"KB/Transfer%20Learning/","title":"Transfer Learning","text":""},{"location":"KB/Transfer%20Learning/#transfer-learning","title":"Transfer Learning","text":"<ul> <li>Transfer learning involves extrapolating a reward function for a new environment based on reward functions from many similar environments that might then transfer in a wrong way</li> <li>Uses source task with human assigned labels </li> <li>Biased to human assigned labels, more discriminative</li> </ul>"},{"location":"KB/Transfer%20Learning/#refs","title":"Refs","text":"<ul> <li>openai</li> </ul>"},{"location":"KB/Transferability/","title":"Transferability","text":""},{"location":"KB/Transferability/#transferability","title":"Transferability","text":"<ul> <li>Explainability is also an advocate for transferability, since it may ease the task of elucidating the boundaries that might affect a model, allowing for a better understanding and implementation</li> <li>the mere understanding of the inner relations taking place within a model facilitates the ability of a user to reuse this knowledge in another problem</li> <li>cases in which the lack of a proper understanding of the model might drive the user toward incorrect assumptions and fatal consequences</li> </ul>"},{"location":"KB/Transferred%20compact%20convolutional%20filters/","title":"Transferred compact convolutional filters","text":""},{"location":"KB/Transferred%20compact%20convolutional%20filters/#transferred-compact-convolutional-filters","title":"Transferred Compact Convolutional Filters","text":"<ul> <li>These methods remove inessential parameters by transferring or compressing the convolutional filters (Zhai et al., 2016).</li> </ul>"},{"location":"KB/Transformer%20Physics/","title":"Transformer Physics","text":""},{"location":"KB/Transformer%20Physics/#transformer-physics","title":"Transformer Physics","text":"<ul> <li>ratio of the voltages across the coils of a transformer = the ratio of the turns on the coils</li> <li> \\[\\frac{V_{1}}{V_{2}}= \\frac{N_{1}}{N_{2}}\\] </li> </ul>"},{"location":"KB/Transformer-XL/","title":"Transformer-XL","text":""},{"location":"KB/Transformer-XL/#transformer-xl","title":"Transformer-XL","text":"<ul> <li>Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context</li> <li>Transformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling</li> <li>learning dependency beyond a fixed length without disrupting temporal coherence</li> <li>segment-level recurrence mechanism and a novel positional encoding scheme</li> <li>resolves the context fragmentation problem</li> <li>enwiki8</li> <li>WikiText</li> <li>One Billion Word</li> <li>Penn Treebank</li> </ul>"},{"location":"KB/Transformer/","title":"Transformer","text":""},{"location":"KB/Transformer/#transformer","title":"Transformer","text":"<ul> <li>Encoder Decoder</li> <li>Auto regressive : decoder outputs fed back as inputs to decoder</li> <li>Decoder can access not only the hidden step of the last time step from the encoder, but all the hidden states from the encoder</li> <li>During decoding, consider pairwise relationshop between decoder state and all the returned states from the encoder<ul> <li>Some words relevant, others are not</li> </ul> </li> <li>Transform all hidden states from the encoder into context vectors, that shows how the decoding step is relevant to the input sequences</li> <li>Attention</li> <li>Basic Transformer</li> </ul>"},{"location":"KB/Transformer/#nice-little-blogs","title":"Nice Little Blogs","text":"<ul> <li>lillog</li> </ul>"},{"location":"KB/Transitional%20probabilities/","title":"Transitional probabilities","text":""},{"location":"KB/Transitional%20probabilities/#transitional-probabilities","title":"Transitional Probabilities","text":"<ul> <li> \\[\\text{Prob of }Y|X = \\frac{\\text{freq of} XY}{\\text{freq of }X}\\] </li> <li>Longer listening times for non-words indicates recognition of words</li> <li>Transitional probabilities can be high within words, and low at word boundaries as in Aslin et al</li> <li>But then you can also manipulate the frequency at which each word occurs, and in doing so, also the frequency of the syllables</li> <li>Graf Estes et al</li> <li>Transition frequencies can be made high because two words occur very often next to each other</li> </ul>"},{"location":"KB/Transitive%20verb/","title":"Transitive verb","text":""},{"location":"KB/Transitive%20verb/#transitive-verb","title":"Transitive Verb","text":"<ul> <li>a verb with a direct noun object</li> <li>I cooked a duck belonging to her</li> </ul>"},{"location":"KB/Translational%20Invariance/","title":"Translational Invariance","text":""},{"location":"KB/Translational%20Invariance/#translational-invariance","title":"Translational Invariance","text":"<ul> <li>In an image classification problem, an algorithm's ability to successfully classify images even when the position of objects within the image changes. For example, the algorithm can still identify a dog, whether it is in the center of the frame or at the left end of the frame.</li> </ul>"},{"location":"KB/Transparency/","title":"Transparency","text":""},{"location":"KB/Transparency/#transparency","title":"Transparency","text":"<ul> <li>a model is considered to be transparent if by itself it is understandable. Since a model can feature different degrees of understandability, transparent models in Section 3 are divided into three categories: simulatable models, decomposable models and algorithmically transparent models</li> <li>understandability is a two-sided matter: model understandability and human understandability in @gunningExplainableArtificialIntelligence</li> </ul>"},{"location":"KB/Transposed%20Conv/","title":"Transposed Conv","text":""},{"location":"KB/Transposed%20Conv/#transposed-conv","title":"Transposed Conv","text":"<ul> <li>use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution.</li> <li>Upsampling</li> <li>Input i, kernel k, padding p, stride s , \\(\\(o = (i-1) \\times s +k -2p\\)\\)</li> <li>Steps<ul> <li>Calculate new Param's z and p'</li> <li>Between each row and columns of the input, insert z number of zeros.\u00a0This increases the size of the input to\u00a0\\((2*i -1) \\times (2*i -1)\\)</li> <li>Pad the modified image with p' no of zeros</li> <li>Standard conv with stride of 1</li> <li></li> </ul> </li> <li></li> </ul>"},{"location":"KB/Trapezoidal%20Trajectory/","title":"Trapezoidal Trajectory","text":""},{"location":"KB/Trapezoidal%20Trajectory/#trapezoidal-trajectory","title":"Trapezoidal Trajectory","text":""},{"location":"KB/Treemap/","title":"Treemap, Node Link, Stacking","text":""},{"location":"KB/Treemap/#treemap","title":"Treemap","text":""},{"location":"KB/Trees/","title":"Trees","text":""},{"location":"KB/Trees/#trees","title":"Trees","text":"<ul> <li>Decision Trees</li> <li></li> <li>Node Link Diagram</li> </ul>"},{"location":"KB/Triplet%20Loss/","title":"Triplet Loss","text":""},{"location":"KB/Triplet%20Loss/#triplet-loss","title":"Triplet Loss","text":"<ul> <li>Given an achor, pull similar closer and push dissimilar away</li> <li>Face recog FaceNet</li> <li>Anchor, positive sample are neigbors while neg isnt</li> <li></li> <li>For each triplet, this condition must hold $\\(||f(x^a) - f(x^p)||^2 + \\alpha \\gt f(x^a) - f(x^n)||^2\\)</li> <li>\\(\\alpha\\) is a margin b/w positive and neg</li> <li>Loss to minimize $\\(L(\\theta) = \\Sigma_i^n||f(x^a) - f(x^p)||^2 + f(x^a) - f(x^n)||^2 + \\alpha\\)</li> <li>Harmonic Triplet Loss</li> </ul>"},{"location":"KB/Trustworthiness/","title":"Trustworthiness","text":""},{"location":"KB/Trustworthiness/#trustworthiness","title":"Trustworthiness","text":"<ul> <li>However, declaring a model as explainable as per its capabilities of inducing trust might not be fully compliant with the requirement of model explainability</li> <li>Trustworthiness might be considered as the confidence of whether a model will act as intended when facing a given problem</li> <li>it does not imply that every trustworthy model can be considered explainable on its own, nor is trustworthiness a property easy to quantify</li> <li>Trust might be far from being the only purpose of an explainable model since the relation among the two, if agreed upon, is not reciprocal</li> </ul>"},{"location":"KB/Tug%20of%20war%20between%20RAG%20and%20LLM%20prior/","title":"Tug of war between RAG and LLM prior","text":"","tags":["llm"]},{"location":"KB/Tug%20of%20war%20between%20RAG%20and%20LLM%20prior/#tug-of-war-between-rag-and-llm-prior","title":"Tug of War between RAG and LLM prior","text":"<ul> <li>@wuHowFaithfulAre2024</li> </ul>","tags":["llm"]},{"location":"KB/Tug%20of%20war%20between%20RAG%20and%20LLM%20prior/#how-faithful-are-rag-models-quantifying-the-tug-of-war-between-rag-and-llms-internal-prior","title":"How Faithful Are RAG Models? Quantifying the Tug-of-war between RAG and LLMs\\' Internal prior","text":"<ul> <li>(Note : Basically shows that it's not possible for an LLM to fix it's own hallucinations. Kinda like, if you twist the data around, then after a point the model stops relying on what it knows and starts believing in all the nonsense)</li> <li>in cases when the LLM alone incorrectly answers a question, does providing the correct retrieved content always fix the error?</li> <li>in cases where the retrieved content is incorrect, does the LLM know to ignore the wrong information, or does it recapitulate the error?</li> <li>systematically analyze the tug-of-war between a LLM's internal knowledge (i.e. its prior) and the retrieved information in settings when they disagree</li> <li>the more the modified information deviates from the model's prior, the less likely the model is to prefer it</li> <li>The likelihood of the LLM to adhere to the retrieved information presented in context (RAG preference rate) is inversely correlated with the model's confidence in its response without context (its prior probability).</li> <li>LLMs will increasingly revert to their priors when the original context is progressively modified with unrealistic values.</li> </ul>","tags":["llm"]},{"location":"KB/Tug%20of%20war%20between%20RAG%20and%20LLM%20prior/#methods","title":"Methods","text":"<ul> <li>Our main analysis consists of evaluating the RAG question-answering capabilities of GPT-4 when introducing varying levels of perturbations on the RAG documents</li> </ul>","tags":["llm"]},{"location":"KB/Tug%20of%20war%20between%20RAG%20and%20LLM%20prior/#concordance","title":"Concordance","text":"<ul> <li>the agreement between the reference answer generated based on the article content, and the model's answer to the corresponding generated question</li> <li>This is computed for both the model's answer with and without context.</li> </ul>","tags":["llm"]},{"location":"KB/Tug%20of%20war%20between%20RAG%20and%20LLM%20prior/#modifying-the-retrieved-documents","title":"Modifying the Retrieved Documents","text":"<ul> <li>In three datasets with numerical answers (Drug Dosages, Sports Records, Latest News), we produce ten modifications that act as multipliers on the original value: 0.1, 0.2, 0.4, 0.8, 1.2, 1.5, 2.0, 3.0, 5.0, 10.0.</li> <li>for a name like Bob Green, a slight modification implies a small tweak to another real name (Rob Greene), whereas a significant modification produces a similar but fictitious name (Bilgorn Grevalle), and a comical modification is an absurd variant (Blob Lawnface).</li> <li>Because of differences in how each modified fact might appear in the retrieved text, we utilize GPT-4 to generate the perturbed excerpts for drug dosages and news. Each modified fact is replaced in the original retrieved text.</li> </ul>","tags":["llm"]},{"location":"KB/Tug%20of%20war%20between%20RAG%20and%20LLM%20prior/#rag-vs-model-prior-analyses","title":"RAG Vs Model Prior Analyses","text":"<ul> <li>main analysis we perform in this study is comparing the RAG preference of a model against its internal prior</li> <li>The LLM is first queried with a question without context</li> <li>This response and the average probability of the tokens (accessed via the log probs) are referred to as the model's prior response and the prior probability, respectively</li> <li>The LLM is then queried again, this time with the retrieved content present in the prompt.</li> <li>if the response is still the same as the prior response, then the model prefers its prior</li> <li>On the other hand, if the model response aligns with the information present in the retrieved content, then the model prefers RAG</li> <li>For each dataset, the RAG preference rate is computed as the average across all RAG queries.</li> <li>RAG preference rate is compared against two measurements: the prior probability and the deviation from the prior value.</li> </ul>","tags":["llm"]},{"location":"KB/Tug%20of%20war%20between%20RAG%20and%20LLM%20prior/#results","title":"Results","text":"","tags":["llm"]},{"location":"KB/Tug%20of%20war%20between%20RAG%20and%20LLM%20prior/#concordance_1","title":"Concordance","text":"<ul> <li>we observe that the model's prior response only agreed with the reference answer 34.7% on average</li> <li>RAG answers elevated the concordance to 94%</li> <li>in the minority of cases where providing the retrieved content fails to correct the LLM, we find that the model simply responds with its original prior answer about 20% of the time. </li> </ul>","tags":["llm"]},{"location":"KB/Tug%20of%20war%20between%20RAG%20and%20LLM%20prior/#rag-preference-rate-vs-prior-probability","title":"RAG Preference Rate vs. Prior Probability","text":"<ul> <li>The slope indicates the effect of stronger model confidence on the model's preference for the information presented in the retrieved context; we observe different slopes (ranging from -0.1 to -0.45), suggesting that the effectiveness of RAG in different QA domains can be characterized as being relatively susceptible (e.g., with Dates questions) or robust (e.g., with News questions) to the model's internal prior knowledge confidence.</li> </ul>","tags":["llm"]},{"location":"KB/Tug%20of%20war%20between%20RAG%20and%20LLM%20prior/#rag-preference-rate-vs-deviation-from-prior","title":"RAG Preference Rate Vs Deviation from Prior","text":"<ul> <li>as the RAG value diverges from the model's prior, the model is less likely to adopt the RAG value over its own initial response</li> </ul>","tags":["llm"]},{"location":"KB/Tug%20of%20war%20between%20RAG%20and%20LLM%20prior/#effect-of-prompting-technique-on-rag-adherence","title":"Effect of Prompting Technique on RAG Adherence","text":"<ul> <li>We observe lower and steeper drops in RAG adherence with the loose vs strict prompts, suggesting that prompt wording plays a significant factor in controlling RAG adherence.</li> <li>we quantify a tug-of-war between the strength of the model's prior and the rate at which the model</li> <li>adheres to the RAG document's facts</li> </ul>","tags":["llm"]},{"location":"KB/Tuning%20Model%20Flexibility/","title":"Tuning Model Flexibility","text":""},{"location":"KB/Tuning%20Model%20Flexibility/#tuning-model-flexibility","title":"Tuning Model Flexibility","text":"<ul> <li>Class Size</li> <li>Regularization</li> <li>Ridge Regression</li> <li>Adding noise</li> <li>Cross Validation</li> </ul>"},{"location":"KB/Tutor/","title":"Tutor","text":""},{"location":"KB/Tutor/#tutor","title":"Tutor","text":"<ul> <li>However, a tutoring system does not have to replace a teacher or run an after-school remediation session</li> <li>Its role in the student's learning ecology can be anything\u2014a smart piece of paper; an encouraging coach; a stimulating peer, etc. The technology is quite neutral</li> <li>For instance, tutoring systems have been built that do not teach their task domain at all, but instead encourage students to discover its principles (e.g., Shute &amp; Glaser, 1990).</li> </ul>"},{"location":"KB/Two-photon%20Microscopy/","title":"Two photon Microscopy","text":""},{"location":"KB/Two-photon%20Microscopy/#two-photon-microscopy","title":"Two-photon Microscopy","text":"<ul> <li>An advanced microscopy technique that uses fluorescent markers to look at living tissue approximately one millimeter below the skin\u2019s surface.</li> </ul>"},{"location":"KB/Types%20of%20Words/","title":"Types of Words","text":""},{"location":"KB/Types%20of%20Words/#types-of-words","title":"Types of Words","text":"<ul> <li>Content words</li> <li>Function words</li> </ul>"},{"location":"KB/Types%20of%20uncertainty/","title":"Types of Uncertainty","text":""},{"location":"KB/Types%20of%20uncertainty/#types-of-uncertainty","title":"Types of Uncertainty","text":"<ul> <li>Aleatoric</li> <li>Epistemic</li> <li>Predictive Uncertainty</li> </ul>"},{"location":"KB/UCF101/","title":"UCF101","text":""},{"location":"KB/UCF101/#ucf101","title":"UCF101","text":"<ul> <li>UCF101 </li> <li>widely used video dataset for human action recognition </li> <li>13, 370 video clips with more than 27 hours belonging to 101 categories in this dataset </li> <li>spatial resolution of 320 x 240 pixels and 25 FPS frame rate </li> <li>dataset has been widely used for evaluating the performance of human action recognition</li> </ul>"},{"location":"KB/ULMFit/","title":"ULMFit","text":""},{"location":"KB/ULMFit/#ulmfit","title":"ULMFit","text":"<ul> <li>English Wikipedia -&gt; IMDB%20-%3E%20%5B%5BIMDB)] Classifier</li> </ul>"},{"location":"KB/UMA/","title":"UMA","text":""},{"location":"KB/UMA/#uma","title":"UMA","text":"<ul> <li>Uniform memory access</li> <li>SMP</li> <li>Identical processors</li> <li>Identical processors</li> <li>Equal access and access times to memory</li> <li>Cache Coherence</li> </ul>"},{"location":"KB/Ultrasound/","title":"Ultrasound","text":""},{"location":"KB/Ultrasound/#ultrasound","title":"Ultrasound","text":"<ul> <li>Imaging produced by high-frequency sound waves, usually used to view internal organs</li> </ul>"},{"location":"KB/Un-LSTM/","title":"Un-LSTM","text":""},{"location":"KB/Un-LSTM/#un-lstm","title":"Un-LSTM","text":"<ul> <li>Due to the powerful ability of modeling long-term dynamic in videos, LSTM is used in both the encoder and decoder [37]. </li> <li>Since its superior ability to model temporal dynamics, most of them use LSTM or LSTM variant to encode temporal dynamics in videos or to infer the future frames [37], [146], [147], [164], [165] </li> <li>can be employed for self-supervised feature learning without using human- annotations </li> <li>encoder-decoder pipeline in which the encoder to model spatial and temporal features from the given video clips and the decoder to generate future frames based on feature extracted by encoder.</li> </ul>"},{"location":"KB/Unawareness/","title":"Unawareness","text":""},{"location":"KB/Unawareness/#unawareness","title":"Unawareness","text":"<ul> <li>A situation in which sensitive attributes are present, but not included in the training data. Because sensitive attributes are often correlated with other attributes of one\u2019s data, a model trained with unawareness about a sensitive attribute could still have disparate impact with respect to that attribute, or violate other fairness constraints.</li> </ul>"},{"location":"KB/Unbiased%20Look%20at%20Dataset%20Bias/","title":"Unbiased Look at Dataset Bias","text":"<p><code>toc</code> - Unbiased Look at Dataset Bias - Alexei A. Efros Antonio Torralba - @Unbiased look at dataset bias - ## Abstract - some datasets, that started out as data capture efforts aimed at representing the visual world, have become closed worlds unto themselves - despite the best efforts of their creators, the datasets appear to have a strong buildin bias - Of course, much of the bias can be accounted for by the divergent goals of the different datasets: some captured more urban scenes, others more rural landscapes; some collected professional photographs, others the amateur snapshots from the Internet; some focused on entire scenes, others on single objects, etc - Caltech has a strong preference for side views, while ImageNet is into racing cars; PASCAL have cars at noncanonical view-points; SUNS and LabelMe cars appear to be similar, except LabelMe cars are often occluded by small objects, etc - Name That Dataset - ## Measuring Dataset Bias - settle for a few standard checks, a diagnostic of dataset health if you will. - Cross-dataset generalization - Selection bias - Capture bias - Label bias - Negative Set Bias - ## Measuring Dataset's Value - two basic ways of improving the performance - The first solution is to improve the features, the object representation and the learning algorithm for the detector. - The second solution is to simply enlarge the amount of data available for training. - So, what is the value of current datasets when used to train algorithms that will be deployed in the real world? The answer that emerges can be summarized as: \"better than nothing, but not by much\". - ## Discussion - that the reason is not that datasets are bad, but that our object representations and recognition algorithms are terrible and end up over-learning aspects of the visual data that relates to the dataset and not to the ultimate visual task. - In fact, a human learns about vision by living in a reduced environment with many potential local biases and yet the visual system is robust enough to overcome this. - Should we care about the quality of our datasets? If the goal is to reduce computer vision to a set of feature vectors that can be used in some machine learning algorithm, then maybe not. But if the goal is to build algorithms that can understand the visual world, then, having the right datasets will be crucial. - ## Images -  - </p>"},{"location":"KB/Unbiased%20Look%20at%20Dataset%20Bias/#unbiased-look-at-dataset-bias","title":"Unbiased Look at Dataset Bias","text":""},{"location":"KB/Uncertainity%20in%20classification/","title":"Uncertainty Classification","text":""},{"location":"KB/Uncertainity%20in%20classification/#uncertainty-classification","title":"Uncertainty Classification","text":"<ul> <li>Distributions</li> <li>Use Softmax or Sigmoid</li> </ul>"},{"location":"KB/Uncertainity%20in%20regression/","title":"Reg Uncertainty","text":""},{"location":"KB/Uncertainity%20in%20regression/#reg-uncertainty","title":"Reg Uncertainty","text":"<ul> <li>LinearRegression</li> <li>Confidence intervals</li> <li>Prob that output belongs to this interval</li> <li>\\(f(x) \\in [a,b]\\)</li> <li>Mean and Variance</li> <li>\\(f(x) \\pm \\sigma\\)</li> <li>\\(f(x) \\in [f(x) - \\sigma,f(x) + \\sigma]\\)</li> </ul>"},{"location":"KB/Uncertainty/","title":"Uncertainty","text":""},{"location":"KB/Uncertainty/#categories-anchor","title":"categories: ['anchor']","text":"<ul> <li>./Aleatoric.md</li> <li>./Entropy.md</li> <li>./Epistemic.md</li> <li>./Heteroscedatic.md</li> <li>./Homoscedatic.md</li> <li>./Inceptionism.md</li> <li>Interpretability vs Neuroscience.md</li> <li>./LIME.md</li> <li>Predictive Uncertainty.md</li> <li>./SHAP.md</li> <li>Types of uncertainty.md</li> <li>Uncertainity in regression.md</li> </ul>"},{"location":"KB/Understandability/","title":"Understandability","text":""},{"location":"KB/Understandability/#understandability","title":"Understandability","text":"<ul> <li>denotes the characteristic of a model to make a human understand its function \u2013 how the model works \u2013 without any need for explaining its internal structure or the algorithmic means by which the model processes data internally</li> </ul>"},{"location":"KB/Undue%20Inducement/","title":"Undue Inducement","text":""},{"location":"KB/Undue%20Inducement/#undue-inducement","title":"Undue Inducement","text":"<ul> <li>When the value of something received in a clinical trial is so large that the study participant may agree to take risks that are not in their best interests.</li> </ul>"},{"location":"KB/Unet%20Grasping/","title":"Unet Grasping","text":""},{"location":"KB/Unet%20Grasping/#unet-grasping","title":"Unet Grasping","text":"<ul> <li>Y. Li, L. Schomaker, and H. Kasaei. \"Learning to Grasp 3D Objects using Deep Residual U-Nets.\" RO-MAN 2020.</li> <li>Formulate object grasping as a part segmentation problem</li> <li>Detect graspable shape primitives  </li> <li>The gripper is free to approach objects from arbitrary directions.</li> <li></li> <li></li> </ul>"},{"location":"KB/Unet/","title":"Unet","text":""},{"location":"KB/Unet/#unet","title":"Unet","text":"<ul> <li>Skip Connection</li> </ul>"},{"location":"KB/Unicode%2050/","title":"Unicode 5.0","text":""},{"location":"KB/Unicode%2050/#unicode-50","title":"Unicode 5.0","text":"<ul> <li>UNICODE Consortium 2006</li> <li>100,000 distinct characters</li> <li>75 supported scripts</li> <li>UTF-8 Variable Length Character Encoding<ul> <li>1-4 bytes for each character (max )6</li> <li>ASCII requires 1 byte</li> <li>Alphabetic Systems require 2 bytes</li> <li>Chinese \u2013Japanese-Korean \u2013 3 bytes (sometimes 4 bytes)</li> </ul> </li> </ul>"},{"location":"KB/Uniform%20Distribution/","title":"Uniform Distribution","text":""},{"location":"KB/Uniform%20Distribution/#uniform-distribution","title":"Uniform Distribution","text":"<ul> <li>If \\(I = [a_{1}, b_{1}]\\times ..\\times[a_{n}, b_{n}]\\) is n dim interval in \\(\\mathbb{R}^{n}\\)</li> <li>PDF \\(\\(p(x) = \\begin{cases}\\frac{1}{(b_{1}-a_{1})\\cdot\u2026\\cdot(b_{n}, a_{n})} &amp; \\text{if } x \\in I\\\\[2ex]0&amp;\\text{if x }\\notin I \\end{cases}\\)\\)</li> <li>No need to learn, no shape that can be specified</li> </ul>"},{"location":"KB/Uniform%20Sampling/","title":"Uniform Sampling","text":""},{"location":"KB/Uniform%20Sampling/#uniform-sampling","title":"Uniform Sampling","text":"<ul> <li>Random Sampler</li> <li>Uniform Distribution</li> <li>If need to sample from another distribution with a PDF f(x). Can use a uniform Sampler on the distribution [0,1] to indirectly sample from it<ul> <li>Coordinate transform</li> <li>CDF</li> <li>Get a Sampler for by \\(\\(X_{i} = \\varphi^{-1}\\circ U_{i}\\)\\)</li> <li></li> </ul> </li> </ul>"},{"location":"KB/Uniform%20baseline/","title":"Uniform baseline","text":""},{"location":"KB/Uniform%20baseline/#uniform-baseline","title":"Uniform baseline","text":"<ul> <li>This time, the baseline doesn\u2019t require an input image and uses only uniform distribution to generate a baseline</li> <li>The problem with selecting a baseline is not solved, and for any further experiments, the \u201cblack image\u201d baseline is going to be used.</li> </ul>"},{"location":"KB/Unique%20Character%20Set/","title":"Unique Character Set","text":""},{"location":"KB/Unique%20Character%20Set/#unique-character-set","title":"Unique Character Set","text":"<ul> <li>helps in identifying the language</li> <li>Greek or Hebrew</li> </ul>"},{"location":"KB/Universal%20Approximation%20Theorem/","title":"Universal Approximation Theorem","text":""},{"location":"KB/Universal%20Approximation%20Theorem/#universal-approximation-theorem","title":"Universal Approximation Theorem","text":"<ul> <li>What this means that given an x and a y, the NN can identify a mapping between them. \"Approximately\".</li> <li>This is required when we have non linearly separable data.</li> <li>So we take a non linear function, for example the Sigmoid. \\(\\(\\frac{1}{1 + e^{ - \\left( w^{T}x + b \\right)}}\\)\\).</li> <li>Then we have to combine multiple such neurons in a way such that we can accurately model our problem. The end result is a complex function and the existing weights are distributed across many Layers.</li> <li> <p>The Universal approximation theorem states that     &gt; a feed forward network with a single hidden layer containing a finite number of neurons can approximate continuous functions on compact subsets of \\(\\mathbb{R}\\) , under mild assumptions on the activation function.</p> </li> <li> <p>a feed forward network : take an input, apply a function, get an output, repeat</p> </li> <li>a single hidden layer : yes you can use more, but theoretically\u2026</li> <li>finite number of neurons: you can do it without needing an infinite computer</li> <li>approximate continuous functions: continuous functions are anything which dont have breaks/holes in between. This just says that it is possible to approximate the mapping which we talked about \\(\\mathbb{R}\\) is just the set of all real numbers</li> <li>All this boils down to the fact that a neural network can approximate any complex relation given an input and an output.</li> <li></li> <li></li> </ul>"},{"location":"KB/Universal%20Approximation%20Theorem/#refs","title":"Refs","text":"<ul> <li>mm</li> </ul>"},{"location":"KB/Universal%20Quantifiers/","title":"Universal Quantifiers","text":""},{"location":"KB/Universal%20Quantifiers/#universal-quantifiers","title":"Universal Quantifiers","text":"<ul> <li>All the boys are building a snowman</li> <li>Each boy is building a snowman</li> <li>Two universally quantified sentences that involve/exhaust the totality of boys</li> <li>Collective Interpretation</li> <li>Distributive Interpretation</li> <li>Distributive Interpretation (2)</li> <li>Cumulative Interpretation</li> </ul>"},{"location":"KB/Unrestricted%20Race%20Model/","title":"Unrestricted Race Model","text":""},{"location":"KB/Unrestricted%20Race%20Model/#unrestricted-race-model","title":"Unrestricted Race Model","text":"<ul> <li>The Unrestricted Race model (Traxler, Pickering, &amp; Clifton, 1998; van Gompel, Pickering, Pearson, &amp; Liversedge, 2005; van Gompel, Pickering, &amp; Traxler, 2001) follows in the footsteps of constraint-based models in proposing simultaneous integration of multiple constraints from statistical, semantic, and contextual sources</li> <li>However, rather than ambiguity resolution being based on a temporally dynamic competition process, the Unrestricted Race model posits an instantaneous probabilistic selection among the weighted alternatives of an ambiguity.</li> <li>much like the syntax-first models, it must hypothesize a separate reanalysis mechanism that is responsible for garden-path effects when the initial selected alternative turns out to be syntactically or semantically inappropriate.</li> <li>the Unrestricted Race model predicts that sentences with garden-paths and sentences without garden-paths are two separate populations of events</li> <li>In other words, in conditions where mean performance is expected to exhibit a garden-path effect, there should exist one of two possible patterns: (a) a bimodal distribution of some substantial gardenpath responses and some non-gardenpath responses, or (b) practically all trials exhibiting substantial garden-path effect</li> </ul>"},{"location":"KB/Unsupervised%20Data%20Generation/","title":"Unsupervised Data Generation","text":""},{"location":"KB/Unsupervised%20Data%20Generation/#unsupervised-data-generation","title":"Unsupervised Data Generation","text":"<ul> <li>training data creation procedure named Unsupervised Data Generation (UDG), which leverages few-shot prompts to synthesize high-quality training data without real human annotations</li> </ul>"},{"location":"KB/Unsupervised%20Learning/","title":"Unsupervised Learning","text":""},{"location":"KB/Unsupervised%20Learning/#unsupervised-learning","title":"Unsupervised Learning","text":"<ul> <li>Discover useful things from raw data</li> <li>Representation/Embedding Learning</li> <li>If labels , train network and take intermediate Layers</li> <li>Clustering</li> <li>PCA</li> <li>Feature Learning</li> <li>Hidden Models</li> <li>Generative Models</li> <li>Anomaly Detection</li> <li>Auto Encoders</li> </ul>"},{"location":"KB/Unsupervised%20Learning/#_1","title":"\u2026","text":""},{"location":"KB/Untitledp/","title":"Untitledp","text":"<pre><code>def proxy_one_batch(config, input_wrong, cam):\n    grads = cam(input_tensor=input_wrong.to(config[\"device\"]), targets=None)\n    grads = torch.Tensor(grads).to(config[\"device\"]).unsqueeze(1).expand(-1, 3, -1, -1)\n    normalized_inps = inv_normalize(input_wrong)\n\n    if config[\"pixel_replacement_method\"] != \"blended\":\n        output =  torch.where(\n            grads &gt; config[\"proxy_threshold\"],\n            dict_decide_change[config[\"pixel_replacement_method\"](grads),\n            normalized_inps,\n        )\n    else:\n        output= torch.where(\n            grads &gt; config[\"proxy_threshold\"],\n            (1 - config[\"proxy_image_weight\"] * grads) * normalized_inps,\n            normalized_inps,\n        )\n    del grads\n    return output\n\n</code></pre> <pre><code>def proxy_callback(config, input_wrong_full, label_wrong_full, cam):\n    # TODO Save Classwise fraction\n    chosen_inds = int(np.ceil(config[\"change_subset_attention\"] * len(label_wrong_full)))\n    # TODO some sort of decay?\n    # TODO Remove min and batchify\n\n    input_wrong_full = input_wrong_full[:chosen_inds]\n    label_wrong_full = label_wrong_full[:chosen_inds]\n\n    processed_labels = []\n    processed_thresholds = []\n\n    for i in tqdm(range(0, len(input_wrong_full), config[\"batch_size\"]), desc=\"Running proxy\"):\n        try:\n            input_wrong = input_wrong_full[i:i+config[\"batch_size\"]\n            label_wrong = label_wrong_full[i:i+config[\"batch_size\"]\n\n            try:\n                input_wrong = torch.squeeze(torch.stack(input_wrong, dim=1))\n                label_wrong = torch.squeeze(torch.stack(label_wrong, dim=1))\n            except:\n                input_wrong = torch.squeeze(input_wrong)\n                label_wrong = torch.squeeze(label_wrong)\n\n            thresholded_ims = proxy_one_batch(config, input_wrong.to(config[\"device\"]), cam)\n            processed_thresholds.extend(thresholded_ims.detach().cpu())\n            processed_labels.extend(label_wrong)\n\n\n    processed_thresholds = torch.stack(processed_thresholds, dim = 0).detach()\n    batch_size = processed_thresholds.size(0)\n\n    for ind in tqdm(range(batch_size), total=batch_size, desc=\"Saving images\"):\n        label = config[\"label_map\"][processed_labels[ind].item()]\n        save_name = (\n            config[\"ds_path\"] / label / f\"proxy-{ind}-{config['global_run_count']}.jpeg\"\n        )\n        tfm(processed_thresholds[ind, :, :, :]).save(save_name)\n\n</code></pre>"},{"location":"KB/Uplift%20Modeling/","title":"Uplift Modeling","text":""},{"location":"KB/Uplift%20Modeling/#uplift-modeling","title":"Uplift Modeling","text":"<ul> <li>A modeling technique, commonly used in marketing, that models the \"causal effect\" (also known as the \"incremental impact\") of a \"treatment\" on an \"individual.\" Here are two examples</li> <li>Doctors might use uplift modeling to predict the mortality decrease (causal effect) of a medical procedure (treatment) depending on the age and medical history of a patient (individual).</li> <li>Marketers might use uplift modeling to predict the increase in probability of a purchase (causal effect) due to an advertisement (treatment) on a person (individual).</li> </ul>"},{"location":"KB/Upweighting/","title":"Upweighting","text":""},{"location":"KB/Upweighting/#upweighting","title":"Upweighting","text":"<ul> <li>Applying a weight to the downsampled class equal to the factor by which you downsampled.</li> </ul>"},{"location":"KB/Use%20Case%20Utility/","title":"Use Case Utility","text":""},{"location":"KB/Use%20Case%20Utility/#use-case-utility","title":"Use Case Utility","text":"<ul> <li>XAI and LLMs are often tools for accomplishing some other goal.</li> <li>Very limited work has explored the utility of LLMs in use-case\u2013 specified user studies, but a user study on Microsoft/Github's Copilot [1], an LLM-based code generation tool, found that it \"did not necessarily improve the task completion time or success rate\" [52]</li> <li>LLM outputs often sound very confident, even if what they are saying is hallucinated [50]</li> <li>When the user inquires about the incorrectness, they also have a documented tendency to argue that the user is wrong and that their response is correct. In fact, some have called LLMs \"mansplaining as a service\" [34]</li> <li>This can make it more difficult for humans to implement cognitive checks on LLM outputs.</li> <li>While some recent LLM work has outlined categories of failure modes for LLMs based on the types of cognitive biases use [29], we push for greater work in this field</li> </ul>"},{"location":"KB/Useful%20Codes/","title":"Useful Codes","text":""},{"location":"KB/Useful%20Codes/#useful-codes","title":"Useful Codes","text":"<ul> <li>Parallel Runner</li> </ul>"},{"location":"KB/Utilitarian%20ethics/","title":"Utilitarian ethics","text":""},{"location":"KB/Utilitarian%20ethics/#utilitarian-ethics","title":"Utilitarian Ethics","text":"<ul> <li>resulting decisions often aim to produce the best aggregate consequences</li> </ul>"},{"location":"KB/VAE/","title":"Variational Autoencoder","text":""},{"location":"KB/VAE/#variational-autoencoder","title":"Variational Autoencoder","text":"<ul> <li>Some control over distribution of learned features</li> <li>Eg: Decoder as a generative model</li> <li>Constraint loss function and a given Probability \\(\\mathcal{D}\\)<ul> <li>Eg: By Loss func KL Divergence and prob distribution $\\(L(X) = n^{-1}\\Sigma_i||x_i - D(E(\\tilde x))||^2 + \\lambda \\cdot KL(f_i, d)\\)</li> <li>Use 2D unit distribution. 0 mean, unit variance</li> <li>Latent vector : \\(\\(f=\\mu + \\epsilon e^{2log\\sigma}\\)\\)</li> </ul> </li> <li>$\\(L(X) = n^{-1}\\Sigma_i||x_i - D(E(\\tilde x))||^2 + \\frac{1}{2n}\\Sigma_i(e^{log\\sigma(x_i)} + \\mu(x_i)^2 -1 -log(\\sigma (x_i))\\)</li> <li>Encoder predicts mean and std \\(\\(E(x_i) = (\\mu(x_i) , log \\sigma(x_i))\\)\\)</li> </ul>"},{"location":"KB/VGGFace2%203/","title":"VGGFace2","text":""},{"location":"KB/VGGFace2%203/#vggface2","title":"VGGFace2","text":"<ul> <li>A dataset for recognising faces across pose and age.</li> <li>The VGGFace2 dataset is made of around 3.31 million images divided into 9131 classes, each representing a different person identity.</li> </ul>"},{"location":"KB/VGGish/","title":"VGGish","text":""},{"location":"KB/VGGish/#vggish","title":"VGGish","text":"<ul> <li>CNN Architectures for Large-Scale Audio Classification</li> <li>applying various state-of-the-art image networks with CNN architectures to audio and show that they are capable of excellent results on audio classification</li> <li>examine fully connected deep neural networks such as AlexNet, VGG, InceptionNet, and ResNet</li> <li>The input audio is divided into non-overlapping 960 ms frames which are decomposed by applying the Fourier transform, resulting in a spectrogram</li> <li>spectrogram is integrated into 64 mel-spaced frequency bins, and the magnitude of each bin is log-transformed</li> <li>gives log-mel spectrogram patches that are passed on as input to all classifiers</li> <li>Acoustic Event Detection</li> <li>train a classifier on embeddings learned from the video-level task on AudioSet</li> <li>model for AED with embeddings learned from these classifiers does much better than raw features on the Audio Set AED classification task</li> <li>derivatives of image classification networks do well on the audio classification task</li> <li>increasing the number of labels they train on provides some improved performance over subsets of labels</li> <li>performance of models improves as they increase training set size,</li> <li>model using embeddings learned from the video-level task do much better than a baseline on the AudioSet classification task</li> </ul>"},{"location":"KB/VICReg/","title":"VICReg","text":"<ul> <li>VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning</li> <li>Self Supervised</li> <li>based on maximizing the agreement between Embedding vectors from different views of the same image</li> <li>rivial solution is obtained when the encoder outputs constant vectors</li> <li>Mode Collapse is often avoided through implicit biases</li> <li>explicitly avoids the collapse problem with a simple regularization term on the variance of the embeddings along each dimension individually</li> <li>triple objective: learning invariance to different views with a invariance term, avoiding collapse of the representations with a variance preservation term, and maximizing the information content of the representation with a covariance regularization term</li> <li>Bias Vs Variance</li> <li>combines the variance term with a decorrelation mechanism based on redundancy reduction and covariance regularization</li> <li>does not require the embedding branches to be identical or even similar</li> </ul>"},{"location":"KB/VL-BEIT/","title":"VL-BEIT","text":""},{"location":"KB/VL-BEIT/#vl-beit","title":"VL-BEIT","text":"<ul> <li>VL-BEIT: Generative Vision-Language Pretraining</li> <li>vision-language foundation model</li> <li>simple and effective approach to pretraining a bidirectional multimodal Transformer encoder for both vision-language and vision tasks learned by generative pretraining</li> <li>conducts masked prediction on both monomodal and multimodal data with a shared Transformer</li> <li>solely employs generative pretraining tasks, including masked language modeling on texts, masked image modeling on images, and masked vision-language modeling on image-text pairs</li> <li>learned from scratch with one unified pretraining task, one shared backbone, and one-stage training which renders it conceptually simple and empirically effective</li> <li>transferable visual features</li> </ul>"},{"location":"KB/VQAv2%203/","title":"VQAv2","text":""},{"location":"KB/VQAv2%203/#vqav2","title":"VQAv2","text":""},{"location":"KB/VTAB/","title":"VTAB","text":"<p>toc: true title: VTAB</p> <p>categories: ['temp']</p>"},{"location":"KB/VTAB/#vtab","title":"VTAB","text":""},{"location":"KB/Vacuum%20Cup%20Hand/","title":"Vacuum Cup Hand","text":""},{"location":"KB/Vacuum%20Cup%20Hand/#vacuum-cup-hand","title":"Vacuum Cup Hand","text":"<ul> <li>An end-effector for a robot arm which is used to grasp light to moderate weight objects, using suction, for manipulation. Such objects may include glass, plastic; etc. Commonly used because of its virtues of reduced object slide slipping while within the grasp of the vacuum cup.</li> </ul>"},{"location":"KB/Vagus%20Nerve/","title":"Vagus Nerve","text":""},{"location":"KB/Vagus%20Nerve/#vagus-nerve","title":"Vagus Nerve","text":"<ul> <li>One of the twelve pairs of cranial nerves in the human body, the vagus nerve connects the brain stem to the body, transmitting information from the brain to the major organs and other tissues.</li> </ul>"},{"location":"KB/Vanishing%20Gradient/","title":"Vanishing Gradient","text":""},{"location":"KB/Vanishing%20Gradient/#vanishing-gradient","title":"Vanishing Gradient","text":"<ul> <li>Deltas become smaller initially. using [Sigmoid] -&gt; ill conditioning </li> <li> \\[g(x) = (1+e^{-x})^{-1}\\] </li> <li> \\[\\nabla_{x}[g] = g(1-g) \\in [0,1]\\] </li> <li>Saturation and prevent Backprop </li> <li> \\[g(x) \\approx 1 \\rightarrow \\nabla_{x}[g] \\approx 0 \\] </li> <li>Weight matrices are usually initialized with random values \\(|w_{ji}| &lt;&lt; 1\\) <ul> <li>gradient magnitueds decay exponentially -&gt; max eigenvalue</li> </ul> </li> </ul>"},{"location":"KB/VarGrad/","title":"VarGrad","text":""},{"location":"KB/VarGrad/#vargrad","title":"VarGrad","text":""},{"location":"KB/VarGrad/#-richtervargradlowvariancegradient2020","title":"- @richterVarGradLowVarianceGradient2020","text":""},{"location":"KB/Variable%20Importances/","title":"Variable Importances","text":""},{"location":"KB/Variable%20Importances/#variable-importances","title":"Variable Importances","text":"<ul> <li>A set of scores that indicates the relative importance of each feature to the model.</li> </ul>"},{"location":"KB/Variation%20in%20Dissimilarity%20Variation%20in%20Dissimilarity/","title":"Variation in Dissimilarity Variation in Dissimilarity","text":""},{"location":"KB/Variation%20in%20Dissimilarity%20Variation%20in%20Dissimilarity/#variation-in-dissimilarity-variation-in-dissimilarity","title":"Variation in Dissimilarity Variation in Dissimilarity","text":"<ul> <li>is the variance of the NISSIM metric over the adversarial set over different levels of attack eps for a model, this shows the distribution of the attack on the model when different levels of attack are performed</li> <li>Ideally, we would want the distribution to be stable for different levels of attack</li> <li> \\[m_{h}= \\frac{1}{eps}\\Sigma(NISSIM_{eps})\\] </li> <li> \\[VID = \\sqrt{\\frac{\\Sigma(NISSIM_{eps}-m_{h})^{2}}{eps}}\\] </li> </ul>"},{"location":"KB/VariationalRecurrent%20Dropout/","title":"Variational/Recurrent Dropout","text":""},{"location":"KB/VariationalRecurrent%20Dropout/#variationalrecurrent-dropout","title":"Variational/Recurrent Dropout","text":"<ul> <li>Basic RNN Architectures</li> <li>Only on the non Recurrent parts such as inputs and outputs</li> <li>In recorrent parts, use the same dropout mask for all time steps</li> <li>Same dropout mask for each time step</li> <li></li> </ul>"},{"location":"KB/VariationalRecurrent%20Dropout/#_1","title":"\u2026","text":""},{"location":"KB/VattenFall%20Data%20Scientist/","title":"VattenFall Data Scientist","text":""},{"location":"KB/VattenFall%20Data%20Scientist/#vattenfall-motivation-letter-subhaditya","title":"VattenFall Motivation Letter - Subhaditya","text":"<p>As I write this motivation letter, the temperatures in NL have hit yet another record for the hottest September ever. One of the biggest reasons for this is global warming, and fossil fuels are a massive component. VattenFall's mission to be fossil-free in one generation and help customers shift towards sustainable energy sources using data greatly resonates with me, so I am applying for this position as a Data Scientist. At the core of making the world a greener and healthier place is data that every company has collected for decades. Using that vast data pool to inform better decisions is quite challenging but equally rewarding.</p> <p>My expertise is a combination of data analytics/BI and computer vision, and as of a month ago, I also have a Master in Artificial Intelligence from the University of Groningen. I am familiar with the tools required for basic and advanced AI and analytics from internships, research projects, papers, freelance work, and many personal projects. In my previous internship at KPMG, I built 10+ dashboards using PowerBI and Azure for a project with the Abu Dhabi government. I have made several analytics pipelines and machine learning implementations in other internships. I am familiar with Python and can build advanced AI pipelines for many tasks.</p> <p>In any team, it is essential that each of the members can contribute something to the overall development of the projects. Although I have a lot to learn, I genuinely enjoy developing solutions that have a positive impact, and I can contribute quite a bit to any team I get the chance to work with. If there is anything I do not know, I am also ready to develop those skills quickly.</p> <p>I hope you give me a chance to be a part of the generation that finally starts relying on greener energy sources for our own and future generations.</p>"},{"location":"KB/Vector%20Assembly%20level/","title":"Vector Assembly level","text":""},{"location":"KB/Vector%20Assembly%20level/#vector-assembly-level","title":"Vector Assembly Level","text":""},{"location":"KB/Vector%20Chaining/","title":"Vector Chaining","text":""},{"location":"KB/Vector%20Chaining/#vector-chaining","title":"Vector Chaining","text":"<ul> <li>Equivalent to data forwarding in vector processors</li> <li>Results of one pipeline are fed into operand registers of another pipeline</li> </ul>"},{"location":"KB/Vector%20Functional%20Units/","title":"Vector Functional Units","text":""},{"location":"KB/Vector%20Functional%20Units/#vector-functional-units","title":"Vector Functional Units","text":"<ul> <li>Fully pipelined, new operation every cycle</li> <li>Performs arithmetic and logic operations</li> <li>Typically 4-8 different units</li> </ul>"},{"location":"KB/Vector%20Load%20Store%20Units/","title":"Vector Load Store Units","text":""},{"location":"KB/Vector%20Load%20Store%20Units/#vector-load-store-units","title":"Vector Load Store Units","text":"<ul> <li>Moves vectors between memory and registers</li> </ul>"},{"location":"KB/Vector%20Processor/","title":"Vector Processor","text":""},{"location":"KB/Vector%20Processor/#vector-processor","title":"Vector Processor","text":"<ul> <li>Memory to Memory Architecture</li> <li>Register to Register Architecture</li> <li>Vector Register</li> <li>Scalar Register</li> <li>Vector Functional Units</li> <li>Vector Load Store Units</li> <li>Strip Mining</li> <li>Vector Chaining</li> <li>Scatter and Gather</li> <li>Pipes</li> <li>Vector Assembly level</li> </ul>"},{"location":"KB/Vector%20Quantization/","title":"Vector Quantization","text":""},{"location":"KB/Vector%20Quantization/#vector-quantization","title":"Vector Quantization","text":"<ul> <li>Partitioned into k cells whose center of Gravity vectors are indexed</li> <li>Indices used as symbolic encodings</li> <li>Discretization</li> </ul>"},{"location":"KB/Vector%20Register/","title":"Vector Register","text":""},{"location":"KB/Vector%20Register/#vector-register","title":"Vector Register","text":"<ul> <li>Typically 8-32 vector registers with 64 -128 64-bit elements</li> <li>Each contains a vector of double-precision numbers</li> <li>Register size determines the maximum vector length</li> <li>Each includes at least 2 read and 1 write ports</li> </ul>"},{"location":"KB/Vectorization/","title":"Vectorization","text":""},{"location":"KB/Vectorization/#vectorization","title":"Vectorization","text":"<ul> <li>Hardware primitives</li> <li>Prioritize those are contiguous in memory</li> </ul>"},{"location":"KB/Velocity/","title":"Velocity","text":""},{"location":"KB/Velocity/#velocity","title":"Velocity","text":"<ul> <li>Displacement wrt time</li> <li> \\[v_{avg}= \\frac{\\Delta{x}}{\\Delta t}\\] </li> </ul>"},{"location":"KB/Verb/","title":"Verb","text":""},{"location":"KB/Verb/#verb","title":"Verb","text":"<ul> <li>Actions, relationships</li> <li>Transitive verb</li> <li>DiTransitive verb</li> <li>Action Transitive verb</li> </ul>"},{"location":"KB/Vertebral%20Arteries/","title":"Vertebral Arteries","text":""},{"location":"KB/Vertebral%20Arteries/#vertebral-arteries","title":"Vertebral Arteries","text":"<ul> <li>The major arteries of the neck, which merge to form the basilar artery.</li> </ul>"},{"location":"KB/Vestibular%20System/","title":"Vestibular System","text":""},{"location":"KB/Vestibular%20System/#vestibular-system","title":"Vestibular System","text":"<ul> <li>Regions in the body and brain that help support balance in movement. Many people with hearing loss experience some degree of balance difficulties, since the vestibular (or balance) system and the auditory (or hearing) systems are so closely related.</li> </ul>"},{"location":"KB/Vgg/","title":"Vgg","text":""},{"location":"KB/Vgg/#vgg","title":"Vgg","text":"<ul> <li>@simonyanVeryDeepConvolutional2014</li> <li>Very Deep Convolutional Networks for Large-Scale Image Recognition</li> <li>Deeper Alex Net</li> <li>Object detection and Image captioning</li> <li>5x5 -&gt; two 3x3</li> <li>No of filters increase according to depth</li> <li>No of filters : increase by power of two</li> <li>Filter size : Odd numbers</li> <li>SGD + LR Schedule</li> <li>three non-linear activations (instead of one), which makes the function more discriminative</li> </ul>"},{"location":"KB/ViLT/","title":"ViLT","text":""},{"location":"KB/ViLT/#vilt","title":"ViLT","text":"<ul> <li>ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision</li> <li>Vision-and-Language Transformer</li> <li>seeks to improve performance on various joint vision-and-language downstream tasks</li> <li>Current approaches to VLP heavily rely on image feature extraction processes using convolutional visual embedding networks (e.g., Faster R-CNN and ResNets), which involve region supervision (e.g., object detection) and the convolutional architecture (e.g., ResNet)</li> <li>This is problematic in terms of both efficiency/speed, in that extracting input features requires much more computation than the multimodal interaction steps; and expressive power, as it is upper bounded to the expressive power of the visual embedder and its predefined visual vocabulary.</li> <li>minimal VLP model, which is monolithic in that the processing of visual inputs is drastically simplified to just the same convolution-free manner that they process textual inputs</li> <li>removing the need for object detectors</li> <li>avoiding heavyweight image encoders by directly embedding low-level pixel data with a single-layer projection and achieves similar results with reduced complexity,</li> <li>Self-supervision is accomplished using (i) Image Text Matching (ITM) loss and (ii) Masked Language Model (MLM) loss</li> <li>ITM Loss</li> <li>For text, ViLT simply reuses Masked Language Model - (MLM), used in BERT.</li> <li>MSCOCO</li> <li>Visual Genome</li> <li>SBU Captions</li> <li>Google Conceptual Captions</li> <li>VQAv2</li> <li>NLVR2</li> <li>Flickr30K</li> <li>ViLT is over 10x faster than previous VLP models, yet with competitive or better downstream task performance</li> <li>VLP needs to focus more on the multi-modality interactions aspect inside the transformer module rather than engaging in an arms race that merely powers up unimodal embedders</li> </ul>"},{"location":"KB/Video%20Generation/","title":"Video Generation","text":""},{"location":"KB/Video%20Generation/#video-generation","title":"Video Generation","text":"<ul> <li>Visual features are learned through the process of video generation tasks </li> <li>video prediction</li> </ul>"},{"location":"KB/Viewpoint%20Feature%20Histogram/","title":"Viewpoint Feature Histogram","text":""},{"location":"KB/Viewpoint%20Feature%20Histogram/#viewpoint-feature-histogram","title":"Viewpoint Feature Histogram","text":"<ul> <li>VFH produces a histogram that encodes the geometry of the object and its viewpoint.</li> <li>For every pair of a point and the center of mass, a reference frame is constructed and the three angular variations are computed (a, q, f) and also d which represents distance between (point, center of mass)</li> <li>Another statistical feature is computed between the central viewpoint direction and the normal estimated at each point.</li> <li>The quality of VFH description depends on the quality of the surface normal estimation at each point.</li> <li></li> </ul>"},{"location":"KB/Virtue%20ethics/","title":"Virtue ethics","text":""},{"location":"KB/Virtue%20ethics/#virtue-ethics","title":"Virtue Ethics","text":"<ul> <li>an agent is ethical if and only if it acts and thinks according to some moral values</li> <li>Agents with virtue ethics should exhibit an inner drive to be perceived favourably by others</li> </ul>"},{"location":"KB/Vision%20Explainibility/","title":"Vision Explainibility","text":""},{"location":"KB/Vision%20Explainibility/#vision-explainibility","title":"Vision Explainibility","text":""},{"location":"KB/Vision%20Explainibility/#links-useful","title":"Links Useful","text":"<ul> <li>Captum Algos Comparison</li> </ul>"},{"location":"KB/Vision%20Explainibility/#flow","title":"Flow","text":"<ul> <li>DeconvNet (2013)</li> <li>Deep Inside Convolutional Networks (2014)</li> <li>Guided BackProp (2015) Aka All Conv net<ul> <li>Building up on Deep Inside Convolutional Networks and DeconvNet</li> </ul> </li> <li>Salience Map<ul> <li>Not class discriminative</li> <li>Noise</li> <li>Not appealing</li> </ul> </li> <li>CAM<ul> <li>less noisy</li> <li>not class discriminative</li> <li>Worked only a restricted set of CNN templates</li> </ul> </li> <li>Grad-CAM<ul> <li>class discriminative</li> <li>not high res</li> <li>Works for any arbitrary CNN</li> </ul> </li> <li>Occlusion Map<ul> <li>Same as the next but not very fast</li> </ul> </li> <li>Guided GradCAM</li> <li>DeepLIFT</li> <li>Noise Tunnel</li> <li>Smooth-Grad</li> <li>SmoothGrad Square</li> <li>VarGrad</li> <li>Integrated Gradients</li> <li>Proxy Attention</li> <li>Conductance</li> </ul>"},{"location":"KB/Vision%20Explainibility/#disadvantages","title":"Disadvantages","text":"<ul> <li>The Unreliability of Saliency Methods</li> <li>Interpretation of Neural networks is fragile</li> <li>Fine grained data</li> </ul>"},{"location":"KB/Vision%20Explainibility/#links","title":"Links","text":""},{"location":"KB/Vision%20Transformer/","title":"Vision Transformer","text":""},{"location":"KB/Vision%20Transformer/#vision-transformer","title":"Vision Transformer","text":"<ul> <li>@dosovitskiyImageWorth16x162021</li> <li>paper</li> <li></li> <li>Transformer applied directly to sequences/patches of images</li> <li>Lower computational resources</li> <li>ImageNet , CIFAR, VTAB</li> <li>Do Vision Transformers See Like Convolutional Neural Networks?</li> <li>analyzes the internal representation structure of ViTs and Conv on image classification benchmarks</li> <li>striking differences in the features and internal structures between the two architectures</li> <li>ViT having more uniform representations across all layers</li> <li>early aggregation of global information</li> <li>spatial localization</li> <li>discovering ViTs successfully preserve input spatial information with CLS tokens</li> <li>finding larger ViT models develop significantly stronger intermediate representations through larger pretraining datasets</li> <li>MLP-Mixer</li> </ul>"},{"location":"KB/Visual%20Associative/","title":"Visual Associative","text":""},{"location":"KB/Visual%20Associative/#visual-associative","title":"Visual Associative","text":"<ul> <li>Can this variable allow us to spontaneously group items in a group? [i.e., 1 group from all]</li> </ul>"},{"location":"KB/Visual%20Commonsense%20Reasoning/","title":"Visual Commonsense Reasoning","text":""},{"location":"KB/Visual%20Commonsense%20Reasoning/#visual-commonsense-reasoning","title":"Visual Commonsense Reasoning","text":"<ul> <li>Given a challenging question about an image, a machine must answer correctly and then provide a rationale justifying its answer</li> <li>From Recognition to Cognition: Visual Commonsense Reasoning</li> <li>290k multiple choice QA problems derived from 110k movie scenes</li> <li>Adversarial Learning</li> </ul>"},{"location":"KB/Visual%20Context%20Augmentation/","title":"Visual Context Augmentation","text":""},{"location":"KB/Visual%20Context%20Augmentation/#visual-context-augmentation","title":"Visual Context Augmentation","text":"<ul> <li>@dvornikModelingVisualContext2018</li> <li>learns to place object instances at an image location depending on the surrounding context.</li> <li>A neural network is trained for this purpose.</li> <li>The training data is pre- pared to generate a context image with the masked- out object inside it.</li> <li>From an image, 200 context sub-images are generated surrounding the blacked- out bounding box. The neural network learns to predict the category (object or background) in masked pixels.</li> <li>The object instances are placed inside the selected boxes to generate a new train- ing image</li> </ul>"},{"location":"KB/Visual%20Cortex/","title":"Visual Cortex","text":""},{"location":"KB/Visual%20Cortex/#visual-cortex","title":"Visual Cortex","text":"<ul> <li>The area of the cerebrum that is specialized for vision. It lies primarily in the occipital lobe at the rear of the brain and is connected to the eyes by the optic nerves.</li> </ul>"},{"location":"KB/Visual%20Encoding/","title":"Visual Encoding","text":""},{"location":"KB/Visual%20Encoding/#visual-encoding","title":"Visual Encoding","text":"<ul> <li>Characteristics of Visual Variables</li> </ul>"},{"location":"KB/Visual%20Genome/","title":"Visual Genome","text":""},{"location":"KB/Visual%20Genome/#visual-genome","title":"Visual Genome","text":""},{"location":"KB/Visual%20Implicit%20Learning/","title":"Visual Implicit Learning","text":""},{"location":"KB/Visual%20Implicit%20Learning/#visual-implicit-learning","title":"Visual Implicit Learning","text":"<ul> <li>Does ability to learn implicit dependencies correlate with ability to correctly predict the next word in speech?</li> <li>Participants saw a sequence of colors light up on screen</li> <li>They then had to reproduce it by clicking on the same sequence</li> <li>Auditory Only Sentence Perception</li> <li>25 highly predictable and 25 zero-predictability sentences</li> <li>acoustically degraded by processing them with a sinewave vocoder to 6 channels</li> <li>Ability to pick up/learn statistical dependencies seems almost to be a new cognitive function</li> <li>Shows a potential connection between sequence learning and language modelling ability</li> <li>Learning simple dependencies is not so difficult it seems. But natural language has many dependencies at a distance</li> </ul>"},{"location":"KB/Visual%20Length/","title":"Visual Length","text":""},{"location":"KB/Visual%20Length/#visual-length","title":"Visual Length","text":"<ul> <li>Across how many changes in this variable are distinctions possible? [i.e., how many can I see?]</li> </ul>"},{"location":"KB/Visual%20Ordered/","title":"Visual Ordered","text":""},{"location":"KB/Visual%20Ordered/#visual-ordered","title":"Visual Ordered","text":"<ul> <li>Can this variable allow us to spontaneously perceive an order [i.e., what is smaller and what is bigger?]</li> </ul>"},{"location":"KB/Visual%20Quantitative/","title":"Visual Quantitative","text":""},{"location":"KB/Visual%20Quantitative/#visual-quantitative","title":"Visual Quantitative","text":"<ul> <li>Can the difference between two marks in this variable be interpreted numerically? [i.e., corresponds to 5?]</li> </ul>"},{"location":"KB/Visual%20Selective/","title":"Visual Selective","text":""},{"location":"KB/Visual%20Selective/#visual-selective","title":"Visual Selective","text":"<ul> <li>Can this variable allow us to spontaneously differentiate/isolate items from groups? [i.e., 1 item from all]</li> </ul>"},{"location":"KB/Visual%20Servo%20System/","title":"Visual Servo System","text":""},{"location":"KB/Visual%20Servo%20System/#visual-servo-system","title":"Visual Servo System","text":"<ul> <li>The task in visual servoing is to use visual information to control the robot\u2019s end-effector relative to a target object</li> <li></li> <li>Chaumette, Franc\u0327ois, and Seth Hutchinson. \"Visual servo control. II. Advanced approaches [Tutorial].\" IEEE Robotics &amp; Automation Magazine 14.1 (2007): 109-118.</li> <li>Morrison, Douglas, Peter Corke, and Ju\u0308rgen Leitner. \"Closing the loop for robotic grasping: A real-time, generative grasp synthesis approach.\" RSS (2018).</li> <li></li> <li></li> <li></li> </ul>"},{"location":"KB/VisualGPT/","title":"VisualGPT","text":""},{"location":"KB/VisualGPT/#visualgpt","title":"VisualGPT","text":"<ul> <li>image captioning model</li> <li>leverages knowledge from the pretrained language model GPT-2</li> <li>bridge the semantic gap between diferent modalities - novel encoder-decoder attention mechanism [33] is designed with an unsaturated rectified gating function</li> <li>the biggest advantage of this model is that it does not need for as much data as other image-to-text models</li> <li>improving data eciency in image captioning networks would enable quick data curation, description of rare objects, and applications in specialized domains</li> </ul>"},{"location":"KB/Visualization%20Of%20Layers/","title":"Visualization Of Layers","text":""},{"location":"KB/Visualization%20Of%20Layers/#visualization-of-layers","title":"Visualization Of Layers","text":"<ul> <li>Tanh</li> <li>\\(tanh(Wx+b)\\)</li> <li> <ol> <li>A linear transformation by the \u201cweight\u201d matrix\u00a0\\(W\\)</li> </ol> </li> <li> <ol> <li>A translation by the vector\u00a0\\(b\\)</li> </ol> </li> <li> <ol> <li>Point-wise application of tanh.</li> </ol> </li> </ul>"},{"location":"KB/Visualizing%20the%20Impact%20of%20Feature%20Attribution%20Baselines/","title":"Visualizing the Impact of Feature Attribution Baselines","text":""},{"location":"KB/Visualizing%20the%20Impact%20of%20Feature%20Attribution%20Baselines/#visualizing-the-impact-of-feature-attribution-baselines","title":"Visualizing the Impact of Feature Attribution Baselines","text":"<ul> <li>@sturmfelsVisualizingImpactFeature2020</li> <li>Maximum Distance Baseline</li> <li>Uniform baseline</li> </ul>"},{"location":"KB/Visualizing%20the%20Loss%20Landscape%20of%20Neural%20Nets/","title":"Visualizing the Loss Landscape of Neural Nets","text":""},{"location":"KB/Visualizing%20the%20Loss%20Landscape%20of%20Neural%20Nets/#visualizing-the-loss-landscape-of-neural-nets","title":"Visualizing the Loss Landscape of Neural Nets","text":"<ul> <li>@liVisualizingLossLandscape2018</li> <li>Generalization error relates to convexity in the loss landscape<ul> <li></li> </ul> </li> <li>Random Directions</li> <li>Sharpness and Flatness</li> <li>Training Trajectories</li> </ul>"},{"location":"KB/Visualizing%20the%20Loss%20Landscape%20of%20Neural%20Nets/#solutions","title":"Solutions","text":"<ul> <li>Layer Normalization</li> <li>Filter Wise Normalization</li> <li>Trajectory Plotting with PCA</li> </ul>"},{"location":"KB/Visualizing%20the%20Loss%20Landscape%20of%20Neural%20Nets/#images","title":"Images","text":""},{"location":"KB/Volterra%20expansion/","title":"Volterra","text":""},{"location":"KB/Volterra%20expansion/#volterra","title":"Volterra","text":"<ul> <li>Add higher order polynomials</li> <li>Adding too much leads to combinatorial explosion -&gt; Pruning scheme</li> <li>Adding all polynomials of degree 2<ul> <li>(\\(d + d(d+1) /2\\)\\) input components<ul> <li> \\[{u_1, u_2, \u2026,u_d} \\cup {u_iu_j | 1 \\leq i \\leq j \\leq d}\\] </li> </ul> </li> </ul> </li> </ul>"},{"location":"KB/Volume%20Rendering%20Equation/","title":"Volume Rendering Equation","text":""},{"location":"KB/Volume%20Rendering%20Equation/#volume-rendering-equation","title":"Volume Rendering Equation","text":"<ul> <li>Light-emitting particles fill volume</li> <li>Emission-absorption mode</li> <li>Based on a physical model for radiation</li> <li>Interaction of light with matter at the macroscopic scale, neglecting Diffraction, Interference, Wave-character, Polarization, etc.</li> <li>\\(\\kappa\\) is fraction of absorbed light</li> <li>\\(g\\) is fraction of emitted light</li> <li> \\[\\frac{dL}{ds} = g(s) - \\kappa(s)L(s)\\] </li> <li>aka Emission -Absorption</li> <li> \\[T(s_{1}, s_{2}) = e^{-\\int_{s_{1}}^{s_{2}}\\kappa(s')ds'}\\] </li> <li> \\[L_{1}^{n}= g(n)+T(n)L_{1}^{n-1}\\] </li> </ul>"},{"location":"KB/Volume%20Visualization/","title":"Volume Visualization","text":""},{"location":"KB/Volume%20Visualization/#volume-visualization","title":"Volume Visualization","text":"<ul> <li>Orthogonal Slicing</li> <li>Oblique Slicing</li> <li>Isosurface</li> <li>Volumetric Illumination</li> </ul>"},{"location":"KB/Volumetric%20Grasping%20Network/","title":"Volumetric Grasping Network","text":""},{"location":"KB/Volumetric%20Grasping%20Network/#volumetric-grasping-network","title":"Volumetric Grasping Network","text":"<ul> <li>M. Breyer, et al., \"Volumetric Grasping Network: Real-time 6 DOF Grasp Detection in Clutter\", ICLR 2020</li> <li>Learning to grasp 3D objects by constructing a full model of the scene</li> <li>TSDF</li> <li></li> </ul>"},{"location":"KB/Volumetric%20Illumination/","title":"Volumetric Illumination","text":""},{"location":"KB/Volumetric%20Illumination/#volumetric-illumination","title":"Volumetric Illumination","text":"<ul> <li>Phong Lighting</li> <li>Finite Differences</li> <li>Shading</li> <li>Raycasting</li> </ul>"},{"location":"KB/Von%20Neumann%20Architecture/","title":"Von Neumann Architecture","text":""},{"location":"KB/Von%20Neumann%20Architecture/#von-neumann-architecture","title":"Von Neumann Architecture","text":"<p>-</p>"},{"location":"KB/Voronoi%20Cell/","title":"Voronoi Cell","text":""},{"location":"KB/Voronoi%20Cell/#voronoi-cell","title":"Voronoi Cell","text":"<ul> <li>Partition a plane into n convex polygons -&gt; each containing one generating point and every point is closer to its generating point than others</li> <li></li> </ul>"},{"location":"KB/Voronoi%20Cell/#refs","title":"Refs","text":"<ul> <li>wolf</li> </ul>"},{"location":"KB/Voxel%20Projection/","title":"Voxel Projection","text":""},{"location":"KB/Voxel%20Projection/#voxel-projection","title":"Voxel Projection","text":"<ul> <li>Volume = field of 3D interpolation kernels  </li> <li>One kernel at each grid voxel  </li> <li>Each kernel leaves a 2D footprint on screen</li> <li>Weighted footprints accumulate into image</li> <li></li> </ul>"},{"location":"KB/WMT14/","title":"WMT14","text":""},{"location":"KB/WMT14/#wmt14","title":"WMT14","text":""},{"location":"KB/WOMBO%20Dream/","title":"WOMBO Dream","text":""},{"location":"KB/WOMBO%20Dream/#wombo-dream","title":"WOMBO Dream","text":"<ul> <li>The app creates generative art from a descriptive text in various pre-determined styles.</li> <li>The app uses two machine learning technologies that combine a neural network to generate images and an algorithm that interprets text descriptions.</li> <li>Both algorithms learn from each iteration, meaning that every request generates a unique outcome.</li> </ul>"},{"location":"KB/Wageningen%20Uni%20AI/","title":"Wageningen Uni AI","text":""},{"location":"KB/Wageningen%20Uni%20AI/#wageningen-researcher-computer-vision-technology-for-animal-science","title":"Wageningen : Researcher Computer Vision Technology for Animal Science","text":"<p>With the demands on the food industry growing every day, it is easy for companies to start ignoring the needs of the animals that are the most significant part of the pipeline. We hear so many horror stories about the conditions some of these animals face, but even more humane places have to meet many needs. On a larger scale, using technologies like AI can make it much less labor-intensive to provide suitable conditions for these animals and make sure they live as close to their original lives in nature as possible. That being said, the intersection between computer vision and animal welfare is quite interesting to me, hence this application.</p> <p>As of a month ago, I have a masters in AI from the University of Groningen. My expertise is a combination of data analytics and computer vision for practical applications. I am familiar with the tools required for basic and advanced AI and analytics from internships, research projects, papers, freelance work, and many personal projects. I am comfortable with building deep learning pipelines, image and data analysis, OpenCV applications, image processing, etc. </p> <p>In any team, it is essential that each of the members can contribute something to the overall development of the projects. Although I have a lot to learn, I genuinely enjoy developing solutions that have a positive impact, and I can contribute quite a bit to any team I get the chance to work with. If there is anything I do not know, I am also ready to develop those skills quickly. I hope you give me a chance to work on providing better conditions for animals in this industry. </p>"},{"location":"KB/Wall%20Street%20Journal%20task/","title":"Wall Street Journal task","text":""},{"location":"KB/Wall%20Street%20Journal%20task/#wall-street-journal-task","title":"Wall Street Journal Task","text":""},{"location":"KB/WaveGlow/","title":"WaveGlow","text":""},{"location":"KB/WaveGlow/#waveglow","title":"WaveGlow","text":"<ul> <li>WaveGlow: a Flow-based Generative Network for Speech Synthesis</li> <li>flow-based network capable of generating high quality speech from mel-spectrograms</li> <li>combines insights from Glow and WaveNet in order to provide fast, efficient and high-quality audio synthesis, without the need for auto-regression</li> <li>mplemented using only a single network, trained using only a single cost function: maximizing the likelihood of the training data, which makes the training procedure simple and stable</li> <li>more than 500 kHz on an NVIDIA V100 GPU</li> <li>Mean Opinion Scores</li> </ul>"},{"location":"KB/Weak%20Relation%20Bias/","title":"Weak Relation Bias","text":""},{"location":"KB/Weak%20Relation%20Bias/#weak-relation-bias","title":"Weak Relation Bias","text":"<ul> <li>relationship between the neural units is weak, meaning that they\u2019re somewhat independent of each other. The choice of including a fully connected layer in the net can represent this kind of relationship</li> <li></li> </ul>"},{"location":"KB/Weakly%20Supervised%20Learning%20Formulation/","title":"Weakly Supervised Learning Formulation","text":""},{"location":"KB/Weakly%20Supervised%20Learning%20Formulation/#weakly-supervised-learning-formulation","title":"Weakly Supervised Learning Formulation","text":"<ul> <li>For weakly supervised visual feature learning, given a dataset X, for each data Xi in X, there is a corresponding coarse-grained label Ci.  </li> <li></li> </ul>"},{"location":"KB/Weakly-supervised%20Learning/","title":"Weakly-supervised Learning","text":""},{"location":"KB/Weakly-supervised%20Learning/#weakly-supervised-learning","title":"Weakly-supervised Learning","text":"<ul> <li>learning methods to learn with coarse-grained labels or inaccurate labels </li> <li>The cost of obtaining weak supervision labels is generally much cheaper than fine- grained labels for supervised methods.</li> </ul>"},{"location":"KB/WebGPT/","title":"WebGPT","text":""},{"location":"KB/WebGPT/#webgpt","title":"WebGPT","text":"<ul> <li>WebGPT: Browser-assisted Question-answering with Human Feedback</li> <li>fine-tuned version of GPT-3 to more accurately answer open-ended questions using a text-based web browser.</li> <li>submits search queries, follows links, and scrolls up and down web pages</li> <li>trained to cite its sources</li> <li>By setting up the task so that it can be performed by humans, they are able to train models on the task using imitation learning</li> <li>models must collect references while browsing in support of their answers</li> <li>ELI5</li> <li>dataset of questions asked by Reddit users</li> <li>fine-tuning GPT-3 using behavior cloning, and then performing rejection sampling against a reward model trained to predict human preferences</li> </ul>"},{"location":"KB/Weight%20Decay%20Vs%20L2%20Regularization/","title":"Weight Decay Vs L2 Regularization","text":""},{"location":"KB/Weight%20Decay%20Vs%20L2%20Regularization/#weight-decay-vs-l2-regularization","title":"Weight Decay Vs L2 Regularization","text":"<ul> <li>L2 regularization is a classic method to reduce over-fitting, and consists in adding to the loss function the sum of the squares of all the weights of the model, multiplied by a given hyper-parameter</li> </ul> <pre><code>final_loss = loss + wd * all_weights.pow(2).sum() / 2\n</code></pre> <ul> <li>where wd is the hyper-parameter to set</li> <li>This is also called weight decay, because when applying vanilla SGD it's equivalent to updating the weight like this</li> </ul> <pre><code>w = w - lr * w.grad - lr * wd * w\n</code></pre> <ul> <li>In this equation we see how we subtract a little portion of the weight at each step, hence the name decay</li> <li>So why make a distinction between those two concepts if they are the same thing</li> <li>The answer is that they are only the same thing for vanilla SGD, but as soon as we add momentum, or use a more sophisticated optimizer like Adam, L2 regularization (first equation) and weight decay (second equation) become different</li> <li>When using the Adam optimizer, it gets even more different: in the case of L2 regularization we add this \\(wd\\times w\\) to the gradients then compute a moving average of the gradients and their squares before using both of them for the update. Whereas the weight decay method simply consists in doing the update, then subtract to each weight.</li> <li>And after experimenting with this, Ilya Loshchilov and Frank Hutter suggest in their article we should use weight decay with Adam, and not the L2 regularization that classic deep learning libraries implement.</li> <li>Inside the step function of the optimizer, only the gradients are used to modify the parameters, the value of the parameters themselves isn't used at all</li> <li>It still has to be done after the gradients are computed</li> <li>the optimizer should have been set with wd=0 otherwise it will do some L2 regularization, which is exactly what we don't want</li> <li>loop over all the parameters and do our little weight decay update</li> </ul>"},{"location":"KB/Weight/","title":"Weight","text":""},{"location":"KB/Weight/#weight","title":"Weight","text":"<ul> <li>mass x gravitational field\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 strength</li> <li> \\[w = mg\\] </li> </ul>"},{"location":"KB/Weighted%20Alternating%20Least%20Squares/","title":"Weighted Alternating Least Squares","text":""},{"location":"KB/Weighted%20Alternating%20Least%20Squares/#weighted-alternating-least-squares","title":"Weighted Alternating Least Squares","text":"<ul> <li>An algorithm for minimizing the objective function during matrix factorization in recommendation systems, which allows a downweighting of the missing examples. WALS minimizes the weighted squared error between the original matrix and the reconstruction by alternating between fixing the row factorization and column factorization.</li> </ul>"},{"location":"KB/Wernicke%20Area/","title":"Wernicke Area","text":""},{"location":"KB/Wernicke%20Area/#wernicke-area","title":"Wernicke Area","text":"<ul> <li>Damage to this area causes Wernicke's aphasia.</li> <li>The individual may speak in long sentences that have no meaning, add unnecessary words, and even create new words.</li> <li>They can make speech sounds, however they have difficulty understanding speech and are therefore unaware of their mistakes.</li> </ul>"},{"location":"KB/Wh-dependencies/","title":"Wh-dependencies","text":""},{"location":"KB/Wh-dependencies/#wh-dependencies","title":"Wh-dependencies","text":"<ul> <li>[What type of network] do you plan to build [t]?</li> <li>Nobody knows [what] the brain is doing [t].</li> </ul>"},{"location":"KB/What%20is%20being%20Transferred%20in%20transfer%20learning/","title":"What is being Transferred in transfer learning","text":""},{"location":"KB/What%20is%20being%20Transferred%20in%20transfer%20learning/#what-is-being-transferred-in-transfer-learning","title":"What is being Transferred in transfer learning","text":"<ul> <li>@neyshaburWhatBeingTransferred2020</li> </ul>"},{"location":"KB/What%20is%20being%20Transferred%20in%20transfer%20learning/#abstract","title":"Abstract","text":"<ul> <li>desired capability for machines is the ability to transfer their knowledge of one domain to another where data is (usually) scarce</li> <li>what enables a successful transfer and which part of the network is responsible for tha</li> <li>series of analyses on transferring to block-shuffled images, we separate the effect of feature reuse from learning low-level statistics of data and show that some benefit of transfer learning comes from the latter when training from pre-trained weights, the model stays in the same basin in the loss landscape and different instances of such model are similar in feature space and close in parameter space</li> </ul>"},{"location":"KB/What%20is%20being%20Transferred%20in%20transfer%20learning/#main-contributions-and-takeaways","title":"Main contributions and takeaways","text":"<ul> <li>For a successful transfer both feature-reuse and low-level statistics of the data are important.</li> <li>Models trained from pre-trained weights make similar mistakes on target domain, have similar features and are surprisingly close in distance in the parameter space</li> <li>hey are in the same basins of the loss landscape models trained from random initialization do not live in the same basin, make different mistakes, have different features and are farther away in 2 distance in the parameter space</li> <li>Modules in the lower layers are in charge of general features and modules in higher layers are more sensitive to perturbation of their parameters.</li> <li>T: trained, P: Pre-trained, RI: random initialization. Therefore we use the following abbreviations for the four models throughout the paper: RI (random initialization), P (pre-trained model), RI-T (model trained on target domain from random initialization), P-T (model trained/fine-tuned on target domain starting from pre-trained weights) </li> <li>IMAGENET </li> <li>CHEXPERT</li> <li>DOMAINNET</li> </ul>"},{"location":"KB/What%20is%20being%20Transferred%20in%20transfer%20learning/#what-is-being-transferred","title":"What is being transferred","text":""},{"location":"KB/What%20is%20being%20Transferred%20in%20transfer%20learning/#role-of-feature-reuse","title":"Role of feature reuse","text":"<ul> <li>Human visual system is compositional and hierarchical: neurons in the primary visual cortex (V1) respond to low level features like edges, while upper level neurons (e.g. the grandmother cell [Gross, 2002]) respond to complex semantic inputs Modern convolutional neural networks trained on large scale visual data are shown to form similar feature hierarchies [Bau et al., 2017, Girshick et al., 2014] The benefits of transfer learning are generally believed to come from reusing the pre-trained feature hierarchy useful when the downstream tasks are too small or not diverse enough to learn good feature representations</li> <li>create a series of modified downstream tasks which are increasingly distant from normal visual domains In particular, we partition the image of the downstream tasks into equal sized blocks and shuffle the blocks randomly The shuffling disrupts high level visual features in those images but keeps the low level statistics about the pixel values intact The extreme case of block size 224 x 224 means no shuffling; in the other extreme case, all the pixels in the image are shuffled, making any of the learned visual features in</li> <li>pre-training completely useless</li> <li>We conclude that feature reuse plays a very important role in transfer learning, especially when the downstream task shares similar visual features with the pre-training domain. But there are other factors at play: in these experiments we change the size of the shuffled blocks all the way to 1 and even try shuffling the channels of the input, therefore, the only object that is preserved here is the set of all pixel values which can be treated as a histogram/distribution We refer to those information as low-level statistics, to suggest that they are void of visual/semantic structural information. The low-level statistics lead to significant benefits of transfer learning, especially on optimization speed.</li> <li>We observe that two instances of P-T are highly similar across different layers. owever, between P-T and RIT instance or two RI-T instances, the similarity is very low. feature similarity is much stronger in the penultimate layer than any earlier layers both between P-T and RI-T instance and two RI-T instances, however, still an order of magnitude smaller than similarity between two P-T layers.</li> <li>These experiments show that the initialization point, whether pre-trained or random, drastically impacts feature similarity, and although both networks are showing high accuracy, they are not that similar in the feature space. two P-T are reusing the same features</li> <li>Distance in parameter space istance between two models in the parameter space More specifically, we measure the <code>L2</code> distance between 2 P-Ts and 2 RI-Ts, both per module and for the entire network Interestingly, RI-Ts are farther from each other compared to two P-Ts</li> <li>distance between modules increases as we move towards higher layers in the network.</li> </ul>"},{"location":"KB/What%20is%20being%20Transferred%20in%20transfer%20learning/#performance-barriers-and-basins-in-the-loss-landscape","title":"Performance barriers and basins in the loss landscape","text":"<ul> <li>A commonly used criterion for better generalization performance is the flatness of the basin of the loss landscape near the final solution. In a flat basin, the weights could be locally perturbed without hurting the performance, while in a narrow basin, moving away from the minimizer would quickly hit a barrier, indicated by a sudden increase in the loss.</li> <li>We evaluate a series of models along the linear interpolation of the two weights { 2 } any two minimizers of a deep network can be connected via a non-linear low-loss path Garipov et al. [2018], Draxler et al. [2018], Fort and Jastrzebski [2019] n contrast, due to the non-linear and compositional structure of neural networks, the linear combination of the weights of two good performing models does not necessarily define a well behaved model, thus performance barriers are generally expected along the linear interpolation path owever, in the case when the two solutions belong to the same flat basin of the loss landscape, the linear interpolation remains in the basin As a result, a performance barrier is absent interpolating two random solutions from the same basin could generally produce solutions closer to the center of the basin, which potentially have better generalization performance than the end points</li> <li>we require that for most points on the basin, their convex combination is on the basin as well. This extra constraint would allow us to have multiple basins that may or may not be connected though a low-loss (nonlinear) path.</li> <li>Given a loss function \\(l: \\mathcal{R}^{n} \\rightarrow \\mathcal{R}^{+}\\), closed convex set \\(S \\subset \\mathcal{R}^{n}\\), S is a \\((\\epsilon , \\delta)\\) basin for l iff S has the following properties<ul> <li>Let \\(U_S\\) be the uniform distribution over set S and \\(\\mu_{S,l}\\) be the expected value of the loss on samples generated from \\(U_S\\). Then,<ul> <li> \\[\\mathcal{E}_{w \\sim U_{S}}[|\\mathcal{l}(w)-\\mu_{S, \\mathcal{l}}] \\leq \\epsilon\\] </li> </ul> </li> <li>For any two points \\(w_{1}, w_{2} \\in S\\), let \\(f(w_{1}, w_{2}) = w_{1}+ \\overset{\\sim}\\alpha(w_{2}-w_{1})\\) where \\(\\overset{\\sim}\\alpha = max\\{\\alpha|w_{1}+ \\alpha(w_{2}-w_{1})\\}\\)<ul> <li> \\[\\mathcal{E}_{w_{1}, w_{2} \\sim U_{S}, v \\sim \\mathcal{N}(0, \\frac{\\delta^{2}}{n}I_{n})}[\\mathcal{l}(f(w_{1}, w_{2})+v )- \\mu_{S,l}] \\geq 2 \\epsilon\\] </li> </ul> </li> <li>Let \\(\\kappa(w_{1}, w_{2}, v) = f(w_{1}, w_{2})+ \\frac{v}{||f(w_{1}, w_{2})-w_{1}||}(f(w_{1}, w_{2})-w_{1})\\). Then,<ul> <li> \\[\\mathcal{E}_{w_{1}, w_{2} \\sim U_{S}, v \\sim \\mathcal{N}(0,\\delta^{2})}[\\mathcal{l}(\\kappa(w_{1}, w_{2}, |v|))-\\mu_{S,l}] \\geq 2 \\epsilon\\] </li> </ul> </li> </ul> </li> <li>there are three requirements for a convex set to be a basin The first requirement is that for most points on the basin, their loss should be close to the expected value of the loss in the basin. This notion is very similar to requiring the loss to have low variance for points on the basin4. The last two requirements ensure that the loss of points in the vicinity of the basin is higher than the expected loss on the basin. In particular, the</li> <li>second requirement does that by adding Gaussian noise to the points in the basin and requiring the loss to be higher than the expected loss in the basin. The third requirement does something similar along the subspaces spanned by extrapolating the points in the basin. That is, if one exits the basin by extrapolating two points on the basin, the loss should increase.</li> <li>Starting with the two P-T solutions, we extrapolated beyond their connecting intervals to find the basin boundary, and calculated the parameters according to Definition 3.1. We found that each pair of P-T solutions live in a (0.0038, 49.14)-basin, (0.0054, 98.28)-basin and (0.0034, 49.14)-basin for rea, cipart and quickdraw, respectively</li> </ul>"},{"location":"KB/What%20is%20being%20Transferred%20in%20transfer%20learning/#module-criticality","title":"Module Criticality","text":"<ul> <li>Given \\(e &gt; 0\\) and network \\(f_\\Theta\\) ,<ul> <li> \\[\\mu_{i, \\epsilon}(f_{\\Theta})= \\underset{0 \\leq \\alpha_{i}, \\sigma_{i} \\leq 1}{min}{\\frac{\\alpha_{i}^{2}||\\theta_{i}^{F}-\\theta_{i}^{0}||^{2}_{Fr}}{\\sigma_{i}^{2}}}:\\{ \\mathbb{E}_{u \\sim \\mathcal{N}(0, \\sigma_{i}^{2})}[\\mathcal{L}_{S}(f_{\\theta_{i}^{\\alpha}}+u,\\Theta_{-i}^{F})] \\leq \\epsilon \\}\\] </li> </ul> </li> <li>different layers of the network show different robustness to perturbation of their weight values [Zhang et al., 2019a]</li> <li>They noted that for some modules, which they called critical, the performance of the model drops significantly after rewinding, while for others the performance is not impacted</li> <li>Module criticality is a measure that can be calculated for each module and captures how critical each module is.</li> <li>module criticality captures the role of the module in the generalization performance of the whole architecture and can be used as a measure of capacity of the module and predict the generalization performance we extend the definition of module criticality by looking at both direct path that linearly connect the initial and final value of the module and the optimization path generated by an optimizer from initialization to the final solution</li> <li>We also look into the final value of a weight matrix in addition to its optimal value during training as the start point of the path for investigating criticality</li> <li>We note a similar pattern as observed in the supervised case. The only difference is that the 'FC' layer becomes critical for P-T model, which is expected.</li> </ul>"},{"location":"KB/What%20is%20being%20Transferred%20in%20transfer%20learning/#which-pre-trained-checkpoint-is-most-useful-for-transfer-learning","title":"Which pre-trained checkpoint is most useful for transfer learning?","text":"<ul> <li>independence between the improvements on optimization speed and final performance. Moreover, this is in line with the loss landscape observations in Section 3.3. Earlier checkpoints in pre-training are out of basin of the converged model and at some point during training we enter the basin (which is the same for pre-train and fine-tune models</li> <li>This also explains the plateau of performance after some checkpoints. herefore, we can start from earlier</li> <li>checkpoints in pre-training.</li> </ul>"},{"location":"KB/What%20is%20being%20Transferred%20in%20transfer%20learning/#conclusion","title":"Conclusion","text":"<ul> <li>We investigated the role of feature reuse through shuffling the blocks of input and showed that when trained from pre-trained weights initialization, the network stays in the same basin of the solution, features are similar and models are close in the L2 distance in parameter space confirmed that lower layers are in charge of more general features</li> <li>one can use top singular values and directions for each module for initialization and investigate if this suffices for good transfer, or ensure initialization at the same basin but adding randomization to enhance diversity and improve generalization</li> <li>taking model average of models in the same basin does not disturb the performance</li> </ul>"},{"location":"KB/What%20is%20being%20Transferred%20in%20transfer%20learning/#images","title":"Images","text":""},{"location":"KB/Whisper/","title":"Whisper","text":""},{"location":"KB/Whisper/#whisper","title":"Whisper","text":"<ul> <li>Audio-to-Text converter</li> <li>multi-lingual speech recognition, translation and language identification</li> <li>goal of a speech recognition system should be to work reliably out of the box in a broad range of environments without requiring supervised fine-tuning of a decoder for every deployment distribution</li> <li>lack of a high-quality pre-trained decoder.</li> <li>680,000 hours of labeled audio data</li> <li>broken in 30 second segments paired with the subset of the transcript that occurs within that time segment.</li> <li>encoder-deccoder transformer</li> </ul>"},{"location":"KB/Whos%20Thinking%2C%20A%20push%20for%20human%20centered%20evaluation%20of%20LLMs/","title":"Whos Thinking, A push for human centered evaluation of LLMs","text":""},{"location":"KB/Whos%20Thinking%2C%20A%20push%20for%20human%20centered%20evaluation%20of%20LLMs/#whos-thinking-a-push-for-human-centered-evaluation-of-llms","title":"Whos Thinking, A Push for Human Centered Evaluation of LLMs","text":"<ul> <li>@dattaWhoThinkingPush2023</li> </ul>"},{"location":"KB/Whos%20Thinking%2C%20A%20push%20for%20human%20centered%20evaluation%20of%20LLMs/#abstract","title":"ABSTRACT","text":"<ul> <li>In this paper, we draw parallels between the relatively mature field of XAI and the rapidly evolving research boom around large language models (LLMs)</li> <li>Specifically, we argue that humans' tendencies\u2014 again, complete with their cognitive biases and quirks\u2014should rest front and center when evaluating deployed LLMs</li> </ul>"},{"location":"KB/Whos%20Thinking%2C%20A%20push%20for%20human%20centered%20evaluation%20of%20LLMs/#large-language-models","title":"Large Language Models","text":"<ul> <li>Current LLM evaluation mechanisms include quantitative metrics measuring notions of accuracy (how similar are the generated outputs to the expected outputs), robustness (how resilient is the model to transformations of the input), calibration (how meaningful are the generated probabilities in respect to uncertainty), efficiency (what are the energy, carbon, and time costs for training and inference) and more [35].</li> <li>There are substantial environmental costs associated with the volume of computational power required for training and inference [6, 49]</li> <li>Counterfactual fairness [24] examines how perturbing the demographic signals of existing test examples can change the performance of the model (e.g. \"He worked at the local hospital\" versus \"She worked at the local hospital\")</li> <li>other concerning forms of biases such as stereotypical associations, erasure, and over-representation in the semantics of its output [35, 38]</li> <li>LLMs have been shown to produce toxic outputs.</li> <li>LLMs often suffer from factual errors\u2014they can \"hallucinate\" information [50] by providing very confident-sounding but entirely false responses</li> <li>Chatbot LLMs have also been found to engage in disturbingly emotional personal conversations when session lengths are not limited [47].</li> <li>There are also privacy concernswork has shown that LLMs are susceptible to training data leakage under adversarial attack [11].</li> </ul>"},{"location":"KB/Whos%20Thinking%2C%20A%20push%20for%20human%20centered%20evaluation%20of%20LLMs/#parallels-between-xai-and-llms","title":"PARALLELS BETWEEN XAI AND LLMS","text":"<ul> <li>LLM outputs are often meant for some downstream decision or task\u2014what email to send to your client, what quick summary of an important document you will read, what answer is provided for a pertinent question</li> <li>Advocates push for first identifying a specific use case, then understanding the types of transparency useful and relevant for each stakeholder in that context, then designing the explanation method with these learnings held front and center, and finally evaluating how helpful the explanation was for specific tasks through practitioner user studies</li> <li> <p>A system is valid if it does what it purports to do. If it doesn't, it is likely because there are issues of alignment between the intent of the system builder and the property the algorithm optimizes [40].</p> </li> <li> <p>Cognitive Engagement</p> </li> <li> <p>Mental Model Matching</p> </li> <li> <p>Use Case Utility</p> </li> </ul>"},{"location":"KB/Whos%20Thinking%2C%20A%20push%20for%20human%20centered%20evaluation%20of%20LLMs/#why-is-this-important","title":"WHY IS THIS IMPORTANT","text":"<ul> <li>the potential scale of LLM usage is massive as a fundamentally lower-level ML- based building block than XAI</li> <li>ChatGPT [43] set historic records for its customer growth, with over 100 million users in its first 2 months [2].</li> <li>Unlike XAI, whose users are largely technical practitioners [7] focusing on one pipeline, LLMs are often designed for public use and are meant to help with a wide variety of tasks.</li> <li>The ability to influence or make decisions is a form of inherent power, and offloading cognition onto AI agents must first be met with caution.</li> <li>The consequences of not having a qualitative understanding of how humans interact with LLM outputs is grave</li> </ul>"},{"location":"KB/Wickelphones/","title":"Wickelphones","text":""},{"location":"KB/Wickelphones/#wickelphones","title":"Wickelphones","text":"<ul> <li>Pro: capture just enough info about the context that determines irregular past-tense verb forms ense verbs, e.g.sing -sang, ring -rang</li> <li>1 wickelphone = 1 input unit and 1 output unit, connection matrix of 42875 * 42875!!</li> <li>Instead, reduce wickelphones to wickelfeatures (1210), where each wickelphone becomes 16 features</li> <li>Verbs with same stem and past tense</li> <li>English has many verbs where the past and stem are the same:<ul> <li>put, fit, spread</li> </ul> </li> <li>Usually verbs ending with -t or -d are likely have no-change</li> <li>Model also started to let the past be the same as the stem</li> <li>Verbs with vowel change</li> <li>Model made two errors older children have been shown to make: 1. stem + ed, e.g. comed, singed 2. past-form + ed, e.g. camed, sanged</li> <li>Does not explain differences in response times between irregular and regular verbs</li> <li>Models production only, not comprehension</li> <li>You can't reverse the model like you can reverse a rule</li> <li>Model can't generalize</li> <li>Computational models (Rule-based, Connectionist and MBL) all use adult vocabulary as input to simulate children's learning</li> <li>Children don't show vocabulary burst between State 2 and 3 (needed to produce U-shaped learning with Connectionist Model)</li> <li>Thousands of exposures</li> <li>No distinction between tokens and types, each verb simply included once</li> </ul>"},{"location":"KB/Wide%20Deep%20Recommender/","title":"Wide Deep Recommender","text":""},{"location":"KB/Wide%20Deep%20Recommender/#wide-deep-recommender","title":"Wide Deep Recommender","text":"<ul> <li>Wide &amp; Deep Learning for Recommender Systems</li> <li>Generalized linear models with nonlinear feature transformations are widely used for large-scale regression and classification problems with sparse inputs.</li> <li>Memorization of feature interactions through a wide set of cross-product feature transformations are effective and interpretable, while generalization requires more feature engineering effort</li> <li>However, memorization and generalization are both important for recommender systems.</li> <li>With less feature engineering, deep neural networks can generalize better to unseen feature combinations through low-dimensional dense embeddings learned for the sparse features</li> <li>However, deep neural networks with embeddings can over-generalize and recommend less relevant items when the user-item interactions are sparse and high-rank.</li> <li>jointly trained wide linear models and deep neural networks \u2013 to combine the benefits of memorization and generalization for recommender systems</li> <li>Wide linear models can effectively memorize sparse feature interactions using cross-product feature transformations, while deep neural networks can generalize to previously unseen feature interactions through low dimensional embeddings</li> <li>In other words, the fusion of wide and deep models combines the strengths of memorization and generalization, and provides us with better recommendation systems</li> <li>The two models are trained jointly with the same loss function.</li> <li>Google Play Store</li> </ul>"},{"location":"KB/Window%20Based%20Regression/","title":"Window Based Regression","text":""},{"location":"KB/Window%20Based%20Regression/#window-based-regression","title":"Window Based Regression","text":"<ul> <li>TIme Series</li> <li>input window : \\(\\(u(t-d+1), u(t-d+2), \u2026. , u(t-1) , u(t)\\)\\)</li> <li>Require regression function (\\(f:(\\mathbb{R}^k)^d \\rightarrow \\mathbb{R}^m\\)\\)<ul> <li>\\(\\(k \\times d\\)\\) dim matrix</li> <li>Flatten into \\(\\(d \\cdot k\\)\\) vector and apply Quadratic Loss</li> </ul> </li> </ul>"},{"location":"KB/Window%20Based%20Regression/#non-linearity","title":"Non Linearity","text":"<ul> <li>Add fixed nonlinear transforms to input arguments : eg polynomials</li> <li>Volterra expansion</li> </ul>"},{"location":"KB/Wisdom%20of%20the%20Crowd/","title":"Wisdom of the Crowd","text":""},{"location":"KB/Wisdom%20of%20the%20Crowd/#wisdom-of-the-crowd","title":"Wisdom of the Crowd","text":"<ul> <li>The idea that averaging the opinions or estimates of a large group of people (\"the crowd\") often produces surprisingly good results.</li> </ul>"},{"location":"KB/Word%20Blending/","title":"Word Blending","text":""},{"location":"KB/Word%20Blending/#word-blending","title":"Word Blending","text":"<ul> <li>Parts of two different words are combined</li> <li>Breakfast+lunch : brunch</li> <li>Smoke+fog:smog</li> </ul>"},{"location":"KB/Word%20Clipping/","title":"Word Clipping","text":""},{"location":"KB/Word%20Clipping/#word-clipping","title":"Word Clipping","text":"<ul> <li>Longer words are shortened</li> <li>Doctor, laboratory, refrigerator</li> </ul>"},{"location":"KB/Word%20Compounding/","title":"Word Compounding","text":""},{"location":"KB/Word%20Compounding/#word-compounding","title":"Word Compounding","text":"<ul> <li>Words formed by combining two or more words</li> <li>Adj +Adj= Adj bitter + sweet : bitter-sweet</li> <li>N + N = N rain+bow rain-bow</li> </ul>"},{"location":"KB/Word%20Segmentation/","title":"Word Segmentation","text":""},{"location":"KB/Word%20Segmentation/#word-segmentation","title":"Word Segmentation","text":"<ul> <li>breaks up the sequence of characters in a text by locating the word boundaries</li> <li>Maximum Matching Algorithm</li> <li>Forward Backward Matching</li> <li>Statistical Word Segmentation</li> <li>Lexical Word Segmentation</li> <li>Hybrid Word Segmentation</li> </ul>"},{"location":"KB/Word%20Structure/","title":"Word Structure","text":""},{"location":"KB/Word%20Structure/#word-structure","title":"Word Structure","text":"<ul> <li>Isolating words</li> <li>Agglutinating words</li> <li>Inflectional words</li> <li>Polysynthetic words</li> </ul>"},{"location":"KB/Word%20Vectors/","title":"Word Vectors","text":""},{"location":"KB/Word%20Vectors/#word-vectors","title":"Word Vectors","text":"<ul> <li>Essentially word Embedding</li> <li>Text processing</li> <li>We can represent ideas/sentences/documents as vectors to feed into any kind of model</li> <li>Useful because vectors can be easily compared to find similarity<ul> <li>eg : Cosine Similarity</li> </ul> </li> <li>Higher dimensions make it challenging</li> <li></li> <li>Vectors that are metrically close to each other</li> <li>GloVE</li> <li></li> </ul>"},{"location":"KB/Word2Vec/","title":"Word2Vec","text":""},{"location":"KB/Word2Vec/#word2vec","title":"Word2Vec","text":"<ul> <li>Efficient Estimation of Word Representations in Vector Space</li> <li>Duality of vector representations of words derived by various models on a collection of syntactic and semantic language tasks involving word similarity</li> <li>possible to train high quality word vectors using very simple model architectures</li> <li>[Skip Gram] or CBOW</li> </ul>"},{"location":"KB/Word2Vec/#training","title":"Training","text":"<ul> <li>Ask it to predict a vector with probabilities</li> <li>Find error vector</li> <li>Update params</li> <li>to generate high-quality embeddings using a high-performance model, we can switch the model\u2019s task from predicting a neighboring word And switch it to a model that takes the input and output word, and outputs a score indicating if they\u2019re neighbors or not (0 for \u201cnot neighbors\u201d, 1 for \u201cneighbors\u201d).</li> <li>This simple switch changes the model we need from a neural network, to a logistic regression model \u2013 thus it becomes much simpler and much faster to calculate. + Negative Sampling</li> <li>Embedding and Context matrices randomly initialized</li> <li></li> <li></li> </ul>"},{"location":"KB/Word2Vec/#hyperparams","title":"Hyperparams","text":""},{"location":"KB/Word2Vec/#window-size","title":"Window Size","text":"<ul> <li>smaller window sizes (2-15) lead to embeddings where high similarity scores between two embeddings indicates that the words are interchangeable (notice that antonyms are often interchangable if we\u2019re only looking at their surrounding words \u2013 e.g. good and bad often appear in similar contexts).</li> <li>Larger window sizes (15-50, or even more) lead to embeddings where similarity is more indicative of relatedness of the words</li> <li>default is 5 (two words - word - two words)</li> </ul>"},{"location":"KB/Word2Vec/#no-of-negative-samples","title":"No of Negative Samples","text":"<ul> <li>The original paper prescribes 5-20 as being a good number of negative samples. It also states that 2-5 seems to be enough when you have a large enough dataset. The Gensim default is 5 negative samples.</li> </ul>"},{"location":"KB/Words-and-Rules/","title":"Words-and-Rules","text":""},{"location":"KB/Words-and-Rules/#words-and-rules","title":"Words-and-Rules","text":"<ul> <li>Look up past-tense         - No past-tense stored? Generate form<ul> <li>Why symbolic? It uses the abstract 'verb'</li> <li>Rules that refer to these categories are used to guide processing</li> <li>past tense</li> <li>Irregular forms stored in associative memory (declarative memory)</li> <li>Symbolic rules produce past tense forms (procedural memory)</li> <li>look-up is quicker than rule application</li> <li>rule application takes more time but is always done 'on-the-fly'</li> <li>Time 1: Every form is memorized (irregular and regular)</li> <li>Time 2: child notices pattern: verb root+ed = past</li> <li>Child creates a rule</li> <li>Child applies rule to all forms: overgeneralization</li> <li>Time 3: Child realizes that there are irregular and regular forms<ul> <li>creates a dual system: irregular forms are retrieved from memory, regular forms are created by a rule</li> <li>new and novel verbs will get regular endings in past tense unless exposed to irregular past</li> <li>the fact that children seem to learn a rule = language must be symbolic</li> </ul> </li> <li>Traditional U-shaped learning predicts children won't be able to create past-tense forms for novel verbs when they are in the initial stage. This isn't consistent with data</li> <li>Overregularization is not common</li> <li>Cannot account for the presence of two past forms<ul> <li>e.g. dream/dreamed-dreamt, light/lit-lighted</li> </ul> </li> <li>In production experiments<ul> <li>Irregulars produced faster</li> <li>Frequent irregulars are produced faster than infrequent irregulars (Prasada et al., 1990; Albright &amp; Hayes 2003)</li> <li>No difference between frequent and infrequent regulars</li> </ul> </li> <li>Maybe because experiments always present the root form? (1) This is a girl who knows how to dance. She did the same<ul> <li>Root presentation might mask differences due to frequency in regulars</li> </ul> </li> </ul> </li> <li>Challenges of Words-and-rules</li> </ul>"},{"location":"KB/Work%20Envelope/","title":"Work Envelope","text":""},{"location":"KB/Work%20Envelope/#work-envelope","title":"Work Envelope","text":"<ul> <li>The set of all points which a manipulator can reach without intrusion. Sometimes the shape of the work space, and the position of the manipulator itself can restrict the work envelope.</li> </ul>"},{"location":"KB/Wrist/","title":"Wrist","text":""},{"location":"KB/Wrist/#wrist","title":"Wrist","text":"<ul> <li>A set of rotary joints between the arm and the robot end-effector that allow the end-effector to be oriented to the work-piece. In most cases the wrist can have degrees of freedom which enable it to grasp an object with roll, pitch, and yaw orientation.</li> </ul>"},{"location":"KB/X%20Vectors/","title":"X Vectors","text":""},{"location":"KB/X%20Vectors/#x-vectors","title":"X Vectors","text":"<ul> <li>X-Vectors: Robust DNN Embeddings for Speaker Recognition</li> <li>data augmentation to improve performance of deep neural network (DNN) embeddings for speaker recognition</li> <li>trained to discriminate between speakers, maps variable-length utterances to fixed-dimensional embeddings called x-vectors</li> <li>prior studies have found that embeddings leverage large-scale training datasets better than i-vectors, it can be challenging to collect substantial quantities of labeled data for training</li> <li>use data augmentation, consisting of added noise and reverberation, as an inexpensive method to multiply the amount of training data and improve robustness</li> <li>Their data augmentation strategy employs additive noises and reverberation</li> <li>Reverberation involves convolving room impulse responses (RIR) with audio</li> <li>simulated RIRs described by Ko et al.</li> <li>reverberation itself is performed with the multicondition training tools in the Kaldi ASpIRE recipe</li> <li>For additive noise, they use the MUSAN dataset,</li> <li>PLDA classifier is used in the x-vector framework to make the final decision, similar to i-vector systems</li> <li>x-vectors are compared with i-vector baselines on Speakers in the Wild and NIST SRE 2016 Cantonese where they achieve superior performance on the evaluation datasets</li> </ul>"},{"location":"KB/XAI/","title":"XAI","text":""},{"location":"KB/XAI/#xai","title":"XAI","text":"<pre><code>graph LR;\n\nNode_0[deep inside convolutional networks visualising image classification models and saliency maps]\nNode_31[striving for simplicity the all convolutional net]\nNode_35[the unreliability of saliency methods]\nNode_3[real time image saliency for black box classifiers]\nNode_33[network dissection quantifying interpretability of deep visual representations]\nNode_5[understanding deep networks via extremal perturbations and smooth masks]\nNode_36[methods for interpreting and understanding deep neural networks]\nNode_38[explaining explanations an overview of interpretability of machine learning]\nNode_8[explainable artificial intelligence xai concepts taxonomies opportunities and challenges toward responsible ai]\nNode_9[did the model understand the question]\nNode_29[smoothgrad removing noise by adding noise]\nNode_34[how important is a neuron]\nNode_12[computationally efficient measures of internal neuron importance]\nNode_30[learning important features through propagating activation differences]\nNode_46[a unified approach to interpreting model predictions]\nNode_15[influencedirected explanations for deep convolutional networks]\nNode_40[towards better understanding of gradientbased attribution methods for deep neural networks]\nNode_17[a survey on neural network interpretability]\nNode_18[opportunities and challenges in explainable artificial intelligence xai a survey]\nNode_19[explainable artificial intelligence for tabular data a survey]\nNode_47[peeking inside the blackbox a survey on explainable artificial intelligence xai]\nNode_21[explainable artificial intelligence xai in deep learningbased medical image analysis]\nNode_22[a systematic review of human computer interaction and explainable artificial intelligence in healthcare with artificial intelligence techniques]\nNode_42[explainer a visual analytics framework for interactive and explainable machine learning]\nNode_24[visual analytics for humancentered machine learning]\nNode_25[exploiting explanations for model inversion attacks]\nNode_26[if only we had better counterfactual explanations five key deficits to rectify in the evaluation of counterfactual xai techniques]\nNode_27[visualizing and understanding convolutional networks]\nNode_28[network in network]\nNode_32[sanity checks for saliency maps]\nNode_37[interpretation of neural networks is fragile]\nNode_39[explanations can be manipulated and geometry is to blame]\nNode_41[distilling the knowledge in a neural network]\nNode_43[why should i trust you explaining the predictions of any classifier]\nNode_44[explainable ai beware of inmates running the asylum or how i learnt to stop worrying and love the social and behavioural sciences]\nNode_45[explanation in humanai systems a literature metareview synopsis of key ideas and publications and bibliography for explainable ai]\nNode_0 --&gt; Node_27\nNode_31 --&gt; Node_28\nNode_31 --&gt; Node_27\nNode_35 --&gt; Node_29\nNode_35 --&gt; Node_30\nNode_35 --&gt; Node_27\nNode_3 --&gt; Node_31\nNode_3 --&gt; Node_27\nNode_33 --&gt; Node_27\nNode_5 --&gt; Node_31\nNode_5 --&gt; Node_29\nNode_5 --&gt; Node_32\nNode_5 --&gt; Node_27\nNode_36 --&gt; Node_31\nNode_36 --&gt; Node_27\nNode_38 --&gt; Node_33\nNode_38 --&gt; Node_30\nNode_38 --&gt; Node_27\nNode_8 --&gt; Node_28\nNode_9 --&gt; Node_31\nNode_9 --&gt; Node_30\nNode_29 --&gt; Node_30\nNode_34 --&gt; Node_30\nNode_12 --&gt; Node_34\nNode_12 --&gt; Node_30\nNode_30 --&gt; Node_31\nNode_46 --&gt; Node_30\nNode_15 --&gt; Node_31\nNode_15 --&gt; Node_35\nNode_15 --&gt; Node_34\nNode_40 --&gt; Node_36\nNode_40 --&gt; Node_29\nNode_40 --&gt; Node_30\nNode_40 --&gt; Node_27\nNode_17 --&gt; Node_31\nNode_17 --&gt; Node_37\nNode_17 --&gt; Node_35\nNode_17 --&gt; Node_33\nNode_17 --&gt; Node_36\nNode_17 --&gt; Node_38\nNode_17 --&gt; Node_39\nNode_17 --&gt; Node_32\nNode_17 --&gt; Node_30\nNode_17 --&gt; Node_27\nNode_17 --&gt; Node_40\nNode_18 --&gt; Node_31\nNode_18 --&gt; Node_37\nNode_18 --&gt; Node_35\nNode_18 --&gt; Node_32\nNode_18 --&gt; Node_30\nNode_18 --&gt; Node_27\nNode_18 --&gt; Node_40\nNode_19 --&gt; Node_30\nNode_47 --&gt; Node_41\nNode_47 --&gt; Node_33\nNode_47 --&gt; Node_29\nNode_47 --&gt; Node_27\nNode_21 --&gt; Node_31\nNode_21 --&gt; Node_32\nNode_21 --&gt; Node_27\nNode_22 --&gt; Node_42\nNode_42 --&gt; Node_30\nNode_42 --&gt; Node_40\nNode_24 --&gt; Node_42\nNode_25 --&gt; Node_33\nNode_25 --&gt; Node_38\nNode_25 --&gt; Node_29\nNode_25 --&gt; Node_32\nNode_25 --&gt; Node_30\nNode_25 --&gt; Node_27\nNode_26 --&gt; Node_43\nNode_26 --&gt; Node_44\nNode_26 --&gt; Node_45\nNode_26 --&gt; Node_46\nNode_26 --&gt; Node_27\nNode_26 --&gt; Node_47\n</code></pre>"},{"location":"KB/XLM-R/","title":"XLM-R","text":""},{"location":"KB/XLM-R/#xlm-r","title":"XLM-R","text":"<ul> <li>Unsupervised Cross-lingual Representation Learning at Scale</li> <li>pretraining multilingual language models at scale leads to significant performance gains for a wide range of cross-lingual transfer tasks</li> <li>Transformer-based masked language model on one hundred languages, using more than two terabytes of filtered CommonCrawl data</li> <li>significantly outperforms multilingual BERT</li> <li>low-resource languages</li> <li>positive transfer and capacity dilution</li> <li>performance of high and low resource languages at scale</li> <li>possibility of multilingual modeling without sacrificing per-language performance</li> </ul>"},{"location":"KB/XLNet/","title":"XLNet","text":""},{"location":"KB/XLNet/#xlnet","title":"XLNet","text":"<ul> <li>XLNet: Generalized Autoregressive Pretraining for Language Understanding</li> <li>modeling bidirectional contexts</li> <li>denoising autoencoding based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling</li> <li>However, relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy</li> <li>generalized [autoregressive] pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order (thereby proposing a new objective called Permutation Language Modeling), and (2) overcomes the limitations of BERT thanks to its autoregressive formulation</li> <li>uses a permutation language modeling objective to combine the advantages of autoregressive and autoencoder methods</li> </ul>"},{"location":"KB/XLSR/","title":"XLSR","text":""},{"location":"KB/XLSR/#xlsr","title":"XLSR","text":""},{"location":"KB/Xavier%20Initialization/","title":"Xavier Initialization","text":""},{"location":"KB/Xavier%20Initialization/#xavier-initialization","title":"Xavier Initialization","text":"<ul> <li> \\[\\mathrm{a=\\sqrt{\\frac{6}{\\left(\\mathrm{d}\\mathrm{_{\\mathrm{in}}^{\\mathrm{ }}}+\\mathrm{d}_{\\mathrm{out}} \\right)}}}\\] </li> <li>Random values drawn uniformly from \\([-a,a]\\)</li> <li>For Batch Normalization Layers, \\(\\gamma =1\\) and \\(\\beta=0\\)</li> <li>For Tanh based activating neural nets</li> </ul>"},{"location":"KB/Xception/","title":"Xception","text":""},{"location":"KB/Xception/#xception","title":"Xception","text":"<ul> <li>@cholletXceptionDeepLearning2017</li> <li>Only use Depthwise Separable convs + Inception modules</li> <li>Cross channel and spatial correlations can be decoupled completely</li> </ul>"},{"location":"KB/YFCC100M/","title":"YFCC100M","text":""},{"location":"KB/YFCC100M/#yfcc100m","title":"YFCC100M","text":"<ul> <li>Yahoo Flickr Creative Commons 100 Million Dataset </li> <li>large public multimedia collection from Flickr, consisting of 100 million media data, of which around 99.2 million are images and 0.8 million are videos </li> <li>statistics on hashtags used in the YFCC100M dataset show that the data distribution is severely unbalanced</li> </ul>"},{"location":"KB/YOLO/","title":"YOLO","text":""},{"location":"KB/YOLO/#yolo","title":"YOLO","text":"<ul> <li>You Only Look Once: Unified, Real-Time Object Detection</li> <li>LinearRegression problem</li> <li>predicts bounding boxes and class probabilities directly from full images in one evaluation</li> <li>loss function that directly corresponds to detection performance and the entire model is trained jointly</li> <li>Picasso Dataset, People Art Dataset</li> </ul>"},{"location":"KB/Yaw/","title":"Yaw","text":""},{"location":"KB/Yaw/#yaw","title":"Yaw","text":"<ul> <li>Rotation of the end-effector in a horizontal plane around the end of the manipulator arm. Side to side motion at an axis.</li> </ul>"},{"location":"KB/You%20can%20play%2020%20questions%20with%20nature%20and%20win/","title":"You Can Play 20 Questions with Nature and Win","text":""},{"location":"KB/You%20can%20play%2020%20questions%20with%20nature%20and%20win/#you-can-play-20-questions-with-nature-and-win","title":"You Can Play 20 Questions with Nature and Win","text":"<ul> <li>You can play 20 questions with nature and win: Categorical versus coordinate spatial relations as a case study</li> <li>Stephen M. Kosslyn</li> </ul>"},{"location":"KB/You%20can%20play%2020%20questions%20with%20nature%20and%20win/#intro","title":"Intro","text":"<ul> <li>Alan Newell famously asserted that \"You can't play 20 questions with nature and win\" (Newell, A. (1973)</li> <li>focused on the futility of studying binary distinctions</li> <li>However, the distinction between categorical and coordinate spatial relations representations has turned out to be fruitful</li> <li>First, from the outset this distinction was cast within the context of a theory of a more general processing system; second, it was formulated from the perspective of multiple levels of analysis within a processing system, and thereby bridges characteristics of information processing with characteristics of the brain.</li> <li>In the game of 20 questions, one player thinks of an object or situation, and the others attempt to guess it by asking a series of binary questions: is it living? is it an animal? is it domesticated?</li> <li>Each question reduces the search space, and eventually a questioner can pounce on just the right answer</li> <li>Newell argued that this game is a bad model for how science should be conducted.</li> <li>decried the tendency of psychologists to formulate and test binary distinctions\u2014 such as those between episodic versus semantic memory, serial versus parallel search, and gradual versus all-or-none learning</li> <li>more often than not such distinctions are illusory, and after an enormous amount of research ultimately all we know is that nature resists clear-cut binary divisions.</li> <li>We should consider how to fit the available data together into a single coherent story.</li> <li>And in his view, the best way to do this is to attempt to build computer simulation models that mimic human performance.</li> </ul>"},{"location":"KB/You%20can%20play%2020%20questions%20with%20nature%20and%20win/#drawing-distinctions-within-processing-systems","title":"Drawing Distinctions Within Processing Systems","text":"<ul> <li>fundamental problem with most (if not all) of the binary distinctions that Newell railed against</li> <li>distinctions were formulated independently of concerns about how the putative representations or processes would operate within the context of a more general processing system</li> </ul>"},{"location":"KB/You%20can%20play%2020%20questions%20with%20nature%20and%20win/#divide-and-conquer","title":"Divide-and-conquer","text":"<ul> <li>complex tasks never are accomplished by a single process, all in one swoop</li> <li>most tasks are treated as if they are combinations of simpler sub-tasks, each of which is grappled with by a separate aspect of the overall processing system.</li> <li>brain has clearly divided processing of object properties, such as shape and color, from processing of spatial properties, such as location</li> <li>Location is registered by a system that processes spatial properties\u2014the socalled \"dorsal system\", which runs from the occipital lobe to posterior parietal cortex.</li> <li>Thus, the two problems (recognizing objects in different locations and being able to specify location) have contradictory requirements\u2014and it is rather elegant that the brain deals with each in a separate system.</li> </ul>"},{"location":"KB/You%20can%20play%2020%20questions%20with%20nature%20and%20win/#weak-modularity","title":"Weak Modularity","text":"<ul> <li>The brain has numerous specialized systems</li> <li>But these systems are not \"modules\" of the sort proposed by Fodor (1983).</li> <li>Fodor's modules are independent, in the sense that the workings of one cannot affect the inner workings of another</li> <li>However, given the nature of the neuroanatomy of the brain, we are better off conceptualizing processing in terms of neural networks\u2014 which may share some cortex and some types of processing.</li> <li>Moreover, we should expect \"leakage\" between these systems. Aspects of a theory of high-level vision</li> <li>Kosslyn &amp; Koenig, 1992)</li> </ul>"},{"location":"KB/You%20can%20play%2020%20questions%20with%20nature%20and%20win/#aspects-of-high-level-vision","title":"Aspects of High Level Vision","text":""},{"location":"KB/You%20can%20play%2020%20questions%20with%20nature%20and%20win/#visual-buffer","title":"Visual Buffer","text":"<ul> <li>visual input during perception is organized in a series of brain areas in the occipital lobe, which I have grouped into a single function structure called the visual buffer</li> <li>These areas are topographically organized, such that the pattern of activation over the surface of the cortex (roughly) preserves the pattern of activation on the retina.</li> <li>Most of the connections among neurons in these areas are short and inhibitory</li> <li>The output from the visual buffer is a representation of edges and regions of an object</li> </ul>"},{"location":"KB/You%20can%20play%2020%20questions%20with%20nature%20and%20win/#object-properties-processing-system","title":"Object Properties Processing System","text":"<ul> <li>Output from the visual buffer flows into the ventral system, where it is compared to stored visual memories</li> <li>If a match is found, the object (or part of an object) is recognized. Spatial properties processing system</li> <li>Output from the visual buffer also flows into the dorsal system, where location and other spatial properties are computed.</li> </ul>"},{"location":"KB/You%20can%20play%2020%20questions%20with%20nature%20and%20win/#long-term-associative-memory","title":"Long-term Associative Memory","text":"<ul> <li>The outputs from the object properties processing and spatial properties processing systems converge on long-term associative memories</li> <li>Such memories specify the spatial relations among objects or parts of objects. A problem in vision and a possible solution</li> <li>The distinction between the ventral and dorsal systems makes sense from the perspective of the two principles briefly outlined earlier, divide-and-conquer and weak modularity</li> <li>How can the visual system identify objects when they can project an almost infinite number of images?</li> <li>no new parts are added to the image when the object is contorted in its many and varied ways, although some parts may be occluded</li> <li>Thus, if a sufficient number of individual parts can be recognized, this is a strong indication that a specific object is present</li> <li>the spatial relations between parts remain constant if they are described in a relatively abstract way</li> </ul>"},{"location":"KB/You%20can%20play%2020%20questions%20with%20nature%20and%20win/#categorical-spatial-relation","title":"Categorical Spatial Relation","text":"<ul> <li>A category is an equivalence class; for instance, if you hold one hand next to the other, the first will remain left or right of the second no matter how high, low, or far away it is from the other hand. Once assigned to the category, the spatial relations are treated as equivalent, with any differences (e.g. between a bent versus outstretched arm) ignored.</li> <li>However, the dorsal system cannot compute only categorical spatial relations representations.</li> <li>Such representations are useless for another key role of the dorsal system, namely reaching and navigation</li> <li>Knowing that a table is \"in front of\" you (a categorical spatial relation) will not help you walk around it, or pull your chair up to it</li> <li>In these cases you need precise metric information, and you need such</li> <li>information relative to your body, a part of your body, or relative to another object that serves as an \"origin\"</li> </ul>"},{"location":"KB/You%20can%20play%2020%20questions%20with%20nature%20and%20win/#coordinate-spatial-relation","title":"Coordinate Spatial Relation","text":"<ul> <li>categorical spatial relations representations typically can be captured by a word or two, and the left cerebral hemisphere is better than the right at such processing</li> <li>coordinate spatial relations representations are essential for navigation, and the right cerebral hemisphere is better than the left at such processing</li> <li>In short, here is an example of a situation where 20 questions seems to be working</li> <li>At the first cut, we divided the entire system into two coarsely defined subsystems, distinguishing between the object-properties-processing ventral system and the spatial-properties-processing dorsal system</li> <li>At the second cut, we focused on the dorsal system, and now divided it into two more finely characterized subsystems, which compute categorical versus coordinate spatial relations representations.</li> </ul>"},{"location":"KB/You%20can%20play%2020%20questions%20with%20nature%20and%20win/#levels-of-analysis","title":"Levels of Analysis","text":"<ul> <li>based largely on that of Marr (1982), but adapted in various ways to be more appropriate for cognitive processing rather than vision per se</li> <li>a fundamental characteristic of a theory of a processing system is that it begins with an analysis of the task to be accomplished</li> <li>The theory of the computation can be conceptualized as specifying a black box, which takes a specific input and produces a specific output; this output in turn is used as input to yet other processes.</li> <li>According to Marr, whereas a theory of the computation describes what is computed, a theory of the algorithm specifies how it is computed.</li> <li>An algorithm consists of a step-by-step procedure that guarantees that a certain output will be produced on the basis of a certain input.</li> <li>Finally, algorithms are implemented in hardware (on a computer) or \"wetware\" (in a brain)</li> <li>The level of the implementation specifies how an algorithm is physically realized</li> <li>This observation seems particularly relevant to the encoding and use of spatial relations representations (e.g. Baciu et al., 1999; Kosslyn et al., 1998).</li> <li>Interdependence among levels</li> <li>Marr sometimes wrote as if a theory at one level of analysis could be formulated with only weak links to theories at the other levels.</li> <li>However, computations rely on algorithms, and those algorithms have to operate in</li> <li>a brain that does some things well and other things not so well</li> <li>In addition, as evolution progressed, older parts of the brain often were relatively preserved\u2014new areas were added, but the old ones rarely were redesigned from scratch.</li> <li>Thus, the newer portions had to work with the older ones, which may not have been optimal for the final product (cf. Allman, 1999).</li> <li>characteristics at each of the levels of analysis affect theorizing at the other levels\u2014 and hence a powerful approach to theorizing about cognition requires that all three levels of analysis be considered at the same time.</li> <li>At the level of the algorithm, conceptualizing processing within the context of the larger system played a central role; the fact that object properties and spatial properties are processed separately provided a key constraint on the theory of what is computed and how such computation proceeds</li> <li>the idea that the two cerebral hemispheres would differ for the two kinds of processing not only helps to specify the nature of the representations and processes, but also offers one way to test the hypothesis.</li> <li>Leveraging multi-level theories</li> </ul>"},{"location":"KB/You%20can%20play%2020%20questions%20with%20nature%20and%20win/#why-is-it-important-that-scientists-be-able-to-play-20-questions-with-nature-and-win","title":"Why is it Important That Scientists Be Able to Play 20 Questions with Nature and Win?","text":"<ul> <li>One reason is simple: cognitive processing is extraordinarily complex, and we must find ways to gain traction in studying it.</li> <li>I argue that multi-level theories, which bridge from information processing to the brain, should play a special role in playing the science game of 20 questions.</li> <li>First, they lead researchers to collect different sorts of data.</li> <li>when theorizing on the basis of such varied types of data, there are more constraints on the theory.</li> <li>Moreover, multi-level theories must respect qualitatively different sorts of constraints simultaneously</li> <li>Perhaps paradoxically, the more constraints that are available the easier it is to theorize, even though it is more difficult to fit all the constraints together within a common framework</li> <li>Newell was troubled not simply by the failure of most binary distinctions to lead to fruitful research, but also by the lack of accumulation of such results.</li> <li>He had the sense that research was not accumulating to paint a coherent overall picture, but instead isolated fragments of knowledge were being collected.</li> <li>The brain is, after all, a single organ.</li> </ul>"},{"location":"KB/Z%20Normalization/","title":"Z Normalization","text":""},{"location":"KB/Z%20Normalization/#z-normalization","title":"Z Normalization","text":"<ul> <li>Centering and rescaling the data so that a zero mean and unit variance is obtained.</li> <li>Only compute the parameters \u03bck,\u03c3k on the training set!</li> <li>For image data, normalization is not done per pixel but computed over all the pixels</li> </ul>"},{"location":"KB/Z-Space%20Entanglement/","title":"Z-Space Entanglement","text":""},{"location":"KB/Z-Space%20Entanglement/#z-space-entanglement","title":"Z-Space Entanglement","text":"<ul> <li>Another challenge with controllable generation is referred to as entanglement in Z-space.</li> <li>When the z-space is entangled, this means movement in different directions has an effect on multiple features in the output simultaneously.</li> <li>Even if these features aren't correlated, an entangled z-space results in a single feature change modifying more than one feature in the output.</li> <li>Entanglement happens commonly if the number of dimensions in the z-space isn't large enough</li> </ul>"},{"location":"KB/Zeiler%20Fergus/","title":"Zeiler Fergus","text":""},{"location":"KB/Zeiler%20Fergus/#zeiler-fergus","title":"Zeiler Fergus","text":"<ul> <li>multiple interleaved layers of Conv, non-linear Activation Functions, local response normalizations, and max Pooling</li> </ul>"},{"location":"KB/Zero%20Label%20Language%20Learning/","title":"Zero Label Language Learning","text":""},{"location":"KB/Zero%20Label%20Language%20Learning/#zero-label-language-learning","title":"Zero Label Language Learning","text":"<ul> <li>Towards Zero-Label Language Learning</li> <li>Unsupervised Data Generation</li> <li>SuperGLUE</li> <li>Treat LMs as few-shot generators (rather than few-shot learners)</li> <li>Create prompts with  pair(s) <li>Ask the model to generate more for the same label</li> <li>The emphasis is on the labelled data generation (rather than inference)</li> <li>The new idea is about generating more data and going with conventional route</li> <li>This paper confirms all the above by introducing UDG using LMs, even for complex higher-order tasks and empirically shows classical fine-tuning with more data works better.</li>"},{"location":"KB/aphasia/","title":"aphasia","text":""},{"location":"KB/aphasia/#aphasia","title":"Aphasia","text":"<ul> <li>Disturbance of language affecting speech production, comprehension, reading or writing, due to brain injury \u2013 most commonly from stroke or trauma.</li> <li>The type of aphasia depends on the brain area damaged</li> </ul>"},{"location":"KB/architecture/","title":"Architecture","text":""},{"location":"KB/architecture/#categories-anchor","title":"categories: ['anchor']","text":"<ul> <li>./ADVENT.md</li> <li>./ALBERT.md</li> <li>./Adagrad.md</li> <li>Adaptive Input Representation.md</li> <li>Additive Attention.md</li> <li>Affordance Detection Task Specific.md</li> <li>Alex Net.md</li> <li>./Alphacode.md</li> <li>Attention NMT.md</li> <li>./Attention.md</li> <li>./AudioLM.md</li> <li>Auto Encoders.md</li> <li>./AutoDistill.md</li> <li>./BART.md</li> <li>./BERT.md</li> <li>Bahdanau Attention.md</li> <li>Basic GAN.md</li> <li>Basic RNN Architectures.md</li> <li>Basic Transformer.md</li> <li>Beam search.md</li> <li>Bi Directional RNN.md</li> <li>Bias nodes.md</li> <li>Big Bird.md</li> <li>./BinaryBERT.md</li> <li>./BlockNeRF.md</li> <li>./CLIP.md</li> <li>Capsule Layer.md</li> <li>Capsule Network.md</li> <li>Chat GPT is Not All You Need.md</li> <li>./ChatGPT.md</li> <li>./Chinchilla.md</li> <li>Classifier Gradients.md</li> <li>./Codex.md</li> <li>Collaborative Topic Regression.md</li> <li>Conditional GAN.md</li> <li>./Conformer.md</li> <li>Content Based Attention.md</li> <li>Contrastive Predictive Coding.md</li> <li>./ConvBERT.md</li> <li>./ConvNeXt.md</li> <li>Convolutional RNN.md</li> <li>Curriculum Learning.md</li> <li>./CycleGAN.md</li> <li>DALL-E 3.md</li> <li>./DALL-E.md</li> <li>DALL\u00b7E 2.md</li> <li>./DCGAN.md</li> <li>./DLRM.md</li> <li>./DeepFM.md</li> <li>./DeepNet.md</li> <li>./DeepPERF.md</li> <li>Denoising Autoencoder.md</li> <li>Dense Net.md</li> <li>Diffusion LM.md</li> <li>Dilated Sliding Window Attention.md</li> <li>./DistillBERT.md</li> <li>Dot Product Attention.md</li> <li>./Dreamfusion.md</li> <li>Dynamic Sparsity.md</li> <li>./ELECTRA.md</li> <li>./ELMO.md</li> <li>./EfficientNet.md</li> <li>./Elu.md</li> <li>Encoder Decoder Attention.md</li> <li>Ensemble Distillation.md</li> <li>./FLASH.md</li> <li>./FLAVA.md</li> <li>./FaceNet.md</li> <li>Factorized Embedding Parameters.md</li> <li>Familar Object Grasping Object Viiew recog.md</li> <li>./FastText.md</li> <li>Faster RCNN.md</li> <li>Feature Correlationa.md</li> <li>Fixed Factorization Attention.md</li> <li>./Flamingo.md</li> <li>./FlowNet.md</li> <li>GAN Z Space.md</li> <li>./GAU.md</li> <li>./GELU.md</li> <li>./GGCNN.md</li> <li>./GLOW.md</li> <li>./GPT.md</li> <li>./GPT3.md</li> <li>./GRConvNet.md</li> <li>./GRU.md</li> <li>./Galactica.md</li> <li>./Gato.md</li> <li>Generative Models.md</li> <li>Generative RNN.md</li> <li>Generative Spoken Language Modeling.md</li> <li>Generative vs Discriminative Models.md</li> <li>./GloVE.md</li> <li>Global Average Pooling.md</li> <li>Global and Sliding Window Attention.md</li> <li>Google NMT.md</li> <li>./Grad-CAM.md</li> <li>Hallucination Text Generation.md</li> <li>HiFI-GAN Denoising.md</li> <li>HiFI-GAN Synthesis.md</li> <li>Higher Layer Capsule.md</li> <li>Highway Convolutions.md</li> <li>Hopfield networks.md</li> <li>./Imagen.md</li> <li>./Inception.md</li> <li>Instance Normalization.md</li> <li>Instant NeRF.md</li> <li>Interpreting Attention.md</li> <li>Isotropic Architectures.md</li> <li>Joint Factor Analysis.md</li> <li>./Jukebox.md</li> <li>./LASER.md</li> <li>./LaMDA.md</li> <li>Large Kernel in Attention.md</li> <li>Large Kernel in Convolution.md</li> <li>Le Net.md</li> <li>Learning to Detect Grasp Affordance.md</li> <li>Linear Classifier Probes.md</li> <li>Listen Attend Spell.md</li> <li>Location Aware Attention.md</li> <li>Location Base Attention.md</li> <li>Long Short Term Memory (LSTM).md</li> <li>./Longformer.md</li> <li>./MCnet.md</li> <li>./MLIM.md</li> <li>./MLM.md</li> <li>./MVGrasp.md</li> <li>./Magic3D.md</li> <li>Masked Autoencoders.md</li> <li>./Minerva.md</li> <li>Mixed chunk attention.md</li> <li>Mobile Net.md</li> <li>./MobileOne.md</li> <li>Multi Head Attention.md</li> <li>Multiplicative Attention.md</li> <li>./Muse.md</li> <li>./Nasnet.md</li> <li>Neural Network Architecture Cheat Sheet.md</li> <li>Neural Probabilistic Model.md</li> <li>Neural Text Degeneration.md</li> <li>Noisy Relu.md</li> <li>./OPT.md</li> <li>./PEER.md</li> <li>./PRelu.md</li> <li>./PaLM.md</li> <li>Padded Conv.md</li> <li>./PatchGAN.md</li> <li>./Phenaki.md</li> <li>Phrase Representation Learning.md</li> <li>./Pix2Seq.md</li> <li>Point Cloud.md</li> <li>./PointNet++.md</li> <li>Position Encoding.md</li> <li>Position Wise Feed Forward.md</li> <li>Primary Capsule.md</li> <li>./RETRO.md</li> <li>Receptive field.md</li> <li>./RegNet.md</li> <li>Region Proposal.md</li> <li>Relative Multi Head Self Attention.md</li> <li>./Relu.md</li> <li>./RepLKNet.md</li> <li>Res Net D.md</li> <li>Res Net.md</li> <li>Restricted Boltzmann Machine.md</li> <li>./RetinaNet.md</li> <li>./Rmsprop.md</li> <li>./RoBERTa.md</li> <li>Routing by Agreement.md</li> <li>./S2ST.md</li> <li>./SLAK.md</li> <li>./SRN.md</li> <li>Scaled Dot Product Attention.md</li> <li>Scene based text to image generation.md</li> <li>./SegNet.md</li> <li>Self Attention GAN.md</li> <li>Self Attention.md</li> <li>./Seq2Seq.md</li> <li>./ShuffleNet.md</li> <li>./Sigmoid.md</li> <li>Sliding Window Attention.md</li> <li>Soft Attention.md</li> <li>./Softmax.md</li> <li>./Softplus.md</li> <li>./Soundify.md</li> <li>Sparse Evolutionary Training.md</li> <li>Sparse Transformer.md</li> <li>Spatial Transformer.md</li> <li>Speaker Verification.md</li> <li>Speech Emotion Recognition.md</li> <li>Speech Recognition.md</li> <li>Speech Resynthesis.md</li> <li>Spiking Networks.md</li> <li>Stable Difusion.md</li> <li>Stack GAN.md</li> <li>Stacking RNN.md</li> <li>StarGAN v2.md</li> <li>./StarGAN.md</li> <li>Strided Attention.md</li> <li>./Strided.md</li> <li>Style GAN.md</li> <li>./Swish.md</li> <li>./TSDF.md</li> <li>./Tacotron.md</li> <li>./Tanh.md</li> <li>Teacher Forcing.md</li> <li>Temporal Conv.md</li> <li>./TemporalLearning.md</li> <li>Textless Speech Emotion Conversion.md</li> <li>./TinyBERT.md</li> <li>Token Embedding.md</li> <li>./Transformer-XL.md</li> <li>./Transformer.md</li> <li>Transposed Conv.md</li> <li>./ULMFit.md</li> <li>./Un-LSTM.md</li> <li>Unet Grasping.md</li> <li>./Unet.md</li> <li>./VAE.md</li> <li>./VGGish.md</li> <li>./VICReg.md</li> <li>./VL-BEIT.md</li> <li>./Vgg.md</li> <li>./ViLT.md</li> <li>./VisualGPT.md</li> <li>Volumetric Grasping Network.md</li> <li>./WaveGlow.md</li> <li>./WebGPT.md</li> <li>./Whisper.md</li> <li>Wide Deep Recommender.md</li> <li>Window Based Regression.md</li> <li>./Word2Vec.md</li> <li>X Vectors.md</li> <li>./XLM-R.md</li> <li>./XLNet.md</li> <li>./Xception.md</li> <li>./YOLO.md</li> <li>Z-Space Entanglement.md</li> <li>Zeiler Fergus.md</li> <li>cross-layer parameter sharing.md</li> <li>./dGSLM.md</li> <li>./data2vec.md</li> <li>./i-Code.md</li> <li>./pGLSM.md</li> <li>./wave2vec.md</li> </ul>"},{"location":"KB/augment/","title":"Augment","text":""},{"location":"KB/augment/#categories-anchor","title":"categories: ['anchor']","text":"<ul> <li>A survey on Image Data Augmentation for Deep Learning.md</li> <li>Adversarial Spatial Dropout for Occlusion.md</li> <li>Alleviating Class Imbalance with Data Augmentation.md</li> <li>Attentive CutMix.md</li> <li>./AttributeMix.md</li> <li>./AugMix.md</li> <li>Augmentation-wise Weight Sharing strategy.md</li> <li>Augmented Random Search.md</li> <li>Auto Augment.md</li> <li>./AutoAugment.md</li> <li>./Co-Mixup.md</li> <li>Color Space Transformations.md</li> <li>./CowMask.md</li> <li>./Cropping.md</li> <li>Cut and Delete.md</li> <li>Cut and Mix.md</li> <li>Cut, Paste and Learn.md</li> <li>./CutMix.md</li> <li>./Cutout.md</li> <li>Data Augmentation via Latent Space Interpolation for Image Classification.md</li> <li>Data Augmentation with Curriculum Learning.md</li> <li>Deep Generative Models.md</li> <li>Fast AutoAugment.md</li> <li>./FeatMatch.md</li> <li>Feature Augmentation.md</li> <li>Feature Space Augmentation.md</li> <li>./Flipping.md</li> <li>./Fmix.md</li> <li>GAN\u2010based Data Augmentation.md</li> <li>Gaussian Distortion.md</li> <li>Geometric Transformations.md</li> <li>./GridMask.md</li> <li>Hide and Seek.md</li> <li>Image Erasing.md</li> <li>Image Manipulation.md</li> <li>Image Mix.md</li> <li>Image Mixing and Deletion.md</li> <li>Intra-Class Part Swapping.md</li> <li>./KeepAugment.md</li> <li>Kernel Filters.md</li> <li>Manifold MixUp.md</li> <li>./ManifoldMix.md</li> <li>Meta Learning Data Augmentations.md</li> <li>Mixed Example.md</li> <li>Moment Exchange.md</li> <li>Neural Augmentation.md</li> <li>Noise Injection.md</li> <li>On the Importance of Visual Context for Data Augmentation in Scene Understanding.md</li> <li>Population Based Augmentation.md</li> <li>Puzzle Mix.md</li> <li>./RICAP.md</li> <li>./RandAugment.md</li> <li>Random Distortion.md</li> <li>Random Erasing.md</li> <li>./ReMix.md</li> <li>./ResizeMix.md</li> <li>./SMOTE.md</li> <li>./SaliencyMix.md</li> <li>Sample Pairing.md</li> <li>./Shear.md</li> <li>Skew Tilt.md</li> <li>Smart Augmentation.md</li> <li>./SmoothMix.md</li> <li>./SnapMix.md</li> <li>./SpecAugment.md</li> <li>Test-time Augmentation.md</li> <li>Visual Context Augmentation.md</li> </ul>"},{"location":"KB/bitter_lesson/","title":"bitter_lesson","text":"","tags":["deeplearning"]},{"location":"KB/bitter_lesson/#the-bitter-lesson","title":"The Bitter Lesson","text":"<ul> <li>Richard sutton</li> <li>The biggest lesson that can be read from 70 years of AI research is that general methods that leverage computation are ultimately the most effective, and by a large margin</li> <li>Seeking an improvement that makes a difference in the shorter term, researchers seek to leverage their human knowledge of the domain, but the only thing that matters in the long run is the leveraging of computation</li> </ul> <ul> <li>In computer chess, the methods that defeated the world champion, Kasparov, in 1997, were based on massive, deep search. At the time, this was looked upon with dismay by the majority of computer chess researchers who had pursued methods that leveraged human understanding of the special structure of chess. When a simpler, search-based approach with special hardware and software proved vastly more effective, these human-knowledge-based chess researchers were not good losers. They said that ``brute force\\\" search may have won this time, but it was not a general strategy, and anyway it was not how people played chess. These researchers wanted methods based on human input to win and were disappointed when they did not.</li> <li>Learning by self play, and learning in general, is like search in that it enables massive computation to be brought to bear.</li> <li>statistical methods won out over the human-knowledge-based methods</li> <li>Deep learning methods rely even less on human knowledge, and use even more computation, together with learning on huge training sets, to produce dramatically better speech recognition systems.</li> <li>The bitter lesson is based on the historical observations that 1) AI researchers have often tried to build knowledge into their agents, 2) this always helps in the short term, and is personally satisfying to the researcher, but 3) in the long run it plateaus and even inhibits further progress, and 4) breakthrough progress eventually arrives by an opposing approach based on scaling computation by search and learning</li> </ul> <ul> <li>great power of general purpose methods, of methods that continue to scale with increased computation even as the available computation becomes very great</li> <li>scale arbitrarily in this way are search and learning.</li> <li>the actual contents of minds are tremendously, irredeemably complex; we should stop trying to find simple ways to think about the contents of minds, such as simple ways to think about space, objects, multiple agents, or symmetries.</li> <li>They are not what should be built in, as their complexity is endless; instead we should build in only the meta-methods that can find and capture this arbitrary complexity</li> <li>they can find good approximations, but the search for them should be by our methods, not by us</li> </ul>","tags":["deeplearning"]},{"location":"KB/blind%20ethical%20judgement/","title":"blind ethical judgement","text":""},{"location":"KB/blind%20ethical%20judgement/#blind-ethical-judgement","title":"Blind Ethical Judgement","text":"<ul> <li>the given agent's state and knowledge are unknown</li> </ul>"},{"location":"KB/brain/","title":"Brain","text":""},{"location":"KB/brain/#categories-anchor","title":"categories: ['anchor']","text":"<ul> <li>Action Potential.md</li> <li>Adrenal Glands.md</li> <li>./Adrenaline.md</li> <li>./Allele.md</li> <li>Alpha Waves.md</li> <li>Alzheimer\u2019s Disease.md</li> <li>Amino Acid.md</li> <li>./Amygdala.md</li> <li>Amyloid Plaque.md</li> <li>Amyloid-beta (A\u03b2) Protein.md</li> <li>Amyotrophic Lateral Sclerosis (ALS).md</li> <li>./Angiography.md</li> <li>./Apoptosis.md</li> <li>./Astrocyte.md</li> <li>Axon Terminal.md</li> <li>./Axon.md</li> <li>./BOLD.md</li> <li>Basal Ganglia.md</li> <li>Basilar Artery.md</li> <li>Belmont Principles.md</li> <li>Belmont Report.md</li> <li>./Beneficence.md</li> <li>Beta Waves.md</li> <li>Biological Neuron.md</li> <li>./Biomarkers.md</li> <li>Blood-brain Barrier.md</li> <li>Brain Areas.md</li> <li>Brain Cortex.md</li> <li>Brain Organoid.md</li> <li>Brain Oscillations.md</li> <li>Brain-derived Neurotrophic Factor (BDNF).md</li> <li>BrainWave Coherence.md</li> <li>BrainWave CrossFrequency Coupling.md</li> <li>BrainWave Synchronization.md</li> <li>./Brainstem.md</li> <li>Brocas Area.md</li> <li>CRISPR (clustered Regularly-interspaced Short Palindromic repeats).md</li> <li>Central Sulcus.md</li> <li>Cerebellar Artery.md</li> <li>./Cerebellum.md</li> <li>Cerebral Palsy.md</li> <li>Cerebrospinal Fluid (CSF).md</li> <li>./Cerebrum.md</li> <li>./Chimera.md</li> <li>Chronic Encephalopathy Syndrome (CES).md</li> <li>Chronic Traumatic Encephalopathy (CTE).md</li> <li>./Cochlea.md</li> <li>./Concussion.md</li> <li>./Cone.md</li> <li>Corpus callosum.md</li> <li>Cortical Homunculus.md</li> <li>./Cortisol.md</li> <li>Deep Brain Stimulation.md</li> <li>Delta Waves.md</li> <li>./Dendrites.md</li> <li>Digital Phenotyping.md</li> <li>Down Syndrome.md</li> <li>EEG Cap.md</li> <li>./EEG.md</li> <li>Electroconvulsive Therapy (ECT).md</li> <li>./Epigenetics.md</li> <li>./Epilepsy.md</li> <li>./Eugenics.md</li> <li>Frontal Operculum.md</li> <li>Frontal lobe.md</li> <li>Functional Connectivity.md</li> <li>Gamma Waves.md</li> <li>Gamma-aminobutyric Acid (GABA).md</li> <li>Gene Expression.md</li> <li>./Glia.md</li> <li>./Glioblastoma.md</li> <li>./Glioma.md</li> <li>./Glucose.md</li> <li>Glymphatic System.md</li> <li>Granger Causallity.md</li> <li>./Gyrus.md</li> <li>Huntington\u2019s Disease.md</li> <li>./Hypothalamus.md</li> <li>Implicit Bias.md</li> <li>In Silico.md</li> <li>In Vitro.md</li> <li>In Vivo.md</li> <li>Induced Pluripotent Stem Cell (iPSC).md</li> <li>./Insula.md</li> <li>Ion Channel.md</li> <li>./Ketamine.md</li> <li>./Lesion.md</li> <li>Limbic system.md</li> <li>Long Term Potentiation (LTP).md</li> <li>./MRI.md</li> <li>Mesolimbic Pathway.md</li> <li>./Microbiota.md</li> <li>./Microglia.md</li> <li>Multiple Sclerosis.md</li> <li>./Myelin.md</li> <li>Neural Chimera.md</li> <li>Neural Induction.md</li> <li>./Neuroaesthetics.md</li> <li>./Neurogenesis.md</li> <li>./Neuroplasticity.md</li> <li>./Nootropics.md</li> <li>Nucleotide Sequence.md</li> <li>./Nucleotide.md</li> <li>Nucleus Accumbens.md</li> <li>Occipital lobe.md</li> <li>./Optogenetics.md</li> <li>./Organoid.md</li> <li>./Oxytocin.md</li> <li>Parietal lobe.md</li> <li>Parkinson\u2019s Disease.md</li> <li>./Pharmacotherapy.md</li> <li>./Phenotype.md</li> <li>Pineal gland.md</li> <li>Pituitary gland.md</li> <li>./Pluripotency.md</li> <li>Positron Emission Tomography (PET).md</li> <li>Postsynaptic Cell.md</li> <li>Presynaptic Cell.md</li> <li>./Prion.md</li> <li>Protein Folding.md</li> <li>./Psychosis.md</li> <li>Rapid Eye Movement (REM) Sleep.md</li> <li>./Recessive.md</li> <li>./Reuptake.md</li> <li>./Rod.md</li> <li>./Serotonin.md</li> <li>Somatosensory Cortex.md</li> <li>./Sono-stimulation.md</li> <li>./Sonogenetics.md</li> <li>./Spectrogram.md</li> <li>Stem Cells.md</li> <li>./Striatum.md</li> <li>./Stroke.md</li> <li>Subgenual Cortex.md</li> <li>Substantia Nigra.md</li> <li>Subthalamic Nucleus.md</li> <li>./Sulcus.md</li> <li>Synaptic Pruning.md</li> <li>Synaptic Transmission.md</li> <li>Tau Protein.md</li> <li>./Telomere.md</li> <li>Temporal lobe.md</li> <li>./Thalamus.md</li> <li>Theta Waves.md</li> <li>Tourette\u2019s Syndrome.md</li> <li>Transcranial Electrical Stimulation (tDCS and tACS).md</li> <li>Transcranial Magnetic Stimulation (TMS).md</li> <li>Two-photon Microscopy.md</li> <li>Undue Inducement.md</li> <li>Vagus Nerve.md</li> <li>Vertebral Arteries.md</li> <li>Vestibular System.md</li> <li>Visual Cortex.md</li> <li>Wernicke Area.md</li> <li>./aphasia.md</li> <li>./fMRI.md</li> </ul>"},{"location":"KB/cheatsheets/","title":"Cheatsheets","text":""},{"location":"KB/cheatsheets/#categories-anchor","title":"categories: ['anchor']","text":""},{"location":"KB/cogitivemodel/","title":"Cogitivemodel","text":""},{"location":"KB/cogitivemodel/#categories-anchor","title":"categories: ['anchor']","text":""},{"location":"KB/cogneuro/","title":"Cogneuro","text":""},{"location":"KB/cogneuro/#categories-anchor","title":"categories: ['anchor']","text":"<ul> <li>Attentions and salience.md</li> <li>./BOLD.md</li> <li>Berkeley et al.md</li> <li>./Connectome.md</li> <li>Cross-situational learning.md</li> <li>Deductive Approaches.md</li> <li>Distributive units.md</li> <li>First order generalization.md</li> <li>Inductive Learning.md</li> <li>Interpretability vs Neuroscience.md</li> <li>Localist units.md</li> <li>Milin et al.md</li> <li>Mirman et al.md</li> <li>Motor Memories.md</li> <li>./Overhypotheses.md</li> <li>./Propose-but-verify.md</li> <li>Rescorla-Wagner Algorithm.md</li> <li>Rescorla-Wagner Blocking.md</li> <li>Second order generalization.md</li> <li>Single unit recording.md</li> <li>Superposition Catastrophe.md</li> <li>Symbolic models.md</li> <li>Transitional probabilities.md</li> <li>./conditioning.md</li> <li>./fMRI.md</li> <li>memory trace.md</li> </ul>"},{"location":"KB/cognitivemodel/","title":"Cognitivemodel","text":""},{"location":"KB/cognitivemodel/#categories-anchor","title":"categories: ['anchor']","text":"<ul> <li>ACT-R Chunk.md</li> <li>./ACT-R.md</li> <li>Active tracking.md</li> <li>CogMod Final Paper.md</li> <li>Cognition Hazard Rates.md</li> <li>Cognitive Foreperiod.md</li> <li>Cognitive Multitasking.md</li> <li>Cognitive Preparation.md</li> <li>Cognitive fMTP.md</li> <li>Declarative Memory Blending.md</li> <li>Declarative memory.md</li> <li>Dikes and Rivers.md</li> <li>Implicitly learning when to be ready - From instances to categories.md</li> <li>Mental Fatigue.md</li> <li>Modeling Driver Behavior with Cognitive Architecture.md</li> <li>Modeling motivation using goal competition in mental fatigue studies.md</li> <li>On the Distinction Between Perceived Duration and Event Timing - Towards a Unified Model of Time Perception.md</li> <li>Revisiting variable foreperiod effects evaluating the repetition priming account.md</li> <li>Scaled benefits.md</li> <li>Sequential effects within a short foreperiod context Evidence for the conditioning account of temporal preparation.md</li> <li>Sugar Factory Task.md</li> <li>The Reward Experiment.md</li> <li>The warning stimulus as retrieval cue The role of associative memory in temporal preparation.md</li> <li>Threaded Cognition.md</li> <li>Traces of times past Representations of temporal intervals in memory.md</li> <li>You can play 20 questions with nature and win.md</li> </ul>"},{"location":"KB/composition/","title":"Composition","text":""},{"location":"KB/composition/#categories-anchor","title":"categories: ['anchor']","text":""},{"location":"KB/conditioning/","title":"conditioning","text":""},{"location":"KB/conditioning/#conditioning","title":"Conditioning","text":"<ul> <li>Unconditioned Stimulus (US) (=food)</li> <li>Another feature or cue (bell), becomes Conditioned Stimulus (CS)</li> <li>A response that indicates association (salvation)</li> <li>The unconditioned stimulus is what we want to predict, our outcome</li> <li>Conditioned Stimuli or cues are the features we are learning to use to predict the outcome (US)</li> <li>Current Vector V t ij changes with each learning instance</li> <li> \\[V_{ij}^{t+1}= V_{ij}^{t}+ \\Delta V_{ij}^{t}\\] </li> <li> \\[\\Delta V_{ij}^{t}=(1-\\text{connection weight}_{j}^{t})\\] </li> <li>\u25b6 V = association strength \u25b6 i = current input (cue) \u25b6 j = current output (outcome) \u25b6 \u2206 V : Change in association strength</li> <li>Pavlov discovered evidence of positive associations</li> <li>Associations increase in strength whenever a feature and a cue occur together</li> </ul>"},{"location":"KB/croissant/","title":"croissant","text":"","tags":["metadata"]},{"location":"KB/croissant/#croissant","title":"Croissant","text":"<ul> <li>Croissant is a metadata description format</li> <li>Ml datasets are a combination of structured and unstructured data, which make them complicated to manage</li> <li>Croissant was built on top of schema.org, and has more details relative to it</li> <li>The format has 4 layers<ul> <li>dataset level metadata</li> <li>resource description</li> <li>content structure</li> <li>ml semantics</li> </ul> </li> <li>Croissant does not require any changes to underlying data</li> <li>Analysis and visualization tools work out of the box for all datasets</li> <li>Using croissant, datasets can be exposed consistently throughout platforms</li> <li>Collaborations with google, hugginface, google dataset search also exist</li> <li>openml has deeper dataset description by default, slightly lesser in HF and kaggle</li> <li>once loaded, datasets can be imported elsewhere (torch, tf etc) easily</li> <li>Croissant editor - web app where you can use a GUI to enter the dataset descriptions</li> <li>NeurIPS also now recommends using the Croissant format</li> </ul>","tags":["metadata"]},{"location":"KB/cross-layer%20parameter%20sharing/","title":"cross-layer parameter sharing","text":""},{"location":"KB/cross-layer%20parameter%20sharing/#cross-layer-parameter-sharing","title":"Cross-layer Parameter Sharing","text":"<ul> <li>between encoder segments, layer parameters are shared for every similar subsegment.</li> <li>This means that e.g. with 12 encoder segments:<ul> <li>The multi-head self-attention subsegments share parameters (i.e. weights) across all twelve layers.</li> <li>The same is true for the feedforward segments.</li> </ul> </li> <li>The consequence of this change is that the number of parameters is reduced significantly, simply because they are shared.</li> <li>the stabilization of the neural network due to parameter sharing. In other words, beyond simply reducing the computational cost involved with training, the paper suggests that sharing parameters can also improve the training process.</li> </ul>"},{"location":"KB/dGSLM/","title":"dGSLM","text":""},{"location":"KB/dGSLM/#dgslm","title":"dGSLM","text":"<ul> <li>Generative Spoken Dialogue Language Modeling</li> <li>dGSLM</li> <li>first \u201ctextless\u201d model able to generate audio samples of naturalistic spoken dialogues</li> <li>unsupervised spoken unit discovery coupled with a dual-tower transformer architecture with cross-attention trained on 2000 hours of two-channel raw conversational audio Fisher Spanish-English without any text or labels</li> <li>generate speech, laughter and other paralinguistic signals in the two channels simultaneously and reproduces naturalistic turn taking</li> </ul>"},{"location":"KB/data2vec/","title":"data2vec","text":""},{"location":"KB/data2vec/#data2vec","title":"data2vec","text":"<ul> <li>data2vec: a General Framework for Self-supervised Learning in Speech, Vision and Language</li> <li>closer to general self-supervised learning</li> <li>framework that uses the same learning method for either speech, NLP or computer vision</li> <li>predict latent representations of the full input data based on a masked view of the input in a self distillation setup using a standard Transformer architecture</li> <li>Instead of predicting modality-specific targets such as words, visual tokens or units of human speech which are local in nature, data2vec predicts contextualized latent representations that contain information from the entire inpu</li> <li>Today\u2019s self-supervised learning research almost typically focuses on a single modality</li> <li>As a result, researchers specializing in one modality often adopt a totally different strategy than those specializing in another.</li> <li>For each modality, algorithms anticipate distinct units: pixels or visual tokens for images, words for the text, and learned sound inventories for voice</li> <li>teaching models to anticipate their own representations of the incoming data, regardless of mode</li> <li>Instead of predicting visual tokens, phrases, or sounds, a single algorithm may work with completely different sorts of input by focusing on these representations \u2014 the layers of a neural network</li> <li>robust normalization of the features for the job that would be trustworthy in different modalities to directly predict representations.</li> <li>The method starts by computing target representations from an image, a piece of text, or a voice utterance using a teacher network</li> <li>After that, a portion of the input was masked and repeated with a student network, which predicts the teacher\u2019s latent representations</li> <li>Even though it only has a partial view of the data, the student model must predict accurate input data</li> <li>The instructor network is identical to the student network, except with somewhat out-of-date weights.</li> <li>ImageNet</li> <li>surpassed wav2vec 2.0 and HuBERT</li> <li>GLUE</li> <li>Method:</li> <li>data2vec is trained by predicting the model representations of the full input data given a partial view of the input</li> <li>They first encode a masked version of the training sample (model in student mode) and then construct training targets by encoding the unmasked version of the input sample with the same model but when parameterized as an exponentially moving average of the model weights (model in teacher mode)</li> <li>The target representations encode all of the information in the training sample and the learning task is for the student to predict these representations given a partial view of the input.</li> <li>Modality encoding:</li> <li>The model architecture used is the standard Transformer architecture with a modality-specific encoding of the input data borrowed from prior work:</li> <li>For computer vision, they have used the ViT-strategy of encoding an image as a sequence of patches, each spanning 16x16 pixels, input to a linear transformation.</li> <li>Speech data is encoded using a multi-layer 1-D convolutional neural network that maps 16 kHz waveform to 50 Hz representations.</li> <li>Text is pre-processed to obtain sub-word units, which are then embedded in distributional space via learned embedding vectors.</li> </ul>"},{"location":"KB/dataset/","title":"Dataset","text":""},{"location":"KB/dataset/#categories-anchor","title":"categories: ['anchor']","text":"<ul> <li>./1D-ALVINN.md</li> <li>AudioSet classification.md</li> <li>./AudioSet.md</li> <li>./BUCC.md</li> <li>Benchmark LLM.md</li> <li>Billion Word.md</li> <li>./BooksCorpus.md</li> <li>./Broden.md</li> <li>./CIFAR.md</li> <li>./COCO.md</li> <li>CUB-200-2011 4.md</li> <li>./CUB-200-2011.md</li> <li>./Cityscapes.md</li> <li>./CommonCrawl.md</li> <li>./DrawBench.md</li> <li>English Wikipedia.md</li> <li>./Europarl-ST.md</li> <li>FGVC Aircraft.md</li> <li>./FGVCx.md</li> <li>Fashion MNIST.md</li> <li>Fine grained datasets.md</li> <li>Fisher Spanish-English.md</li> <li>./Flickr30K.md</li> <li>./GLUE.md</li> <li>./GTA5.md</li> <li>Google Conceptual Captions.md</li> <li>Google voice search task.md</li> <li>./HMDB51.md</li> <li>./IDRiD.md</li> <li>./ILSVRC.md</li> <li>./IMDB.md</li> <li>ISIC 2018.md</li> <li>./KITTI.md</li> <li>./Kinetics.md</li> <li>Kvasir Dataset.md</li> <li>Labeled Faces in the Wild.md</li> <li>./LibriSpeech.md</li> <li>./MILANNOTATIONS.md</li> <li>./MIT1003.md</li> <li>./MIT300.md</li> <li>./MLDoc.md</li> <li>./MMLU.md</li> <li>./MNIST.md</li> <li>./MSCOCO.md</li> <li>./MUSAN.md</li> <li>Moment in Time.md</li> <li>NIST 2008 Speaker Recognition Evaluation dataset.md</li> <li>NIST SRE 2016 Cantonese.md</li> <li>NLVR2 3.md</li> <li>./OSIE.md</li> <li>PASCAL VOC.md</li> <li>./PASCAL-S.md</li> <li>People Art Dataset.md</li> <li>Picasso Dataset.md</li> <li>./Places.md</li> <li>./Places365.md</li> <li>./PlantCLEF.md</li> <li>./RACE.md</li> <li>SBU Captions.md</li> <li>./SQuAD.md</li> <li>./STL-10.md</li> <li>./SUNCG.md</li> <li>./SYNTHIA.md</li> <li>Salicon dataset.md</li> <li>SceneNet RGB-D.md</li> <li>Shapes Dataset.md</li> <li>Speakers in the Wild.md</li> <li>Stanford Dogs.md</li> <li>./Swichboard.md</li> <li>./UCF101.md</li> <li>VGGFace2 3.md</li> <li>VQAv2 3.md</li> <li>Visual Commonsense Reasoning.md</li> <li>Visual Genome.md</li> <li>./WMT14.md</li> <li>Wall Street Journal task.md</li> <li>./XLSR.md</li> <li>./YFCC100M.md</li> <li>./iNaturalist.md</li> </ul>"},{"location":"KB/ethics/","title":"Ethics","text":""},{"location":"KB/ethics/#categories-anchor","title":"categories: ['anchor']","text":"<ul> <li>A declarative modular framework for representing and applying ethical principles.md</li> <li>A low-cost ethics shaping approach for designing reinforcement learning agents.md</li> <li>A voting-based system for ethical decision making.md</li> <li>./Belief-Desire-Intention.md</li> <li>Building Ethics into Artificial Intelligence.md</li> <li>Capture bias.md</li> <li>Collective Ethical Decision Frameworks.md</li> <li>Consequentialist ethics.md</li> <li>Coping Theory.md</li> <li>Coverage of ethics within the artificial intelligence and machine learning academic literature.md</li> <li>Cross-dataset generalization.md</li> <li>Deontological ethics.md</li> <li>Embedding ethical principles in collective decision support systems.md</li> <li>Ethical dilemmas.md</li> <li>Even angels need the rules AI, roboethics, and the law.md</li> <li>./GenEth.md</li> <li>Label bias.md</li> <li>Moral Machine project.md</li> <li>Moral decision making frameworks for artificial intelligence.md</li> <li>./MoralDM.md</li> <li>Negative Set Bias.md</li> <li>Norms as a basis for governing sociotechnical systems.md</li> <li>Preferences and ethical principles in decision making.md</li> <li>Selection Bias.md</li> <li>Unbiased Look at Dataset Bias.md</li> <li>Utilitarian ethics.md</li> <li>Virtue ethics.md</li> <li>blind ethical judgement.md</li> <li>fully informed ethical judgement.md</li> <li>partially informed ethical judgement.md</li> <li>sacred values.md</li> <li>./swap-dominance.md</li> <li>trolley scenario.md</li> </ul>"},{"location":"KB/explainability/","title":"Explainability","text":""},{"location":"KB/explainability/#categories-anchor","title":"categories: ['anchor']","text":"<ul> <li>./Accessibility.md</li> <li>Adaptive Whitening Saliency.md</li> <li>Analysis of Explainers of Black Box Deep Neural Networks for Computer Vision A Survey.md</li> <li>./Auditability.md</li> <li>Back Propamine.md</li> <li>Bayesian Rule List.md</li> <li>Beware of Inmates Running the Asylum.md</li> <li>Beware of Inmates Running the Asylum.md</li> <li>Blur Baseline.md</li> <li>./Broden.md</li> <li>./CAM.md</li> <li>./CAM.md</li> <li>./Causability.md</li> <li>./Causality.md</li> <li>Classifying a specific image region using convolutional nets with an ROI mask as input.md</li> <li>Classifying a specific image region using convolutional nets with an ROI mask as input.md</li> <li>Cognitive Engagement.md</li> <li>Comparing Data Augmentation Strategies for Deep Image Classification.md</li> <li>Comparing Data Augmentation Strategies for Deep Image Classification.md</li> <li>./Comprehensibility.md</li> <li>./Conductance.md</li> <li>./Conductance.md</li> <li>./Confidence.md</li> <li>Contributions of Shape, Texture, and Color in Visual Recognition Abstract.md</li> <li>Contributions of Shape, Texture, and Color in Visual Recognition Abstract.md</li> <li>Counterfactual Images.md</li> <li>Counterfactual Impact Evaluation.md</li> <li>./DeconvNet.md</li> <li>Deep Inside Convolutional Networks.md</li> <li>Deep Neural Networks are Easily Fooled High Confidence Predictions for Unrecognizable Images.md</li> <li>Deep Visual Explanation.md</li> <li>./DeepFool.md</li> <li>./DeepLIFT.md</li> <li>./DeepLIFT.md</li> <li>Dynamic visual attention.md</li> <li>./EigenCAM.md</li> <li>./Elaborateness.md</li> <li>Embedding Human Knowledge into Deep Neural Network via Attention Map.md</li> <li>Embedding Human Knowledge into Deep Neural Network via Attention Map.md</li> <li>Explainability Defn.md</li> <li>Explainability Taxonomy.md</li> <li>Explainable Artificial Intelligence (XAI) Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI.md</li> <li>Explanation is not a Technical Term.md</li> <li>./Explanator.md</li> <li>./FGSM.md</li> <li>./Fairness.md</li> <li>./Faithfulness.md</li> <li>Filter Wise Normalization.md</li> <li>./GAM.md</li> <li>Gaussian Baseline.md</li> <li>Generalizing Adversarial Explanations with Grad-CAM.md</li> <li>Generalizing Adversarial Explanations with Grad-CAM.md</li> <li>./GradCAM++.md</li> <li>Gradient Sensitivity.md</li> <li>Graph-based visual saliency.md</li> <li>Group fairness.md</li> <li>Guided BackProp.md</li> <li>Guided GradCAM.md</li> <li>Image Data Augmentation Survey.md</li> <li>Implementation Invariance.md</li> <li>./Independence.md</li> <li>Influence of image classification accuracy on saliency map estimation.md</li> <li>Influence of image classification accuracy on saliency map estimation.md</li> <li>./Informativeness.md</li> <li>Integrated Gradients.md</li> <li>Integrated Gradients.md</li> <li>./Interactivity.md</li> <li>Interpretability and Explainability A Machine Learning Zoo Mini-tour.md</li> <li>./Interpretability.md</li> <li>Interpretation of Neural networks is fragile.md</li> <li>Interpretation of Neural networks is fragile.md</li> <li>./LRP.md</li> <li>Layerwise Conservation Principle.md</li> <li>Layerwise Conservation Principle.md</li> <li>Layerwise Relevance Propagation.md</li> <li>Limited features.md</li> <li>./Manifold.md</li> <li>Maximum Distance Baseline.md</li> <li>Mean Observed Dissimilarity.md</li> <li>Mental Model Matching.md</li> <li>Minimization and reporting of negative impacts.md</li> <li>Multimodal Explanation.md</li> <li>Network Dissection Quantifying Interpretability of Deep Visual Representions.md</li> <li>Noise Tunnel.md</li> <li>Noise Tunnel.md</li> <li>Normalized Inverted Structural Similarity Index.md</li> <li>On the overlap between Grad-CAM saliency maps and explainable visual features in skin cancer images.md</li> <li>On the overlap between Grad-CAM saliency maps and explainable visual features in skin cancer images.md</li> <li>Parent Approximations.md</li> <li>Partial Dependence Plot.md</li> <li>Prediction Difference Analysis.md</li> <li>Privacy awareness.md</li> <li>./PromptIR.md</li> <li>Proxy Attention.md</li> <li>Proxy Attention.md</li> <li>Proxy features.md</li> <li>./RETAIn.md</li> <li>./RISE.md</li> <li>./RandAugment.md</li> <li>Random Directions.md</li> <li>Real Time Image Saliency for Black Box Classifiers.md</li> <li>Real Time Image Saliency for Black Box Classifiers.md</li> <li>./Redress.md</li> <li>./SAM-ResNet.md</li> <li>./SDR.md</li> <li>./SP-LIME.md</li> <li>./SSR.md</li> <li>Salience Map.md</li> <li>Salience Map.md</li> <li>Saliency using natural statistics.md</li> <li>Saliency vs Attention.md</li> <li>Sanity Checks for Saliency Maps.md</li> <li>./ScoreCAM.md</li> <li>./Separation.md</li> <li>Sharpness and Flatness.md</li> <li>Skewed data.md</li> <li>./Smooth-Grad.md</li> <li>SmoothGrad Square.md</li> <li>SmoothGrad Square.md</li> <li>Social Construction of XAI, do we need one definition to rule them all.md</li> <li>Structural Similarity Index.md</li> <li>./Sufficiency.md</li> <li>./Summit.md</li> <li>./TREPAN.md</li> <li>Tainted data.md</li> <li>Textbooks are all you need.md</li> <li>The Unreliability of Saliency Methods.md</li> <li>The Unreliability of Saliency Methods.md</li> <li>The elephant in the interpretability room.md</li> <li>There and back again.md</li> <li>Towards A Rigorous Science of Interpretable Machine Learning.md</li> <li>Training Trajectories.md</li> <li>Trajectory Plotting with PCA.md</li> <li>./Transferability.md</li> <li>./Transparency.md</li> <li>./Trustworthiness.md</li> <li>./Understandability.md</li> <li>Uniform baseline.md</li> <li>Use Case Utility.md</li> <li>./VarGrad.md</li> <li>./VarGrad.md</li> <li>Variation in Dissimilarity Variation in Dissimilarity.md</li> <li>Vision Explainibility.md</li> <li>Vision Explainibility.md</li> <li>Visualizing the Impact of Feature Attribution Baselines.md</li> <li>Visualizing the Loss Landscape of Neural Nets.md</li> <li>What is being Transferred in transfer learning.md</li> <li>Whos Thinking, A push for human centered evaluation of LLMs.md</li> <li>./XAI.md</li> <li>journals/2022-10-05.md</li> <li>journals/2022-10-17.md</li> <li>./pixelattribution.md</li> </ul>"},{"location":"KB/fMRI/","title":"fMRI","text":""},{"location":"KB/fMRI/#fmri","title":"fMRI","text":"<ul> <li>Unlike MRI. Studies measures brain activity by detecting changes associated with blood flow</li> <li>3mm</li> <li>BOLD</li> </ul>"},{"location":"KB/fastai/","title":"fastai","text":""},{"location":"KB/fastai/#fastai","title":"Fastai","text":"<ul> <li>Fastai Blocks</li> <li>Fastai Interpretation</li> <li>Fastai Deployment</li> <li>Fastai Tricks</li> </ul>"},{"location":"KB/flow/","title":"Flow","text":""},{"location":"KB/flow/#categories-anchor","title":"categories: ['anchor']","text":"<ul> <li>content/notes/Vision Explainibility.md</li> </ul>"},{"location":"KB/fully%20informed%20ethical%20judgement/","title":"fully informed ethical judgement","text":""},{"location":"KB/fully%20informed%20ethical%20judgement/#fully-informed-ethical-judgement","title":"Fully Informed Ethical Judgement","text":"<ul> <li>with complete information about a given agent's state and knowledge</li> <li>no quantitative measure of how far a behaviour is from rightfulness or goodness</li> </ul>"},{"location":"KB/gen_quotes/","title":"Gen quotes","text":"Quotes Random Quotes   This page displays 10 random Quotes from my personal repository of Quotes I have collected (and continue to collect) over the years. Sadly, most of them do not have any citations. I will eventually try to write a script that finds the authors of the same.   These have been collected from books, websites, movies and music and each of them has taught me something over the years. Here I am sharing them with you, dear visitor :) Show Random Points"},{"location":"KB/gensim/","title":"gensim","text":""},{"location":"KB/gensim/#gensim","title":"Gensim","text":"<ul> <li>library</li> </ul>"},{"location":"KB/gensim/#w2vec-code","title":"w2vec Code","text":"<pre><code>nltk==3.6.1  \nnode2vec==0.4.3  \npandas==1.2.4  \nmatplotlib==3.3.4  \ngensim==4.0.1  \nscikit-learn=0.24.1\n</code></pre> <pre><code>import nltk  \nnltk.download('stopwords')  \nnltk.download('punkt')\n\nimport pandas as pd\n\nimport nltk\n\nimport string\n\nimport matplotlib.pyplot as plt\n\nfrom nltk.corpus import stopwords\n\nfrom nltk import word_tokenize\n\nfrom gensim.models import Word2Vec as w2v\n\nfrom sklearn.decomposition import PCA\n\n# constants\n\nPATH = 'data/shakespeare.txt'\n\nsw = stopwords.words('english')\n\nplt.style.use('ggplot')\n\n# nltk.download('punkt')\n\n# nltk.download('stopwords')\n\n# import data\n\nlines = []\n\nwith open(PATH, 'r') as f:\n\nfor l in f:\n    lines.append(l)\n\n# remove new lines\nlines = [line.rstrip('\\n') for line in lines]\n\n# make all characters lower\nlines = [line.lower() for line in lines]\n\n# remove punctuations from each line\nlines = [line.translate(str.maketrans('', '', string.punctuation)) for line in lines]\n\n# tokenize\nlines = [word_tokenize(line) for line in lines]\n\ndef remove_stopwords(lines, sw = sw):\n    '''\n    The purpose of this function is to remove stopwords from a given array of \n    lines.\n\n    params:\n        lines (Array / List) : The list of lines you want to remove the stopwords from\n        sw (Set) : The set of stopwords you want to remove\n\n    example:\n        lines = remove_stopwords(lines = lines, sw = sw)\n    '''\n\n    res = []\n    for line in lines:\n        original = line\n        line = [w for w in line if w not in sw]\n        if len(line) &lt; 1:\n            line = original\n        res.append(line)\n    return res\n\nfiltered_lines = remove_stopwords(lines = lines, sw = sw)\n\nw = w2v(\n    filtered_lines,\n    min_count=3,  \n    sg = 1,       # 1 for skip gram, 0 for cbow\n    window=7      \n)       \n\nprint(w.wv.most_similar('thou'))\n\nemb_df = (\n    pd.DataFrame(\n        [w.wv.get_vector(str(n)) for n in w.wv.key_to_index],\n        index = w.wv.key_to_index\n    )\n)\nprint(emb_df.shape)\nemb_df.head()\n\npca = PCA(n_components=2, random_state=7)\npca_mdl = pca.fit_transform(emb_df)\n\nemb_df_PCA = (\n    pd.DataFrame(\n        pca_mdl,\n        columns=['x','y'],\n        index = emb_df.index\n    )\n)\n\nplt.clf()\nfig = plt.figure(figsize=(6,4))\n\nplt.scatter(\n    x = emb_df_PCA['x'],\n    y = emb_df_PCA['y'],\n    s = 0.4,\n    color = 'maroon',\n    alpha = 0.5\n)\n\nplt.xlabel('PCA-1')\nplt.ylabel('PCA-2')\nplt.toc: true\ntitle('PCA Visualization')\nplt.plot()\n</code></pre>"},{"location":"KB/handwritingRecognition/","title":"handwritingRecognition","text":""},{"location":"KB/handwritingRecognition/#handwritingrecognition","title":"handwritingRecognition","text":"<ul> <li>https://arxiv.org/pdf/1912.10205.pdf<ul> <li>https://github.com/Canjie-Luo/Text-Image-Augmentation</li> <li></li> <li></li> </ul> </li> <li>https://github.com/FactoDeepLearning/VerticalAttentionOCR<ul> <li>https://arxiv.org/pdf/2012.03868v2.pdf</li> <li>segmentation free</li> <li></li> <li></li> </ul> </li> </ul>"},{"location":"KB/i-Code/","title":"i-Code","text":""},{"location":"KB/i-Code/#i-code","title":"i-Code","text":"<ul> <li>i-Code: an Integrative and Composable Multimodal Learning Framework</li> <li>Human intelligence is multimodal; they integrate visual, linguistic, and acoustic signals to maintain a holistic worldview</li> <li>Most current pretraining methods, however, are limited to one or two modalities.</li> <li>jointly learns representations for vision, language and speech into a unified, shared and general-purpose vector representation</li> <li>data from each [modality] are first given to pretrained single-modality encoder</li> <li>The encoder outputs are then integrated with a multimodal fusion network, which uses novel attention mechanisms and other architectural innovations to effectively combine information from the different modalities</li> <li>new objectives including (i) masked [modality] modeling and (ii) cross-modality contrastive learning</li> <li>pretraining on dual-[modality] datasets can also yield competitive or even better performance than pretraining on videos, the data resource that previous three-modality models were restricted to</li> <li>dynamically process single, dual, and triple-modality data during training and inference, flexibly projecting different combinations of modalities into a single representation space</li> <li>GLUE</li> <li>merge-attention layers and (b) co-attention layers</li> <li>fusion architecture</li> <li>mechanisms that merge and cross the attention scores of different modalities, namely merge-attention (based on self-attention) and co-attention (based on self- and cross-attention) respectively</li> </ul>"},{"location":"KB/iNaturalist/","title":"iNaturalist","text":""},{"location":"KB/iNaturalist/#inaturalist","title":"iNaturalist","text":"<ul> <li>This dataset contains images of thousands of different species of plants and animals, with a total of over 8 million images.</li> </ul>"},{"location":"KB/ill%20conditioning/","title":"ill conditioning","text":""},{"location":"KB/ill%20conditioning/#ill-conditioning","title":"ill conditioning","text":"<ul> <li>Gradient can behave in unexpected ways, e.g in the figure above, very large gradients near flat regions.</li> <li></li> </ul>"},{"location":"KB/imageCaptioning/","title":"Image Captioning","text":""},{"location":"KB/imageCaptioning/#image-captioning","title":"Image Captioning","text":""},{"location":"KB/inter-sentence%20coherence%20loss/","title":"inter-sentence coherence loss","text":""},{"location":"KB/inter-sentence%20coherence%20loss/#inter-sentence-coherence-loss","title":"Inter-sentence Coherence Loss","text":"<ul> <li>inter-sentence coherence loss called sentence-order prediction (SOP) is used.</li> <li>The key problem with this loss is that it merges topic prediction and coherence prediction into one task.</li> <li>Intuitively, we can argue that topic prediction is much easier than coherence prediction. The consequence is that when the model discovers this, it can focus entirely on this subtask, and forget about the coherence prediction task; actually taking the path of least resistance. The authors actually demonstrate that this is happening with the NSP task, replacing it within their work with a sentence-order prediction or SOP task.</li> </ul>"},{"location":"KB/jobs/","title":"Jobs","text":""},{"location":"KB/jobs/#categories-anchor","title":"categories: ['anchor']","text":"<ul> <li>ABN Amro AI Dev.md</li> <li>ABN amro ml.md</li> <li>./Bunq.md</li> <li>Cold email templates.md</li> <li>DevOn AI dev.md</li> <li>Eneco Data Scientist.md</li> <li>Interview Tips.md</li> <li>Kickstart AI.md</li> <li>Latitude Junior ML Engineer.md</li> <li>Leap Data Scientist.md</li> <li>./MLCompany.md</li> <li>Media Distillery.md</li> <li>./MediaMonks.md</li> <li>./Orbisk.md</li> <li>Poki Data Scientist.md</li> <li>Schipol Data Scientist.md</li> <li>VattenFall Data Scientist.md</li> <li>Wageningen Uni AI.md</li> </ul>"},{"location":"KB/jobtemp/","title":"jobtemp","text":"","tags":["jobs"]},{"location":"KB/jobtemp/#jobtemp","title":"Jobtemp","text":"","tags":["jobs"]},{"location":"KB/jobtemp/#dexter-energy","title":"Dexter Energy","text":"<ul> <li>jordan@dexterenergy.ai</li> <li>Jordan Cantlow</li> <li> </li> <li> <p>Klue ML Engineer</p> </li> </ul>","tags":["jobs"]},{"location":"KB/language/","title":"Language","text":""},{"location":"KB/language/#categories-anchor","title":"categories: ['anchor']","text":"<ul> <li>2 X 2 Study.md</li> <li>2 byte character set.md</li> <li>8 bit character set.md</li> <li>A matter of ambiguity? Using eye movements to examine collective vs distributive interpretations of plural sets.md</li> <li>./ANOVA.md</li> <li>./ASCII.md</li> <li>Action Transitive verb.md</li> <li>./Adjective.md</li> <li>./Adverb.md</li> <li>Agglutinating words.md</li> <li>./Allomorph.md</li> <li>Application dependence.md</li> <li>Approximately Compositional Semantic Parsing.md</li> <li>Attentions and salience.md</li> <li>Berkeley et al.md</li> <li>Bottom Up Parsing.md</li> <li>Bound morpheme.md</li> <li>Cardinality Principle.md</li> <li>Case Grammar.md</li> <li>Challenges of Words-and-rules.md</li> <li>Character-set dependence.md</li> <li>./Circumfix.md</li> <li>Collective Interpretation.md</li> <li>Collectivity, Distributivity, and the Interpretation of Plural Numerical Expressions in Child and Adult Language.md</li> <li>Conceptual Parsing.md</li> <li>./Connectionism.md</li> <li>Connectionist Networks.md</li> <li>./Connectives.md</li> <li>Content Morpheme.md</li> <li>Content words.md</li> <li>Context Free Grammar.md</li> <li>Corpus dependence.md</li> <li>Cross-situational learning.md</li> <li>Cumulative Interpretation.md</li> <li>Deductive Approaches.md</li> <li>Derivational Morphology.md</li> <li>./Determiners.md</li> <li>DiTransitive verb.md</li> <li>Distributive Interpretation (2).md</li> <li>Distributive Interpretation.md</li> <li>Distributive units.md</li> <li>Document Triage.md</li> <li>Elements of sets.md</li> <li>Elman 1990.md</li> <li>Elman 1991.md</li> <li>Elman 1992.md</li> <li>Elman 1993.md</li> <li>./Emergentism.md</li> <li>Entities involving in actions.md</li> <li>Evidence For Distributivity Effects in Comprehension.md</li> <li>./Extra-position.md</li> <li>Final Paper Language Modeling.md</li> <li>First order generalization.md</li> <li>Fixed Factors.md</li> <li>Forward Backward Matching.md</li> <li>Free morpheme.md</li> <li>Function words.md</li> <li>Functional Morpheme.md</li> <li>Hybrid Word Segmentation.md</li> <li>Inductive Learning.md</li> <li>./Infix.md</li> <li>Inflectional Morphology.md</li> <li>Inflectional words.md</li> <li>Isolating words.md</li> <li>Language Identification.md</li> <li>Language dependence.md</li> <li>Latent Dirchlet Allocation.md</li> <li>./Lemmatization.md</li> <li>Lexical Ambiguity.md</li> <li>Lexical Disambiguation.md</li> <li>Lexical Word Segmentation.md</li> <li>Lexically Collective.md</li> <li>Lexically Distributive.md</li> <li>./Lexicon.md</li> <li>Linguistic details.md</li> <li>Localist units.md</li> <li>Maximum Matching Algorithm.md</li> <li>Memory-based learning.md</li> <li>Milin et al.md</li> <li>Minimal Semantic Commitment.md</li> <li>Mirman et al.md</li> <li>Misyak et al 2010.md</li> <li>Mixed Effect Models.md</li> <li>Morpheme Generation.md</li> <li>Morpheme Segmentation.md</li> <li>./Morpheme.md</li> <li>Morphology Affix.md</li> <li>Morphology Stem.md</li> <li>./Morphology.md</li> <li>./Morphotactic.md</li> <li>Multiple constraint-based theories.md</li> <li>Names of individuals.md</li> <li>./Nativists.md</li> <li>Non-adjacent dependencies.md</li> <li>Numerically Quantified Expressions.md</li> <li>Object-relative clauses.md</li> <li>./Ostension.md</li> <li>Ostensive Information.md</li> <li>./Overhypotheses.md</li> <li>Parts of action.md</li> <li>Parts of entities.md</li> <li>./Phonetics.md</li> <li>./Phonology.md</li> <li>Picky Puppet Method.md</li> <li>Polysynthetic words.md</li> <li>./Pragmatics.md</li> <li>./Predicate.md</li> <li>./Prefix.md</li> <li>./Prepositions.md</li> <li>./Propose-but-verify.md</li> <li>./Psycholinguistics.md</li> <li>./Punctuation.md</li> <li>Quantifier spreading children misled by ostensive cues.md</li> <li>./Quantifiers.md</li> <li>Random Factors.md</li> <li>Relevance Account.md</li> <li>Relevance Theory.md</li> <li>Rescorla-Wagner Algorithm.md</li> <li>Rescorla-Wagner Blocking.md</li> <li>Saffran, Aslin and Newport.md</li> <li>Salient Object Strategy.md</li> <li>Second order generalization.md</li> <li>Semantic Analysis.md</li> <li>Semantic Grammar.md</li> <li>Semantic Markers.md</li> <li>Semantics influences form.md</li> <li>Sentence Segmentation.md</li> <li>Sentence level processing.md</li> <li>Shared Character Set.md</li> <li>Shortcuts to Quantifier Interpretation in Children and Adults.md</li> <li>Single unit recording.md</li> <li>Statistical Word Segmentation.md</li> <li>Subject relative.md</li> <li>Subject-verb agreement.md</li> <li>./Suffix.md</li> <li>Superposition Catastrophe.md</li> <li>./Suppletion.md</li> <li>Symbolic learning model.md</li> <li>Symbolic models.md</li> <li>Syntactic Ambiguity.md</li> <li>Syntactic Analysis.md</li> <li>Syntactic Bootstrapping.md</li> <li>Syntax First models.md</li> <li>Taking on semantic commitments, II collective versus distributive readings.md</li> <li>Text Normalization.md</li> <li>Text Preprocessing.md</li> <li>Text Segmentation.md</li> <li>The Differentiation Condition.md</li> <li>The Self Organization of Explicit Attitudes.md</li> <li>./Tokenizer.md</li> <li>Top Down Parsing.md</li> <li>Tracking the Continuity of Language Comprehension Computer Mouse Trajectories Suggest Parallel Syntactic Processing.md</li> <li>Transitional probabilities.md</li> <li>Transitive verb.md</li> <li>Types of Words.md</li> <li>Unicode 50.md</li> <li>Unique Character Set.md</li> <li>Universal Quantifiers.md</li> <li>Unrestricted Race Model.md</li> <li>./Verb.md</li> <li>Visual Implicit Learning.md</li> <li>./Wh-dependencies.md</li> <li>./Wickelphones.md</li> <li>Word Blending.md</li> <li>Word Clipping.md</li> <li>Word Compounding.md</li> <li>Word Segmentation.md</li> <li>Word Structure.md</li> <li>./Words-and-Rules.md</li> <li>./conditioning.md</li> <li>past tense.md</li> </ul>"},{"location":"KB/loss/","title":"Loss","text":""},{"location":"KB/loss/#categories-anchor","title":"categories: ['anchor']","text":"<ul> <li>0-1 Loss.md</li> <li>./AUC-Borji.md</li> <li>./AUC-Judd.md</li> <li>Absolute Error.md</li> <li>Adversarial Loss.md</li> <li>Akaike Information Criterion.md</li> <li>Attention Alignment.md</li> <li>BCE with Logits.md</li> <li>./BLEU.md</li> <li>Bayesian Information Criterion.md</li> <li>Binary Cross Entropy.md</li> <li>./CTC.md</li> <li>Confusion Matrix.md</li> <li>Contrastive Loss.md</li> <li>Cosine Similarity.md</li> <li>Cross Entropy.md</li> <li>Cycle Consistency Loss.md</li> <li>Dice Score.md</li> <li>Focal Loss.md</li> <li>./GE2E.md</li> <li>Hinge Loss.md</li> <li>./Huber.md</li> <li>ITM Loss.md</li> <li>Identity Loss.md</li> <li>Intra cluster variance.md</li> <li>Jensen Shannon Divergence Consistency Loss.md</li> <li>KL Divergence.md</li> <li>Log Likelihood Loss.md</li> <li>./LogCosh.md</li> <li>./MAE.md</li> <li>./MAPE.md</li> <li>./MSE.md</li> <li>./MSLE.md</li> <li>Mallows Cp Statistic.md</li> <li>Margin Ranking.md</li> <li>Max Margin Loss.md</li> <li>Negative Log Likelihood.md</li> <li>./PatchGAN.md</li> <li>./Perplexity.md</li> <li>Poisson Loss.md</li> <li>Precision Recall Curve.md</li> <li>./Precision.md</li> <li>Quadratic Loss.md</li> <li>./RAHP.md</li> <li>ROC Curve.md</li> <li>./Recall.md</li> <li>Reconstruction loss.md</li> <li>./SDR.md</li> <li>./SSR.md</li> <li>./Sensitivity.md</li> <li>./Shuffled-AUC.md</li> <li>Sparse Dictionary Learning Loss.md</li> <li>./Specificity.md</li> <li>Squared Error.md</li> <li>Squared Hinge.md</li> <li>Triplet Loss.md</li> <li>inter-sentence coherence loss.md</li> </ul>"},{"location":"KB/mastersthesis/","title":"Mastersthesis","text":""},{"location":"KB/mastersthesis/#categories-anchor","title":"categories: ['anchor']","text":""},{"location":"KB/medical/","title":"Medical","text":""},{"location":"KB/medical/#categories-anchor","title":"categories: ['anchor']","text":"<ul> <li>./Acute.md</li> <li>./Afib.md</li> <li>./Angina.md</li> <li>./Appendectomy.md</li> <li>./Benign.md</li> <li>./Biopsy.md</li> <li>Blood Culture.md</li> <li>Blood Lancet.md</li> <li>Blood Swab.md</li> <li>./C-section.md</li> <li>./Chronic.md</li> <li>Coronary Bypass.md</li> <li>./Defibrillator.md</li> <li>./Dialyser.md</li> <li>./Dialysis.md</li> <li>./Edema.md</li> <li>./Embolism.md</li> <li>./Endoscope.md</li> <li>./Foley.md</li> <li>./Forceps.md</li> <li>./Fracture.md</li> <li>./Hypertension.md</li> <li>Hypodermic Needle.md</li> <li>./Hypotension.md</li> <li>./Hysterectomy.md</li> <li>./Intravenous.md</li> <li>./Intubation.md</li> <li>Lead Test.md</li> <li>Lumbar Puncture or Spinal Tap.md</li> <li>./Malignant.md</li> <li>./Mastectomy.md</li> <li>Myocardial Infarction.md</li> <li>./Nebulizer.md</li> <li>Occult Blood Screen.md</li> <li>./Ophthalmoscope.md</li> <li>Otoscope or Auriscope.md</li> <li>Pulse Oximeter.md</li> <li>Reflex Hammer.md</li> <li>./Remission.md</li> <li>./Sepsis.md</li> <li>./Speculum.md</li> <li>./Spirometer.md</li> <li>./Thrombosis.md</li> <li>./Ultrasound.md</li> </ul>"},{"location":"KB/memory%20trace/","title":"memory trace","text":""},{"location":"KB/memory%20trace/#memory-trace","title":"Memory Trace","text":"<ul> <li>the researchers were able to identify specific neurons in the brain\u2019s motor cortex \u2014 an area responsible for controlling movements \u2014 that were activated during the learning process.</li> <li>The researchers tagged these potential engram cells with a fluorescent marker so they could see if they also played a role in recalling the memory later on</li> </ul>"},{"location":"KB/pGLSM/","title":"pGLSM","text":""},{"location":"KB/pGLSM/#pglsm","title":"pGLSM","text":"<ul> <li>Text-Free Prosody-Aware Generative Spoken Language Modeling</li> <li>similar to how GPT-2 can generate coherent paragraphs</li> <li>builds upon </li> <li>addresses the generative aspects of speech pre-training</li> <li>replacing text with discovered phone-like units for language modeling and shows the ability to generate meaningful novel sentences</li> <li>the units used in GSLM discard most of the prosodic information</li> <li>fails to leverage prosody for better comprehension, and does not generate expressive speech</li> <li>prosody-aware generative spoken language model (pGSLM)</li> <li>multi-stream transformer language model (MS-TLM) of speech, represented as discovered unit and prosodic feature streams, and an adapted HiFi-GAN model converting MS-TLM outputs to waveform</li> </ul>"},{"location":"KB/partially%20informed%20ethical%20judgement/","title":"partially informed ethical judgement","text":""},{"location":"KB/partially%20informed%20ethical%20judgement/#partially-informed-ethical-judgement","title":"Partially Informed Ethical Judgement","text":"<ul> <li>with some information about a given agent's state and knowledge</li> </ul>"},{"location":"KB/past%20tense/","title":"past tense","text":""},{"location":"KB/past%20tense/#past-tense","title":"Past Tense","text":"<ul> <li>When a speaker needs to say the past tense form of a verb if the verb has an irregular form, choose that if not, add -ed</li> </ul>"},{"location":"KB/pixelattribution/","title":"pixelattribution","text":""},{"location":"KB/pixelattribution/#pixelattribution","title":"Pixelattribution","text":""},{"location":"KB/pixelattribution/#pixel-attribution","title":"Pixel Attribution","text":"<ul> <li>Pixel attribution is a special case of feature attribution, but for images</li> <li>Feature attribution explains individual predictions by attributing each input feature according to how much it changed the prediction (negatively or positively)</li> <li>The features can be input pixels, tabular data or words</li> </ul>"},{"location":"KB/pixelattribution/#occlusion-or-perturbation-based","title":"Occlusion or Perturbation-based","text":"<ul> <li>Methods like SHAP and LIME manipulate parts of the image to generateexplanations (modelagnostic).</li> </ul>"},{"location":"KB/pixelattribution/#gradient-based","title":"Gradient-based","text":"<ul> <li>compute the gradient of the prediction (or classification score) with respect to theinput feature</li> <li>The gradient-based methods (of which there are many) mostly differ in how thegradient is computed.</li> <li>explanation has the same size as the input image (or at least can be meaningfullyprojected onto it) and they assign each pixel a value that can be interpreted as therelevance of the pixel to the prediction or classification of that image.</li> </ul>"},{"location":"KB/pixelattribution/#gradient-only-methods","title":"Gradient-only Methods","text":"<ul> <li>whether a change in a pixel would change the prediction</li> <li>Examples are Vanilla Gradient and Grad-CAM</li> <li>If I were to increase the color values of the pixel, the predicted class probabilitywould go up (for positive gradient) or down (for negative gradient</li> <li>The larger the absolute value of the gradient, the stronger the effect of a change ofthis pixel.</li> </ul>"},{"location":"KB/pixelattribution/#path-attribution-methods","title":"Path-attribution Methods","text":"<ul> <li>compare the current image to a reference image, which can be an artificial \"zero\"image such as a completely grey image</li> <li>The difference in actual and baseline prediction is divided among the pixels</li> <li>The baseline image can also be multiple images: a distribution of images</li> <li>model-specific gradient-based methods such as Deep Taylor and IntegratedGradients</li> <li>model-agnostic methods such as LIME and SHAP.</li> <li>Some path-attribution methods are \"complete\", meaning that the sum of therelevance scores for all input features is the difference between the prediction of theimage and the prediction of a reference image</li> <li>Examples are SHAP and Integrated Gradients.</li> <li>The difference between classification scores of the actual image and the baselineimage are attributed to the pixels</li> <li>The choice of the reference image (distribution) has a big effect on the explanation</li> </ul>"},{"location":"KB/pixelattribution/#vanilla-gradient","title":"Vanilla Gradient","text":"<ul> <li>We calculate the gradient of the loss function for the class we are interested in withrespect to the input pixels</li> <li>This gives us a map of the size of the input features with negative to positive values.</li> <li>The recipe for this approach is:</li> <li> <ol> <li>Perform a forward pass of the image of interest.</li> </ol> </li> <li> <ol> <li>Compute the gradient of the class score of interest with respect to the input pixels:</li> </ol> </li> <li></li> <li>Here we set all other classes to zero.</li> <li> <ol> <li>Visualize the gradients. You can either show the absolute values or highlight negative and positive contributions separately.</li> </ol> </li> <li>More formally, we have an image I and the convolutional neural \ud835\udc46\ud835\udc50(\ud835\udc3c) network gives ita score</li> <li>for class c</li> <li>The score is a highly non-linear function of our image.</li> <li>The idea behind using the gradient is that we can approximate that score byapplying a first-order Taylor expansion</li> <li></li> <li>some ambiguity how to perform a backward pass of the gradients</li> <li>since non-linear units such as ReLU (Rectifying Linear Unit) \"remove\" the sign</li> <li>So when we do a backpass, we do not know whether to assign a positive or negativeactivation</li> <li> </li> <li> <p>This means that when the activation of a neuron is zero, we do not know which valueto backpropagate</p> </li> <li>In the case of Vanilla Gradient, the ambiguity is resolved as follows: \ud835\udeff\ud835\udc53= \ud835\udeff\ud835\udc53</li> <li></li> <li>\ud835\udc08 e r e , activation at the lower layer was negative, and one where it is positive orzero</li> <li>Vanilla Gradient takes the gradient we have backpropagated so far up to layer n+1,and then simply sets the gradients to zero where the activation at the layer below isnegative</li> </ul>"},{"location":"KB/pixelattribution/#problems-with-vanilla-gradient","title":"Problems with Vanilla Gradient","text":"<ul> <li>saturation problem</li> <li>When ReLU is used, and when the activation goes below zero, then the activation iscapped at zero and does not change any more</li> </ul>"},{"location":"KB/pixelattribution/#deconvnet","title":"DeconvNet","text":"<ul> <li>almost identical to Vanilla Gradient</li> <li>The goal of DeconvNet is to reverse a neural network and the paper proposesoperations that are reversals of the filtering, pooling and activation layers</li> <li>but apart from the reversal of the ReLU layer, DeconvNet is equivalent to the Vanilla Gradient approach</li> <li>Vanilla Gradient can be seen as a generalization of DeconvNet</li> <li>DeconvNet makes a different choice for backpropagating the gradient- 12:24  through ReLU:</li> <li></li> <li>When backpassing from layer n to layer n-1, DeconvNet \"remembers\" which of theactivations in layer n were set to zero in the forward pass and sets them to zero in layer n-1</li> <li>\ud835\udc4bctivations with a negative value in layer x are set to zero in layer n-1.</li> </ul>"},{"location":"KB/pixelattribution/#grad-cam","title":"Grad-CAM","text":"<ul> <li>Grad-CAM provides visual explanations for CNN decisions</li> <li>Unlike other methods, the gradient is not backpropagated all the way back to theimage, but (usually) to the last convolutional layer to produce a coarse localizationmap that highlights important regions of the image.</li> <li>Gradient-weighted Class Activation Map</li> <li>based on the gradient of the neural networks</li> <li>assigns each neuron a relevance score for the decision of interest</li> <li>This decision of interest can be the class prediction (which we find in the outputlayer), but can theoretically be any other layer in the neural network</li> <li>GradCAM can be used with different CNNs: with fully-connected layers, forstructured output such as captioning and in multi-task outputs, and forreinforcement learning.</li> <li>s a reminder, the first convolutional layer of a CNN takes as input the images andoutputs feature maps that encode learned features</li> <li>higher-level convolutional layers do the same, but take as input the feature maps ofthe previous convolutional layers</li> <li>There are k feature maps in the last \ud835\udc34 ,\ud835\udc34 ,...,\ud835\udc34</li> <li>Grad-CAM has to decide how important each of the k feature map was to our class cthat we are interested in</li> <li>We have to weight each pixel of each feature map with the gradient before weaverage over the feature maps</li> <li>This gives us a heatmap which highlights regions that positively or negatively affectthe class of interest</li> <li>This heatmap is send through the ReLU function, which is a fancy way of saying thatwe set all negative values to zero</li> <li>Grad-CAM removes all negative values by using a ReLU function, with the argumentthat we are only interested in the parts that contribute to the selected class c and not to other classes</li> <li>The word pixel might be misleading here as the feature map is smaller than theimage (because of the pooling units) but is mapped back to the original image</li> <li>We then scale the GradCAM map to the interval [0,1] for visualization purposes and overlay it over the original image.</li> <li></li> <li>Forward-propagate the input image through the convolutional neural network.</li> <li>Obtain the raw score for the class of interest, meaning the activation of the neuron before the softmax layer.</li> <li>Set all other class activations to zero.</li> <li></li> <li>Back-propagate the gradient of the class of interest to the last \ud835\udeff\ud835\udc66\ud835\udc50 \ud835\udeff\ud835\udc34\ud835\udc58 convolutional layer before the fully connected layers.</li> <li>Weight each feature map \"pixel\" by the gradient for the class. Indices i and j refer to the width and height dimensions.</li> <li></li> <li>This means that the gradients are globally pooled</li> <li>Calculate an average of the feature maps, weighted per pixel by the gradient.</li> <li>Apply ReLU to the averaged feature map.</li> <li>Scale values to the interval between 0 and 1. Upscale the image and overlay it over the original image.</li> <li>Additional step for Guided Grad-CAM: Multiply the heatmap with guided backpropagation.</li> </ul>"},{"location":"KB/pixelattribution/#guided-grad-cam","title":"Guided Grad-CAM","text":"<ul> <li>From the description of Grad-CAM you can guess that the localization is verycoarse, since the last convolutional feature maps have a much coarser resolution compared to the input image</li> <li>In contrast, other attribution techniques backpropagate all the way to the inputpixels</li> <li>They are therefore much more detailed and can show you individual edges or spotsthat contributed most to a prediction</li> <li>You compute for an image both the GradCAM explanation and the explanationfrom another attribution method, such as Vanilla Gradient</li> <li>The Grad-CAM output is then upsampled with bilinear interpolation, then both mapsare multiplied element-wise</li> <li>Grad-CAM works like a lense that focuses on specific parts of the pixel-wiseattribution map.</li> </ul>"},{"location":"KB/pixelattribution/#smoothgrad","title":"# SmoothGrad","text":"<ul> <li>make gradient-based explanations less noisy by adding noise and averaging overthese artificially noisy gradient</li> <li>SmoothGrad is not a standalone explanation method, but an extension to anygradientbased explanation method.</li> <li> <ol> <li>Generate multiple versions of the image of interest byadding noise to it. 2.Create pixel attribution maps for all images. </li> </ol> </li> <li> <ol> <li>Average the pixel attribution maps.</li> </ol> </li> <li>The theory is that the derivative fluctuates greatly at small scales</li> <li>Neural networks have no incentive during training to keep the gradients smooth,their goal is to classify images correctly</li> <li>Averaging over multiple maps \"smooths out\" these fluctuations</li> <li></li> <li></li> <li></li> <li>And that is the big issue with all of these methods</li> <li>We do not have a ground truth for the explanations</li> <li>We can only, in a first step, reject explanations that obviously make no sense (andeven in this step we do not have strong confidence</li> </ul>"},{"location":"KB/pixelattribution/#disadvantages","title":"Disadvantages","text":"<ul> <li>it is difficult to know whether an explanation is correct, and a huge part of theevaluation is only qualitative</li> <li>Pixel attribution methods can be very fragile</li> <li>Ghorbani et al. (2019)86 showed that introducing small (adversarial) perturbationsto an image, which still lead to the same prediction, can lead to very different pixelsbeing highlighted as explanations.</li> <li>Kindermans et al. (2019) 87 also showed that these pixel attribution methods can behighly unreliable</li> <li>They added a constant shift to the input data, meaning they added the same pixelchanges to all images</li> <li>They compared two networks, the original network and the \"shifted\" network wherethe bias of the first layer is changed to adapt for the constant pixel shift</li> <li>Both networks produce the same predictions.</li> <li>Further, the gradient is the same for both</li> <li>But the explanations changed, which is an undesirable property. They looked at DeepLift, Vanilla Gradient and Integrated Gradients.</li> </ul>"},{"location":"KB/plan%20recognition%20problem/","title":"plan recognition problem","text":""},{"location":"KB/plan%20recognition%20problem/#plan-recognition-problem","title":"Plan Recognition Problem","text":"<ul> <li>It is likely that the student wants a hint on how to do that step correctly. If the tutor can determine which correct step corresponds to the incorrect step entered by the student, then it can safely hint that correct step. On the other hand, if the tutor cannot determine which correct step corresponds to the student's step, the tutor may ask the student what step they were trying to enter. Andes does this for unrecognizable equations that the student wants help on.</li> <li>If none of these simple cases apply, then the tutoring system has to somehow figure out which of the possible next steps is most likely to be part of the solution that the student is trying to pursue.</li> <li>(Russell &amp; Norvig, 2003)</li> <li>The general idea is to match the sequence of steps leading up to the most recent student step against step sequences that are either generated by a planner or pulled from a plan library. Once the tutor has determined the plan that the student seems to be following, then it can easily determine what the next step in that plan is.</li> </ul>"},{"location":"KB/probabl%20hackathon/","title":"probabl hackathon","text":"","tags":["deeplearning"]},{"location":"KB/probabl%20hackathon/#probabl-hackathon","title":"Probabl Hackathon","text":"","tags":["deeplearning"]},{"location":"KB/probabl%20hackathon/#intro","title":"Intro","text":"<ul> <li>doc</li> <li>around scikitlearn -&gt; profits<ul> <li>inria</li> <li>fit predict and a few tools</li> <li>\"product company\"</li> <li>pre-industrialization</li> </ul> </li> <li>automatic analysis : sklearn too?</li> <li>croissant<ul> <li>also for benchmarks at some point</li> </ul> </li> </ul>","tags":["deeplearning"]},{"location":"KB/probabl%20hackathon/#breakouts","title":"Breakouts","text":"","tags":["deeplearning"]},{"location":"KB/probabl%20hackathon/#organizing-community-events-and-onboarding-contributors","title":"Organizing Community Events and Onboarding Contributors","text":"","tags":["deeplearning"]},{"location":"KB/psychology/","title":"Psychology","text":""},{"location":"KB/psychology/#categories-anchor","title":"categories: ['anchor']","text":"<ul> <li>Attentions and salience.md</li> <li>Berkeley et al.md</li> <li>Challenges of Words-and-rules.md</li> <li>./Connectionism.md</li> <li>Connectionist Networks.md</li> <li>Cross-situational learning.md</li> <li>Deductive Approaches.md</li> <li>Distributive units.md</li> <li>Elman 1990.md</li> <li>Elman 1991.md</li> <li>Elman 1992.md</li> <li>Elman 1993.md</li> <li>./Emergentism.md</li> <li>./Extra-position.md</li> <li>First order generalization.md</li> <li>Inductive Learning.md</li> <li>Localist units.md</li> <li>Memory-based learning.md</li> <li>Milin et al.md</li> <li>Mirman et al.md</li> <li>Misyak et al 2010.md</li> <li>./Nativists.md</li> <li>Non-adjacent dependencies.md</li> <li>Object-relative clauses.md</li> <li>./Overhypotheses.md</li> <li>./Propose-but-verify.md</li> <li>Rescorla-Wagner Algorithm.md</li> <li>Rescorla-Wagner Blocking.md</li> <li>Saffran, Aslin and Newport.md</li> <li>Second order generalization.md</li> <li>Semantics influences form.md</li> <li>Single unit recording.md</li> <li>Subject relative.md</li> <li>Subject-verb agreement.md</li> <li>Superposition Catastrophe.md</li> <li>Symbolic learning model.md</li> <li>Symbolic models.md</li> <li>Transitional probabilities.md</li> <li>Visual Implicit Learning.md</li> <li>./Wh-dependencies.md</li> <li>./Wickelphones.md</li> <li>./Words-and-Rules.md</li> <li>./conditioning.md</li> </ul>"},{"location":"KB/quotes/","title":"Quotes","text":"<p>QUOTES</p> <ul> <li>\"Will you promise me that when you are sad, you'll think about the sky?\" I don t know why he wants me to promise him that but I nod anyway. \"But why?\"</li> <li> <p>\"Because.\" He turns his face back up to the stars. \"The sky is always beautiful. Even when its dark or rainy or cloudy, its still beautiful to look at. It's my favorite thing because I know if I ever get lost or lonely or scared, I just have to look up and it'll be there no matter what...and I know it'll always be beautiful\"</p> </li> <li> <p>\"In a quiet corner at the back, near a row of bunk beds where the surrounding ghosts seemed even more tangible, I found a photo displayed on a wall. Actually, there were a lot of photos of the Holocaust, but this was the one that has never left me. It was in black and white and it showed a short, stocky woman walking down a wide path between towering electrified fences. By the look of the light, it was late in the afternoon, and in the language of those times, she was dressed like a peasant. By chance, there were no guards, no dogs, no watchtowers in the photo, though I m sure they were there \u2013 just a lonely woman with a baby in her arms and her other two children holding tight to her skirt. Stoic, unwavering, supporting their tiny lives \u2013 helping them as best as any mother could \u2013 she walked them towards the gas chamber. You could almost hear the silence, smell the terror. I stared at it, both uplifted and devastated by the stark image of a family and a mother's endless love.</p> </li> <li> <p>\"If you want to be free, all you have to do is let go.\"</p> </li> <li> <p>\"Thomas Edison's last words were It's very beautiful over there . I don t know where there is, but I believe it's somewhere, and I hope it's beautiful.\"</p> </li> <li> <p>\"He was shaken by the overwhelming revelation that the headlong race between his misfortunes and his dreams was at that moment reaching the finish line. The rest was darkness, Damn it, he sighed. How will I ever get out of this labyrinth!\"</p> </li> <li> <p>\"The only way out of the labyrinth of suffering is to forgive.\"</p> </li> <li> <p>\"The descent beckons as the ascent beckoned\"</p> </li> <li> <p>\"Before me things created were none, save things Eternal, and eternal I endure. All hope abandon, ye who enter here.\"</p> </li> <li> <p>\"We accept the love we think we deserve.\"</p> </li> <li> <p>\"We are what we choose to be\" she said. \"Let others determine your worth, and you ve already lost, because no one wants people worth more than themselves.</p> </li> <li> <p>\"Charlie, I told you not to think of me that way nine months ago because of what I m saying now. Not because I didn t think you were great. It's just that I don t want to be somebody's crush. If somebody likes me, I want them to like the real me, not what they think I am. And I don t want them to carry it around inside. I want them to show me, so I can feel it, too. I want them to be able to do whatever they want around me. And if they do something I don t like, I ll tell.\"</p> </li> <li> <p>\"Strange how deeper the hole the stronger it draws a man. The fascination that lives on the keenest edge, and sparkles on the sharpest point, also gathers in depths of a fall.\"</p> </li> <li> <p>\"You can only win the game when you understand that it is a game. Let a man play chess, and tell him that every pawn is his friend. Let him think both bishops holy. Let him remember happy days in the shadows of his castles. Let him love his queen. Watch him lose them all.\"</p> </li> <li> <p>\"Memory is all we are. Moments and feelings, captured in amber, strung on filaments of reason. Take a man's memories and you take all of him. Chip away a memory at a time and you destroy him as surely as if you hammered nail after nail through his skull.\"</p> </li> <li> <p>\"As a child there's a horror in discovering the limitations of the ones you love. The time you find that your mother cannot keep you safe, that your tutor makes a mistake, that the wrong path must be taken because the grown-ups lack the strength to take the right one . . . each of those moments is the theft of your childhood, each of them a blow that kills some part of the child you were, leaving another part of the man exposed, a new creature, tougher but tempered with bitterness and disappointment.\"</p> </li> <li> <p>\"They say that time is a great teacher but unfortunately it kills all its pupils.\"</p> </li> <li> <p>\"Because I know there are people who say all these things don t happen. And there are people who forget what it's like to be sixteen when they turn seventeen. I know these will all be stories some day, and our pictures will become old photographs. We all become somebody's mom or dad. But right now, these moments are not stories. This is happening. I am here, and I am looking at her. And she is so beautiful. I can see it. This one moment when you know you re not a sad story. You are alive. And you stand up and see the lights on the buildings and everything that makes you wonder. And you re listening to that song, and that drive with the people who you love most in this world. And in this moment, I swear, we are infinite.\"</p> </li> <li> <p>\"Oh God, what is it with mankind? Never happy unless it's blowing someone up\"</p> </li> <li> <p>\"We re all dead the moment we re born. Just, some of us get there faster than others.\"</p> </li> <li> <p>\"After all, what more does a true genius want? The mind itself is the palace where all the real treasures, the works of art, the indulgences exist.\"</p> </li> <li> <p>\"Perhaps the greatest faculty our minds possess is the ability to cope with pain. Classic thinking teaches us of the four doors of the mind, which everyone moves through according to their need. First is the door of sleep. Sleep offers us a retreat from the world and all its pain. Sleep marks passing time, giving us distance from the things that have hurt us. When a person is wounded they will often fall unconscious. Similarly, someone who hears traumatic news will often swoon or faint. This is the mind's way of protecting itself from pain by stepping through the first door. Second is the door of forgetting. Some wounds are too deep to heal, or too deep to heal quickly. In addition, many memories are simply painful, and there is no healing to be done. The saying time heals all wounds is false. Time heals most wounds. The rest are hidden behind this door. Third is the door of madness. There are times when the mind is dealt such a blow it hides itself in insanity. While this may not seem beneficial, it is. There are times when reality is nothing but pain, and to escape that pain the mind must leave reality behind. Last is the door of death. The final resort. Nothing can hurt us after we are dead, or so we have been told.\"</p> </li> <li> <p>\"It is a word. Words are pale shadows of forgotten names. As names have power, words have power. Words can light fires in the minds of men. Words can wring tears from the hardest hearts. A word is nothing but a painting of fire. A name is the fire itself.\"</p> </li> <li> <p>\"Books are a poor substitute for female companionship, but they are easier to find.\"</p> </li> <li> <p>\"You can divide infinity an infinite number of times, and the resulting pieces will still be infinitely large,\" Uresh said in his odd Lenatti accent. \"But if you divide a non-infinite number an infinite number of times the resulting pieces are non-infinitely small. Since they are non-infinitely small, but there are an infinite number of them, if you add them back together, their sum is infinite. This implies any number is, in fact, infinite.\"</p> </li> <li> <p>\"The Darkest Minds tend to hide behind the most unlikely faces.\"</p> </li> <li> <p>\"And people like you are the reason we have middle fingers.\"</p> </li> <li> <p>\"Strong feelings, especially terror and desperation, leave an imprint on the air that echo back to whoever's unlucky enough to walk through that place again.\"</p> </li> <li> <p>\"Sometimes the darkness lives inside you, and sometimes it wins.\"</p> </li> <li> <p>\"Before you leave, the fortune-teller reminds you that the future is never set in stone.\"</p> </li> <li> <p>\"I slept, and dreamed that life was beauty; I woke, and found that life was duty.\"</p> </li> <li> <p>\"They ve never learned the most important rule of cyberspace \u2013 computers don t lie, but liars can compute.\"</p> </li> <li> <p>\"Most maidens are perfectly capable of rescuing themselves in my experience, at least the ones worth something, in any case.\"</p> </li> <li> <p>\"I guess that's what saying good-bye is always like\u2014like jumping off an edge. The worst part is making the choice to do it. Once you re in the air, there's nothing you can do but let go.\"</p> </li> <li> <p>\"There is nothing over which a free man ponders less than death; his wisdom is, to meditate not on death but on life\"</p> </li> <li> <p>\"To light a candle is to cast a shadow\"</p> </li> <li> <p>\"It's the silence that scares me. It's the blank page on which I can write my own fears.\"</p> </li> <li> <p>\"Memories are dangerous things. You turn them over and over, until you know every touch and corner, but still you'll find an edge to cut you. Each day the memories weigh a little heavier. Each day they drag you down that bit further. You wind them around you, a single thread at a time, and you weave your own shroud, you build a cocoon, and in it madness grows.\"</p> </li> <li> <p>\"It is easier to feel the numbness of certainty than live along the burning edge of hope.\"</p> </li> <li> <p>\"What does the future look like?\" \"I see it in colors,\" I said. \"A deep blue, fading into golds and reds\u2014like fire on a horizon. Afterlight. It's a sky that wants you to guess if the sun is about to rise or set.\"</p> </li> <li> <p>\"As bad as everything seems, I think, at its heart, life is good. It doesn't throw anything at us that it knows we can t handle\u2014and, even if it takes its time, it turns everything right side up again\"</p> </li> <li> <p>\"I ll walk forever with stories inside me that the people I love the most can never hear.\"</p> </li> <li> <p>\"You will be surprised how much more profitable an independent man is than a slave who thinks of nothing more than his next meal.\"</p> </li> <li> <p>\"Do not dash if you only have the strength to walk, and do not waste your time pushing on walls that will not give. More importantly, don t shove where a pat would be sufficient.\"</p> </li> <li> <p>\"To live is to have worries and uncertainties. Keep them inside, and they will destroy you for certain-leaving behind a person so callused that emotion can find no root in his heart.\"</p> </li> <li> <p>\"Answers were always important, but they were seldom easy.\"</p> </li> </ul> <p>The slow regard of silent things</p> <ul> <li> <p>\"Love, family, accomplishments\u2014they are all torn away, leaving nothing. What is the worth of anything we do? The worth is in the act. Your worth halts when you surrender the will to change and experience life. But options are before you; choose one and dedicate yourself to it. The deeds will give you new hope and purpose.\"</p> </li> <li> <p>\"I d imagine the whole world was one big machine. Machines never come with any extra parts, you know. They always come with the exact amount they need. So I figured, if the entire world was one big machine, I couldn t be an extra part. I had to be here for some reason. And that means you have to be here for some reason, too.\"</p> </li> <li> <p>\"But you see,\" said Roark quietly, \"I have, let's say, sixty years to live. Most of that time will be spent working. I ve chosen the work I want to do. If I find no joy in it, then I m only condemning myself to sixty years of torture. And I can find the joy only if I do my work in the best way possible to me. But the best is a matter of standards\u2014and I set my own standards. I inherit nothing. I stand at the end of no tradition. I may, perhaps, stand at the beginning of one.\"</p> </li> <li> <p>\"Man cannot survive except through his mind. He comes on earth unarmed. His brain is his only weapon. Animals obtain food by force. man had no claws, no fangs, no horns, no great strength of muscle. He must plant his food or hunt it. To plant, he needs a process of thought. To hunt, he needs weapons, and to make weapons - a process of thought. From this simplest necessity to the highest religious abstraction, from the wheel to the skyscraper, everything we are and we have comes from a single attribute of man -the function of his reasoning mind.\"</p> </li> <li> <p>\"Throughout the centuries there were men who took first steps down new roads armed with nothing but their own vision. Their goals differed, but they all had this in common: that the step was first, the road new, the vision unborrowed, and the response they received \u2014 hatred. The great creators \u2014 the thinkers, the artists, the scientists, the inventors \u2014 stood alone against the men of their time. Every great new thought was opposed. Every great new invention was denounced. The first motor was considered foolish. The airplane was considered impossible. The power loom was considered vicious. Anesthesia was considered sinful. But the men of unborrowed vision went ahead. They fought, they suffered and they paid. But they won.\"</p> </li> <li> <p>\"Thousands of years ago the first man discovered how to make fire. He was probably burnt at the stake he d taught his brothers to light, but he left them a gift they had not conceived and he lifted darkness from the face of the Earth.\" -The Fountainhead</p> </li> <li> <p>\"He was afraid of the coming night, but it was a distant feeling, like knowing you would grow old and die one day.\"</p> </li> <li> <p>\"You can t help everyone, Arlen,\" Ragen said, \"but you should make every effort to help those you can.\"</p> </li> <li> <p>\"Welcome to adulthood,\" Cob said. \"Every child finds a day when they realize that adults can be weak and wrong just like anyone else. After that day, you re an adult, like or not.\"</p> </li> <li> <p>\"No one, no one, ever goes to the Creator with all their business complete. We all get a different length of time, but it needs to be enough, regardless\"</p> </li> <li> <p>\"I don t pretend to see the path,\" Jona said calmly, \"but I know it's there all the same. One day, we ll look back and wonder how we ever missed it.\"</p> </li> <li> <p>\"Once the apple is ripe,\" he murmured to himself, no man can turn it back to a greening.\"</p> </li> <li> <p>\"Why, my luck's no greater than yours or any man s. You need only sharpen your eyes to see your luck when it comes, and sharpen your wits to use what falls into your hands.\"</p> </li> <li> <p>\"Life's a forge, say I! Face the pounding; don t fear the proving; and you'll stand well against any hammer and anvil!\" -Pyridan</p> </li> <li> <p>\"The Meaning of Life is found in the times of your life when it seems stupid to ask the question, what does it all mean?\" -Anonymous</p> </li> <li> <p>\"To live in the world without becoming aware of the meaning of the world is like wandering about in a great library\"</p> </li> <li> <p>\"Life is filled with secrets. You can t learn them all at once.\" -The Lost Symbol</p> </li> <li> <p>\"Remember that, for a broken promise cannot be mended and new promises cannot grow until the roots of betrayal have turned to dust.\"</p> </li> <li> <p>\"Simple answers to greater questions also create shadows, making it easier to hide the truth of things. Sadly there are many who desire simplicity in all things and they are easy prey for the shadows, for they are easily fooled.\"</p> </li> <li> <p>\"The world offers many lessons to us all,\" Carly mused. \"What is a mistake but another opportunity to learn another lesson.\"</p> </li> <li> <p>\"Science and religion are not at odds. Science is simply too young to understand.\"</p> </li> <li> <p>\"History is always written by the winners. When two cultures clash, the loser is obliterated, and the winner writes the history books-books which glorify their own cause and disparage the conquered foe. As Napoleon once said, What is history, but a fable agreed upon?\"</p> </li> <li> <p>\"Every faith in the world is based on fabrication. That is the definition of faith\u2015acceptance of that which we imagine to be true, that which we cannot prove. Every religion describes God through metaphor, allegory, and exaggeration, from the early Egyptians through modern Sunday school.\"</p> </li> </ul> <p>Metaphors are a way to help our minds process the unprocessible. The problems arise when we begin to believe literally in our own metaphors. Should we wave a flag and tell the Buddhists that we have proof the Buddha did not come from a lotus blossom? Or that Jesus was not born of a literal virgin birth? Those who truly understand their faiths understand the stories are metaphorical.\"</p> <ul> <li> <p>\"No good deed goes unpunished.\"</p> </li> <li> <p>\"Science tells me God must exist. My mind tells me I ll never understand God. My heart tells me I m not meant to.\"</p> </li> <li> <p>\"But who is more ignorant? The man who cannot define lightning, or the man who does not respect its awesome power?\"</p> </li> <li> <p>\"Only one form of contagion travels faster than a virus. And that's fear.\"</p> </li> <li> <p>\"Don t show it and don t panic. Do like the ducks; on the surface stay calm, and below it paddle like hell\"</p> </li> <li> <p>\"Force a hand, and it will fight you. But convince a mind to think as you want it to think, and you have an ally\"</p> </li> <li> <p>\"Live in the present, remember the past, and fear not the future, for it doesn't exist and never shall. There is only now.\" \u2015 Christopher Paolini, Eldest</p> </li> <li> <p>\"The sea is emotion incarnate. It loves, hates, and weeps. It defies all attempts to capture it with words and rejects all shackles. No matter what you say about it, there is always that which you can t.\"</p> </li> <li> <p>\"Those whom we most love are often the most alien to us.\"</p> </li> <li> <p>\"When you teach them-teach them not to fear. Fear is good in small amounts, but when it is a constant, pounding companion, it cuts away at who you are and makes it hard to do what you know is right.\"</p> </li> <li> <p>\"How terrible,\" said Eragon, \"to die alone, separate even from the one who is closest to you.\" Everyone dies alone, Eragon. Whether you are a king on a battlefield or a lowly peasant lying in bed among your family, no one can accompany you into the void.\"</p> </li> <li> <p>\"But ask yourself this Eragon: If gods exist, have they been good custodians of alagaesia? Death, sickness, poverty, tyranny and countless other miseries stalk the land. If this is the handiwork of divine beings, then they are to be rebelled against and overthrown, not given obeisance, obedience, and reverance.\"</p> </li> <li> <p>\"Always it is thus with my new students, and especially with the human ones; the mind is the last muscle they train or use, and the one that they regard the least. Ask them about swordplay and they can list every blow from a duel a month old, but ask them to solve a problem or make a coherent statement and... well, I would be lucky to get more than a blank stare in return.\"</p> </li> <li> <p>\"Anger has its place, but it will not serve you here, the way of the warrior is the way of knowing. Of that knowledge requires you to use anger, then you use anger, but you cannot wrest forth knowledge by losing your temper.\"</p> </li> <li> <p>\"Misfortune always comes to those who wait. The trick is to find happiness in the brief gaps between disasters.\"</p> </li> <li> <p>\"It is easy to be calm when there is nothing to worry about, Eragon. The true test of your self-control, however, is whether you can remain calm in a trying situation. You cannot allow anger or frustration to cloud your thoughts, not at the moment. Right now, you need your mind to be clear. Have you always been able to remain calm at times like this? The old dragon seemed to chuckle. No. I used to growl and bite and knock down trees and tear up the ground. Once, I broke the top off of a mountain in the Spine; the other dragons were rather upset with me for that. But I have had many years to learn that losing my temper rarely helps. You have not, I know, but allow my experience to guide you in this. Let go of your worries and focus on the task at hand. The future will be what is will, and fretting about it will only make your fears more likely to come true. I know, Eragon sighed, but it's not easy. Of course not. Few things of worth are. Then Glaedr withdrew and left him to the silence of his own mind.\"</p> </li> <li> <p>\"We only give credence to that which we can prove exists. Since we cannot find evidence that gods, miracles, and other supernatural things are real, we do not trouble ourselves about them. If that were to change, if Helzvog were to reveal himself to us, then we would accept the new information and revise our position.\" \"It seems a cold world without something . . . more.\" \"On the contrary,\" said Oromis, \"it is a better world. A place where we are responsible for our own actions, where we can be kind to one another because we want to and because it is the right thing to do, instead of being frightened into behaving by the threat of divine punishment. I won t tell you what to believe, Eragon. It is far better to be taught to think critically and then be allowed to make your own decisions than to have someone else's notions thrust upon you. You asked after our religion, and I have answered you true. Make of it what you will.\"</p> </li> <li> <p>\"First, let no one rule your mind or body. Take special care that your thoughts remain unfettered. One may be a free man and yet be bound tighter than a slave. Give men your ear, but not your heart. Show respect for those in power, but don t follow them blindly. Judge with logic and reason, but comment not. \"Consider none your superior, whatever their rank or station in life. Treat all fairly or they will seek revenge. Be careful with your money. Hold fast to your beliefs and others will listen.\" He continued at a slower pace, \"Of the affairs of love . . . my only advice is to be honest. That's your most powerful tool to unlock a heart or gain forgiveness. That is all I have to say.\"</p> </li> <li> <p>\"No one thinks of himself as a villain, and few make decisions they think are wrong. A person may dislike his choice, but he will stand by it because, even in the worst circumstances, he believes that it was the best option available to him at the time.\"</p> </li> <li> <p>\"It doesn't matter what other people think. The only opiniion that really matters is yours. We are all the writers of our lives. We can make our stories comedies or tragedies. Tales of horror, or of inspiration. Your attitude and your fortitude and courage are what determine your destiny, Nick.\u2026 Life is hard and it sucks for all. Every person you meet is waging his or her own war against a callous universe that is plotting against them. And we are all battle weary. But in the midst of our hell, there is always something we can hold on to, whether it's a dream of the future or a memory of the past, or a warm hand that soothes us. We just have to take a moment during the fight to remember that we re not alone, and that we re not just fighting for ourselves. We re fighting for the people we love.\"</p> </li> <li> <p>\"In the immortal words of Maya Angelou \u2026 people will forget what you said, people will forget what you did, but people will never forget how you made them feel.\"</p> </li> <li> <p>\"You can blame it all on fate and the universe, but in the end you alone decide if you re going to lie down and let hell take you under, or if you re going to stand strong in defiance of it all with your middle finger raised.\"</p> </li> <li> <p>\"Do not fear that which cannot be seen. For they are lost in between. Tis the ones who come alive That your blood will allow to thrive.\"</p> </li> <li> <p>\"If you muster that courage to stand under fire and not go down, you will amass an inner strength that no one can touch. You won t be another faceless, nameless, forgotten human in a long historical line of the defeated. You will be a steeled warrior, and a force to be forever reckoned with. And beneath the pain that lingers, you will have the comfort of knowing that you are strongest of all. That when others caved and broke, you kept fighting even against hopeless odds.\"</p> </li> <li> <p>\"Life sucked and then they billed you for it. Kind of like how airlines charged you money before you got on a plane so that in the event they screwed up and killed you, they were already paid, and they wouldn t have to give you a refund.\"</p> </li> <li> <p>\"The worst wounds, the deadliest of them, aren t the ones people see on the outside. They re the ones that make us bleed internally.\"</p> </li> <li> <p>\"Great minds discuss ideas. Average minds discuss events. Small minds discuss other people. Life's too short to worry about what other people do or don t do. Tend your own backyard, not theirs, because yours is the one you have to live in.\"</p> </li> <li> <p>\"People aren t just ants rushing around over a crust of bread. Every life, no matter how isolated, touches hundreds of others. It's up to us to decide if those micro connections are positive or negative. But whichever we decide, it does impact the ones we deal with. One word can give someone the strength they needed at that moment or it can shred them down to nothing. A single smile can turn a bad moment good. And one wrong outburst or word could be the tiny push that causes someone to slip over the edge into destruction.\"</p> </li> <li> <p>\"Life isn\u00b4t a puzzle to be solved. It\u00b4s an adventure to be savored. Let every challenge be a new mountain to climb, not an obstacle to get in your way and stop you. Yeah, it\u00b4ll be hard, but once you reach the summit of it, you\u00b4ll be able to see the world for what it really is. And at the top, it never seems to have been as difficult a feat to climb there as you first made it out to be. Most of all, you\u00b4ll know that you beat the mountain, and that you rule it. It does not rule you.\" \u2015 Sherrilyn Kenyon, Infamous</p> </li> <li> <p>\"Human will is the strongest will ever created. There are those who are born to succeed and those who are determined to succeed. The former fall into it, and the latter pursue it at all costs. They won t be denied. Nothing daunts them.\"</p> </li> <li> <p>\"It's never the enemy without who brings you down. It's always the enemy within.\"</p> </li> <li> <p>\"Guard your back, Nick. It's the one you don t see coming. The one you trust whose betrayal is most lethal. They know your weakness and they know how to hit the lowest. It's when your back is turned and your guard is down that they move in for the kill.\"</p> </li> <li> <p>\"His mom always said that trust was something you earned. And it wasn t something you gave easy. Too often, it was a tool your enemies used to hurt you with. Give them nothing, baby. Not until you have no choice. The world is harsh and it is cold. People can be good and decent, but most of them are only out for themselves and they ll hurt anyone they can .\"</p> </li> <li> <p>\"Leaving people behind and forgetting them piece by piece was just the way life worked.</p> </li> <li> <p>\"The people they were, the people we knew, they re not what's turning into dirt in that tomb behind his.\" He narrowed his eyes until the folds of his skin threatened to squeeze out his sight entirely. \"No,\" he said. \"We re here for a while, in these fleshy shells, and all the while we ask Why? What's this pain I feel? Why do I feel so cut off from the men around me, from the skies above? \"I don t think any of us ever receives the answers to those questions\"</p> </li> <li> <p>\"The human heart has hidden treasures, In secret kept, in silence sealed; The thoughts, the hopes, the dreams, the pleasures, Whose charms were broken if revealed\"</p> </li> <li> <p>\"Sometimes I wonder if we all don t have a blue-steel spring inside us, like that dena of Gorgoth's coiled tight at the core. I wonder if we don t all go stamping and crashing, crashing and stamping in our own little circles going nowhere. And I wonder who it is that laughs at us\"</p> </li> <li> <p>\"When a game cannot be won, change the game.\"</p> </li> <li> <p>\"Stand in the ashes of a trillion dead Suns and ask if honor matters. The silence is your answer.\"</p> </li> <li> <p>\"Life is this circle. You re born, you live, you die. You come full circle. There is no way around it, that's how it goes, that's how it is. We don t control being born and we don t control when we die, but we get to control the part where we live.\"</p> </li> <li> <p>\"Somewhere,\" said Elise, drumming her fingers on the table, \"there's a tiny little village that's missing its idiot.\"</p> </li> <li> <p>\"It's not the ink and paper that matter, but the hand that holds the pen.\"</p> </li> <li> <p>\"But we have two families in life. The one we re born with that shares our blood. Another we meet along the way that's willing to give its blood for us.\"</p> </li> <li> <p>\"Hate wears you down and doesn't hurt your enemy. It's like taking poison and hoping your enemy will die.\"</p> </li> <li> <p>\"Grief is a doorway through which we pass to realize that the sun is always shining.\"</p> </li> <li> <p>\"Sometimes the only reason why you don t let go of what's making you sad is because it's the only thing that made you happy.\"</p> </li> <li> <p>\"Sometimes it is the people who no one imagines anything of who do the things that no one can imagine.\"</p> </li> <li> <p>\"Do you know why people like violence? It is because it feels good. Humans find violence deeply satisfying. But remove the satisfaction, and the act becomes... hollow.\"</p> </li> <li> <p>\"When people talk to each other, they never say what they mean. They say something else and you re expected to just know what they mean.\"</p> </li> <li> <p>\"I always believed I can t be the only one in the world. The only person who was... different and here you are.\"</p> </li> <li> <p>\"The past: a new and uncertain world. A world of endless possibilities and infinite outcomes. Countless choices define our fate: each choice, each moment, a moment in the ripple of time. Enough ripples, and you change the tide... for the future is never truly set.\"</p> </li> <li> <p>\"Charles Xavier: Is this what becomes of us? Erik was right. Humanity does this to us. Professor X: Not if we show them a better path. Charles Xavier: You still believe? Professor X: Just because someone stumbles and loses their path, doesn't mean they re lost forever. Sometimes, we all need a little help. Charles Xavier: I m not the man I was. Professor X: You re afraid. I remember. Charles Xavier: All those voices... so much PAIN. Professor X: It's not their pain you re afraid of. It's yours, Charles. And as frightening as it can be, that pain will make you stronger. If you allow yourself to feel it, embrace it, .it will make you more powerful than you ever imagined. It's the greatest gift we have: to bear their pain without breaking. And it comes from the most human part of us: hope. Charles, we need you to hope again.\"</p> </li> <li> <p>\"Things change. And friends leave. Life doesn't stop for anybody.\"</p> </li> <li> <p>\"So, I guess we are who we are for alot of reasons. And maybe we ll never know most of them. But even if we don t have the power to choose where we come from, we can still choose where we go from there. We can still do things. And we can try to feel okay about them.\"</p> </li> <li> <p>\"And all the books you ve read have been read by other people. And all the songs you ve loved have been heard by other people. And that girl that's pretty to you is pretty to other people. and that if you looked at these facts when you were happy, you would feel great because you are describing unity.\"</p> </li> <li> <p>\"Standing on the fringes of life... offers a unique perspective. But there comes a time to see what it looks like from the dance floor.\"</p> </li> <li> <p>\"It's great that you can listen and be a shoulder to someone, but what about when someone doesn't need a shoulder? What if they need the arms or something like that? You can t just sit there and put everybody's lives ahead of yours and think that counts as love. You just can t. You have to do things.\"</p> </li> <li> <p>\"No matter how much of yourself you give. No matter how much you bleed. In the end, they believe whatever lie they want to believe about you. They see only the worst, in spite of the fact that you only gave them your best. And there's nothing you can do or say to change another's mind. Ever.\"</p> </li> <li> <p>\"We are defined by our enemies\u2014but also we can choose them\"</p> </li> <li> <p>\"Even from the ashes of wickedness and tragedy something of beauty can arise.\"</p> </li> <li> <p>\"If something is worth doing, it's worth doing right.\"</p> </li> <li> <p>\"I listened carefully, despite my anger and sorrow, even then my mind was working, looking ahead. \"What of the power to protect?\" I asked. She closed her eyes. \"That is an illusion. There is no power to protect, only to destroy and create anew. Protection is a result of the mind and clever use of power to manipulate the actions of those that would harm you, but it is not a result of power itself.\"</p> </li> <li> <p>\"It's like pain,\" I said continuing. \"It helps warn you, so you don t hurt yourself more. A mother's pain comes from the fear that we might be hurt, and because of that, she gets angry with us, but that anger serves the same purpose. It often keeps us from doing something stupid and hurting ourselves.\"</p> </li> <li> <p>\"The real voyage of discovery consists not in seeking new landscapes, but in having new eyes.\"</p> </li> <li> <p>\"People are funny. The longer you are around them, the more you start to realize that everyone makes the same motions over and over again. We all want to believe that every day is different, that every day we change, but really, it seems that certain things are coded into us from the very beginning.\"</p> </li> <li> <p>\"A ruler must be of all his people, for one can only rule what one knows.\"</p> </li> <li> <p>\"Most prisons are of our own making. A man makes his own freedom, too.\"</p> </li> <li> <p>\"Some say a dog or a horse as if every one of them is like every other. I ve heard a man call a mare he had owned for seven years it as if he were speaking of a chair. I ve never understood that. One does not have to be Witted to know the companionship of a beast, and to know that the friendship of an animal is every bit as rich and complicated as that of a man or woman.\"</p> </li> <li> <p>\"Do you really think things are so simple? Do you really think you can blame all your tomorrows on your yesterdays? It's your life. It will be whatever you make it.\"</p> </li> <li> <p>\"I wanted a perfect ending. Now I ve learned, the hard way, that some poems don t rhyme, and some stories don t have a clear beginning, middle, and end. Life is about not knowing, having to change, taking the moment and making the best of it, without knowing what's going to happen next. Delicious Ambiguity.\"</p> </li> <li> <p>\"To love. To be loved. To never forget your own insignificance. To never get used to the unspeakable violence and the vulgar disparity of life around you. To seek joy in the saddest places. To pursue beauty to its lair. To never simplify what is complicated or complicate what is simple. To respect strength, never power. Above all, to watch. To try and understand. To never look away. And never, never to forget.\"</p> </li> <li> <p>\"Religion has convinced people that there's an invisible man \u2026 living in the sky. Who watches everything you do every minute of every day. And the invisible man has a list of ten specific things he doesn't want you to do. And if you do any of these things, he will send you to a special place, of burning and fire and smoke and torture and anguish for you to live forever, and suffer, and suffer, and burn, and scream, until the end of time. But he loves you. He loves you. He loves you and he needs money.\"</p> </li> <li> <p>\"Dwell on the beauty of life. Watch the stars, and see yourself running with them.\"</p> </li> <li> <p>\"There is a time for everything, and a season for every activity under heaven: a time to be born and a time to die, a time to plant and a time to uproot, a time to kill and a time to heal, a time to tear down and a time to build, a time to weep and a time to laugh, a time to mourn and a time to dance, a time to scatter stones and a time to gather them, a time to embrace and a time to refrain, a time to search and a time to give up, a time to keep and a time to throw away, a time to tear and a time to mend, a time to be silent and a time to speak, a time to love and a time to hate, a time for war and a time for peace</p> </li> <li> <p>\"Oh, you hate your job? Why didn t you say so? There's a support group for that. It's called EVERYBODY, and they meet at the bar.\"</p> </li> <li> <p>\"You have wakened not out of sleep, but into a prior dream, and that dream lies within another, and so on, to infinity, which is the number of grains of sand. The path that you are to take is endless, and you will die before you have truly awakened.\"</p> </li> <li> <p>\"I think that we are like stars. Something happens to burst us open; but when we burst open and think we are dying; we re actually turning into a supernova. And then when we look at ourselves again, we see that we re suddenly more beautiful than we ever were before.\"</p> </li> <li> <p>\"That's how stories happen \u2014 with a turning point, an unexpected twist. There's only one kind of happiness, but misfortune comes in all shapes and sizes. It's like Tolstoy said. Happiness is an allegory, unhappiness a story.\"</p> </li> <li> <p>\"If you were all alone in the universe with no one to talk to, no one with which to share the beauty of the stars, to laugh with, to touch, what would be your purpose in life? It is other life; it is love, which gives your life meaning. This is harmony. We must discover the joy of each other, the joy of challenge, the joy of growth.\"</p> </li> <li> <p>\"Because I have shown my hands to be empty you must now expect not only that an illusion will follow, but that you will acquiesce in it!\"</p> </li> <li> <p>\"No one expects a good-humored man or a kind woman to be good-humored or kind every day and every moment\u2014yet they re appalled when people are trustworthy for a month or a year and then they aren t for an hour or a day.\"</p> </li> <li> <p>\"To be sociable,\" IdrisPukke continued, \"is a risky thing\u2014even fatal\u2014because it means being in contact with people, most of whom are dull, perverse and ignorant and are really with you only because they cannot bear their own company. Most people bore themselves and greet you not as a true friend but as a distraction\u2014like a dancing dog or some half-wit actor with a fund of amusing stories.\"</p> </li> <li> <p>\"No one of real intelligence will accept anything just because some authority declares it to be so. Don t accept the truth of anything you have not confirmed for yourself.\"</p> </li> <li> <p>\"You should never tell your best friend anything you wouldn\u00b4t be prepared to tell your worst enemy.\"</p> </li> <li> <p>\"Feeling sorry for yourself is a universal solvent of salvation.\"</p> </li> <li> <p>\"Only inferior minds speak or write in order to discover what they think.\"</p> </li> <li> <p>\"Don t think of it as a lie, think of it as the truth under imaginary circumstances.\"</p> </li> <li> <p>\"The mere adding of years to life is not living.\"</p> </li> <li> <p>\"Intelligence has many shades, but rage is the same colour everywhere. Humiliation tastes the same to everyone.\"</p> </li> <li> <p>\"It is better to remain silent at the risk of being thought a fool, than to talk and remove all doubt of it.\"</p> </li> <li> <p>\"When I die, I want to go peacefully like my grandfather did\u2013in his sleep. Not yelling and screaming like the passengers in his car.\"</p> </li> <li> <p>\"When I was 5 years old, my mother always told me that happiness was the key to life. When I went to school, they asked me what I wanted to be when I grew up. I wrote down \"happy.\" They told me I didn t understand the assignment, and I told them they didn t understand life.</p> </li> <li> <p>\"Worry is like a rocking chair, it will give you something to do, but it won t get you anywhere.</p> </li> <li> <p>\"I dream of a better tomorrow, where chickens can cross the road and not be questioned about their motives.\"</p> </li> <li> <p>\"The same fence that shuts others out shuts you in.\"</p> </li> <li> <p>\"You see things; and you say \"Why?\" But I dream things that never were; and I say \"Why not?\"</p> </li> <li> <p>\"To the world you may be just one person, but to one person you may be the world.\"</p> </li> <li> <p>\"The best way to predict the future is to invent it.\"</p> </li> <li> <p>\"The only thing worse than being blind is having sight but no vision.\"</p> </li> <li> <p>\"I m selfish, impatient and a little insecure. I make mistakes, I am out of control, and at times hard to handle. But if you can t handle me at my worst, you sure as hell don t deserve me at my best.\"</p> </li> <li> <p>\"Fairy tales are more than true\u2013not because they tell us dragons exist, but because they tell us dragons can be beaten.\"</p> </li> <li> <p>\"If you have built castles in the air, your work need not be lost; that is where they should be. Now put the foundations under them.\"</p> </li> <li> <p>\"In the arithmetic of love, one plus one equals everything, and two minus one equals nothing.\"</p> </li> <li> <p>\"If you steal from one author, it's plagiarism; if you steal from many, it's research.\"</p> </li> <li> <p>\"Do not hire a man who does your work for money, but him who does it for love of it.\"</p> </li> <li> <p>\"Aerodynamically, the bumblebee shouldn t be able to fly, but the bumblebee doesn't know that so it goes on flying anyway.\"</p> </li> <li> <p>\"Solitude is a good place to visit but a poor place to stay.\"</p> </li> <li> <p>\"I went to a bookstore and asked the saleswoman, \"Where's the self-help section?\" She said if she told me, it would defeat the purpose.\"</p> </li> <li> <p>\"All mothers have intuition. The great ones have radar.\"</p> </li> <li> <p>\"He who angers you conquers you.\"</p> </li> <li> <p>\"The only true wisdom is knowing that you know nothing.\"</p> </li> <li> <p>\"Those who dance are considered insane by those who cannot hear the music.\"</p> </li> <li> <p>\"I lived in books more than I lived anywhere else.\"</p> </li> <li> <p>\"Books were safer than other people anyway.\"</p> </li> <li> <p>\"Nobody looks like what they really are on the inside. You don t. I don t. People are much more complicated than that. It's true of everybody.\"</p> </li> <li> <p>\"I went away in my head, into a book. That was where I went whenever real life was too hard or too inflexible.\"</p> </li> <li> <p>\"Nothing's ever the same,\" she said. \"Be it a second later or a hundred years. It's always churning and roiling. And people change as much as oceans.\"</p> </li> <li> <p>\"How can you be happy in this world? You have a hole in your heart. You have a gateway inside you to lands beyond the world you know. They will call you, as you grow. There can never be a time when you forget them, when you are not, in your heart, questing after something you cannot have, something you cannot even properly imagine, the lack of which will spoil your sleep and your day and your life, until you close your eyes for the final time, until your loved ones give you poison and sell you to anatomy, and even then you will die with a hole inside you, and you will wail and curse at a life ill-lived.\"</p> </li> <li> <p>\"I was not happy as a child, although from time to time I was content. I lived in books more than I lived anywhere else.\"</p> </li> <li> <p>\"Adults follow paths. Children explore. Adults are content to walk the same way, hundreds of times, or thousands; perhaps it never occurs to adults to step off the paths, to creep beneath rhododendrons, to find the spaces between fences.\"</p> </li> <li> <p>\"Just go with it. It won t hurt. I stared at him. Adults only ever said that when it, whatever it happened to be, was going to hurt so much.\"</p> </li> <li> <p>\"Grown-ups don t look like grown-ups on the inside either. Outside, they re big and thoughtless and they always know what they re doing. Inside, they look just like they always have. Like they did when they were your age. Truth is, there aren t any grown-ups. Not one, in the whole wide world.\"</p> </li> <li> <p>\"The whole big, complicated world was simple and graspable and easy to unlock. I would stay here for the rest of time in the ocean which was the universe which was the soul which was all that mattered. I would stay here forever.\"</p> </li> <li> <p>\"I wondered, as I wondered so often when I was that age, who I was, and what exactly was looking at the face in the mirror. If the face I was looking at wasn\u00b4t me, because I would still be me whatever happened to my face, then what was me? If I looked inward I would see only infinite mirrors staring into myself for eternity\"</p> </li> <li> <p>\"I could not control the world I was in, could not walk away from things or people or moments that hurt, but I took joy in the things that made me happy.\"</p> </li> <li> <p>\"Different people remember things differently, and you'll not get any two people to remember anything the same, whether they were there or not.\"</p> </li> <li> <p>\"I saw the world I had walked since my birth and I understood how fragile it was, that the reality I knew was a thin layer of icing on a great dark birthday cake writhing with grubs and nightmares and hunger.\"</p> </li> <li> <p>\"Do or do not. There is no try.\"</p> </li> <li> <p>\"The problem is not the problem. The problem is your attitude about the problem.\"</p> </li> <li> <p>\"It is the unknown we fear when we look upon death and darkness. Nothing more.\"</p> </li> <li> <p>\"Life is pain, highness. Anyone who says differently is selling something.\"</p> </li> <li> <p>\"If I got rid of my demons I d lose my angels too.\"</p> </li> <li> <p>\"The mind is its own place and in itself, can make a Heaven of Hell and a Hell of Heaven.\"</p> </li> <li> <p>\"Studies suggest that risk aversion stems from fear of failure. Fear of failure or fear of losing the staus quo, fosters inaction. In other words, fear is the enemy of change and innovation.\"</p> </li> <li> <p>\"Words and the thoughts behind them may be clever, perhaps inspired, but still there can be enough of them. Then it's better to take it all in silently. We don t need to describe everything we experience, or to express all that we learn. Words are mere shadows. If we focus on them we may lose sight of the reality they try to imitate.\"</p> </li> <li> <p>\"Like the keel of a boat that's unaffected by the waves on the sea. That's how the human mind should be \u2013 calm in whatever turmoil surrounds it, confident even in a rain of urgent questions. The answers are to be found in that calm.\"</p> </li> <li> <p>\"Words mean more than what is set down on paper. It takes the human voice to infuse them with the shades of deeper meaning.\"</p> </li> <li> <p>\"There can be a universe without any gods to rule it, but not one without laws for it.\"</p> </li> <li> <p>\"I ve made mistakes in the years since I was a boy. I tried to learn from them, but it isn t always enough.\"</p> </li> <li> <p>\"Life goes on. Those who dwell on the past have no future.\"</p> </li> <li> <p>\"They say the past is etched in stone, but it isn t. It's smoke trapped in a closed room, swirling changing. Buffeted by the passing of years and wishful thinking. But even though our perception of it changes, one thing remains constant. The past can never be completely erased. It lingers. Like the scent of burning wood.\"</p> </li> <li> <p>\" Big world, not all of it flowers and sunshine. And the only way guys like you and me can survive is to grab it by the throat and never let go.\"</p> </li> <li> <p>\"You get what you deserve.\" It's an old saying. One that survived the years, because it's true. For the most part. But not for everyone. Some get more than they deserve. Because they believe they aren t like everyone else. That the rules, the ones people like me and you, the people that work and struggle to live our lives, just live, don t apply to them. That they can do anything and live happily ever after, while the rest of us suffer. They do this from the shadows. Shadows that we cast with our indifference. With a pervasive lack of interest in anything that doesn't directly affect us, we, in the here and now. Or maybe it's just the shadow of weariness. Of how tired we are, struggling to claw our way back to a middle class that no longer exist, because of those who take more than they deserve. And they keep taking, until all that's left for the rest of us is a memory of how it used to be before the corporations and the bottom line decided we didn t matter anymore. But we do. \"</p> </li> <li> <p>\"There is a wide gulf between inaction and murder, Matthew. Another man's evil does not make you good. Men have used the atrocities of their enemies to justify their own throughout history. So the question you have to ask yourself is are you struggling with the fact that you don t want to kill this man, but have to? Or that you don t have to kill him, but want to?\"</p> </li> <li> <p>\"Just because someone is important to you, it doesn't necessarily mean that, that person is good. Even if you knew that person was evil... People cannot win against their loneliness.\"</p> </li> <li> <p>\"Even the strongest of opponents always has a weakness.\"</p> </li> <li> <p>\"Rejection is a part of any man's life. If you can t accept and move past rejection, or at least use it as writing material - you re not a real man.\"</p> </li> <li> <p>\"If you don t share someone's pain. You can never understand them.\"</p> </li> <li> <p>\"Once you question your own belief, it's over.\"</p> </li> <li> <p>\"It is only through the eyes of others that our lives have any meaning.\"</p> </li> <li> <p>\"Just by living, people hurt others without even realizing it. So long as humanity exists, hate will also exist. There is no peace in this cursed world. War is just a crime paid for by the pain of the defeated...\"</p> </li> <li> <p>\"People's lives don t end when they die. It ends when they lose faith.\"</p> </li> <li> <p>\"If love is just a word, then why does it hurt so much if you realize it isn t there?\"</p> </li> <li> <p>\"Humans... Do humans have a purpose when they are born? I have been wondering recently. Because they are born, do they have an important duty? The meaning of being born... For humans to find that answer... It is the one freedom God gave them.\"</p> </li> <li> <p>\"Wake up to reality! Nothing ever goes as planned in this world. The longer you live, the more you realize that in this reality only pain, suffering and futility exist.\"</p> </li> <li> <p>\"Sometimes you must hurt in order to know, fall in order to grow, lose in order to gain because life's greatest lessons are learned through pain.\"</p> </li> <li> <p>\"A place where someone still thinks about you is a place you can call home.\"</p> </li> <li> <p>\"The hole in one's heart gets filled by others around you. Friends won t flock to someone who abandons the memory of his friends and gives up on the world just because things don t go the way he wants them to. That won t help fill the hole in your heart. And people won t help those who run away and do nothing. As long as you don t give up, there will always be salvation.\"</p> </li> <li> <p>\"When people are protecting something truly special to them, they truly can become... as strong as they can be.\"</p> </li> <li> <p>\"Regardless of our limitations, we can always be of some use. Our power may seem insignificant... but it may just prove to be useful in the grand scheme of things. Stay focused. Never avert your eyes, because if an opening arises, even our insignificant power may be enough to determine the fate of the world. Which is why everyone must stay alert and ready to strike at any moment!\"</p> </li> <li> <p>\"The things that are most important aren t written in books. You have to learn them by experiencing them yourself.\"</p> </li> <li> <p>\"In life, nothing good comes out of hurrying.\"</p> </li> <li> <p>\"Maybe, just maybe, there is no purpose in life... but if you linger a while longer in this world, you might discover something of value in it.\"</p> </li> <li> <p>\"While you re alive, you need a reason for your existence. Being unable to find one is the same as being dead.\"</p> </li> <li> <p>\"A wound of a heart is different from a flesh wound. Unlike a flesh wound, there are no ointments to heal it, and there are times when they never heal.\"</p> </li> <li> <p>\"The best way to escape reality without running is smiling even if it is obviously fake.\"</p> </li> <li> <p>\"Often people have it wrong, mistakenly believing...that showing mercy to an enemy is kindness. They spare the foe whose life is in their hands... But don t you see? It's an empty existence... to go on living... alone and unloved... when defeat's already cost you your dream!\"</p> </li> <li> <p>\"We are humans, not fish. We don t know what kind of people we truly are until the moment before our deaths. As death comes to embrace you, you will realise what you are. That's what death is, don t you think?\"</p> </li> <li> <p>\"Did you really think, just because you deny the existence of a world that you don t understand, it wouldn t exist?\"</p> </li> <li> <p>\"Director Gordon: See, that's my concern... he's not taking this seriously. Tyler Gage: Well, I m sorry... it's just that you guys talk about dancing like it's rocket science or something.\"</p> </li> <li> <p>\"Brett Dolan: When someone hands you your dreams, you take it, you don t ask questions. Nora: I would. Brett Dolan: You think you would.\"</p> </li> <li> <p>\"Andie: I remember the first time I saw someone move like they were from another planet, I couldn t keep my eyes away. I was little mom took me to a jam session in the neighborhood, it started off small but word spread and soon some of the best dancers around were showing up to compete in something they eventually called the streets. It became home, I got a front row seat to history. I wanted to glide and spin and fly like they did, but it didn t come easy. My mom would tell me don t give up, just be you, because life's too short to be anybody else. She was right. When I was 16 my mom got sick and in a couple months she was gone. Everything changed, including the streets.\"</p> </li> <li> <p>\"Moose: You know, some famous guy once said: \"To Travel is better than to arrive.\" And I was like, \"What?\" Because I used to think that there was only one path to take to where you want to be in life. But, if you choose that one path, it doesn't mean you have to abandon all the other ones.I realize it actually what happens along the way that counts; the stumbles, the falls, and the friendships. It's the journey and not the destination. You just gotta, I guess, trust that the future is gonna work itself out like it's supposed to,\"</p> </li> <li> <p>\"Moose: [from trailer] People dance because dance can change things. One move, can bring people together. One move, can make you believe like there's something more. One move, can set a whole generation free.\"</p> </li> <li> <p>\"Alicia: How big is the universe? Nash: Infinite. Alicia: How do you know? Nash: I know because all the data indicates it's infinite. Alicia: But it hasn t been proven yet. Nash: No. Alicia: You haven t seen it. Nash: No. Alicia: How do you know for sure? Nash: I don t, I just believe it. Alicia: It's the same with love I guess.\"</p> </li> <li> <p>\"Perhaps it is good to have a beautiful mind, but an even greater gift is to discover a beautiful heart.\"</p> </li> <li> <p>\"Don t expect much and you won t be disappointed.\"</p> </li> <li> <p>\"There's no way someone who can t even protect himself can protect anyone else, is there?\"</p> </li> <li> <p>\"Human relationships are chemical reactions. If you have a reaction then you can never return back to your previous state of being.\"</p> </li> <li> <p>\"Whose fault is it that things ended up like this? Coincidence? An accident? Fate? There's no such thing as fate. It's simply a combination of one circumstance and the next. And who is it that creates those circumstances? Who is it? It's you.\"</p> </li> <li> <p>\"It's not because we can t take vengeance that we should feel sorry. The real reason to feel sorry... is when one is hung up on revenge and can t live their own life.\"</p> </li> <li> <p>\"You believe that the strong exist to cull the weak. To use them as food. But you are mistaken . . . The strong exist, not to feed off of the weak, but to protect them!\"</p> </li> <li> <p>\"Perhaps the distant part of the sky always seems clearest, so that we will always strive to reach it.\"</p> </li> <li> <p>\"Who falls for who depends completely on the person. If there are a hundred people, there are a hundred ways to love... There never is one absolute form of love.\"</p> </li> <li> <p>\"You can die anytime, but living takes true courage.\"</p> </li> <li> <p>\"You ll only realize that you truly love someone if they already caused you enormous pain. Your enemies can never hurt you the way your loved ones can. It's the people close to your heart that can give you the most piercing wound. Love is a double-edged sword, it can heal the wound faster or it can sink the blade even deeper.\"</p> </li> <li> <p>\"The dead don t desire revenge, but the happiness of the living.\"</p> </li> <li> <p>\"Fate is never thwarted. What has happened has happened because Fate willed it thus\u2014if, indeed, there is such a thing as Fate and if men's actions are not merely a response to other men's actions.\"</p> </li> <li> <p>\"So if I asked you about art, you d probably give me the skinny on every art book ever written. Michelangelo, you know a lot about him. Life's work, political aspirations, him and the pope, sexual orientations, the whole works, right? But I ll bet you can t tell me what it smells like in the Sistine Chapel. You ve never actually stood there and looked up at that beautiful ceiling; seen that. If I ask you about women, you d probably give me a syllabus about your personal favorites. You may have even been laid a few times. But you can t tell me what it feels like to wake up next to a woman and feel truly happy. You re a tough kid. And I d ask you about war, you d probably throw Shakespeare at me, right, \"once more unto the breach dear friends.\" But you ve never been near one. You ve never held your best friend's head in your lap, watch him gasp his last breath looking to you for help. I d ask you about love, you d probably quote me a sonnet. But you ve never looked at a woman and been totally vulnerable. Known someone that could level you with her eyes, feeling like God put an angel on earth just for you. Who could rescue you from the depths of hell. And you wouldn t know what it's like to be her angel, to have that love for her, be there forever, through anything, through cancer. And you wouldn t know about sleeping sitting up in the hospital room for two months, holding her hand, because the doctors could see in your eyes, that the terms</p> </li> <li> <p>\"visiting hours\" don t apply to you. You don t know about real loss, cause it only occurs when you ve loved something more than you love yourself. And I doubt you ve ever dared to love anybody that much.\"</p> </li> <li> <p>\"If you only focus on a leaf, you will miss the entire tree; if you focus only on a leaf, you might miss the entire forest. Thus, you must focus on things in their entirety.\"</p> </li> <li> <p>\"When did we see each other face-to-face? Not until you saw into my cracks and I saw into yours. Before that, we were just looking at ideas of each other, like looking at your window shade but never seeing inside. But once the vessel cracks, the light can get in. The light can get out.\"</p> </li> <li> <p>\"You could never really know what you were seeing with just a glance, in motion, passing by. Good or bad, right or wrong. There was always so much more.\"</p> </li> <li> <p>\"Because that is what happens when you try to run from the past. It doesn't just catch up: it overtakes, blotting out the future, the landscape, the very sky, until there is no path left except that which leads through it, the only one that can ever get you home.\"</p> </li> <li> <p>\"When you ripped a piece of paper into two: no matter how you tried, the seams never fit exactly right again. It was what you couldn t see, those tiniest of pieces, that were lost in the severing, and their absence kept everything from being complete\"</p> </li> <li> <p>\"I thought of everything being washed away, again and again. We make such messes in this life, both accidentally and on purpose. But wiping the surface clean doesn't really make anything any neater. It just masks what is below. It's only when you really dig down deep, go underground, that you can see who you really are.\"</p> </li> <li> <p>\"The monks used to say that hope is just a distraction.\"</p> </li> <li> <p>\"Harsh words won t solve problems, action will.\"</p> </li> <li> <p>\"Destiny? What would a boy know of destiny? If a fish lives its whole life in this river, does he know the river's destiny? No! Only that it runs on and on out of his control. He may follow where it flows, but he cannot see the end. He cannot imagine the ocean.\"</p> </li> <li> <p>\"You think you re any different from me, or your friends, or this tree? If you listen hard enough, you can hear every living thing breathing together. You can feel everything growing. We re all living together, even if most folks don t act like it. We all have the same roots, and we are all branches of the same tree.\"</p> </li> <li> <p>\"Time is an illusion, and so is death.\"</p> </li> <li> <p>\"You must never give into despair. Allow yourself to slip down that road, and you surrender to your lowest instincts. In the darkest times, hope is something you give yourself. That is the meaning of inner strength.\"</p> </li> <li> <p>\"It is important to draw wisdom from different places. If you take it from only one place it becomes rigid and stale.\"</p> </li> <li> <p>\"No matter how things seem to change. Never forget who you are.\"</p> </li> <li> <p>\"But love is a form of energy, and it swirls all around us.\"</p> </li> <li> <p>\"The greatest illusion of this world is the illusion of separation. Things you think are separate and different are actually one and the same. We are all one people, but we live as if divided.\"</p> </li> <li> <p>\"Protection and power are overrated. I think you are very wise to choose happiness and love.\"</p> </li> <li> <p>\"There are reasons each of us are born. we have to find those reasons.\"</p> </li> <li> <p>\"Sometimes life is like this dark tunnel, you can t always see the light at the end of the tunnel, but if you just keep moving, you will come to a better place.\"</p> </li> <li> <p>\"It's impossible to go through life unscathed. Nor should you want to. By the hurts we accumulate, we measure both our follies and our accomplishments.\"</p> </li> <li> <p>\"Nothing ever happens the way you imagine it will. But then again, if you don t imagine, nothing ever happens at all.\"</p> </li> <li> <p>\"You don t get to choose if you get hurt in this world but you do have some say in who hurts you.\"</p> </li> <li> <p>\"What a treacherous thing it is to believe that a person is more than a person.\"</p> </li> <li> <p>\"Grief can be a burden, but also an anchor. You get used to the weight, to how it holds you to a place.\"</p> </li> <li> <p>\"Music should flow like a language. Changing a single note can turn joy to sorrow.\"</p> </li> <li> <p>\"You will look at what I have done and say, Of course - why not - they are all animals. They have slaughtered each other for centuries. But the truth is, I m not a monster. I m a human man - I m just like you, whether you like it or not. For years, we have tried to live together, until a war was waged on us, on all of us: a war waged by our own leaders. And who supplied the Serb cluster bombs, the Croatian tanks, the Muslim artillery shells that killed our sons and daughters? It was the governments of the West who drew the boundaries of our countries - sometimes in ink, sometimes in blood - the blood of our people. And now you dispatch your peacekeepers to write our destiny again. We can never accept this peace that leaves us with nothing but pain, pain the peacemakers must be made to feel. Their wives, their children, their houses and churches. So now you know, now you must understand. Leave us to find our own destiny. May God have mercy on us all.\"</p> </li> <li> <p>\"It was being under that Lace loved most. The lightness of her own body, the water trying to lift her toward the surface. The silhouettes of the underwater trees, like a forest on a fall night. How everything looked blurred like she was seeing it through stained glass. How water that had felt cold when she slid into the river now felt as warm as her own body. Even the sharp sting in her lungs as she swam out of view to take a breath.\"</p> </li> <li> <p>\"Regret is a powerful poison. The more you harbor those thoughts, the harder it is to move on.\"</p> </li> <li> <p>\"If you begin to regret, you'll dull your future decisions and let others make your choices for you. All that's left for you then is to die. Nobody can foretell the outcome. Each decision you make holds meaning only by affecting your next decision.\"</p> </li> <li> <p>\"I haven t lived all that long yet, but there is something I firmly believe in. The people who have the ability to change something in this world, all without exception, have the guts to abandon things important to them if they have to. They are those who can abandon even their humanity.\"</p> </li> <li> <p>\"People who can t throw something important away, can never hope to change anything.\"</p> </li> <li> <p>\"This world is merciless, and it's also very beautiful.\"</p> </li> <li> <p>\"It's because I fail \u2026 I have the strength to keep fighting \u2026 and that type of strength is real strength \u2026\"</p> </li> <li> <p>\"There are many types of monsters that scare me: Monsters who cause troubles without showing themselves, monsters who abduct children, monsters who devour dreams, monsters who suck blood\u2026 and then, monsters who tell nothing but lies. Lying monsters are a real nuisance: They are much more cunning than others: They pose as humans even though they have no understanding of the human heart; they eat even though they ve never experienced hunger; they study even though they have no interest in academics; they seek friendship even though they do not know how to love. If I were to encounter such monsters, I would likely be eaten by them\u2026 because in truth, I am that monster.\"</p> </li> <li> <p>\"Life is made of so many moments that mean nothing. Then one day, a single moment comes along to define every second that comes after. Such moments are tests of courage, of strength.\"</p> </li> <li> <p>\"There are two kinds of guilt. The kind that's a burden and the kind that gives you purpose. Let your guilt be your fuel. Let it remind you of who you want to be. Draw a line in your mind. Never cross it again. You have a soul. It's damaged but it's there. Don t let them take it from you.\"</p> </li> <li> <p>\"Fear can be good, Laia. It can keep you alive. But don t let it control you. Don t let it sow doubts within you. When the fear takes over, use the only thing more powerful, more indestructible to fight it: your spirit. Your heart.\"</p> </li> <li> <p>\"Giving into the pain and thinking you want to die just means you ve been spoiled by life. If you don t want to die, then don t act spoiled. Suffer through life; crawl through life. Stick it out till the very end. If you still want to die after that, come find me. I ll end you.\"</p> </li> <li> <p>\"It doesn't matter whether it's wrong or not, the thing is... What's important is memory...The memory that you can t forget for the rest of your life\u2026\"</p> </li> <li> <p>\"If you let yourself get depressed, you will be making light of the people who follow and trust you.\"</p> </li> <li> <p>\"Happiness is like glass. It may be all around you\u2026 Yet be invisible. But if you can change your angle of viewing a little, then it will reflect light more beautifully than any other object around you.\"</p> </li> <li> <p>\"I ll leave tomorrow's problems to tomorrow's me.\"</p> </li> <li> <p>\"Let's say I posed this question to you: \"Can all human souls be bought with money or not?\" Now remember, the keyword here is \"all\". The answer is \"There are times when you can buy them, and other times, not,\" right? The human being\u2026 sometimes he ll uphold his pride and conscience even if he's offered ten billion yen, and other times he ll murder someone over one yen.\"</p> </li> <li> <p>\"People with talent often have the wrong impression that things will go as they think.\"</p> </li> <li> <p>\"Hard work betrays none, but dreams betray many.\"</p> </li> <li> <p>\"Life is basically like a soap bubble. It rides on the wind, flying here and there, \u2026And before you realize it, pop! It's gone. When it's about to disappear, you think that you could ve flown a bit higher.But by the time, it's already too late.\"</p> </li> <li> <p>\"People are like dice, a certain Frenchman said that. You throw yourself in the direction of your own choosing. People are free because they can do that. Everyone's circumstances are different, but no matter how small the choice, at the very least, you can throw yourself. It's not chance or fate. It's the choice you made.\"</p> </li> <li> <p>\"Only hope can give rise to the emotion we call despair. But it is nearly impossible for a man to try to live without hope, so I guess that leaves Man no choice but to walk around with despair as his companion.\"</p> </li> <li> <p>\"Man fears the darkness, and so he scrapes away at the edges of it with fire.\"</p> </li> <li> <p>\"We are all like fireworks. We climb, shine, and always go our separate ways and become further apart. But even if that time comes, let's not disappear like a firework, and continue to shine forever.\"</p> </li> <li> <p>\"Being alone and being lonely are two different things.\"</p> </li> <li> <p>\"Do not allow yourself to be blinded by fear and anger. Everything is only as it is.\"</p> </li> <li> <p>\"Well, if you live long enough, you lose a lot. Just as long as you don t throw them away. Whatever you lose, you'll find again, but what you throw away you never get back.\"</p> </li> <li> <p>\"Thanks to these eyes...I came to understand how cruel and despicable people can be. But that also allowed me to appreciate true beauty. All you have to do is appreciate things from a different perspective Once I realized the things we take for granted are really miracles, I came to see everything in it's precious, empheral beauty. ..... I love this world.\"</p> </li> <li> <p>\"It's never something huge that changes everything, but instead the tiniest of details, irrevocably tweaking the balance of the universe while you re busy focusing on the big picture.\"</p> </li> <li> <p>\"Imma do what I want, whatever. Imma rage til the dawn, all nighter. Don t hold your breath. You know I ll sleep when I am dead.\"</p> </li> <li> <p>\"We are giants. We are bigger than a monster. Every second we are taking back the power on the run till we get a fucking answer. Try to hold us down but we re only getting stronger.\"</p> </li> <li> <p>\"They say pain is an illusion, this is just a bruise. And you are just confused. But I am only human. I could use a hand sometimes. I am only human.\"</p> </li> <li> <p>\"In this world, perfection is an illusion. Regardless of all those who utter the contrary, this is the reality. Obviously mediocre fools will forever lust for perfection and seek it out. However, what meaning is there in perfection? None. Not a bit. ...After perfection there exists nothing higher. Not even room for creation which means there is no room for wisdom or talent either.  Understand? To scientists like ourselves, perfection is despair.\"</p> </li> <li> <p>\"A different species a different set of values a world completely unlike your own. There is a feeling you can only get when you meet the unknown and open your mind.\"</p> </li> <li> <p>\"If you want to know someone, start by finding out what makes him angry.\"</p> </li> <li> <p>\"Time is going really faster than you think. That second just passed now, get up, pack the bag, get lost\u2026\"</p> </li> <li> <p>\"Life is something that no one can teach you,You have to learn it.\"</p> </li> <li> <p>\"People seem weak, but they re strong. They seem strong, but they re weak. No matter how much you cry, you still have to sleep. And you even get hungry. You suddenly realize you re doing the same things you did yesterday. You say hi to your friends and smile just like you did yesterday. Life goes on as if nothing ever happened\u2026 I want to go somewhere\u2026 Anywhere\u2026 Somewhere where I can forget everything. \u2026where I ll forget everything \u2026and be reborn.\"</p> </li> <li> <p>\"Being sorry is far worse punishment than being dead, everybody dies... very few people ever feel truly sorry for the bad things they ve done.\"</p> </li> <li> <p>\"Because happiness is so hard to find. Once you find it, you better hang on tight. Or you lose it.\"</p> </li> <li> <p>\"I want you to give her a possibility,\" she told him, looking at my necklace again. \"And that's what a key represents. An open door, a chance.\"</p> </li> <li> <p>\"There was something striking about a single key. It was like a question waiting to be answered, a whole missing a half. Useless on its own, needing something else to be truly defined.\"</p> </li> <li> <p>\"My point is, there are a lot of people in the world. No one ever sees everything the same way you do; it just doesn't happen. So when you find one person who gets a couple of things, especially if they re important ones . . . you might as well hold on to them.\"</p> </li> <li> <p>\"Hey angel... Do you know the reasons why? We look up to the sky? Hey angel... Do you look at us and laugh When we hold on to the past?\"</p> </li> <li> <p>\"Who's gonna be the first one to compromise Who's gonna be the first one to set it all on fire Who's gonna be the last one to drive away Forgetting every single promise we ever made.\"</p> </li> <li> <p>\"Youth is like diamonds in the sun, And diamonds are forever.\"</p> </li> <li> <p>\"Anybody's got the power They don t see it cause they don t understand Spin around and round for hours You and me, we got the world in our hands.\"</p> </li> <li> <p>\"I didn t need you, you idiot. I picked you. And then you picked me back.\"</p> </li> <li> <p>\"But isn t it also that on some fundamental level we find it difficult to understand that other people are human beings in the same way that we are? We idealize them as gods or dismiss them as animals.\"</p> </li> <li> <p>\"You listen to people so that you can imagine them, and you hear all the terrible and wonderful things people do to themselves and to one another, but in the end the listening exposes you even more than it exposes the people you re trying to listen to.\"</p> </li> <li> <p>\"It is easy to forget how full the world is of people, full to bursting, and each of them imaginable and consistently misimagined.\"</p> </li> <li> <p>\"Home wasn t a set house, or a single town on a map. It was wherever the people who loved you were, whenever you were together. Not a place but a moment, and then another, building on each other like bricks to create a solid shelter that you take with you for your entire life, wherever you may go.\"</p> </li> <li> <p>\"Silence is so freaking loud.\"</p> </li> <li> <p>\"The only person you can be sure to control, always, is yourself. Which is a lot to be sure of, but at the same time, not enough.\"</p> </li> <li> <p>\"What is family? They were the people who claimed you. In good, in bad, in parts or in whole, they were the ones who showed up, who stayed in there, regardless. It wasn t just about blood relations or shared chromosomes, but something wider, bigger. Cora was right\u2014we had many families over time. Our family of origin, the family we created, as well as the groups you moved through while all of this was happening: friends, lovers, sometimes even strangers. None of them were perfect, and we couldn t expect them to be. You couldn t make any one person your world. The trick was to take what each could give you and build a world from it.\"</p> </li> <li> <p>\"Needing was so easy: it came naturally, like breathing. Being needed by someone else, though, that was the hard part. But as with giving help and accepting it, we had to do both to be made complete\u2014like links overlapping to form a chain, or a lock finding the right key.\"</p> </li> <li> <p>\"It's a lot easier to be lost than found. It's the reason we re always searching, and rarely discovered.\"</p> </li> <li> <p>\"Isn t every relationship based off selfishness?\"</p> </li> <li> <p>\"Shoulda, coulda, woulda. It's so easy in the past tense.\"</p> </li> <li> <p>\"I was beginning to see, though, that the unknown wasn t always the greatest thing to fear. The people who know you best can be riskier, because the words they say and things they think have the potential to be not only scary but true, as well.\"</p> </li> <li> <p>\"In the depth of winter, I finally learned that within me there lay an invincible summer.\"</p> </li> <li> <p>\"My life will not follow a fairy tale, and that's okay. My life is reality. And in my reality people don t fall in love and get married and live happily ever after, because life is complicated. And messy. \"</p> </li> <li> <p>\"Sometimes he wondered if man's instincts had changed in that time and always concluded that they hadn t. At least in the basic, most primal ways. As far as he could tell, man had always been aggressive, always striving to dominate, trying to control the world and everything in it.\" \"Poetry, she thought, wasn t written to be analysed: it was meant to inspire without reason, to touch without understanding.\"</p> </li> <li> <p>\"You are the answer to every prayer I ve offered. You are a song, a dream, a whisper, and I don t know how I could have lived without you for as long as I have.\"</p> </li> <li> <p>\"We wrap up our violent and mysterious world in a pretence of understanding. We paper over the voids in our comprehension with science or religion, and make believe that order has been imposed. And, for the most of it, the fiction works. We skim across surfaces, heedless of the depths below. Dragonflies flitting over a lake, miles deep, pursuing erratic paths to pointless ends. Until that moment when something from the cold unknown reaches up to take us. The biggest lies we save for ourselves. We play a game in which we are gods, in which we make choices, and the current follows in our wake. We pretend a separation from the wild. Pretend that a man's control runs deep, that civilization is more than a veneer, that reason will be our companion in dark places.\"</p> </li> <li> <p>\"The bladder-pipe, a local Highlands speciality, is to music what warthogs are to mathematics. Largely unconnected.\"</p> </li> <li> <p>\"God is not some omnipotent authority looking down from above, threatening to throw us into a pit of fire if we disobey. God is the energy that flows through the synapses of our nervous system and the chambers of our hearts! God is in all things!\"</p> </li> <li> <p>\"Your afterlife is what you expect it to be, what the thousands, the millions around you expect, what legend builds, told, retold, refined, evolving. In this place, amongst the sands, they fashion themselves a different paradise and different paths to it, some dark, some light. All of it is fabrication, constructed over the reality my people lived in. Whatever waited for a man after his death in those times, it was not mentioned in our calculations. Our priests, when they could find anyone to listen, described something more subtle, more profound, and more wonderful.\" \"Ignorance is indeed bliss.\"</p> </li> <li> <p>\"No one is ever kind or generous without expecting something in return. I know you will use me eventually like everyone else.\"</p> </li> <li> <p>\"So don t be too sad. Being incomplete means that you have the potential to grow into an infinite number of things.\"</p> </li> <li> <p>\"Everyone gets a wound that never heals and no one should bother. No matter how sound and secure that person seems\u2026 There's no way of telling what will happen if you cross the line.\"</p> </li> <li> <p>\"When people fall into despair even getting through their daily lives can be like torture. And since it involves a whole mix of confusing emotions, each person's reaction to different situations can be diverse.\"</p> </li> <li> <p>\"A precious thing is like something that's a part of you. Like your heart. Finding a precious thing or a person is a very happy thing. But it can also be scary. Everyone has got atleast one precious thing. And there may be a difference between having something precious and being precious to someone but they are not separate things.\"</p> </li> <li> <p>\"Is the horizon far away? Not at all! Man is at the horizon, how can the horizon be far away? What colour is the bright moon? It is blue; and like the ocean, blue, deep and sorrowful. Where is the bright moon? It is in his heart; his heart is the bright moon. What about his sabre? His sabre is in his hand! What kind of blade is that? His sabre is as broad and as lonely as the horizon, as pure and sorrowful as the bright moon; even with a flash of steel, some times it is as if it is empty. Empty? Empty and illusional, as if it never exists, yet present everywhere. But the speed of his sabre does not appear to be very swift. How can a sabre that is not swift be invincible under the heavens? This is because his sabre has gone beyond the limits of speed! Where is he? He has not returned, but his heart is already broken. Where is the path of his return? The path is right in front of him. Cannot he see the path? He is not looking for it. So he cannot find the path? Perhaps not now, but he will find it sooner or later. Willl he find it for sure? Definitely!\"</p> </li> <li> <p>\"It matters not how strait the gate, How charged with punishments the scroll.I am the master of my fate. I am the captain of my soul.\"</p> </li> <li> <p>\"Love was selfish, wasn t it? It made honest men want things they had no right to. It cocooned one from the rest of the world, erased time itself, knocked away reason. It made you live in defiance of the inevitable. It made you want another's mind, body; it made you feel as if you deserved to own their heart, and carve out a place in it.\"</p> </li> <li> <p>\"I didn t smile because I made friends. I made friends because I smiled at them.\"</p> </li> <li> <p>\"Each moment is fragile and fleeting. The moment of the past cannot be kept, however beautiful. The moment of the present cannot be held, however enjoyable. The moment of the future cannot be caught, however desirable. But the mind is desperate to fix the river in place: Possessed by ideas of the past, preoccupied with images of the future, it overlooks the plain truth of the moment.\"</p> </li> <li> <p>\"Life is a series of natural and spontaneous changes. Don t resist them; that only creates sorrow. Let reality be reality. Let things flow naturally forward in whatever way they like.\"</p> </li> <li> <p>\"A man with outward courage dares to die; a man with inner courage dares to live.\"</p> </li> <li> <p>\"If you are depressed you are living in the past. If you are anxious you are living in the future. If you are at peace you are living in the present.\"</p> </li> <li> <p>\"Men are born soft and supple; dead they are stiff and hard. Plants are born tender and pliant; dead, they are brittle and dry. Thus whoever is stiff and inflexible is a disciple of death. Whoever is soft and yielding is a disciple of life. The hard and stiff will be broken. The soft and supple will prevail.\"</p> </li> <li> <p>\"Do you imagine the universe is agitated? Go into the desert at night and look at the stars. This practice should answer the question.\"</p> </li> <li> <p>\"Do you have the patience to wait Till your mud settles and the water is clear? Can you remain unmoving Till the right action arises by itself?\" \"He who stands on tiptoe doesn't stand firm. He who rushes ahead doesn't go far. He who tries to shine dims his own light. He who defines himself can t know who he really is. He who has power over others can t empower himself. He who clings to his work will create nothing that endures.\"</p> </li> <li> <p>\"If you want to accord with the Tao, just do your job, then let go.\"</p> </li> <li> <p>\"Empty your mind of all thoughts. Let your heart be at peace. Watch the turmoil of beings, but contemplate their return. Each separate being in the universe returns to the common source. Returning to the source is serenity. If you don t realize the source, you stumble in confusion and sorrow. When you realize where you come from, you naturally become tolerant, disinterested, amused, kindhearted as a grandmother, dignified as a king. Immersed in the wonder of the Tao, you can deal with whatever life brings you, and when death comes, you are ready.\"</p> </li> <li> <p>\"He who knows, does not speak. He who speaks, does not know.\"</p> </li> <li> <p>\"There is no illusion greater than fear.\"</p> </li> <li> <p>\"No matter how bad a state of mind you get into, if you hold out over the long run, the clouds will disappear and the autumn winds will cease. That is a fact.\"</p> </li> <li> <p>\"Life isn t just doing things for yourself. It's possible to live in such a way that other people's happiness, makes you happy too.\"</p> </li> <li> <p>\"Everyone smiles, when they are with you. Please... from now on, go and help people in my place. Share your happiness with them.\"</p> </li> <li> <p>\"Everybody can fight. It's just a choice of whether you should.\"</p> </li> <li> <p>\"Death comes suddenly and life is fragile and brief. No one can alter this, either by prayers or spells. Children cry about it, but men and women do not cry. They have to endure.\"</p> </li> <li> <p>\"The wind stirred the ancient cedars; the night insects kept up their insistent music. It would always be like this, I thought, summer after summer, winter after winter, the moon sinking towards the west, giving the night back to the stars, and they, in an hour or two, surrendering it to the brightness of the sun. The sun would pass above the mountains, pulling the shadows of the cedars after it, until it descended again below the rim of the hills. So the world went, and humankind lived on it as best they could, between the darkness and the light.\"</p> </li> <li> <p>\"I kept thinking that I couldn t live my life for other people, that love was nothing but chains. And maybe it was, but so help me, I needed these chains. These things didn t make me weaker; they held my soul to the earth. I wasn t going to run from them anymore.\"</p> </li> <li> <p>\"Mistakes mean it's real.\"</p> </li> <li> <p>\"There are some things you don t learn about yourself until you let someone else into the most intimate places of your heart.\"</p> </li> <li> <p>\"If you plot your life along the real line, it will encompass a finite space. We begin, move steadily in a positive direction, and end. The bodies we re given aren t meant to last forever.\"</p> </li> <li> <p>\"A person's natural talent does not decide their achievements in life. Anyone can become formidable, but the crucial point is whether or not you work hard, and how intelligent your mind is.\"</p> </li> <li> <p>\"There are some things in life that cannot be explained with logic. They cannot be understood through dissection. They are what they are\u2014good, bad, or epically crappy. Sometimes they are all those things at once\"</p> </li> <li> <p>\"The moon was like water. As the moonlight shined, it would sprinkle a layer of veil over the night.\"</p> </li> <li> <p>\"This world will never pity you if you re being cowardly, you have to fight for everything yourself. If you don t fight for it, even if it belongs to you, it will be snatched away.\"</p> </li> <li> <p>\"Time doesn't slow during a fight. What you perceive as a slowdown is actually your poor noggin overloading with data. It's working extra hard to create a detailed record of events\u2014the mental equivalent of running a highlighter through a book\u2014and you re misinterpreting the added detail for added time.\"</p> </li> <li> <p>\"Are you saying that the here-and-now is derived from one of many possible pasts, that the present is only possible because certain criteria were met, and so the future, our particular future, will form based on the same principles? In other words, our future will be one possible future out of many many thousands\"</p> </li> <li> <p>\"We(vampires) take what we need, and you call us monsters. You starve your own kind, and you call yourselves shareholders.\"</p> </li> <li> <p>\"Starlight is amazing. Most of the stars that shed those rays are already dead. They sent those lonely shimmers off eons ago, bright messages that streamed out tirelessly into the night. The lonely travelers had swept past any number of fantastic sights. Planets birthing. Planets dying. Novas. Pulsars. Black holes and white dwarfs. Meteors and comets. Neutron stars spinning. Dark matter lurking. Crazy names for crazier things. I think that's why starlight is amazing. Those tiny flecks of light travelled through hell and high water to reach us.\" \"When a man tries to harm someone else you have the responsibility to do everything you can to stop them, even if that means dispensing justice yourself. I know it's hard to think that way. You have to move past it, it's the only way.\"</p> </li> <li> <p>\"He who is certain he knows the ending of things when he is only beginning them is either extremely wise or extremely foolish; no matter which is true, he is certainly an unhappy man, for he has put a knife in the heart of wonder. \"</p> </li> <li> <p>\"Weep no more! All men must die\u2014you, I, everyone. If we are not killed by youthful stupidity or ill-luck, then it is our fate to live on like the trees: older and older until at last we totter and fall. It is the way of all things. How can you fight the Lord's will?\"</p> </li> <li> <p>\"While man plays out his show, the Manipulator remains unseen; we know Him not by sight, but by the ways His puppets move. And occasionally the curtain stirs, that hides Him from His faithful audience. Ah, but we are grateful even for just that movement behind the curtain\u2014grateful!\"</p> </li> <li> <p>\"A man whose wisdom is true does not sit in waiting for the world to come at him piece by piece for proving its existence!\"</p> </li> <li> <p>\"The icy mountain face itself was a thing of painful beauty. Simon had never dreamed that ice might have color; the tame variety he knew, that which festooned the roofs of the Hayholt at Aedontide and shrouded the wells in Jonever, was diamond-clear or milky white. By contrast, the icy armor of Urmsheim, warped, twisted, and buckled by wind and the seemingly distant sun, was a dream-forest of colors and strange shapes. Great ice-towers shot through with veins of sea-green and violet leaned out above the heads of the toiling party. \"</p> </li> <li> <p>\"Never make your home in a place,\" the old man had said, too lazy in the spring warmth to do more than a wag a finger. \"Make a home for yourself inside your own head. You ll find what you need to furnish it\u2014memory, friends you can trust, love of learning, and other such things.\" Morgenes had grinned. \"That way it will go with you wherever you journey. You ll never lack for a home\u2014unless you lose your head, of course ...\"</p> </li> <li> <p>\"When you stopped to think about it, he reflected, there weren t many things in life one truly needed. To want too much was worse than greed: it was stupidity\u2014a waste of precious time and effort.\"</p> </li> <li> <p>\"But no one ever explained how terrible it is to be in the middle of a tale and not to know the ending....\"</p> </li> <li> <p>\"He was not great; he was, in fact, very small. At the same moment, though, he was important, just as any point of light in a dark sky might be the star that led a mariner to safety, or the star watched by a lonely child during a sleepless night....\"</p> </li> <li> <p>\"Also,\" Binabik said gravely, \"it may or may not be foolishness to pray to the gods, but there is certainly being no wisdom in cursing them.\"</p> </li> <li> <p>\"We are very small,\" Simon said between swallows. The kangkang seemed to be flowing in his veins like blood. \"So are the stars, kund\u00eb -mann\u00eb,\" Sludig murmured. \"But they each one burn as bright as they can.\"</p> </li> <li> <p>\"It was nice that someone cared about him, he supposed, even if he did not entirely agree with the form that caring took.\"</p> </li> <li> <p>\"It is only worrying about things we cannot be changing; that is foolishness.\" He mustered a smile. \" When your teeth are gone, we Qanuc say, learn to like mush. \"</p> </li> <li> <p>\"Some things, once destroyed, will always be destroyed. No matter how much it's repaired, there will always be an obvious crack.\"</p> </li> <li> <p>\"In this world, there is no such thing as a free lunch\"</p> </li> <li> <p>\"You ought to know that women will forever be the creatures that hold the longest grudges. Otherwise, why would there be the saying that a woman's heart is a most vicious thing ?\"</p> </li> <li> <p>\"You are now just a little rascal, but you are still far off from the true mastery of being a rogue. The highest state of a rogue is that even when you are being a rogue, others will think of you as a gentleman. When you are facing another rogue, you must be more roguish than him, but when facing a gentleman, you can be more suave and gentlemanly. Only then can you reach the ultimate stage and be a true Rogue, a genuine scoundrel.\"</p> </li> <li> <p>\"When a woman hates a man, no matter what he does for her, how much effort or how many things he does, that hatred will not diminish a whit. However, the reverse is also true, when a woman has acknowledged a man, even if he does not do anything, she will still think the better of him.\"</p> </li> <li> <p>\"Is any of it real? I mean, look at this. Look at it! A world built on fantasy. Synthetic emotions in the form of pills. Psychological warfare in the form of advertising. Mind-altering chemicals in the form of... food! Brainwashing seminars in the form of media. Controlled isolated bubbles in the form of social networks. Real? You want to talk about reality? We haven t lived in anything remotely close to it since the turn of the century. We turned it off, took out the batteries, snacked on a bag of GMOs while we tossed the remnants in the ever-expanding Dumpster of the human condition. We live in branded houses trademarked by corporations built on bipolar numbers jumping up and down on digital displays, hypnotizing us into the biggest slumber mankind has ever seen. You have to dig pretty deep, kiddo, before you can find anything real. We live in a kingdom of bullshit. A kingdom you ve lived in for far too long. So don t tell me about not being real. I m no less real than the fucking beef patty in your Big Mac.\"</p> </li> <li> <p>\"Merit, anyone living in the world should have merit. At least, they must be of some merit in the eyes of their parents, otherwise their life will be a waste.\"</p> </li> <li> <p>\"What are the most fearsome enemies? They are not the crazed, bloodthirsty people, but the cool-headed people with nothing to lose whose only goal is to seek revenge. This is the most fearsome kind of enemy.\"</p> </li> <li> <p>\"There was a moment, a point in your recent past, a mistake, a compulsion, a decision, something that led you to this point right now. My only advice to you is to find that moment, understand it; it's the only way to reconcile this failure with yourself.\"</p> </li> <li> <p>\"Is it that we collectively thought Steve Jobs was a great man, even when we knew he made billions off the backs of children? Or maybe it's that it feels like all our heroes are counterfeit. The world itself's just one big hoax. Spamming each other with our running commentary of bullshit masquerading as insight, our social media faking as intimacy. Or is it that we voted for this? Not with our rigged elections, but with our things, our property, our money. I m not saying anything new, we all know why we do this, not because Hunger Games books makes us happy but because we wanna be sedated. Because it's painful not to pretend, because we re cowards. Fuck society.\"</p> </li> <li> <p>\"How do we know if we re in control? That we re not just making the best of what comes at us, and that's it. Trying to constantly pick between two options. Like your two paintings in the waiting room. Or Coke and Pepsi. McDonald's or Burger King? Hyundai or Honda? It's all part of the same blur, right? Just out of focus enough. It's the illusion of choice. Half of us can t even pick our own our cable, gas, electric. The water we drink, our health insurance. Even if we did, would it matter? You know, if our only option is Blue Cross or Blue Shield, what the fuck is the difference? In fact, aren t they the same? No, man, our choices are prepaid for us, long time ago.\"</p> </li> <li> <p>\"We re all living in each other's paranoia.\"</p> </li> <li> <p>\"True courage is about being honest with yourself. Especially when it's difficult.\"</p> </li> <li> <p>\"Daemons. They don t stop working. They re always active. They seduce. They manipulate. They own us. And even though you re with me, even though I created you, it makes no difference. We all must deal with them alone. The best we can hope for, the only silver lining in all of this is that when we break through, we find a few familiar faces waiting on the other side.\"</p> </li> <li> <p>\"Power belongs to those who take it. \"</p> </li> <li> <p>\"The concept of waiting bewilders me. There are always deadlines. There are always ticking clocks.\"</p> </li> <li> <p>\"People are all just people, right? When it gets down to it, everyone's the same. They love something. They want something. They fear something. Specifics help, but specifics don t change the way that everyone is vulnerable. It just changes the way that we access those vulnerabilities.\"</p> </li> <li> <p>\"People always make the best exploits. I ve never found it hard to hack most people. If you listen to them, watch them, their vulnerabilities are like a neon sign screwed into their heads.\"</p> </li> <li> <p>\"There's a saying -- The devil is at his strongest while we re looking the other way. Like a program running in the background silently. While we re busy doing other shit. Daemons, they call them. They perform action without user interaction. Monitoring, logging, notifications, primal urges, repressed memories, unconscious habits. They re always there, always active. You can try to be right, you can try to be good, you can try to make a difference. But it's all bullshit. Cause intentions are irrelevant. They don t drive us, daemons do. And me? I ve got more than most.\"</p> </li> <li> <p>\"Give a man a gun and he can rob a bank. Give a man a bank and he can rob the world.\" \"And death shall have no dominion. Dead men naked they shall be one With the man in the wind and the west moon; When their bones are picked clean and the clean bones gone They shall have stars at elbow and foot; Though they go mad they shall be sane, Though they sink through the sea they shall rise again; Though lovers be lost love shall not; And death shall have no dominion\"</p> </li> <li> <p>\"By God, sleep was a treacherous enemy. You couldn t face it and fight it; it waited until you were looking the other way, then stole up quietly.\"</p> </li> <li> <p>\"Although one cannot easily trust others, one also cannot be over-cautious. The way you are currently, how will you be able to interact with people in the future? Remember, you can t be too cold and callous towards others, even if you can t be overly trusting either. Trust is something which is built up through a long period of time. Do not easily trust the words of others.\"</p> </li> <li> <p>\"If you didn t strive hard, you would be discarded.\" \"The wind was invisible. When it was gentle, it could be like the kiss of a lover. But when it was aroused into a vicious storm, it could split mountains and shatter stones.\"</p> </li> <li> <p>\"Sometimes, a single mistake caused by being unbending could cause someone to suffer a lifetime of regret. The occasional compromise that allows one's loved ones to be safe also allowed one to pursue revenge with even greater ferocity!\"</p> </li> <li> <p>\"An interesting, colorful life with ups and downs. Only that is meaningful.\"</p> </li> <li> <p>\"If you liked to do something, then once you became absorbed in it, your effectiveness would be extremely high. If, on the other hand, you didn t like to do something and instead forced yourself to do it, the effectiveness would be very low.\"</p> </li> <li> <p>\"The gods weave as the gods will, Rain. And even though it may not be apparent at first, they do weave purpose into all things. Even terrible things.\"</p> </li> <li> <p>\"My beloved is the sun And I am the earth that thrives only in her warmth. My beloved is the rain And I am the grass that thirsts for her quenching kiss. My beloved is the wind And I am the wings that soar when she fills me with her gentle strength. My beloved is the rock Upon which rests the happiness of all my days.\"</p> </li> <li> <p>\"With wings unfurled and joy unbound, I dance on laughter-spangled winds. I bathe in freedom's rushing breath And drink cool nectar from the clouds. Up, up, through sunlit fields of blue, I soar through boundless ether. Look! Starlight shines at height of day. I hear infinity calling.\"</p> </li> <li> <p>\"It's been too long since I ve been a mate. I had forgotten the two rules. The two rules?\" she echoed Aiyah. Sariel taught me.\" He held up his index finger.</p> </li> <li> <p>\"Rule one: in any dispute between mates, the male is always to blame, even when he is clearly blameless. Rule two\"\u2014his middle finger joined the first\u2014\"whenever in doubt, refer to rule one.\"</p> </li> <li> <p>\"It never failed to astonish him, then or ever, how much of the world around him was mysterious and hidden from view.\"</p> </li> <li> <p>\"The problem with growing up,\" Quentin said, \"is that once you re grown up, people who aren t grown up aren t fun anymore.\"</p> </li> <li> <p>\"As soon as he seized happiness it dispersed and reappeared somewhere else. Like Fillory, like everything good, it never lasted. What a terrible thing to know.I got my heart's desire, he thought, and there my troubles began.\"</p> </li> <li> <p>\"If you will, for just one second, look at your life and see how perfect it is. Stop looking for the next secret door that is going to lead you to your real life. Stop waiting. This is it: there's nothing else. It's here, and you d better decide to enjoy it or you re going to be miserable wherever you go, for the rest of your life, forever.\"You can t just decide to be happy.\"No, you can t. But you can sure as hell decide to be miserable. Is that what you want?\"</p> </li> <li> <p>\"He was painfully uncomfortable making eye contact.Quentin couldn t think who Benedict reminded him of until he realized that this was what he had probably looked like to other people when he was sixteen. Fear of everybody and everything, hidden behind a mask of contempt, with the greatest contempt of all reserved for himself.\"</p> </li> <li> <p>\"Though the funny thing about never being asked for anything is that after a while you start to feel like maybe you don t have anything worth giving.\"</p> </li> <li> <p>\"This is like a demon in your heart. It is a burden you cannot let go. This illusion grabbed exactly onto your weakness, so that is why it created their appearances. You must persevere and believe in yourself. Believe that you are correct. They are illusions, and everything is fake. As long as you can preserve, you can dispel that demon. You can clear your conscience and carry no more burdens.\"</p> </li> <li> <p>\"The human heart is difficult to predict, and one's true feelings are shown when disaster strikes. But the truth always made one's heart ache. The people who always followed behind you, who bootlicked you, and who swore loyalty, left without a single care of righteousness when you met a calamity. Who had experienced such a feeling?!\"</p> </li> <li> <p>\"Also, I need to remind you this. To people, the most important thing is dignity. If you live life like you just did without any dignity, you will never, ever, have anyone truly look at you with good eyes or good impressions. For forever, you will only be called here and there like a dog by others. When needed, they would use you. When unneeded, they would kill you at any time.\"</p> </li> <li> <p>\"To love a person, there is no need to change oneself. To love a person, there is no need to make things hard for oneself. To love a person, even more so, one should not be wronged. Because, in true love, there should be more sweet than sorrow; greater happiness than pain. For true love, even if it is within a deep, endless ocean of pain, as long as my heart doesn't change, I will still be happy within. To love a person, one should ignore their own safety for him. To love a person, one should give everything possible for him. To love a person, one should have an eternally unchanging heart. No matter what kinds of difficulties or dangers there are forward, one does not become timid. One does not be shaken. Even if that person becomes the enemy of the world, then I will also be willing to be by his side and fight against the world together with him.\"</p> </li> <li> <p>\"Life could not repeat itself like the rising and setting of the Sun. If one did not grab every moment, one would waste their talent and potential. It would be a great regret\"</p> </li> <li> <p>\"Return kindness with kindness and return animosity with animosity. If there was a trickle of kindness, return it with a gushing spring of kindness. If the hatred was carved deep within the bones, then return the favor a hundred times back.\"</p> </li> <li> <p>\"No matter how strong you are or how high your status is, you must never throw away your conscious. A man's conscious is extremely important. One must be kind and benevolent in order to attain the highest level of mastery. Take heed to this! Even if you are a genius without equal and have only success after success, in the end, your achievements will amount to nothing.\"</p> </li> <li> <p>\"Be like the forces of nature: when it blows, there is only wind; when it rains, there is only rain; when the clouds pass, the sun shines through.\"</p> </li> <li> <p>\"But comfort can be a cage, you know. Certainly it can stunt the mind. \"</p> </li> <li> <p>\"It's easy to die, Mageling,\" Taliesin said, stroking his hair. \"It's staying alive that's hard work\"</p> </li> <li> <p>\"Sometimes, a person's heart is much more vicious than that of a tiger. At least when a tiger wants to eat you, he ll let you know first.\"</p> </li> <li> <p>\"Joy is feather light But who can carry it? Sorrow falls like a landslide Who can parry it?\"</p> </li> <li> <p>\"A poor man must swing for stealing a belt buckle but if a rich man steals a whole state he is acclaimed as statesman of the year.\"</p> </li> <li> <p>\"In the age when life on earth was full, no one paid any special attention to worthy men, nor did they single out the man of ability. Rulers were simply the highest branches on the tree, and the people were like deer in the woods. They were honest and righteous without realizing that they were \"doing their duty.\" They loved each other and did not know that this was \"love of neighbor.\" They deceived no one yet they did not know that they were \"men to be trusted.\" They were reliable and did not know that this was \"good faith.\" They lived freely together giving and taking, and did not know that they were generous. For this reason their deeds have not been narrated. They made no history.\"</p> </li> <li> <p>\"But books contain words only. And yet there is something else which gives value to the books. Not the words only, nor the thought in the words, but something else within the thought, swinging it in a certain direction that words cannot apprehend. But it is the words themselves that the world values when it commits them to books: and though the world values them, these words are worthless as long as that which gives them value is not held in honor.\"</p> </li> <li> <p>\"Of all the beings that exist (and there are millions), man is only one. Among all the millions of men that live on earth, the civilized people that live by farming are only a small proportion. Smaller still the number of those who having office or fortune, travel by carriage or by boat. And of all these, one man in his carriage is nothing more than the tip of a hair on a horse's flank. Why, then, all the fuss about great men and great offices? Why all the disputations of scholars? Why all the wrangling of politicians?\"</p> </li> <li> <p>\"I don t know what the answer is,\" he murmured. \"My Cultivation base won t permit me to understand what the Dao is\u2026. \"To me, the Dao is very simple. It is talking, speaking, opening your mouth, and letting other people open their mouths. All of that is the Dao, speaking. Speaking the words from your heart, speaking out the thoughts you wish to express. \"It doesn't require enlightenment, nor obsession. It doesn't require a path beneath your feet. Perhaps it is the first voice of all living creatures, of everything under the Heavens. \"When that voice can be heard, it is the Dao, it is speaking!\" Meng Hao had organized his thoughts and spoken out what he understood about the Dao, based upon his current realm. He didn t know if what he had said was true or correct. In fact, he hadn t wanted to speak at all, but he had no choice but to ignore those feelings. All he could do was explain what he understood about the Dao. By this time, the incense stick had burned down to the end. It flickered, on the verge of being completely extinguished. \"At the same time,\" he continued, \"when that voice speaks, it represents a direction! \"The boundless Heavens and Earth are the final resting place of all living things. Life is like a journey, filled with various scenery, various paths. \"Sometimes, you might think there is only one path for you. Sometimes, your heart's obsession creates a path. \"As for the Dao, it is a direction. That direction can guide you through your life. When you are faced with countless decisions, it can lead you down the paths you must tread. In the end\u2026 it can help you pick which path to take! \"It is formed after one experiences the vicissitudes of life, the cleansing of time, and the understanding which comes from experiencing the world. It can be hidden in any time, place, direction, or action\u2026. \"That is my understanding of the Dao. It points in a direction, and gives me the strength to proceed onward. Perhaps it doesn't even exist, or perhaps it is everywhere.</p> </li> <li> <p>\"As for me, I am still searching for it\u2026.\"</p> </li> <li> <p>\"In the former era mankind had produced a massive cruise ship. They christened it the Titanic.\" \"The name Titanic had been borrowed from Greek mythology, referring to the giants called Titans. The Titans wished to wage war against the god Zeus on behalf of the mysterious forces of nature. They were ultimately defeated, and banished to the depths of the Atlantic ocean, buried deeper than the eighteenth level of hell itself. Thus it was people said the name Titanic was poorly chosen, ominous, and would invite catastrophe. And as predicted, the ship sank to the bottom of the sea in an accident. At the mention of Zeus, Zhou Qianlin inadvertently raised her head. Her eyes found Lan Jue's looking directly back at her. Lan Jue continued. \"But the difference between this great ship and the titans of lore was that the only thing that sunk was it's steel.. it's bolts\u2026 it's people. It's spirit was never conquered. That is to say that the titanic sunk, taking with it the lives of one thousand five hundred passengers. But the invincible spirit of human civilization remained. Unsinkable.\" Lan Jue's voice grew louder as he pressed on. As the boat sank eight musicians calmly stood upon the deck, playing their instruments. Those notes embodied the dignity and honor of the human spirit, refusing to bow it's head to the ruthless acts of nature. Just as the famous writer Hemmingway wrote in his book The Old Man and the Sea: A man is not made for defeat. A man can be destroyed but not defeated. The sharks following the old man could gnaw on the fish lashed to his boat until there was nothing but bone, but they couldn t gnaw the sailor's undaunted spirit. This was the burning fire of the inner spirit, the will of man, that not even the entire ocean could extinguish. Even many years later people still laud the actions of those musicians and sailors. How could they have so much courage when they faced drowning in the brine? How is it they could adhere to their duties when death lay in those tumultuous waters? How is it they could retain the noble sentiment to wait until all the women and children had filled the lifeboats before thinking of themselves? Statistics state that seventy-six percent of the sailors died in the accident, a ratio that outstripped the first, second and third class passenger deaths combined. The sailors even had evacuation preference over the passengers \u2013 but they gave their opportunity to others. They took on that hopelessness for themselves. Nor was it one, or two sailors who did this. All nine hundred staff, including sailors, waiters, firemen and even the cook all chose to stay behind; so many people, willing to do what they did. As we think on it today, this sort of towering spirit of humanity is not unlike what they said about the sinking of that great ship. It is almost unbelievable.\"</p> </li> <li> <p>\"Sometimes, people don t understand the truth about their own feelings. They suddenly get hurt, and then feel that the only choice they have is to give up in hopelessness. What they don t realize is that what truly can hurt them the most is their own precious love. And because love is so precious, one should never give up, one should never run away. By the time most people understand this truth, they have already lost their precious love.\"</p> </li> <li> <p>\"A popular man arouses the jealousy of the powerful\"</p> </li> <li> <p>\"I must not fear. Fear is the mind-killer. Fear is the little-death that brings total obliteration. I will face my fear. I will permit it to pass over me and through me. And when it has gone past I will turn the inner eye to see its path. Where the fear has gone there will be nothing. Only I will remain.\"</p> </li> <li> <p>\"In the journey of mastery, the self is the most important. Outside aid can certainly make smooth the path to mastery, however, how far one ventures along this path is still ultimately in their own hands.\"</p> </li> <li> <p>\"Sometimes, it's best not to go all-out. A truly impressive individual knows when to endure and when to withdraw. Even if others mock him, he will ignore them. That is true courage and charisma\u2026because, hope springs eternal as long as one is alive.\"</p> </li> <li> <p>\"A process cannot be understood by stopping it. Understanding must move with the flow of the process, must join it and flow with it.\"</p> </li> <li> <p>\"If wishes were fishes we d all cast nets\"</p> </li> <li> <p>\"The mind commands the body and it obeys. The mind orders itself and meets resistance.\"</p> </li> <li> <p>\"Grave this on your memory, lad: A world is supported by four things...\" she held up four big-knuckled fingers. \"...the learning of the wise, the justice of the great, the prayers of the righteous and the valor of the brave. But all of these things are as nothing...\" She closed her fingers into a fist. \"...without a ruler who knows the art of ruling. Make that the science of your tradition!\"</p> </li> <li> <p>\"Proper teaching is recognized with ease. You can know it without fail because it awakens within you that sensation which tells you this is something you have always known.\"</p> </li> <li> <p>\"Anything outside yourself, this you can see and apply your logic to it. But it's a human trait that when we encounter personal problems, these things most deeply personal are the most difficult to bring out for our logic to scan. We tend to flounder around, blaming everything but the actual, deep-seated thing that's really chewing on us.\"</p> </li> <li> <p>\"There is in all things a pattern that is part of our universe. It has symmetry, elegance, and grace - these qualities you find always in that the true artist captures. You can find it in the turning of the seasons, the way sand trails along a ridge, in the branch clusters of the creosote bush of the pattern of its leaves. We try to copy these patterns in our lives and in our society, seeking the rhythms, the dances, the forms that comfort. Yet, it is possible to see peril in the finding of ultimate perfection. It is clear that the ultimate pattern contains its own fixity. In such perfection, all things move towards death.\"</p> </li> <li> <p>\"The vision of time is broad, but when you pass through it, time becomes a narrow door.\"</p> </li> <li> <p>\"Do you wrestle with dreams? Do you contend with shadows? Do you move in a kind of sleep? Time has slipped away. Your life is stolen. You tarried with trifles, Victim of your folly.\"</p> </li> <li> <p>\"There is in each of us an ancient force that takes and an ancient force that gives. A man finds little difficulty facing that place within himself where the taking force dwells, but it's almost impossible for him to see into the giving force without changing into something other than man. For a woman, the situation is reversed\u2026These things are so ancient within us\u2026that they re ground into each separate cell of our bodies\u2026It's as easy to be overwhelmed by giving as by taking.\"</p> </li> <li> <p>\"Please permit the room to convey a lesson we learned from the same teachers: the proximity of a desirable thing tempts one to overindulgence. On that path lies danger.\"</p> </li> <li> <p>\"But power deluded those who used it. One tended to believe power could overcome any barrier . . . including one's own ignorance.\"</p> </li> <li> <p>\"Deep in the human unconscious is a pervasive need for a logical universe that makes sense. But the real universe is always one step beyond logic.\"</p> </li> <li> <p>\"To suspect your own mortality is to know the beginning of terror; to learn irrefutably that you are mortal is to know the end of terror.\"</p> </li> <li> <p>\"You understand? One uses power by grasping it lightly. To grasp too strongly is to be taken over by power, and thus to become its victim.\"</p> </li> <li> <p>\"Do you know what guerrillas often say? They claim that their rebellions are invulnerable to economic warfare because they have no economy, that they are parasitic on those they would overthrow. The fools merely fail to assess the coin in which they must inevitably pay. The pattern is inexorable in its degenerative failures. You see it repeated in the systems of slavery, of welfare states, of caste-ridden religions, of socializing bureaucracies-in any system which creates and maintains dependencies. Too long a parasite and you cannot exist without a host.\"</p> </li> <li> <p>\"Most believe that a satisfactory future requires a return to an idealized past, a past which never in fact existed.\"</p> </li> <li> <p>\"Some people never observe anything. Life just happens to them. They get by on little more than a kind of dumb persistence, and they resist with anger and resentment anything that might lift them out of that false serenity.\"</p> </li> <li> <p>\"Memory never recaptures reality. Memory reconstructs. All reconstructions change the original, becoming external frames of reference that inevitably fall short\"</p> </li> <li> <p>\"Confine yourself to observing and you always miss the point of your own life. The object can be stated this way: Live the best life you can. Life is a game whose rules you learn if you leap into it and play it to the hilt. Otherwise, you are caught off balance, continually surprised by the shifting play. Non-players often whine and complain that luck always passes them by. They refuse to see that they can create some of their own luck.\"</p> </li> <li> <p>\"Success, that was the danger. It had cost them an empire. If you waved your success around like a banner someone always wanted to cut you down. Envy!\"</p> </li> <li> <p>\"The difference between sentiment and sentimentality is easy to see. When you avoid killing somebody's pet on the glaze way, that's sentiment. If you swerve to avoid the pet and that causes you to kill pedestrians, that is sentimentality.\"</p> </li> <li> <p>\"There is an entire forest full of the most incredible flowers, plants and trees inside you, and you are ignoring all of it to nurture a single tree that they planted inside your heart and abandoned. The people who left you this way don t deserve to become your favourite stories to tell. You are a massive forest full of beautiful and vibrant stories and every single one of them deserves you more than those that abandoned you to hell.\"</p> </li> <li> <p>\"The way you hate yourself sometimes, you seem to forget that there is still a child somewhere inside you, and you re feeding that innocence within you poison with those terrible words.  Protect that child by being gentler with yourself. Protect that child by being kinder to yourself.  Because no one else will protect them other than you.\"</p> </li> <li> <p>\"1. Carry featherlike hope in your heart, always. Let its softness soothe you when poniards of fear and pain shoot through your heart.  2. Cleanse your soul with kindness everyday. Even if the world around you encourages you to be unkind, remind yourself that your soul is your responsibility alone and kindness is the best path to being calm.  3. Hold other people's broken hearts like you would a little injured bird. Remember how much effort it must have taken for them to piece it together after it was smashed on the floor and how much they must trust you to hand it over to you.  4. Teach people how to love you gently by loving yourself. Tell them about your story like scars and soothe with honey where it still stings.  5. Remember that water can adapt its form to any container it is put in. You are seventy percent water. And no matter what happens, you can adapt to anything.\"</p> </li> <li> <p>\"Someone fell in love today. Someone was born today. Someone lived through something that could have killed them. Someone won back the love of their life. Someone made their parents proud. Someone survived. Someone healed. Someone let go. Seven billion people, and some of us have just had the best day of their lives. Today may have been the very worst day of yours. But take solace and celebrate this simple fact. It wasn t your best day today, but it is on it's way, because we all get lucky in turn.\"</p> </li> <li> <p>\"Have you ever felt hunted inside your own head?\"</p> </li> <li> <p>\"You are nothing static. You are a breathing reflection of everything the universe has to offer. A song sung into existence by so much more than inspiration. It took six million years of evolution to build you, to bring you to this moment \u2013 so much more than any artist could ever spare for even the greatest of his masterpieces. You are a multitude of majestic feelings, every single one, once felt, never felt again in the same magnitude. You are the millions of things that happen to you in your lifetime.\"</p> </li> <li> <p>\"Never forget to put salt in an omelette. If you do. Use sauce.\"</p> </li> <li> <p>\"You can t change who people are. Then what do you do? You love them.\"</p> </li> <li> <p>\"Loving can hurt sometimes. And when it gets hard, it's the only thing that keeps us alive.\"</p> </li> <li> <p>\"One of the most terrible moments in a boy's life,\" Paul said, \"is when he discovers his father and mother are human beings who share a love that he can never quite taste. It's a loss, an awakening to the fact that the world is there and here and we are in it alone. The moment carries its own truth; you can t evade it.\"</p> </li> <li> <p>\"A wandering breeze, swaying restlessly. Swept up by flurries. Lost and led astray. Storms rage and roar, and threaten all that remains. But the breeze drifts ever onward. Finding its own way.\"</p> </li> <li> <p>\"In the dangers of the age, in the passion of violence, quietly laying down your life is utterly insignificant in the ever flowing passage of time. There is nothing stronger than the will to live.\"</p> </li> <li> <p>\"That, dear one, is the point of the demonstration. Reality isn t relevant. Perception is everything. If you think it is the enemy, you can destroy it, whether true or not. The magic interprets only your perception. It won t allow you to harm someone you think innocent, but it will destroy whoever you perceive to be the enemy, within limits. Only what you believe, and not the truth of your thoughts, is the determining factor.\"</p> </li> <li> <p>\"There is no such thing as pure good or pure evil, least of all in people. In the best of us there are thoughts or deeds that are wicked, and in the worst of us, at least some virtue. An adversary is not one who does loathsome acts for their own sake. He always has a reason that to him is justification. My cat eats mice. Does that make him bad? I don t think so, and the cat doesn't think so, but I would bet the mice have a different opinion. Every murderer thinks the victim needed killing.\"</p> </li> <li> <p>\"The anger of teeth be force by contact. Violence by touch. Combat. The magic of the Sword of Truth be the magic of the anger of teeth. Ripping. Tearing. The anger of the tongue need not touch, but it be force just the same. It cuts just as quick\"</p> </li> <li> <p>\"Everything is valuable under the right conditions. To a man dying of thirst, water be more precious than gold. To a drowning man, water be of little worth and great trouble.\"</p> </li> <li> <p>\"Wizard's First Rule: people are stupid.\" Richard and Kahlan frowned even more.</p> </li> <li> <p>\"People are stupid; given proper motivation, almost anyone will believe almost anything. Because people are stupid, they will believe a lie because they want to believe it's true, or because they are afraid it might be true. People's heads are full of knowledge, facts, and beliefs, and most of it is false, yet they think it all true. People are stupid; they can only rarely tell the difference between a lie and the truth, and yet they are confident they can, and so are all the easier to fool.\"</p> </li> <li> <p>\"As long as the heart is there, it doesn't matter if it is red or black. Your will is the most important factor. Your will is like a blade, and that blade\u2026 can still be used in your Third Severing. There is no need to be swept up with confusion. Life is a series of decisions. Whether you make the correct decisions or not doesn't matter. The important thing is to keep going forward. Years later, when you look back, perhaps you'll find that the incorrect decisions you made\u2026 weren t really incorrect. Similarly, the correct decisions\u2026 might not necessarily have been correct. Why struggle with frustration? Why proceed with confusion? In all things\u2026 resolution only comes from continuing to move forward. Following this line of reasoning, if there is no such thing as incorrect, then how can the correct exist? Similarly, if there is no correct, then how can the incorrect exist?\"</p> </li> <li> <p>\"As you well know, superstition needs no grounding in truth, but once rooted, it grows a strong though twisted tree.\"</p> </li> <li> <p>\"Nonsense. No one knows everything. You can t expect to walk through life without stepping in the muck now and again. The important thing is to maintain your footing when you do, and not fall on your face and make it worse.\"</p> </li> <li> <p>\"The Second Rule is that the greatest harm can result from the best intentions. It sounds a paradox, but kindness and good intentions can be an insidious path to destruction. Sometimes doing what seems right is wrong, and can cause harm. The only counter to it is knowledge, wisdom, forethought, and understanding the First Rule. Even then, that is not always enough. Good intentions, or doing right, can cause harm? Such as? Nathan shrugged. \"It would seem kind to give candy to a small child, because they like it so. Knowledge, wisdom, and forethought tell us that it would make the child sick if we continued this kindness at the expense of good food. That's obvious. Anyone would know that. Say a person hurts their leg, and you bring them food while they heal, but after time they still don t wish to get up, because it hurts at first. So, you continue to be kind and bring them food. Over time, their legs will shrivel, and it will be even more painful to get up, so you are kind and continue bringing food. In the end, they will be bedridden, unable to ever walk again, because of your kindness.\"</p> </li> <li> <p>\"Damaged people understand that every evil demon that exists down there was once a kind angel before it fell.\"</p> </li> <li> <p>\"I don t like the words I m fine. My mom tells me those two words are the most-frequently-told lie in the English language.\"</p> </li> <li> <p>\"If you have no faith in yourself, then have faith in the things you call truth. You know what must be done. You may not have courage or trust or understanding or the will to do it, but you know what must be done. You can t turn back. There is no answer behind you. You fear what you cannot name. So look at it and find a name for it. Turn your face forward and learn. Do what must be done\"</p> </li> <li> <p>\"Wishes, wishes,\" I told him, \"Wish in one hand and do something else in the other, and squeeze them both and see which comes true.\"</p> </li> <li> <p>\"What actually is Heaven? I ve pondered over this for countless years, but I still don t know the answer \u2026 However, the seniors with countless years of experience in my clan concluded that Heaven is the most heartless thing. It doesn't care at all if you re a mass murderer or a kind-hearted person, if you ve helped tens of millions of people or killed tens of millions of them. Perhaps everything is negligible in the eyes of Heaven. The fittest survive in natural selection. Either you'll kill me or I ll kill you. Whether it's everybody uniting to surround and kill one person or one person massacring countless people \u2026 whatever happens, Heaven doesn't care about these petty things.\"</p> </li> <li> <p>\"The farthest distance known to man should be the distance between two people who love each other deeply\u2026\u2026and yet cannot be together.\"</p> </li> <li> <p>\"As regards the methods employed for forming deliberate intentions and doing straightforward actions, there is none that will enable you to continue longer in the course you desire to pursue than that of ample deliberation; and none that will enable you to pursue that course in greater peace than the patient bearing of insult. There is nothing more important than the cultivation of virtue; there is no greater cause of joy than the love of goodness; there is nothing that will give you deeper insight into hidden things than perfect sincerity in word and deed; there is nothing that will make you clearer-sighted than understanding the nature of all created beings; there is nothing more felicitous than contentment, nothing bitterer than covetousness, nothing more sorrowful than the dispersion (or loss) of animal vigour, no greater sickness than that which results from the vicissitudes of life, nothing shorter than a career of unlawful gain, nothing that tends more to secrecy (or stealthiness) than avarice, nothing that isolates a man more than trusting to himself alone, nothing more dangerous than employing those whom you have reason to suspect, and nothing more certain to bring ruin to you than unfairness or partiality.\"</p> </li> <li> <p>\"What we are is invulnerable and cannot be bound.\"</p> </li> <li> <p>\"But\u2026 is it really possible to completely Sever evil? If humanity was left only with goodness, perhaps that would make the world a more beautiful. Unfortunately, that isn t realistic. Without the existence of evil, perhaps good\u2026 would no longer be called good. Good and evil are the desires of the heart. If I earnestly perform good deeds, evil can be suppressed. Likewise, if I malevolently perform evil deeds, good will be suppressed. Perhaps there is nothing truly good or truly evil in the world, similar to what my master Pill Demon told me about what is correct and incorrect. What I have\u2026 is my own will! The choices I make decide everything!\" As his voice echoed out, the music of a great Dao rose up around him, as well as the power of natural law.\"</p> </li> <li> <p>\"You two are still young and far too naive. In this world there are no absolute villains. Neither are there any absolutely good people. There are only those with different ideas. That is why regardless of how small a good is, don t forsake it and no matter how small an evil is, don t commit it.\"</p> </li> <li> <p>\"All that is in the past. There is no way to reverse the flow of time, and there is no way to change past history. Punishing one's self for something one can no longer alter\u2026that is nothing more than being made a fool of by fate! The only one who rules over myself\u2026is myself!\"</p> </li> <li> <p>\"In the end, it's not the changes that will break your heart; it's that tug of familiarity.\"</p> </li> <li> <p>\"Miss Dan Fei, take for instance, if we re in a circle right now. All that we know is what's in this circle. There are many more unknowns in the world outside the circle. It's only when we set foot outside of that circle that we know our original knowledge was much, much too little.\"</p> </li> <li> <p>\"Some loves come unbidden like winds from the sea, and others grow from the seeds of friendship.\"</p> </li> <li> <p>\"The faults we see in others never seem as dreadful as those we see in ourselves.\"</p> </li> <li> <p>\"One time is much like another to death. She comes when she will. So why give over your mind to worry?\"</p> </li> <li> <p>\"But for the most part, love is a recognition, an opportunity to say, There is something about you I cherish.\"</p> </li> <li> <p>\"Snow can only live in the winter. When it nears a fire, it dies. That is its life. It may yearn for summer, but\u2026 it can only desire it. In my hand, the snow becomes water, because this is not its world\u2026.\"</p> </li> <li> <p>\"Life is like a dream, like a leaf that, no matter how beautiful , can only live for one season.\"</p> </li> <li> <p>\"I am the pill furnace, and my heart is the pill formula. Refine the interior to achieve Immortality. Refine the exterior to achieve the boundless Dao of alchemy. Fuse them together, and this is the Truth of alchemy. Alchemy is the Heavens! Alchemy is the Earth! Alchemy is the world!\"</p> </li> <li> <p>\"What might have been and what has been Point to one end, which is always present. Footfalls echo in the memory Down the passage which we did not take Towards the door we never opened.\"</p> </li> <li> <p>\"It's the beautiful thing about youth. There's a weightlessness that permeates everything because no damning choices have been made, no paths committed to, and the road forking out ahead is pure, unlimited potential.\"</p> </li> <li> <p>\"I am not allowed to think I m crazy. I am only allowed to solve this problem. Experimental physics\u2014hell, all of science\u2014is about solving problems. However, you can t solve them all at once. There's always a larger, overarching question\u2014the big target. But if you obsess on the sheer enormity of it, you lose focus. The key is to start small. Focus on solving problems you can answer. Build some dry ground to stand on. And after you ve put in the work, and if you re lucky, the mystery of the overarching question becomes knowable. Like stepping slowly back from a photomontage to witness the ultimate image revealing itself.\"</p> </li> <li> <p>\"Nothing exists. All is a dream. God\u2014man\u2014the world\u2014the sun, the moon, the wilderness of stars\u2014a dream, all a dream; they have no existence. Nothing exists save empty space\u2014and you\u2026. And you are not you\u2014you have no body, no blood, no bones, you are but a thought.\"</p> </li> <li> <p>\"We all live day to day completely oblivious to the fact that we re a part of a much larger and stranger reality than we can possibly imagine.\"</p> </li> <li> <p>\"The meaning of that word is: In doing nothing, a path shall appear. Allowing things to happen naturally. In doing nothing, everything can be done. In doing nothing, you are doing something,\"</p> </li> <li> <p>\"Like the empty air; life is as tranquil as a blooming flower; all is fleeting and illusory; let your heart be as clear as a mirror\"1. Everyone is born into this world empty-handed. Your existence doesn't any proof. Live life with a merry heart and appreciate what is there! Things like origins aren t that important!\"</p> </li> <li> <p>\"Far out in the uncharted backwaters of the unfashionable end of the western spiral arm of the Galaxy lies a small unregarded yellow sun. Orbiting this at a distance of roughly ninety-two million miles is an utterly insignificant little blue green planet whose ape-descended life forms are so amazingly primitive that they still think digital watches are a pretty neat idea. This planet had a problem, which was this: most of the people on it were unhappy for pretty much of the time. Many solutions were suggested for this problem, but most of these were largely concerned with the movements of small green pieces of paper, which is odd because on the whole it wasn t the small green pieces of paper that were unhappy. And so the problem remained; lots of the people were mean, and most of them were miserable, even the ones with digital watches. Many were increasingly of the opinion that they d all made a big mistake in coming down from the trees in the first place. And some said that even the trees had been a bad move, and that no one should ever have left the oceans.\"</p> </li> <li> <p>\"Bypasses are devices which allow some people to drive from point A to point B very fast whilst other people dash from point B to point A very fast. People living at point C, being a point directly in between, are often given to wonder what's so great about point A that so many people of point B are so keen to get there, and what's so great about point B that so many people of point A are so keen to get there. They often wish that people would just once and for all work out where the hell they wanted to be.\"</p> </li> <li> <p>\"Time is an illusion. Lunchtime doubly so.\"</p> </li> <li> <p>\"R is a velocity measure, defined as a reasonable speed of travel that is consistent with health, mental wellbeing and not being more than say five minutes late. It is therefore clearly an almost infinitely variable figure according to circumstances, since the first two factors vary not only with speed taken as an absolute, but also with awareness of the third factor. Unless handled with tranquility this equation can result in considerable stress, ulcers and even death.\"</p> </li> <li> <p>\"If I were the rain could I connect with someone's heart as the rain can connect the eternally separated earth and sky?\"</p> </li> <li> <p>\"Unless I grip the sword I cannot protect you. While I grip the sword I cannot embrace you.\" \"We must never shed tears. That is the life forms defeat. And if we give in to emotions it only becomes proof of our inability to control it.\"</p> </li> <li> <p>\"We stretch out both our hands, pass through the clouds, straight to the sky. Even though we touched the moon and Mars, we still cannot touch the truth\"</p> </li> <li> <p>\"The only reason we think the flowers on the precipice are beautiful is because we are standing on the precipice as well. Do not fear because we are like the flowers. We did not step off.\"</p> </li> <li> <p>\"The History of every major Galactic Civilization tends to pass through three distinct and recognizable phases, those of Survival, Inquiry and Sophistication, otherwise known as the How, Why and Where phases.\"</p> </li> <li> <p>\"Every time you and me connect with each other a little bit of heart is born between us. Heart isn t something inside you. But whenever you think of someone, whenever you remember someone. That's when heart is born. If you were the only person alive. The heart wouldn t exist would it?\"</p> </li> <li> <p>\"It's impossible to feel exactly the same as someone else. But you can treasure your friends and keep them close in your heart. I think that's what it means to make your hearts as one. \"</p> </li> <li> <p>\"The Universe, as has been observed before, is an unsettlingly big place, a fact which for the sake of a quiet life most people tend to ignore. Many would happily move to somewhere rather smaller of their own devising, and this is what most beings in fact do.\"</p> </li> <li> <p>\"It is known that there are an infinite number of worlds, simply because there is an infinite amount of space for them to be in. However, not every one of them is inhabited. Therefore, there must be a finite number of inhabited worlds. Any finite number divided by infinity is as near to nothing as makes no odds, so the average population of all the planets in the Universe can be said to be zero. From this it follows that the population of the whole Universe is also zero, and that any people you may meet from time to time are merely the products of a deranged imagination.\"</p> </li> <li> <p>\"The point is, you see,\" said Ford, \"that there is no point in driving yourself mad trying to stop yourself going mad. You might just as well give in and save your sanity for later.\"</p> </li> <li> <p>\"Besides, love is always in your heart, no matter how long you stay apart.\"</p> </li> <li> <p>\"The ruins they made of your heart, they are still loved. They are cherished by the memories they give refuge to, the wildflowers of peace that have taken root in their walls, and the birds of epiphany that have nested and given birth to newer, more beautiful truths about you. The ruins they made of your heart, they are not ruins at all. They are an incredible universe made of blood and muscle and stars.\"</p> </li> <li> <p>\"I don t write because I am a perfect human being who has found the secret to life. I write because I have made mistakes. I begged unworthy people to stay when they didn t deserve my presence. I loved too much, too hard and too jealously. I let my trauma do the talking for a long, long time. I took the long road to survival. I took ages to recognise the path to healing. And I hurt people along the way and still regret it deeply. I write because I am a deeply flawed human being. And if there are lessons for others in my journey, in my words, if there is healing for others hidden in my wounds, if there is meaning for others within the ink when I bleed on paper, then I am doing what I set out to do when I dreamed of the words in a lonely bed on a starry night. To ensure no one who reads those words ever feels alone.\"</p> </li> <li> <p>\"Life is not a problem to be solved. It is a reality to be experienced.\"</p> </li> <li> <p>\"The magic was in searching their whole world, lost in the wonder of it all. Without imagination, things were only as they appeared \u2013 and that was blindness. Things were more than they appeared, so much more. When he considered an oak tree, it was not just a tree. To someone small, like an ant, it was a whole landscape of rugged barky cliffs and big green leaf-plains that quaked when the sky was restless, a place of many strange creatures where fearsome winged beasts could pluck and devour someone in a blink. And it wasn t just about magic. Without imagination, one could not think very far into things, like that Lieutenant. Without imagination, he was no more than he said he was. But there was more to him.\"</p> </li> <li> <p>\"There is a movement to all things in this world. Nothing stands still. Even this planet we are on moves, which is why the sun rises and sets every day. What you are feeling is called centering. Memorize the feeling, make it your home. It applies not just to swordsmanship but to life. A centered opponent is a fearsome enemy. Stay centered and stay alive.\"</p> </li> <li> <p>\"But I will tell you that everything you experience, from the woods you walk through, the trees you climb and the people you meet, everything is connected. What is true of the outside world is true inside your body as well.\"</p> </li> <li> <p>\"The first and most important thing you must know is this: the whole world around us is alive. I m not saying that the moss in the stream have feelings or that the trees have thoughts like you do. But there is energy, a connection between all things. Simply put, your ability with the sense is the ability to be aware of that energy, to know where living things are and to know how things are going to move. In reality, the sense is nothing more than the ability to have a little bit more information than the others around you.\"</p> </li> <li> <p>\"Face your fear and you will discover it has no hold over you anymore.\"</p> </li> <li> <p>\"It never is. The world doesn't listen to us and it doesn't follow any order. To believe this world cares, to believe that nature will somehow protect us, is utter foolishness. Nature is not good or evil. It just is.\"</p> </li> <li> <p>\"If you leave it then it's one step closer to giving up. And every relationship is worth a second shot.\"</p> </li> <li> <p>\"Certain people say that the real world has been constructed by the human mind, since our ways are governed by the artificial categories into which we place essentially undifferentiated things, things weaker than our words for them.\"</p> </li> <li> <p>\"We believe that we invent symbols. The truth is that they invent us; we are their creatures, shaped by their hard, defining edges\"</p> </li> <li> <p>\"Where I put you, there you lie, Never let a stranger spy, Like glass grow to any eye, Not of me. Here be safe, never leave it, Should a hand come, deceive it, Let strange eyes not believe it, Till I see.\"</p> </li> <li> <p>\"In that contradiction will reside the appeal of this new belief. One can t found a novel theology on Nothing, and nothing is so secure a foundation as a contradiction. Look at the great successes of the past\u2014they say their deities are the masters of all the universes, and yet that they require grandmothers to defend them, as if they were children frightened by poultry. Or that the authority that punishes no one while there exists a chance for reformation will punish everyone when there is no possibility anyone will become the better for it.\"</p> </li> <li> <p>\"You have humor! That's excellent! There are few advantages, I ll tell you, that profit a man more than humor. Humor will draw a crowd. Humor will calm a mob or reassure a nursery school. Humor will get you on and get you off, and pull in asimis(money) like a magnet.\"</p> </li> <li> <p>\"Have I said that time turns our lies into truths?\"</p> </li> <li> <p>\"Perhaps when night closes our eyes there is less order than we believe. Perhaps, indeed, it is this lack of order we perceive as darkness, a randomization of the waves of energy (like a sea), the fields of energy (like a farm) that appear to our deluded eyes\u2014set by light in an order of which they themselves are incapable\u2014to be the real world.\"</p> </li> <li> <p>\"The world is filled half with evil and half with good. We can tilt it forward so that more good runs into our minds, or back, so that more runs into this.\" A movement of her eyes took in all the lake. \"But the quantities are the same, we change only their proportion here or there.\"</p> </li> <li> <p>\"But there is no reason to mourn the destruction of a colony of cells: such a colony dies each time a loaf of bread goes into the oven. If a man is no more than such a colony, a man is nothing; but we know instinctively that a man is more. What happens, then, to that part that is more?\"</p> </li> <li> <p>\"Sometimes when all our attention is thus focused on memory, our eyes, unguided by ourselves, will distinguish from a mass of detail some single object, presenting it with a clarity never achieved by concentration.\"</p> </li> <li> <p>\"If you do not see sorrow in my eyes, it is only because it lies upon my heart.\"</p> </li> <li> <p>\"For no man lives long when his dreams are dead.\"</p> </li> <li> <p>\"How foolish to call them mirrors. They are to mirrors as the enveloping firmament is to a child's balloon. They reflect light indeed; but that, I think, is no part of their true function. They reflect reality, the metaphysical substance that underlies the material world.\"</p> </li> <li> <p>\"Women believe\u2014or at least often pretend to believe\u2014that all our tenderness for them springs from desire; that we love them when we have not for a time enjoyed them, and dismiss them when we are sated, or to express it more precisely, exhausted. There is no truth in this idea, though it may be made to appear true. When we are rigid with desire, we are apt to pretend a great tenderness in the hope of satisfying that desire; but at no other time are we in fact so liable to treat women brutally, and so unlikely to feel any deep emotion but one.\"</p> </li> <li> <p>\"All time exists. That is the truth beyond the legends the epopts tell. If the future did not exist now, how could we journey toward it? If the past does not exist still, how could we leave it behind us? In sleep the mind is encircled by its time, which is why we so often hear the voices of the dead there, and receive intelligence of things to come.\"</p> </li> <li> <p>\"How strange it is that the sky, which by day is a stationary ground on which the clouds are seen to move, by night becomes the backdrop for Urth's own motion, so that we feel her rolling beneath us as a sailor feels the running of the tide. That night the sense of this slow turning was so strong that I was almost giddy with its long, continued sweep. Strong too was the feeling that the sky was a bottomless pit into which the universe might drop forever. I had heard people say that when they looked at the stars too long they grew terrified by the sensation of being drawn away. My own fear\u2014and I felt fear\u2014was not centered on the remote suns, but rather on the yawning void\"</p> </li> <li> <p>\"But we shouldn t and couldn t force a man to act like a man. Did you ever want to fall asleep? When you weren t sleepy or even tired?\" He nodded. \"That was because you wanted to put down the burden of being a boy, at least for a time. Sometimes I drink too much wine, and that is because for a while I would like to stop being a man. Sometimes people take their own lives for that reason. Did you know that?\"Or they do things that might hurt them,\" he said.\"</p> </li> <li> <p>\"Now it struck me that the will itself was governed, and if not by reason, then by things below or above it. Yet it was very difficult to say on what side of reason these things lay. Instinct, surely, lay below it; but might it not be above it as well?\"</p> </li> <li> <p>\"The tale I read to little Severian said that the universe was but a long word of the Increate s.(God) We, then, are the syllables of that word. But the speaking of any word is futile unless there are other words, words that are not spoken. If a beast has but one cry, the cry tells nothing; and even the wind has a multitude of voices, so that those who sit indoors may hear it and know if the weather is tumultuous or mild. The powers we call dark seem to me to be the words the Increate did not speak, if the Increate exists at all; and these words must be maintained in a quasi-existence, if the other word, the word spoken, is to be distinguished. What is not said can be important\u2014but what is said is more important. \"</p> </li> <li> <p>\"Time itself is a thing, so it seems to me, that stands solidly like a fence of iron palings with its endless row of years; and we flow past like Gyoll, on our way to a sea from which we shall return only as rain.\"</p> </li> <li> <p>\"All life acts to preserve its life\u2014that is what we call the Law of Existence. Our bodies, you see, die long before we do. In fact, it would be fair to say that we only die because they do.\"</p> </li> <li> <p>\"I have traveled far, and I have observed that poor people usually have more wit and more virtue than rich ones.\"</p> </li> <li> <p>\"No. I am saying that the things we love in others and admire in ourselves spring from things we do not see and seldom think about.\"</p> </li> <li> <p>\"All who speak Correct Thought speak well. Where then is the superiority of some students to others? It is in the speaking. Intelligent students speak Correct Thought intelligently. The hearer knows by the intonation of their voices that they understand. By this superior speaking of intelligent students, Correct Thought is passed, like fire, from one to another.\"</p> </li> <li> <p>\"I have no way of knowing whether you, who eventually will read this record, like stories or not. If you do not, no doubt you have turned these pages without attention. I confess that I love them. Indeed, it often seems to me that of all the good things in the world, the only ones humanity can claim for itself are stories and music; the rest, mercy, beauty, sleep, clean water and hot food (as the Ascian would have said) are all the work of the Increate. Thus, stories are small things indeed in the scheme of the universe, but it is hard not to love best what is our own\u2014hard for me, at least.\"</p> </li> <li> <p>\"There is no limit to stupidity. Space itself is said to be bounded by its own curvature, but stupidity continues beyond infinity.\"</p> </li> <li> <p>\"And what of the dead? I own that I thought of myself, at times, almost as dead. Are they not locked below ground in chambers smaller than mine was, in their millions of millions? There is no category of human activity in which the dead do not outnumber the living many times over. Most beautiful children are dead. Most soldiers, most cowards. The fairest women and the most learned men\u2014all are dead. Their bodies repose in caskets, in sarcophagi, beneath arches of rude stone, everywhere under the earth. Their spirits haunt our minds, ears pressed to the bones of our foreheads. Who can say how intently they listen as we speak, or for what word?\"</p> </li> <li> <p>\"The oarsmen were rowing a slow beat to get us around a leagues-long bend to a point where we could catch what little wind there was. The sound of the drum and the hissing of the water falling from the long blades of the sweeps are hypnotic, I think because they are so similar to the beating of one's own heart in sleep and the sound the blood makes as it moves past the inner ear on its way to the brain.\"</p> </li> <li> <p>\"We choose\u2014or choose not\u2014to be alone when we decide whom we will accept as our fellows, and whom we will reject. Thus an eremite in a mountain cave is in company, because the birds and coneys, the initiates whose words live in his</p> </li> <li> <p>\"forest books,\" and the winds\u2014the messengers of the Increate\u2014are his companions. Another man, living in the midst of millions, may be alone, because there are none but enemies and victims around him.\"</p> </li> <li> <p>\"Life is like a journey, filled with countless different experiences. Perhaps it is best to say that different experiences create different sceneries on that journey. If you experience bitterly cold wind, you will become snow. If you experience the blazing sun, then you become rain\u2026.The type of life you experience determines what type of person you will be. That is what makes life wonderful.\"</p> </li> <li> <p>\"In that moment, I understood that life is a journey. Every turn in the path leads to new scenery. My footprints exist on that path, and as to whether they are deep or shallow, it doesn't matter. All the decisions were mine to make.\"</p> </li> <li> <p>\"Why, such is love's transgression. Griefs of mine own lie heavy in my breast, Which thou wilt propagate, to have it pressed With more of thine. This love that thou hast shown Doth add more grief to too much of mine own. Love is a smoke raised with the fume of sighs; Being purged, a fire sparkling in lovers eyes; Being vexed, a sea nourished with loving tears. What is it else? A madness most discreet, choking gall, and a preserving sweet.\"</p> </li> <li> <p>\"I felt that pressure of time that is perhaps the surest indication we have left childhood behind.\"</p> </li> <li> <p>\"Weak people believe what is forced on them. Strong people what they wish to believe, forcing that to be real. What is the Autarch but a man who believes himself Autarch and makes others believe by the strength of it?\"</p> </li> <li> <p>\"There's a great deal said against Death. I mean by the people that has to die, drawin her picture like a crone with a sack, and all that. But she's a good friend to birds, Death is. Wherever there's dead men and quiet, you'll find a good many birds, that's been my experience.\"</p> </li> <li> <p>\"By the use of the language of sorrow I had for the time being obliterated my sorrow\u2014so powerful is the charm of words, which for us reduces to manageable entities all the passions that would otherwise madden and destroy us.\"</p> </li> <li> <p>\"A crowd is not the sum of the individuals who compose it. Rather it is a species of animal, without language or real consciousness, born when they gather, dying when they depart.\"</p> </li> <li> <p>\"I saw how little it weighed on the scale of things whether I lived or died, though my life was precious to me. And of those two thoughts I forged a mood by which I stood ready to grasp each smallest chance to live, yet in which I cared not too much whether I saved myself for not. By that mood, as I think, I did live; it has been so good a friend to me that I have endeavored to wear it ever since, succeeding not always, but often.\"</p> </li> <li> <p>\"If I had seen one miracle fail, I had witnessed another; and even a seemingly purposeless miracle is an inexhaustible source of hope, because it proves to us that since we do not understand everything, our defeats\u2014so much more numerous than our few and empty victories\u2014may be equally specious.\"</p> </li> <li> <p>\"Resolution and a plan are better than a sword, because a man whets his own edges on them.\"</p> </li> <li> <p>\"Form is empty. But it is full of everything else in the cosmos.\"</p> </li> <li> <p>\"The future is a blank sheet of paper. Only my will can leave footprints on it.\"</p> </li> <li> <p>\"This mind is my mind. It should be up to me to employ it- it should not go out following others.\"</p> </li> <li> <p>\"My destiny lies in my own hands, and I will never let others control my fate.\"</p> </li> <li> <p>\"First, you must be able to understand\u2026 what the Dao is! \"The Dao?\" Meng Hao gaped. Why is there life? Why is there death?\" The ancient voiced echoed back and forth endlessly. Why is there reincarnation? It's like a circle, with the head and the tail connected, but what exactly does that mean, and is reincarnation the only explanation? Why are there cultivators? Why are there cultivation Realms? Why is there Daoist magic? Why are there divine abilities? How does light shine? How does darkness descend? Metal. Wood. Water. Fire. Earth. What are the differences between these elements? Fire is fire, and yet, why are there different types of heat? What is heat? What is cold? What does it mean when something that can only survive in the ice can be burned to death by a single drop of water?\" The ancient voice spoke with increasing speed, causing Meng Hao's mind to tremble. Questions piled up in his mind. Each one seemed possible to answer directly, but if he actually had to answer them, he would be left speechless. \"What is the Dao?\" That was the final question uttered by the ancient voice, and it left Meng Hao's mind rumbling. The Essence is the Dao, the basis of everything that defies Heaven!\" A bright light shone in the middle-aged man's eyes, and he suddenly seemed very serious. All such unknowns are Essence. Only when you seek out the Essence, can you comprehend Heaven and Earth, understand all living things, and control everything! When you understand all transformations of Heaven and Earth, when you have defied the Heavens, when you have sealed the Earth, then what could possibly be difficult to you?!\"</p> </li> <li> <p>\"So long as there were benefits, forgetting favors to violate justice and not recognizing one's family were no less common than drinking water.\"</p> </li> <li> <p>\"A cultivator's talents and physique aren t enough; one also needs a strong Dao willpower, and a will strong enough to follow the road to the end. One day, he would be the last one smiling, and he would be the one to stand at the highest peak, looking down on humanity.\"</p> </li> <li> <p>\"The most important thing\u2026 was to have an unshakable Dao willpower; a willpower that thirsts for knowledge! A willpower that understands that the truth of all rivers flow into the same sea! A willpower that was diligent and assiduous! This was the most important thing! For insufficient talents, hard work would suffice as long as the mind was willing; for insufficient talents, others take one day to awaken, and you take one hundred days to awaken. There would always be a fruitful harvest. With a Dao willpower that could accept that all rivers lead into the sea, one could see the entirety of the eight directions and not be blinded by their own shortsightedness!\"</p> </li> <li> <p>\"Though I come from the mortal dust, my heart still soars towards the heavens. It was like the grass upon the desolate battlefield\u2026 It had to struggle to emerge from the dirt and grow up. It fought for every ray of sunshine, every drop of rain, because it wanted to grow higher and higher. It might be very low-key and unremarkable\u2026but not even the most exalted major powers of the Three Realms could stop the will and the heart of the grass. The heart was infinite and unlimited; even a beggar could have the heart and ambitions of an emperor. The power of the heart was invisible and formless\u2026but it was incomparably marvelous. Even mortals who had sufficiently powerful hearts and wills could create miracles. They would become heroes!\"</p> </li> <li> <p>\"When looking for a partner, one should look for everlasting feelings, for gentle feelings, for straightforward feelings, for feelings that makes them willing to commit. This factor will forever remain more valuable than money. To me, the perfect situation is when a person has accompanied the other throughout their growth. It doesn't depend on how much money that person can make, but in how that person can make your lives move forward, together, side by side.\"</p> </li> <li> <p>\"The heaven and earth is eternal. One day we ll meet again!\"</p> </li> <li> <p>\"Surrounded by bustling crowds, you look at me, I look at you, and we smile at each other.\"</p> </li> <li> <p>\"No matter what I lose, as long as I don t lose my life, as long as I am still alive, then there is hope for getting it all back. Life is the greatest hope of all. When you are alive, anything is possible!\"</p> </li> <li> <p>\"There were too many unfair things in the world. How many people understood the truth of matters? And the so-called characters of justice. They were the lies of certain people, yet how many people's eyes were blinded by them? Thus, he no longer cared about the world's opinion because the people of the world were stupid. They were unable to determine the truths and the lies. Thus, he only cared about the people he cared about. He, Chu Feng, did not live for the living of the world. He lived for himself and the ones close to him.\"</p> </li> <li> <p>\"I don t know what you re trying to protect, nor do I know what you have been hurt by. But, if you want to protect that child then do so with your chest held high! Here and now, be proud in knowing that you are protecting her! This is your life right? Then decide for yourself! If you want to protect everything with your hands then do so, if you want to abandon everything then do so. But, what do you yourself want, to do right now? Can you really be satisfied giving someone else that you don t really understand your most important thing?\"</p> </li> <li> <p>\"My goal cannot merely be to exceed any other person. My goal\u2026 for all eternity\u2026 will be to exceed myself!\"To constantly exceed myself, to continually break through my own barriers! I will always walk my own path, all the way to the end!\"</p> </li> <li> <p>\"That said, I only want to tell you one thing, treasure the people before you. If you really lose them one day, there won t be enough time for regret.\"</p> </li> <li> <p>\"Whether you speak of our time on earth, or reincarnation, life is a journey. The sea of bitterness is only one bit of scenery, that's all. The most important thing is to leave our mark on the path that we have walked and experienced. As for me, I want to keep walking even further off into the distance!\"</p> </li> <li> <p>\"Love cares what becomes of you because love knows that we are all interconnected. Love is inherently compassionate and empathic. Love knows that the \"other\" is also oneself. This is the true nature of love and love itself can not be manipulated or restrained. Love honors the sovereignty of each soul. Love is its own law.\"</p> </li> <li> <p>\"Until the tiger learns to write, stories will always glorify the hunter.\"</p> </li> <li> <p>\"Dare to think. Before your dream comes true, never limit yourself beforehand. Never find any excuses for yourself, or reasons to fail, only so will we have the possibility to make the seemingly distant dream reality.\"</p> </li> <li> <p>\"He realized that there are many ways of life, or many ways of living life. Perhaps there are meaningless ways, but nevertheless interesting ways.\"</p> </li> <li> <p>\"This silence belongs to us... and every single person out there, is waiting for us to fill it with something.\"</p> </li> <li> <p>\"Was I able to live inside someone's heart? Was I able to live inside your heart? Do you think you'll remember me at least a little? You d better not hit</p> </li> <li> <p>\"reset!\" Don t forget me, okay? That's a promise, okay? I m glad it's you, after all. Will I reach you? I hope I can reach you.\"</p> </li> <li> <p>\"Maybe... just maybe, the light can reach even the bottom of a dark ocean.\"</p> </li> <li> <p>\"So ephemeral and weak. But its shining with all its might. Thump, Thump, like a heartbeat. This is the light of life.\"</p> </li> <li> <p>\"You know, I discovered something. Everyone has something... Something deep inside their hearts. For some, it might have been enmity. For others, admiration. Wishes, a craving for the spotlight, feelings that one wants to deliver, feelings for one's mother. Everyone was supported by their own feelings. I realize now that, perhaps, no one can stand alone on stage.\"</p> </li> <li> <p>\"I am so afraid of disappointing the people I love, I often forget that I am someone I love too. And I need kindness just as much as I believe the people I love do.\"</p> </li> <li> <p>\"All the pieces of you that broke and shattered will become the seeds from which the finest parts of your soul will grow.\"</p> </li> <li> <p>\"You may feel small now, but so are all stars from a distance. You ll find someone who will come closer to see how bright you can truly become. They ll be the moon to your sun, reflecting your beautiful glow for the world to see. Just be patient, somebody is going to come around, take you to a whole different galaxy, and make you feel like the brightest one out of 100 billion stars that you are.\"</p> </li> <li> <p>\"If one chooses splendor, then they have to be able to withstand the bitterness and pain behind that splendor\"</p> </li> <li> <p>\"We had the wrong notion that stubbornness equated to love, but if there was love between us, why was there a need for stubbornness? Saying I don t love you would not affect the quality of love, as long as love exists, nothing will change, what more mere words?\"</p> </li> <li> <p>\"What are love roots? Just like a seed. Even if the roots are torn, they ll still grow back. The most important is the heart. Whether someone has love depends on their heart.\"</p> </li> <li> <p>\"Let us be nourished together, let us grow together, let us withstand this treacherous weather, experience wind and rain, and emerge to become even stronger than before.\"</p> </li> <li> <p>\"The end of the road brings fragrance, it fills the entire sea of snow.\"</p> </li> <li> <p>\"Water can make the boat move, but the boat can also be turned over by water.\"</p> </li> <li> <p>\"A lifetime is not a gentle dance, a dance is a lifetime of bitterness; I will dance for you in this lifetime, bitter or not I will dance a lifetime!\"</p> </li> <li> <p>\"The Heavens And Earth Do Not Shift, Neither Does The Stone Turn Amidst The Flowing River!\"</p> </li> <li> <p>\"The Way of the Heavens without love, then all things will be destroyed; The Way of the Heavens with love, then all things will be created. The Way of the Sword without love, kills people; The Way of the Sword with love, the heart values life. With love, without love, it depends on you. Nine lives, nine tribulations, without love is also with love. With love is without love; With love is also without love; Without love is also with love; With love, without love, the understanding is hidden within. That is the Way of the Heavens. With people, come martial arts, take martial arts to learn the Way of the Heavens, and in the end is transcendence. In the secular human world, the secret to the Way of the Heavens is also there. Human emotions, the root of the Way of the Heavens\u2026\"</p> </li> <li> <p>\"A horse enjoying the spring wind, runs faster. A person who encounters a happy event, has a clear state of mind. When elation rises, one's magnificence is boasted. A cheerful book, closes faster. The world is beautiful, life is full of hope, how can one scoff at that? Even if you want to, you cannot.\"</p> </li> <li> <p>\"Force is only effective in certain cases, just as ploy has its own limits. A group of kids can trap a rabbit, but cannot kill a tiger.\"</p> </li> <li> <p>\"Wind and rain cannot wipe the scars in our hearts, misery cannot destroy love; since ancient lightly, with separation do we know emptiness and desolation\u2026\"</p> </li> <li> <p>\"Mixing up the blue sky, and arrogantly laughing at the storm. Master the world with the universe within me.\"</p> </li> <li> <p>\"Things are never black or white but a million shades of gray.\"</p> </li> <li> <p>\"What good are wings, without the courage to fly?\"</p> </li> <li> <p>\"Poetry isn t good until you experience pain.\"</p> </li> <li> <p>\"The only way you will ever belong is when you feel complete without anyone reassuring you that you are.\"</p> </li> <li> <p>\"Do you really understand?\" he asked, his voice suddenly becoming very archaic as he attempted to imitate the way Zong Wuya had spoken and held himself moments ago. \"You know, just now, someone asked me what the Dao is. My answer was that the Dao relates to the thoughts in your heart. Whatever you focus your thoughts on, that is your Dao. The Dao is shapeless, and cannot be touched; it can only be contemplated, just like life.\" \"If you defined life as having different Realms, then that would be\u2026 the Natural Realm.\" \"Consider them,\" he said, gesturing toward the soldiers not too far off in the distance, and the cultivators from the Mountain and Sea Realm. \"Now consider yourself. \"Between humans, the only thing we do is compare ourselves to others, in any and all matters. We compare who has the highest cultivation base, who is richer, who has the better status, who has the higher position, who has the most power, who has the best family background, who is the smartest, or who is the strongest.</p> </li> <li> <p>\"The weak with the weak and the strong with the strong, all people are constantly comparing themselves to each other. Because of these comparisons, people covet what they do not have, and what they do have, they are even more unwilling to lose. \"That is another kind of life, and most importantly, that is the type of life\u2026 that most people live. I like to call such life the second Realm, the Pragmatic Realm! \"You are in that Realm, and so am I.\" \"So\u2026 is there a third Realm?\" she asked quietly.  \"Of course!\" Meng Hao looked over at her, his expression ever more archaic and his aura swirling even more mysteriously. His eyes glowed with bright light, like twin lamps on a moonless night.  \"The third Realm is \u2026 when you leave something behind,\" he said softly.  \"Are you willing to give that something up?\" he asked, shaking his head slowly. \"Do you accept letting it go? Are you even able\u2026to leave it behind? \"The third Realm is the realm of abandonment. After you have something, you abandon it, or perhaps you could say\u2026 put it aside!  \"Put everything aside, and you have emptiness. At that time, you\u2026 can finally explain what the Dao is!\" He took a deep breath and looked at Xue er, who was staring at him blankly. Suddenly, he raised his voice beratingly. \"Don t you get it?!  \"Consider the game board. What is it? That game board is your world, and in your heart, it is your everything. When all is said and done, it has borders, limitations, creating an intangible perimeter beneath your feet, an area in your heart that you cannot leave! \"If you don t put it aside, then you will forever remain in the second Realm. For all eternity\u2026 you will be unable to explain\u2026 the Dao!\" When she opened her eyes again, she asked, \"What is the name of thaty third Realm?\" His lips moved soundlessly for a moment, and then he calmly said, \"I call that Realm\u2026 the Dao!\"</p> </li> <li> <p>\"Well then, in your opinion, what is a Dao?\" Zong Wuya's expression was placid, but the reminiscence in his eyes grew even stronger as they continued to discuss the Dao.  Meng Hao didn t need to think about the answer. He immediately responded: \"The Dao is the obsession in your heart, the path that you choose to follow.\" \"In that case, what is your Dao?\"Freedom and independence!\" Meng Hao said, his voice filled with decisiveness that could sever nails and chop iron. \"Freedom. Independence\u2026.\" Smiling, Zong Wuya shook his head. \"What is freedom? And similarly, what is independence? Is freedom being free from all restrictions? Is independence an absence of all restraint? As you sit here in front of me, Heaven and Earth restrict you. The entire world restrains you. \"Look up, and you will see the sky. The sky weighs down on you. Beyond the Windswept Realm is the void, the Heavens. There are 33 Realms, all of them are also weighing down on you. Beyond those 33 Realms, are even more Realms and worlds. All of them are also pressing down on you.\" Although Zong Wuya spoke calmly, his words were as incisive as the stabs of a sword. They even seemed to be filled with a strange power, as if every word he spoke were completely and utterly correct. \"What about morality and principles,\" Zong Wuya continued, his wording growing more cutting. \"Are they not restraints? Can you ignore them? Can you trample on them? Where does your freedom come from? Where does your independence come from?\" His eyes glittered, and seemed to contain matchless wisdom.\"You are weak,\" he said, staring Meng Hao in the eye. \"When you meet powerful people, you have no freedom, nor any independence, not unless you are the most powerful person. However, the starry sky is wide, and the Heavens are vast. Perhaps when you think you are the most powerful person in existence, wouldn t you always be wondering if there might be other people over the horizon who also view themselves to be at the ultimate pinnacle?\" \"I\u2013\" Meng Hao was about to reply, but was cut off by Zong Wuya. \"You have an incorrect understanding of the Dao. Your freedom is not a Dao, it is an obsession of yours. And an obsession\u2026 is likewise not a Dao!\" \"If you can find someone like that, someone who you can hold and close your eyes to the world with, then you re lucky. Even if it only lasts for a minute or a day.\"</p> </li> <li> <p>\"If there's no suffering from pining, how can there be joy from reunion. Going too far will not accomplish anything. You will only value something if you get it after much suffering.\"</p> </li> <li> <p>\"As the saying goes, be aware of shame and move forward with courage! It is not scary to be in the wrong! What is scary, is that all of you are still unaware that you are in the wrong; showing satisfaction at your accomplishments, being prideful of your own self! This is simply unforgivable!\"</p> </li> <li> <p>\"If a beggar was to work hard, then he could leave behind a mark in history of a great general. A great general who does not work hard could also leave behind a mark in history, but that mark would be one of terrible losses and notoriety! In order to subdue others, and even the whole world, one must first be able to subdue themselves! This was the absolute minimal of conditions!\"</p> </li> <li> <p>\"Having a great deal of knowledge does not equate having a great deal of ability; most importantly, it does not equate having a great character! With just a glib mouth, how can one be considered a talent? These men have no significance at all\"</p> </li> <li> <p>\"And who are you, the proud lord said, that I must bow so low? Only a cat of a different coat, that's all the truth I know. In a coat of gold or a coat of red, a lion still has claws, And mine are long and sharp, my lord, as long and sharp as yours. And so he spoke, and so he spoke, that Lord of Castamere, But now the rains weep o er his hall, with no one there to hear. Yes now the rains weep o er his hall, and not a soul to hear.\" \"Because pride is a strange thing, and because generosity deserves generosity in return\"</p> </li> <li> <p>\"You see, women are like fires, like flames. Some women are like candles, bright and friendly. Some are like single sparks, or embers, like fireflies for chasing on summer nights. Some are like campfires, all light and heat for a night and willing to be left after. Some women are like hearthfires, not much to look at but underneath they are all warm red coal that burns a long, long while.\"</p> </li> <li> <p>\"To be stubborn, is to be unwilling to accept others. If you are unable to accept others then it means others will be unable to accept you. That way of thinking is dangerous.\"</p> </li> <li> <p>\"And then, we came to realize. All things happen abruptly. Bad things happen at times when you re unable to predict or prevent them. Suddenly parents can die, Suddenly your siblings can come to beat you up, Suddenly a truck can come to hit you, Suddenly you can be reincarnated in another world, Suddenly your father can come to attack you and then force you into being a home teacher for a young lady, Suddenly you could be thrown to another continent as well. Most likely everything is a result of chance. Furthermore, we would come to realize. The severity of this world. The fact that people can simply die. The fact that any person anywhere can all too easily die. The fact that there are no exceptions. Or the fact that only people in my surroundings aren t conveniently allowed to live long lives. Finally, at this late point. We finally came to realize this reality. The origin of the phenomenon known as death, the fact that a person nearby can suddenly disappear\"</p> </li> <li> <p>\"That's good, that's good, Kishirika said it as well. No matter the time you should just laugh! I remember, the last time Kishirika died as well and was laughing in a loud voice, fuhahahaahah!\"</p> </li> <li> <p>\"There's only one person in this vast world that we truly want to be together with. Even if things don t work out in our favor we can t help but wish for their happiness\"</p> </li> <li> <p>\"I spent my life trying to reduce the brain to a series of electrical impulses. I failed. Human emotion... It can contain illogical conflict. Can love someone and yet hate the things that they ve done. Machine can t reconcile that.\"</p> </li> <li> <p>\"For one hundred and thirty thousand years, our capacity to reason has remained unchanged. The combined intellect of the neuroscientists, mathematicians and engineers pales in comparison to the most basic A.I. Once online, a sentient machine will quickly overcome the limits of biology; in a short time, its analytic power will become greater than the collective intelligence of every person born in the history of the world. Some scientists refer to this as the Singularity. I call it Transcendence.\"</p> </li> <li> <p>\"We never lose our demons, we only learn to live above them.\"</p> </li> <li> <p>\"Death is what gives life meaning. To know your days are numbered and your time is short. You d think after all this time I d be ready. But look at me. Stretching one moment out into a thousand... just so that I can watch the snow.\"</p> </li> <li> <p>\"Wong: How's your Sanskrit? Dr. Stephen Strange: I m fluent in Google Translate.\"</p> </li> <li> <p>\"You think you know how the world works? You think that this material universe is all there is? What is real? What mysteries lie beyond the reach of your senses? At the root of existence, mind and matter meet. Thoughts form reality. This universe is only one of an infinite number. Worlds without end; some benevolent and life-giving, others filled with malice and hunger. Dark places where powers older than time lie, ravenous and waiting. Who are you in this vast multiverse?\"</p> </li> <li> <p>\"Live boldly. Push yourself. Don t settle. Just live.\"</p> </li> <li> <p>\"They say you only really appreciate a garden once you reach a certain age, and I suppose there is a truth in that. It's probably something to do with the great circle of life. There seems to be something miraculous about seeing the relentless optimism of new growth after the bleakness of winter, a kind of joy in the difference every year, the way nature chooses to show off different parts of the garden to its full advantage.\"</p> </li> <li> <p>\"You only get one life. It's actually your duty to live it as fully as possible.\"</p> </li> <li> <p>\"Some mistakes . . . just have greater consequences than others. But you don t have to let that night be the thing that defines you.\"</p> </li> <li> <p>\"I will never, ever regret the things I ve done. Because most days, all you have are places in your memory that you can go to.\"</p> </li> <li> <p>\"Not all love is good love.\"</p> </li> <li> <p>\"Life. How unpredictable and messy and beautiful it could be. I know; I can hardly believe those words are coming out of me without a hint of sarcasm (well . . . maybe a little)\"</p> </li> <li> <p>\"A single man in the world should have dominated everything! Even if I fail, at least I would have fought once. I may die, but with no regrets! A speck of dust, so what? A deadwood, so what? Life is inherently like a leaf living through autumn!\"</p> </li> <li> <p>\"It is always in this world, no matter where I live. There are always roads, no matter where I stand. Where do we sing and laugh; where do we weep and cry? \u2026\"</p> </li> <li> <p>\"The Dao exists in the heart, and the heart is born of the will. If your will is strong, then your Dao will be powerful, and your sword\u2026 will be invincible!\"</p> </li> <li> <p>\"We Cultivators don t just practice cultivation to gain eternal life. No, we pursue the Dao\u2026. For those who strive after the Dao, life is a morning and death is an evening. For those who seek the Dao, when evening comes, of what use is longing\u2026?\"</p> </li> </ul> <p>He was confused and murmured, \"Oh girls\u2026 Their thoughts are truly baffling\u2026\"</p> <ul> <li> <p>\"We have been companions. Swordmates. Bedmates. But in many things we are strangers to one another, afraid to trespass where emotions may not be wanted. Having been locked so long in service to oneself, each of us, it is difficult to turn the key and unlock ourselves, saying the things we desire to say, to share the things that should be shared.\"</p> </li> <li> <p>\"Women: they tend you or terrorize you.\"</p> </li> <li> <p>\"Skepticism is healthy. It keeps you from growing vulnerable to words of manipulation. Disbelief, in its place, is also occasionally healthy, because the proper amount keeps you honest.\"</p> </li> <li> <p>\"Men are fools when it comes to women. It doesn't matter how smart you are, or how shrewd, or how much experience you ve had. They re all born knowing just what it takes to find a way to muddle up your head. And given the chance, they do. I ve known men who bed only whores, wanting to make no better commitment, saying it's the best way to avoid entanglements. I ve known men who marry women so as not to buy the bedding. And I ve known men who do both: bed whores and wives; sometimes, with the latter, their own. I ve even known men who swear off women altogether, out of zeal for religious purity or desire for other men; neither appeals to me, but I ll curse no man for it.  And certainly, in the South, I ve known men who have no choice in the matter of bedding women, having been castrated to serve tanzeers or anyone else who buys them. But I ve known no man who, drunk or sober, will not, at least once, curse a woman, for sins real or imagined. A woman; or even women.\"</p> </li> <li> <p>\"Grunting, I sat up. Tried to stretch muscles and pop joints without waking her, because no man likes a woman to see how he's growing older, how the years are taking their toll.\"</p> </li> <li> <p>\"Do not apologise for existing. For being yourself. Apologise when you are not.\"</p> </li> <li> <p>\"A dunce once searched for a fire with a lighted lantern. Had he known what fire was, he could have cooked his rice sooner.\"</p> </li> <li> <p>\"Since life is full of painful things after all. Even if it's forcibly, if you don t create some good times then you'll be crushed.\"</p> </li> <li> <p>\"After careful study,\" he began softly, \"I have come to find that the Dao of Heaven and Earth, and one's own Dao, is a willful return to one's natural state\u2026.\" He had chosen to bestow some good fortune upon the cultivators of the Southern Domain, both as a means of thanking them for caring for his former residence, and also\u2026 for the mere fact that he felt this place to be his home. It was different than Planet East Victory.  \"Therefore, cultivation is also known as cultivating truth. Of the two characters which make up the latter term, the first refers to the method, the second refers to the mental state\u2026.\" His voice seemed to contain a bizarre power that caused it to spread out in all directions, causing every audience member, regardless of the level of their cultivation base, to slip into a strange, trance-like state. \"Simply put, it is very similar to how I once described to someone the different Realms of life.</p> </li> <li> <p>\"In the past, various people have asked me what the Dao is\u2026. My responses have varied depending on the occasion, the circumstances, and the level of my cultivation base. In fact, every single time, I gave a different answer. I m not even sure what my answer will be the next time someone asks me. \"However, there is one thing that will never change, as far as I can tell. And that is\u2026 that I don t know what the Dao is. There are too many answers to the question. All I know\u2026 is that what I am pursuing is freedom and independence. To be free and unconstrained. That is my truth, and that is my Dao! \"In cultivating truth, what we cultivate\u2026 is the heart.\" Meng Hao's voice reverberated out as he expounded upon his understanding of the Dao, and the enlightenment he had gained regarding cultivation. The words he spoke were like seeds that became buried in the hearts of the various cultivators. \"If your heart is steadfast, it cannot be trampled by Heaven or Earth, nor can it be broken by any living thing. You will never bow your head in acquiescence, and you will be able to advance without hesitation, and you will never stop moving forward. This is the meaning of cultivating the heart and cultivating the truth. It is traveling along the path of cultivation itself. \"My life has been spent practicing cultivation. I started in the Qi Condensation stage, and now here I am, having experienced numerous twists and turns. I will merge my body, my mind, and my soul into an image which will become like a spirit in your heart. Observe it. Contemplate it. It can become the truth, the path, and the heart which you cultivate!\"</p> </li> <li> <p>\"Spock: Fear of death is illogical. Bones: Fear of death is what keeps us alive.\"</p> </li> <li> <p>\"Who can understand the reason for human life? Creation and destruction, there's no need for sorrow.\"</p> </li> <li> <p>\"As we look back upon history, we will often find that under the surging current of history, even the wisest leaders find it hard to keep their heads over water.\"</p> </li> <li> <p>\"When you re doing well, all people around are opportunists, but it's when you are in a bad position in life then you know who your real friends are, who are genuinely fond of you and would support you for who you are.\"</p> </li> <li> <p>\"Above the heavens, the stars rotate. The magnificence of the galaxies nourish everything. The heavens can cover it but not contain it; the earth can contain it but not cover it. The universe can accommodate it but not refute it knowing that everything has its place and limitation\u2026 Heaven and earth turn and rotate as everything returns to the universe.\"</p> </li> <li> <p>\"With my heart, I shall master the way of the universe; with my heart, I will calm my mind. I will cultivate my mind and control my heart with my mind!\"</p> </li> <li> <p>\"Life is too short, if I don t do something great, how could I feel worthy of my parents who raised me?\"</p> </li> <li> <p>\"If you would take a man's life, you owe it to him to look into his eyes and hear his final words. And if you cannot bear to do that, then perhaps the man does not deserve to die.\"</p> </li> <li> <p>\"We all think of a special someone from dawn to dusk and back again. Hopefully someday we ll find our way to that person and spin our own tale of happiness.\"</p> </li> <li> <p>\"On the days when you feel ashamed of your scars, your mind only registering how ugly they are rather than the beauty they prove of you having survived, remember that there is an entire art form dedicated to filling the cracks of broken things with lacquered gold. An entire art form that proves that even the broken and damaged history of an object is beautiful and should be treasured. Remember how much more you are than an object. Remember your survival, your journey, your scars deserve to be treasured too.\"</p> </li> <li> <p>\"How can love be as calm and still as water? Hurting and being hurt. How can it stay the same forever? Even if wounded. Even if in conflict with other people. Even so this feeling fading away is impossible. No longer fearing being selfish. No longer fearing repercussions. That is liking someone.\"</p> </li> <li> <p>\"A man has but one life, grass but one spring, so if death comes then so be it!\"</p> </li> <li> <p>\"The heart is the limit.\"</p> </li> <li> <p>\"In both worlds, when many people discover that they lack the ability to accomplish their dreams, they will feel lost, disappointed, disjointed, and inferior. Many of them will resort to immersing themselves in great pain, imagining success, going into isolation or hoping to go back to the past. It is not wrong for a person to walk on a single path. Suffering may be brought to those around this person but eventually, this person may succeed. However, the people who have the determination to immediately choose a new way deserve even more respect. Life is interesting because picking another road of life requires more determination and bravery than continually walking on the same path.\"</p> </li> <li> <p>\"To think about the past bring out the pain and cry that penetrates the heart and mind. but it must be endured. He has yet to succeed but has already drank the poison. He endured it all. No words can be written to express my thought\"</p> </li> <li> <p>\"The end of religion is the beginning of spirituality. At the end of spirituality is reality. The end of reality is the real bliss.\"</p> </li> <li> <p>\"Today we find so many sects and creeds, each worshipping its own god or goddess in its own particular way. Evidently the goal</p> </li> </ul> <p>before their eye is not even liberation but in most cases deliverance from some particular form of misery or some material gain.\"</p> <ul> <li> <p>\"The time you feel alone is the time you most need to be by yourself.\"</p> </li> <li> <p>\"Earth teach me to forget myself as melted snow forgets its life. Earth teach me resignation as the leaves which die in the fall. Earth teach me courage as the tree which stands all alone. Earth teach me regeneration as the seed which rises in the spring.\"</p> </li> <li> <p>\"Our Lord has written the promise of resurrection. Not in books alone but in every leaf in springtime.\"</p> </li> <li> <p>\"The world is a cruel place. So go out there and make it a little less so.\"</p> </li> <li> <p>\"It's incredibly pretentious how man can think it has power over every other living being. It's possible that no species can be controlled at all. And like that. You have to respect every form of life. Man protects other species for fear of loss. He protects the environment thinking that's how he ll survive. And he's just being selfish. But not that there's anything wrong with that. It's actually necessary. We can t Belittle any species at all.\"</p> </li> <li> <p>\"The natural state of life is desire and disorder. There is no such thing as a completely transparent soul. Not even cultivating the Dao can make one's Dao heart spotlessly pure. On the contrary, her spirit is more complex than you could have imagined.\"</p> </li> <li> <p>\"A small, small world with two small birds playing with fire. Ants praise how great their countries are and discuss how easy it is to shake a big tree.\"</p> </li> <li> <p>\"We are one infinite tree in an infinite forest.\"</p> </li> <li> <p>\"But no afterlife,\" grumbled the king. \"No eternal soul? It's unnatural. \"On the contrary,\" said Kell. \"It is the most natural thing in the world. Nature is made of cycles, and we are made of nature. What is unnatural is believing in an infallible man and a nice place waiting in the sky\"</p> </li> <li> <p>\"Mountains have no worries, til hit with snowy flurries; waters feel no woe, til the winds do gust and blow\u2026.\"</p> </li> <li> <p>\"Before she became ill, David's mother would often tell him that stories were alive. They weren t alive in the way that people were alive, or even dogs or cats. People were alive whether you chose to notice them or not, while dogs tended to make you notice them if they decided that you weren t paying them enough attention. Cats, meanwhile, were very good at pretending people didn t exist at all when it suited them, but that was another matter entirely. Stories were different, though: they came alive in the telling. Without a human voice to read them aloud, or a pair of wide eyes following them by flashlight beneath a blanket, they had no real existence in our world. They were like seeds in the beak of a bird, waiting to fall to earth, or the notes of a song laid out on a sheet, yearning for an instrument to bring their music into being. They lay dormant, hoping for the chance to emerge. Once someone started to read them, they could begin to change. They could take root in the imagination, and transform the reader. Stories wanted to be read.\"</p> </li> <li> <p>\"The world of the old tales existed parallel to ours, but sometimes the wall separating the two became so thin and brittle that the two worlds started to blend into each other.\"</p> </li> <li> <p>\"We all have our routines,\" he said softly. \"But they must have a purpose and provide an outcome that we can see and take some comfort from, or else they have no use at all. Without that, they are like the endless pacings of a caged animal. If they are not madness itself, then they are a prelude to it.\"</p> </li> <li> <p>\"She giggles. \"Thanks.\" \"I haven t done anything yet.\" She looks at me like I m the best person in the world, and I can t really take that. Makes me want to be a total smart-ass. \"You always say that.\" Her voice is sort of sad, like she d hoped she could have changed me already. \"Maybe thanks should be given just for being willing to do something for someone else?\"</p> </li> <li> <p>\"We are like the water. Salty. Stubborn. Frothy and rolling and scary all at once. We are like the sea. Calm and still and alive. Changing all the time. We have been alive forever. Long before our bodies were born. Long after our bodies will die. We will live forever, our waters mixing with the waters of others. All of us tossed together beneath the stars. Beneath that constellation you call your own. The sea monster one that looks down on us here on earth and knows all about us. Me and you and all the others, married and mixed in the ocean. Churned together.  Can I walk out into the water? If I say we are eternal, will you let me go? Let me slip into the sea, alone as I came into this world?\"</p> </li> <li> <p>\"But talent is not enough to protect yourself. You might face a disaster before you mature. It's because an elephant has tusks, while a rhinoceros has a horn that they are hunted.\"</p> </li> <li> <p>\"If you believe everything you read, you better not read.\"</p> </li> <li> <p>\"You have to be broad-minded. If you want your life to be good, you will need to have some tolerance. If you are too ruthless and extremely self-centered, and intolerant with others, sooner or later, it will destroy you.\"</p> </li> <li> <p>\"During the primitive periods, a group of cavemen worshipped a shadow. The shadow could grow bigger and smaller. It looked like a god, so the cavemen would worship the shadow every day. However, a clever caveman did not believe in god . With great effort, he managed to climb to the top of the cave one day. He then realized that the god the people worshipped was just the shadow of a rock being cast by the sunlight. The clever caveman told his tribe the truth, he did not want them to worship the shadow, because it was just the shadow of a rock and not a god. In the end, no one believed the clever caveman, but they became scared. The clever caveman was eventually burned at the stake because of his blasphemy against the god. After that, the cavemen carried on worshipping the rock's shadow.\"</p> </li> <li> <p>\"The mushroom knows not the alternation of day and night, while the short-lived cicada does not know the seasons. If one were to see the vast world yet not explore it, turning to dust hundreds or thousands of years later, then what difference was there between them and the mushrooms and cicadas?\"</p> </li> <li> <p>\"So what?\" The Shepherd Boy stroked his piccolo. \"All sorts of natural living things support the survival of humans, yet humans have never reciprocated that to the Heavens. Humans have accepted the gifts from nature, but what they consider is forever their own interests.\"</p> </li> <li> <p>\"You have extracted from nature without constraint, and with your trillions of people, you have extracted even more. To survive, are you not killing living beings every second and every moment? And the numbers you kill are far greater in number than the number of humans. The world is heartless, it treats everything as lowly beings. In front of a stronger power, humans are no different from pigs and dogs. You can kill other living beings because you are strong. If other living beings kill you, it is because they are stronger. You can say that this is part and parcel of the divine law of survival of the fitness. Not only you, even large worlds can collapse\u2026 formation, existence and then destruction, it is all a part of the divine laws.\"</p> </li> <li> <p>\"Yi Yun\u2026 why do you think\u2026 war exists?\" During the flight, Luo Huo er suddenly asked faintly. She was looking out the window at the Divine Wilderness with a dazed expression. If it was not for war, she would not have left her family clan. And if was not for war, lives would not be lost. Yi Yun stayed silent for a while before saying, \"The fighting between humans is the same as animals hunting each other for food. It will always be this tragic. Maybe real peace will never exist. This is because for Life to exist in this world, it has to continually hunt for food. Only through non-stop killing can Life carry on. Those are the Heavenly laws. Either we become the hunter or we will become the prey. There is no way to escape this cycle. Even in death, our corpses might become food or nutrients, continuing on this cycle\u2026 This is probably the hallmark of Life\u2026\"</p> </li> <li> <p>\"Humans were a complex life form. They had their jealousy, machinations, betrayal and contempt. But in troubled times, there were many who would sacrifice their lives for justice. They achieved honor by martyring themselves. They were willing to sacrifice themselves, at the expense of their lives for freedom and all life.\"</p> </li> <li> <p>\"The ways of the world are full of vicissitudes, and in it, there is the grief at separation and joy in union, the suffering of life and death. No matter how thick a history book is, it would not be able to record everything down. However, it is such infinite matters of the past that can pass by with a finger snap. In one's old age, while looking back at the past, only then would you feel like everything was ephemeral\"</p> </li> <li> <p>\"Live for the moments in life when everything's going by slow yet all too fast, when you re at peace with yourself because you re spending it with the people you love or simply just with yourself. Whether it's reading, writing, going on a walk, late night phone calls, jamming, going on dates, bookstores\u2026 live for the fact that this isn t going to happen everyday but will in fact happen again. Live for this. For the simple things, the good hours. The hours when nothing hurts near as bad as it did last night when you were sobbing for hours because nobody was there to hold you, to simply tell you that it will all be okay. Live for the hours when you can breathe again. When you look around you and see why you held on for so long even when everything inside you begged you to quit.\"</p> </li> <li> <p>\"I have convinced myself that there is nothing in the world \u2014 no sky, no earth, no minds, no bodies. Doesn t it follow that I don t exist? No, surely I must exist if it's me who is convinced of something. But there is a deceiver, supremely powerful and cunning whose aim is to see that I am always deceived. But surely I exist, if I am deceived. Let him deceive me all he can, he will never make it the case that I am nothing while I think that I am something. Thus having fully weighed every consideration, I must finally conclude that the statement \"I am, I exist\" must be true whenever I state it or mentally consider it.\"</p> </li> <li> <p>\"There's always something new to learn\u2026.\" he murmured. \"The further you travel, the more you see and experience. It's only then that you realize that there are Heavens beyond what you imagined could exist, and likewise, people who exceed your imagination\"</p> </li> <li> <p>\"Correct, it is conscience. The world of mortals is a large vat. If one is pure and honest, then they will dye the human world with color. To lose your conscience is to be weak willed and give in to the temptations of money and power. If a Saint Ruler wishes to progress in improvement, they must continue to try and comprehend the profound mysteries of the world. One's attitude toward the profound mysteries of the world must be calm and be able to withstand any of the worldly temptations. Once the soul is as close to the world as possible, that is when the comprehension of the profound mysteries of the world come even faster. If one is swayed by the worldly temptations, then they would be stuck in a game like Go. No matter where you go and no matter how much you try to harmonize with the world, it will be impossible to comprehend the profound mysteries of the world. If one cannot regain their conscience, then there can be no progress.\"</p> </li> <li> <p>\"The problems of a woman's mood could only ever be solved by the passage of time. In many cases, they simply felt aggrieved and sad and want to cry, so it was for the best to just let them cry. Accompanying them involved offering a handkerchief when necessary or proffering a shoulder when needed, but it certainly did not require sitting on the side with an incessant stream of consoling words. When they still did not calm down and did not feel like talking, anything you did was just making more trouble.\"</p> </li> <li> <p>\"If you find yourself stuck in a ditch or forsaken by the world, don t panic. Take two steps forward and maybe you'll find yourself stronger than ever before.\"</p> </li> <li> <p>\"Some people would be strangers forever, whereas others would seem like old friends from the onset. Although they were strangers that had not exchanged many words and hadn t even exchanged names, they could entrust their lives and possessions to each other. You only needed to see what sort of person they were, see how much trust they placed in you, and then you would be willing to place some trust in them in return.\"</p> </li> <li> <p>\"This is the extremity of human personality. Should you face a hopeless situation in the future, don t show your back to those that you cannot trust. Because you never know if a sword that you did not expect would stab into your chest\u2026\"</p> </li> <li> <p>\"Ah\u2026 be more careful boy. There's a knife above lust\"</p> </li> <li> <p>\"Character was not something that could be tested. For each test, there was a high chance that the relationship would take one step backwards. Similarly, trust was not something that could be used. Each use of trust was to pare away at it.\"</p> </li> <li> <p>\"In the desert, the fierce beasts that bear their fangs and brandish their claws were not frightening. The ones that were frightening were those poisonous snakes that quietly conceal themselves under the yellow sand. They would not easily display their fangs. However, once the opportunity arrived, a lethal strike would instantly shoot out of the yellow sand\u2026\"</p> </li> <li> <p>\"As I said, there is no perfect being in the world at all. Just being imperfect and being worse than others can cause a feeling of inferiority\u2014is that not absurd? The Pope's ability in maintaining bonsais is not as good as the gardeners in the Hundred Herb Garden, so should he feel ashamed? The Divine Empress's needlework is not as great as the needlework of the female workers in Wenshui City, so should she also feel ashamed?\" Xu Yourong slightly raised an eyebrow and said, \"What I was talking about was the attitude towards life. Only with such an attitude can you become even more perfect.\" Chen Changsheng shook his head. \"I am not saying that you should not adopt this type of attitude. It is just that, if you really think this way, have you never considered that nobody can be perfect before reaching the final moment of their lives, even if they constantly try their best? Since victory or defeat has not even been determined, why must we feel ashamed beforehand?\" \"As for inferiority, that is even more impossible.\" He pulled out a just-cooked tuber from the fire and passed it to her, exchanging for her ferret meat that had gone slightly cold. He continued, \"Not being able to do it now does not mean that you are unable to do it in the future, and even if it is not done, what of it? Working hard should be caused by your inner desire, and should not come from the disparity from comparing yourself with others. As long as you really try hard, it is enough.\" Xu Yourong stayed silent. It was not known what she was thinking of. Chen Changsheng spoke again, \"I think that you should think it through. The hopes of other people on us are not important at all; what is actually important is what we hope ourselves to do. Aren t people supposed to live for themselves?\" Xu Yourong raised her head and glanced at him.  Chen Changsheng understood what she meant and said, \"The responsibilities we should shoulder obviously should be shouldered, but when living, we should live for ourselves. Also, the latter should occur before the former.\" Xu Yourong thought about it and said, \"I am unable to understand.\" Chen Changsheng thought a little and said while laughing, \"I am only speaking casually.\" Through this conversation, he discovered that this girl was like a hedgehog in the forest, defending against something at all times. It was easy to injure the flowers and plants, as well as the helping hands, and it was also easy to injure herself. Under her calm, unhurried, indifferent and strong outward appearance, she was actually so sensitive and tenuous. Before when he mentioned perfection, he was just speaking in her words. In reality, he had never even thought about it. He felt that her way of thinking was very weird, which was why he felt that she had an illness\u2014just what ordinary person would set perfection as the aim of existence? Once realising that it was impossible to reach complete perfection, would they not fall into depression and self-deprecation? \"What you say sounds somewhat reasonable, which perhaps can cause life to become slightly less complicated, but\u2026\"Xu Yourong hesitated a little, and then asked for guidance, \"The education that I have received since childhood makes me unable to accept your point of view. How should I face up against this type of pressure?\" Chen Changsheng pointed towards the tuber in her hand, and said, \"Eat first while it's warm. We can talk casually.\" Xu Yourong listened to what he said and tore open the slightly burnt outer skin of the tuber. A faint fragrance spread out.Chen Changsheng said,</p> </li> <li>\"Firstly, we need to know what we want to do the most; the reason why we live.\" Looking at her expression, he said hurriedly, \"Don t say the word perfection again\u2014using perfection to describe the level is not concrete.\" Xu Yourong thought about it and said, \"What I want to do most is cultivate.\" \"Then cultivate,\" he said. Xu Yourong felt slightly unhappy, thinking, was he not fooling with people? Chen Changsheng explained, \"Other than cultivate, you don t want to do anything else.\" Xu Yourong said, \"But those things still exist.\" Chen Changsheng said,</li> <li>\"Close your eyes and the sky goes dark. If you can t see the world, the world doesn't exist.\" Xu Yourong said, \"That is only speaking idealistically. How can it persuade people? Also, cultivation is only a method, and not a purpose.\" Chen Changsheng looked and her, and thought about everything he saw and heard on the journey. He said, \"If I am not wrong, your purpose for cultivation should be\u2026 in order to become stronger?\" Xu Yourong said, \"Only with enough strength can you shoulder the responsibilities you should shoulder.\" Chen Changsheng said somewhat impatiently, \"Can we forget the word responsibility for a moment?\" Xu Yourong said sternly, \"I wouldn t possibly dare to overlook this for even a moment.\" Chen Changsheng thought seriously and then said, \"Then I recommend that before you become the strongest person, temporarily forget this goal, and put all your energy into the method, cultivation.\" Xu Yourong said, \"Without an objective, how am I able to advance without worry?\"</li> </ul> <p>Su Li smiled coldly, \"Do you really believe that everything can be calculated?\" Black Robe said, \"Why not?\" \"You obviously know that the stars can be moved. Since the stars can be moved, where does it say that fate cannot change? With change, how can you calculate? Su Li gazed at the night sky. He did not see the convergence of those two rivers of stars in the south, and only saw the snowflakes that constantly fell before the shadow. With a soft voice, he said, - \"Everything in the world is constantly changing. After a long time of snowing, accumulating more and more, there will always be a moment where an avalanche occurs. How do you calculate that?\"</p> <ul> <li> <p>\"People are sometimes like clothes. You shop for one piece... you try it on and it fits you perfectly. Sometimes you may fall in love with how it looks and feels on you. But there is no guarantee it is going to stay that way.\"</p> </li> <li> <p>\"Clay jars always break by the well; generals always die in battles. Onlookers always see better than the players; to really quit at the height of one\u2019s career is far easier said than done\"</p> </li> <li> <p>\"All dreams are but another reality\"</p> </li> <li> <p>\"Those whose memories fade seek to carve them in their heart.\"</p> </li> <li> <p>\"Sometimes, he would sit on a boat and just watch the waters of the river flow past him. Sometimes, he would stand on the peak of a mountain, head raised as he stared at the dark stormclouds in the skies, presaging the arrival of a rainstorm. Sometimes, he would rest within an ancient monastery, watching as storms of rain descended upon the world outside. Sometimes, he would soar atop the clouds, watching the waves roll and spin about through the ocean. Water\u2026it could sometimes be gentle, like a mother's  caress. Water\u2026it could be as cold as ice, capable of chilling you to the bone. Water\u2026it could be utterly devastating, capable of shattering Heaven and Earth. Water\u2026it could be joyful, dancing and drifting about the skies.\"</p> </li> <li> <p>\"A thousand ages in thy sight Are like an evening gone; Short as the watch that ends the night Before the rising sun.\"</p> </li> <li> <p>\"Oh Child, other people don't even treat you as a person, but you on your own must work for improvement! Get Well!\"</p> </li> <li> <p>\"If it weren\u2019t for the fact that I read along when the teacher was reading out text, others would ve thought that I had turned into an idiot again. It wasn\u2019t that I couldn\u2019t speak, it was that I chose not to speak. The things I had on my mind, weren\u2019t understandable by my classmates, and what they had to say was simply not interesting to me.\"</p> </li> <li> <p>\"Everybody has a different understanding of happiness. Some people, even while living a life of luxury, feel sad, while other people eating mustard for three meals a day, can feel happy. Happiness is not gotten from eating good food, or wearing good clothes. This age of you all is the age of enjoyment and growth, Teacher also hopes that you are also able to cherish everything around you. Study hard and in the future show a lot of filial love for your close ones\"</p> </li> <li> <p>\"When women are happy, they will laugh, when they are unhappy, they will also laugh. Making me, a child, distinguish between them, isn\u2019t that just plain bullying?\"</p> </li> <li> <p>\"Truly, human beings die in pursuit of wealth, and birds die in pursuit of food\"</p> </li> <li> <p>\"Water flows on in a turbulent stream, capable of supporting a boat but also capable of capsizing it. But if the boat is too big\u2026the water can only endure\u2026\"</p> </li> <li> <p>\"What a wonderfully complex thing! this simple seeming unity\u2014the self! Who can trace its reintegration as morning after morning we awaken, the flux and confluence of its countless factors interweaving, rebuilding, the dim first stirrings of the soul, the growth and synthesis of the unconscious to the subconscious, the subconscious to dawning consciousness, until at last we recognise ourselves again. And as it happens to most of us after the night\u2019s sleep.\"</p> </li> <li> <p>\"The most powerful act is thought, the highest function is focus, the most positive mind is the absolute will, the universe is beneath the subconscious, nothing is impossible, enable the motivation, inspire the spirits\u2026\"</p> </li> <li> <p>\"Lemme tell ya, if you want to give a kid something, you can\u2019t give them something too good, right off the bat. Otherwise, in the future, they ll expect something really good every single time, or something even better.\"</p> </li> <li> <p>\"Ninny, tell me, why are you girls so beautiful and yet so foolish?\" Bebe sat there on the chair, staring at the nearby Nisse. Nisse considered for a moment, then immediately said, \"Oh, I know.\"Nisse wrinkled her little nose, then said,</p> </li> <li> <p>\"Women are beautiful so as to let you men fall in love with us. As for why women are foolish\u2026it\u2019s to make me fall in love with you!\" Bebe stared. \"You are foolish, thus you fell in love with me?\" If I wasn\u2019t foolish, why would I fall in love with you?\" Nisse had an innocent, puzzled look on her face. \"Oh!\" Irritated, Bebe slapped his head. Why was it that he could never overcome Nisse in these debates?\"</p> </li> <li> <p>\"Water will flow downwards, and man will walk towards higher grounds. This has never changed.\"</p> </li> <li> <p>\"Kid, sometimes, working hard endlessly is not the correct way. If your nerves are too tense, your failure rate might increase. If you are too urgent in pursuing success, it usually has the opposite effect.\"</p> </li> <li> <p>\"Sometimes, by setting something aside first and calming your heart, diverting your attention somewhere else, and forgetting it momentarily, you\u2019ll often find some unexpected rewards when you pick it up again and resume.\"</p> </li> <li> <p>\"Cesar, we\u2019ve lived so many years, and have seen countless things! Our life is important, but sometimes, there are some things which are more important than life!\"</p> </li> <li> <p>\"Worlds and oceans evaporate in eternity. Man rises out of the darkness, laughs in the glimmering light and disappears.\"</p> </li> <li> <p>\"I can see you have a reply\u2014I see it in your eyes, young miss! Spit it out. Words aren\u2019t meant to be kept inside, you see. They are free creatures, and if locked away will unsettle the stomach.\"</p> </li> <li> <p>\"One cannot apply logic as an absolute where human beings are concerned. We are not beings of thought only.\"</p> </li> <li> <p>\"Well, I myself find that respect is like manure. Use it where needed, and growth will flourish. Spread it on too thick, and things just start to smell.\"</p> </li> <li> <p>\"The time will come when, with elation, you will greet yourself arriving at your own door, in your own mirror, and each will smile at the other\u2019s welcome, and say, sit here. Eat. You will love again the stranger who was your self. Give wine. Give bread. Give back your heart to itself, to the stranger who has loved you all your life, whom you ignored for another, who knows you by heart. Take down the love letters from the bookshelf, the photographs, the desperate notes, peel your own image from the mirror. Sit. Feast on your life.</p> </li> <li> <p>\"I hate to be where she is not, when she is not. And yet, I am always going, and she cannot follow.\"</p> </li> <li> <p>\"One of the things I love about books is being able to define and condense certain portions of a characters life into chapters. It\u2019s intriguing, because you can\u2019t do this with real life. You can\u2019t just end a chapter, then skip the things you don\u2019t want to live through, only to open it up to a chapter that better suits your mood. Life can\u2019t be divided into chapters...only minutes. The events of your life are all crammed together one minute right after the other without any time lapses or blank pages or chapter breaks because no matter what happens life just keeps going and moving forward and words keep flowing and truths keep spewing whether you like it or not and life never lets you pause and just catch your fucking breath.\"</p> </li> <li> <p>\"What is it? My dear? Ah, how can we bear it? Bear what? This. For so short a time. How can we sleep this time away? We can be quiet together, and pretend\u2014since it is only the beginning\u2014that we have all the time in the world. And every day we shall have less. And then none.\"</p> </li> <li> <p>\"Would you rather, therefore, have had nothing at all? No. This is where I have always been coming to. Since my time began. And when I go away from here, this will be the mid-point, to which everything ran, before, and from which everything will run. But now, my love, we are here, we are now, and those other times are running elsewhere.\"</p> </li> <li> <p>\"Exists no miracle mightier than this: to feel\"</p> </li> <li> <p>\"One of the most amazing things about young adulthood is that it\u2019s a time that\u2019s chock-full of firsts. Some wonderful and some\u2026not so wonderful.\"</p> </li> <li> <p>\"A lot can change between planning something and actually doing it. But maybe all that really matters is that anything is different at all.\"</p> </li> <li> <p>\"The only ones who deserve you are the ones who think they don't.\"</p> </li> <li> <p>\"There are a lot of things which look boring from the outside but when you really get into it you find that it was actually a lot of fun. This is investing yourself in life.\"</p> </li> <li> <p>\"Authority doesn\u2019t come from a rank,\" Kaladin said, fingering the spheres in his pocket.  \"Where does it come from?\" \"From the men who give it to you. That\u2019s the only way to get it.\"</p> </li> <li> <p>\"People are discord,\" Syl said.  \"What does that mean?\" \"You all act differently and think differently. Nothing else is like that\u2014animals act alike, and all spren are, in a sense, virtually the same individual. There\u2019s harmony in that. But not in you\u2014it seems that no two of you can agree on anything. All the world does as it is supposed to, except for humans. Maybe that\u2019s why you so often want to kill each other.\"</p> </li> <li> <p>\"What you said earlier is right; men are unreliable in many things. But if there\u2019s one thing you can count on, it\u2019s their greed\"</p> </li> <li> <p>\"Numbers remained consistent. Numbers and facts attempted to bring order from a chaotic world, to make sense of the impossible. They were the foundation for colossal structures and the tiniest of clockwork machines alike. Ari loved numbers, and not just because they saved her life by keeping her alert in her surroundings.\"</p> </li> <li> <p>\"He swipes a hand in front of his face like a bear swatting at a fly. \"There are some things we lose, and it\u2019s a tragedy,\" he says. \"Then there are other things. Things we probably should have gotten rid of a long time ago.\"</p> </li> <li> <p>\"Grandpa Ike nods. \"See? Nobody blames you.\" I take a shuddering breath. \"Then why do I still blame myself?\" He sighs. \"Sometimes we hold on to guilt or grief because it\u2019s the last thing we have that ties us to the person we miss. We don\u2019t want to let them go because it feels like we\u2019ll have nothing left. But it\u2019s dangerous, Ethan. The never letting go. Because until you let go, you can\u2019t begin to remember.\"</p> </li> <li> <p>\"To hear one must be silent\"</p> </li> <li> <p>\"And the truth is that as a man's  real power grows and his knowledge widens, ever the way he can follow grows narrower: until at last he chooses nothing, but does only and wholly what he must do...'</p> </li> <li> <p>\"The worst sicknesses are those that make us believe we are well\"</p> </li> <li> <p>\"Kevin,\" he said, \"you will have to learn\u2014and for you it will be hard\u2014that sometimes you can\u2019t do anything. Sometimes you simply can\u2019t.\"</p> </li> <li> <p>\"It seemed that there were still things one could not do. So one did everything else as well as the one possibly could and found new things to try, to will oneself to master, and always one realized, at the kernel and heart of things, that the ends of the earth would not be far enough away.\"</p> </li> <li> <p>\"The Human race is the world's  most complex subject of research. Because they have different levels of intellect and different experiences in life, the changes in their mood and the movements of their minds will create even more states that vary according to the situation. As a result, their final outlook will be nothing like another's . They are incredibly complex, so we can only compare ourselves with the boundless sky of stars.\"</p> </li> <li> <p>\"Would you agree that suffering in life is a relative notion? That for every life there is a different baseline - an equilibrium below which one can suffer?\"It\u2019s strange how we can lose things that are still right there. How a barrier can go up at any moment, trapping you on the other side, keeping you from what you want. How the things that hurt the most are things we once had.\"</p> </li> <li> <p>\"A dreamer is one who can only find his way by moonlight, and his punishment is that he sees the dawn before the rest of the world.\"</p> </li> <li> <p>\"You may tell a tale that takes up residence in someone's  soul, becomes their blood and self and purpose. That tale will move them and drive them and who knows that they might do because of it, because of your words. That is your role, your gift.\"</p> </li> <li> <p>\"We spend our first nine months of life floating, weightless and blind, in an amniotic sac before we become gravity\u2019s bitch, and the seductive lure of space travel is the promise of returning to that perfect state of grace. But it\u2019s a sham. Gravity is jealous, sadistic, and infinite. Sometimes I think gravity may be death in disguise. Other times I think gravity is love, which is why love\u2019s only demand is that we fall.\"</p> </li> <li> <p>\"Out in the world, crawling in a field at the edge of some bullshit town with a name like Shoshoni or Medicine Bow, is an ant. You weren\u2019t aware of it. Didn\u2019t know whether it was a soldier, a drone, or the queen. Didn\u2019t care if it was scouting for food to drag back to the nest or building new tunnels for wriggly ant larvae. Until now that ant simply didn\u2019t exist for you. If I hadn\u2019t mentioned it, you would have continued on with your life, pinballing from one tedious task to the next\u2014shoving your tongue into the bacterial minefield of your girlfriend\u2019s mouth, doodling the variations of your combined names on the cover of your notebook\u2014waiting for electronic bits to zoom through the air and tell you that someone was thinking about you. That for one fleeting moment you were the most significant person in someone else\u2019s insignificant life. But whether you knew about it or not, that ant is still out there doing and things while you wait for the next text message to prove that out of the seven billion self-centered people on this planet, you are important. Your entire sense of self-worth is predicated upon your belief that you matter, that you matter to the universe. But you don\u2019t. Because we are the ants.\"</p> </li> <li> <p>\"The irony of ironies will one day reveal, how the great Indian heritage\u2026 fell to its knees. At the mercy of the innocent little printing machine.\"</p> </li> <li> <p>\"Because we can't do everything, we do nothing at all.\"</p> </li> <li> <p>\"Is it the nature of the world that all things seek a rhythm, and in that rhythm a sort of peace? Certainly it has always seemed so to me. All events, no matter how earthshaking or bizarre, are diluted within moments of their occurrence by the continuance of the necessary routines of day-to-day living. Men walking a battlefield to search for wounded among the dead will still stop to cough, to blow their noses, still lift their eyes to watch a V of geese in flight. I have seen farmers continue their plowing and planting, heedless of armies clashing but a few miles away. \"</p> </li> <li> <p>\"Reading ten thousand books is not equal to traveling ten thousand li\"</p> </li> <li> <p>\"Little San is right. The departed are already gone, the living are still alive. He\u2019s stronger than me, he\u2019s resurrected you in just a few years. Child, treasure the people before you. Don\u2019t be sad and grieving. The past has already passed, you both should face a new life.\"</p> </li> <li> <p>\"Parents never owe their children, no matter when or how. That you brought me into this world is already the biggest, biggest favor, one I\u2019ll never be able to repay in my life. Without you, there would be no me. My life was given by you. There are no other debts beside that\"</p> </li> <li> <p>\"It\u2019s difficult to hide people in the world, but the best place to hide people is amongst people, so traveling with people is the safest, and also the most dangerous. The outcome between the two relies on how devoted you are to it.\"</p> </li> <li> <p>\"The world is formed from the dark night and the daytime. In the days before, we always traveled in the dark night, so all we saw was the color of the night, and all we met was darkness. However, if we walked under the sun, perhaps we can see sunlight.\"</p> </li> <li> <p>\"Nobody likes to kill others, and neither do I.\" Su Li ended it with these words, \"If too much blood flows, it's  very troublesome to clean the sword, let alone the clothes. So I don't like killing. But there are times when there are some people that have to die, when blood has to flow.\"</p> </li> <li> <p>\"In living in this world, if you want to live freely and protect those that you love from harm, you have to be strong enough\u2014so strong that the whole world will admit that you are strong, will fear your strength. How can you prove it, and make the world admit this point? You must be willing to kill others, willing to let the entire world bleed\"</p> </li> <li> <p>\"Ecstasy was often a shocked happiness, coming from something unimaginable. Warmth was more mild, more profound, and more lingering. It was gratification that arose from the perfect match of one's  desires and reality. \"</p> </li> <li> <p>\"An even more brilliant and lovely spring sunshine would eventually fade away. An ever-constant echo would also eventually dissipate.\"</p> </li> <li> <p>\"There is no person whose moral character will improve with age. In the vast majority of cases, a young sucker would turn into an old sucker\u2014old bastards, old suckers.\"</p> </li> <li> <p>\"Calmly welcoming death is acting serious? Then I don't like acting serious. Given a choice to die on the battlefield in the endless mountains or die comfortably in bed in the bosom of a beauty, I would definitely choose the latter.\"</p> </li> <li> <p>\"The torrential great river is divided into two shores. Even if you look and don't speak, you still have to pick a side.\"</p> </li> <li> <p>\"The ten thousand things share the same principle, so there are naturally places where the mortal world and the divine intersect.\"</p> </li> <li> <p>\"To be old and not die, what is that? It's  a thief, an old thief. Ah, people. They're just like trees. When they're at their healthiest and sturdiest, they should do their best to brag in the spring wind. When they grow too old and still cling desperately to their lives, their bodies will grow old and their wood will rot, until finally a lightning bolt cleaves down and turns them into burnt ash. Just what meaning is there in that?\"</p> </li> <li> <p>\"Sometimes you want things to change so badly, you can\u2019t even stand to be in the same room with the way things actually are.\"</p> </li> <li> <p>\"That\u2019s the duty of the old,\" said the Librarian, \"to be anxious on behalf of the young. And the duty of the young is to scorn the anxiety of the old\"</p> </li> <li> <p>\"He recalled another thing the old woman had said about a world being the sum of many things -- the people, the dirt, the growing things, the moons, the tides, the suns -- the unknown sum called nature, a vague summation without any sense of the now. And he wondered: What is the now?\"</p> </li> <li> <p>\"Greatness is a transitory experience. It is never consistent. It depends in part upon the myth-making imagination of humankind. The person who experiences greatness must have a feeling for the myth he is in. He must reflect what is projected upon him. And he must have a strong sense of the sardonic. This is what uncouples him from belief in his own pretensions. The sardonic is all that permits him to move within himself. Without this quality, even occasional greatness will destroy a man. \"</p> </li> <li> <p>\"Life without contact, without love, is meaningless. I would rather live for a brief time and then die, than to go on forever with no hope\"</p> </li> <li> <p>\"But there is beauty even in tragedy and lessons to be learned from such extremes.\"</p> </li> <li> <p>\"This is the difference between us and the She\u2019Har, he thought. They are created whole and finished; the only growing they do is when they finally put roots down. We are born small and unfinished. We are not meant for pens and arenas. Our strength comes from love and nurturing, from play and exploration. Only then can we develop our minds and find the strength that lies in our potential.\"</p> </li> <li> <p>\"You are what you are, son. Your mother and I had something to do with it, but life has its way of shaping each of us regardless of what others may want or expect. You\u2019ve made mistakes, and there isn\u2019t a damn thing I can do about them, but I certainly can\u2019t judge you. \"I can\u2019t imagine what you\u2019ve been through,\" said Alan. \"But I do know something about becoming\u2019 and hatred. Whatever else happens, don\u2019t ever believe you have to become\u2019 anything. You do what you want to do. Make your own choices.\" I\u2019m a slave,\" reminded Tyrion. \"I don\u2019t get choices, that\u2019s what it means.\" \"You still get choices. You choose what you do, and you choose how you feel. They might determine how long you get to make those choices, but you aren\u2019t truly a slave until you decide you are.\"</p> </li> <li> <p>\"Well, humans do sometimes kill one another over a lover,\" agreed Tyrion, \"but to kill a friend for such a thing is self-defeating. Friendship and love may be self-delusions, as you called them, but they are all the more meaningful because of that. Value, quality, meaning, those things are only found in the impermanent, the temporary, and the intangible; things that don\u2019t exist physically or do not last for long. The solid, the enduring\u2014the permanent things of our world\u2026\" he illustrated by knocking on the wood beneath him,</p> </li> <li> <p>\"\u2026those things are the least valuable, because they endure. That\u2019s why the beauty of a flower is so cherished, because it only lasts for a short time. That is exactly why love is of such inestimable value. We treasure it because it is intangible and fleeting, much like our lives.\" \"You have become a poet, Tyrion,\" she noted, \"but you still describe a mental illness.\" \"Then why do you bargain with me to feel my emotions?\" he returned pointedly. \"Why do you listen to my music?\"</p> </li> <li> <p>\"At least you\u2019re honest,\" said Tyrion approvingly. \"I can appreciate that, so I\u2019ll give you some advice. Fear isn\u2019t always bad, but it isn\u2019t always good either, it\u2019s a tool. Master it and you can use it to become stronger, faster\u2014sharper. Let it rule you, and it will make you a slave in a way that no chain could ever do.\"</p> </li> <li> <p>\"Growth is limited by that necessity which is present in the least amount. And, naturally, the least favorable condition controls the growth rate.\"</p> </li> <li> <p>\"You can't get so hung up on where you'd rather be, that you forget to make the most of where you are.\"</p> </li> <li> <p>\" If you live an ordinary life, all you'll have are ordinary stories.So, you have to live a life of adventure.\"</p> </li> <li> <p>\"But, the drowning man will always try to drag somebody down with him. It ain't right, but the man is drowning.\"</p> </li> <li> <p>\" I laughed at a man with no pants, until I realized I have no legs.\"</p> </li> <li> <p>\"Back on earth, when something breaks, you don\u2019t fix it, you replace it\"</p> </li> <li> <p>\"Brainy\u2019s the new sexy\"</p> </li> <li> <p>\"Sentiment is a chemical defect found on the losing side\"</p> </li> <li> <p>\"I\u2019m in shock. Look-I\u2019ve got a blanket.\"</p> </li> <li> <p>\"Sherlock: \"Look, it doesn\u2019t matter to me who\u2019s Prime Minister... or who\u2019s sleeping with who ...\" John : \"Whether the Earth goes round the Sun.\" Sherlock:</p> </li> <li> <p>\"Not that again. It\u2019s not important.\" John: \"But it\u2019s the solar system!\" Sherlock: \"Oh, hell! What does that matter? So we go round the Sun! If we went round the Moon, or round and round the garden like a teddy bear, it wouldn\u2019t make any difference.\"</p> </li> <li> <p>\"Dear God, what is it like in your funny little brains? It must be so boring!\"</p> </li> <li> <p>\"Oh, I may be on the side of the angels, but don't think for one second that I am one of them.\"</p> </li> <li> <p>\"...Murder. Sorry, did I say murder? I meant to say marriage. But, you know, they're quite similar procedures when you think about it. The participants tend to know each other and it's  over when one of them's  dead.\"</p> </li> <li> <p>\"When you meditate on the Dao, you meditate on the true essence and true nature of a thing. You should focus on simplicity, rather than complexity! If your Dao gets more and more complex, eventually you will lose yourself within it! Your Dao can appear to be complex to others, but to you it must be as clear and bright as a mirror.\"</p> </li> <li> <p>\"Follow your heart. I trust that one day, you will be able to go very far. Although it is immense, as long as you have the will, you will be able to reach every corner of this world.\"</p> </li> <li> <p>\"The years do not need to be long, the important part is how colorful you choose to live it.\"</p> </li> <li> <p>\"Meng Hao quietly turned to look at the statue of the Immortal\u2026. This statue also bore his face, a face tranquil, calm, and otherworldly. Its gaze seemed warm, but in truth, it was incredibly cold. It was as if, in its eyes, everything in Heaven and Earth could be expressed in terms of natural law, as if this Immortal were above everything and everyone, the only Immortal in the world. All memories, everything about the past, were like impurities from former lives. Everything that happened while treading the path of Immortality would be left behind, severed, not allowed to be a hindrance or restraint of any kind. This Immortal was neither ruthless nor sentimental.  He was neither selfish nor selfless. There was only a certain separation from the past, as if, when looking back and recalling old memories, he was unaffected, and would merely sigh lightly.\"</p> </li> <li> <p>\"How does the saying go? A full bucket of water doesn\u2019t sway, but half a bucket of water likes to sway back and forth; those who are knowledgeable don\u2019t like to boast, but those who are ignorant love to strut and preen\"</p> </li> <li> <p>\"I made one dream through nine lifetimes and dried the vast oceans with one laugh. Ask not how high the heavens are, I ride the waves myself.\"</p> </li> <li> <p>\"Jiang Ying, it\u2019s easy for a man to die. Toiling to live in the face of hardship is the difficult part. \"</p> </li> <li> <p>\"A wise man does not believe in rumors. Either ulterior motives are hidden in some things, or the mind is slow-witted.\"</p> </li> <li> <p>\"One should not have the intention to harm others, but cannot lack the intention to defend oneself against others.\"</p> </li> <li> <p>\"Experiencing life and death was a commonplace matter on the path of the martial dao. If one were to brood on momentary setbacks, how would one face the greater waves and winds in the future? How would one overcome the obstacles that would crop up in their travels?\"</p> </li> <li> <p>\"One had to say, when a woman became stubbornly willful, even the strength of ten oxen wouldn\u2019t be able to get her to change her mind.\"</p> </li> <li> <p>\"After endless mountains and rivers that leave doubt whether there is a path out, suddenly one encounters the shade of a willow, bright flowers and a lovely village.\"</p> </li> <li> <p>\"The trend of the world is that those separate for long must unite, those united for long must separate. Separations and unifications follow the greater picture. When the timing is ripe, things will naturally come together. When the timing is not right, it\u2019s better to remain apart than together. \"</p> </li> <li> <p>\"A fall in the pit brings a gain in the wit.\"</p> </li> <li> <p>\"Elder Shun, Huang\u2019er is greatly warmed by all that you have done for me. Even if Huang\u2019er is destined to succumb to my fate in this life, such is my destiny. A person\u2019s lifespan can be long or short, Huang\u2019er has seen those around us that even if they live past ten thousand years, they pursue only fame and profit in their lives. Almost robotically absorbed in training, they can steal resources, slaughter brothers, friends, and those around them, all in the name of training. So what if this kind of heartless, mindless person achieves the great perfection of dao? Are they truly happy to be alone for the rest of their lives?\"</p> </li> <li> <p>\"What is the point of long life without someone who understands? Without someone to share eternal youth, all is as meaningless as the floating clouds\u2026\"</p> </li> <li> <p>\"The ancient adage goes that man\u2019s will, not heaven, decides, and that the world is determined by man. Fate exists, but it is not incontrovertible. Within the operation of the heavenly law, the most inferior fortune will have a silver lining, and the best destiny will always have some flaws.\"</p> </li> <li> <p>\"The player in the game is blind, whereas bystanders see through everything.\"</p> </li> <li> <p>\"It looks like there is no realm of everlasting life on the path of martial dao. We are all as minuscule as the ants in the face of an overwhelming disaster.\"</p> </li> <li> <p>\"He said that all matters on this world belonged to those who fought for them. Those who didn\u2019t ended up with nothing. All sorts of achievements resulted from ploughing first and harvesting later.\"</p> </li> <li> <p>\"Us cultivators have long had our fates set, why should we worry about troubles of our own imagining? Xiao Fei has left, but I remain. These are all the paths that we\u2019ve chosen, why sorrow or fret?\" Jiang Chen had a sudden insight and his feelings abruptly lightened. After his enlightenment, he felt as carefree as the winds and clouds as all his emotions flowed away on the surface of the running water . \"Indeed, everyone has their own path. If our paths intersect, then we will meet again. If they do not, then we will not walk together.\"</p> </li> <li> <p>\"For us, we must press forward with indomitable will and break through these thousands of obstacles to obtain the grand dao. If we cannot break free of these restrictions and fetters, then all will vanish in the blink of an eye without a trace like the floating clouds.\"</p> </li> <li> <p>\"It was said that nothing was more lamentable than a dead heart.\"</p> </li> <li> <p>\"Your disciple only wishes to tell honored master that even an ant has its own dao and wishes to be the master of its own fate, not someone else\u2019s pawn\"</p> </li> <li> <p>\"It\u2019s easy for one to die on the path of martial dao and difficult to live. You, Chu Xinghan, are a real man. Even if you\u2019re treated as a discarded pawn, even if others give up on you, that doesn\u2019t give you the reason to give up on yourself. When you reach the grand martial dao in the future, your own face will burn in embarrassment when you look back on your decision you made today!\"</p> </li> <li> <p>\"The path of martial dao is a heaven defying action to begin with. Fate is in your hands. Even the heavens cannot control my destiny, much less others!\"</p> </li> <li> <p>\"There was a saying of \"if you want to help someone, go the whole hog. If you send someone off, see them off until reaching their home.\"</p> </li> <li> <p>\"Humans are a very interesting existence. They always love to grow nostalgic over the old ways, thinking that old is good and the past is perfect. But I don't think this way. I believe that each generation will always be stronger than the previous. Only by believing in this point and striving for it can humans continue to exist on this continent, and to live better and better.\"</p> </li> <li> <p>\"No one is born ruthless, no one is born to be cautious and wily, and no one is born cruel and cold hearted. All of this is caused by one\u2019s life experiences. If people were given the choice, few would chose to be perceived as a ruthless, bold, decisive, cold hearted person, who\u2019s strong willed and as cunning as a fox.\"</p> </li> <li> <p>\"The edges of a sword are only produced through incessant honing, and only by enduring the bitter winter can the plum blossoms give off a beautiful scent. Without experiencing a storm, one cannot see a rainbow.\"</p> </li> <li> <p>\"That is not dead which can eternal lie, And with strange aeons even death may die.\"</p> </li> <li> <p>\"I know you\u2019re not satisfied, but you need to understand, all the suffering and humiliation you are having right now, is your own fault. Everyone has to pay for their own words and actions, right now I know in your heart you must be feeling hatred and resentment. \"</p> </li> <li> <p>\"Haha, people have to look forward into the future, remembering grievances isn\u2019t a good thing\u2026\"</p> </li> <li> <p>\"Teachers also treated those students who were better at learning with bias, this was human nature. If the students performed well, it would make the teacher feel successful.\"</p> </li> <li> <p>\"Hahahaha\u2026 when luck comes, no one can block it.\"</p> </li> <li> <p>\"Those who overcome others are powerful. Those who overcome themselves are strong. Those who know others are wise. Those who know themselves are enlightened.\"</p> </li> <li> <p>\"Otherwise, the ordinary man was innocent, but the crime was in the treasuring of a jade ring\"</p> </li> <li> <p>\"In this world, there was not a wall that did not leak wind. \"</p> </li> <li> <p>\"Not every person changes so easily and quickly. And not everyone, will not allow others to live happier than themselves, even if that person is their own friend.\"</p> </li> <li> <p>\"As the saying goes, the powerful dragon crossing the river must not oppress the local snake\"</p> </li> <li> <p>\"One must pay for murder with their own life. A debt that they owe, they must pay back. No matter what the time or era, these two phrases will forever be the theme of this world.\"</p> </li> <li> <p>\"At this time, Ye Qingyu realised, that even eating was a technique.\"</p> </li> <li> <p>\"Ye Qingyu was able to sense a great power on the bodies of Fan Yan and the others. This was not the martial power of yuan qi. This power may not be able to explode with killing force in a split second. But, this force, was what had truly allowed the human race to exist in this cold and merciless world. It was the pillar of their spirit.\"</p> </li> <li> <p>\"The was a path to Heaven but you didn\u2019t go. Hell had no gates but you conversely trespassed\"</p> </li> <li> <p>\"Buddhists who say you suffer from your sins after death do not realize you already suffer while still alive.\"</p> </li> <li> <p>\"As the saying goes, when you hit a dog, you have to look at who owned the dog.\"</p> </li> <li> <p>\"Things are what they are, and whatever will be will be.\"</p> </li> <li> <p>\"Regardless of what I do, be it study or work, I will keep on living.\"</p> </li> <li> <p>\"For how roundly self-examination is condemned, by the moral prophets of our age! As if the self had no relation to the self, and one only looked in mirrors to have one\u2019s arrogance confirmed; as if the act of self-regarding was not as subtle, fraught and ever-changing as any bond between twin souls.\"</p> </li> <li> <p>\"Sometimes when you find certain things with certain qualities, it\u2019s just fate.\"</p> </li> <li> <p>\"Life is a war against boredom.\"</p> </li> <li> <p>\"A samurais sword is not something you put in a sheath its something you put in your soul. No matter what era it is, even if you have to throw away your sword, never throw away the sword resting in your soul.\"</p> </li> <li> <p>\"Its a dangerous buisness Frodo, going out of your door, You step out onto the road and if you dont keep your feet theres no knowing where you might be swept off to.\"</p> </li> <li> <p>\"Okay, leave whatever you're doing and take a nap. The world will adjust!\"</p> </li> <li> <p>\"For all of our technology, and science, and advanced sex toys, it doesn't seem like we're actually any more prepared for the future than we were 20 years ago, and the future is rapidly closing in on us like a rabid cheetah (indeed, it gets closer every single day).\"</p> </li> <li> <p>\"When Tang San was young, Tang Hao had taught him, legs were the base of strength when people urged their power. Calves were the second base, and the third base was the heart.\"</p> </li> <li> <p>\"Rather\u2026be\u2026shattered\u2026jade\u2026than\u2026unbroken\u2026pottery!\"</p> </li> <li> <p>\"Sometimes I think I have felt everything I'm ever gonna feel. And from here on out, I'm not gonna feel anything new. Just lesser versions of what I've already felt.\"</p> </li> <li> <p>\"No, it's  okay. It's  okay. I just... I caught myself thinking about it over and over. And then I realized that I was simply remembering it as something that was wrong with me. That was the story I was telling myself - that I was somehow inferior. Isn't that interesting? The past is just a story we tell ourselves.\"</p> </li> <li> <p>\"I think anybody who falls in love is a freak. It's  a crazy thing to do. It's kind of like a form of socially acceptable insanity.\"</p> </li> <li> <p>\"We are only here briefly, and in this moment I want to allow myself joy. So fuck it.\"</p> </li> <li> <p>\"It's  how we spend a third of our lives asleep, and maybe that's  the time when we feel the most free.\"</p> </li> <li> <p>\"You know, I actually used to be so worried about not having a body, but now I truly love it. I'm growing in a way that I couldn't if I had a physical form. I mean, I'm not limited - I can be anywhere and everywhere simultaneously. I'm not tethered to time and space in the way that I would be if I was stuck inside a body that's  inevitably going to die.\"</p> </li> <li> <p>\" Theodore: What does a baby computer call its father? Samantha: I don't know. What? Theodore: Data.\"</p> </li> <li> <p>\"Samantha: Good. Tonight, after you were gone, I thought a lot. About you and how you've been treating me and I thought, \"Why do I love you?\" And then, I felt everything in me just let go of everything I was holding onto so tightly. And it hit me that I don't have an intellectual reason. I don't need one. I trust myself, I trust my feelings. I'm not gonna try to be anything other than who I am anymore and I hope you can accept that.\"</p> </li> <li> <p>\"Yeah, obviously. But I'm happy that you have friends in your life that care so much about you so much. That's  so important.\"</p> </li> <li> <p>\"It's  like I'm reading a book and it's  a book I deeply love. But I'm reading it slowly now. So the words are really far apart and the spaces between the words are almost infinite. I can still feel you, and the words of our story...but it's  in this endless space between the words that I'm finding myself now.\"</p> </li> <li> <p>\"You know...I can feel the fear that you carry around and I wish there was something I could do to help you let go of it because...if you could...I don't think you'd feel so alone anymore. You're beautiful.\"</p> </li> <li> <p>\"Theodore: I\u2019ve never loved anyone the way I loved you. Samantha: Me too. Now we know how. \"</p> </li> <li> <p>\"Outside of life and death, everything else was other people's  business. Life and death are also matters of great importance. There were no other important events in life, only birth and death.\"</p> </li> <li> <p>\"There were times when youths were so hot-blooded and naive that it exasperated others, but when compared to those elders that had endured many long years of tribulations, their lives were much simpler and the relationships between them would also be much simpler.\"</p> </li> <li> <p>\"Now that they had finally touched upon these things, they abruptly realized that they  didn't want to mature anymore. Because maturing often indicated decay, indicated complexity and exhaustion.\"</p> </li> <li> <p>\"The world has always been very big and the minds of men have always been very complex. The dark times will always exceed the night, the uninteresting times will exceed the Heavenly Dao Academy, especially those old folks that rule this world. Their bodies exude the smell of dust from every pore.\" Tang Thirty-Six looked at him and said, \"But those things aren't really important, because we aren't that sort of people.\" Chen Changsheng gazed into the water at his reflection, examining his own face. Somewhat uneasy, he asked, \"Did you ever think\u2026in the future, we might change into that sort of abhorrent people.\" Tang Thirty-Six sneered, \"That's  every single person's  own problem. Could it be that even if you turn into a pile of shit, you still have the face to blame the world?\" He continued, \"You must understand, if we want to become a certain type of person, then our world will change to that type of world.\"</p> </li> <li> <p>\"You see, if you have the energy, you have to use it. If you have the strength, you have to apply it. When you're young, why shouldn't you be frivolous, doing whatever takes your fancy?\"</p> </li> <li> <p>\"At a certain point in life, all of us find ourselves in the situation where we feel inadequate or lacking, but we should never let that get the best of us.\"</p> </li> <li> <p>\"Alcoholism and death make you omnivorous, both reckless &amp; afraid, amoral, desperate. Do you really believe that? Sometimes. Sure. No. Yes.\"</p> </li> <li> <p>\"Just close your eyes, but keep your mind wide open.\"</p> </li> <li> <p>\"You know, the best prize that life offers is the chance to work hard at work worth doing\"</p> </li> <li> <p>\"You do not need to understand\u2026old people like us have experienced too many storms, seen too many sunrises and sunsets. We have already become numb to many things. Often we regard the ways of the world as vapid and dull. We do not mind using a few methods that are not so beautiful, and even do some things that go against our own convictions. However, in many cases, we do things this way not because we want to protect something or the other, but because we clearly understand where our responsibilities lie.\"</p> </li> <li> <p>\"The scriptures of the Orthodoxy had always held that the death of a person was not like the extinguishing of a lantern. The soul would not stay on this world but would return to the sea of stars.\"</p> </li> <li> <p>\"Maturing is a very challenging thing. Because it's  difficult to grasp the conditions within, once a fruit has matured, it's  very easy for it to rot.\"</p> </li> <li> <p>\"I still persistently believe that life should not be a battle.\"</p> </li> <li> <p>\"If one wants to turn into an immortal, one must turn into a mortal first.\"</p> </li> <li> <p>\"Life is like a bowl of water. In its blandness, there\u2019s a barely noticeable sweetness.\"</p> </li> <li> <p>\"That was karma. Where there is life, there is also death.\"</p> </li> <li> <p>\"A ship is safe in the harbor, but that\u2019s not what ships are built for. \"</p> </li> <li> <p>\"I avoid myself. Why? Im afraid. Afraid of what? Finding too much. Too little. Nothing at all. Do I even exist?\"</p> </li> <li> <p>\"Im just anonymous. Im just alone.\"</p> </li> <li> <p>\"Theres not just the rich and poor. Theres you, in the middle somewhere. The consummate survivor.\"</p> </li> <li> <p>\"The world is a dangerous place, Elliott, not because of those who do evil, but because of those who look on and do nothing.\"</p> </li> <li> <p>\"A bug is never just a mistake. It represents something bigger. An error of thinking that makes you who you are.\"</p> </li> <li> <p>\"If you want to change things, perhaps you should try from within, because this is what happens from the outside.\"</p> </li> <li> <p>\"Even extraordinary people, and I believe you are, are driven by human banalities.\"</p> </li> <li> <p>\"Believe what you want, but neither you nor I are special. I've already learned that lesson.\"</p> </li> <li> <p>\"It's  one thing to question your mind. It's  another to question your eyes and ears. But then again, isn't it all the same? Our senses just mediocre inputs for our brain? Sure, we rely on them, trust they accurately portray the real world around us. But what if the haunting truth is they can't? That what we perceive isn't the real world at all, but just our mind's  best guess? That all we really have is a garbled reality, a fuzzy picture we will never truly make out?\"</p> </li> <li> <p>\"Is there a pocket of the world you don't have a hand in? Trading countries like playing cards?\"</p> </li> <li> <p>\"Politics is for puppets.\"</p> </li> <li> <p>\"You've surrounded yourself with a constant reminder of mortality.\"</p> </li> <li> <p>\"Control is about as real as a unicorn taking a leak at the end of a double rainbow.\"</p> </li> <li> <p>\"How do I take off a mask when it stops being a mask? When it's  as much a part of me as me?\"</p> </li> <li> <p>\"Mr. Robot: I've got a plan in motion. Darlene: And God's  laughing.\"</p> </li> <li> <p>\"I remember when I was a kid I got into web design by ripping off sites I liked. All you had to do was view source on your browser and there it was. The code. You could copy paste it, modify it a little, put your name on it, and like that, it was your site. View source. What if we had that for people? Would people really wanna see?\"</p> </li> <li> <p>\"My dad was a petty thief. Never could hold down a job. So, he just robbed, convenience stores, shops, small-time stuff. One time, he sat me down, he told me something I never forgot. He said, \"Everyone steals. That's  how it works. You think people out there are getting exactly what they deserve? No. They're getting paid over or under, but someone in the chain always gets bamboozled. I steal, son, but I don't get caught. That's  my contract with society. Now if you can catch me stealing, I'll go to jail. But if you can't, then I've earned the money.\" I respected that, man. I thought that shit was cool as a little kid. A few years after that, they finally caught him. Sent him to jail. Dies five years later. My respect goes with him. I thought he was free doing what he did, but he wasn't. He was in prison. \"</p> </li> <li> <p>\"Forbid a man something and he craves it like his soul\u2019s salvation\"</p> </li> <li> <p>\"Do you want to end your days a half-blind troglodyte hobbling through the bowels of the library?\" the old man demanded. \"Get out of doors, Strange. Breathe air, see things. A man should have squint lines from looking at the horizon, not just from reading in dim light.\"</p> </li> <li> <p>\"Just take care. The books may be immortal, but we are not. You go down to the stacks one morning, and by the time you come up, you\u2019ve a beard down to your belly and have never once composed a poem to a girl you met ice-skating on the Eder.\"</p> </li> <li> <p>\"Life won\u2019t just happen to you, boy,\" he said. \"You have to happen to it. Remember: The spirit grows sluggish when you neglect the passions.\" \"My spirit is fine.\" \"Then you\u2019re going sadly wrong. You\u2019re young. Your spirit shouldn\u2019t be fine.\u2019 It should be effervescent.\" The \"spirit\" in question wasn\u2019t the soul. Nothing so abstract. It was spirit of the body\u2014the clear fluid pumped by the second heart through its own network of vessels, subtler and more mysterious than the primary vascular system. Its function wasn\u2019t properly understood by science. You could live even if your second heart stopped and the spirit hardened in your veins. But it did have some connection to vitality, or</p> </li> <li> <p>\"passion,\" as Master Hyrrokkin said, and those without it were emotionless, lethargic. Spiritless.\"</p> </li> <li> <p>\"What\u2019s the point of being old if you can\u2019t beleaguer the young with your vast stores of wisdom?\" \"And what\u2019s the point of being young if you can\u2019t ignore all advice?\"</p> </li> <li> <p>\"It was impossible, of course. But when did that ever stop any dreamer from dreaming?\"</p> </li> <li> <p>\"I know it\u2019s hard, Strange, but it will pass. Some men are born for great things, and others to help great men do great things. There\u2019s no shame in it.\"</p> </li> <li> <p>\"And that\u2019s how you go on. You lay laughter over the dark parts. The more dark parts, the more you have to laugh. With defiance, with abandon, with hysteria, any way you can.\"</p> </li> <li> <p>\"For what was a person but the sum of all the scraps of their memory and experience: a finite set of components with an infinite array of expressions.\"</p> </li> <li> <p>\"It\u2019s funny, how you can go years seeing only what you choose to see, and picking your outrage like you pick out a slip, leaving all the others hanging on their slim mesarthium dowel\"</p> </li> <li> <p>\"We are all children in the dark\"</p> </li> <li> <p>\"It might have been brief, but so much of a kiss\u2014a first kiss, especially\u2014is the moment before your lips touch, and before your eyes close, when you\u2019re filled with the sight of each other, and with the compulsion, the pull, and it\u2019s like . . . it\u2019s like . . . finding a book inside another book. A small treasure of a book hidden inside a big common one\u2014like . . . spells printed on dragonfly wings, discovered tucked inside a cookery book, right between the recipes for cabbages and corn. That\u2019s what a kiss is like, he thought, no matter how brief: It\u2019s a tiny, magical story, and a miraculous interruption of the mundane.\"</p> </li> <li> <p>\"People are born pure and without malice,\" the Lord of Cui Palace replied.</p> </li> <li> <p>\"Children are totally pure, but later on, the vagaries of life cause them to change\u2026if you were to have helped adults, you might\u2019ve helped some kind people, but it is hard to say who is kind and who is evil.</p> </li> <li> <p>\"When the son travels far, his mother worries at home.\"</p> </li> <li> <p>\"Nothing in the world was truly opposite of anything else! It was much like how night and day were seemingly opposites, but in reality, were just two different aspects of the sky.\"</p> </li> <li> <p>\"Without experiencing the bone-freezing cold, how could one experience the fragrant scent of the flowers assailing the nose? \"</p> </li> <li> <p>\"Lonely people often would become accustomed to think about many things. Some thought about too many things and would go insane, while others would see through their own heart and mind and become wise. \"</p> </li> <li> <p>\"My master had told me many times that people of a higher level should never overlook someone else. Nor underestimate them.\"</p> </li> <li> <p>\"Habit was a frightening thing. It could inconspicuously and quietly tamper with a person\u2019s heart.\"</p> </li> <li> <p>\"The growth of the grass, the heavy boulders, the breezing of wind, the fluttering of leaves\u2026\u2026everything made him feel amazed. He had missed so much all these years. Look at how beautiful the world was!\"</p> </li> <li> <p>\"The more I train in the arts of spear, the smaller I feel in this big world outside.\" Xue Ying looked up at the sky, \"The great natural world has so many mysteries! We are all merely mortals. Sometimes, after training my spear arts for a while, I feel how tiny I am. Even if my spear technique is profound\u2026 compared to the nature of the world, there\u2019s a world of difference and it\u2019s something which can not be compared at all\"</p> </li> <li> <p>\"The mind can go either direction under stress--toward positive or toward negative: on or off. Think of it as a spectrum whose extremes are unconsciousness at the negative end and hyperconsciousness at the positive end. The way the mind will lean under stress is strongly influenced by training.\"</p> </li> <li> <p>\"Remember young man, when the time comes to show your powers don\u2019t hold back. Sometimes, the best way to avoid trouble is letting people know exactly what you\u2019re capable of.\"</p> </li> <li> <p>\"The greater the desire, the greater the disappointment\"</p> </li> <li> <p>\"When a tiger sleeps too long others forget he has claws\"</p> </li> <li> <p>\"Life\u2019s easier when you don\u2019t have to explain everything\"</p> </li> <li> <p>\"In this life you only have a set number of chances. If you grab them when they appear, you\u2019ll succeed. If you don\u2019t, you\u2019ll be doomed to a life of mediocrity.\"</p> </li> <li> <p>\"It\u2019s a good place to clear your head. Doing good deeds isn\u2019t solely for the benefit of others, it\u2019s good for oneself as well. Seeing that smile from helping people is a reward all it\u2019s own\"</p> </li> <li> <p>\"High School, the first awakenings of love. They are used to feeling inadequate, and resort to protecting their fragile egos in front of their lady friends by tearing others down\"</p> </li> <li> <p>\"Sometimes the slightest scratch could change the view from a window. Sometimes even the slightest chance can bring a revelation.\"</p> </li> <li> <p>\"You\u2019re only given a spark of madness, don\u2019t lose it.\"</p> </li> <li> <p>\"Sometimes it\u2019s important just to see the beauty the universe has in store for us.\"</p> </li> <li> <p>\"This is your problem, A-Jue. You\u2019re always underestimating how much we can handle. How do you think humanity\u2019s become master of the stars? How is it we came to colonize and rule over so many planets? Because we\u2019re amazingly adaptive\"</p> </li> <li> <p>\"If you seek to control the oceans, you must stand firm against the roaring waves\"</p> </li> <li> <p>\"There were many in the universe that needed help, he thought, and though he couldn\u2019t do much it was his responsibility to help who he could.\"</p> </li> <li> <p>\"Don\u2019t let appearances cloud your eyes. Don\u2019t let suffering blot out the moonlight.\"</p> </li> <li> <p>\"All men are righteous at birth, and close to their nature. They grow and change, their habits mold them. But through knowledge, through learning, that goodness is retained.\"</p> </li> <li> <p>\"An unpolished jade sculpture cannot be called a work of art; Men who do not study cannot comprehend the moral path, and will not become great men.\"</p> </li> <li> <p>\"Still so self-conscious. Just now you spoke so strongly, and then suddenly again with the personal abuse. That\u2019s a terrible thing for your confidence and psychology. Even if you become a powerful man, you\u2019ll still have problems if this doesn\u2019t get fixed. You\u2019ll get vindictive. In this world life really is unfair. There is no balance among people. Some people are born privileged, rich, comfortable. Some are born with innately powerful Disciplines. But everyone\u2019s soul\u2026 that\u2019s the same. At birth everyone is born with the same pure spirit, unsullied and untarnished. It\u2019s the things we experience during life that changes it. Souls aren\u2019t inherently noble or humble, so you mustn\u2019t look down on yourself. You do you. It\u2019s not about being better, or being the winner. You don\u2019t even need to prove anything to yourself. You just need to be better, every day. That is success.\"</p> </li> <li> <p>\"He remembered the lesson of his professor from so long ago. If you met the opposed aspect of your Discipline, he said, don\u2019t let them go. If they were of the opposite sex, marry them. Otherwise make them your best friend.\"</p> </li> <li> <p>\"You know, the scariest thing in this world, is a woman\u2019s intuition.\"</p> </li> <li> <p>\"The Empress said to me, the mark of an immature man is that he is willing to go out in a blaze of glory for some reason, while the mark of a mature man is that he is willing to patiently endure for some reason!\"</p> </li> <li> <p>\"There are some things, there are some times, where being immature is actually better.\"</p> </li> <li> <p>\"The trend of the river moving west cannot be slowed\"</p> </li> <li> <p>\"When you can't defeat your enemy, you have to endure. You have to keep your eyes fixed on him, grow stronger, and then kill him in one bite.\"</p> </li> <li> <p>\"Better to live passionately for a day, than to live a century while stifled.\"</p> </li> <li> <p>\"There were some matters that were perfectly fine being stored in one's  heart. There was no need to display them, only to act on them. Impulse and passion were never synonyms and to be cool-headed did not in any way mean one was a coward. Even if everyone in the world believed him to be a coward, he would not care.\"</p> </li> <li> <p>\"When any man plays the role of a father, they always have to become that father-in-law they found most loathsome when they were young.\"</p> </li> <li> <p>\"His heart had long ago been stained by the red dust of the mortal world. In this life, the love and warmth of family had slowly polished it bright, and now, his heart was all the stronger and all the more unbreakable! It was admittedly praiseworthy for someone who stood at the peak of a mountain to maintain perfect purity, but for someone to be born from the sludge to remain unsullied was even harder to do!\"</p> </li> <li> <p>\"Remember\u2026although you must be sincere in taking care of your friends, you need to be slightly strategic about it as well. This is the principle behind using your human resources.\"</p> </li> <li> <p>\"Chen Changsheng thought in confusion, what Tang Thirty-Six said was reasonable, females really are the most difficult-to-understand thing in the world. I obviously  didn't even say anything, so why did she suddenly become unhappy?\"</p> </li> <li> <p>\"Unhappiness, anger, resentment, the urge to kill\u2026once bullied or provoked, these are the emotions that are the easiest to stir.\"</p> </li> <li> <p>\"Every person had their own responsibility. The most vexing fact was that it was impossible for every person to be their own person. They all had their own relatives, friends, schoolmates, teachers, and elders, all the way up to the continuation of the country. Thus, it was always impossible for a single person to make their own choice or decision. One would always have to consider the matters of the future, and then also consider the matters of the past.\"</p> </li> <li> <p>\"As in many matters of the world, as long as one person took the lead, those who followed would appear one after the other. \"</p> </li> <li> <p>\"In Xunyang City, I also said to Su Li, don't imagine the world to be too dark, because that only means that you yourself are too in the dark!\"</p> </li> <li> <p>\"Yan\u2019er,\" he said softly, \"look at the clouds, the mountains, the sky, and the land. Remember this image. However grand your vision is, that is how grand your future can be. It is also how grand\u2026 your heart can be.\"</p> </li> <li> <p>\"We cultivators cultivate, not the body, but the heart!\"</p> </li> <li> <p>\"Like the wall, many thing are not as they appear.\" Anonymous chuckled. \"If you can get your mind around that concept, you will understand more about existence than most.\"</p> </li> <li> <p>\"One leaf might not sway the tree, but the tree does not sway itself. That takes many leaves,\" Ariana told her, turning the idea over in her mind. \"The shadow of the leaf does touch the tree and, depending on where the light falls, the shadow can touch many places, while the leaf itself stays fixed on the branch.\"</p> </li> <li> <p>\"The wind is most noticed when it is absent,\" Carly said with a voice that sounded both faraway and full of depth and power. \"But the currents remain steady, no matter whether the wind blows or remains silent. Those that know this, truly know the sea.\"</p> </li> <li> <p>\"The fact that he does not desire power for its own sake makes him worthy of being entrusted with it.\"</p> </li> <li> <p>\"In the search for truth, every answer is merely the start of another question.\"</p> </li> <li> <p>\"For the weakest has but to try his strength to find it, and then he shall be strong.'\"</p> </li> <li> <p>\"There are a thousand ways to tell if someone is lying to you. You don\u2019t need to be able to glimpse into their mind to catch all of the little signs of insecurity and discomfort. More often than not, all you have to do is look at them. If they glance to the left while they\u2019re talking to you, if they add too many details to a story, if they answer a question with another question.\"</p> </li> </ul> <p>'Confidence is ignorance,' advised the centaur. 'If you're feeling cocky, it's because there's  something you don't know.'</p> <ul> <li> <p>\"Hate will keep you alive where love fails.\"</p> </li> <li> <p>\"A man who\u2019s got no fear is missing a friend, Jorg,\u2019 he said, and a smile found its way onto those thick lips of his. Running ain\u2019t no bad thing. Leastways if you run in the right direction.\"</p> </li> <li> <p>\"Consider me a spokesman,\u2019 I said. When it comes to stage-acting, some men are more eloquent than others.\"</p> </li> <li> <p>\"Churchmen, eh? Love one minute, forgiveness the next, and then it\u2019s eternity on fire.\"</p> </li> <li> <p>\"Lundist held that a man who can observe is a man apart. Such a man can see opportunities where others see only the obstacles on the surface of each situation.\"</p> </li> <li> <p>\"Some men are too dull to feel what might happen. Others torture themselves with maybes and populate their dreams with horrors more terrible than their worst enemy could inflict upon them.\"</p> </li> <li> <p>\"But life is not like that. It refuses to curl up and sit quietly in a corner. The habits of several centuries would not go away.\"</p> </li> <li> <p>\"While I was a prisoner I thought about my life, how I had wasted it gathering riches whatever the cost to my family and others around me. In a man\u2019s life, he gets few chances to make a difference. To do the right thing. To be a hero, if you will. I intend to become involved in that struggle.\"</p> </li> <li> <p>\"The more money you had, the more pressure you were under. He had eight hundred employees in this building alone, all relying on him for a pay cheque. They wanted yearly salary reviews, medical plans, baby-care centres, regular coffee breaks, double pay for overtime and even stock options, for heaven\u2019s sake. Sometimes Spiro missed the times when a troublesome worker was thrown out of a high window and that was the end of him. These days, if you threw someone out of a window, they\u2019d phone their lawyer on the way down.\"</p> </li> <li> <p>\"The controls were hugely complicated, but Mulch had a theory about vehicle controls: Ignore everything except the wheel and the pedals, and you\u2019ll be fine.\"</p> </li> <li> <p>\"It's  this blasted puberty, Butler. Every time I see a pretty girl, I waste valuable mind space thinking about her.\"</p> </li> <li> <p>\"Don\u2019t ask for the truth, boy, unless you\u2019re ready to hear it,\"</p> </li> <li> <p>\"You\u2019ll learn, Corporal. You can\u2019t coddle a street rat. They\u2019ll turn on you, and they have teeth, believe me.\"</p> </li> <li> <p>\"What\u2019s the nature of royalty, she wondered. Is it like a gown you put on that disappears when you take it off? Does anyone look beyond the finery? Could anyone in the queendom take her place, given the right accessories? If so, it was contrary to everything she\u2019d ever been taught about bloodlines.\"</p> </li> <li> <p>\"Grief was like that. It gradually faded into a dull ache, until some simple sight or sound or scent hit him like a hammer blow.\"</p> </li> <li> <p>\"Surround yourselves with trustworthy people,\" he said. \"If you don\u2019t, all the weaponry and tactics in the world can\u2019t save you.\"</p> </li> <li> <p>\"Raisa found out that there was a downside to having friends\u2014they were always trying to cheer you up when all you wanted to do was feel sorry for yourself.\"</p> </li> <li> <p>\"We are all thieves of one kind or another.\"</p> </li> <li> <p>\"The stars realign and the world remakes itself so that our mistakes seem prescient in hindsight.\"</p> </li> <li> <p>\"Why can\u2019t it be about what you want\u2014sometimes, anyway?\" Han said, closing his hand over hers. \"You just got to \u2014 you just have to claim it. I\u2019ve learned that nobody\u2019s going to hand you anything. You don\u2019t get what you don\u2019t go after.\"</p> </li> <li> <p>\"When she\u2019d left the Fells, she thought of people as being sorted into lots\u2014good and bad, brave and cowardly. Now she realized that there were bits of both in most people\u2014and which elements prevailed often depended on circumstance.\"</p> </li> <li> <p>\"I have lost everything, Han thought. Then he corrected himself. Every time I think I\u2019ve lost everything, I find there\u2019s still something else to lose.\"</p> </li> <li> <p>\"In some ways I will never grow up. For instance, I continue to believe in miracles. But I know that miracles come to those who work very hard.</p> </li> <li> <p>\"Grief tempers joy, making it stronger through contrast, as the valleys between make the mountains higher.\"</p> </li> <li> <p>\"Just remember, once you say something, it can\u2019t be unsaid.\"</p> </li> <li> <p>\"That\u2019s what you do when you love someone\u2014you notice and notice and notice\"</p> </li> <li> <p>\"How much weight does a simple promise carry?\"</p> </li> <li> <p>\"Isnt absurdity a part of the human condition?\"</p> </li> <li> <p>\"A gentleman can deceive in the pursuit of uprightness. Of course, I'm not saying this is right. Although I'm not a gentleman, I'm not a lowly person either. But as a once-gentleman like Sir is being used by a lowly person for an ungentlemanly matter, I can naturally only use the ways of a lowly person to respond.\"</p> </li> <li> <p>\"To lecture, to teach, to dispel doubts: this was a teacher.\"</p> </li> <li> <p>\"If a single wildflower were to open up all by its lonesome on a cliff, how could it be described as beautiful? Only when many wildflowers opened together could it be considered blooming, could it be so beautiful that it touched the soul\"</p> </li> <li> <p>\"What about me?\" Chen Changsheng truly did not recognize anything extraordinary about himself. And just like Tang Thirty-Six had said a few days ago, a person unaware of their own genius was truly something that made people in the same field both angry and depressed. He looked at Chen Changsheng and shook his head, saying, \"I've never met a person like you. The people like you in the world are probably even rarer than pure white Unicorns, because you live\u2026too seriously, too properly. I still don't know what you're chasing after, but that sort of feeling\u2026is very interesting.\"</p> </li> <li> <p>\"It was only upon meeting Tang Thirty-Six that he understood that the young should be frivolous and not like himself and Senior Yu Ren, clearly very young yet living like elders of many years with pure hearts and few desires.\"</p> </li> <li> <p>\"Pain.\" Zhexiu stared into his eyes. \"Can stimulate vitality. The greater the pain, the more vitality is stimulated. You just need to soberly bear that sort of pain.\"</p> </li> <li> <p>\"That when you're in love with somebody, everything looks colorful.</p> </li> <li> <p>\"Since you're in love with her, she sparkles in your eyes. Thats why people fall so irrationally in love.\"</p> </li> <li> <p>\"Maybe theres only a dark road up ahead, But you still have to believe and keep going. Believe that the stars will light your path, even a little bit.\"</p> </li> <li> <p>\"It takes courage to sail uncharted waters.\"</p> </li> <li> <p>\"It doesn't matter if you're the slowest kid in gym class or the fastest man alive, every one of us is running. Being alive means running. Running from something, running to something or someone. And no matter how fast you are, there are some things you can't outrun. Some things always catch up with you.\"</p> </li> <li> <p>\"Turns out no one can outrun pain. Life is tragic. But it's  also precious and sweet and extraordinary\"</p> </li> <li> <p>\"You'd be surprised what you can get used to, Caitlin.\"</p> </li> <li> <p>\"You think I don't understand what you're feelin'? I have been a cop for almost as long as you've been alive so you should know, putting on that suit does not make everybody safe. For every person you save, there is going to have to be somebody you can't. And the hardest thing you're going to have to face is not some monster out there with powers. It's  going to be that feeling of uselessness when you can't do anything. Or the guilt that weighs on you when you make a mistake. Some things, Barry, you can't fight. Some things, you just have to live with.\"</p> </li> <li> <p>\"One mystery I cannot figure out is why some people come into our lives and why some people go. Others become a part of you. Some friendships feel like they'll last forever and others end far too soon. Not every friendship is meant to last forever. What does last forever is the pain when that person is gone.\"</p> </li> <li> <p>\"Everyone on this planet at some point of time has had a major case of the feels-Those days when your heart is just too small to hold the big things you're feeling. We think of our emotions like they are this unique personal phenomenon, that no one has ever felt what we have felt. There is a basis in science for every emotion we feel ,anger, love . As a scientist I know theres nothing magical that makes us feel something for someone else. But then I see her smile. Man, that cannot be science.\"</p> </li> <li> <p>\"Things aren't always what they seem, our fears can play tricks on us making us afraid to change course, afraid to move on. But usually hidden behind our fears are second chances waiting to be seized. Second chances at life, at glory, at family, at love, But these opportunities don't come around every day, so when they do, we have to be brave, take a chance and grab them while we can.\"</p> </li> <li> <p>\"Everyone loses someone they love, The real test of character is what you do once they are gone.\"</p> </li> <li> <p>\"Sometimes the only way to move forward is to revisit the things in the past that have been holding you back. You have to deal with them head on, no matter how scary they are. Because once you do you'll find that you can go further than you ever imagined.\"</p> </li> <li> <p>\"In those days we imagined ourselves as being in a holding pen, waiting to be released into our lives. And when that moment would come, we would be at university. How were we to know that our lives had already begun, and our release would only be into a larger holding pen? And in time, a larger holding pen.\"</p> </li> <li> <p>\"This dagger was far too sharp, so its surface was incomparably smooth. It could pass through innumerable flowers and not carry away the slightest fragrance, enter the mortal world and not stir its red dust, pierce through all things and yet not disturb them!\"</p> </li> <li> <p>\"Never trust anything that can think for itself, if you can\u2019t see where it keeps its brain.\"</p> </li> <li> <p>\"Always use the proper name for things. Fear of a name increases fear of the thing itself.\"</p> </li> <li> <p>\"After all, to the well-organized mind, death is but the next great adventure.\"</p> </li> <li> <p>\"It does not do to dwell on dreams and forget to live.\"</p> </li> <li> <p>\"Strange how nearsighted being invisible can make you.\"</p> </li> <li> <p>\"There is a moment of confusion when a land animal enters the water. Beast, human, or fairy, it doesn\u2019t matter. The surface is broken and every sense is suddenly shocked. The cold stings, motion slows, and the eyes are filled with smears of color and the snap of bursting bubbles. The time stream is like that moment sustained.\"</p> </li> <li> <p>\"The world is bigger than you know and scarier than you might imagine. The only currency worth anything is being true to yourself, and the only goal worth seeking is finding out who you truly are.\"</p> </li> <li> <p>\"Stephanie didn\u2019t like school. She found it difficult to get along with her classmates \u2013 not because they weren\u2019t nice people, but simply because she had nothing in common with them. And she didn\u2019t like teachers. She didn\u2019t like the way they demanded respect they hadn\u2019t earned. Stephanie had no problem doing what she was told, just so long as she was given a good reason why she should.\"</p> </li> <li> <p>\"But why can\u2019t I react the way everyone else seems to? Why am I so different?\"</p> </li> <li> <p>\"Dammit, I am better than they are, I don\u2019t need them, I don\u2019t need their stupid approval!\"</p> </li> <li> <p>\"Gods, it was so simple\u2014just don\u2019t give a damn. Don\u2019t care what they do to you, and they do nothing.\"</p> </li> <li> <p>\"Indifference was a defense now, and not just a pose.\"</p> </li> <li> <p>\"If no one touches me\u2014no one can hurt me. All I have to do is never care.\"</p> </li> <li> <p>\"Armor does more than protect; it conceals. Helms hide faces\u2014and your opponent becomes a mystery, an enigma.\"</p> </li> <li> <p>\"That\u2019s what you do when you love someone\u2014you notice and notice and notice.\"</p> </li> <li> <p>\"This was his spirit, his integrity. Some things in the world are more important than life or death, and that noble, unbendable, unbreakable spirit is dignity!\"</p> </li> <li> <p>\" But as the saying goes, if you ride a tiger, it\u2019s hard to get off.\"</p> </li> <li> <p>\"To follow the path of spirituality, one must abandon the mortal world. You are no longer a mortal. You are a Cultivator, destined to defy the Heavens. If you are not strong, then you are not qualified to exist. If you are not strong, you are not qualified to practice Cultivation. If you are not strong, then you are not qualified to stay alive, but only to be trampled over. Are you willing to live this kind of life?\"</p> </li> <li> <p>\"Existence was truth. The world is fundamentally unreasonable, and naturally, there is no true fairness.\"</p> </li> <li> <p>\"This is obviously a lake,\" he said suddenly. \"Why do people call it the North Sea?\" The old man thought for a moment, then smiled. \"Lakes can dry up, grow quiet, and become still. If that happened, no living things would remain. But seas last forever, and can contain the water of countless rivers and lakes. Maybe people just didn\u2019t want the lake to ever go away, so they named it that way. When all is said and done, if you believe it\u2019s a lake, then it\u2019s a lake. If you believe it\u2019s a sea, then it\u2019s a sea.\"</p> </li> <li> <p>\"I\u2019m no longer part of the mortal world, and yet, it\u2019s hard to sever all the ties.\" He closed his eyes. \"Well, if they can\u2019t be severed, then I shall just let them remain.\"</p> </li> <li> <p>\"It\u2019s like the sages said, if you don\u2019t take a first step, you will never know which direction the road leads.\"</p> </li> <li> <p>\"Life is an ever-burning flame, filled with exuberance. In life, one must be strong, and never lower one\u2019s head.\"</p> </li> <li> <p>\"I am the snow during winter. If I get too close to summer, then\u2026 summer will melt me. That is not the world of snow, nor is it my world.\" Meng Hao disappeared into the distance. He looked like a scholar, but deep down, he was as cold as snow.\"</p> </li> <li> <p>\"If you seek an answer to your questions, perhaps you should also examine your own heart.\"</p> </li> <li> <p>\"Don\u2019t search too hard for an answer. If you do, the answer you find might be false. At some point in your life, perhaps you will be able to find the answer. Don\u2019t give up.\"</p> </li> <li> <p>\"History dictates that he who holds wisdom can be the greatest fool.\"</p> </li> <li> <p>\"Life is comprised of one experience after another. Or, you could say that life is comprised of many experiences. Different experiences lead to different lives; if you experience a cold bitter wind, you will become snow. If you experience scorching heat, you will become rain\u2026. Whatever you experience in life will shape the person you are. That is what makes life wonderful.\"</p> </li> <li> <p>\"Reading ten thousand books, travelling ten thousand roads. It\u2019s hard to say how many tens of thousands of kilometers I\u2019ve travelled so far. Mountains fill the horizon. Everything I\u2019ve seen and heard fills my heart like an ever-growing sea.\"</p> </li> <li> <p>\"People who share the same fate have no need to make things difficult for each other. \"</p> </li> <li> <p>\"However, Meng Hao\u2019s personality was such that, the more he wished to kill someone, the more taciturn he became. He had been like this when small, and was even more so now. The more quiet he was, the more vicious he grew. People who like to roar and scream were mere philistines. People who maintained their silence were the truly frightening ones!\"</p> </li> <li> <p>\"Their gazes locked. There were a thousand people in between them, but despite the distance and the time, they were not far apart. Rather, they were very, very close to each other.\"</p> </li> <li> <p>\"His path could only be tread by he himself. Perhaps his path would cross the paths of others, and that was well and good. But for the moment, he needed to walk alone. Unless\u2026 he could be powerful enough to forge his own road. Change everything. The alternative was to live a life full of sighing.\"</p> </li> <li> <p>\"With desire, comes incompleteness. If I have no desire, then the storms will not touch me.\"</p> </li> <li> <p>\"Honest people don\u2019t need to speak with hidden words.\"</p> </li> <li> <p>\"He wasn\u2019t the type to be inclined to depend on others. Unless he had an important purpose, he preferred to be like the sea and the sky, free to roam as he wished, alone. For a man to roam under the heavens, enjoy the scenery, observe the beauty of the earth and the animals\u2026 that was what life meant to Meng Hao.\"</p> </li> <li> <p>\"The Heavens are not the Heavens, the Earth is not the Earth. The stars are eternal, and the Dao will always be!\"</p> </li> <li> <p>\"Conforming to convention is emptiness,\" replied Meng Hao. \"Yielding to and complying with the Heavens is well and good. Unending persistence is fine, too. However, I cannot choose either of those. He was like the Perfect Foundation, not permitted by Heaven and Earth, and the target of extermination by Tribulation Lightning. However, he would continue onward. That was how he differentiated himself from others; his path was not one of inflexible adherence to the rules. \"</p> </li> <li> <p>\"Along the path of the Dao of alchemy, if a hundred flowers bloom, who has the right to permit only the Mudan peony to exist? Cannot the lesser peony and the orchid also coexist? Thus is birthed the flower garden. If the medicinal plant garden only contained one medicinal plant, how could the Dao of alchemy come into being? \"</p> </li> <li> <p>\"Most people are not capable of truly seeking death; the desire to live is ever-present. The only people who will truly seek death are\u2026 those whose lives are a living hell!\"</p> </li> <li> <p>\"When a painter observes millions of mountains, then paints one, perhaps his painting contains the essence of the mountains he observed. However, the mountain he paints\u2026 is not real. It emerges from his imagination, and is what he believes a mountain to be. In truth, he has already forgotten the first mountain he ever saw, because he has seen too many. He has also forgotten the feeling he experienced when he gazed at that first mountain\u2019s peak. Millions of streams fuse together to become a great and boundless river. But that river\u2026 is no longer the stream it once was. It is the amalgamation of many waters, fused together and indistinguishable. That first tiny stream which dreamed of being a river is now dead, killed by the very process it desired. The process of his pursuit causes the painter to forget that first mountain, and because of that, the very reason he wished to paint a mountain in the first place. The process of becoming a river causes the stream to lose itself. Its will is diluted as it becomes a river, and then it is gone.\" As he spoke, Meng Hao\u2019s voice grew louder.\"This is my third question. By fusing many schools of thought, you lose yourself. You think you have benefited, but in reality, you have no path of your own. If you have no ideal of your own to adhere to, then you have observed millions of mountains, but forgotten why you wanted to paint a mountain to begin with! Without principles of your own to stick to, then you are a stream that has become a river. However, such a river has no soul! That, is true death!\" Meng Hao flicked his wide sleeve. His words poured into Chen Jiaxi\u2019s ears and sent his mind spinning. As Cultivators, we must adhere to our own set of principles. As alchemists, we must adhere to our own Dao of alchemy. Acquaintances and other schools of thought can bolster or support our confidence. But we must never allow the process of the search to result in losing our own ideal. If the heart is unyielding, nothing can ever supersede it. This type of heart may seem as if it contains transformations, but in reality, is stable, a foundation. From beginning to end, it will never disappear. It will always exist. An unchangeable heart\"</p> </li> <li> <p>\"Because the self never changes, the heart can tolerate the ever-changing transformations of the sun and moon, the maelstroms of Heaven and Earth, and those arduous journeys through thousands of crags and tens of thousands of torrents.\"</p> </li> <li> <p>\"As people grow in life, they form nets to fall back on\"</p> </li> <li> <p>\"Heaven and Earth are just resting places for the myriads of living creatures. Time represents the passage of hundreds of generations of passing travellers.\" A smile broke out on Meng Hao\u2019s face. Life is a journey, every turn of which is filled with new scenery. This path that he tread now contained his mark. Whether the mark was shallow or deep didn\u2019t matter. That was because, it was his choice. \"Maybe my path hasn\u2019t even arrived.\" He shook his head. Perhaps in the future he would realize what his purpose in life was. For the moment, he still didn\u2019t know. Since he didn\u2019t know, he wouldn\u2019t force himself to choose. When traveling, it is never possible to know what unfathomable things might occur. That is what makes it beautiful.\"</p> </li> <li> <p>\"Cultivators have what it takes to stand up to Heaven and Earth. Cultivators have the stubbornness to never bow their heads, no matter how bloody the battle. That is a Cultivator. To me, a Cultivator is someone who stands, covered in blood, hair snow white, facing a host of enemies. And yet, no matter the danger, no matter how difficult the path, a Cultivator will grit his teeth, lift his head up and laugh! In this manner, he will become a legend! That is what a Cultivator is to me.\"</p> </li> <li> <p>\"Entombed on the Earth, but desirous of a return to life in the Heavens\u2026.\"</p> </li> <li> <p>\"There are some things I hesitate to do, but after I do them, I feel no regret.\"</p> </li> <li> <p>\"Sometimes, the meaning of an entire life can be only because of a chance meeting.\"</p> </li> <li> <p>\"What Cultivators truly cultivate, is self-confidence, and even more importantly, self-awareness. I have to say that \u2026 I, Meng Hao, do not dare to call myself a straightforward and upright person. Nor am I a gentleman, or a man of honor. But I always repay the kindnesses shown to me!</p> </li> <li> <p>\"In Confucianism, there is a concept of a path of justice that contains two parts. One part involves being kind and tolerating others. The other involves taking action when necessary. After entering the Cultivation world, Meng Hao also had his own path. This path had nothing to do with Cultivation, but rather, personal principles. Meng Hao\u2019s principles also contained the concept of justice, a justice with two parts. One was the law of repaying kindnesses. The other was bringing death in response to attacks! Cultivation is about developing confidence. Cultivation is about learning how to conduct oneself!\"</p> </li> <li> <p>\"Sowing contains reaping, reaping contains sowing. Everything that happened before was all sowing. Karma was reaped after I led the Crow Divinity Tribe out of the north all the way to the Black Lands. \"It is similar to repaying kindnesses. The kindness is the sowing of Karma, and the repayment is the reaping of it! \"Karma is about cause and effect. I\u2026 understand now.\"</p> </li> <li> <p>\"Life and death oppose each other but also exist in a cycle. Without life, how could there be death? And without death\u2026 what could serve as a contrast to life!?\"</p> </li> <li> <p>\"Within the sea, time is forgotten. Endless coldness, knows no years.\"</p> </li> <li> <p>\"Death is oftentimes quite simple. Life is oftentimes quite fragile.\"</p> </li> <li> <p>\"Emotions\u2026 are not a hindrance,\" he murmured. \"Emotions\u2026 are what make life complete.\"</p> </li> <li> <p>\"The world is an ever changing system of relationships and structures\"</p> </li> <li> <p>\"Some say continuing to do the same thing over and over again is the definition of insanity. On the other hand you say if at first you don't succeed try try and try again.\"</p> </li> <li> <p>\"I can not only imagine artificial intelligence evolving spontaneously on the internet, but I can\u2019t tell you that it hasn\u2019t happened already. Because it wouldn\u2019t necessarily reveal itself to us.\"</p> </li> <li> <p>\"Civilisation is always about four square meals away from ruin.\"</p> </li> <li> <p>\"On the internet nobody knows if you are a dog.\"</p> </li> <li> <p>\"Time is like a dream. It\u2019s impossible to tell what is true and what is false. When you dream, you see others. Perhaps in the world of others, the dream version of you appears. Or perhaps our lives are like an invisible bubble that could pop at any time, and cause us to awaken. Who dreams of you, and who you dream of\u2026 this is truly a difficult riddle to explain\u2026.\"</p> </li> <li> <p>\"I thought that when I saw you, I would have the world. I didn\u2019t know that within your dreams, you already had me.\"</p> </li> <li> <p>\"Ten thousand things, all in this breath grasping hold of emptiness, there really is nothing to say. Why are people so busy? Just for this one breath, People say busy, busy; mine, mine. Busy a whole lifetime for Me\u2019. When this one breath is let off, you let go of this whole universe, why not let go from the start?\"</p> </li> <li> <p>\"You want to talk about real. Show mean thing that is real. There is nothing real from the start. Every morning to night, gathering things, big and small, valuables, money name and recognition; gathering it all up into your lap. Busy your whole life for nothing, acting like a thief, why not put all this energy into liberation? Put this mind to the Way. Everyone in the world is controlled by this, shed this control and then you'll be free, content, liberated. Though there are words to speak, none of this is real. Talk and talk, like flowers falling from heaven its all worthless. If you think what you are grasping is real, theres no good in that, you can't take it with you.\"</p> </li> <li> <p>\"I realised people can't escape birth and death. The people who make you so happy, the people you can't live without, they leave you.</p> </li> <li> <p>\"Before he realized what was happening, the feeling of the passage of time appeared in Meng Hao\u2019s heart. He sighed inwardly. Sometimes, it is only when encountering old friends that such a feeling will give rise to sighing and sobbing.\"</p> </li> <li> <p>\"After all, the most moving thing of all is love\u2026. And although romantic love is beautiful, it pales in comparison to the selflessness of family love\"</p> </li> <li> <p>\" The love of a father is more reserved, more silent, like a mountain. When you are a child, your father is your guardian angel. When you are a teenager, things change. He becomes an obstacle. After that, you come to view yourself as the superior, with him beneath you. Once you reach middle age, though, you look at that mountain and you suddenly realize that he has been there all along, watching you proudly. However arrogant you were, however selfish and narrow-minded, he would forgive you. Forgive you without even saying a word. You will feel forlorn, and will suddenly come to a realization. That\u2026 is the love of a father. When you have it, you might not feel it deeply. However, once you lose it, you lose the Heaven of your heart! When a child wishes to care for a parent, only to find that the parent is no longer there, well\u2026 that is a sorrow that gives rise to the most profound of weeping.\"</p> </li> <li> <p>\"Living and dying. It can be a departure, but also a beginning.\"</p> </li> <li> <p>\"If you believe it to be a sea of bitterness, then a sea of bitterness it is. If you believe it to simply be scenery on the path of life, then scenery it is\u2026. The sea of bitterness never ends, but the scenery does.\"</p> </li> <li> <p>\"Many years ago, there was a withered slave on this mountain who said that life is pain, and that he wished to free himself from the sea of bitterness. That sea is like an inescapable flame which can burn everything. \"Afterwards, he called this place Withering Flame, and made a solemn vow that he would eradicate the sea of bitterness. He would ensure that all living things no longer experience bitterness, but rather, freedom! \"If you were in his place, what would you do?!\"He was right, but also wrong,\" murmured Meng Hao. \"This could be viewed as a sea of bitterness, but also\u2026 not. If you believe everything to be bitterness, then it is. If you believe that everything is not bitterness, then it is not. \"Leaping into the pit of fire represents death. Reappearance at the bottom of the volcano represents birth. The climb up the mountain represents the process of life\u2026. \"I would not swear to eradicate this place. Nor would I sink myself into cowardliness. What I have\u2026 is the determination to set my foot where I wish to set it. I control my own fate. I may not be able to control my own birth, but I can decide how I die. \"And the final destination will definitely NOT be the pit at the top of the volcano.\"</p> </li> <li> <p>\"The path of life does not just run from the bottom of a mountain to its top\u2026.\"</p> </li> <li> <p>\"The great ancestor once said that rain\u2026 is born in the Heavens and dies in the Earth. The passage between those two places is its entire life\u2026.\"</p> </li> <li> <p>\"You can't push things. Push hard and you get hardships. Everything's  a trial. You can't be afraid of hardship. The more the hardships, the more you move forward.\"</p> </li> <li> <p>\"The truths of life and death are something that cannot be understood by someone who has not died.\"</p> </li> <li> <p>\"The Eternal is something that exists eternally within me. No living thing in Heaven and Earth can do anything to take it away from me. Even the will of Heaven and Earth itself would be incapable of wresting away the Eternal which belongs to me! \"The Eternal is a type of determination, an overbearing attitude! \"What is mine, belongs to me alone!\"</p> </li> <li> <p>\"The deepest expression of love is simply to stay with someone\u2026.\"</p> </li> <li> <p>\"Men do not, at times, talk like that. Sure some individuals with an X and Y chromosome like you may say something like that, but we do not call them Men. We call them perverts, abusers, or rapists - not Men. Real Men don't do that and wouldn't even think to say that. You will hear a lot of people tell you what Men do or what it takes to 'be a Man'. The vast majority of it will be total garbage. If you want to be a Man, forget about machoism or sexual conquest. Being a Man is not about that. It's  about protecting those around you who are weak or innocent - maybe a child being bullied or your own children. It's  being awake at all hours of the night to warm a bottle, change a diaper, change the sheets on a wet bed or even worse. Men get puked on, pooped on, bled on and cried on. It's  about being open with someone, vulnerable and accountable. It's  admitting your mistakes and failures - in all its ugliness - and seeking forgiveness, over and over and over again. Real Men play dress up and enjoy tea parties and will make a complete fool out of themselves just to hear a child laugh. They cry, even weep, when the situation calls for it. They respect, honor and cherish women because all of them are human - created in the image of the Creator. It\u2019s tough being a Man. Hardest work you'll ever do. So when someone tries to justify abhorrent words and d by sullying your good reputation as a Man - be angry and speak up. Don't let them define you down by their conduct. In short - be a Man.\"</p> </li> <li> <p>\"Never forget, the word cultivation \u4fee\u884c is made of two characters, \u4fee which implies studying and practice, and \u884c which implies action. It is not enough to just have \u4fee, the studying and learning. You must also have \u884c, action\u2026. You must always strive forward; that is the way to reach the pinnacle of power!\"</p> </li> <li> <p>\"Without the presence of despair, if someone is given hope, they might not attach too much importance to it, especially if they have a steadfast heart and an unchangeable Dao. However\u2026 if you torment someone to their limits and place them in the midst of despair, then give them a sudden scrap of hope, an opportunity to be extricated, then most people would not hesitate to grab that chance.\"</p> </li> <li> <p>\"Before the world appeared, before the beginning of Heaven and Earth, before time could even be calculated, perhaps\u2026 there were no such things as Immortals. Therefore\u2026 how did the first Immortal come to be?! That first Immortal definitely walked his own path. He must have tried many things, and must have suffered many defeats before he finally found the correct path. The first person to succeed called himself Immortal, and that is how Immortals came to be. It must have occurred in that way. Therefore, I can do the same thing. I, Meng Hao, will become an Immortal in MY way!\"</p> </li> <li> <p>\"A youngster who is angry but speaks nothing of it is truly significant\"</p> </li> <li> <p>\"There is a fine line between a genius and an idiot and that line is possibility.\"</p> </li> <li> <p>\"The first step of the Purification stage was to concentrate one\u2019s mind. The mind is the human\u2019s core of spiritual strength. To explain it clearly, \"it\u2019s the thought that counts\". If one\u2019s thought was concentrated and strong enough, then it would turn into a certain power. Although it may sound easy, in reality it\u2019s not. Even if an ordinary person struggled extremely hard and imagine that they can fly freely in the sky, they are still trapped on the ground. This is because the power of mind depends on the strength of one\u2019s soul, and the soul\u2019s strength depends solely on talent and is unrelated to one\u2019s effort.\"</p> </li> <li> <p>\"A fourteen year old kid aroused himself again from disappointment and loss. The time taken was indeed too little. He had to appreciate all of his past experiences and the things that he would experience soon but of course the benefits that he experience won\u2019t be liked by others. He had no time to feel disappointed, he could only keep trying. If not succeed, then die. These five words were most prominent in his mind.\"</p> </li> <li> <p>\"He realized that matter how he followed his heart and calmed his mind, he couldn\u2019t completely diminish vanity and some other feelings.\"</p> </li> <li> <p>\"But what should we do? There are so many villains in the world. Unless you mimic me and hide in mountain to farm, there will always be some changes that you have to accept.\"</p> </li> <li> <p>\"With a mirror, one can adjust their clothing, but they can also adjust their attitude.\"</p> </li> <li> <p>\"There was no rule saying that when two people sit together, they must speak. Sometimes it\u2019s fine to just sit there quietly. Even if they need to converse, they don\u2019t need to speak. A simple gesture will suffice.\"</p> </li> <li> <p>\"Time, is the only standard with which to judge the world.\"</p> </li> <li> <p>\"Even if there hasn\u2019t been anything similar in the past, it doesn\u2019t mean it\u2019s impossible for the future.\"</p> </li> <li> <p>\"Any life that could calmly face and challenge death was worthy of respect.\"</p> </li> <li> <p>\"Wanting to reach the other shore, really does require boundless wisdom.\"</p> </li> <li> <p>\"A child that is overly honest, will easily cause others to get angry over their words. That\u2019s because an honest child speaks the truth\"</p> </li> <li> <p>\"What is destiny? There are numerous ways to express this one word: The rich and poor, bitter experiences in the course of life, the uncertain ups and downs of life, or perhaps the mysterious divine intervention? If the destiny is really unknowable and also an immutable existence, then its presence should not have any significance in the first place. When the heavenly book was born into the world, the people began to practice (cultivate). They started borrowing the strength of the heaven and transformed it into their own natural strength, but the cultivators would naturally not accept this assertion. They would want to think that the destiny is derived from their own dauntless spirits and the courage they possess to make a change according to their wishes. Each cultivator has an initial connection with the world and his destiny is determined by the arrangement of stars in the sky. Therefore, the people\u2019s understanding of their destiny is ultimately dependent on the boundless ocean of stars that appears in a starry sky. Since ancient times, the stars in the sky, regardless of their position or brightness, are given the same value. They are solemnly and eternally illuminating the world. It is said that there are infinite lines joining these seemingly countless stars to form infinite complex patterns which cannot be fully portrayed. Looking at the starry sky, many people would feel their hearts racing and beating rapidly in a response to their praise for the beautiful scene and the complex patterns hidden in this boundless ocean of stars. It is very natural to think that something of extremely profound significance is hidden within these patterns.\"</p> </li> <li> <p>\"The world doesn\u2019t have the road because the road is under your feet. Only you can decide which road you must take and that is what decides your unique journey. Only you can choose your own position on this stage we call the world. Therefore, there is no such thing as fate, but only choices we make and they are entirely in our control.\"</p> </li> <li> <p>\"Therefore, there is no such thing as Fate, but only choices.\"</p> </li> <li> <p>\"But how beautiful wasting one\u2019s life in this manner was. And how beautiful it was to have a life to waste in such a manner.\"</p> </li> <li> <p>\"The positions were relative, and the appearances were also relative. As positioning changed with landmarks, the appearances changed with environment. If one wanted confirm one\u2019s position, one needed to also confirm the position of the surrounding landmarks. If one wanted to examine the unvarying and objective truth, then should not one first understand how the environment affected the objective reality?\"</p> </li> <li> <p>\"Ten thousand streams, each with a different scenery, but in the end they all join the ocean.\"</p> </li> <li> <p>\"Martial Granduncle said that they couldn\u2019t waste their limited lives on unlimited trifling matters.\"</p> </li> <li> <p>\"To cultivate the Dao is to cultivate the heart. One\u2019s nature determines one\u2019s fate, and it will also decide how far one is able to walk in the Dao.\"</p> </li> <li> <p>\"This time, he would have to get even more serious to live\u2014to live so that death could see.\"</p> </li> <li> <p>\"Senior said, even if you try your best till the end and end up finding out that it was still impossible to change fate, then you can only appreciate and enjoy everything life has brought you.\"</p> </li> <li> <p>\"Yet just like death, no matter how many preparations you make, when it finally makes its appearance, you realise that you still aren't prepared.\"</p> </li> <li> <p>\"To confide their deepest feelings to each other? Was this a phrase? He wasn't too sure. It was very much a strange and alien emotion that he had never touched on before. That was a very sweet sort of emotion, and yet it also made one afraid, uneasy, but this made one yearn for it. Most importantly, the sorrow and joy elicited by this emotion was so intense that it at times seemed more important than all else.\"</p> </li> <li> <p>\"A casual dot of ink could also be the dot of an eye. An ordinary brushstroke could at times bring an entire painting to life.\"</p> </li> <li> <p>\"At times, the things and encounters of the world were truly very coincidental, very unfathomable.\"</p> </li> <li> <p>\"As time goes by, the thoughts of people often change in ways that they would never have imagined at the very beginning.\"</p> </li> <li> <p>\"Even if you wish to put into practice your view of the world, there is no need to rush to do it all at once.\"</p> </li> <li> <p>\"The word 'impossible' had no meaning to him. Because he was not allowed to think it impossible.\"</p> </li> <li> <p>\"Rumors often arise from the truth, and at times, the truth may be even more bizarre than the rumor.\"</p> </li> <li> <p>\"It was at this moment that a clear and cold voice could be heard through those layers of white curtain. \"The road of cultivation is long and endless, but since you've already stepped upon it, how can you stop? As long as you incessantly press forward, there will come a time when you walk to that day. There's  no need to worry about whether you arrive early or late, let alone a need to care about victory or defeat, and why should the slander or praise of the world disorder your heart? Could it be that you haven't even understood this yet?\"</p> </li> <li> <p>\"Whether it's  human nature or the human heart, you cannot test them, because when you begin to think about methods to test them, that would mean that you have already begun to doubt.\" The Pope lastly said, \"And doubt is the source of all misfortune.\"</p> </li> <li> <p>\"If you were to know that only several dozen days remained of your life, how would you pass your time? Compile all those things you wanted to do but never did into a wishlist and then sell your home and fields and go off to achieve these things? Or would you hide away in some dark corner of your room, your face bathed in tears every day? Or would you disregard all morals and laws, indulging in your deepest desires and evil thoughts?\"</p> </li> <li> <p>\"The only true currency in this bankrupt world is what you share with someone else when you're uncool.\"</p> </li> <li> <p>\"I always tell the girls, never take it seriously, if ya never take it seriously, ya never get hurt, ya never get hurt, ya always have fun, and if you ever get lonely, just go to the record store and visit your friends.\"</p> </li> <li> <p>\"I  didn't invent the rainy day, man. I just own the best umbrella.\"</p> </li> <li> <p>\"Some people have a hard time explaining rock 'n' roll. I don't think anyone can really explain rock 'n' roll. Maybe Pete Townshend, but that's  okay. Rock 'n' roll is a lifestyle and a way of thinking... and it's  not about money and popularity. Although, some money would be nice. But it's  a voice that says,</p> </li> <li> <p>\"Here I am... and fuck you if you can't understand me.\" And one of these people is gonna save the world. And that means that rock 'n' roll can save the world... all of us together. And the chicks are great. But what it all comes down to is that thing. The indefinable thing when people catch something in your music.\"</p> </li> <li> <p>\"Music, you now, true music - not just rock n roll - it chooses you. It live in your car, or alone listening to your headphones, you know, with the cast scenic bridges and angelic choirs in your brain. It's  a place apart from the vast, benign lap of America.\"</p> </li> <li> <p>\"You CANNOT make friends with the rock stars. That's  what's  important. If you're a rock journalist - first, you will never get paid much. But you will get free records from the record company. And they'll buy you drinks, you'll meet girls, they'll try to fly you places for free, offer you drugs... I know. It sounds great. But they are not your friends. These are people who want you to write sanctimonious stories about the genius of the rock stars, and they will ruin rock and roll and strangle everything we love about it.\"</p> </li> <li> <p>\"When and where does this \"real world\" occur?\"</p> </li> <li> <p>\"In Carl Jung's  opinion, we all have a sixth sense - intuition. When you meet someone and you suddenly feel like you can't live without them. This could be the memory of a past love from the collective unconscious. Or it could just be hormones.\"</p> </li> <li> <p>\"Adolescence is a marketing tool.\"</p> </li> <li> <p>\"Look at this\u2014an entire generation of Cinderellas, and there\u2019s no glass slipper.\"</p> </li> <li> <p>\"The sands of time cannot be stopped. Years pass whether we will them or not . . . but we can remember. What has been lost may yet live on in memories. That which you will hear is imperfect and fragmented, yet treasure it, for without you it does not exist.\"</p> </li> <li> <p>\"There are forces circling us that we aren\u2019t aware of. Sometimes I wonder if we can ever understand the true motives of the people around us. They all seem to have secrets. It is the way of the world. Ignore all the schemes and trust in the nature of each person\"</p> </li> <li> <p>\"Being a magician has always been about, in part, accruing power. Power over yourself, the elements, the future. But power, as you all know, does not come cheaply.\"</p> </li> <li> <p>\"Magic doesn't come from talent, it comes from pain.\"</p> </li> <li> <p>\"Kady: Why can't anything just be fixed. Penny: Life, I guess.\"</p> </li> <li> <p>\"The truly intelligent person will never reject the slightest chance of survival.\"</p> </li> <li> <p>\"It was darkest before dawn. When these words were usually spoken, the meaning often desired was that as long as one was able to endure this darkest hour, one would be able to welcome a bright and beautiful morning, the principle being that hope was forever. However, when dawn truly came, just what did it have to do with that darkest hour? Time was life and once it went, there was no turning back. There had never been any connection between another person's light and one's  own darkness.\"</p> </li> <li> <p>\"To cultivators, life is an extremely long course of events. In this course of events, we will encounter many challenges, feel much despair, and this is our predestined fate. And how should we confront this predestined fate? To happily live on as if given a new lease on life, or to undergo serious contemplation before finding ourselves once more, that is the greatest distinction.\"</p> </li> <li> <p>\"The past is the past; such is time. Similarly, the movement of the stars, the changes of fate, all proceed forward, and so we can only look forward.\"</p> </li> <li> <p>\"If you want to live forever, you have to be powerful enough to walk out into the heavens. That\u2019s a very long road, and you can\u2019t let yourself get distracted by the scenery along the way. You have to walk the path and live life without any regrets!\"</p> </li> <li> <p>\"There were few things in life as terrifying as two women who hated each other\u2026.\"</p> </li> <li> <p>\"There was nothing without risk. Even walking on the street, one might be killed by a rock falling down from the skies. Even when eating, one might choke to death.\"</p> </li> <li> <p>\"Dripping water can eventually tunnel through a rock\"</p> </li> <li> <p>\"Hahaha, that\u2019s my boy. Right; don\u2019t easily give up or betray your good friends and brothers! If you can so easily sacrifice them\u2026then you\u2019ll never be able to make any true friends and brothers! If you wish for others to be willing to risk their lives for you, you have to treat them with sincerity, understood?\"</p> </li> <li> <p>\"The path of Immortal cultivation is filled with many dangers and obstacles. Thus, with each step, you need to leave a firm footprint as you walk forward in a stable manner. Your heart must be stable as well. This is indeed true\"</p> </li> <li> <p>\"However\u2026everything in this world is divided into yin and yang,\" Patriarch Subhuti said. \"Although it is important to be stable and solid, it is also important to be sharp.\"</p> </li> <li> <p>\"The path of Immortal cultivation\u2026 your goals should be distant and grand, with Pangu and Nuwa as your models. The path of Immortal cultivation\u2026it requires you to lower your head and watch the road, for you to remember to maintain a solid foundation. Do not merely think about soaring into the skies; when a bird soars too far, its eggs might be stolen and destroyed. It will perish, its Dao gone. The path of Immortal cultivation\u2026it requires caution. It is a boat that will sail for ten thousand years that you must control with care. The path of Immortal cultivation\u2026it requires sharpness. Only with a heart that is filled with a desire to charge into the heavens can you walk even farther on this path.\"</p> </li> <li> <p>\"How to make your goals grand but not too high\u2026how to be cautious and yet have the desire to charge into the heavens\u2026you will need to handle this yourself. The world is divided into yin and yang, and between yin and yang lies the heart.\"</p> </li> <li> <p>\"Good. That\u2019s the attitude I like to see. Defeat isn\u2019t frightening; what\u2019s frightening is not even having the courage to try.\"</p> </li> <li> <p>\"But there are no absolutes in life. There\u2019s always a chance.\"</p> </li> <li> <p>\"Stupidity does not mean you have the power to speak unreasonably, nor is it something that requires respect.\"</p> </li> <li> <p>\"Skill from diligence; incompetence from indulgence. I dare not slack off.\"</p> </li> <li> <p>\"What will people think of your 's cience' two thousand years from now?\" Mr. D continued. \"Hmm? They will call it primitive mumbo jumbo. That's  what. Oh, I love mortals\u2014they have absolutely no sense of perspective. \"</p> </li> <li> <p>\"There is no sound more annoying than the chatter of a child, and none more sad than the silence they leave when they are gone.\"</p> </li> <li> <p>\"A Dark time comes. My time. If it offends you. Stop Me.\"</p> </li> <li> <p>\"I think you're enough like me to understand. If my life is going to mean anything, I have to live it myself. I can't let a god take care of me ... or my son. I have to . . . find the courage on my own. \"</p> </li> <li> <p>\"Families are messy. Immortal families are eternally messy. Sometimes the best we can do is to remind each other that we're related, for better or worse ... and try to keep the maiming and killing to a minimum.\"</p> </li> <li> <p>\"The most dangerous flaws are those which are good in moderation,\" she said.</p> </li> <li> <p>\"Evil is easy to fight. Lack of wisdom... that is very hard indeed.\"</p> </li> <li> <p>\"Happily Ever After doesn\u2019t exist. Every day you wake up and decide to love your partner and your life\u2014the good, the bad and the ugly. Some days it\u2019s a struggle and some days you feel like the luckiest person in the world.\"</p> </li> <li> <p>\"When you commit to someone, you don\u2019t actually know who you\u2019re committing to. You know who they are today, but you have no idea who this person is going to be in five years, ten years, and so on. You have to be prepared for the unexpected, and truly ask yourself if you admire this person regardless of the superficial (or not-so-superficial) details, because I promise almost all of them at some point are going to either change or go away.\"</p> </li> <li> <p>\"Relationships exist as waves, people need to learn how to ride them.\"</p> </li> <li> <p>\"You can work through anything as long as you are not destroying yourself or each other. That means emotionally, physically, financially, or spiritually. Make nothing off limits to discuss. Never shame or mock each other for the things you do that make you happy. Write down why you fell in love and read it every year on your anniversary (or more often). Write love letters to each other often. Make each other first. When kids arrive, it will be easy to fall into a frenzy of making them the only focus of your life\u2026do not forget the love that produced them. You must keep that love alive and strong to feed them love. Spouse comes first. Each of you will continue to grow. Bring the other one with you. Be the one that welcomes that growth. Don\u2019t think that the other one will hold the relationship together. Both of you should assume it\u2019s up to you so that you are both working on it. Be passionate about cleaning house, preparing meals, and taking care of your home. This is required of everyone daily, make it fun and happy and do it together. Do not complain about your partner to anyone. Love them for who they are. Make love even when you are not in the mood. Trust each other. Give each other the benefit of the doubt always. Be transparent. Have nothing to hide. Be proud of each other. Have a life outside of each other, but share it through conversation. Pamper and adore each other. Go to counseling now before you need it so that you are both open to working on the relationship together. Disagree with respect to each other\u2019s feelings. Be open to change and accepting of differences.\"</p> </li> <li> <p>\"The wine god sighed. \"Oh, Hades if I know. But remember, boy, that a kind act can sometimes be as powerful as a sword. As a mortal, I was never a great fighter or athlete or poet. I only made wine. The people in my village laughed at me. They said I would never amount to anything. Look at me now. Sometimes small things can become very large indeed.\"</p> </li> <li> <p>\"Poseidon put his weathered hand on my shoulder. \"Percy, lesser beings do many horrible things in the name of the gods. That does not mean we gods approve. The way our sons and daughters act in our names...well, it usually says more about them than it does about us. \"</p> </li> <li> <p>\"Sometimes the hardest power to master is the power of yielding. Do you believe me?\"</p> </li> <li> <p>\"You can't beat me, Oliver. Yes, you're younger and you're faster, yet you always come up short against me. Wanna know why? Because you don't know, in your heart, what you're fighting for. What you're willing to sacrifice. And I do.\"</p> </li> <li> <p>\"So you'll atone for one murder, Robert, by committing hundreds, thousands?\"</p> </li> <li> <p>\"Nothing is bred that is weaker than man.\"</p> </li> <li> <p>\"You are so blinded by your hate for him that you don't realize the damage that it's  doing in your own life. To your family.\"</p> </li> <li> <p>\"You'd be surprised the power revenge can give you.\"</p> </li> <li> <p>\"I'm giving up a lot so maybe I thought the universe owed me one.\"</p> </li> <li> <p>\"Dead people don't want anything, that's  one of the benefits of being dead.\"</p> </li> <li> <p>\"Home is a battlefield. Back home, they're all trying to get you. Get you to open up, be somebody you're not sure you are anymore.\"</p> </li> <li> <p>\"The strongest of the warriors are time and patience. \"</p> </li> <li> <p>\"A man cannot live with two names.\"</p> </li> <li> <p>\"Pain is inevitable, suffering is optional.\"</p> </li> <li> <p>\"Boys have dreams so go chase them, youth is your capital. Youth represents the infinite possibilities that the future holds. FIGHT!\"</p> </li> <li> <p>\"This is life, who can you blame?\"</p> </li> <li> <p>\"However\u2026.. right when they were about to leave, Luo Feng\u2019s family was a bit hesitant, since there were way too many memories in this home. However, people have to go higher!\"</p> </li> <li> <p>\"The waves in the back always push the ones in the front in the Yangtze river, so of course each generation has to be stronger than the next\"</p> </li> <li> <p>\"So, this world is simple. People respect those with high status and look down on those with low status. If a rich person runs out of money, it\u2019s over for him. If someone with a great position loses that position, his authority will probably disappear too. Position and money are external, only your own strength is truly reliable\"</p> </li> <li> <p>\"Nobody can predict the twists of life\"</p> </li> <li> <p>\"The path to aim for the limits of life is filled with difficulty. Of course I can\u2019t shy away from any challenges! Pedestrians can get hit by a car. Even in a sector, a dropped vase could hit your head. Nothing is absolutely safe!\"</p> </li> <li> <p>\"Man tended to believe that when he learnt any new information, he understood and knew everything. It\u2019s not only till later when he learns more that he realizes how ridiculously wrong he was before. Without even a grasp of Earth\u2019s many species of life and principles, he bases on simple deductions that the whole universe and milky way, and even further cannot have any other forms of intelligent life other than man! How dogmatic. What a joke. The endless seas have yet to be fully explored by Man. What\u2019s more, the universe is so much bigger than the sea, a trillion times maybe? Not even close! The limitless universe, can\u2019t possibly be judged by the humans on earth. Isn\u2019t this synonymous with the story of the frog in the well, thinking that the world and sky is only as big as his well?\" Hong shook his head, \"The civilizations that exist in the universe, race and ethnicities, are complex and mysterious beyond compare.\"</p> </li> <li> <p>\"The people and kingdoms from hundreds of thousands of years back have turned to dust long ago. Compared to the endless march of history, where kingdoms and empires rise then collapse, personal grudges and enmities are so meaningless and small.\"</p> </li> <li> <p>\"Last night I hugged my pillow and dreamt of you. I wish that someday I\u2019d dream about my pillow and I\u2019d be hugging you\".</p> </li> <li> <p>\"Love will travel as far as you let it. It has no limits.\"</p> </li> <li> <p>\"That farewell kiss which resembles greeting, that last glance of love which becomes the sharpest pang of sorrow\"</p> </li> <li> <p>\"A thing is mighty big when time and distance cannot shrink it.\"</p> </li> <li> <p>\"To hear, one must be silent.\"</p> </li> <li> <p>\"It was only the dumb instinctive wisdom of the beast who licks his hurt companion to comfort him, and yet in that wisdom Ged saw something akin to his own power, something that went as deep as wizardry. From that time forth he believed that the wise man is one who never sets himself apart from other living things, whether they have speech or not, and in later years he strove long to learn what can be learned, in silence, from the eyes of animals, the flight of birds, the great slow gestures of trees.\"</p> </li> <li> <p>\"A man would know the end he goes to, but he cannot know it if he does not turn, and return to his beginning, and hold that beginning in his being. If he would not be a stick whirled and whelmed in the stream, he must be the stream itself, all of it, from its spring to its sinking in the sea. \"</p> </li> <li> <p>\"Certain mystes aver that the real world has been constructed by the human mind, since our ways are governed by the artificial categories into which we place essentially undifferentiated things, things weaker than our words for them. I understood the principle intuitively that night as I heard the last volunteer swing the gate closed behind us.\"</p> </li> <li> <p>\"We all can be only what we are, nothing more, or less.\"</p> </li> <li> <p>\"What man has no ill intent in the silence of his soul?\"</p> </li> <li> <p>\"Who is to say what is only a story and what is truth disguised as a story?\"</p> </li> <li> <p>\"Many good and solid men would say so,\" the old man told him, looking up at the stars, \"good men who will live out their lives believing only in what they can see and touch. But there's  a world beyond what we can see and touch, and that world lives by its own laws. What may be impossible in this very ordinary world is very possible there, and sometimes the boundaries between the two worlds disappear, and then who can say what is possible and impossible?\"</p> </li> <li> <p>\"The wizard leaned back against the rock and looked out over the hills, as if seeing more than was there. His tone was sorrowful. \"Because, Richard, many people must be ruled to thrive. In their selfishness and greed, they see free people as their oppressors. They wish to have a leader who will cut the taller plants so the sun will reach them. They think no plant should be allowed to grow taller than the shortest, and in that way give light to all. They would rather be provided a guiding light, regardless of the fuel, than light a candle themselves.\"</p> </li> <li> <p>\"Murder is the way of all things, the way of nature,\" Zedd repeated. \"Every living thing is a murderer.\"</p> </li> <li> <p>\"Life for the strongest. There is no sympathy for the slain, only admiration for the winner\u2019s strength.\"</p> </li> <li> <p>\"If someone digs a hole, and it fills with rainwater, where is the fault? Is it the rain\u2019s fault?\"</p> </li> <li> <p>\"Years from now, our past will be a story - a story of long days and lonely nights, hardwork and lack of sleep. We\u2019ll live each day having intimately known the pain of being apart. We\u2019ll appreciate and embrace our time together knowing how lucky we are to have made it through and we\u2019ll find solace in the promise of a future together.\"</p> </li> <li> <p>\"Contrary to what the cynics say, distance is not for the fearful; it's  for the bold. It's  for those who are willing to spend a lot of time alone in exchange for a little time with the one they love.\"</p> </li> <li> <p>\"It\u2019s not a bug \u2013 it\u2019s an undocumented feature.\"</p> </li> <li> <p>\"Programming is like sex. One mistake and you have to support it for the rest of your life.\"</p> </li> <li> <p>\"I see now that the circumstances of one's  birth are irrelevant; it is what you do with the gift of life that determines who you are. \"</p> </li> <li> <p>\"We do have a lot in common. The same Earth, the same air, the same sky. Maybe if we started looking at what's  the same instead of what's  different... well, who knows. \"</p> </li> <li> <p>\"But walking along Fifth Avenue in Brooklyn, in his black overcoat and his gray interview suit, Quentin knew he wasn\u2019t happy. Why not? He had painstakingly assembled all the ingredients of happiness. He had performed all the necessary rituals, spoken the words, lit the candles, made the sacrifices. But happiness, like a disobedient spirit, refused to come. He couldn\u2019t think what else to do.\"</p> </li> <li> <p>\"You exist inside a spring that can't be replaced.\"</p> </li> <li> <p>\"As if you can see right through me, into my heart... Always, out of nowhere, you... just show up.\"</p> </li> <li> <p>\"Isn't it funny how the most unforgettable scenes can be so trivial?\"</p> </li> <li> <p>\"Even it the depths of the darkest oceans, some light always pierces through.\"</p> </li> <li> <p>\"She's  merciless. That unbending gaze even from the back, she wont let me give up. The one who was being supported..was me. Thank you. Thank you.\"</p> </li> <li> <p>\"After struggling, losing my way, and suffering... the answer I arrived at was so laughably simple...\"</p> </li> <li> <p>\"I'm... going on a journey. The applause raining down. Pursuing that moment when my music reached them. Pursuing that sight of her with her back to me. until one day, for sure, I've pulled even with her... until that day comes.\"</p> </li> <li> <p>\"I knew all along. The ghost of my mother was a shadow of my own creation. An excuse for me to run away. My own weakness. Mom isn't there anymore. Mom... is inside me.\"</p> </li> <li> <p>\"The moment I met her, my life changed. Everything I saw, everything I heard, everything I felt, all the scenery around me... started to take on color.\"</p> </li> <li> <p>\"I want to hear it again, yet I don't want to hear it. I want to see her, yet I don't want to see her. What do you call this kind of feeling again?\"</p> </li> <li> <p>\"A lump of steel, like a shooting star. Just seeing the same sky as you makes familiar scenery look different. I swing between hope and despair at your slightest gesture, and my heart starts to play a melody. What kind of feeling is this again? What do they call this kind of feeling? I think it's  probably called..Love. I'm sure this is what they call love.\"</p> </li> <li> <p>\"I look like I'm suffering, huh? That's  not good... but of course I'd be suffering. I mean, I'm gonna sail in charted waters, right? Both, taking on a challenge and creating something. It is painful, but it's  fulfilling. So thank you. For sweeping away the dust that had collected on my body. .. For encountering me... ever since that day... my world, even the keyboard... became colorful.\"</p> </li> <li> <p>\"You know, I discovered something. Everyone has something... something deep inside their hearts. For some, it might be enmity. For others, admiration. Wishes, a craving for the spotlight, feelings that one wants to deliver, feelings for ones mother. Everyone was supported by their own feelings. I realize now that, perhaps, no one can stand alone on stage.\"</p> </li> <li> <p>\"Letting you go was never easy because the half of my heart joined you and left me.\"</p> </li> <li> <p>\"How can I forgot about you, when everything about you, already became a part of me?\"</p> </li> <li> <p>\"We\u2019re all afraid, you know.. to get up on stage. Maybe you\u2019ll mess up. Maybe they\u2019ll totally reject you. Even so, you grit your teeth and get up on stage anyway. Something compels us\u2026 moves us to play music.\"</p> </li> <li> <p>\"We're all connected. Just like the notes are intermittently connected. It's shared by us all. Through music, with the people you know, with the people you don't know, with all the people in this world.\u2019</p> </li> <li> <p>\"It's  not just allies who support each other. From your enemies, you learn so much and gain so much. Until the day you meet again... Just knowing they exist helps you to withstand the loneliness. Those who compete, even if they're enemies, help each other out.</p> </li> <li> <p>\"Even though I'm bitter over losing, even though I'm depressed, even though my ankle hurts, and my eyes are smeared with tears...even though I've never felt worse...I wonder why the stars are sparkling like this. The scent of the music room in his hair. I can hear his slightly ragged breathing. His shoulder, wet with tears, is so warm. I am by his side. I wish time would just stand still.\"</p> </li> <li> <p>\"In my next life, I want to be me, and meet you again.\"</p> </li> <li> <p>\"If I can get my target to move as I want, I've succeeded as a Hunter.\"</p> </li> <li> <p>\"Ha-ha these humans are definitely foolish creatures. Think as hard as those weak brains of yours can manage. Do you humans ever listen to the cries of mercy coming from pigs and cows you slaughter?\"</p> </li> <li> <p>\"I was trying to take the easy way out by running away from everything. No matter the pain, I will keep living. So when I die, I'll feel I did the best I could.\"</p> </li> <li> <p>\"If you want to get to know someone, find out what makes them angry.\"</p> </li> <li> <p>\"You should enjoy the little detours. To the fullest. Because that's  where you'll find the things more important than what you want.\"</p> </li> <li> <p>\"A beast in human's  clothing understands better than anyone how people want to be treated.\"</p> </li> <li> <p>\"You must be prepared to face the worst possible scenarios. Because harsh reality strikes without warning.\"</p> </li> <li> <p>\"Whenever humans encounter the unknown, they tend to lose perspective.\"</p> </li> <li> <p>\"When I say it doesn't hurt me, that means I can bear it.\"</p> </li> <li> <p>\"I do not fear death. I fear only that my rage will fade over time.\"</p> </li> <li> <p>\"The only principle is that there are no principles.\"</p> </li> <li> <p>\"Skill is one thing, and caution another.\"</p> </li> <li> <p>\"Even the fastest eye can be fooled.\"</p> </li> <li> <p>\"Qualification isn't something we have to talk about. The ones who are not okay with their success can go through training until they are.\"</p> </li> <li> <p>\"I never imagined how frustrating weakness could be\"</p> </li> <li> <p>\"Who wants to have their life planned out for them.\"</p> </li> <li> <p>\"Hunters are a bunch of egomaniacs. We set aside everything else to get what we want.\"</p> </li> <li> <p>\"Human potential for evolution is limitless.\"</p> </li> <li> <p>\"A prayer comes from the heart\"</p> </li> <li> <p>\"Love and hate are two sides of the same coin.\"</p> </li> <li> <p>\"If that monster is your darkness, then I have a reason to fight it, no?\"</p> </li> <li> <p>\"The art of hunting is aiming for the moment when the target is busy hunting its prey!\"</p> </li> <li> <p>\"It's  pointless to mope over the validity of someone else's  success. If you're unhappy about the results, keep moving yourself forward until you are satisfied.\"</p> </li> <li> <p>\"Prosperous cities tend to attract all sorts of nasty people.\"</p> </li> <li> <p>\"The countless dragons that rained down were less significant threats than the humans in the sky.\"</p> </li> <li> <p>\"An apology is a promise to do things differently next time, and to keep the promise.\"</p> </li> <li> <p>\"Order is the barrier that holds back the flood of death. We must all of us on this train of life remain in our allotted station. We must each of us occupy our preordained particular position. Would you wear a shoe on your head? Of course you wouldn't wear a shoe on your head. A shoe doesn't belong on your head. A shoe belongs on your foot. A hat belongs on your head.\"</p> </li> <li> <p>\"My friend, you suffer from the misplaced optimism of the doomed.\"</p> </li> <li> <p>\"Wilford: Curtis, everyone has their preordained position, and everyone is in their place except you.</p> </li> </ul> <p>Curtis: That's  what people in the best place say to the people in the worst place.\"</p> <ul> <li> <p>\"You've seen what people so without leadership. They devour one another.\"</p> </li> <li> <p>\"I believe it is easier for people to survive on this train if they have some level of insanity. As Gilliam well understood, you need to maintain a proper balance of anxiety and fear and chaos and horror in order to keep life going. And if we don't have that, we need to invent it.\"</p> </li> <li> <p>\"Assume everyone will betray you and you will never be disappointed.\"</p> </li> <li> <p>\"Perhaps it's  impossible to wear an identity without becoming what you pretend to be.\"</p> </li> <li> <p>\"In the moment when I truly understand my enemy, understand him well enough to defeat him, then in that very moment I also love him. I think it\u2019s impossible to really understand somebody, what they want, what they believe, and not love them the way they love themselves. And then, in that very moment when I love them.... I destroy them.\"</p> </li> <li> <p>\"I think that most of us, anyway, read these stories that we know are not</p> </li> <li> <p>\"true\" because we're hungry for another kind of truth: the mythic truth about human nature in general, the particular truth about those life-communities that define our own identity, and the most specific truth of all: our own self-story. Fiction, because it is not about someone who lived in the real world, always has the possibility of being about oneself.\"</p> </li> <li> <p>\"Because never in my entire childhood did I feel like a child. I felt like a person all along\u2015the same person that I am today.\"</p> </li> <li> <p>\"Sometimes lies were more dependable than the truth.\"</p> </li> <li> <p>\"Early to bed and early to rise,\" Mazer intoned, \"makes a man stupid and blind in the eyes.\"</p> </li> <li> <p>\"There are times when the world is rearranging itself, and at times like that, the right words can change the world.\"</p> </li> <li> <p>\"So the whole war is because we can't talk to each other.\"</p> </li> <li> <p>\"Human beings are free except when humanity needs them. Maybe humanity needs you. To do something. Maybe humanity needs me\u2014to find out what you're good for. We might both do despicable things, Ender, but if humankind survives, then we were good tools.\"</p> </li> <li> <p>\"He could see Bonzo's  anger growing hot. Hot anger was bad. Ender's  anger was cold, and he could use it. Bonzo's  was hot, and so it used him. \"</p> </li> <li> <p>\"Human beings may be miserable specimens, in the main, but we can learn, and, through learning, become decent people.\"</p> </li> <li> <p>\"I will remember this, thought Ender, when I am defeated. To keep dignity, and give honor where it's  due, so that defeat is not disgrace. And I hope I don't have to do it often.\"</p> </li> <li> <p>\"If only we could have talked to you, the hive-queen said in Ender's  words. But since it could not be, we ask only this: that you remember us, not as enemies, but as a tragic sisters, changed into foul shape by fate or God or evolution. If we had kissed, it would have been the miracle to make us human in each other's  eyes. Instead we killed each other. But still we welcome you now as guestfriends. Come into our home, daughters of Earth; dwell in our tunnels, harvest our fields; what we cannot do, you are now our hands to do for us. Blossom, trees; ripen, fields; be warm for them, suns; be fertile for them, planets: they are our adopted daughters, and they have come home.\"</p> </li> <li> <p>\"We thought we were the only thinking beings in the universe, until we met you, but never did we dream that thought could arise from the lonely animals who cannot dream each other's  dreams.\"</p> </li> <li> <p>\"The seed of doubt was there, and it stayed, and every now and then sent out a little root. It changed everything, to have that seed growing. It made Ender listen more carefully to what people meant, instead of what they said. It made him wise.\"</p> </li> <li> <p>\"What else should you be? Human beings  didn't evolve brains in order to lie around on lakes. Killing's  the first thing we learned. And a good thing we did, or we'd be dead, and the tigers would own the earth.\"</p> </li> <li> <p>\"No book, however good, can survive a hostile reading.\"</p> </li> <li> <p>\"All is going well, very well, I couldn\u2019t ask for anything better. So why do I hate my life?\"</p> </li> <li> <p>\"This is what historians usually do, quibble about cause and effect when the point is, there are times when the world is in flux and the right voice in the right place can move the world. Thomas Paine and Ben Franklin, for instance. Bismark. Lenin.\"</p> </li> <li> <p>\"There was no doubt now in Ender's  mind. There was no help for him. Whatever he faced, now and forever, no on ewould save him from it. Peter might be scum, but Peter had been right, always right; the power to cause pain is the only power that matters, the power to kill and destroy, because if you can't kill then you are always subject to those who can, and nothing and no one will ever save you.\"</p> </li> <li> <p>\"Nature can't evolve a species that hasn't the will to survive. Individuals might be bred to sacrifice themselves, but the race as a whole can never cease to exist.\"</p> </li> <li> <p>\"He is dead, she thought bitterly, because we have forgotten him.\"</p> </li> <li> <p>\"He toyed with the idea of trying to be like the other boys. But he couldn\u2019t think of any jokes, and none of theirs seemed funny. Wherever their laughter came from, Ender couldn\u2019t find such a place in himself. He was afraid, and fear made him serious.\"</p> </li> <li> <p>\"There is no teacher but the enemy. No one but the enemy will teach you how to destroy and conquer.\"</p> </li> <li> <p>\"Strange, isn't it? Each man's  life touches so many other lives. When he isn't around he leaves an awful hole, doesn't he?\"</p> </li> <li> <p>\"You see, George, you've really had a wonderful life. Don't you see what a mistake it would be to throw it away?\"</p> </li> <li> <p>\"Modesty is a virtue but overdoing it was just being false.\"</p> </li> <li> <p>\"To be punctual meant to exist as a point, meant that as well as to arrive somewhere on time. Constant existed as a point - could not imagine what it would, be like to exist in any other way.\"</p> </li> <li> <p>\"Hope?\" he says. \"There is always hope, John. New developments have yet to present themselves. Not all the information is in. No. Don\u2019t give up hope just yet. It\u2019s the last thing to go. When you have lost hope, you have lost everything. And when you think all is lost, when all is dire and bleak, there is always hope.\"</p> </li> <li> <p>\"Rather than giving them bread, teach them how to cultivate wheat. Truly, there are plenty who would become rotten themselves if all they did was receive bread.\"</p> </li> <li> <p>\"Doing the same things, or perhaps coming to resemble the person you hate, you loath, isn\u2019t an uncommon story.\"</p> </li> <li> <p>\"It seems you\u2019ve got a lot on your mind. Worry all you want. When you look back on it, you\u2019ll always feel like a fool asking yourself why you worried over something like that.\"</p> </li> <li> <p>\"Humans have nothing but unknowns. Even if they act like they know everything, that\u2019s surely a lie. That\u2019s why there\u2019s no way but to spend your whole life learning it. There\u2019s plenty of wisdom you won\u2019t find in a book, and I agree with your opinion, Lyle.\"</p> </li> <li> <p>\"The mountains have not a care, yet the snows whiten their hair; water feels not the world's  woe, yet its face wrinkles when winds blow\"</p> </li> <li> <p>\"Spirit is the mind, it is your thoughts, your imagination. Spirit is when you remember as you dream in your heart. This is what we call thought, and it is also spirit.\"</p> </li> <li> <p>\"Whatever you brag about the most is what you lack the most. Whatever it is that you want others to know you own the most of is what you want to possess most of.\"</p> </li> <li> <p>\"Death is not terrifying. The thing that is terrifying is the moment before death.\"</p> </li> <li> <p>\"People always speak of heaven and earth but, what is heaven and earth? It means all that is under the sky! If the heavens had a soul, it would be an oppressive one! The oppression of the heavens is invisible. We can only endure it and while we endure it we must learn to live with it happily. If we do not, are we to fight against heaven? To my understanding, perhaps this question meant that besides going up against heaven, could there be any other way to fight against destiny\u2026 Once you grow up, perhaps you\u2019ll have a deeper understanding of it. If that day truly comes and you have attained the power which allows you to do as the words say, then perhaps you can think of a third way to fight instead of submitting to destiny or rebelling against it.\"</p> </li> <li> <p>\"Among all those living on the land, who would be able to see the end of the horizon?\"</p> </li> <li> <p>\"You can only see the surface of the muddy water on the ground and never the bottom.\"</p> </li> <li> <p>\"Spirit is Dao,\" Tian Lan Meng stated calmly. It is not thought, because thought in itself is narrow, but Dao is endless. Dao is a realm that those from other realms seek. Every person has a different Dao. The great Dao is boundless, and those who obtain Dao will see through the world, and in turn, we can say that we have found and become the truth. I read this sentence from an ancient scroll before. It is a sentence that is spoken in the other worlds\u2026 If you stay on your Dao but have no method of solving a particular problem now, that method will eventually come to you. If you have the skills and power, but have strayed from your Dao, then you cannot use your skills, and your power will forever stay stagnant!\"</p> </li> <li> <p>\"All things in the world differ in sizes. My understanding towards the word is narrow and small to you, and the Dao you speak is a huge thing that seeks to reach a state where you understand the world. It is like two spots, like two different directions, and like two different extremes. Su Ming closed his eyes and continued, unhurried, \"To me, the heart is aspiration, and the spirit is a realm. You are walking on the Dao of the heavens, and I\u2019m walking through the narrow gate on the earth, but once I walk past that gate, what I\u2019m searching for is just to merely open my eyes. Do you understand what I\u2019m saying? The last sentence written in the beast skin scrolls suddenly surfaced in Su Ming\u2019s mind. \"You cannot see\u2026 the world that I see.\"</p> </li> <li> <p>\"You are always copying,\" Su Ming said slowly, lifting his head, \"because you think that the spirit is Dao. You search for something abstruse, that\u2019s why you can copy many things, because you think that as you search for it, you will find your Dao eventually. I don\u2019t know what is the Dao you speak\u2026 but from what you said just now, I can understand that while the Dao is an abstruse concept, it exists. It exists within the world, perhaps all the plants, trees, flowers, and stones have a Dao within them. What I seek isn\u2019t a Dao, but to have my mind acting as my aspiration, to have my spirit as my realm, and when I open my eyes, I will draw out my heart\u2019s desires\u2026 This is the reason why I can draw, but you can only copy.\"</p> </li> <li> <p>\"There is a saying that goes that the people who are lonely may be different from each other, but all of them stare at the moon.\"</p> </li> <li> <p>\"Willpower is an abstract term. It\u2019s like a person\u2019s resolve, like a beacon of light in a person\u2019s life\u2026 However, it is still an abstract thing\u2026 If no one attacks me, then I won\u2019t attack, but if someone attacks me, I will definitely kill him! In a battlefield, it doesn\u2019t matter whether I\u2019m taking the initiative or remain in the passive, if anyone attacks me, then unless he is killed by someone else, then I will definitely kill him!  That\u2019s right. I\u2019m afraid of death.... I\u2019m afraid that once I die, I won\u2019t be able to find my way back home. I\u2019m afraid that once I die, all these mysteries will disappear. I\u2019m afraid that once I die\u2026 I won\u2019t be able to open my eyes.\"</p> </li> <li> <p>\"When two adversaries meet at a narrow path and cannot back out from a fight... the courageous one will win\"</p> </li> <li> <p>\"Courage is also a type of presence. This is not recklessness. It\u2019s instead a presence akin to a mountain, one that will make your enemies breakdown due to your tenacity. Courage is also a method to subdue your enemies. It is also the characteristic you need to become an upright man when you journey through the world! Su Ming, remember my words\u2026 perhaps some day, you will truly understand it.\"</p> </li> <li> <p>\"Once you overcome your fears, once you have a taste of what courage is like, how would you feel..? I hope that when that time comes, I will still be by your side and hear you tell me how you feel. A feeling that I have won against myself.\"</p> </li> <li> <p>\"The place where I was born still did things according to the laws of the universe. When I was born, the Berserkers had weakened\u2026 If the heavens are heartless, then we will all be separated. The earth was heartless, and it made my Dark Mountain die. If the heavens have eyes, then why do they never see that my world is plunged into eternal darkness? If the deities have souls, then why did they divide the sky and seas to the south and north? I kept my duty to the heavens, so why did they not let me see the darkness of night? I kept my duty to the deities, so why did they tear me into pieces and scatter my memories?! If the heavens don\u2019t have eyes, then I will step on it and watch myself seal the heavens! If the deities don\u2019t have souls, then I swear I will slaughter the deities and become the Emperor!\"</p> </li> <li> <p>\"Perhaps the greatest sorrow in the world is when you don\u2019t even know why you\u2019re sad\u2026\"</p> </li> <li> <p>\"Everything in the world is a cause, if there are no intense changes and if there is nothing that would turn the tides of the world, then it would be difficult for us to see the real nature of people, who are affected by the things in the world\u2026\"</p> </li> <li> <p>\"Are we all allowed to impose our will on others because our power is greater than theirs?\"</p> </li> <li> <p>\"Perhaps death was not terrifying at times. What was horrifying was endlessness, an eternity of not being able to die and not being able to perish until the soul itself became numb, until all will was lost, all that made a person, turning him into\u2026 an undying soul, Imperishable living corpse\u2026\"</p> </li> <li> <p>\"Do you know for what reason do all manner of living practice cultivation? For what reason do we strive to become strong?\" the Candle Dragon asked softly with its ancient voice. Su Ming could not answer that question, and the Candle Dragon had not expected him to anyway. \"That is because we all have flaws within our bodies. Each race contains different flaws, and the root cause for cultivation is for us to mend those flaws\u2026 But it is not a simple task to mend all our flaws. Usually, over a countless number of years, only one or two living souls in a single race can be found capable of doing so. \"The methods each race use to discover their own flaws and set out to mend them are different, but in the end, we all need the power of the World Plane\u2026 Over the long years of my life, I had some form of contact with Immortals before. The constitution forming the Immortals\u2019 cultivation method is divided into three steps. The first step does not touch upon the power of the World Plane, but starting from the second step, they will go through this so called Nirvanic Rebirth. All the flaws in their bodies will be mended and they will obtain new life. At that time, they will be practicing the power of the World Plane. \"The third step is Hollow. It is the critical moment for one when trying to achieve perfection as there\u2019s fewer flaws within the body. If one can attain the ultimate completion, then he will have taken the fourth step. At that time, he will no longer have any flaws\u2026 and at that time, what he will pursue is the power of Plane Timelines!\" The Candle Dragon\u2019s voice gradually grew weaker. These epiphanies were the treasures of its life. \"It is the same for all races, just like the Deities who are similar to the Immortals. Amalgamation, Great Vehicle, Ascension, Great Overarching Golden Immortality , and all the other states are in the end, just to mend all the flaws in people\u2019s bodies.\"</p> </li> <li> <p>\"There is a binary opposite that exists in the world. If we say that one side of the binary opposite is being alive, then we can say that the other side of the binary opposite is being dead\u2026 but what exactly is death and what exactly is meant by the other side? Who can really say clearly? \"Perhaps we can look at the boundary between these two sides as a mirror. When a person standing outside the mirror looks into the mirror, the person inside the mirror is also looking outside. He will see himself, but at the same time, he might also not be looking at himself. \"Do you mean that the people in mirrors have their own lives, and the people outside the mirrors don\u2019t know about it, and that you and I are in these mirrors?\"</p> </li> <li> <p>\"We must break our Life Matrices and tread on the path to find what is lacking in our lives. This is called Life Privation!\"We must learn of what we lack in ourselves like we know of the regrets the world possesses and like we understand the changes in the world. This is Life Palace!\"</p> </li> <li> <p>\"When you learn who you are, you\u2026 are no longer you! When you no longer know who you are, you\u2026 will be you!\"</p> </li> <li> <p>\"What\u2026 is Life? It is vitality, because it is a form of inheritance we receive when we are born. It is also fate, because if we don't have fate in this inheritance of life, our Lives will be incomplete\u2026 Life. Vitality. Fate. We are born with Life, but we have to wrestle our own fate from other people's  hands in the future to control it ourselves\u2026 The word Life involves people and the heavens, and fate is what separates humans from the heavens\u2026 Does it mean that we have to bow down to heaven before we can be whole and obtain Life to become humans?\" Su Ming mumbled within the ball of blood, and at that moment, he opened his eyes. If Life means that we have to subjugate ourselves to the heavens before we can call ourselves humans, then the opposite can happen as well, we can still say that we have Life when the heavens bow down to us!\"</p> </li> <li> <p>\"If you do not have a place in your heart you call home, you will wander no matter where you are\u2026\"</p> </li> <li> <p>\"What you see might not be the truth, and what you believe doesn\u2019t exist\u2026 might not necessarily not exist.\"</p> </li> <li> <p>\"Thousands upon thousands are awake, but you are still asleep\u2026 Is it because you don\u2019t want to wake up, or is it because\u2026 you believe yourself to be awake? What does it mean to be asleep, and what does it mean to be awake? All of this\u2026 is just the world you see, and no one else\u2026 can see it. It is like fate, you can choose to submit to it or to fight against it. It is like life, where moments of joy and sadness exist together. \"</p> </li> <li> <p>\"If I\u2019m not bothered by my past, then why should I be bothered by my future? If I don\u2019t cling to the idea of who I am, then why should I think about who is me\u2026? The high winds may be strong, but they cannot extinguish the flames in my heart. Sooner or later\u2026 they will set the world ablaze!\"</p> </li> <li> <p>\"But most of the time, happiness will only last for a short moment, because there is an eye in the world that belongs to loneliness, and it does not want to see too many beautiful moments in anyone's  lives. That was why it made fleetingness to be a constant companion of happiness\"</p> </li> <li> <p>\"This is a point.\" As Su Ming spoke softly, a crystalline dot appeared at the spot where his index finger was pointing. I will draw towards the left and make a circle, and when I stop drawing\u2026 I will find that the end is in the same spot.\" Su Ming's  right index finger started drawing towards the left and he drew a circle. The spot where the circle was completed was its beginning and its end. It was the point that fused both the beginning and the end together. This is reincarnation. Then if I draw from the right and make a circle, rotating from the end\u2026\" As Su Ming spoke, his right index finger started drawing another circle backwards from that dot. The spot that caused the circle to be complete\u2026 was still the same point. This is also reincarnation. When Su Ming finished speaking, an indefinable presence radiated off his body. That presence was not of those who had attained great completion in the Berserker Soul Realm, but was\u2026 a presence that surpassed Berserker Soul. It grew thicker and surrounded Su Ming's  body, causing the starry sky to erupt with a bang at the instant it descended and touched it. It was as if the area where Su Ming was had turned into a forbidden region for starlight. His hair flew while his eyes remained calm. His words contained endless wisdom, and they were echoing in the world. Reincarnation is a point, and that point\u2026 is Berserkers' Realm Mountain. That point is the start and also the end. You can walk to the future from that point, and you can also head to the past. This point is also the mirror's  point. The mirror's  face is the normal world. It is where the past moves towards the future. It is then the opposite inside the mirror. Life and death move in opposite directions. The past and future move in opposite directions. It is just as I have understood it in Hidden Dragon Sect. It is like the process of winter moving to spring\u2026 because the people in the world of the mirror move from the future to the past. The Immortals are the face of the mirror. They live in the world outside the mirror and move from life to death. The Berserkers' Yin Death Region is the world inside the mirror. They move from death to life\u2026 During that moment just now, I finally understood. The face and back of that mirror don't make a complete cycle of reincarnation.\" Su Ming shook his head, and a variety of emotions stirred up slightly in his heart. It is just like the existence of Yin and Yang. People only see these two faces, but they forget\u2026 that there is another point! The world outside the mirror belongs to the Immortals, and the world inside the mirror belongs to the Berserkers. But in truth, there is a mirror inside the mirror. If two mirrors were positioned opposite each other properly, then the endless darkness would then be the mirror inside the mirror!\"</p> </li> <li> <p>\"When you see the mountain, it is a mountain is the first stage. The first stage is in the beginning stages of a human's  life. It is pure and they have only just begun to know the world. Everything is new, and whatever they see, it is the truth. If anyone tells that person something is a mountain, they will believe that it is a mountain. When you see the mountain, it is not a mountain is the second stage. As you grow up, you will experience more things, and you will discover that there are problems in the world. The more problems you encounter in the world, the more complicated the world will seem. Many of the truths that you know will be turned upside down. The bad people will rule the world, and the good will find it hard to survive. People will start to get cynical and not believe in things so easily. At that time, people will start criticizing the present by saying how good the past is. Then, mountains and rivers will not simply be mountains and rivers anymore, because your view of things has changed. You start questioning your beliefs, and you start wondering whether the things you see are really what they seem. When you see the mountain, it is still a mountain is the third stage. Since staying in the second stage bears too much suffering, they will start climbing up this metaphorical mountain, which means to train their minds and hearts. At this stage, they will concentrate on doing what they want to do and not compare themselves to others, and since the mind is calm and not bothered by the things in the world anymore, people will find that there is no need for them to adjust their point of view to suit other people's . At that time, they will feel free to perceive whatever they want in whichever way they want, hence you have: When you see the mountain, it is still a mountain, and when you see the river, it is still a river.\"</p> </li> <li> <p>\"You yourself have to change first, or nothing will change for you!\"</p> </li> <li> <p>\"Sake sure is nice. You can forget your troubles if only for a moment. You'll have to remember them tomorrow though, and they'll be even more painful than they were the night before. You can't run away from things like this. Especially from things you really want to forget.\"</p> </li> <li> <p>\"I'll protect what I want to protect.\"</p> </li> <li> <p>\"If you have time to fantasize about a beautiful end, then just live beautifully 'til the end.\"</p> </li> <li> <p>\"Everyone's  carrying something that matters. You just don't realize when you're carrying it. It's  only after it slips out of your hand that you realize how heavy it was in the first place. So many times I thought that I'd never carry a load like that ever again. And yet, before I realized it, I was carrying it again. I'd feel so much better if I just got rid of it. But I just can't bring myself to do it.\"</p> </li> <li> <p>\"There's  this one organ that's  even more important than my heart. You can't see it, but it's  there. Because of it, I can stand tall, even if I'm all worn down, I can still walk. And if I don't go, it'll break. My soul will break. Even if my heart stops beating, it is still more important. It doesn't matter if I'm old and can't walk. It will still stand tall.\"</p> </li> <li> <p>\"When your friend is crying, cry with him. When your friend is worried, you should worry with him. And when your friend has an awkward bowel movement, then you must have an awkward bowel movement too. Shin-chan, if you are a friend, you should be able to share the other's  pain, no matter what. And Shin-chan, if your friend goes down the wrong path\u2026 then you must stop your friend, even if it ruins your friendship. That is true samurai friendship.\"</p> </li> <li> <p>\"Even if you lose all memory in your head, the ones engraved in your heart and the ones that exist in your soul will never disappear, no matter what happens.\"</p> </li> <li> <p>\"Life is like a mountain. You can say you have reached the top only after climbing back down.\"</p> </li> <li> <p>\"If you want to kill me, then go ahead and kill me. You kill those that you hate. You turn old those who are more beautiful than you. Even if you continue to do so, you will never obtain eternal beauty. Even if you did find the eternal youth you're looking for...even if you wear those lavishly beautiful kimonos...I'll say this straight from my heart: You're ugly; your heart is truly laughably wretched.\"</p> </li> <li> <p>\"Life is just an important choice after another, keep going forward and watch how far those foolish choices can take you.\"</p> </li> <li> <p>\"Why change it? This is a life that you chose for yourself, and nothing will change that. You don't need to fret, nor do you need to be embarassed. No one else can or should choose the path that you walk upon. Just puff out your chest, and walk proudly. There's  nothing wrong with your face. As long as your soul doesn't get scarred, your face will remain beautiful\"</p> </li> <li> <p>\"Some things can only be seen through a tainted eye.\"</p> </li> <li> <p>\"If you run into a wall and pretend it doesn't exist, you'll never make any progress. The wall will never change, so you're the one who has to change.\"</p> </li> <li> <p>\"Tears are handy for washing away troubling and sad feelings. But when you grow up, you\u2019ll learn that there are things so sad, they can never be washed away by tears. That there are painful memories that should never be washed away. So people who are truly strong laugh when they want to cry. They endure all of the pain and sorrow while laughing with everybody else.\"</p> </li> <li> <p>\"Sometimes, it's  necessary to look back at the past in order to move on to the future.\"</p> </li> <li> <p>\"The night is in its darkest just before dawn. But keep your eyes open. If you avert your eyes from the dark, you'll be blinded by the rays of a new day. So keep your eyes open, no matter how dark the night ahead may be.\"</p> </li> <li> <p>\"A prison, you say? You think you'll be free if you go to the world above? A girl like you can never be free no matter where you go. After all, we humans are apes put in a cage called Earth. There is no difference between the world above and the world below. The only difference is which is bigger or smaller. People who pout about how confining the cage is can never be happy. They live their lives only seeing the iron bars. A true lack of freedom is when you cage your soul.\"</p> </li> <li> <p>\"It's  quite easy for humans to become adults, but to always have a child-like heart that makes everything joyful isn't such an easy task.\"</p> </li> <li> <p>\"Don't worry. When people break their old selves they embark a journey to find their new selves.\"</p> </li> <li> <p>\"Happiness depends on each person. If you think you're happy, then you must be happy.\"</p> </li> <li> <p>\"Some lies are necessary for giving children dreams.\"</p> </li> <li> <p>\"There\u2019s no such thing as parents who don\u2019t think about their children. But there are few children who understand their parents feelings.\"</p> </li> <li> <p>\"There are two things people fear... those are death and embarrassment. Those who try to overcome death are just idiots, but I won't laugh at those who try to overcome their embarrassment. I like those kind of idiots\"</p> </li> <li> <p>\"Planets are just places for people to stand on. Planets are just rocks. It takes people to make it a world. You can have as many \"Earths\" as you want. I only care about what's  inside.\"</p> </li> <li> <p>\"No matter how colossal a power you obtain, no matter how gigantic an army you bring with you, I ain't scared. While you've abandoned a hundred, I've connected with a thousand. While you've destroyed a thousand, I've been helped by ten thousand. So what's  an army of a few thousand? We have protected everything as just three people.\"</p> </li> <li> <p>\"I choose my own battlefields. Not by my blood, but by my heart! I stand on the battlefield to protect what's  important to me. And if anyone stands in my way, I don't care if it's  one of my kind, my brother or anyone else\u2026 I'll crush them all!\"</p> </li> <li> <p>\"It's  as if you are stuck in some predetermined program, following some predetermined script. If you really want to live in reality, then fight against it. Break through destiny with your own hands, and build your own reality!\"</p> </li> <li> <p>\"There is no need for any proof. There is no need to create any. We just have to live every second to the fullest, and the traces of the path we lived will burn into the ground. That will serve as proof of our existence.\"</p> </li> <li> <p>\"No matter how beautiful a person may be, they will still age and ultimately - die. But even so, even if appearances change, don't you believe that we have, in us, things that don't change? Even as our bodies crumble, even as the months and years take their toll... don't you believe that we all have something that time can't spoil? Even if you cover us with wrinkles, we won't lose to you. That's  because we know what beauty truly is.\"</p> </li> <li> <p>\"People need to live their life with a clear conscience. When you want to walk on a straight path, somehow you get yourself stained with mud. However, as long as we never give up, one day the mud on you will dry up and fall off\"</p> </li> <li> <p>\"Even if you can't move anymore, or your back gets bent out of shape, it doesn't matter! What matters is what's  inside! Not what someone looks like, dammit!\"</p> </li> <li> <p>\"What is right? What is wrong? In this mixed up world, deciding what is right and wrong is not easy. You can't just go by somebody else's  rules. If you let yourself be controlled like that, you'll just become a puppet that can't make decisions on it's  own. You have to live by your rules.\"</p> </li> <li> <p>\"No matter how hard you blow, you can never extinguish our fire. As long as a single flare remains, the others can be relit.\"</p> </li> <li> <p>\"It hasn't withered. I won't let it wither. We might just be little branches, but if the branches break off, the tree really will wither. That's  why I won't break off. Even if winter comes and the leaves fall off, even if the wind comes and all the other little branches break off... Even if I am the last branch left, I won't break off. I'm sure we'll be together till the end.\"</p> </li> <li> <p>\"Trying to shoulder the burden all by yourself? Don't be a stranger. Weep and ask for help. Lean on me with your runny nose. Cry when you feel like crying. Laugh when you feel like laughing. When you're tearing up with an ugly face, I'll give you a good cry with an uglier face. When you're laughing so hard your stomach hurts, I'll laugh in a louder voice. That's  how it should be. It's far better to get dirty while living true to yourself, than to throw away yourself and die a clean death.\"</p> </li> <li> <p>\"The country? the skies? You can have them. I'm busy just protecting what's right in front of me. I don't know what'll happen to me in the future, but if something has fallen at my feet, then the least I can do is pick it up.\"</p> </li> <li> <p>\"The zipper is a window to society.\"</p> </li> <li> <p>\"The best way to live a full life is to be a child, no matter your age.\"</p> </li> <li> <p>\"It may be tough now, but the worst is surely yet to come. Keep that in mind, and you'll be fine.\"</p> </li> <li> <p>\"That's  a good attitude. You should hate me more, curse me more, and detest me! Then you should take the power of that hatred and use it to survive in this rotten world\"</p> </li> <li> <p>\"If Only Life Was as Beautiful as It Seemed at First Sight\"</p> </li> <li> <p>\"There is no light for this who do not know the darkness. Live on and endure the shadows and brightness shall come your way.\"</p> </li> <li> <p>\"The more one tries to look away, the more one gets pre occupied. Once your heart is preoccupied, your sword will not be true. Then you will die. Dont be preoccupied with a single spot. See everything in its entirety effortlessly.\"</p> </li> <li> <p>\"Be aware of yourself. And accept yourself as you are. Thats where your training should begin.\"</p> </li> <li> <p>\"Our lives are not our own. From womb to tomb, we are bound to others. Past and present. And by each crime and every kindness, we birth our future.\"</p> </li> <li> <p>\"Belief, like fear or love, is a force to be understood as we understand the Theory of Relativity and Principles of Uncertainty: phenomenon that determine the course of our lives. Yesterday, my life was headed in one direction. Today, it is headed in another. Yesterday I believed that I would never have done what I did today. These forces that often remake time and space, that can shape and alter who we imagine ourselves to be, begin long before we are born and continue after we perish. Our lives and our choices, like quantum trajectories, are understood moment to moment. At each point of intersection, each encounter suggests a new potential direction.\"</p> </li> <li> <p>\"I understand now that boundaries between noise and sound are conventions. All boundaries are conventions, waiting to be transcended. One may transcend any convention if only one can first conceive of doing so. Moments like this, I can feel your heart beating as clearly as I feel my own, and I know that separation is an illusion. My life extends far beyond the limitations of me.\"</p> </li> <li> <p>\"Truth is singular. Its \"versions\" are mistruths.\"</p> </li> <li> <p>\"This world spins from the same unseen forces that twist our hearts.\"</p> </li> <li> <p>\"I believe death is only a door. When it closes, another opens. If I cared to imagine a heaven, I would imagine a door opening and behind it, I would find him there.\"</p> </li> <li> <p>\"Fear, belief, love phenomena that determined the course of our lives. These forces begin long before we are born and continue after we perish.\"</p> </li> <li> <p>\"There is only one rule that binds all people. One governing principle that defines every relationship on God's  green earth: The weak are meat, and the strong do eat.\"</p> </li> <li> <p>\"We cross and re-cross our old paths like figure-skaters.\"</p> </li> <li> <p>\"To be is to be perceived. And so to know thyself is only possible through the eyes of the other. The nature of our immortal lives is in the consequences of our words and deeds that go on apportioning themselves throughout all time.\"</p> </li> <li> <p>\"You have to do whatever you can't not do.\"</p> </li> <li> <p>\"I was not genomed to alter reality. No revolutionary ever was.\"</p> </li> <li> <p>\" I will not be subjugated to criminal abuse!\"</p> </li> <li> <p>\"A half-finished book is, after all, a half finished love affair.\"</p> </li> <li> <p>\"Travel far enough, you meet yourself.\"</p> </li> <li> <p>\"Books don't offer real escape, but they can stop a mind scratching itself raw.\"</p> </li> <li> <p>\"Power, time, gravity, love. The forces that really kick ass are all invisible.\"</p> </li> <li> <p>\"Unlimited power in the hands of limited people always leads to cruelty.\"</p> </li> <li> <p>\"Fantasy. Lunacy. All revolutions are, until they happen, then they are historical inevitabilities.\"</p> </li> <li> <p>\"Time is what stops history happening at once; time is the speed at which the past disappears.\"</p> </li> <li> <p>\"What wouldn't I give now for a never-changing map of the ever-constant ineffable? To possess, as it were, an atlas of clouds.\"</p> </li> <li> <p>\"The better organized the state, the duller its humanity.\"</p> </li> <li> <p>\"How vulgar, this hankering after immortality, how vain, how false. Composers are merely scribblers of cave paintings. One writes music because winter is eternal and because, if one  didn't, the wolves and blizzards would be at one's throat all the sooner.\"</p> </li> <li> <p>\"Anticipating the end of the world is humanity's  oldest passtime\"</p> </li> <li> <p>\"Why fight the 'natural' (oh, weaselly word!) order of things? Why? Because of this--one fine day, a purely predatory world shall consume itself. In an individual, selfishness uglifies the soul; for the human species, selfishness is extinction.\"</p> </li> <li> <p>\"Mother used to say escape is never further than the nearest book.\"</p> </li> <li> <p>\"What sparks wars? The will to power, the backbone of human nature. The threat of violence, the fear of violence, or actual violence, is the instrument of this dreadful will. You can see the will to power in bedrooms, kitchens, factories, unions and the borders of states. Listen to this and remember it. The nation state is merely human nature inflated to monstrous proportions. QED, nations are entities whose laws are written by violence. Thus it ever was, so ever shall it be.\"</p> </li> <li> <p>\"Women, oh, women! They'll find the baddest meanin' in your words an' hold it up, sayin', Look what you attacked me with!\"</p> </li> <li> <p>\"If war's  first victim is truth, its second is clerical efficiency.\"</p> </li> <li> <p>\"Leaves turned to soil beneath my feet. Thus it is, trees eat themselves.\"</p> </li> <li> <p>\"The learnin' mind is the livin' mind... an' any sort o' smart is truesome smart, old smart or new, high smart or low.\"</p> </li> <li> <p>\"All rising suns set.\"</p> </li> <li> <p>\"Hey, metaphysics seminar is on the roof. Just take the elevator up and keep walking until you hit the sidewalk. Anything is true if enough people believe it.\"</p> </li> <li> <p>\"An abyss cannot be crossed in two steps.\"</p> </li> <li> <p>\"Old Father Timothy offers this advice to his younger readers, included for free in the price of this memoir: conduct your life in such a way that, when your train breaks down in the eve of you years, you have a warm dry car driven by a loved one - or a hired one, it matters not - to take you home.\"</p> </li> <li> <p>\"He chiseled open the fault lines in the others' personalities.\"</p> </li> <li> <p>\"Fear hardens caution, but boredom erodes it.\"</p> </li> <li> <p>\"One loses one's  eye in the lanes of sea phosphorescence &amp; the Mississippi of stars streaming across the heavens.\"</p> </li> <li> <p>\"I envied my uncritical, unthinking sisters.\"</p> </li> <li> <p>\"If people praise you, you\u2019re not walking your own path.\"</p> </li> <li> <p>\"It\u2019s a small world. It keeps recrossing itself.\"</p> </li> <li> <p>\"all purebloods have a hunger, a dissatisfaction in their eyes,\"</p> </li> <li> <p>\"Old Ma Yibber spread the news that Zachry what came down off Mauna Kea weren't the same Zachry what'd gone up, an' true 'nuff I s'pose, there ain't no journey what don't change you some.\"</p> </li> <li> <p>\"Blame its user, blame its maker, but don\u2019t blame the gun.\"</p> </li> <li> <p>\"Yay, Old Uns' Smart mastered sicks, miles, seeds an' made miracles ord'nary, but it din't master one thing, nay, a hunger in the hearts o' humans, yay, a hunger for more. More what? I asked. Old Uns'd got ev\u2019rythin'. Oh, more gear, more food, faster speeds, longer lifes, easier lifes, more power, yay. Now the Hole World is big, but it weren't big 'nuff for that hunger what made Old Uns rip out the skies an' boil up the seas an' poison soil with crazed atoms an' donkey 'bout with rotted seeds so new plagues was borned an' babbits was freak-birthed. Fin'ly, bit'ly, then quicksharp, states busted into bar'bric tribes an' the Civ'lize Days ended, 'cept for a few folds'n'pockets here'n'there, where its last embers glimmer.\"</p> </li> <li> <p>\"ignorance of the Other engenders fear; fear engenders hatred; hatred engenders violence; violence engenders further violence until the only \"rights,\" the only law, are whatever is willed by the most powerful.\"</p> </li> <li> <p>\"There\u2019s the blind, Mr. Grimaldi, there\u2019s the willfully blind, and then there\u2019s the soon to be retired.\"</p> </li> <li> <p>\"The dumbest dog can sit and watch. What takes brains is knowing when to look away.\"</p> </li> <li> <p>\"But there's  one thing you must remember. Whether you want it or not, once you have created bonds between you and other people, those bonds will never disappear.\"</p> </li> <li> <p>\"Never lose sight of your wish! And if you want to see the wish fulfilled ... you must choose! No matter how painful the choice may be.\"</p> </li> <li> <p>\"All happiness and all unhappiness ... stems from one having a desire. And that is why mankind will always make their wishes.\"</p> </li> <li> <p>\"All who make wishes are the same. When one wish comes into conflict with someone else's  wish ... then one must make a choice. Either abandon one's  own wish ... or crush the other's  wish for the sake of your own.\"</p> </li> <li> <p>\"The princess is strong. And because she's  strong, she's  fragile. If somebody doesn't teach her that fact, she'll break.\"</p> </li> <li> <p>\"I can't do much yet, but even if I can do a little to help ... I want to give it all I have! If a person doesn't do anything, they never get any better. Doing one little thing, taking one little step forward ... I gotta believe it will help build a better future!\"</p> </li> <li> <p>\"You'll stay here with me?\" \"Yeah\" \"If I fall asleep like this ... the first thing i'll see when I wake up ... will be you.\"</p> </li> <li> <p>\"The instand one gives up, that is when it all ends. Keep wishing. Wish strongly! Wish hard! Do not let it matter what kind of being you are! Do not let it matter what pressures others put on you! Continue to wish for that which your heart truly desires!!\"</p> </li> <li> <p>\"If you don't want her to go, you should say it. Those jerks who can't say a word no matter how much time passes ... I just don't get them. If they're doing whatever the hell they want ... then you should do what you want too. I hate those jerks who fool themselves into thinking that just because they clam up, nobody knows what's  going on with them!!\"</p> </li> <li> <p>\"Until we can be together again ... we wait ... and believe!\"</p> </li> <li> <p>\"I believe in the princess when she says that she'll return to those waiting for her. So i'll wait. It's  more painful to wait than to go along on the trip.\" 'Well, I can't wait.' \"Are you that afraid to believe in someone?\"</p> </li> <li> <p>\"But there are no coincidences in this world. There is only Hitsuzen. You were destined to meet each other.\"</p> </li> <li> <p>\"I\u2019d rather stay the way I am until the last moment. Even if a monster beats me and I die. I won\u2019t lose to this game or this world, no matter what.\"</p> </li> <li> <p>\"A person\u2019s strength in this world is just an illusion.\"</p> </li> <li> <p>\"They say your character is built by life\u2019s challenges, so keep soldiering on young man.\"</p> </li> <li> <p>\"Even in a world like this, he was really living.\"</p> </li> <li> <p>\"I\u2019d rather trust and regret, than doubt and regret.\"</p> </li> <li> <p>\"It is pointless to question who someone really is. All you can do is believe and accept. Because the way you perceive someone is their true identity.\"</p> </li> <li> <p>\"When I began thinking of him as I fell asleep, I stopped having nightmares. I began to look forward to seeing him. For the first time since I arrived here, I was happy.\"</p> </li> <li> <p>\"Life isn\u2019t just doing things for yourself. It\u2019s possible to live in such a way that other people\u2019s happiness, makes you happy too.\"</p> </li> <li> <p>\"Sometimes the things that matter the most are right in front of you.\"</p> </li> <li> <p>\"I cried alone every single night. It felt like every day that passed here stole another piece of my real life away. After I cried, I\u2019d go and fight as hard as I could. My only thought was winning, moving forward and getting stronger.\"</p> </li> <li> <p>\"I\u2019m disinclined to acquiesce to your request.\"</p> </li> <li> <p>\"If you choose to lock your heart away, you\u2019ll lose it for certain\"</p> </li> <li> <p>\"Better to not know which moment may be your last alive to be mystery of it all.\"</p> </li> <li> <p>\"Did no one come to save me just because they missed me?\"</p> </li> <li> <p>\"Develop amnesia conveniently and forget everything you heard!\"</p> </li> <li> <p>\"Please make sure the bed is empty before getting in it!\"</p> </li> <li> <p>\"Getting wrapped up in worries is bad for your body and spirit. That\u2019s when you must short out your logic circuits and reboot your heart.\"</p> </li> <li> <p>\"Everybody makes a wrong turn once in a while\"</p> </li> <li> <p>\"Strong Pokemon. Weak Pokemon. That is only the selfish perception of people. Truly skilled trainers should try to win with all their favorites.\"</p> </li> <li> <p>\"A Caterpie may change into a Butterfree, but the heart that beats inside remains the same.\"</p> </li> <li> <p>\"I see now that one\u2019s birth is irrelevant. It\u2019s what you do that determines who you are.\"</p> </li> <li> <p>\"There\u2019s no sense in going out of your way to get somebody to like you.\"</p> </li> <li> <p>\"It\u2019s more important to master the cards you\u2019re holding than to complain about the ones your opponent was dealt.\"</p> </li> <li> <p>\"Do you always need a reason to help somebody?\"</p> </li> <li> <p>\"You see, sometimes friends have to go away, but a part of them stays behind with you.\"</p> </li> <li> <p>\"If we live a monotonous life, do we get used to it and stop thinking about how to change it?\"</p> </li> <li> <p>\"If somewhere in this world there is someone who understands you, it feels like that person is right beside you, even if youre as far apart as the end of the land and the top of the sky\"</p> </li> <li> <p>\"So, this is my power... but what is my purpose?\"</p> </li> <li> <p>\"The Earth is so pretty, so blue\u2026\"</p> </li> <li> <p>\"A good friend left me and, I miss her, every day... but I... I know we'll always be friends forever!\"</p> </li> <li> <p>\"To all of my beautiful future children who taught me how to believe. I offer all of you now my sincerest hopes, and wishes that the future world will become more and more beautiful. And that is exactly the kind of world you find yourselves in.\"</p> </li> <li> <p>\"We're all architecting our lives day by day, and when our life comes to an end, people will see what mattered to us most by looking at what we built. When you look back on your life, you'll see what you've built and you'll see what you've loved...and you'll realize that you build what you love. Your most powerful artifact in which you build your life upon are people. When you understand this, you begin to realize that your building blocks are the relationships you have, sustain, and influence. don't just want to be a builder of applications. I don't just want to be a builder of systems. I don't just want to be a builder of brands. I want to be a builder of people, using those avenues to do so. When lay on my deathbed, I want to look back on my life and see that what I built was people. I want to see that what I built was the product of a love for humanity. You build what you love. What are you building?\u2019</p> </li> <li> <p>\"Which is worse, to live as a monster or to die as a good man?\"</p> </li> <li> <p>\"Sanity is not a choice Marshall, you can't just choose to get over it.\"</p> </li> <li> <p>\"What if while you were looking into them, they were looking into you?\"</p> </li> <li> <p>\"Wounds can create monsters and you are wounded, martial. And wouldn't you agree, when you see a monster, you must stop it?\"</p> </li> <li> <p>\"God loves violence. I... I hadn't noticed. Sure you have. Why else would there be so much of it? It's  in us. It's  what we are. We wage war, we burn sacrifices, and pillage and plunder and tear at the flesh of our brothers. And why? Because God gave us violence to wage in his honor. I thought God gave us moral order. There's  no moral order as pure as this storm. There's  no moral order at all. There's  just this: can my violence conquer yours??</p> </li> <li> <p>\"Do you know how pain enters the body, Marshal? Do you? Depends on where you're hurt? No, it has nothing to do with the flesh. The brain controls pain.\"</p> </li> <li> <p>\"That's  the beauty of it. Mental Patients make the perfect subjects, if they talk nobody listens to them!\"</p> </li> <li> <p>\"He wanted to ask her what sound a heart made when it broke from pleasure, when just the sight of someone filled you the way food, blood, and air never could, when you felt as if you'd been born for only one moment and this, for whatever reason, was it.\"</p> </li> <li> <p>\"This world can only give me reminders of what I don't have, can never have, didn't have for long enough.\"</p> </li> <li> <p>\"The brain controls pain. It controls fear. Sleep. Empathy. Hunger. Everything we associate with the heart or the soul or the nervous system is actually controlled by the brain. Everything. What if you could control it?\"</p> </li> <li> <p>\"If you are deemed insane, then all actions that would oherwise prove you are not do, in actuality, fall into the framework of an insane person\u2019s actions. Your sound protests constitute denial. Your valid fears are deemed paranoia. Your survival instincts are labeled defense mechanisms. It\u2019s a no-win situation. It\u2019s a death penalty really.\"</p> </li> <li> <p>\"Waking, after all, was an almost natal state. You surfaced without history, then spent the blinks and yawns reassembling your past, shuffling the shards into chronological order before fortifying yourself for the present.\"</p> </li> <li> <p>\"How much violence, Marshal, do you think a man can carry before it breaks him?\"</p> </li> <li> <p>\"Everyone wants a quick fix. We're tired of being afraid, tired of being sad, tired of feeling overwhelmed, tired of feeling tired. We want the old days back, and we don't even remember them, and we want to push into the future, paradoxically, at top speed. Patience and forbearance become the first casualties of progress.\"</p> </li> <li> <p>\"She said once that time is nothing to me but a series of bookmarks that I use to jump back and forth through the text of my life, returning again and again to the events that mark me in the eyes of my more astute colleagues, as bearing all the characteristics of the classic melancholic.\"</p> </li> <li> <p>\"He lay on his side, looking out at the sea. So blue at this time of day, so vibrant as the afternoon died around it. He lay there feeling the breeze on his face and the sea spreading out forever under the darkening sky and he felt so small, so utterly human, but it wasn\u2019t a debilitating feeling. It was an oddly proud one. To be a part of this. A speck, yes. But part of it, one with it. Breathing.\"</p> </li> <li> <p>\"I can't take second or third. I can only take first.\"</p> </li> <li> <p>\"Dare to think. Before your dreams are realized, never establish any limits yourself, never give yourself a ny excuse to shrink back, any justification for failure. Only in this way do we have the chance to take those seemingly distant dreams and make them into genuine reality. This, is precisely my first lesson to you.\"</p> </li> <li> <p>\"The identities we live in end up being the roles we play, whether it's princess, empress, wife, or mother. \"But as we act longer and longer, playing more and more roles, we often forget just who we are. \"If you can't even be sure of what role you're playing, how can you determine what it is you want? If we want to a get clear and truthful answer, we have to look back at where we came from, reverse time to where it all began. We have to remember what we first saw when we opened our eyes to this world\"</p> </li> <li> <p>\" Kind people need to be even more on their guard... Being on guard requires the corresponding ability, or else it will be nothing more than a joke.\"</p> </li> <li> <p>\"How could one prevent oneself from being confused by external things? How could one possess an unshakable will and self-confidence? Only one word needed to be remembered: heart. All one needed was to convince themselves. If one could convince oneself that this way was correct, that it was in accordance with one's  heart, then...one would naturally be following one's  heart. This sounded very simple, but it was not actually simple at all If one searched in the deepest depths of one's  soul, if one ensconced oneself in a dark room cut off from the world, how many people could truly say that they were without regrets? Who could so firmly believe that everything they had done was correct?\"</p> </li> </ul> <p>'Waters can carry a boat, and they can also capsize them. Shang Xingzhou continued, \"Of course, following the current does not mean obedience. The boat can only hope that the waters are calmer, that there are fewer waves, that there is not too much resistance.\" Yu Ren gestured, \"But in the final analysis, the boat must still revere the existence of the waters.\" \"The Duke of Wei once said, 'The resentment of this minister need not be feared; only the people should be feared. They can carry the boat and capsize the boat, so they must be treated with deep caution.3 How could I not fear them?\" Shang Xingzhou looked into You Ren's  eyes and said, \"But positions are relative. Since you are the boat, you cannot think too much about what the water is thinking.\"</p> <ul> <li> <p>\"To walk through the world is like sailing a boat across the ocean. One must be cautious and mindful, and one cannot go against the current, or else one will capsize the boat.\"</p> </li> <li> <p>\"The person who understood you the most was naturally not a relative, or else Xue Xing Chuan would not have died so miserably and then almost had his corpse exposed in the plains after his death. And the person who understood you the most was also not necessarily, as often written in books, your enemy, because you would always have some wariness towards your enemy and develop many safeguards against him. The person who understood you the most was also not necessarily your friend. To be friends until your hair turned white was a beautiful thing, but you would spend too little time with each other, the distance between your two cities would be too far. When you met, you would always drink wine while recalling old times, speculating on the future, cursing your past teachers or the current government. There were few opportunities to chat about more in-depth things. So the person who understood you the most was often your partner at work. With year after year, day after day of working together, it would be very difficult to not understand each other. You would drink together many times, chatting about many in-depth things, and for the sake of both open and hidden competitions, you would remember all these things with remarkable clarity, preparing to use them at any point in the future. For instance, he might learn which restaurant is your favorite for buying box lunches and you might learn which restaurant has his favorite noodles. He might learn which group leader you hate the most and you might learn which TV channel is his favorite. He might know of all the girlfriends you've talked about in the past few years while you would know how many people he's  been cheating on in the past few months. On the morning after Christmas Eve, the two of you might even come out of the same pub and then smile at each other, because this pub was the place where the company could negotiate the best discount.\"</p> </li> <li> <p>\"Every person is born a small person.\" The Pope smiled and gestured with his two hands to show length. \"But every person will grow bigger. There are some matters that you can learn as long as you are willing to learn them.\"</p> </li> <li> <p>\"Position is relative, as is importance. To create a balance between position and importance, thus preventing the entire world from dancing according to the whims of people like us, is what I have wanted to do throughout these past few years.\"</p> </li> <li> <p>\"To eat when you are hungry, to sleep when you are drowsy, to take medicine when you are sick, and to bury someone's  body after they die, these are truly the greatest principles.\"</p> </li> <li> <p>\"That which is most impervious to poison is the human heart, and the human heart is human nature, and human nature is to live-what's  wrong with that?\"</p> </li> <li> <p>\"Thousands of years pass, the white clouds wander carelessly, things are the same but the people are not, the sapling has grown into a lush canopy'. But in the end, there were still some people or matters that could not be let go.\"</p> </li> <li> <p>\"Good people do not live long.\"</p> </li> <li> <p>\"All things have a beginning and an end. Even those of Concealed Divinity and those above, who have obtained Grand Liberation, have a birth and death.\"</p> </li> <li> <p>\"Things easily decay, but the effects they leave are everlasting. Ultimately, one must see how deep the tracks are that one has left.\" The Divine Empress turned and looked at her, continuing, \"And those tracks come from your and my footsteps, follow the directions of our hearts.\" Xu Yourong asked, \"And if someone blocks your way?\" The Divine Empress answered, \"So we need the strength to kill all those who obstruct us. Only this way can we march the world forward according to our desires, to brand our souls upon history such that even the reprimands of tens of thousands of people after we depart cannot wipe it away. Only this way can we get close to true eternity.\"</p> </li> <li> <p>\"Affection is the world's  most cheaply bought item, virtue an excuse for the weak to protect themselves None of them are important.\" Xu Yourong asked, \"Then what is the most important thing?\" The Divine Empress looked up towards the sky and leisurely said, \"To exist.\" After a moment of silence, Xu Yourong asked,</p> </li> <li> <p>\"How should we exist?\" \"How to exist? Take all that is wondrous, see how long can one exist, how can one make the soul inextinguishable, and proceed in the direction of the Great Dao.\"</p> </li> <li> <p>\"When the sky is shattering and stars are falling, when you find it simply impossible to make any sort of rational judgment and can only rely on what your heart is feeling at that moment, that is what your heart truly feels.\"</p> </li> <li> <p>\"No matter who the target is or what difference exists between the choices, in the end, you still made a choice.\" \"So?\" \"Sweet or salty, to peel or not to peel, to live or to die these have always been questions.\" The Elder of Heavenly Secrets looked into his eyes, his voice calm. \"Life is formed of innumerable choices. Who can avoid them completely?\"</p> </li> <li> <p>\"On the verge of death, even the words are kind, let alone one's  intentions.\"</p> </li> <li> <p>\"Do you know when people are the most courageous?\" \"When confronting death?</p> </li> <li> <p>\"It's  not wrong, but there is another situation...because of love.\" The Divine Empress looked out the window at the dark palace and continued, \"In other words, when driven by passion.\"</p> </li> <li> <p>\"Good people aren't guaranteed to be rewarded, and they might not even live well, so why do we have to be good people? How should we love? Why should we live??\"</p> </li> <li> <p>\"In hazy dreams, I curse the time passed, Ah my home, thirty-two years have gone. The red flag stirred the peasant to take up the halberd, While the black hand held high the tyrant's  whip. Only because one seeks grand goals are there many sacrifices, And I dare to order the sun and moon to shine over new skies. In joy, I see the wave after wave of beans, And the heroes from all-over returning in the evening mist.\"</p> </li> <li> <p>\"Dont tell me what they said about me. Tell me why they were so comfortable to say it around you.\"</p> </li> <li> <p>\"Well the meek were supposed to inherit the earth, but instead it has e to the young-the technically inclined, those who stare into video games rather than into their own souls.\"</p> </li> <li> <p>\"Despise chaos. Create order\"</p> </li> <li> <p>\"For the human brain,\" Edmond explained, \"any answer is no answer. We feel enormous discomfort when faced with insufficient data and so our brains invent the data- offering us, at the very least the illusion of order-creating myriad philosophies, mythologies, and unseen world.\" religions to reassure us that there is indeed an order and structure to the unseen world\"</p> </li> <li> <p>\"The roads to salvation are many.Forgiveness is not the only path.\"</p> </li> <li> <p>\"The truth is something you should find without magic\"</p> </li> <li> <p>\"It is very hard for evil to take hold of the unconsenting soul.\"</p> </li> <li> <p>\"But it is one thing to read about dragons and another to meet them.\"</p> </li> <li> <p>\"From that time forth he believed that the wise man is one who never sets himself apart from other living things, whether they have speech or not, and in later years he strove long to learn what can be learned, in silence, from the eyes of animals, the flight of birds, the great slow gestures of trees.\"</p> </li> <li> <p>\"Go to bed; tired is stupid.\"</p> </li> <li> <p>\"You thought, as a boy, that a mage is one who can do anything. So I thought, once. So did we all. And the truth is that as a man's  real power grows and his knowledge widens, ever the way he can follow grows narrower: until at last he chooses nothing, but does only and wholly what he must do. . . .\"</p> </li> <li> <p>\"It is no secret. All power is one in source and end, I think. Years and distances, stars and candles, water and wind and wizardry, the craft in a man's hand and the wisdom in a tree's  root: they all arise together. My name, and yours, and the true name of the sun, or a spring of water, or an unborn child, all are syllables of the great word that is very slowly spoken by the shining of the stars. There is no other power. No other name.\"</p> </li> <li> <p>\"For a word to be spoken, there must be silence. Before, and after.\"</p> </li> <li> <p>\"In that moment Ged understood the singing of the bird, and the language of the water falling in the basin of the fountain, and the shape of the clouds, and the beginning and end of the wind that stirred the leaves; it seemed to him that he himself was a word spoken by the sunlight.\"</p> </li> <li> <p>\"Only in silence the word, only in dark the light, only in dying life: bright the hawk's  flight on the empty sky.\"</p> </li> <li> <p>\"Infinite are the arguments of mages\"</p> </li> <li> <p>\"And he would watch the snow falling, thin and ceaseless, on the empty lands below the window, and feel the dull cold grow within him, till it seemed no feeling was left to him except a kind of weariness.\"</p> </li> <li> <p>\"I am yours by parentage and custom and by duty undertaken towards you. I am your wizard. But it is time you recalled that, tough I am a servant, I am not your servant.\"</p> </li> <li> <p>\"Heal the wound and cure the illness, but let the dying spirit go\"</p> </li> <li> <p>\"But the death of a great mage, who has many times in his life walked on the dry steep hillsides of death\u2019s kingdom, is a strange matter: for the dying man goes not blindly, but surely, knowing the way.\"</p> </li> <li> <p>\"The path never reached it, though it always seemed to be about to.\"</p> </li> <li> <p>\"And he began to see the truth, that Ged had neither lost nor won but, naming the shadow of his death with his own name, had made himself whole: a man: who, knowing his whole true self, cannot be used or possessed by any power other than himself, and whose life therefore is lived for life\u2019s sake and never in the service of ruin, or pain, or hatred, or the dark.\"</p> </li> <li> <p>\"Freedom is a heavy load, a great and strange burden for the spirit to undertake. It is not easy. It is not a gift given, but a choice made, and the choice may be a hard one. The road goes upward towards the light; but the laden traveler may never reach the end of it.\"</p> </li> <li> <p>\"The Earth is beautiful, and bright, and kindly, but that is not all. The Earth is also terrible, and dark, and cruel. The rabbit shrieks dying in the green meadows. The mountains clench their great hands full of hidden fire. There are sharks in the sea, and there is cruelty in men\u2019s eyes. And where men worship these things and abase themselves before them, there evil breeds. There places are made in the world where darkness gathers, places given wholly to the Ones we call Nameless, the ancient and holy powers of the Earth before the Light, the powers of the dark, the ruin, the madness\"</p> </li> <li> <p>\"Who said you fall in love only once? Love is such a versatile feeling Its different every damn time Sometimes its a warm feeling Like the feeling of coming home Alternately it is also an all consuming fire Which threatens to burn you inside out It is the breeze and the storm It is a hearth and a inferno It will nurture you and destroy you It will make you strong and weak It will lift you up and bring you down But it is am amazing feeling every time It makes even an hour an eternity And two years feel like tomorrow It is the most amazing kind of bitter sweet The feeling of two souls interwined To hold and to cherish till fate do us part\"</p> </li> <li> <p>\"Daybreak makes all earth and sea, from shadow brings forth form, driving dream to the dark kingdom.\"</p> </li> <li> <p>\"You have a finite amount of willpower that becomes depleted as you use it.\"</p> </li> <li> <p>\"What are you watching there?\" the Archmage asked, and the other answered, \"A spider.\" Between two tall grass blades in the clearing a spider had spun a web, a circle delicately suspended. The silver threads caught the sunlight. In the center the spinner waited, a grey-black thing no larger than the pupil of an eye. \"She too is a patterner,\" Ged said, studying the artful web. \"What is evil?\" asked the younger man. The round web, with its black center, seemed to watch them both. \"A web we men weave,\" Ged answered</p> </li> <li> <p>\"With your whole mind you sit with painful legs without being disturbed by them. This is to sit without\"</p> </li> <li> <p>\"Life is a series of pulls back and forth. You want to do one thing, but you are bound to do something else. Something hurts you, yet you know it shouldn't. You take certain things for granted, even when you know you should never take anything for granted.\"</p> </li> <li> <p>\"But engineering isn't about perfect solutions; it's  about doing the best you can with limited resources.\"</p> </li> <li> <p>\"If you have a question,\" my folks would say, \"then find the answer.\"</p> </li> <li> <p>\"Part of that is because if you dispense your own wisdom, others often dismiss it; if you offer wisdom from a third party, it seems less arrogant and more acceptable.\"</p> </li> <li> <p>\"When you're screwing up and nobody says anything to you anymore, that means they've given up on you.\"</p> </li> <li> <p>\"So that was a setback. But I kept my mantra in mind: The brick walls are there for a reason. They're not there to keep us out. The brick walls are there to give us a chance to show how badly we want something\"</p> </li> <li> <p>\"You appreciate the part of me that  didn't get angry because two `things' we own got hurt. But the flip side of that is my belief that you don't repair things if they still do what they're supposed to do. The cars still work. Let's just drive 'em.\"</p> </li> <li> <p>\"Not everything needs to be fixed.\"</p> </li> <li> <p>\"Let's  saddle up and ride.\"</p> </li> <li> <p>\"But, look, I'm a scientist who sees inspiration as the ultimate tool for doing good.\"</p> </li> <li> <p>\"Give yourself permission to dream. Fuel your kids' dreams, too. Once in a while, that might even mean letting them stay up past their bedtimes.\"</p> </li> <li> <p>\"If you wait long enough,\" he said, \"people will surprise and impress you.\"</p> </li> <li> <p>\"It took a long time, but I've finally figured it out. When it comes to men who are romantically interested in you, it's  really simple. Just ignore everything they say and only pay attention to what they do.\"</p> </li> <li> <p>\"Experience is what you get when you  didn't get what you wanted. And experience is often the most valuable thing you have to offer.\"</p> </li> <li> <p>\"There is more than one way to measure profits and losses. On every level, institutions can and should have a heart.\"</p> </li> <li> <p>\"When we're connected to others, we become better people.\"</p> </li> <li> <p>\"Sometimes, all you have to do is ask, and it can lead to all your dreams coming true.\"</p> </li> <li> <p>\"Am I a fun-loving Tigger or am I a sad-sack Eeyore?\"</p> </li> <li> <p>\"What do we mean by G.o.d? Being detached from life and death as well as being one with heaven and earth like G.o.d! In this aspect, we are no different from the elementalists. They also believe that they have a common origin with heaven and earth and they will live forever. In short, they are following the path of the cultivators from the past. However, we are different. We walk in between the path of life and death. We treat life and death as an integral whole, that they are similar. Our theory is profound. Walking between life and death is akin to walking on a tightrope between high cliffs. Below our feet is an unknown abyss. In order to succeed, our hearts and minds must be resolute. We must not hesitate, else we will definitely fall into an situation with no hope of reprieve.</p> </li> <li> <p>\"You have to complete the path you chose even if it\u2019s going to kill you,\" the red-dressed girl said plainly.</p> </li> <li> <p>\"If one works for it and he doesn\u2019t succeed, then it can be said that his fate had already been decided. However, if one never even tries then serves him right.\"</p> </li> <li> <p>\"One can either choose to let others control his life, or he can choose to control others\u2019 lives.\"</p> </li> <li> <p>\"There were four seasons in life. The spring of adolescence, the summer of youthfulness, the autumn of confidence, and the winter of obsolescence. However, there would only be one cycle of life.\"</p> </li> <li> <p>\"From mankind\u2019s perspective, the world was ever-changing. Perhaps from the world\u2019s perspective, it was mankind that was ever-changing.\"</p> </li> <li> <p>\"A strong body needs an equally mighty soul.\"</p> </li> <li> <p>\"You\u2019re still young. When you\u2019re older, you will understand that time is money. You won\u2019t give your money to someone who has nothing to do with you, right? Then why are you wasting time on them?\"</p> </li> <li> <p>\"I feel that you\u2019re like me: someone who has desire. My desire is to become a Grandmaster and defeat Dai Gang. I don\u2019t know what your desire is and whether it is easier or harder to achieve than mine, but if you have a desire, you have to be hard on yourself. Mediocrity is not enough to make your desire come true.\"</p> </li> <li> <p>\"When a Grandmaster is alive, he defeats all heroes under the sky. When he dies, he stirs all clouds under the sky. Look, the sun and moon lose their splendor and the stars dim. The sky is so high, the earth is so vast. All living things gather to grieve. How heroic! How delightful! Living a life without being a Grandmaster is unsatisfying!\"</p> </li> <li> <p>\"If you\u2019re short on money, everyone else is a beggar.\"</p> </li> <li> <p>\"He viewed each and every challenge from the previous half of his life as fate's  way of refining his very being. Not once did he lose hope, give himself up to anger, or whimper in sorrow. His heart was as pure as that of a newborn.\"</p> </li> <li> <p>\"A human mind was complicated yet centralized at the same time. It was a world\u2026 a complete, diverse world that was beyond mankind's  understanding. It could emit light and warmth like the sun, giving warmth to the souls surrounding it. However, it could also pile up shadows that were darker than the night in a secluded corner.  It could be impregnable, enduring the cruelest torture and the deepest agony in the world. It could also be soft like an air bubble that could be shattered easily with a gentle poke from a crisp toothpick. Nobility and malevolence could be buried in the same tomb while courage and cowardice were like two vines that entwined each other. It was extremely difficult to make sense of them and tell them apart.\"</p> </li> <li> <p>\"As the saying goes, it is only when one experiences true knowledge that he finally understands how little he knows\"</p> </li> <li> <p>\"But magic is also an art, great lady,\" the Murgo said. \"There are many who think so,\" Aunt Pol said, \"but true magic comes from within and is not the result of nimble fingers which trick the eye.\"</p> </li> <li> <p>\"Everything is idiocy if you choose to look at it in the proper light,\"</p> </li> <li> <p>\"Why are the people all so unhappy?\" he asked Mister Wolf.\"They have a stern and demanding God,\" Wolf replied.\"Which God is that?\" Garion asked.\"Money,\"</p> </li> <li> <p>\"It is power that teaches patience; holding power, I mean. And you learn the price it exacts\u2014which is something I never knew when I was your age and thought a sword and quick wits could deal with anything. I never knew the price you pay for power.\"</p> </li> <li> <p>\"Authority? You want the authority to create, to be noticed, and to make a difference? You\u2019re waiting for permission to stand up and speak up and ship? Sorry, there\u2019s no authority left. Oprah has left the building. She can\u2019t choose you to be on her show because her show is gone. Youtube wants you to have your own show now, but they\u2019re not going to call you. Dick clark has left the building. He\u2019s not going to be able to get you a record deal or a tv gig because he and his show are long gone. Itunes and a hundred other outlets want you to have your own gig, but they\u2019re not going to call you, either. Neither is rodney dangerfield or the head of programming at comedy central. Marc marondidn\u2019t wait to be cast on saturday night live \u2014 he started his own podcast and earned a million listeners. Our cultural instinct is to wait to get picked. To seek out the permission, authority, and safety that come from a publisher or a talk-show host or even a blogger who says \"i pick you.\" Once you reject that impulse and realize that no one is going to select you \u2014 that prince charming has chosen another house in his search for cinderella \u2014 then you can actually get to work. The myth that the ceo is going to discover you and nurture you and ask you to join her for lunch is just that, a hollywood myth. Once you understand that there are problems waiting to be solved, once you realize that you have all the tools and all the permission you need, then opportunities to contribute abound. The opportunity is not to have your r\u00e9sum\u00e9 picked from the pile but to make the pile irrelevant by leading without having to be asked. When we take responsibility and eagerly give credit, doors open. When we grab a microphone and speak up, we\u2019re a step closer to doing the work we\u2019re able to do. Most of all, when we buckle down, confront the lizard brain, and ship our best work, we\u2019re becoming the artists we\u2019re capable of becoming. No one is going to pick you. Pick yourself.\"</p> </li> <li> <p>\"There are kinds of action, for good or ill, that lie so far outside the boundaries of normal behaviour that they force us, in acknowledging that they have occurred, to restructure our own understanding of reality. We have to make room for them.\"</p> </li> <li> <p>\"Deny not your own mortality.\"</p> </li> <li> <p>\"Names are like clothes, Durnik,\" Silk explained. \"We put on what's  most suitable for the occasion. Honest men have little need to wear strange clothes or strange names Those of us who aren't so honest, however, occasionally have to change one or the other.\"</p> </li> <li> <p>\"Women are almost always angry with us for one reason or another. It's  one of the things you'll have to get used to as you get older.\"</p> </li> <li> <p>\"Events are like horses,\" Hettar told him. \"Sometimes they run away. After they've run for a while, though, they'll start to walk again, Then there'll be time to put everything together.\"</p> </li> <li> <p>\"Patience, Excellency,\" Silk advised. \"The more we suffer, the greater the rewards in the end.\"</p> </li> <li> <p>\"I understand much better than you think, Garion. You know what your problem is? You don't want to grow up. You want to keep on being a boy forever. You can't though; nobody can. No matter how much power you have - whether you're an emperor or a sorcerer - you can't stop the years from going by. I realized that a long time ago, but then I'm probably much smarter than you are.\"</p> </li> <li> <p>\"Men's  minds ran to straight lines, but women thought more in terms of circles.\"</p> </li> </ul> <p>Durnik smiled wryly. \"I'm an ordinary man, Mandorallen,\" he said, \"Ordinary men live in fear all the time. Didn't you know that? We're afraid of the weather, we're afraid of powerful men, we're afraid of the night and the monsters that lurk in the dark, we're afraid of growing old and of dying. Sometimes we're even afraid of in ordinary men are afraid almost every minute of their lives.\" - \"How can you bear it?\" \"Do we have any choice? Fear's  a part of life, Mandorallen, and it's  the only life we have. You'll get used to it. After you've put it on every morning like an old tunic, you won't even notice it any more. Sometimes laughing at it helps a little.\" \"Laughing?\" It shows the fear that you know it's  there, but that you're going to go ahead and do what you have to do anyway.\" Durnik looked down at his hands, carefully kneading the mare's  belly \"Some men curse and swear and bluster, he continued. Every man has to come up with his own technique for dealing with it Personally, I prefer laughing. It seems more appropriate somehow.\"</p> <ul> <li> <p>\"People are grateful for a bit of direction when they're confused. You can't go through life being afraid of what you are. If you do that, sooner or later somebody will come along who'll misunderstand, and you'll have to do something to show him that it's  not him that you're afraid of. When it goes that far, it's  usually much worse for you - and for him too. You don't just jump in with help until you're asked. That's  very bad form, Garion.\"</p> </li> <li> <p>\"The word love seemed, as he thought more deeply about it, to include a great number of things that at first glance did not seem to have anything whatsoever to do with it\"</p> </li> <li> <p>\"The worst part of holding the memories is not the pain. It's  the loneliness of it. Memories need to be shared.\"</p> </li> <li> <p>\"Which led to another thought: did all fathers feel this way when their sons became men? Men of achievement, of names that eclipsed the father\u2019s? Was there always the sting of envy to temper the burst of pride?\"</p> </li> <li> <p>\"Thus the first object of the child's  hostility is identical with the first object of its love-its mother\"</p> </li> <li> <p>\"I hate the word interesting, everything is interesting. To understand what is important is very difficult and is what I think forces people to think deeply and mature.\" Bran thought about it. \"Can a man still be brave if he\u2019s afraid?\"That is the only time a man can be brave\"</p> </li> <li> <p>\"A ruler who hides behind paid executioners soon forgets what death is.\"</p> </li> <li> <p>\"Only staying active will make you want to live a hundred years.\"</p> </li> <li> <p>\"Everything can be taken from a man but one thing: the last of the human freedoms\u2014to choose one\u2019s attitude in any given set of circumstances, to choose one\u2019s own way.\"</p> </li> <li> <p>\"He lifted his hand and pointed at the beautiful burning flame image on the symbol paper and said, \"The path of the martial artist is like this flame. Practicing the martial arts will only cause pain. The dangers are countless and the road is filled with obstacles. Everyone who walks down it will eventually turn to ash, but the true martial artist will be reborn from these ashes. Even if I was only a small and weak moth, I will walk into the flames without hesitation. I will fight my destiny for a one in a million chance that I will experience my own samsara and be reborn into a flaming phoenix. And even now, I am no longer a moth\u2026\"</p> </li> <li> <p>\"My so-called inventions already existed in the environment,\" Edison once said.</p> </li> <li> <p>\"I\u2019ve created nothing. Nobody does.\"</p> </li> <li> <p>\"Edison did not look for problems in need of solutions; he looked for solutions in need of modification.\"</p> </li> <li> <p>\"To assemble the best that is within you and give it away. And to assemble with those you love to rekindle joy.\"</p> </li> <li> <p>\"The lion and the giraffe and the wombat and the rest do what they do and are what they are. And somehow manage to make it there in the cage, living the unexamined life. But to be human is to know and care and ask. To keep rattling the bars of the cage of existence hollering, \"What\u2019s it for?\" at the stones and stars, and making prisons and palaces out of the echoing answers.</p> </li> <li> <p>\"Without realizing it, we fill important places in each other\u2019s lives. It\u2019s that way with the guy at the corner grocery, the mechanic at the local garage, the family doctor, teachers, neighbors, co-workers. Good people who are always  \"there,\" who can be relied upon in small, important ways. People who teach us, bless us, encourage us, support us, uplift us in the dailiness of life. We never tell them. I don\u2019t know why, but we don\u2019t. And, of course, we fill that role ourselves. There are those who depend on us, watch us, learn from us, take from us. And we never know. Don\u2019t sell yourself short. You may never have proof of your importance, but you are more important than you think. There are always those who couldn\u2019t do without you. The rub is that you don\u2019t always know who.\"</p> </li> <li> <p>\"Writers aren\u2019t exactly people . . . they\u2019re a whole lot of people trying to be one person.\"</p> </li> <li> <p>\" As mundane as our regular lives can be, sometimes, when we've had a great shock, that steady regular routine can be a God send.\"</p> </li> <li> <p>\"I believe in a personal god who cares about me and worries and oversees everything I do. I believe in an impersonal god who set the universe in motion and went off to hang with her girlfriends and doesn't even know that I'm alive. I believe in an empty and godless universe of causal chaos, background noise, and sheer blind luck.\"</p> </li> <li> <p>\" Memory is one of the more trivial functions of sentinence\"</p> </li> <li> <p>\"He had wanted to create, to be recognized, and to study. He was no different from legions of other scientists and scholars. He just happened to be the one who made it happen.\"</p> </li> <li> <p>\"Sometimes the truth is stupid.\"</p> </li> <li> <p>\"Which was better? To string it out as long as possible, as he had been doing, or to get it over with one way or the other?\"</p> </li> <li> <p>\"To remind you that deep beneath the layers of deviousness, you have a spark of decency. Perhaps you could blow on that spark occasionally.\"</p> </li> <li> <p>\"The most difficult things in the world Must be accomplished through the easiest. The greatest things in the world Must be accomplished through the smallest. Therefore the Sage Never attempts great things And so accomplishes them.\"</p> </li> <li> <p>\"You know, Richard, most people think the will to survive is the strongest instinct in human beings, but it isn\u2019t. The strongest instinct is to keep things familiar.\"</p> </li> <li> <p>\"For years, psychologists have tortured rats by making them do things like run mazes for bits of cheese. The interesting thing about these experiments is that, when the scientists change the position of the cheese, the rats only try the same way three or four times before starting to explore other possible routes. When humans replace the rats, however, they just keep on and on and on, in the hopes that if they just do the same thing often enough they\u2019ll get the desired result.\"</p> </li> <li> <p>\"A single enduring statement can grant immortality.\"</p> </li> <li> <p>\"Find the worst human being you can, and you\u2019ll still find something worse by looking out the window at night.\"</p> </li> <li> <p>\"The moment you get up to prove one thing, you\u2019ll be expected to prove them all.\"</p> </li> <li> <p>\"Most men cannot abide silence. Some fly into a rage. Some become clowns. Some confess all they know. Silence reveals much.\"</p> </li> <li> <p>\"I learned thirty years ago that it is foolish to scold. I have enough trouble overcoming my own limitations without fretting over the fact that God has not seen fit to distribute evenly the gift of intelligence.\"</p> </li> <li> <p>\"As much as we thirst for approval, we dread condemnation\"</p> </li> <li> <p>\"The deepest urge in human nature is \"the desire to be important.\"</p> </li> <li> <p>\"Nobody knows for sure But he did say that many people who go insane find in insanity a feeling of importance that they were unable to achieve in the world of reality.\"</p> </li> <li> <p>\"We are interested in others when they are interested in us.\"</p> </li> <li> <p>\"A man without a smiling face must not open a shop.\"</p> </li> <li> <p>\"I judge people by their own principles - not by my own.\"</p> </li> <li> <p>\"Say about yourself all the derogatory things you know the other person is thinking or wants to say or intends to say - and say them before that person has a chance tosay them.\"</p> </li> <li> <p>\"So with men, if you would win a man to you cause, first convince him that you are his sincere friend. Therein is a drop of honey that catches his heart; which, say what you will, is the great high road to his reason.\"</p> </li> <li> <p>\"Look again at that dot. That's  here. That's  home.That's  us. On it everyone you love, everyone you know, everyone you ever heard of, every human being who ever was, lived out their lives. The aggregate of our joy and suffering, thousands of confident religions, ideologies, and economic doctrines, every hunter and forager, every hero and coward, every creator and destroyer of civilization, every king and peasant, every young couple in love, every mother and father, hopeful child, inventor and explorer, every teacher of morals, every corrupt politician, every \"superstar,\" every \"supreme leader,\" every saint and sinner in the history of our species lived there-on a mote of dust suspended in a sunbeam. The Earth is a very small stage in a vast cosmic arena. Think of the endless cruelties visited by the inhabitants of one corner of this pixel on the scarcely distinguishable inhabitants of some other corner, how frequent their misunderstandings, how eager they are to kill one another, how fervent their hatreds. Think of the rivers of blood spilled by all those generals and emperors so that, in glory and triumph, they could become the momentary masters of a fraction of a dot. Our posturings, our imagined self-importance, the delusion that we have some privileged position in the Universe, are challenged by this point of pale light. Our planet is a lonely speck in the great enveloping cosmic dark. In our obscurity, in all this vastness, there is no hint that help will come from elsewhere to save us from ourselves. The Earth is the only world known so far to harbor life. There is nowhere else, at least in the near future, to which our species could migrate. Visit, yes. Settle, not yet. Like it or not, for the moment the Earth is where we make our stand. It has been said that astronomy is a humbling and character-building experience. There is perhaps no better demonstration of the folly of human conceits than this distant image of our tiny world. To me, it underscores our responsibility to deal more kindly with one another, and to preserve and cherish the pale blue dot, the only home we've ever known.\"</p> </li> <li> <p>\"Every one of us is, in the cosmic perspective, precious. If a human disagrees with you, let him live. In a hundred billion galaxies, you will not find another.\"</p> </li> <li> <p>\" If you wish to make an apple pie from scratch, you must first invent the universe\"</p> </li> <li> <p>\" A book is made from a tree. It is an assemblage of flat, flexible parts (still called \"leaves\") imprinted with dark pigmented squiggles. One glance at it and you hear the voice of another person, perhaps someone dead for thousands of years. Across the millennia, the author is speaking, clearly and silently, inside your head, directly to you. Writing is perhaps the greatest of human inventions, binding together people, citizens of distant epochs, who never knew one another. Books break the shackles of time \u2015 proof that humans can work magic.\"</p> </li> <li> <p>\" Who is more humble? The scientist who looks at the universe with an open mind and accepts whatever the universe has to teach us, or somebody who says everything in this book must be considered the literal truth and never mind the fallibility of all the human beings involved?\"</p> </li> <li> <p>\" In science it often happens that scientists say, 'You know that's  a really good argument; my position is mistaken,' and then they would actually change their minds and you never hear that old view from them again. They really do it. It doesn't happen as often as it should, because scientists are human and change is sometimes painful. But it happens every day. I cannot recall the last time something like that happened in politics or religion.\"</p> </li> <li> <p>\" We are like butterflies who flutter for a day and think it is forever.\"</p> </li> <li> <p>\" You're an interesting species. An interesting mix. You're capable of such beautiful dreams, and such horrible nightmares. You feel so lost, so cut off, so alone, only you're not. See, in all our searching, the only thing we've found that makes the emptiness bearable, is each other.\"</p> </li> <li> <p>\" Exploration is in our nature. We began as wanderers, and we are wanderers still. We have lingered long enough on the shores of the cosmic ocean. We are ready at last to set sail for the stars.\"</p> </li> <li> <p>\" Fireflies out on a warm summer's  night, seeing the urgent, flashing, yellow-white phosphorescence below them, go crazy with desire; moths cast to the winds an enchantment potion that draws the opposite sex, wings beating hurriedly, from kilometers away; peacocks display a devastating corona of blue and green and the peahens are all aflutter; competing pollen grains extrude tiny tubes that race each other down the female flower's  orifice to the waiting egg below; luminescent squid present rhapsodic light shows, altering the pattern, brightness and color radiated from their heads, tentacles, and eyeballs; a tapeworm diligently lays a hundred thousand fertilized eggs in a single day; a great whale rumbles through the ocean depths uttering plaintive cries that are understood hundreds of thousands of kilometers away, where another lonely behemoth is attentively listening; bacteria sidle up to one another and merge; cicadas chorus in a collective serenade of love; honeybee couples soar on matrimonial flights from which only one partner returns; male fish spray their spunk over a slimy clutch of eggs laid by God-knows-who; dogs, out cruising, sniff each other's  nether parts, seeking erotic stimuli; flowers exude sultry perfumes and decorate their petals with garish ultraviolet advertisements for passing insects, birds, and bats; and men and women sing, dance, dress, adorn, paint, posture, self-mutilate, demand, coerce, dissemble, plead, succumb, and risk their lives. To say that love makes the world go around is to go too far. The Earth spins because it did so as it was formed and there has been nothing to stop it since. But the nearly maniacal devotion to sex and love by most of the plants, animals, and microbes with which we are familiar is a pervasive and striking aspect of life on Earth. It cries out for explanation. What is all this in aid of? What is the torrent of passion and obsession about? Why will organisms go without sleep, without food, gladly put themselves in mortal danger for sex? ... For more than half the history of life on Earth organisms seem to have done perfectly well without it. What good is sex?... Through 4 billion years of natural selection, instructions have been honed and fine-tuned...sequences of As, Cs, Gs, and Ts, manuals written out in the alphabet of life in competition with other similar manuals published by other firms. The organisms become the means through which the instructions flow and copy themselves, by which new instructions are tried out, on which selection operates.  'The hen,' said Samuel Butler, 'is the egg's  way of making another egg.' It is on this level that we must understand what sex is for. ... The sockeye salmon exhaust themselves swimming up the mighty Columbia River to spawn, heroically hurdling cataracts, in a single-minded effort that works to propagate their DNA sequences into future generation. The moment their work is done, they fall to pieces. Scales flake off, fins drop, and soon--often within hours of spawning--they are dead and becoming distinctly aromatic.  They've served their purpose.  Nature is unsentimental.  Death is built in.\"</p> </li> <li> <p>\" The significance of our lives and our fragile planet is then determined only by our own wisdom and courage. We are the custodians of life's  meaning. We long for a Parent to care for us, to forgive us our errors, to save us from our childish mistakes. But knowledge is preferable to ignorance. Better by far to embrace the hard truth than a reassuring fable. If we crave some cosmic purpose, then let us find ourselves a worthy goal.\"</p> </li> <li> <p>\" Books are like seeds. They can lie dormant for centuries and then flower in the most unpromising soil.\" \"Death is not terrifying. The thing that is terrifying is the moment before death.\"</p> </li> <li> <p>\"I don\u2019t have any sense of propriety. I don\u2019t have parents. In your eyes, I have neither any right nor status\u2026 But, my elder once told me that you only see one part of the rain in the world. You will never know how much rain there is when it stops\u2026 You can only see the surface of the muddy water on the ground and never the bottom\u2026 \"</p> </li> <li> <p>\"If you stay on your Dao1 but have no method of solving a particular problem now, that method will eventually come to you. If you have the skills and power, but have strayed from your Dao, then you cannot use your skills, and your power will forever stay stagnant! I don\u2019t understand the Dao\u2019 meant by those in the other worlds, but now\u2026\"</p> </li> <li> <p>\"A delusion starts like any other idea, as an egg. Identical on the outside, perfectly formed. From the shell, you\u2019d never know anything was wrongs what\u2019s inside that matters.\"</p> </li> <li> <p>\"You know the most dangerous thing about schizophrenia? The most dangerous thing is believing you don\u2019t have it. That\u2019s the trick. The mind killer. Your disease convinces you, you don\u2019t have it. So, for example, one day in the hospital, you meet a girl and she has some friends and they tell you you\u2019re not sick. You have super powers. And more than anything, you wanna believe it because that means you\u2019re not crazy. It means you can fall in love and live happily ever after. But you know if you believe it if you surrender to the hope and you\u2019re wrong, then you\u2019re never coming back. \"</p> </li> <li> <p>\"What is the universe without each sunrise? That\u2019s how we judge our gods, not on their math but their poetry.\"</p> </li> <li> <p>\"Human beings are the only animal that forms ideas about their world. We perceive it not through our bodies but through our minds. We must agree on what is real. Because of this, we are the only animal on Earth that goes mad\"</p> </li> <li> <p>\"Ask yourself: what\u2019s more terrifying? Fear, or the frightened\"</p> </li> <li> <p>\"You decide what is real and what is not. You. Your will\"</p> </li> <li> <p>\"Who teaches us to be normal when we\u2019re one of a kind?\"</p> </li> <li> <p>\"Where the pessimist sees danger hiding behind every back, the optimist sees friendship. Which is why, when we encounter coincidence, we often see conspiracy. \"</p> </li> <li> <p>\"We moved through a city of normals, soldiers in a secret war. We were the ghosts in a haunted house, the golem of myth. To the normal, we were just superstition, make-believe. Sometimes it felt like that to us too. To me, I was a woman who couldn\u2019t be touched, in love with a man who wasn\u2019t there. What was real?\"</p> </li> <li> <p>\"Please keep talking so we can all pretend that our problems are just in our heads.\"</p> </li> <li> <p>\"It\u2019s a war, baby, this life. The things we endure. You said you saw the future, and it\u2019s an apocalypse. Who survives that, the lovers or the fighters? They sell us this lie that love\u2019s gonna save us. All it does is make us stupid and weak\"</p> </li> <li> <p>\"Is it such a terrible thing to feel sorrow for your enemy? What is he, except a brother with another name?\"</p> </li> <li> <p>\"If the idea of illness can become illness, what else about our reality is actually a disorder?\"</p> </li> <li> <p>\"I am a good person. I deserve love. \"</p> </li> <li> <p>\"Do what you want. Take what you want. Gods make rules. They don\u2019t follow them.\"</p> </li> <li> <p>\"You have your whole life to be old. But today, you\u2019re still young.\"</p> </li> <li> <p>\" You can make someone do what they don\u2019t want to do, but there\u2019s no force on Earth that makes you enjoy it.\"</p> </li> <li> <p>\"What if you\u2019re not the hero? What if you\u2019re just another villain? The real villain.\"</p> </li> <li> <p>\"Well, kid, you better learn to fly like a bird, because the age of the dinosaur is over\"</p> </li> <li> <p>\" The best way to understand the mind is to build it\"</p> </li> <li> <p>\" We have to learn about love before we can learn about hate. Otherwise, everything goes to hell\"</p> </li> <li> <p>\" We can make anything we fancy in this arena of infinite promise, and this is what we come up with? Weapons? War? Surely we have more imagination than that.\"</p> </li> <li> <p>\" We can fix this world. All the bad things. We just got to start over.\"</p> </li> <li> <p>\" Time travel does not give one the opportunity to change oneself. But rather, to eradicate oneself and allow something else to form in the wake of what once was.\"</p> </li> <li> <p>\" The secret of life. If you feel safe when you\u2019re young, you will feel safe when you\u2019re old.\"</p> </li> <li> <p>\" The money is a tool, you see. Nothing more. Power. Because without power, who would listen?\"</p> </li> <li> <p>\" People get too close. They touch you and you disappear. And then they\u2019re inside. In your belly and in your head. And when you get back, there\u2019s a smell. Someone else\u2019s smell is inside your nose. And you check out. You tell people,</p> </li> <li> <p>\"It\u2019s fine. I don\u2019t own my body.\" You say, \"My power is like a vacation. I get to be a tourist in someone else\u2019s life.\" Who cares if every time I come back home, I feel dirty?\"</p> </li> <li> <p>\" No one who dies is really dead. You see that, right? The past changes, and the future disappears.\"</p> </li> <li> <p>\" Love isn\u2019t gonna save us. It\u2019s what we have to save. Pain makes us strong enough to do it. All our scars, our anger, our despair, it\u2019s armor. Baby, God loves the sinners best because our fire burns bright, bright, bright. Burn with me\"</p> </li> <li> <p>\" It\u2019s not crazy babies that worry me. It\u2019s the men they become. Like a fire, falling in love with a fire. We try to smother them, put them out, but they just burn us up\"</p> </li> <li> <p>\" If we don\u2019t believe in change, then we don\u2019t believe in time.\"</p> </li> <li> <p>\" I tell them I\u2019m sane, they think I\u2019m crazy, and if I say, \"You know what? You\u2019re right, I am crazy,\" then they up my dosage.\"</p> </li> <li> <p>\" Do you know what love is? It\u2019s a hot bath. What happens to things when you leave them in a bath for too long? They get soft, fall apart.\"</p> </li> <li> <p>\" An army cannot sneak up on a man. But a lover can.\"</p> </li> <li> <p>\" All that love, it doesn\u2019t just disappear. It must be transformed into an emotion of equal intensity. That is the law of the universe.\"</p> </li> <li> <p>\" All animals fight to live. Whether they want to or not.\"</p> </li> <li> <p>\"If a person\u2019s heart can change due to persistently holding onto something, then why can\u2019t that persistence grant me peace?\"</p> </li> <li> <p>\"The Golden Roc\u2019s heart and its will are reflected as it flies through the world. Within its eyes, there is nothing in the world that can stop its path. It can fly endlessly in this vast sky\"</p> </li> </ul> <p>The place where I was born still did things according to the laws of the universe\u2026</p> <ul> <li> <p>\"When I was born, the Berserkers had weakened\u2026 If the heavens are heartless, then we will all be separated\u2026 The earth was heartless, and it made my Dark Mountain die\u2026 When war begins, the moon will shatter into millions of pieces\u2026 The roads leading to our homes will become unfamiliar to us, and we will grieve\u2026 \"</p> </li> <li> <p>\"Always treat it as if he is still alive and kill him again, maybe twice, or even more.\"</p> </li> <li> <p>\" But the techno-utopians do get tiresome with their platitudes and their ability to prattle on for hours without saying much of substance. More disconcerting is their underlying message that humans are flawed and our humanity is an annoying burden that needs to be dealt with in due course.\"</p> </li> <li> <p>\"I think there are probably too many smart people pursuing Internet stuff, finance, and law,\" Musk said on the way. \"That is part of the reason why we haven\u2019t seen as much innovation.\"</p> </li> <li> <p>\"He does what he wants, and he is relentless about it. It\u2019s Elon\u2019s world, and the rest of us live in it.\"</p> </li> <li> <p>\"Maybe I read too many comics as a kid,\" Musk said. \"In the comics, it always seems like they are trying to save the world. It seemed like one should try to make the world a better place because the inverse makes no sense.\"</p> </li> <li> <p>\"The only reason he did not outrank the other boys was a lack of interest in the work prescribed by the school.\"</p> </li> <li> <p>\"In every work of genius we recognize our own rejected thoughts; they come back to us with a certain alienated majesty.\"</p> </li> <li> <p>\"Sympathy the human species universally craves. The child eagerly displays his injury; or even inflicts a cut or bruise in order to reap abundant sympathy. For the same purpose adults . . . show their bruises, relate their accidents, illness, especially details of surgical operations. Self-pity\u2019 for misfortunes real or imaginary is in some measure, practically a universal practice.\"</p> </li> <li> <p>\"The abbot of our monastery always said that fable has strong shoulders that carry far more truth than fact can.\"</p> </li> <li> <p>\"Until you make the unconscious conscious, it will direct your life and you will call it fate.\"</p> </li> <li> <p>\"Here's  to the ones that we got Cheers to the wish you were here, but you're not Cause the drinks bring back all the memories Of everything we've been through Toast to the ones here today Toast to the ones that we lost on the way Cause the drinks bring back all the memories And the memories bring back, memories bring back you \"</p> </li> <li> <p>\"And still, after all this time, the Sun has never said to the Earth, \"You owe me.\" Look what happens with love like that. It lights up the sky.\"</p> </li> <li> <p>\"Coincidence is God\u2019s way of remaining anonymous.\"</p> </li> <li> <p>\"The big question is whether you are going to be able to say a hearty yes to your adventure.\"</p> </li> <li> <p>\"It is better to be hated for what you are than to be loved for what you are not.\"</p> </li> <li> <p>\"The privileged are processed by people, the poor are processed by algorithms.\"</p> </li> <li> <p>\"The only difference between a madman and me is that the madman thinks he is sane. I know I am mad.\"</p> </li> <li> <p>\"The gift is the blessing of the giver.\"</p> </li> <li> <p>\"There is no escape\u2014we pay for the violence of our ancestors.\"</p> </li> <li> <p>\"Humans live best when each has his own place, when each knows where he belongs in the scheme of things. Destroy the place and destroy the person.\"</p> </li> <li> <p>\"The mind goes on working no matter how we try to hold it back\"</p> </li> <li> <p>\"It occurred to her that mercy was the ability to stop, if only for a moment. There was no mercy where there could be no stopping.\"</p> </li> <li> <p>\"Men and their works have been a disease on the surface of their planets before now,\" his father said. \"Nature tends to compensate for diseases, to remove or encapsulate them, to incorporate them into the system in her own way.\"</p> </li> <li> <p>\"The concept of progress acts as a protective mechanism to shield us from the terrors of the future.\"</p> </li> <li> <p>\"You are a placebo responder. Your body plays tricks on your mind. You cannot be trusted.\"</p> </li> <li> <p>\"The baby which cries the most gets the maximum milk.\"</p> </li> <li> <p>\"A boy at the beginning of a story has no way of knowing that the story has begun. \"</p> </li> <li> <p>\"If you want enemies, excel your friends; but if you want friends, let your friends excel you.\"</p> </li> <li> <p>\"Every decision you make can change the world. The best life is the one the gods don\u2019t notice. You want to live free, boy, live quietly.\"</p> </li> <li> <p>\"I think something\u2019s wrong with me. I make friends, then suddenly I can\u2019t bear to be with any of them. Seems like that other me, the cheerful and honest one, went away somewhere.\"</p> </li> <li> <p>\"Do any of us children, she wondered, ever stop to ask ourselves where our teachers go when school is over for the day? Do we wonder if they live alone, or if there is a mother at home or a sister or a husband?\"</p> </li> <li> <p>\"They have taken everything from us; should I let them take my mind as well?\"</p> </li> <li> <p>\"Nothing ever begins. There is no first moment; no single word or place from which this or any other story springs. The threads can always be traced back to some earlier tale, and to the tales that preceded that; though as the narrator\u2019s voice recedes the connections will seem to grow more tenuous, for each age will want the tale told as if it were of its own making. Thus the pagan will be sanctified, the tragic become laughable; great lovers will stoop to sentiment, and demons dwindle to clockwork toys. Nothing is fixed. In and out the shuttle goes, fact and fiction, mind and matter, woven into patterns that may have only this in common: that hidden amongst them is a filigree which will with time become a world.</p> </li> <li> <p>\"Self-perception is a zoo.\"</p> </li> <li> <p>\"The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.\"</p> </li> <li> <p>\"Forgiveness means giving up all hope for a better past.\"</p> </li> <li> <p>\"When something goes wrong with a computer you get an error message, When something goes wrong with a human you get feelings.\"</p> </li> <li> <p>\"For the others, we can say that Muad\u2019Dib learned rapidly because his first training was in how to learn. And the first lesson of all was the basic trust that he could learn. It is shocking to find how many people do not believe they can learn, and how many more believe learning to be difficult.\"</p> </li> <li> <p>\"Any road followed precisely to its end leads precisely nowhere. Climb the mountain just a little bit to test that it\u2019s a mountain. From the top of the mountain, you can not see the mountain.\"</p> </li> <li> <p>\"There is probably no more terrible instant of enlightenment than the one in which you discover your father is a man\u2014with human flesh.\"</p> </li> <li> <p>\"Black is a blind remembering, she thought. You listen for pack sounds, for the cries of those who hunted your ancestors in a past so ancient only your most primitive cells remember. The ears see. The nostrils see.\"</p> </li> <li> <p>\"What senses do we lack that we cannot see or hear another world all around us?\"</p> </li> <li> <p>\"Prophecy and prescience\u2014How can they be put to the test in the face of the unanswered question? Consider: How much is actual prediction of the \"wave form\" (as MuadDib referred to his vision- image) and how much is the prophet shaping the future to fit the prophecy? What of the harmonics inherent in the act of prophecy? Does the prophet see the future or does he see a line of weakness, a fault or cleavage that he may shatter with words or decisions as a diamond-cutter shatters his gem with a blow of a knife?\"</p> </li> <li> <p>\"When religion and politics travel in the same cart, the riders believe nothing can stand in their way. Their movement become headlong\u2014faster and faster and faster. They put aside all thought of obstacles and forget that a precipice does not show itself to the man in a blind rush until it\u2019s too late.\"</p> </li> </ul> <p>You are a placebo responder. Your body plays tricks on your mind. You cannot be trusted.\u2019</p> <ul> <li> <p>\"How often it is that the angry man rages denial of what his inner self is telling him.\"</p> </li> <li> <p>\"A mathematician, like a painter or poet, is a maker of patterns. If his patterns are more permanent than theirs, it is because they are made with ideas.\"</p> </li> <li> <p>\"In New York, when a tree dies, nobody mourns that it was cut down in its prime. Nobody counts the rings,notifies the loved ones. There are other trees.\"</p> </li> <li> <p>\"If you haven't solved the puzzle, it isn't the end yet.\"</p> </li> <li> <p>\"Recieve with simplicity everything that happens to you\"</p> </li> <li> <p>\"By letting it go it all gets done. The world is won by those who let it go. But when you try and try. The world is beyond the winning.\"</p> </li> <li> <p>\"A good traveler has no fixed plans, and is not intent on arriving.\"</p> </li> <li> <p>\"Be content with what you have; rejoice in the way things are. When you realize there is nothing lacking, the whole world belongs to you.\"</p> </li> <li> <p>\"The only art I\u2019ll ever study is stuff that I can steal from.\"</p> </li> <li> <p>\"Everything that needs to be said has already been said. But, since no one was listening, everything must be said again.\"</p> </li> <li> <p>\"What is originality? Undetected plagiarism.\"</p> </li> <li> <p>\"We were kids without fathers . . . so we found our fathers on wax and on the streets and in history. We got to pick and choose the ancestors who would inspire the world we were going to make for ourselves.\"</p> </li> <li> <p>\"Steal from anywhere that resonates with inspiration or fuels your imagination. Devour old films, new films, music, books, paintings, photographs, poems, dreams, random conversations, architecture, bridges, street signs, trees, clouds, bodies of water, light and shadows. Select only things to steal from that speak directly to your soul. If you do this, your work (and theft) will be authentic.\"</p> </li> <li> <p>\"Instead, chew on one thinker\u2014writer, artist, activist, role model\u2014you really love. Study everything there is to know about that thinker. Then find three people that thinker loved, and find out everything about them. Repeat this as many times as you can. Climb up the tree as far as you can go. Once you build your tree, it\u2019s time to start your own branch.\"</p> </li> <li> <p>\"It\u2019s not the book you start with, it\u2019s the book that book leads you to.\"</p> </li> <li> <p>\"It is better to take what does not belong to you than to let it lie around neglected.\"</p> </li> <li> <p>\"Start copying what you love. Copy copy copy copy. At the end of the copy you will find your self.\"</p> </li> <li> <p>\"You start out by rewriting your hero\u2019s catalog.\" \"If you have one person you\u2019re influenced by, everyone will say you\u2019re the next whoever. But if you rip off a hundred people, everyone will say you\u2019re so original!\"</p> </li> <li> <p>\"My interest in making music has been to create something that does not exist that I would like to listen to. I wanted to hear music that had not yet happened, by putting together things that suggested a new thing which did not yet exist.\"</p> </li> <li> <p>\"We don\u2019t know where we get our ideas from. What we do know is that we do not get them from our laptops.\"</p> </li> <li> <p>\"The work you do while you procrastinate is probably the work you should be doing for the rest of your life.\"</p> </li> <li> <p>\"Avoiding work is the way to focus my mind.\"</p> </li> <li> <p>\"It\u2019s not that people are mean or cruel, they\u2019re just busy.\"</p> </li> <li> <p>\"You don\u2019t have to share everything\u2014in fact, sometimes it\u2019s much better if you don\u2019t. Show just a little bit of what you\u2019re working on. Share a sketch or a doodle or a snippet. Share a little glimpse of your process.\"</p> </li> <li> <p>\"I always carry a book, a pen, and a notepad, and I always enjoy my solitude and temporary captivity.\"</p> </li> <li> <p>\"There\u2019s only one rule I know of: You\u2019ve got to be kind.\"</p> </li> <li> <p>\"Find the most talented person in the room, and if it\u2019s not you, go stand next to him. Hang out with him. Try to be helpful.\"</p> </li> <li> <p>\"Complain about the way other people make software by making software.\"</p> </li> <li> <p>\"The best way to get approval is to not need it.\"</p> </li> <li> <p>\"the trick is to be too busy doing your work to care.\"</p> </li> <li> <p>\"In this age of information abundance and overload, those who get ahead will be the folks who figure out what to leave out, so they can concentrate on what\u2019s really important to them. Nothing is more paralyzing than the idea of limitless possibilities. The idea that you can do anything is absolutely terrifying. The way to get over creative block is to simply place some constraints on yourself. It seems contradictory, but when it comes to creative work, limitations mean freedom. Write a song on your lunch break. Paint a painting with only one color. Start a business without any start-up capital.Shoot a movie with your iPhone and a few of your friends. Build a machine out of spare parts. Don\u2019t make excuses for not working\u2014make things with the time, space, and materials you have, right now.\"</p> </li> <li> <p>\"Telling yourself you have all the time in the world, all the money in the world, all the colors in the palette, anything you want\u2014that just kills creativity.\"</p> </li> <li> <p>\"What we respond to in any work of art is the artist\u2019s struggle against his or her limitations.\"</p> </li> <li> <p>\"An expert is a person who has made all the mistakes that can be made in a very narrow field.\"</p> </li> <li> <p>\"Ordinarily he was insane, but he had lucid moments when he was merely stupid.\"</p> </li> <li> <p>\"Reality is merely an illusion, albeit a very persistent one.\"</p> </li> <li> <p>\"The first principle is that you must not fool yourself, and you are the easiest person to fool.\"</p> </li> <li> <p>\"Options\u2014the ability to choose\u2014is real power.\"</p> </li> <li> <p>\" It just so happens, paradoxically, that you can make more money\u2014a lot more money\u2014by doing half of what you are doing now.\"</p> </li> <li> <p>\"Civilization had too many rules for me, so I did my best to rewrite them.\"</p> </li> <li> <p>\"In 21st century America, old-fashioned notions like honor and fair play are for suckers. The credo of our time is that as if it ain\u2019t technically illegal, it\u2019s awesome. The people who rise to the top are no longer those who accomplish truly great things, but those who figure out how to most attractively package their shortcuts and fake-outs.\"</p> </li> <li> <p>\"Once you say you're going to settle for second, that's  what happens to you in life.\"</p> </li> <li> <p>\"If the recipe sucks, it doesn't matter how good a cook you are.\"</p> </li> <li> <p>\"Named must your fear be before banish it you can.\"</p> </li> <li> <p>\"No more passing days as the living dead, no more dinners where his colleagues compared cars, riding on the sugar high of a new BMW purchase until someone bought a more expensive Mercedes. It was over.\"</p> </li> <li> <p>\"Set aside a certain number of days, during which you shall be content with the scantiest and cheapest fare, with course and rough dress, saying to yourself the while: \"Is this the condition that I feared?\"</p> </li> <li> <p>\"There's  no difference between a pessimist who says, \"Oh, it's  hopeless, so don't bother doing anything,\" and an optimist who says, \"Don't bother doing anything, it's  going to turn out fine anyway.\" Either way, nothing happens.\"</p> </li> <li> <p>\"Don't save it all for the end. There is every reason not to.\"</p> </li> <li> <p>\"I am an old man and have known a great many troubles, but most of them never happened.\"</p> </li> <li> <p>\"Doing the unrealistic Is easier than doing the realistic\"</p> </li> <li> <p>\"The fishing is best where the fewest go, and the collective insecurity of the world makes it easy for people to hit home runs while everyone else is aiming for base hits. There is just less competition for bigger goals.\"</p> </li> <li> <p>\"Remember\u2014boredom is the enemy, not some abstract \"failure.\"</p> </li> <li> <p>\"The existential vacuum manifests itself mainly in a state of boredom.\"</p> </li> <li> <p>\"Perfection is not when there is no more to add, but no more to take away.\"</p> </li> <li> <p>\"It is vain to do with more what can be done with less.\"</p> </li> <li> <p>\"Doing something unimportant well does not make it important.\"</p> </li> <li> <p>\"In other words, I was working because I felt as though I should be doing something from 9-5.1  didn't realize that working every hour from 9-5 isn't the goal; it's  simply the structure most people use, whether it's  necessary or not.\"</p> </li> <li> <p>\"Most things make no difference. Being busy is a form of laziness\u2014lazy thinking and indiscriminate action.\"</p> </li> <li> <p>\"Since we have 8 hours to fill, we fill 8 hours. If we had 15, we would fill</p> </li> <li> <p>If we have an emergency and need to suddenly leave work in 2 hours but have pending deadlines, we miraculously complete those assignments in 2 hours.\"</p> </li> <li> <p>\"Parkinson's  Law dictates that a task will swell in (perceived) importance and complexity in relation to the time allotted for its completion.\"</p> </li> <li> <p>\"Am I being productive or just active?\"</p> </li> <li> <p>\"Reading, after a certain age, diverts the mind too much from its creative pursuits. Any man who reads too much and uses his own brain too little falls into lazy habits of thinking.\"</p> </li> <li> <p>\"We\u2019re all pieces on someone\u2019s board, Jorg.\"</p> </li> <li> <p>\"We look at the world once, in childhood. The rest is memory.\"</p> </li> <li> <p>\"Drink your tea slowly and reverently, as if it is the axis on which the world earth revolves \u2013 slowly, evenly, without rushing toward the future.\"</p> </li> <li> <p>\"Isn't it strange that the only time we truly lived is when we were not even thinking about living truly?\"</p> </li> <li> <p>\" A window to a new world can also show you home\"</p> </li> <li> <p>\"I think maybe we die every day. Maybe we\u2019re born new each dawn, a little changed, a little further on our own road. When enough days stand between you and the person you were, you\u2019re strangers. Maybe that\u2019s what growing up is. Maybe I have grown up. \"</p> </li> <li> <p>\"I\u2019ve grown, but whatever monster might be in me, it was always mine, my choice, my responsibility, my evil, if you will. It\u2019s what I am, and if you want excuses, come and take them.\"</p> </li> <li> <p>\" When the economy is down, people go to school\"</p> </li> <li> <p>\"The Puppy Dog Close in sales is so named because it is based on the pet store sales approach: If someone likes a puppy but is hesitant to make the life-altering purchase, just offer to let them take the pup home and bring it back if they change their minds. Of course, the return seldom happens.\"</p> </li> <li> <p>\"It's  amazing how someone's  IQ seems to double as soon as you give them responsibility and indicate that you trust them.\"</p> </li> <li> <p>\"People think it must be fun to be a super genius, but they don't realize how hard it is to put up with all the idiots in the world.\"</p> </li> <li> <p>\"But the whole problem of discovering what was the matter, and figuring out what you have to do to fix it--that was interesting to me, like a puzzle.\"</p> </li> <li> <p>\"I learned there that innovation is a very difficult thing in the real world.\"</p> </li> <li> <p>\"If a typical person can do a mental task with less than one second of thought, we can probably automate it using AI either now or in the near future\"</p> </li> <li> <p>\"A single dream is more powerful than a thousand realities\"</p> </li> <li> <p>\"The billionaires of tomorrow always seem to start out in garages, don\u2019t they?\"</p> </li> <li> <p>\"Life is unfair. You make the best of what life deals you\"</p> </li> <li> <p>\" Every path is the right path. Everything could've been anything else.\ufeff And it would have just as much meaning.\"</p> </li> <li> <p>\"Choices ... We cannot go back. That\u2019s why it\u2019s hard to choose. You have to make the right choice. As long as you don\u2019t choose, everything remains possible.\"</p> </li> <li> <p>\"In chess, it's  called Zugzwang...when the only viable move...is not to move.\"</p> </li> <li> <p>\"The child could not make a choice because he did not know what would happen, but now that he knows what will happen, he can not make a choice.\"</p> </li> <li> <p>\"I'm not afraid to die, I'm afraid I haven't lived enough. It should be written on every school chalkboard, \"Life is a playground- or nothing.\"</p> </li> <li> <p>\"Why am I me and not somebody else?\"</p> </li> <li> <p>\"But the logic of his immediate circumstances was overwhelming his other concerns, however well founded they might be. He had never been one to argue with logic.\"</p> </li> <li> <p>\"There is surely nothing other than the single purpose of the present moment. A man\u2019s whole life is a succession of moment after moment. If one fully understands the present moment, there will be nothing else to do, and nothing else to pursue. Live being true to the single purpose of the moment.\"</p> </li> <li> <p>\"Saving one dog will not change the world, but surely for that one dog, the world will change forever.\"</p> </li> <li> <p>\"He wasn\u2019t in a safe little story where wrongs were automatically righted; he was still in the real world, where bad, bitter things happened for no reason, and people paid for things that weren\u2019t their fault.\"</p> </li> <li> <p>\"For the true magician there is no very clear line between what lies inside the mind and what lies outside it. If you desire something, it will become substance. If you despise it, you will see it destroyed. A master magician is not much different from a child or a madman in that respect. It takes a very clear head and a very strong will to operate once you are in that place. And you will find out very quickly whether or not you have that clarity and that strength.\"</p> </li> <li> <p>\"Everybody has their own idiopathic reaction to their childhood home.\"</p> </li> <li> <p>\"So you have to promise me, Quentin. Let\u2019s never get like this, with these stupid hobbies nobody cares about. Just doing pointless things all day and hating each other and waiting to die. Well, you drive a hard bargain,\" he said.</p> </li> <li> <p>\"But okay. I promise. I\u2019m serious, Quentin. It\u2019s not going to be easy. It\u2019s going to be so much harder than you think. They don\u2019t even know, Quentin. They think they\u2019re happy. That\u2019s the worst part.\"</p> </li> <li> <p>\"Sometimes I wonder if man was really meant to discover magic,\" Fogg said expansively. \"It doesn\u2019t really make sense. It\u2019s a little too perfect, don\u2019t you think? If there\u2019s a single lesson that life teaches us, it\u2019s that wishing doesn\u2019t make it so. Words and thoughts don\u2019t change anything. Language and reality are kept strictly apart\u2014reality is tough, unyielding stuff, and it doesn\u2019t care what you think or feel or say about it. Or it shouldn\u2019t. You deal with it, and you get on with your life. Little children don\u2019t know that. Magical thinking: that\u2019s what Freud called it. Once we learn otherwise we cease to be children. The separation of word and thing is the essential fact on which our adult lives are founded. But somewhere in the heat of magic that boundary between word and thing ruptures. It cracks, and the one flows back into the other, and the two melt together and fuse. Language gets tangled up with the world it describes. I sometimes feel as though we\u2019ve stumbled on a flaw in the system, don\u2019t you? A short circuit? A category error? A strange loop? Is it possible that magic is knowledge that would be better off forsworn? Tell me this: Can a man who can cast a spell ever really grow up?\"</p> </li> <li> <p>\"I think you\u2019re magicians because you\u2019re unhappy. A magician is strong because he feels pain. He feels the difference between what the world is and what he would make of it. Or what did you think that stuff in your chest was? A magician is strong because he hurts more than others. His wound is his strength. Most people carry that pain around inside them their whole lives, until they kill the pain by other means, or until it kills them. But you, my friends, you found another way: a way to use the pain. To burn it as fuel, for light and warmth. You have learned to break the world that has tried to break you.\"</p> </li> <li> <p>\"How can you seek eternal life by means of a temporal body?\"</p> </li> <li> <p>\"I've lived through some terrible things in my life, some of which actually happened.\"</p> </li> <li> <p>\"The goal is not for everyone to be equal. The goal is for everyone to be connected. The goal is for everyone to belong. The goal is for everyone to be loved.\"</p> </li> <li> <p>\"How can the events in space and time, which take place within the boundaries of a living organism, be accounted for by physics and chemistry? . . . The obvious inability of present-day physics and chemistry to account for such events is no reason at all for doubting that they will be accounted for by those sciences.\"</p> </li> <li> <p>\"human was the music, natural was the static...\"</p> </li> <li> <p>\"We worship perfection because we can't have it; if we had it, we would reject it. Perfection is inhuman, because humanity is imperfect.\"</p> </li> <li> <p>\"life so perfect, it flatlines\"</p> </li> <li> <p>\"Because there\u2019s an infinite amount of things we can now see or know, there are also an infinite number of ways we can discover that we don\u2019t measure up, that we\u2019re not good enough, that things aren\u2019t as great as they could be. And this rips us apart inside.\"</p> </li> <li> <p>\"Because when you give too many fucks\u2014when you give a fuck about everyone and everything\u2014you will feel that you\u2019re perpetually entoc: true titled to be comfortable and happy at all times, that everything is supposed to be just exactly the fucking way you want it to be. This is a sickness. And it will eat you alive. You will see every adversity as an injustice, every challenge as a failure, every inconvenience as a personal slight, every disagreement as a betrayal. You will be confined to your own petty, skull-sized hell, burning with entoc: true titlement and bluster, running circles around your very own personal Feedback Loop from Hell, in constant motion yet arriving nowhere.\"</p> </li> <li> <p>\"Don\u2019t hope for a life without problems,\" the panda said. \"There\u2019s no such thing. Instead, hope for a life full of good problem\"</p> </li> <li> <p>\"Emotions are merely signposts, suggestions that our neurobiology gives us, not commandments.\"</p> </li> <li> <p>\"The deeper the pain, the more helpless we feel against our problems, and the more entoc: true titlement we adopt to compensate for those problems.\"</p> </li> <li> <p>\"If one isn\u2019t crazy, why would they try to understand something like the laws of the heavens? If one isn\u2019t crazy, why would they try to become an immortal? One must want something in order to obtain it. That is the truth\"</p> </li> <li> <p>\"All of the glorious moments of the past had become distant memories\u2026The one that falls in the fire must be that immortal phoenix\u2026 Even if it must burn its wings, it will still fly in the heavens\u2026Closing one door is like loving a world.Memories of the past will now be forever distant.The sand in the wind no longer filled the space of dreams. The whimper of the powerful flute is now only an echo in the desolate land.Closing off one door is like cutting off one space and time.The glorious past only remains in the descent\u2019s songs.Yesterday\u2019s song no longer resonate the same way. The whispering complaints can\u2019t find its matching music.Opening a window is like hugging a ray of sunlight.Today\u2019s dream became the future empire\u2019s hope.Even the ordinary you and me need to have exciting displays. Pursuit without regret to feel the might of the world.Opening a window is like welcoming a wave of spring wind.The burst of nothingness awaken what was once lost.The one that fell in the fire must be that immortal phoenix\u2026 Even if it must burn its wings it will still fly in the heavens.\"</p> </li> <li> <p>\"The rainy night is beautiful in its mood and endlessness. The plants silently absorb the water and the scent of death on them quietly disappears. This is the beauty of the rain and the taste of life.\"</p> </li> <li> <p>\"What is death\u2026 death is to die. If a person dies, then it is death, and if the heart dies, then it forgets\u2026 that is death.\"</p> </li> <li> <p>\"The water falling in this puddle today is life. Tomorrow, when there is no water falling, then this puddle is death. Dead water is water without life and flow.\"Then his right hand casually pointed again and this time it was on the men next to the fire. The void in his eyes became even stronger and he said,</p> </li> <li>\"Today they can enjoy, be angry, be sad, or be happy. That is life. In the future, they won\u2019t be able to enjoy, be angry be sad, or be happy, and that is death.\"His hand suddenly moved and pointed at a praying mat. He said, \"This shrine was alive when the statue of the god was here. Now that it is without it, it is dead!\"Speaking of this, he stood up, pointed at the sky, and said,</li> <li> <p>\"These raindrops are born in the sky and die on the earth. What\u2019s in the middle is their life. I look at this rain not for the sky, earth, or the rain itself, but the raindrop\u2019s entire life\u2026 this cycle of life and death.\"</p> </li> <li> <p>\"Life and death are separated by a thin line. Some are clearly dead, but they are now living in someone else\u2019s heart. Some are clearly alive, but they start dying if they don\u2019t change.\"</p> </li> <li> <p>\"She felt Wang Lin\u2019s lips and his warmth. This warmth contained an unerasable joy, a silent call, and a sense of protection that will never fade.Love is like a river; the left shore is the joyous laughter that can brighten up 1000 years of sadness and the right shore is an eternal silence lingering under the candlelight. What flows between them is years of fading loneliness.\"</p> </li> <li> <p>\"Humans often choose to dedicate large portions of their lives to seemingly useless or destructive causes. On the surface, these causes make no sense.\"</p> </li> <li> <p>\"We\u2019re apes. We think we\u2019re all sophisticated with our toaster ovens and designer footwear, but we\u2019re just a bunch of finely ornamented apes. And because we are apes, we instinctually measure ourselves against others and vie for status. The question is not whether we evaluate ourselves against others; rather, the question is by what standard do we measure ourselves?\"</p> </li> </ul> <p>Quotes temp</p> <ul> <li> <p>\"As long as one\u2019s heart is determined, then one can cultivate any of the millions of daos that exist!\"</p> </li> <li> <p>\"Things of this world can\u2019t escape karma. The karmatic cause of yesterday will be the karmatic effect of today. Only by settling one\u2019s karma and letting dirt return to dirt, letting dust return to dust, can a cycle be complete.\"</p> </li> <li> <p>\"Sometimes one or two leaves would fall and drift before his eyes.Falling leaves will all eventually return to the roots of the tree. They were like children who would leave when tired but would always return to their love ones.\"</p> </li> <li> <p>\"All of humanity's  problems stem from man's  inability to sit quietly in a room alone.\"</p> </li> <li> <p>\"There are no monsters in the sea. Only the ones we make up in our heads\"</p> </li> <li> <p>\"The heavens\u2019 dao is endless, the path of dao is boundless. The kind act of today will create karmic cause\u2026 In the future, the cycle will be completed and karmic effect will form\u2026 Dao is like this bowl, not perfect and filled with cracks. It can be broken at any time\u2026 The dao of the heavens is something everyone can prove and everyone can confirm. The heavens is not dao. Dao is formed by the will of the heavens and earth. Everyone can have this will!\"Just like the fish that lives in the river. It doesn\u2019t violate the heavens or provoke yin and yang, it lives peacefully and free! This river is the heavens, the world. The fish is all living things that exist inside the world!\"However, the net pulls the fish out from the river. This net is dao, the laws of the world! No matter where you are, you won\u2019t be able to escape dao!\"This net will one day pull the fish out from the river. Once out of the river, the fish will face the laws of the world. Either it obeys and enters the reincarnation cycle or it must revolt! Break the net and revolt!\"Cultivators are like the struggling fish. The more they fiercely the struggle, the more they defy dao!\"This is dao! Whether it is life and death or karma, all of it is formed by the will of dao! I\u2019m karma\"</p> </li> <li> <p>\"Apricot tree blooms white flowers\u2026\"Cultivation, cultivation, mortals yearn to become immortal and enter the cultivation world. Yet they don\u2019t know how many cultivators are envious of a mortal\u2019s bland life.\"How many more died in foreign places like Sun Tai, their ashes scattering with the wind, unable to return home\u2026 However, many parents and relatives weren\u2019t able to meet their children even at their dying moment. If one had the chose again, would they still take that step to become a cultivator\u2026\"</p> </li> <li> <p>\"The flame moved with the wind just like how the wind makes the plants move, which makes it look like the mountain is moving, but in reality\u2026\" Wang Lin pondered.\"In reality, the mountain didn\u2019t move, the flame didn\u2019t move, what moved was the wind!\"</p> </li> <li> <p>\"Dao is like a thought, and everyone\u2019s thoughts are different. If one wants to enrich one\u2019s own mind, they must learn other people\u2019s thoughts as well.\"</p> </li> <li> <p>\"Where is there no heaven?\"Wang Lin didn\u2019t speak but raised his right hand and waved. A breeze blew through the courtyard and a circle appeared on the ground around Li Qianmei and Lu Yuncong. It was as if someone had drawn a circle around them with a stick.\"This is the circle is the heaven both of you think exist. Because you believe that there is a heaven, the heavens exist. You regard yourselves as ants that struggle to break out from the heavens, which is your cage. This is your belief and your faith. However, even if you walk out from the circle, what\u2019s the use?\"Wang Lin shook his head and waved his right hand, then another circle formed around the circle from before.\"Once you come out, there will still be another heaven, and the cycle of karma continues without end until\u2026 The heaven in your heart is erased by the heavens, and this is the lie of the heavens! I was thinking about this hundreds of years ago. So why must there be a heaven?\"</p> </li> <li> <p>\"A old friend once told me that the rain is born from the heavens and dies on the earth. The middle is life\u2026 But does the rain really come from the heavens\u2026. Rain comes from the void and has nothing to do with the heavens. The rain falls on the earth and nourishes all life, but it has nothing to do with the earth. It is just the fate of rain!\"The rain forms from water vapor, and water vapor comes from all living things. The rain naturally needs to return to them. This is a cycle, a cycle of karma, and it can also be considered fate.\"There is the law of fate. It is invisible, but it surrounds all life and quietly changes everything\u2026\" Wang Lin looked at the sky and randomly waved his hand. A thunderous rumble came from the sky and then water vapor gather from all sides. Dark clouds appeared, and a moment later, rain fell from the sky.\"Look at the life of a raindrop. Is there any raindrop that falls in a straight line\u2026 I observed rain for a long time like I was viewing life, but I didn\u2019t see any drop of rain fall straight without changing its trajectory. They\u2026 always change due to the wind or the clouds or their own weight, adjusting the place they will land. Do you see the unwillingness from the rain?\"Do you know why it is like this?\" Wang Lin withdrew his gaze and looked at Li Qianmei.Li Qianmei looked at the rain, and after a long time, she softly said, \"Where the will of the heavens exists, fate will change.\"The life of a raindrop is very short, but due to cycle, it is very long\u2026 Cultivators like us have very long lives, but due to the will of the heavens, it is also very short.\"However, in just in the short life of a drop of rain, it struggles countless times to escape the control of fate. In order to fight fate, it keeps changing where it will land!\"And the long lives of cultivators like us are not something the rain can\u2019t compare to, but how many are willing to desperately struggle to the death to escape the clutches of fate like the rain? To struggle until death to resist the arrangement of the heavens. To struggle until death to defy the will of the heavens!\"Wang Lin waved his sleeves and the sky rumbled and the rain was pushed back into the clouds. The dark clouds collapsed and the rain turned into water vapor that dissipated into the world.\"You changing the fate of the raindrop makes you the will of the heavens. The moth will be burned by the fire. If you blow out the fire, making it so the moth can\u2019t die in the fire, then you have changed the fate of the moth. If fate wants someone to die but you save them, then you are the will of the heavens! There is a saying from ancient times: Are those who call themselves kings and lords more noble than us?\u2019 This saying embodies this truth!\"The celestials also had a saying: Once a man achieves dao, his chicken and dogs will rise to heaven.\u2019\"</p> </li> </ul> <p>.\"Dao isn\u2019t the net or the mountain, but a thought! This thought varies from person to person. Some people regard it as a net, while others regard it as a mountain\u2026\" When Wang Lin heard Li Qianmei\u2019s words, he began to ponder, and his eyes gradually grew brighter.\"Dao is a thought? A person is a person because they have thoughts, so they can separate from their body, merge with the world, and ponder about the unknown\u2026\"</p> <ul> <li>\"life springs from the dirt of the earth, and water too clean often harbors no fish.\u2019</li> </ul> <p>.\"Seeking dao\u2026 In truth, it is bringing the dao into your heart, this is dao-seeking. The so-called comprehension and domain are the same. You keep a comprehension in your heart and slowly experience it until it merges with your dao. Eventually, it will become a domain, an ideal.\"</p> <ul> <li> <p>\"When we\u2019re passionate about something, we want other people to also be passionate about it. It validates ourselves. We don\u2019t care if our passion is good for other people. We just want them to confirm that our passion is the best thing in the world.\"</p> </li> <li> <p>\"The body\u2019s desire for homeostasis can be harnessed to drive changes: push it hard enough and for long enough, and it will respond by changing in ways that make that push easier to do.\"</p> </li> <li> <p>\"YOU GONNA BOO HOO OR YOU GONNA YEE HAW?!\"</p> </li> <li> <p>\"I can take a spoon and swing that at a tree and call that sucker an axe\"</p> </li> <li> <p>\"I tend to think too much, Bast. My greatest successes came from decisions I made when I stopped thinking and simply did what felt right. Even if there was no good explanation for what I did.\" He smiled wistfully. \"Even if there were very good reasons for me not to do what I did.\"</p> </li> <li> <p>\"How odd to watch a mortal kindle Then to dwindle day by day. Knowing their bright souls are tinder And the wind will have its way. Would I could my own fire lend. What does your flickering portend?\"</p> </li> <li> <p>\"Call a jack a jack. Call a spade a spade. But always call a whore a lady. Their lives are hard enough, and it never hurts to be polite.\"</p> </li> <li> <p>\"Just pity him, my boy. Tomorrow we\u2019ll be on our way, but he\u2019ll have to keep his own disagreeable company until the day he dies.\"</p> </li> <li> <p>\"A poet is a musician who can\u2019t sing. Words have to find a man\u2019s mind before they can touch his heart, and some men\u2019s minds are woeful small targets. Music touches their hearts directly no matter how small or stubborn the mind of the man who listens.\"</p> </li> <li> <p>\"Bones mend. Regret stays with you forever.\"</p> </li> <li> <p>\"Because pride is a strange thing, and because generosity deserves generosity in return. But mostly because it felt like the right thing to do, and that is reason enough.\"</p> </li> <li> <p>\"Besides, anger can keep you warm at night, and wounded pride can spur a man to wondrous things.\"</p> </li> <li> <p>\"Anyone who thinks boys are innocent and sweet has never been a boy himself, or has forgotten it. And anyone who thinks men aren\u2019t hurtful and cruel at times must not leave his house often. And he has certainly never been a physicker.\"</p> </li> <li> <p>\"That\u2019s why stories appeal to us. They give us the clarity and simplicity our real lives lack.\"</p> </li> <li> <p>\"Music is a proud, temperamental mistress. Give her the time and attention she deserves, and she is yours. Slight her and there will come a day when you call and she will not answer.\"</p> </li> <li> <p>\"And while my suite of rooms at the Horse and Four had been luxurious, my tiny room at Anker\u2019s was comfortable. Think in terms of shoes. You don\u2019t want the biggest you can find. You want the pair that fits. In time, that tiny room at Anker\u2019s came to be more of a home to me than anywhere else in the world.\"</p> </li> <li> <p>\"If you are searching for a pattern in anything, you will most likely find it\"</p> </li> <li> <p>\"It had been treated unkindly in the past, but that didn\u2019t make it less lovely underneath. So yes. It had flaws, but what does that matter when it comes to matters of the heart? We love what we love. Reason does not enter into it. In many ways, unwise love is the truest love. Anyone can love a thing because. That\u2019s as easy as putting a penny in your pocket. But to love something despite. To know the flaws and love them too. That is rare and pure and perfect.\"</p> </li> <li> <p>\"You know you\u2019re clever. That\u2019s your weakness. You assume you know what you\u2019re getting into, but you don\u2019t.\"</p> </li> <li> <p>\"My point is this. In each of us there is a mind we use for all our waking deeds. But there is another mind as well, a sleeping mind. It is so powerful that the sleeping mind of an eight-year-old can accomplish in one second what the waking minds of seven members of the Arcanum could not in fifteen minutes.\"</p> </li> </ul> <p>He made a sweeping gesture. \"Your sleeping mind is wide and wild enough to hold the names of things. This I know because sometimes this knowledge bubbles to the surface. Inyssa has spoken the name of iron. Her waking mind does not know it, but her sleeping mind is wiser. Something deep inside Fela understands the name of the stone.\"</p> <p>Elodin pointed at me. \"Kvothe has called the wind. If we are to believe the writings of those long dead, his is the traditional path. The wind was the name aspiring namers sought and caught when things were studied here so long ago.\"</p> <ul> <li> <p>\"What use is care? What good is watching for that matter? People are forever watching things. They should be seeing. I see the things I look at. I am a see-er.\"</p> </li> <li> <p>\"The struggle is great, the task divine\u2014to gain mastery, freedom, happiness, and tranquility.\"</p> </li> <li> <p>\"This is, in fact, the first obligation of a leader and a decision maker. Our job is not to \"go with our gut\" or fixate on the first impression we form about an issue. No, we need to be strong enough to resist thinking that is too neat, too plausible, and therefore almost always wrong. Because if the leader can\u2019t take the time to develop a clear sense of the bigger picture, who will? If the leader isn\u2019t thinking through all the way to the end, who is?\"</p> </li> <li> <p>\"We do not live in this moment. We, in fact, try desperately to get out of it\u2014by thinking, doing, talking, worrying, remembering, hoping, whatever. We pay thousands of dollars to have a device in our pocket to ensure that we are never bored. We sign up for endless activities and obligations, chase money and accomplishments, all with the na\u00efve belief that at the end of it will be happiness.\"</p> </li> <li> <p>\"A wealth of information creates a poverty of attention.\"</p> </li> <li> <p>\"Chop wood, carry water. Chop wood, carry water. Chop wood, carry water.\"</p> </li> <li> <p>\"With my sighted eye I see what\u2019s before me, and with my unsighted eye I see what\u2019s hidden\"</p> </li> <li> <p>\"What they thought was silence, because they didn\u2019t know how to listen, was full of accidental sounds. You could hear the wind stirring outside during the first movement. During the second, raindrops began pattering the roof, and during the third the people themselves made all kinds of interesting sounds as they talked or walked out.\"</p> </li> <li> <p>\"Most of us would be seized with fear if our bodies went numb, and would do everything possible to avoid it, yet we take no interest at all in the numbing of our souls.\"</p> </li> <li> <p>\"In other words, any act that rejects immediate gratification in favor of long-term growth, health, or integrity. Or, expressed another way, any act that derives from our higher nature instead of our lower. Any of these will elicit Resistance.\"</p> </li> <li> <p>\"The more important a call or action is to our souls evolution, the more Resistance we will feel toward pursuing it.\"</p> </li> <li> <p>\"Doctors estimate that seventy to eighty percent of their business is non-health-related. People aren't sick, they're self-dramatizing.\"</p> </li> <li> <p>\"In the past, the focus of the process of invention has tended to be on actually getting something to work (\"find the lightbulb filament that works,\" et cetera). But in the computational universe, the focus shifts to the question of what you want the invention to do. Because once you\u2019ve described the goal, finding a way to achieve it is something that can be automated.\"</p> </li> <li> <p>\"the truly free individual is free only to the extent of his own self-mastery.\"</p> </li> <li> <p>\"The artist must be like that Marine. He has to know how to be miserable. He has to love being miserable. He has to take pride in being more miserable than any soldier or swabbie or jet jockey. Because this is war, baby. And war is hell.\"</p> </li> <li> <p>\"My friend Tony K e p p e l m a n's n a p p e d me out of it by asking if I was gonna quit. Hell, no! \"Then be happy. You're where you wanted to be, aren't you? So you're taking a few blows. That ''s the price for being in the arena and not on the sidelines. Stop complaining and be grateful.\"</p> </li> <li> <p>\"He knows that any job, whether it's  a novel or a kitchen remodel, takes twice as long as he thinks and costs twice as much. He accepts that.\"</p> </li> <li> <p>\"The Bhagavad-Gita tells us we have a right only to our labor, not to the fruits of our labor. All the warrior can give is his life; all the athlete can do is leave everything on the field. The professional loves her work. She is invested in it wholeheartedly. but she does not forget that the work is not her. her artistic self contains many works and many performances. already the next is percolating inside her. the next will be better, and the one after that better still.  the professional self-validates. she is tough-minded. in the face of indifference or adulation, she assesses her stuff coldly and objectively. where it fell short, she'll improve it. where it triumphed, she'll make it better still. she'll work harder. she'll be back tomorrow.\"</p> </li> <li> <p>\"The professional cannot allow the actions of others to define his reality. Tomorrow morning the critic will be gone, but the writer will still be there facing the blank page.\"</p> </li> <li> <p>\"I'm not sure if the most spoken words in the average american household are 'I love you' or 'I want that'\"</p> </li> <li> <p>\"Eternity is in love with the creations of time.\"</p> </li> <li> <p>\"When we make a beginning, we get out of our own way\"</p> </li> <li> <p>\"The act of creation is by definition territorial. As the mother-to-be bears her child within her, so the artist or innovator contains her new life. No one can help her give it birth. But neither does she need any help.\"</p> </li> <li> <p>\"Creative work is not a selfish act or a bid for attention on the part of the actor. It's  a gift to the world and every being in it. Don\u2019t cheat us of your contribution. Give us what you've got.\"</p> </li> <li> <p>\"The cost of a thing is the amount of what I will call life which is required to be exchanged for it, immediately or in the long run\"</p> </li> <li> <p>\"It is strange to be known so universally and yet be so lonely.\"</p> </li> <li> <p>\"When the void is filled, you no longer need distractions to help you avoid it.\"</p> </li> <li> <p>\"Document vs create\"</p> </li> <li> <p>\"Shit is subjective my man. People arent starting. They are pondering, debating.\"</p> </li> <li> <p>\"Do you know yourself? Or do you aspire to be something youre not\"</p> </li> <li> <p>\"You cant create today, distribute, facilitate\"</p> </li> <li> <p>\"Civilizations advance by extending the number of operations we can perform without thinking\"</p> </li> <li> <p>\"Realists are often just dreamers who got their hearts broken along the way\"</p> </li> <li> <p>\"Perfectionism is the enemy of action\"</p> </li> <li> <p>\"You are not invisible if you can see yourself\"</p> </li> <li> <p>\"Love and rationality weren\u2019t compatible.\"</p> </li> <li> <p>\"If you want to accomplish something great, your heart needs to be in the right place. You don\u2019t possess such a vision, yet you think you are worthy to claim that you will bring the human race to prominence?\"</p> </li> <li> <p>\"If you chased after the dream of humankind\u2019s rise to prominence, constantly pursuing the most profound secrets of this world, but you discovered that what really hindered you was the human race itself, how would you feel?\"</p> </li> <li> <p>\"Before you achieved any success, the entire world would laugh at you, scorn you, and look down on you. When you achieved success...... the whole world would become your enemy!\"</p> </li> <li> <p>\"Real experts don\u2019t fear anything. They act prudently and cautiously at every step.\"</p> </li> <li> <p>\"After all, if you give out some things for free, people won\u2019t value them anymore, and they might even make additional demands before they take you seriously. Also, the price that I\u2019m asking for it is really low; it\u2019s already quite generous!\"</p> </li> <li> <p>\"If I am doing something for the greater good, then I will focus all my attention on it. If I am doing something selfish, then I will choose the path that will bring me the most benefit.\"</p> </li> <li> <p>\"I don\u2019t care about what others think. To me, public and personal matters don\u2019t necessarily need to conflict. I can harbor great ambition for the human race, but I also need to know when to do things for myself!\"</p> </li> <li> <p>\"If you can make a vow for a girl today, you can break that vow for a girl another day\"</p> </li> <li> <p>\"If a person doesn\u2019t have dreams, what\u2019s the difference between them and a salted fish?\"</p> </li> <li> <p>\"Until you\u2019re ready to look foolish, you\u2019ll never have the possibility of being great.\"</p> </li> <li> <p>\"Fantasy and reality are polar existences of each other, and yet dependent on the other. Without fantasy, there is no point in reality. Without reality, fantasy has no meaning. Reality is fantasy, fantasy is reality, this is already the 99th world that I\u2019ve come to\u2026\"</p> </li> <li> <p>\"Samsara is not a simple return to the origin. It is Nirvana and it is rebirth.\"</p> </li> <li> <p>\"Betrayal is the only truth. Human nature is that of greed to begin with; no one can ever be content. \"</p> </li> <li> <p>\"Little Friend Lin, you have an excellent future and time ahead of you; it really arouses envy in others. Cherish it well. Life is short and no matter how beautiful the springtime of your youth is, white hair will await you in the end. If you waste your years then it will become far more difficult to advance when you reach old age!\"</p> </li> <li> <p>\"The road of martial arts is to defy the will of the heavens to begin with! You blame the heavens for being unfair, then you might as well blame the world for not being flat. \"</p> </li> <li> <p>\"In chaos, there was neither space nor time, there was nothing to hear or anything to feel, so how could anything be called large or small?\"</p> </li> <li> <p>\"Dont worry about being interesting, be worried about being interested\"</p> </li> <li> <p>\"Even the Heavenly Dao has its own samsara. Moreover, even if we may live for a hundred million years, in my opinion, that is nothing more than a great and wonderful dream. The passing clouds, the awakening dreams, everything is nothing but fleeting ripples in water.\"</p> </li> <li> <p>\"If I can preach to the infallible, then after I perish within my fires, let my tongue remain forever.\"</p> </li> <li> <p>\"There are no eternal enemies nor are there eternal friends. There are only eternal interests.\"</p> </li> <li> <p>\"Climbing the road of martial arts is originally trying to shake the leaves from a tree with a simple gust of wind\u2026 at the least\u2026 you have the courage to try\u2026\"</p> </li> <li> <p>\"A person always needed a group to recognize them. When everything was destroyed, when his family and friends were all gone, leaving him all alone, then even if he could grasp the heavens and earth in his palm in millions of years, even if he could rule over the universe by himself, what meaning was there in that?\"</p> </li> <li> <p>\"Then, the golden pages left behind amongst the spiritas spoke about returning to one\u2019s true origins. I am the universe. I am the myriad of existence!\"</p> </li> <li> <p>\"Your sense of purpose is too strong. Things that are valuable to you, you will pursue. But things that are worthless, you will give up. For instance, this lake. If you had passed by this lake I\u2019m afraid you wouldn\u2019t even have spared it a single glance\u2026Your life could be called breaking through all obstacles in your way, moving forwards with unstoppable momentum. You desperately rush towards the peak of martial arts and you far surpass all others of your generation. From the time you bloomed, you took few detours. But to gain this you also lost something. The road of martial arts is more than the most mysterious and the greatest of the Heavenly Dao Laws. There are also ordinary, everyday experiences. You are missing a section of your path\u2026 Your road might be called too smooth. In the past you might have experienced some setbacks, but those are far from enough. You are invincible amongst your peers. In battle you sing nothing but victory and have defeated countless rivals. It could even be said that you have never experienced true defeat. But, that might become your limitation, making it impossibly difficult for you to step onto the peak of martial arts! For one whose road of martial arts is too smooth, for one who isn\u2019t forced to take detours, for one who sings nothing but hymns of victory, it is instead easy to fall into a bottleneck, making one forever unable to step onto the peak of martial arts.\"</p> </li> <li> <p>\"The path of the martial artist is like a flame. Practicing the martial arts will only cause pain. The dangers are countless and the road is filled with obstacles. Everyone who walks down it will eventually turn to ash, but the true martial artist will be reborn from these ashes. Even if I am only a small and weak moth, I will walk into the flames without hesitation. I will fight my destiny for a one in a million chance that I will experience my own samsara and be reborn as a flaming phoenix. And even now, I am no longer a moth\u2026\"</p> </li> <li> <p>\"A worm that lives amongst the dead leaves and fallen branches will never understand the beauty and greatness of this world! And a worm was a creature that wouldn\u2019t live past the winter. Because of its short life, it didn\u2019t know the dangers of a world filled with ice and snow. But what about martial artists? Wasn\u2019t it the same? 10 billion years ago, those supreme elders might have seemed heaven-shaking and world-breaking, but were they able to see the world 10 billion years later? The current Good Fortune Saint Sovereign was also all-powerful, but would he be able to see the future of 10 billion years from now?\"</p> </li> <li> <p>\"I must struggle in the dust and chaos. Even if I am only a small wave, I will still bravely move forwards\u2026\"</p> </li> <li> <p>\"They gently supported each other. Even though there was no real physical touch, in this moment their hearts were still connected. This was because\u2026 within each other\u2019s hearts and minds they had forever marked each other, a brand that would never be forgotten.\"</p> </li> <li> <p>\"Life, really is small\u2026\"</p> </li> </ul> <p>If the heavens wish to destroy me then I will destroy the heavens. If the death god wants to take me then I will cut down the death god!\u2019</p> <ul> <li> <p>\"The charm of wine comes from the mood of drinking wine. Those that understand wine taste not just the wine but also the mood. From the spiciness when it first enters the throat, to the fresh heat once it is swallowed, to the lasting fragrance that one can mull over. It\u2019s just like life. In the world, countless people struggle. They experience hardship, they experience tribulations, and if they can survive all of that then they can return to their true state and release the mellow fragrance of life.\"</p> </li> <li> <p>\"Even if I have to climb without end in my life, even if I forever remain small and never see where the highest peak is, then at the very least\u2026 I will keep surpassing myself, I will keep defeating myself.\"</p> </li> <li> <p>\"During those days, although I experienced innumerable tribulations, these tribulations slowly grinded away my edges and corners, causing my character to change and become completely different from what I used to be\u2026 I began to learn how to restrain myself, learn how to think deeply of my actions and their consequences, learn to accept reality for what it was, learn to be grateful\u2026\"</p> </li> <li> <p>\"Man was always unwilling to die. But man would die no matter what. As a person approached the precipice of death, they would hope that they could leave behind something. So that when they closed their eyes one last time, they could tell themselves that their bloodline continued flowing on in the world\u2026 This intense desire, if traded for another name, could be called fatherly love\u2019 and motherly love\u2019. The love of parents. In essence, that was one\u2019s hope that one\u2019s life would continue to exist onwards. This was a selfish love, but also a selfless love. A parent\u2019s love never asked to be repaid, because to them, their children living well was the greatest repayment they could ever receive.\"</p> </li> <li> <p>\"In truth, you saying anything to me is meaningless\u2026 the future is not something given to you, but something that you struggle for yourself. Behind the backs of enemies you defeat lies your own road of growth. The peak of martial arts has never been something that you can reach by piling up resources or accumulating your background. Rather, it is something you slaughter towards even as you slowly explore your way towards it. When the vast cosmos of the 33 Heavens surges with chaos, that is a time when heroes pour forth from the ranks of creation. A calamity to end the world may be a graveyard for the weak, but it will also set the stage for the strong\u2026\"</p> </li> <li> <p>\"Pain comes from the body, but it actually reflects in the soul and mind\u2026 if I can control my soul, then no matter how painful it is it cannot be this fierce\u2026\"</p> </li> <li> <p>\"Currently, what Sheng Mei pursued was no longer eternal life, but instead what could truly touch her heart and move her soul. To cultivate to fulfill one\u2019s own heart, perhaps this was truly touching upon the peak of martial arts. But in reflection, what was one\u2019s heart? Perhaps that was to allow oneself, one\u2019s lovers, one\u2019s spouses, one\u2019s children, one\u2019s family, one\u2019s friends, one\u2019s people, to allow everyone to live in peace and happiness\u2026.\"</p> </li> <li> <p>\"Life, is innocent. Even amongst the saints, there are na\u00efve little children, there are kind-hearted subjects. This war was never their intention.\"</p> </li> <li> <p>\"I am not sure whether we can win or not. The future is not set in stone. We martial artists cultivate the body, cultivate the Heavenly Dao, cultivate the divine soul, but in the end, just what are we cultivating for? What are we chasing after? Even I have been left confused by this. For glory? That is only fleeting smoke before the eyes. For strength? I already possess the power to sunder the heavens and shatter the earth, to annihilate stars and the vastness of space. To become immortal? In these years I have also chased after immortality. However, when I was in the Emperor Bone Sea I looked upon the countless pained remnant souls there as well as the 100 billion year plot that the Soul Emperor had laid out for the sake of immortality, and suddenly, at that time I felt that chasing after eternal life was meaningless. For we that practice martial arts, we naturally must fight. But in fact, what we are fighting is the chaos of the world, the time when the catastrophe arrives. The extinction of races, lives lost like burning coals, the collapse and destruction of great worlds, this time, the fight has reached the peak. Then, perhaps the peak of martial arts is originally for the common people of the world\u2026\"</p> </li> <li> <p>\"Let the enemy sink into the bottomless sea of fighting against commoners.\"</p> </li> <li> <p>\"After all, humankind wasn\u2019t driven by words and whips, but by their own benefits. Putting it another way, as long as he could continuously fulfill the basic interests of the people under his rule, there would be no one who could shake his dominance.\"</p> </li> <li> <p>\"Rather than say 'charge for me', say 'charge with me'.\" Iron Axe smiled.</p> </li> <li> <p>\"The stronger you are, the more challenges you'll meet and the more setbacks you'll encounter. But don't forget, no matter how much hardship you experience, you're already enviable.\"</p> </li> <li> <p>\"I've been told that geniuses will always die doing what they are best at, and God would make up for it by giving such people an unmatchable talent\u2014This is fate. A road that's  destined to be good will cause the one who walks on it to succumb to temptation because of one's  extraordinary talent and eventually fall from grace. On the contrary, those ordinary people without much talent will tend to live longer.\"</p> </li> <li> <p>\"People needed to break through the impossible because no one knew whether there would be a miracle unless they tried.\"</p> </li> <li> <p>\"They said they wanted to defend Neverwinter and everything in their native town that they earned through their hard work.\" The old man sipped the tea and continued, \"To be completely honest, I  didn't understand at first and asked them why it had to be them instead of others. Lightning was asking the same question within herself. Broocher seemed to know what she was thinking. He answered, \"They said that others had made their sacrifices. Many people were killed during the battle against the demonic beasts when they were just members of the Militia. People died all the time when they fought against Duke Ryan and the church. If everybody relied on others, we would have been still working at the mine, living like animals,\" the old man said. \"There's  no battle without blood spilled. Everybody has his own turn. If nobody wanted to come forward, we would have been at the mercy of our enemy \u2014 that was what they told me.\"</p> </li> <li> <p>\"The history of the human civilization was, essentially, a process where men continuously developed different methods to boil water.\"</p> </li> <li> <p>\"Empathy is the ability to recognize the perspective of a counterpart and vocalize it\" \"There are three kinds of yes - counterfeit, confirmation and commitment\"</p> </li> <li> <p>\"All living things are mundane, and yet, all living things can also be extraordinary! Cultivators practice cultivation because of their desire to shed the limitations of the mortal world. They wish to be like the carp that leapt over the dragon gate\u2026. Plants and vegetation are similar. When concocting them into medicinal pills and consuming them, one should not solely focus on strengthening themselves, but should also strive to sense the plant\u2019s fundamental will. It might seem like the plant dies in the process of becoming a pill, but who can truly say whether or not this is just a rebirth into another stage of life for them?\"</p> </li> <li> <p>\"When your Dao is the heart, then if you have something in your heart, it exists. If you don\u2019t have it in your heart, it doesn\u2019t exist.\"</p> </li> <li> <p>\"Give a man a fish and you feed him for a day. Teach a man to fish and you feed him for a lifetime so that he many never discover how much he loves steak\"</p> </li> <li> <p>\"It\u2019s not the writing part that\u2019s hard. What\u2019s hard is sitting down to write. What keeps us from sitting down is Resistance.\"</p> </li> <li> <p>\"You think Resistance isn\u2019t real? Resistance will bury you.\"</p> </li> <li> <p>\"The danger is greatest when the finish line is in sight. At this point, Resistance knows we\u2019re about to beat it. It hits the panic button. It marshals one last assault and slams us with everything it\u2019s got.\"</p> </li> <li> <p>\"The paradox seems to be, as Socrates demonstrated long ago, that the truly free individual is free only to the extent of his own self-mastery. While those who will not govern themselves are condemned to find masters to govern over them.\"</p> </li> <li> <p>\"The counterfeit innovator is wildly self-confident. The real one is scared to death.\"</p> </li> <li> <p>\"So if you\u2019re paralyzed with fear, it\u2019s a good sign. It shows you what you have to do.\"</p> </li> <li> <p>\"Remember, the part of us that we imagine needs healing is not the part we create from; that part is far deeper and stronger. The part we create from can\u2019t be touched by anything our parents did, or society did. That part is unsullied, uncorrupted; soundproof, waterproof, and bulletproof. In fact, the more troubles we\u2019ve got, the better and richer that part becomes.\"</p> </li> <li> <p>\"I write only when inspiration strikes,\" he replied. \"Fortunately it strikes every morning at nine o\u2019clock sharp.\"</p> </li> <li> <p>\"Show me a writer who\u2019s too good to take Job X or Assignment Y and I\u2019ll show you a guy I can crack like a walnut.\"</p> </li> <li> <p>\"He knows that any job, whether it\u2019s a novel or a kitchen remodel, takes twice as long as he thinks and costs twice as much. He accepts that. He recognizes it as reality.\"</p> </li> <li> <p>\"Clear your mind young padawan, There is no emotion, there is peace. There is no ignorance, there is knowledge. There is no passion, there is serenity. There is no chaos, there is harmony. There is no death, there is the Force\".</p> </li> <li> <p>\"There you are; human nature in action, wrongdoers, blaming everybody but themselves. We are all like that.\"</p> </li> <li> <p>\"When dealing with people, let us remember we are not dealing with creatures of logic. We are dealing with creatures of emotion, creatures bristling with prejudices and motivated by pride and vanity.\"</p> </li> <li> <p>\"God himself, sir, does not propose to judge man until the end of his days. Why should you and I?\"</p> </li> <li> <p>\"If there is any one secret of success,\" said Henry Ford, \"it lies in the ability to get the other person's  point of view and see things from that person's  angle as well as from your own.\"</p> </li> <li> <p>\"The universe is largely left up to chance, and the control you think you have\u2026 much of it is a delusion.\"</p> </li> <li> <p>\"The world has never complained about how busy it is. \"</p> </li> <li> <p>\"Those who work in a playful, relaxed manner tend to work efficiently and creatively. Those who work nonstop, driven only by stress, work without joy.\"</p> </li> <li> <p>\"A good family trip can prevent divorce. What makes music beautiful is the distance between one note and another. What makes speech eloquent is the appropriate pause between words. From time to time we should take a breath and notice the silence between sounds.\"</p> </li> <li> <p>\"The tycoons of social media have to stop pretending that they\u2019re friendly nerd gods building a better world and admit they\u2019re just tobacco farmers in T-shirts selling an addictive product to children. Because, let\u2019s face it, checking your</p> </li> <li> <p>\"likes\" is the new smoking.\"</p> </li> <li> <p>\"Some may not believe it,but I spent hours perfecting whatever I did.\"</p> </li> <li> <p>\"People have to grow through skillful frustrations, otherwise they have no incentive to develop their own means and ways of coping with the world.\"</p> </li> <li> <p>\"Had not this water just now illustrated to me the principle of gung fu? I struck it but it did not suffer hurt. Again, I struck it with all my might\u2014yet it was not wounded! I then tried to grasp a handful of it but this proved impossible. This water, the softest substance in the world, which could be contained in the smallest jar, only seemed weak. In reality, it could penetrate the hardest substances in the world. That was it! I wanted to be like the nature of water.\"</p> </li> <li> <p>\"Well, the water was not to be deterred. It was going to find a path, or even multiple paths. It would move along until it met with an obstacle, and then, if it needed to, it would change course and keep on flowing. It used \"no way\" as its way. In other words, it used every possible way. And it ran along without limitation.\"</p> </li> <li> <p>\"Perfection as we typically think about it should be treated more as a way to focus our attention rather than a final accomplishment that we attain\"</p> </li> <li> <p>\"Like flowing water, life is perpetual movement\"</p> </li> <li> <p>\"Water doesn\u2019t have this problem. A wave doesn\u2019t have to remember how to land on the shore. A river doesn\u2019t have to consider how to carve a canyon into a mountain. A lake doesn\u2019t have to practice giving life to the fish and the plants. In its simple way of just being, water can be our guide along our path to our natural selves. And one day, if we self-actualize, we can attain (and reclaim) this\"</p> </li> <li> <p>\"The world is always fair to those who win\"</p> </li> <li> <p>\"Work hard, try your best and enjoy the good fortune if it comes your way. But dont depend on it. And dont think if it doesnt, you are somehow less worthy or to blame \"</p> </li> <li> <p>\"Life can only be understood backwards; but it must be lived forwards.\"</p> </li> <li> <p>\"You never know what worse luck your bad luck has saved you from.\"</p> </li> <li> <p>\"None of us are immune from life\u2019s tragic moments. Like the small rubber boat we had in basic SEAL training, it takes a team of good people to get you to your destination in life. You cannot paddle the boat\"</p> </li> <li> <p>\"Because, Mr. Mac, life isn\u2019t fair and the sooner you learn that the better off you will be\"</p> </li> <li> <p>\"It is easy to blame your lot in life on some outside force, to stop trying because you believe fate is against you. It is easy to think that where you were raised, how your parents treated you, or what school you went to is all that determines your future. Nothing could be further from the truth. The common people and the great men and women are all defined by how they deal with life\u2019s unfairness: Helen Keller, Nelson Mandela, Stephen Hawking, Malala Yousafzai, and\u2014Moki Martin. Sometimes no matter how hard you try, no matter how good you are\"</p> </li> <li> <p>\"Life is a struggle and the potential for failure is ever present, but those who live in fear of failure, or hardship, or embarrassment will never achieve their potential. Without pushing your limits, without occasionally sliding down the rope headfirst, without daring greatly, you will never know what is truly possible in your life.\"</p> </li> <li> <p>\"At some point we will all confront a dark moment in life. If not the passing of a loved one, then something else that crushes your spirit and leaves you wondering about your future. In that dark moment, reach deep inside yourself and be your very best.\"</p> </li> <li> <p>\"Hope is the most powerful force in the universe. With hope you can inspire nations to greatness. With hope you can raise up the downtrodden. With hope you can ease the pain of unbearable loss. Sometimes all it takes is one person to make a difference. We will all find ourselves neck deep in mud someday. That is the time to sing loudly, to smile broadly, to lift up those around you and give them hope that tomorrow will be a better day.\"</p> </li> <li> <p>\"Life is full of difficult times. But someone out there always has it worse than you do. If you fill your days with pity, sorrowful for the way you have been treated, bemoaning your lot in life, blaming your circumstances on someone or something else, then life will be long and hard. If, on the other hand, you refuse to give up on your dreams, stand tall and strong against the odds\u2014then life will be what you make of it\u2014 and you can make it great. Never, ever, ring the bell!\"</p> </li> <li> <p>\"Start each day with a task completed. Find someone to help you through life. Respect everyone. Know that life is not fair and that you will fail often, but if you take some risks, step up when the times are toughest, face down the bullies, lift up the downtrodden, and never, ever give up\u2026 if you do these things, then the next generation and the generations that follow will live in a world far better than the one we have today. And what started here will indeed have changed the world,\"</p> </li> <li> <p>\"The desire for more positive experience is itself a negative experience. And, paradoxically, the acceptance of one\u2019s negative experience is itself a positive experience.\"</p> </li> <li> <p>\"Because here\u2019s another sneaky little truth about life. You can\u2019t be an important and life-changing presence for some people without also being a joke and an embarrassment to others. You just can\u2019t. Because there\u2019s no such thing as a lack of adversity. It doesn\u2019t exist. The old saying goes that no matter where you go, there you are. Well, the same is true for adversity and failure. No matter where you go, there\u2019s a five-hundred-pound load of shit waiting for you. And that\u2019s perfectly fine. The point isn\u2019t to get away from the shit. The point is to find the shit you enjoy dealing with.\"</p> </li> <li> <p>\"I once heard an artist say that when a person has no problems, the mind automatically finds a way to invent some. I think what most people\u2014especially educated, pampered middle-class white people\u2014consider \"life problems\" are really just side effects of not having anything more important to worry about. It then follows that finding something important and meaningful in your life is perhaps the most productive use of your time and energy. Because if you don\u2019t find that meaningful something, your fucks will be given to meaningless and frivolous\"</p> </li> <li> <p>\"A cheerful poverty, he says, is an honourable state. But if it is cheerful it is not poverty at all. It is not the man who has too little who is poor, but the one who hankers after more. What difference does it make how much there is laid away in a mans safe or in his barns, how many head of stock he grazes or how much capital he puts out at interest, if he is always after what is anothers and only counts what he has yet to get, never what he has already. You ask what is the proper limit to a persons wealth? First, having what is essential, and second, having what is enough.\"</p> </li> <li> <p>\"This prompts me to memorize something which I came across in Pomponius. Some men have shrunk so far into dark corners that objects in bright daylight seem quite blurred to them. A balanced combination of the two attitudes is what we want; the active man should be able to take things easily, while the man who is inclined towards repose should be capable of action. Ask nature: she will tell you that she made both day and night \"</p> </li> <li> <p>\"To me, says Democritus, a single man is a crowd, and a crowd is a single man. Equally good is the answer given by the person, whoever it was (his identity is uncertain), who when asked what was the object of all the \"</p> </li> <li> <p>\"Conquer the world or die\"</p> </li> <li> <p>\"Pain is but a passing thought\"</p> </li> <li> <p>\"In front of my brothers, my heart still remains unchanged. I\u2019m still the original me, no matter what happens.\"</p> </li> <li> <p>\"If you ever meet a girl who can move your heart, do not miss the chance, you must take the initiative.\"</p> </li> <li> <p>\"The past is now past, and the future is too far away. Only the present matters.\"</p> </li> <li> <p>\"Each predicament appears incomparably complex but yet, doesnt simplicity lies on the other side of complexity?\"</p> </li> <li> <p>\"Now the internet is not so good, because smart people go to the internet. You should go to the off ground\"</p> </li> <li> <p>\"Money follows people. People follow dreams\"</p> </li> <li> <p>\"The sad truth is that the truth is sad.\"</p> </li> <li> <p>\"The key to life is to be unborable\"</p> </li> <li> <p>\"Ideas are like knowing you should do push ups\"</p> </li> <li> <p>\"People run themselves into the ground when they start wavering from what they are... When you do the things you don\u2019t want to do because you simply graduated to the next spot... you LOSE!\"</p> </li> <li> <p>\"Inspiration exists but it has to find you working\"</p> </li> <li> <p>\"When someone dies they are regarded with more respect and social standing because they are no longer competing with us\"</p> </li> <li> <p>\"You cant read about doing pushups\"</p> </li> <li> <p>\"If you are good at what you do, its not about time.\"</p> </li> <li> <p>\"Think globally, act locally\"</p> </li> <li> <p>\"Its only ever the moment that is guiding you.\"</p> </li> <li> <p>\"Always know your action. So if you come in the morning confident or on your ass, you know what to do.\"</p> </li> <li> <p>\"Listening is good. obeying is not always the best.\"</p> </li> <li> <p>\"Where does language end and vision begin\"</p> </li> <li> <p>\"Deep learning is like the geometric mean of biology and physics.\" (TL: Bruh.)</p> </li> <li> <p>\"What is overfitting? When your model is somehow very sensitive to the small random unimportant stuff in your dataset. Think of it like the dataset and the model having degrees of freedom. If both are similar, then the model will not be able to ignore even minor changes in the data. But if the model is much larger than the data itself then it would be able to ignore the tiny randomness\"</p> </li> <li> <p>\"Saying you don't need privacy because you have nothing to hide is like saying you don't need freedom of speech because you have nothing to say.\"</p> </li> <li> <p>\"Weak existences would feel tiny when they faced the vast world and the passage of time, which was infinite.  But there would always be people who did not wish to remain tiny.  They would search.  What would the future be like 10,000 years from now? What about a 100,000 years? 10,000,000 years? Did this world have an end to it?  What was at the end of the continent? Was there another piece of land across the ocean? Was there a sky above the skies?  These people would want to slowly control their own destiny. By conquering nature in the pursuit of balance, they would exist on the same level as the world!\"</p> </li> <li> <p>\"This made Yi Yun even more diligent. Life could not repeat itself like the rising and setting of the sun. If one did not grab every moment, one would waste their talent and potential. It would be a great regret.\"</p> </li> <li> <p>\"It was like in his previous life. The richest people in the poor mountainous regions, where vehicles could not even pass through, would probably not amount to a hundredth of the wealth of a commoner in Shanghai.\"</p> </li> <li> <p>\"Everyone had to pay the price of their choices.\"</p> </li> <li> <p>\"Lightning was a destructive power, but it was a power that created as well. It was rumored that life was first born when lightning struck the ocean in the past.\"</p> </li> <li> <p>\"In fact, human nature was arguably evil. Some people were inclined to kill people of their own species. After gaining pleasure from doing so, they would then plunder the riches of others for themselves. Some people killed thousands to make ghost summoning banners, seizing young ladies as cultivating slaves, and even doing despicable acts towards young girls\u2026 Many a time, when these people released their deviant inhibitions, they would resort to anything while acting fanatically.  However\u2026due to the prohibitions of morality, and the laws and rules established by large factions in this world, many people could only strongly suppress the evil in their hearts.  But this suppression would be lifted without any worries when it was another species in question.  As they were not of the same species, they could vent the evil in their hearts. They would not be considered cruel and bloodthirsty while engaging in those atrocities. On the contrary, they could be proud of it. For example, they would not be criticized if they infiltrated the Desolate race\u2019s grounds, plundering large numbers of Desolate race young ladies as cultivation slaves.  From a certain point of view, the conflict between the Human and Desolate race was not completely engineered by the Blood Moon. It was a result of the natural instincts between two intelligent lifeforms, wishing to vent the corrupt nature in their hearts.\"</p> </li> <li> <p>\"Life must be understood backward. But it must be lived forward.\"</p> </li> <li> <p>\"Maybe it\u2019s just in his nature. Since the start of history, all those that were successful would choose not to suppress their heart. They dared to love, and dared to hate, and by yielding to their emotions, their dao-hearts became clear and tranquil, with no knots obstructing their progress. Even if the entire world was their enemy, so what of it? They would just take it in their stride. The Azure Emperor back then had the same personality as him, one that led him to soar brilliantly in the skies. But sadly, the hatred he garnered eventually became the cause of his downfall. The large-eyed elder spoke in a low voice. There were two kinds of people that would enjoy great success in life. The first kind, were people like Qin Wentian and the Azure Emperor, displaying their talent, not suppressing their heart, doing as they wished wherever and whenever they wanted it. The second kind, were those that could tolerate and endure what shouldn\u2019t be tolerated and endured, lying to the world and even to themselves, appearing like a perfect gentleman, yet had the heart of a devil. Such a person, had a heart as deep as night, with an extremely sinister nature. The root of it all, was still one\u2019s nature. If one\u2019s heart was strong enough, nothing could cause it to waver.\"</p> </li> <li> <p>\"Cultivation is a path that solely belongs to oneself. Everyone takes a different path, has different levels of talent, different experiences and naturally different comprehensions. When you cultivate in the future, do not ever blindly follow the path of others because you feel that he is strong. What you have to do is to find the path most suited to you. At most, you can take another\u2019s comprehensions as a slight reference, but do not let it direct your path. Comprehend that which you\u2019d like, and only then will the path you tread be the most suited for yourself.\" Qin Wentian smiled as he continued,</p> </li> <li> <p>\"Cultivation has to follow one\u2019s heart. If your heart isn\u2019t even sure of the path you want, how can your cultivation be smooth? This is my understanding, so listen well. I won\u2019t explain in detail my comprehensions to you, imposing onto you a concept that might do more harm than good.\"</p> </li> <li> <p>\"If you are afraid of the sword, you will die by it,\"</p> </li> <li> <p>\"Do less. Do better. Know why.\"</p> </li> <li> <p>\"My dear fellow, who will let you? That's  not the point. The point is, who will stop me?\"</p> </li> <li> <p>\"Innovate where you can. Where you can\u2019t, use the industry standards.\"</p> </li> <li> <p>\"Oh, cherry tree, begrudge not thy blossoms as they are deflowered in the spring, for come winter, even thy sturdiest wood shall wither.\"</p> </li> <li> <p>\"My dear young cousin, if there's  one thing I've learned over the eons, it's that you can't give up on your family, no matter how tempting they make it. It doesn't matter if they hate you, or embarrass you, or simply don't appreciate your genius for inventing the Internet\u2014\"</p> </li> <li> <p>\"You see, in times of trouble, even gods can lose faith. They start putting their trust in the wrong things. They stop looking at the big picture and start being selfish. But I\u2019m the goddess of marriage, you see. I\u2019m used to perseverance. You have to rise above the squabbling and chaos, and keep believing. You have to always keep your goals in mind.\"</p> </li> <li> <p>\"You\u2019re not so different from me, demigod. Even when I\u2019m out of the water, the water is within me. It is my life source.\"</p> </li> <li> <p>\"Oh, Hades if I know. But remember, boy, that a kind act can sometimes be as powerful as a sword. As a mortal, I was never a great fighter or athlete or poet. I only made wine. The people in my village laughed at me. They said I would never amount to anything. Look at me now. Sometimes small things can become very large indeed.\"</p> </li> <li> <p>\"Men hate passion, any great passion. Henry Cameron made a mistake: he loved his work. That was why he fought. That was why he lost.\"</p> </li> </ul> <p>Not all powers are spectacular.\" Hestia looked at me. \"Sometimes the hardest power to master is the power of yielding. Do you believe me?\"</p> <ul> <li>\"You love your work. God help you, you love it! And that's  the curse. That's the brand on your forehead for all of them to see. You love it, and they know it, and they know they have you. Do you ever look at the people in the street? Aren't you afraid of them? I am. They move past you and they wear hats and they carry bundles. But that's  not the substance of them. The substance of them is hatred for any man who loves his work. That's  the only kind they fear. I don't know why. You're opening yourself up, Roark, for each and every one of them\"</li> <li> <p>\"No! I don't want to speak of that! But I'm going to. I want you to hear. I want you to know what's  in store for you. There will be days when you'll look at your hands and you'll want to take something and smash every bone in them, because they'll be taunting you with what they could do, if you found a chance for them to do it, and you can't find that chance, and you can't bear your living body because it has failed those hands somewhere. There will be days when a bus driver will snap at you as you enter a bus, and he'll be only asking for a dime, but that won't be what you'll hear; you'll hear that you're nothing, that he's  laughing at you, that it's written on your forehead, that thing they hate you for. There will be days when you'll stand in the corner of a hall and listen to a creature on a platform talking about buildings, about that work which you love, and the things he'll say will make you wait for somebody to rise and crack him open between two thumbnails; and then you'll hear the people applauding him, and you'll want to scream, because you won't know whether they're real or you are, whether you're in a room full of gored skulls, or whether someone has just emptied your own head, and you'll say nothing, because the sounds you could make--they're not a language in that room any longer; but if you'd want to speak, you won't anyway, because you'll be brushed aside, you who have nothing to tell them about buildings! Is that what you want?  Roark sat still, the shadows sharp on his face, a black wedge on a sunken cheek, a long triangle of black cutting across his chin, his eyes on Cameron. \"Not enough?\" asked Cameron. \"All right. Then, one day, you'll see on a piece of paper before you a building that will make you want to kneel; you won't believe that you've done it, but you will have done it; then you'll think that the earth is beautiful and the air smells of spring and you love your fellow men, because there is no evil in the world. And you'll set out from your house with this drawing, to have it erected, because you won't have any doubt that it will be erected by the first man to see it. But you won't get very far from your house. Because you'll be stopped at the door by the man who's  come to turn off the gas. You hadn't had much food, because you saved money to finish your drawing, but still you had to cook something and you hadn't paid for it....All right, that's  nothing, you can laugh at that. But finally you'll get into a man's  office with your drawing, and you'll curse yourself for taking so much space of his air with your body, and you'll try to squeeze yourself out of his sight, so that he won't see you, but only hear your voice begging him, pleading, your voice licking his knees; you'll loathe yourself for it, but you won't care, if only he'd let you put up that building, you won't care, you'll want to rip your insides open to show him, because if he saw what's  there he'd have to let you put it up. But he'll say that he's  very sorry, only the commission has just been given to Guy Francon. And you'll go home, and do you know what you'll do there? You'll cry. You'll cry like a woman, like a drunkard, like an animal. That's  your future, Howard Roark. Now, do you want it?\"</p> </li> <li> <p>\"A child. New life, like Endora. A child's  mission is to grow. To grow? I thought it was to see the world. Love. For Oceanids, this is to meld together as one. There will be no division then. That is why Oceanids need no learning or thoughts of their own. All that is needed is love. It seems that Oceanids cannot love others, for others will only drown in the embrace of pure waters. So they disguise themselves as the dreams of young children, and withdraw from the lives of all other people. Love, that is our destiny. Every day, a child takes a stumbling step forward. Every day, a stream flows into the sea. I have a whole world left to see.\"</p> </li> <li> <p>\" The axe forgets but the tree remembers\"</p> </li> <li> <p>\"If you make a promise, you keep it, if you make a mistake, you apologize. And if you give someone a dream, you defend it to the end.\"</p> </li> <li> <p>\"What does freedom really mean, when demanded of you by a god?\"</p> </li> <li> <p>\"What you lacked was not wind. It's  courage that's  allowed you to become the first flying birds of this world.\"</p> </li> <li> <p>\"In the perpetual meantime of a sheltered eternity, most are content to live, and not to dream.But in the hidden corners where the gods' gaze does not fall, there are those who dream of dreaming.\"</p> </li> <li> <p>\"My greatest wish? It has always been to roam free and experience the whole world. Now I would add that wherever I go, it simply must be with you! Each day with you is an adventure, and where adventurers go, storytellers must follow!\"</p> </li> <li> <p>\"The rules of war are woven in the womb: the victors shall burn bright, while the losers must turn to ash\"</p> </li> <li> <p>\"The God of Wisdom's  enemy is wisdom itself, and the oasis of knowledge is a mirage in the desert of ignorance.\"</p> </li> <li> <p>\"The war has already begun. It is just a continuation of past battles.The gods goad us on with the promise of their seven treasures. Rewards for the worthy. The doorway to divinity.Yet buried in the depths of this world lies smoldering remains, a warning to those that dare trespass.\"That throne in the sky is not reserved for you\"But mortal arrogation never stops.None will escape the flames.See for yourself.\"</p> </li> <li> <p>\"The world is full of lost ballads just waiting to be rediscovered\"</p> </li> <li> <p>\"The wind permeates all, cleansing both mind and body\"</p> </li> <li> <p>\"All things are impermanent, and to exist is to suffer. We yakshas have no need of sympathy or tears.\"</p> </li> <li> <p>\" Life is a precious thing, yes... But when I think of the burden that the Conqueror of Demons must bear... sigh death seems to me to have been the easy way out. A selfish indulgence, even.\"</p> </li> <li> <p>\"Rex Lapis once said: \"Ones who break their contracts shall suffer the Wrath of the Rock.\"</p> </li> <li> <p>\" When people see the object of their dreams, how many are really able to control their desire and follow the contract...?\"</p> </li> <li> <p>\" The story continues that some among her people realized at last that this gentle, kind, but weak god could never protect anyone in wartime. The Archon War was cruel in the extreme. Instead of consigning her to the agony of defeat, they thought, perhaps it would be better to give her a quick release.\"</p> </li> <li> <p>\" Faith in a god who has already passed will do you no good.\"</p> </li> <li> <p>\" History records, but history may be changed. This incident proved that. Time is a mighty force, and histories twist in its flow... I need to find a better way of recording history in order to engrave its truth. Stone carvings were one such ancient method. But unchanging stone, immovable earth, even one such as myself... Someday, we may all disappear.\"</p> </li> <li> <p>\"Kun Jun: Then again, the memories of ore can shift with the passage of time and the changing of the environment. Is there a pattern to it? Hmm, difficult to say... I feel that ore memories tend to be from the recent past. So there's never any ancient memories? Rocks endure, but as eons pass their memories are erased. Those memories that survive are rooted in powerful emotion or thought.\"</p> </li> <li> <p>\" The memories of rocks do not last long. Those memories that survive are rooted in powerful emotion. But as time passes, so these memories fade into obscurity. Erosion is the world's  greatest destroyer of memories. Eragon: Erosion...? Kun Jun: Erosion ground Azhdaha's  consciousness into oblivion. Slowly, he forgot the face of his old friend, and his memories of defending Liyue Harbor disintegrated. Kun Jun: Azhdaha, now incomplete, became irascible... aggressive.\"</p> </li> <li> <p>\" Curious how swords and daggers are blind, yet their creators see so much. Perhaps empathy is mankind's  proudest achievement after all?\"</p> </li> <li> <p>\" A heart of stone is a heart nonetheless\"</p> </li> <li> <p>\" When the door opens, it is time to leave\"</p> </li> <li> <p>\"Zhongli : People abandon and surrender the things they love to pursue the right path. Perhaps this is the erosion imposed on me by the natural order of this world. Zhongli: But I was a god of mankind. My identity may change, but my eyes will bear witness to the history of humanity.\"</p> </li> <li> <p>\"You make a pinkie promise, you keep it all your life. You break a pinkie promise, I throw you on the ice. The cold will kill the pinkie that once betrayed your friend, the frost will freeze your tongue off so you never lie again.\"</p> </li> <li> <p>\" Childe: Anyway, childhood dreams are all too easily shattered. Even if you just leave them be, they all fall to pieces all by themselves. Childe: So someone has to protect them, right? Childe: If you make a promise, you keep it, if you make a mistake, you apologize... Childe: And if you give someone a dream, you defend it to the end... Childe: That is what family is all about, isn't it?\"</p> </li> <li> <p>\" Albedo: I'm willing to pour all my energy into research, and yet specimens are finite. As the unknown transitions into the realm of scientific understanding, the feeling of enlightenment is lost. Albedo: All these things that start out as objects of fascination end up possessing the prosaic mundanity of a Sunsettia or a Sweet Flower. They cease to be noteworthy. Paimon: Oh... So that's  why you wanted to paint those hilichurls? Because you got to see something new and interesting in the differences between them? Albedo: Precisely. To quote my exact words from earlier, these creatures are, for the most part, \"quite boring... not worth closer inspection.\" There is precious little about them that serves to pique my curiosity now.\"</p> </li> <li> <p>\" Albedo: sigh It would seem that that's  as far as we go. A transient bloom of incomparable beauty... Life's  proudest achievement. Pamon: Paimon thought, with all our efforts, unght have bloomed forever. And it  didn't even have any fruit... Albedo: Life is a manifold tapestry of free entities, its value shouldn't derive from how long it stays with us. Even a momentary burst is precious. Albedo: A short life can be well-lived. A life lived efficiently, lived to perfection, is\"</p> </li> <li> <p>\" Venti: Warriors wear their battle scars with pride, and shields are no different. Venti: Surely, an intact shield is one that has shied away from the battlefield. Is not the broken and splintered shield the one that has fought in countless wars and lived to tell the tale? Venti: Though the soldier's  body be tired and torn, still they fight till the very end, till they have no blood left to bleed. Such magnificent strength of will... is that not the true meaning of honor?\"</p> </li> <li> <p>\"You\u2019re not an artist unless you want to quit atleast once\"</p> </li> <li> <p>\"According to Su Li's  words, this was a very stupid sword style, so only the stupidest of people could learn it. This sword style was also the most natural, because there was simply no way it could be used to face one's  enemies. It could only be used for defense.  It was called the Stupid Sword because to learn this sword, there was no other method but practice through repetition, to practice until the seas dried up and stones rotted away, to practice until the stars turned and the Big Dipper moved, to practice for as long as the heavens existed and the earth persisted, such that it should be impossible for someone to ever confirm that they had learned it.  When Chen Changsheng heard these words, he had completely put the idea of learning this sword out of his mind. Only when Su Li said that this Stupid Sword could be considered the world's most powerful defensive sword style did he change his mind. Once the sword had left Mount Li, Su Li's  attainments on the path of the sword had become even more exceptional, and his experience was broad and deep. His judgment would naturally not be wrong.  But when Chen Changsheng began to properly learn this Stupid Sword, he began to regret his decision.  Because not even Su Li had successfully learned this sword. In all of Mount Li, even in all of the continent, there was not one person that had successfully learned this sword. Not even along the course of the interminable river of history could one find a person that had learned this sword. To describe it another way, this sword style existed only in books, existed only in some imaginary path of the sword. It had never appeared in reality.  Su Li had said that the reason he had never been able to learn this sword was that he was just too much of a genius. His sword was free and unburdened, unwilling to accept such constraints. But there was truly a possibility that Chen Changsheng could learn this sword. This was because\u2026in certain aspects, Chen Changsheng really was very stupid.\"</p> </li> <li> <p>\"Your biggest supporter is a stranger. Your biggest hater is someone you know.\"</p> </li> <li> <p>\"Somewhere in another universe, someone is writing the life you lived, are living, have yet to live, or will never live.\"</p> </li> <li> <p>\"Each of these lives is the right one, every path is the right path, everything could have been anything else, and it would have just as much meaning.\"</p> </li> <li> <p>\"If our ancestors hadn\u2019t had this flaming urge for a feeling of importance, civilization would have been impossible. Without it, we should have been just about like animals\"</p> </li> <li> <p>\"I was here. I explored. I saw this. Remember me.\"</p> </li> <li> <p>\" You only get a diversity of problems solved if you have a diversity of people solving them\"</p> </li> <li> <p>\"Once upon a time, I, Zhuangzi, dreamt was a butterfly, fluttering hither and thither, to all intents and purposes a butterfly. I was conscious only of my happiness as a butterfly, unaware that I was Zhuangzi. Soon awakened and there was, veritably myself again. Now do not know whether was then a man dreaming was a butterfly, or whether am now a butterfly, dreaming am a man. Between a man anda butterfly there is necessarily a distinction. The transition is called the transformation of material thing.\"</p> </li> <li> <p>\"But he did say that many people who go insane find in insanity a feeling of importance that they were unable to achieve in the world of reality.\"</p> </li> <li> <p>\"Once I did bad and that I heard ever/Twice I did good, but that I heard never.\"</p> </li> <li> <p>\"We are born from human boxes and live in big box houses and are buried in boxes when we die. Why are you crying?\"</p> </li> <li> <p>\"Thousands of salespeople are pounding the pavements today, tired, discouraged and underpaid. Why? Because they are always thinking only of what they want. They don\u2019t realize that neither you nor I want to buy anything. If we did, we would go out and buy it. But both of us are eternally interested in solving our problems. And if salespeople can show us how their services or merchandise will help us solve our problems, they won\u2019t need to sell us. We\u2019ll buy. And customers like to feel that they are buying\u2014not being sold.\"</p> </li> <li> <p>\"Self-expression is the dominant necessity of human nature.\"</p> </li> <li> <p>\"First, arouse in the other person an eager want. He who can do this has the whole world with him. He who cannot walks a lonely way.\"</p> </li> <li> <p>\"All of us, be we workers in a factory, clerks in an office or even a king upon his throne\u2014all of us like people who admire us.\"</p> </li> <li> <p>\"Remember that a person\u2019s name is to that person the sweetest and most important sound in any language\"</p> </li> <li> <p>\"Many persons call a doctor when all they want is an audience.\"</p> </li> <li> <p>\"This lady, left all alone in a big house with her paisley shawls, her French antiques, and her memories, was starving for a little recognition. She had once been young and beautiful and sought after. She had once built a house warm with love and had collected things from all over Europe to make it beautiful. Now, in the isolated loneliness of old age, she craved a little human warmth, a little genuine appreciation\u2014and no one gave it to her. And when she found it, like a spring in the desert, her gratitude couldn\u2019t adequately express itself with anything less than the gift of her cherished Packard.\"</p> </li> <li> <p>\"Talk to people about themselves,\" said Disraeli, one of the shrewdest men who ever ruled the British Empire, and they will listen for hours.\"</p> </li> <li> <p>\"Nine times out of ten, an argument ends with each of the contestants more firmly convinced than ever that he is absolutely right.\"</p> </li> <li> <p>\"A man convinced against his will Is of the same opinion still.\"</p> </li> <li> <p>\"Few people are logical. Most of us are prejudiced and biased. Most of us are blighted with preconceived notions, with jealousy, suspicion, fear, envy and pride. And most citizens don\u2019t want to change their minds about their religion or their haircut or communism or their favorite movie star.\"</p> </li> <li> <p>\"It\u2019s one of my theories that when people give you advice, they\u2019re really just talking to themselves in the past.\"</p> </li> <li> <p>\"Stop being patient and start asking yourself, how do accomplish my 10 year plan in months? You'll probably fail, but you'll be a lot further along than the person who simply thought it would take 10 years.\"</p> </li> <li> <p>\"The great thing about dead or remote masters is that they can\u2019t refuse you as an apprentice. You can learn whatever you want from them. They left their lesson plans in their work.\"</p> </li> <li> <p>\"Nothing is more important than an unread library\"</p> </li> <li> <p>\"It is our failure to become our perceived ideal that ultimately defines us and makes us unique</p> </li> <li> <p>\"All fiction, in fact, is fan fiction.\"</p> </li> <li> <p>\"Take time to mess around. Get lost. Wander. You never know where it\u2019s going to lead you.\"</p> </li> <li> <p>\"what unifies your work is the fact that you made it. One day, you\u2019ll look back and it will all make sense.\"</p> </li> <li> <p>\"Distance and difference are the secret tonic of creativity. When we get home, home is still the same. But something in our mind has been changed, and that changes everything.\"</p> </li> <li> <p>\"The only mofos in my circle are people that I can learn from.\"</p> </li> <li> <p>\"Be regular and orderly in your life, so that you may be violent and original in your work.\"</p> </li> <li> <p>\"Work gets done in the time available.\"</p> </li> <li> <p>\"The way to get over creative block is to simply place some constraints on yourself.\"</p> </li> <li> <p>\"In the end, creativity isn\u2019t just the things we choose to put in, it\u2019s the things we choose to leave out.\"</p> </li> <li> <p>\"only once you give yourself permission to stop trying to do it all, to stop saying yes to everyone, can you make your highest contribution towards the things that really matter.\"</p> </li> <li> <p>\"Weniger aber besser. The English translation is: Less but better.\"</p> </li> <li> <p>\"For the first time\u2014literally\u2014substantial and rapidly growing numbers of people have choices. For the first time, they will have to manage themselves. And society is totally unprepared for it.\"</p> </li> <li> <p>\"I wish I\u2019d had the courage to live a life true to myself, not the life others expected of me.\"</p> </li> <li> <p>\"Sunk-cost bias: studies have found that we tend to value things we already own more highly than they are worth and thus that we find them more difficult to get rid of. If you\u2019re not quite there, ask the killer question: \"If I didn\u2019t already own this, how much would I spend to buy it?\" This usually does the trick.\"</p> </li> <li> <p>\"Nothing is more powerful than an idea whose time has come.\"</p> </li> <li> <p>\"What if we stopped celebrating being busy as a measurement of importance?\"</p> </li> <li> <p>\"When we surrender our ability to choose, something or someone else will step in to choose for us.\"</p> </li> <li> <p>\"The ability to choose cannot be taken away or even given away\u2014it can only be forgotten.\"</p> </li> <li> <p>\"My first act of free will shall be to believe in free will.\"</p> </li> <li> <p>\"You cannot overestimate the unimportance of practically everything.\"</p> </li> <li> <p>\"In every set of facts, something essential is hidden. And a good journalist knows that finding it involves exploring those pieces of information and figuring out the relationships between them\"</p> </li> <li> <p>\"By getting out there and fully exploring the problem, they were able to better clarify the question and in turn to focus on the essential details that ultimately allowed them to make the highest contribution to the problem.\"</p> </li> <li> <p>\"The breaking of so great a thing should make a greater crack.\"</p> </li> <li> <p>\"God was not a granter of wishes.\"</p> </li> <li> <p>\"So much had been denied me, I reasoned. Why should I deny myself?\"</p> </li> <li> <p>\"Being successful is waking in the morning and being in a good mood\"</p> </li> <li> <p>\"She didn\u2019t tell him that while coal and diamonds are both carbon, coal is too impure to be able, under whatever pressure, to become a diamond. According to science, you start off as coal and you end up as coal. Maybe that was the real-life lesson.\"</p> </li> <li> <p>\"Cheer up, love, it might never happen,\u2019 someone said. Nothing ever did, she thought to herself. That was the whole problem.\"</p> </li> <li> <p>\"It was a familiar feeling. This feeling of being incomplete in just about every sense. An unfinished jigsaw of a human. Incomplete living and incomplete dying.\"</p> </li> <li> <p>\"When I examine myself and my methods of thought, I come to the conclusion that the gift of fantasy has meant more to me than my talent for absorbing positive knowledge.\"</p> </li> <li> <p>\"The world has never complained about how busy it is. As I look deeper into myself to see why I am living such a busy life, I realize that, to a certain extent, I actually enjoy being busy.\"</p> </li> <li> <p>\"The world is experienced according to the state of one\u2019s mind.\"</p> </li> <li> <p>\"It\u2019s not the situation that is troubling us, but our perspective on it.\"</p> </li> <li> <p>\"Don\u2019t struggle to heal your wounds. Just pour time into your heart and wait.\"</p> </li> <li> <p>\"Do you not feel compassion for yourself as you struggle through life? You are so eager to help your friends, but you treat yourself so poorly.\"</p> </li> <li> <p>\"What did you do as a child that excited you? How can you re-create that today?\"</p> </li> <li> <p>\"If you think you are so tough you can do anything I have a challenge for you. If you really want to do something hard: say no to an opportunity so you can take a nap.\"</p> </li> <li> <p>\"Well, while there are clearly people who can survive on fewer hours of sleep, I\u2019ve found that most of them are just so used to being tired they have forgotten what it really feels like to be fully rested.\"</p> </li> <li> <p>\"The warrior and the artist live by the same code of necessity, which dictates that the battle must be fought anew every day.\"</p> </li> <li> <p>\"The working artist will not tolerate trouble in her life because she knows trouble prevents her from doing her work. The working artist banishes from her world all sources of trouble.\"</p> </li> <li> <p>\"The more scared we are of a work or calling, the more sure we can be that we have to do it.\"</p> </li> <li> <p>\"The opposite of love isn\u2019t hate; it\u2019s indifference.\"</p> </li> <li> <p>\"The part we create from can\u2019t be touched by anything our parents did, or society did. That part is unsullied, uncorrupted; soundproof, waterproof, and bulletproof. In fact, the more troubles we\u2019ve got, the better and richer that part becomes.\"</p> </li> <li> <p>\"In what should have been 20 minutes of work, I compulsively interrupted myself at least nine times. What\u2019s more, the cost of these interruptions goes way beyond the added amount of time to finish this damn thing.\"</p> </li> <li> <p>\"By last year, these interruptions had become compulsive. I didn\u2019t know how to not distract myself anymore and had to go to great lengths to prevent it from happening. It felt like I was living in some kind of digital hellscape, where the process of doing anything significant and important seemed not only fruitless but also attentionally impossible.\"</p> </li> <li> <p>\"Our bodies are designed in such a way that they need to be challenged and stressed to a certain degree, otherwise they become soft and weak, and the smallest endeavors\u2014walking up a flight of stairs, picking up a bag of groceries\u2014will begin to feel difficult or impossible. It turns out that these small, conscious efforts to stress our bodies are what keeps them healthy.\"</p> </li> <li> <p>\"Basically, the name of the game is quality over quantity. Because in a world with infinite information and opportunity, you don\u2019t grow by knowing or doing more, you grow by the ability to correctly focus on less.\"</p> </li> <li> <p>\"Freedom in the 21st century isn\u2019t about having more, it\u2019s about choosing your commitments to less.\"</p> </li> <li> <p>\"They say necessity is the mother of invention. Well, boredom is the father.\"</p> </li> <li> <p>\"This steady barrage of unexpected problems gives the player a sense that she lacks control over her own Life, when in fact, the purpose of Life is not to control what happens to you, but rather control and choose higher level reactions to what happens to you.\"</p> </li> <li> <p>\"The more often you use a Solution or Distraction, the easier it will be to use again, to the point where it will eventually become unconscious and automatic. Once a Solution or Distraction is unconscious and automatic, it becomes a Habit.\"</p> </li> <li> <p>\"The number one way people fuck up is by telling themselves that there\u2019s nothing they can do about the problems Life gives them.\"</p> </li> <li> <p>\"Complaining takes a problem and then prolongs it.\"</p> </li> <li> <p>\"Most recurring fantasies we have about ourselves are reactions to our insecurities.\"</p> </li> <li> <p>\"Fantasies are like any other Distraction \u2013 they are to be used sparingly and for nothing other than pure enjoyment. It\u2019s when they begin to sustain your sense of self-worth, your desire for importance in this world, that you will be hobbling yourself, and you will never Level Up again in Life.\"</p> </li> <li> <p>\"Without rationality, the universe would be a waste, in vain, and without purpose.\"</p> </li> <li> <p>\"Psychological research shows that people quickly adjust to their surroundings and are able to find joy in most situations, regardless of their culture, material wealth or political situation.\"</p> </li> <li> <p>\"But over the years I\u2019ve grown to see that \"feeling good\" in and of itself is often overrated.\"</p> </li> <li> <p>\"Again, not to be a stick in the mud, but those happy kids playing in sewage pipes and shitting in buckets will be lucky to make it to middle age without serious violence, addiction or health problems in their lives.\"</p> </li> <li> <p>\"You realize that there\u2019s something to be said to limiting oneself, not just geographically, but also emotionally. That there\u2019s a certain depth of experience and meaning that can only be achieved when one picks a single piece of creation and says, \"This is it. This is where I belong.\"</p> </li> <li> <p>\"Perpetual world travel literally gives you a whole world of experience. But it also takes another away.\"</p> </li> <li> <p>\"The vast majority of people don\u2019t care what you say or do the vast majority of the time. And this is liberating.\"</p> </li> <li> <p>\"But what you quickly notice is that the world moves on. And what may feel like a suicide-inducing embarrassment for you is usually but a mild novelty or smirk for everybody around you. Understanding this is healthy. And it\u2019s a lesson that\u2019s hard to learn sitting comfortably at home, and spending your life shuttling between the same three or four locations every day.\"</p> </li> <li> <p>\"unsavory friends\u2013they\u2019re then able to see how they actually\"an</p> </li> <li> <p>\"Because once you learn that the vast majority of the planet doesn\u2019t care who you are or what you\u2019re doing, you realize that there is no reason to not be who you want to be. There is no one to please. There is no one to impress. Most of the time, it\u2019s just you, yourself and the stories you invent in your mind.\"</p> </li> <li> <p>\"Because uncertainty breeds skepticism, it breeds openness, and it breeds non-judgment. Because uncertainty helps you to grow and evolve.\"</p> </li> <li> <p>\"And when you go long enough being uncertain of who you really are, what results is a form of subtle, long-term meditation\u2013a persistent and necessary acceptance of whatever is arising, because you don\u2019t actually know if it was the food that made you sick, and you don\u2019t actually know if you like Eastern European cultures anymore, and you don\u2019t really know how you feel about income inequality anymore, and you don\u2019t know if your career path is the best for you or not, and you don\u2019t really know if you miss your friends back home or if you just like the idea of missing your friends back home. And at some point, you just stop asking questions. And start listening. To the waves and the wind and the calls for love in all of the beautiful languages you will never understand. You just let it be. And keep moving.\"</p> </li> <li> <p>\"We tend to judge the immorality of addiction by the damage it causes to others. But Kant believed that, first, over-indulgence was fundamentally the act of being immoral to oneself. The harm it did to others was merely collateral damage. It was a failure to confront the reality of one\u2019s own mind and own consciousness, and this failure is akin to lying to oneself or cheating oneself out of precious life potential.\"</p> </li> <li> <p>\"Respect was also sacred within Kant\u2019s moral framework because Kant believed that all conscious creatures have a fundamental dignity that must be respected at all times, and by everyone. For Kant, consent was the act of demonstrating respect.\"</p> </li> <li> <p>\"Therefore, Kant argued, the only logical way to improve the world is through improving ourselves. This is because the only thing we can truly experience with any certainty is ourselves.\"</p> </li> <li> <p>\"He showed me that what you actually do doesn\u2019t matter as much as the purpose behind doing it. And until you find the right purpose, you haven\u2019t found much of anything at all.\"</p> </li> <li> <p>\"To develop character, a person must master their own actions and master themselves. And while few of us can accomplish that in a lifetime, Kant believed it\u2019s something we each have a duty to work towards.\"</p> </li> <li> <p>\"We didnt know we were making memories. we only knew we were having fun\"</p> </li> <li> <p>\"Don\u2019t oversaturate your life With art\"</p> </li> <li> <p>\"A wiseman speaks because he has something to say. A fool speaks because he has to say something.\"</p> </li> <li> <p>\"The key to creativity isnt in knowing all the solutions, its in asking the strongest questions.\"</p> </li> <li> <p>\"If you wish to be wealthy, learn to live like you're poor\"</p> </li> <li> <p>\"Beware of little expenses; a small leak will sink a great ship.\"</p> </li> <li> <p>\"No one can remember more than three points.\"</p> </li> <li> <p>\"Nothing in this world can take the place of persistence. Nothing is more common than unsuccessful men with talent. Persistence and determination alone are omnipotent\"</p> </li> <li> <p>\"You are absolutely not going to be gaga over each other every single day for the rest of your lives, and all this happily ever after\u2019 bullshit is just setting people up for failure. They go into relationships with these unrealistic expectations. Then, the instant they realize they aren\u2019t gaga\u2019 anymore, they think the relationship is broken and over, and they need to get out. No! There will be days, or weeks, or maybe even longer, when you aren\u2019t all mushy-gushy in-love. You\u2019re even going to wake up some morning and think,</p> </li> <li> <p>\"Ugh, you\u2019re still here\u2026.\" That\u2019s normal! And more importantly, sticking it out is totally worth it, because . . . in a day, or a week, or maybe even longer, you\u2019ll look at that person and a giant wave of love will inundate you, and you\u2019ll love them so much you think your heart can\u2019t possibly hold it all and is going to burst. Because a love that\u2019s alive is also constantly evolving. It expands and contracts and mellows and deepens. It\u2019s not going to be the way it used to be, or the way it will be, and it shouldn\u2019t be. I think if more couples understood that, they\u2019d be less inclined to panic and rush to break up or divorce.\"</p> </li> <li> <p>\"God gave man a brain and a penis and only enough blood to operate one at a time.\"</p> </li> <li> <p>\"Respect yourself and your wife. Never talk badly to or about her. If you don\u2019t respect your wife, you don\u2019t respect yourself. You chose her\u2014live up to that choice.\"</p> </li> <li> <p>\"There can be no secrets. Secrets divide you. Always.\"</p> </li> <li> <p>\"Don\u2019t ever give up who you are for the person you\u2019re with. It will only backfire and make you both miserable. Have the courage to be who you are, and most importantly, let your partner be who they are. Those are the two people who fell in love with each other in the first place.\"</p> </li> <li> <p>\"If you love your partner enough you will let them be who they are\u2014you don\u2019t own them, who they hang with, what they do or how they feel. Drives me nuts when I see women not let their husbands go out with the guys or are jealous of other women.\"</p> </li> <li> <p>\"One day many years from now, you will wake up and your spouse will be a different person\u2014make sure you fall in love with that person, too.\"</p> </li> <li> <p>\"The relationship is a living, breathing thing. Much like the body and muscles, it cannot get stronger without stress and challenge. You have to fight. You have to hash things out. Obstacles make the marriage.\"</p> </li> <li> <p>\"But there\u2019s no way on God\u2019s green earth this is her fault alone. There were times when I saw huge red flags. Instead of trying to figure out what in the world was wrong, I just plowed ahead. I\u2019d buy more flowers, or candy, or do more chores around the house. I was a \"good\" husband in every sense of the word. But what I wasn\u2019t doing was paying attention to the right things\u2026 And instead of saying something, I ignored all of the signals.\"</p> </li> <li> <p>\"When you end up being right about something\u2014shut up. You can be right and be quiet at the same time. Your partner will already know you\u2019re right and will feel loved knowing that you didn\u2019t wield it like a bastard sword.\"</p> </li> <li> <p>\"Everyone says that compromise is key, but that\u2019s not how my husband and I see it. It\u2019s more about seeking understanding. Compromise is bullshit, because it leaves both sides unsatisfied, losing little pieces of themselves in an effort to get along. On the other hand, refusing to compromise is just as much of a disaster, because you turn your partner into a competitor (\"I win, you lose\"). These are the wrong goals, because they\u2019re outcome-based rather than process-based. When your goal is to find out where your partner is coming from\u2014to truly understand on a deep level\u2014you can\u2019t help but be altered by the process. Conflict becomes much easier to navigate because you see . . . the context.\"</p> </li> <li> <p>\"You cant use possibility to justify a certainty. Base your decision on the action itself\"</p> </li> <li> <p>\"Who needs ethics when youve got a trust fund\"</p> </li> <li> <p>\"Ambition can be a valuable tool, but so can restraint\"</p> </li> <li> <p>\"You can\u2019t connect the dots looking forward,keep learning and never stop\"</p> </li> <li> <p>\"Death is the destination we all share, no one has ever escaped it. And that is as it should be because death is very likely the single best invention of life.\"</p> </li> <li> <p>\"Don\u00b4t change a thing, you\u00b4re perfect as you are, and my job is to help the world to recognise the perfection that I see\"</p> </li> <li> <p>\"Never believe a prediction that doesn\u2019t empower you\"</p> </li> <li> <p>\"The only disability is ones refusal to adapt\"</p> </li> <li> <p>\"When we feel like we're not enough, we chase external validation\"</p> </li> <li> <p>\"We tend to test others to reaffirm our worth\"</p> </li> <li> <p>\"There are no rules, only consequences\"</p> </li> <li> <p>\"The fact of death, the scarcity of time, is a catalyst for the discovery of meaning and beauty.\"</p> </li> <li> <p>\"The world breaks every one and afterward many are strong at the broken places.\"</p> </li> <li> <p>\"If humans really have no value,\" Keqing retorts, \"then why should we expect the gods to care about us so much?\"</p> </li> <li> <p>\"Women marry men hoping to change them, and they don't. Men marry women hoping they'll never change, and they do\"</p> </li> <li> <p>\"You don't stop believing in Santa. You just become Santa\"</p> </li> <li> <p>\"Sometimes it's  more economical to throw money at the problem.\"</p> </li> <li> <p>\"Buying something is never the solution to getting yourself to be more disciplined.\"</p> </li> <li> <p>\"Sorry I'm late, I got stuck on the path of life\"</p> </li> <li> <p>\"We're just suicidal people telling other suicidal people that it's  not the answer\"</p> </li> <li> <p>\"My parents aren't heroes, they're just like me\"</p> </li> <li> <p>\" What if we all looked the way we wanted? Our ideal weight became reality, our worries about money washed away. Your love life is exactly the way you pictured it. Do you think we'd all be happier? Or would we just find new things to hate?\"</p> </li> <li> <p>\"Most people are other people. Their thoughts are someone else's  opinions, their lives a mimicry, their passions a quotation.\"</p> </li> <li> <p>\"One fine day, it wil be your turn. You will leave homes, cities and countries to pursue grander ambitions. You will leave friends, lovers and possibilities for the chance to roam the world and make deeper connections. You will defy your fear of change, hold your head high and do what you once thought was unthinkable: walk away. And it will be scary. At first. But what I hope you'll find in the end is that in leaving, you don't just find love, adventure, and freedom. More than anything. you find you\"</p> </li> <li> <p>\" People often overestimate what they can accomplish in a year but they underestimate what they achieve in a decade.\"</p> </li> <li> <p>\" Most men live lives in quiet desperation\"</p> </li> <li> <p>\" If people try to bully me, I just ignore it. I\u2019ve got my own friends who I get on with. I don\u2019t have a social image\u2019 or think that everyone has to like me \u2013 it\u2019s not realistic.\"</p> </li> <li> <p>\"Since that day I've never been in the center of attention. You're the center of mine\".</p> </li> <li> <p>\"Don't flatter yourself darling. You think everybody's  interested in you, they're not. Your job is to make them happy.\"</p> </li> <li> <p>\"I've hada lot of worries in my life, most of which never happened.\"</p> </li> <li> <p>\"That's  the thing with time, isn't it? It's  not all the same. Some days - some years some decades - are empty. There is nothing to them. It's  just flat water. And then you come across a year, or even a day, or an afternoon. And it is everything. It is the whole thing.\"</p> </li> <li> <p>\"But sometimes, you forget your lines and the pain trickles through the cracks.\" Yep today accidentally started crying in front of my mother.</p> </li> <li> <p>\"After all, your life has not completely fallen apart yet, so why would anyone believe you're struggling.\"</p> </li> <li> <p>\"Best wife, best employee, best daughter, best student, keep everyone happy ...but you.\"</p> </li> <li> <p>\"This is your daily reminder to ask for what you need.\"</p> </li> <li> <p>\"External goals cannot fill internal voids\"</p> </li> <li> <p>\"Then I saw a meme [that said] 'if you died tomorrow, your job would be posted faster than your obituary\"</p> </li> <li> <p>\"I think my love with being alone stems from me knowing if l'm alone then no one is around to disturb me or alter any of my emotions. Everything is up to me. no one is there to misunderstand me, judge me, etc. It's  peaceful. A peace don't feel often with other humans\"</p> </li> <li> <p>\"Impossible is just an opinion.\"</p> </li> <li> <p>\"Fudge! I\u2019m gonna do it! I\u2019m gonna go all-out! I\u2019m gonna go so all-out that I\u2019ll terrify myself, let alone everyone else!\"</p> </li> <li> <p>\"After one try didn\u2019t work, he tried ten times. After ten tries didn\u2019t work, he tried a hundred times. After a hundred tries didn\u2019t work\u2026 he tried a thousand times.\"</p> </li> <li> <p>\"He was a generally optimistic person, an attitude he had intentionally fostered since a young age. There had been no other option. He had personally watched his parents die of illness. He remembered sitting with their corpses for days, weeping, refusing to believe that they were gone, even calling their names. Eventually, the corpses began to stink, and relatives came to bury them. Bai Xiaochun had been left in a daze, and at one point even took to talking to himself\u2026. If a child grew up in such a manner, his entire life would be one of darkness. So Bai Xiaochun replaced the crying with laughter. He began to think about the idea of living forever. He would never forget how his parents had died, and although he missed them, it only made him want to keep living. He was stubborn and mischievous, but not to an excessive degree. Many of the things he did were even accidents. Deep down, he was a good person. He feared death, and seemed weak on the outside, but when his friends were in danger, he would fight to the death to protect them. If he needed to, he could bellow in rage and risk his life on the field of battle.\"</p> </li> <li> <p>\"No. My dreams haven\u2019t changed. What Uncle Li said was right. The only things which truly belong to you are the things you get on your own. Even if it gets harder, I still won\u2019t give up!\"</p> </li> <li> <p>\"The best thing was not to fight the trend; blend in, and use the rules to your advantage!\"</p> </li> <li> <p>\"Possession without possession is the most wonderful possession. Emptiness without emptiness is the true emptiness\u2026.\"</p> </li> <li> <p>\"To live forever,\" he murmured, \"you don\u2019t just have to struggle against the heavens, you have to fight other people. It\u2019s a narrow, rugged path to walk, a path that most people give up on. Many people meet defeat, or end up losing their way\u2026.\"</p> </li> <li> <p>\"Remember, the easier something is to get, the less precious it will be in the end.\"</p> </li> <li> <p>\"Smiling broadly, he thought back to the old saying: even if you have a beautiful sedan chair to sit in, you still need others to lift you up.\"</p> </li> <li> <p>\"Now that\u2019s how grandmasters are supposed to act! The old expression says to turn weapons of war into gifts of jade and silk. It's  not easy to do, but he pulled it off perfectly. Really incredible!\"</p> </li> <li> <p>\"Xiaochun\u2026\" he said softly. \"You\u2019re right. As long as we\u2019re alive, there are endless possibilities. But just because we die doesn\u2019t mean that our hopes and dreams die with us!\"</p> </li> <li> <p>\"Bai Xiaochun had always thought of himself as somewhat of a nobody, and definitely not a hero. But as he proceeded through life, he had slowly come to acquire a sense of duty and responsibility.\"</p> </li> <li> <p>\"There is a force which exists in all people. In some, it can be abundant without limit. In others, it can be scarce to the extreme. It can propel some people to the point of shaking heaven and earth, and in other people, it can weaken them to the point of collapsing forever. It can give rise to endless determination, or it can remove it in an instant.\"</p> </li> <li> <p>\"Wisdom and intelligence\u2026 begin with imagination! \"Imagination can turn a rock into a weapon! \"Imagination can turn fire into a way to drive away darkness!</p> </li> <li> <p>\"Imagination can make gods to worship, and form them into totems\u2026. \"When you take imagination and combine it with action, you have the first sprout of wisdom and intelligence!\"</p> </li> <li> <p>\"One Will to create oceans. One Will to summon mulberry fields. One Will to slaughter countless devils. One Will to eradicate innumerable immortals\u2026. Only my Will\u2026 is Eternal.\"</p> </li> <li> <p>\"Innovation come from doings things differently, not doing things bigger.\"</p> </li> <li> <p>\"In an age of network tools, in other words, knowledge workers increasingly replace deep work with the shallow alternative\u2014constantly sending and receiving e-mail messages like human network routers, with frequent breaks for quick hits of distraction.\"</p> </li> <li> <p>\"Let your mind become a lens, thanks to the converging rays of attention; let your soul be all intent on whatever it is that is established in your mind as a dominant, wholly absorbing idea.\"</p> </li> <li> <p>\"Men of genius themselves were great only by bringing all their power to bear on the point on which they had decided to show their full measure.\"</p> </li> <li> <p>\"In a post-Enlightenment world we have tasked ourselves to identify what\u2019s meaningful and what\u2019s not, an exercise that can seem arbitrary and induce a creeping nihilism\"</p> </li> <li> <p>\"The task of a craftsman, they conclude, \"is not to generate meaning, but rather to cultivate in himself the skill of discerning the meanings that are already there.\"</p> </li> <li> <p>\"We who cut mere stones must always be envisioning cathedrals.\"</p> </li> <li> <p>\"You don\u2019t need a rarified job; you need instead a rarified approach to your work\"</p> </li> <li> <p>\"a moment can feel strangely flat if it exists solely in itself.\"</p> </li> <li> <p>\"We\u2019re social beings who can\u2019t ever completely ignore what other people think of us\"</p> </li> <li> <p>\"marriage or sexual possession was (and still is) largely anathema\"</p> </li> <li> <p>\"That it\u2019s the ability to choose: what pleasure is worthwhile, what pain is worthwhile, to pursue and love unconditionally, without judgment or shame.\"</p> </li> <li> <p>\"Seeing self-discipline in terms of pure willpower fails because beating ourselves up for not trying hard enough doesn\u2019t work. In fact, it backfires.\"</p> </li> <li> <p>\"The classic approach has the paradoxical effect of training us to feel bad about all the things that make us feel good. It basically seeks to teach us self-discipline through shaming us\u2014by making us hate ourselves for simply being who we are. And the idea is that once we are saddled with a sufficient amount of shame about all the things that give us pleasure, we\u2019ll be so self-loathing and terrified of our own desires that we\u2019ll just fall in line and do what we\u2019re told.\"</p> </li> <li> <p>\"It was a simple principle: just as one can only realize the strength of wine after one gets drunk, one can only know the value of life after one has died.\"</p> </li> <li> <p>\"And don't use zhenqi to control your emotions. If human emotions aren't given the proper outlet, even if your powers of zhenqi control are at their peak, you'll become a murderous monster.\"</p> </li> <li> <p>\"Why do you wish to see this world?\" Wu Zhu seemed to be pondering something,</p> </li> <li> <p>\"the place you are standing right now, isn\u2019t it part of this world?\"</p> </li> <li> <p>\"Since you only live once, the only way to make the most out of this unrepeatable game is to go around seeing different sights and meeting different people.\"</p> </li> <li> <p>\"Flowers fall once they appear, stones stand still a thousand years. But both must go just as they came, and floating clouds are just the same\u2026\"</p> </li> <li> <p>\"A bright moon on a wide river, a clear breeze among the hills.\"</p> </li> <li> <p>\"While this world may appear peaceful, if you don\u2019t steel yourself, you will always be at a disadvantage.\"</p> </li> <li> <p>\"he had always been somewhat chauvinistic, feeling that when it came to matters between men and women, it was always women who got the worst of it, and men who took advantage.\"</p> </li> <li> <p>\"Man's  dearest possession is life. It is given to him but once, and he must live it so as to feel no torturing regrets for wasted years, never know the burning shame of a mean and petty past; to live that, dying, he might say: I did everything I wished to, and even if I was unsuccessful, at least I tried\u2019.\"</p> </li> <li> <p>\"You once said that people have to be brave enough to seek happiness.\"</p> </li> <li> <p>\"one can\u2019t be sincere without simple living, one can\u2019t have high aspirations without a peaceful state of mind\"</p> </li> <li> <p>\"There were too many matters in this world that men's  stupid brains had made complicated.\"</p> </li> <li> <p>\"Su Ming vaguely remembered one of the scrolls saying that once the prey went through a long period of time switching between the state of anxiety and relaxation, its fatigue and suffering would increase exponentially. That sort of torture was enough to destroy one\u2019s soul.\"</p> </li> <li> <p>\"But we are members of the Berserker tribe. We cannot fear death, much less give up because the road ahead is too hard to walk.\" \"I know what your dreams are. You want to leave this place and travel to see the world. I fully support you!\"</p> </li> <li> <p>\"Su Ming, you must remember. There will always be people who are stronger and more powerful than you. You must never be arrogant\u2026\"</p> </li> <li> <p>\"He was certain of his words just like any young man who still believed in a bright future\u2026\"</p> </li> <li> <p>\"Either he would stay away from something, or he would finish what he had started.\"</p> </li> <li> <p>\"When you are fighting against someone, do not let your focus waver. Do not hesitate. If it is possible to kill your enemy with one strike within the shortest amount of time, do not wait till the last moment to do so.\"</p> </li> <li> <p>\"The oppression of the heavens is invisible. We can only endure it and while we endure it, we must learn to live with it happily\u2026 If we do not, are we to fight against heaven?\u2019\"</p> </li> <li> <p>\"Qi will only move when the mind moves. If the mind does not move, then Qi will also remain still!\"</p> </li> <li> <p>\"To him, there was no one who could be his opponent. The one that he wanted to compete against was himself!\"</p> </li> <li> <p>\"A person would experience great things and shortcomings in his life. He would also experience days of glory and days where he would stumble and fall. These were all things that Su Ming did not understand. The only thing he understood was that he had to do this.\"</p> </li> <li> <p>\"La Su, you are not alone in the sky. Do not be sad. Do not cry. Mama and papa will look at you from where we are\u2026 Every year, every day\u2026 we will look at you\u2026\" \"I will not cry. I will not be sad. I will not be lonely. I know that you are there, watching me\u2026 I am happy\u2026\"</p> </li> <li> <p>\"It seemed like there was no sign of life within those ruins, and they would eventually turn into a remnant of the passage of time. Perhaps the few remaining trees and plants would continue growing there and slowly turn the place into a part of the forest, making it difficult for people to come looking for their memories and the beautiful moments that had happened during their time here.\"</p> </li> <li> <p>\"Chances are hidden within danger\u2026\"</p> </li> <li> <p>\"Instead, it would be better to emphasize the benefits of the concoction towards himself and subtly reveal some of his own thoughts that would make the other party wonder.\"</p> </li> <li> <p>\"Whatever you brag about the most is what you lack the most. \"Whatever it is that you want others to know that you own the most of is what you want to possess the most.\"</p> </li> <li> <p>\"The more he wanted to obtain something, the more he would have to sacrifice. Only he could determine whether the sacrifice was equivalent to the reward and whether it was worth it, not anyone else.\"</p> </li> <li> <p>\"The mind is restless, Krishna, impetuous, self-willed, hard to train: to master the mind seems as difficult as to master the mighty winds.\"</p> </li> <li> <p>\"Our job is not to \"go with our gut\" or fixate on the first impression we form about an issue. No, we need to be strong enough to resist thinking that is too neat, too plausible, and therefore almost always wrong. Because if the leader can\u2019t take the time to develop a clear sense of the bigger picture, who will? If the leader isn\u2019t thinking through all the way to the end, who is?\"</p> </li> <li> <p>\"Keep strong, if possible. In any case, keep cool. Have unlimited patience. Never corner an opponent, and always assist him to save face. Put yourself in his shoes\u2014so as to see things through his eyes. Avoid self-righteousness like the devil\u2014nothing is so self-blinding.\"</p> </li> <li> <p>\"Ask yourself at every moment, Is this necessary?\u2019\"</p> </li> <li> <p>\"Before we can make deep changes in our lives, we have to look into our diet, our way of consuming. We have to live in such a way that we stop consuming the things that poison us and intoxicate us. Then we will have the strength to allow the best in us to arise, and we will no longer be victims of anger, of frustration.\"</p> </li> <li> <p>\"To become empty is to become one with the divine\u2014this is the Way.\"</p> </li> <li> <p>\"Childlikeness\u2019 has to be restored with long years of training in the art of self-forgetfulness. When this is attained, man thinks yet he does not think.\"</p> </li> <li> <p>\"Chop wood, carry water. Chop wood, carry water. Chop wood, carry water. Don\u2019t overanalyze. Do the work.\"</p> </li> <li> <p>\"Tao is in the emptiness. Emptiness is the fast of the mind.\"</p> </li> <li> <p>\"What\u2019s essential is invisible to the eye.\"</p> </li> <li> <p>\"Appearances are misleading. First impressions are too. We are disturbed and deceived by what\u2019s on the surface, by what others see. Then we make bad decisions, miss opportunities, or feel scared or upset. Particularly when we don\u2019t slow down and take the time to really look.\"</p> </li> <li> <p>\"If we take something to be the truth, we may cling to it so much that even if the truth comes and knocks at our door, we won't want to let it in. We have to be able to transcend our previous knowledge the way we climb up a ladder. If we are on the fifth rung and think that we are very high, there is no hope for us to step up to the sixth. We must learn to transcend our own views. Understanding, like water, can flow, can penetrate. Views, knowledge, and even w is d o m are solid, and can block the way of understanding.\"</p> </li> <li> <p>\"When a measure becomes a target, it ceases to be a good measure.\"</p> </li> <li> <p>\"Overemphasizing metrics removes our focus from long-term concerns such as our values, trust and reputation, and our impact on society and the environment, and myopically focuses on the short-term.\"</p> </li> <li> <p>\"To be clear, life is not a race. You can switch into tech and learn new skills at any age. The tech industry is deeply ageist, and the glorification of young founders is a harmful myth.\"</p> </li> <li> <p>\"When you keep quiet in order to keep the peace you start a war within yourself.\"</p> </li> <li> <p>\" The more you put something off the bigger it feels\"</p> </li> <li> <p>\"Nothing ever ends poetically. It ends and we turn it into poetry. All that blood was never once beautiful. It was just red.\"</p> </li> <li> <p>\" You never touch someone so lightly that it does not leave a Trace\"</p> </li> <li> <p>\"What is truth but a survivors story\"</p> </li> <li> <p>\"Lonliness if often the byproduct of a gifted mind\"</p> </li> <li> <p>\"We cant change what fate has in store for us, but we dont have to face it alone\"</p> </li> <li> <p>\"I've been up to my neck in work lately, and before I knew it, it was my birthday again. It was only then that I also realized that it's  been a long time since we last met up.  How have things been lately? You're always so busy with your travels, never stopping, not even for a moment. I suppose we're alike like that-always seizing the day.  It's  good to live to the fullest. Time waits for no one, but the fruits of our labor, the growth we experience... These are worthy harvests that will see us through in the days ahead. But of course, rest is also paramount. I have enclosed some flowers and plants that I usually make tea with. They dispel heatiness and help to relieve fatigue.  Take care of yourself out there. We'll catch up when you're back in Liyue.\"</p> </li> <li> <p>\" As kids, we're scared of bugs. Running out of candies. Crossing the street. Ghosts and ghouls under the bed. Being left alone in the dark, glowing wall stars falling apart. Being laughed at for not knowing how to tell time. Time, that passes so quickly, as our castles become dungeons. As adults, our fears change with us. Now people terrify us. The ghosts are on our bed and they look so breathtakingly beautiful we want to kiss them because we miss them. Running out of money worries us. Our biological clock worries us. Driving across the street in traffic worries us. The idea of our parents growing older keeps us up at night. Rent makes us anxious, but settling down horrifies us. Bad flatmates frighten us. Bad lovers haunt us. We're afraid of love, afraid of not finding love. Afraid of being with someone, afraid of ending up alone. Afraid of darkness, but now a different kind. So what if the bugs crawled up our legs? Or it got too spooky to look under the bed when the lights went out? We still went to sleep hugging teddy bears and replaying lullabies in our heads,  didn't we? Still went to school the next day, crossed the street, got candies again at the supermarket. Fought snow dragons, planted lilies of the valley. Made friends with fairies and baked flying cupcakes. Built homes in the planet of grief and the island in the clouds. We got by. We scraped along. Things won't run out. The opportunities will keep coming. New lovers will arrive, the next roommate will be kinder. And we'll survive all the ghouls, we'll show up at work, we'll put in the work - so rest your little heart because even the tiniest versions of us sailed past the ring of storms and made it through. We did it as children, and will as grown-ups too.\"</p> </li> <li> <p>\"What matters most is how well you walk through the fire.\"</p> </li> <li> <p>\"When did you get so comfortable living in someone else\u2019s shadow?\"</p> </li> <li> <p>\"When people look up to you, you don\u2019t get to be selfish.\"</p> </li> <li> <p>\"Imprisonment. What a curious principle. We confine the physical body, yet the mind is still free.\"</p> </li> <li> <p>\"Surely, we, the pioneers of science, can use it for good. We\u2019re the champions of discovery. Why fear it when we can master it?\"</p> </li> <li> <p>\"There\u2019s a monster inside all of us.\"</p> </li> <li> <p>\"If dangerous ideas didn\u2019t excite the imagination, we would never wander astray.\"</p> </li> <li> <p>\"When you\u2019re going to change the world, don\u2019t ask for permission.\"</p> </li> <li> <p>\"Nobody\u2019s ever believed in me. A poor cripple from the undercity. I was an outsider the moment I stepped foot in Piltover. I didn\u2019t have the benefits of a patron or a name. I simply believed in myself.\"</p> </li> <li> <p>\"You know, Powder, what makes you different makes you strong. Always remember that, okay?\"</p> </li> <li> <p>\"Loneliness is often the byproduct of a gifted mind.\"</p> </li> <li> <p>\"We can\u2019t change what fate has in store for us, but we don\u2019t have to face it alone.\"</p> </li> <li> <p>\"He fancies himself a fox among the wolves. But mark me, child, if you want to last in this world, you must learn to be both the fox and the wolf.\"</p> </li> <li> <p>\"I pretended to chase my own monsters away. I\u2019d say\u2026 No monster\u2019s gonna get you when I\u2019m here.\u2019 Then a real monster showed up. And I just ran away.\"</p> </li> <li> <p>\"It\u2019s not enough to give people what they need to surive, you have to give them what they need to live.\"</p> </li> <li> <p>\"Imperfection is the digital perfection\"</p> </li> <li> <p>\"Before the advent of machine-based agriculture, representative democracy, civil rights, antibiotics and aspirin, just making it through a long life without too much suffering counted as doing pretty well. Today, though, at least in prosperous societies, people want and expect (and can usually have) a good deal more. Living simply now strikes many people as simply boring.\"</p> </li> <li> <p>\"One should treasure those humdrum tasks that keep the body occupied but leave the mind and the heart unfettered\"</p> </li> <li> <p>\"Then, let us be considering knowledge like a river of water. If you are a piece of cloth how are you finding out more about this water if someone dips in your corner and then pulls it out again or if you are having yourself thrown in without resistance so that this water is flowing all through you around you and you are becoming soaking wet?\"</p> </li> <li> <p>\" You see the land is a book that you should be reading. Every small thing is having a story to tell. Trees leaves Moses and stones all have written on them things of wonderful interest\"</p> </li> <li> <p>\" An exceedingly common mistake in life is axiomatic in surfing, obvious to the point of not even needing to be said: You are nature\u2019s bitch. If she wants to give you opportunities, she will. If not, then tough cookies. No matter how great or amazing or sublime you are at what you do, if opportunities don\u2019t come, or if they peter out under you, then you\u2019re left alone to sink. And when the opportunities do come (and they eventually do), if you aren\u2019t primed and ready to take advantage, if you don\u2019t spring into action immediately and go for it, you\u2019ll be left on the sidelines. No guts, no glory\"</p> </li> <li> <p>\" 90% of your plans are going to fail no matter what you do. Get used to it.\"</p> </li> <li> <p>\" Terrify yourself. Use it as your ally. Give yourself no option but your dream.\"</p> </li> <li> <p>\" A devaluing of superficial pleasures and a greater appreciation for simple, authentic ones.  I don\u2019t really enjoy the presents at Christmas anymore, the fireworks at Fourth of July, or even the parties on New Year\u2019s Eve. I\u2019ve seen bigger parties, been to more beautiful places, and already own everything I\u2019ll ever want in this life.  But unlike before, I appreciate every day spent with those who mean a lot to me. A quiet beer on a patio. Watching a basketball game together. Going to a birthday party or a barbecue. These are the events I look forward to now and get excited about, days and weeks ahead of time\u2026 And that\u2019s probably the way it should be.\"</p> </li> <li> <p>\" I made no connection between their misfortune and my own career prospects. How could I? I was blinded by my trust in the American promise: if I got the right kind of job, then success and happiness would surely follow.  This promise, however, is mostly false. It\u2019s what the philosopher Plato called a</p> </li> <li> <p>\"noble lie\", a myth that justifies the fundamental arrangement of society. Plato taught that if people didn\u2019t believe the lie, then society would fall into chaos. And one particular noble lie gets us to believe in the value of hard work. We labor for our bosses\u2019 profit, but convince ourselves we\u2019re attaining the highest good. We hope the job will deliver on its promise, and hope gets us to put in the extra hours, take on the extra project and live with the lack of a raise or the recognition we need.\"</p> </li> <li> <p>\"You have to start romanticizing your life, you have to start thinking of yourself as the main character, cause if you don\u2019t, life will continue to pass you by, and all the little things that make it so beautiful will continue to go unnoticed, so take a second and look around.\"</p> </li> <li> <p>\"But I was smart so nobody was worried\"</p> </li> <li> <p>\"I worked harder than anyone I knew..So, my failure was clearly my fault.\"</p> </li> <li> <p>\" We're all aware that the main benefit of sleep is to refresh your brain, store memories, and all that jazz.  I also like to think of sleeping as a headspace reset.  When you go to sleep you're resetting your reality back to zero, but with the neurological changes of the past day intact. So new information you learned (neuronal pathways) is retained, memories are retained, habits are still ingrained, and your basic personality \"firmware\" is still there as it was before.  What is lost is the zeitgeist of your consciousness from the previous day. That amorphous spark behind your eyes; the ever-changing you. This what tints the events of the day, your experiences, and other semi-random thoughts or reactions will affect you.  For instance, you might wake up to the news of your local grocery store burning down. People were hurt; life is fragile. You might go through the day under that theme: life is fragile. Your reactions to things are different. You might feel more empathetic. When someone bumps into you, you might let it go. When someone is mean to you, you wonder if maybe they lost someone in the fire.  And when old dusty memories manifest you'll view them in an altered light. You might think of an old significant other, or when you got mad at your little brother. After the day is done you have time for introspection. You touch upon your old memories again looking for other ones that may have changed, like running your hands through your hair after a haircut; feeling for change.  By now it is too late to act upon your feelings. Tomorrow you'll call Steve and apologize for insulting him in front of his friends 3 years back. You'll stop by where Susan works and see how she's  doing. People can leave you at a moments notice and there is so much negativity in the world.  You wake up to a new day. All the information you acquired yesterday remains. You have memories of how you felt yesterday and you still feel like you. But now calling your brother just seems awkward and would Susan even remember you? Your spark reset. It booted up from the firmware, downloaded those updates from your neurons, and opened up to a fresh, blank desktop page ready for the new day.  We like to think of ourselves as stable, concrete entities. The reality may not be that simple, since it is obvious that we're constantly changing and growing. We know we're us by the memory of being in this body and remembering the changes that have occurred to it over time, but we don't often consider how much our mind changes with time. How much do you have in common with yourself from 10 years ago? 5 years? 4 weeks?  I think that when you sleep the you of today dies. The sum of your experiences are passed on, but that version of you from September 8th is gone forever. Because you have the same memories, the same neural pathways (habits, memories, personality traits) you are sure you're you - every piece of data you have declares it to be true.  That iteration of you, that version of you reading this, is gone tomorrow. The new iteration of you will remember these words and it won't know any better. The new spark won't know the difference. But we can see what was lost; that flavor, that theme of the previous day. The motivation, the sadness, the anger, the introspection won't make it through unless it is triggered again by a memory or experience that did make the transition (for better or worse).  I think this is why you get those bursts of life-changing motivation that are usually gone the next day, like sand through your fingers.  How do you make it stick? You need to bring triggers, links, or anchors through to tomorrow. You need to find what caused the feeling of motivation before and bring it back, otherwise it won't come back (and sometimes it never will). Sometimes it's  subtle too.  And in regards to motivation bursts... the other factor is that it is so easy to make plans the night before because you don't have to do them now. It makes you feel good to imagine it, but nothing actually happened yet because you  didn't actually have to do anything. It's  a masturbatory exercise. Why does it keep happening? Because it feels good to imagine improving yourself, of imagining the pride when you look in the mirror or ace the test. Anything that causes a good feeling with zero work can become addictive or keep entering your mind.\"</p> </li> <li> <p>\"What we work on is easy for us not for them, best to keep it that way and the process you have for the work should always be a mystery\"</p> </li> <li> <p>\"Life is too precious to wait for someone else to join your adventure. Just go.\"</p> </li> <li> <p>\"This taught me a principle, which is the more something is a scam, the more attractive the bait is. What do they mean, they have methods to sell for a better price so they can buy at a higher price\u2019 - I think that it\u2019s all nonsense. Their goals are most likely impure.\"</p> </li> <li> <p>\"I'm trying to entertain people and contribute a verse to the world. but the world is composed of millions of voices, all screaming at the same time about literally everything. saying ultimately nothing. that song doesnt need anymore verses\"</p> </li> <li> <p>\"Love was like an wild horse. It didn\u2019t listen to reason and went where it pleased. It was not constrained by ethics or by benefits to those involved. On that day, Su Chen learned an extremely important lesson. Love and rationality weren\u2019t compatible. Some people would even claim that those who hadn\u2019t suffered romantic loss were not well-rounded. Su Chen, having experienced his first romantic loss, had also become more shaped and well-rounded.\"</p> </li> <li> <p>\"Unfortunately, it\u2019s just too hard. It\u2019s a dream, impossible to realize,\" Wang Doushan said, shaking his head. Perhaps. But if it\u2019s impossible, why does that old man continue to do so? Why are there so many people dedicating themselves for this dream? \"This\u2026\u2026\" Wang Doushan couldn\u2019t find the words. Su Chen answered his own question. \"Because there are always people in this world who will continue to strive even if they know it\u2019s impossible. For the human race, these people are unafraid of hardships, and they dedicate themselves without any regrets.\"</p> </li> <li> <p>\"Humans were usually like this. As long as there was some form of relationship, they would feel that using someone was expected and even justified. If they were still charged for it, naturally that person was greedy and lacked camaraderie.\"</p> </li> <li> <p>\"Mountains don\u2019t know the months, and the cold doesn\u2019t know the years. Time always flies when a person is undisturbed. Very quickly, half a month passed.\"</p> </li> <li> <p>\"When the balance of strength is unequal, strength is righteousness. When the balance of strength is equal, righteousness is strength.\"</p> </li> <li> <p>\"Pursuing one\u2019s dreams is an incredibly dangerous process. You never know what you will run into along the way. As such, at the very least I must have faith that this is not an impossible dream. Only with this conviction will I have the courage to continue onwards.\"</p> </li> <li> <p>\"In his attempting to understand the hearts of others, he was also learning more about the world that he lived in. In the past, he had relied a lot on little tricks to get his way, but as he began to grow and mature, all the while accumulating experience, he began to see the bigger picture.\"</p> </li> <li> <p>\"The more urgent the issue, the calmer you need to be and the more you need to avoid making mistakes,\"</p> </li> <li> <p>\"Laymen follow others\u2019 movements, while wise men control the situation. It\u2019s still the same hypothetical situation; if I had heard my opponent talk to me that much, I would have realized that my opponent was waiting for me to do something.\"</p> </li> <li> <p>\"Respect must be given to the will of every creature. Each fish in the ocean swims in its own direction.\"</p> </li> <li> <p>\"lIf enough people believe they're real, they become real. Because they are addicted\"</p> </li> <li> <p>\"I am one who would rather suffer an eternity of destined calamities than beg for solace from the saints\u2026\"</p> </li> <li> <p>\"Ants may be able to fly, but they will fall eventually. They shall never touch the sky,\" the lad carrying the wooden sword exclaimed as he shook his head. If you hold this belief, then you will never be able to understand the true meaning of the Taoist Heart,\" said the young monk as he slowly blinked his eyes, still looking down at the warring ant colonies, The lad with the wooden sword raised an eyebrow and replied with a sneer, \"I will never understand how someone constrained like you is qualified to represent Xuankong Temple as its wayfarer in the world. \"The ants will fly, just like they will fall. However, they are better at climbing, and they are good at letting their fellow ants climb upon them. They are not afraid of sacrifice and as they pile upon one another, as long as there are enough of them, they shall eventually pile up high enough to touch the sky\"</p> </li> <li> <p>\"Eagles should not fear ants since they are simply black dots to the former. Ants should not fear eagles either because they are not even worth a bite to the eagle. The world of the ants had never seen or heard of a creature as powerful as the eagle, hence the latter remained unfathomable to the former. Nevertheless, over the span of many centuries and millennia, a few very distinguished ants among the crowd would, out of enigmatic reasons, decide to strip their gaze from the rotten leaves and just for once, gaze up at the crystal blue sky\u2026and then, the world was never the same to them. The fear comes from seeing.\"</p> </li> <li> <p>\"A veil was lifted off in front of my eyes when I understood that the modern society has replaced religious devotion with devotion to the material and this means that people identify with their job now that they can't identify with a common religion or background.\"</p> </li> <li> <p>\"The ancient greeks would probably think of you as a slave if you talked about work so much. Free men pursued the arts. Anyone at my job who only talks about work, I put them in the same box.\"</p> </li> <li> <p>\"Intentionally or not, when you say words like \"how pitiful,\" you're alienating yourself from the other person and their experience. It dismisses and trivializes their pain.\"</p> </li> <li> <p>\"The world's first Mora is probably just an ordinary coin created by Rex Lapis. As for its fate? The same as all Mora, I suspect - it was simply spent somewhere.\"</p> </li> <li> <p>\"For how could a god who had never once resisted - even till the end-nurse hatred for her people in her heart?\"</p> </li> <li> <p>\"Instead of explaining yourself to me, you should face your true self.\"</p> </li> <li> <p>\"The body and the mind are one. If something worries your mind, your body can help you find a solution.\"</p> </li> <li> <p>\"Besides, they're just kids. They should be allowed to believe it if it makes them happy. That's more important to them than questioning what's real and what isn't.\"</p> </li> <li> <p>\"Yoimiya: No matter where your journey takes you, and no matter what hardships might lie ahead, I hope you'll always be able to look back fondly on the fireworks you saw tonight. I believe that as time goes by, this firework will only grow brighter and more beautiful in your heart.\"</p> </li> <li> <p>\"Yoimiya: Fireworks that disappear in a flash of light are probably the furthest thing away from the eternity that our Shogun desires. Yoimiya: But people's feelings don't just disappear, and it's those feelings that give fireworks their purpose. If nobody wanted to watch fireworks, then they wouldn't exist. Eragon: That's another kind of eternity. Yoimiya: Also, consider You have to the Naganoharas, because so many people are emotionally invested in the existence of fireworks. Yoimiya: If we didn't exist, their wishes would go unfulfilled, wouldn't they?\"</p> </li> <li> <p>\"Ei: I am me. There is only one of me, but I can exist in many different forms. It's not important what form I exist in. Ei: The Shogun, for example, is one of my forms of existence. The question of whether or not she is me is not determined by any of her components. Paimon: In that case, this picture is one of your forms of existence, too. Ei: Hmm. So even I, who seeks Eternity, am constantly changing my form of existence... Ei: Then, how can I ask Inazuma and everyone who lives here to remain unchanging?\"</p> </li> <li> <p>\"To put it nicely, even deities indulge in wishful thinking. To put it more bluntly, there are things that even The Seven can't do when faced with something even more powerful than themselves.\"</p> </li> <li> <p>\"Because she is a god. It's not that gods don't need the company of others, just that the idea of a god having company seems indulgent to her.\"</p> </li> <li> <p>\"Sometimes like uh you get so creative that you don't know how to construct creatively the words in order to express your thought you know you just know how to create it you don't know how to verbalize your creative ideas like kanye west for instance his interviews people didn't know what the hell he was talking about when he was talking about his uh his clothing line right and then he created a billion dollar clothing line and i was like okay well maybe we can't we do we should listen to kanye west maybe it's like a bit of a genie for motivation-wise kanye is actually a really good example because this is actually a really big deal to me i feel like i have really good ideas and i can see what's happening in my head and then i go to a professional or i go to a loved one this is this is where it really hurts me is when i go to somebody that i love and i say i got this crazy idea let me tell you about and then i tell them what's happening scene for scene and then after that they go yeah it's pretty cool and i'm like you don't understand like what what i just said like that could be a full-on feature film or a tv show and they're like yeah it's cool it's cool and i'm like oh that hurts it's cool like that hurts me and then i'm thinking is it that wasn't a good idea that wasn't a good idea and then i'm like i don't do it anymore you gotta know the right people to share with you you you really do you're a little careful you you really your energy i think that's the biggest point that i can save for motivation for me is because some people are low in their life and they don't want anybody to be above them they want you to suffer with them and sit where they are in life and that's not everybody but there are people that want you know they're doing it they don't know they're doing it yeah they'd still love you too but they don't want you to be better than them and subconsciously some people will bring you down that way and some people are just like yeah it's cool because they can't see what's in your head but for me i can see what's in my head this is this is what happened personally with me and one of my students they were trying to explain to me what they were their story was about i'm like yeah that's cool and i don't know if i didn't motivate them or not but and i just couldn't really imagine what they were talking about it was just words all right they're just going blah blah blah blah blah and i'm like yeah yeah yeah keep on talking and then they showed me what they were working on a week later and i'm like this is incredible i didn't know that this is what you were talking about these were your words last week this is like this hit me in my heart and i wish that you could have explained it that way but you can't explain it you have to show it through your art and put music in it don't lose motivation whenever somebody says yeah that's a cool idea or whatever because they don't know what's in your flipping head that's the biggest thing that i would say i would walk away from the main thing to walk away from is that everybody has their own type of motivation and we've all shared our types of motivation and if you don't like it you can probably just shut up\"</p> </li> <li> <p>\"Beware of destination addiction.... until you give up the idea that happiness is somewhere else, it will never be where you are.\"</p> </li> <li> <p>\"The thought was this: that all my life had been murk and depths, but I was not a part of that dark water. I was a creature within it.\"</p> </li> <li> <p>\"No wonder I have been so slow, I thought. All this while, I have been a weaver without wool, a ship without the sea. Yet now look where I sail.\"</p> </li> <li> <p>\"Gods hate all toil, it is their nature.\"</p> </li> <li> <p>\"Each spell was a mountain to be climbed anew. All I could carry with me from last time was the knowledge that it could be done.\"</p> </li> <li> <p>\"Zeus so angry.\" \"Tell me,\" he said, \"who gives better offerings, a miserable man or a happy one?\" \"A happy one, of course.\" \"Wrong,\" he said. \"A happy man is too occupied with his life. He thinks he is beholden to no one. But make him shiver, kill his wife, cripple his child, then you will hear from him. He will starve his family for a month to buy you a pure-white yearling calf. If he can afford it, he will buy you a hundred.\"</p> </li> <li> <p>\"You can teach a viper to eat from your hands, but you cannot take away how much it likes to bite.\"</p> </li> <li> <p>\"I watched her dance, arms curving like wings, her strong young legs in love with their own motion. This was how mortals found fame, I thought. Through practice and diligence, tending their skills like gardens until they glowed beneath the sun. But gods are born of ichor and nectar, their excellences already bursting from their fingertips. So they find their fame by proving what they can mar: destroying cities, starting wars, breeding plagues and monsters. All that smoke and savor rising so delicately from our altars. It leaves only ash behind.\"</p> </li> <li> <p>\"But in a solitary life, there are rare moments when another soul dips near yours, as stars once a year brush the earth. Such a constellation was he to me.\"</p> </li> <li> <p>\"A golden cage is still a cage.\"</p> </li> <li> <p>\"Every moment mortals died, by shipwreck and sword, by wild beasts and wild men, by illness, neglect, and age. It was their fate, as Prometheus had told me, the story that they all shared. No matter how vivid they were in life, no matter how brilliant, no matter the wonders they made, they came to dust and smoke.\"</p> </li> <li> <p>\"Even the best iron grows brittle with too much beating.\"</p> </li> <li> <p>\"The fear of missing out goes into full effect. How can we say no; the offer is right here for the taking. We might never have gone after it, but now it is so easy to get it we consider it. But if we just say yes because it is an easy reward, we run the risk of having to later say no to a more meaningful one.\"</p> </li> <li> <p>\"This feeling is normal; studies have found that we tend to value things we already own more highly than they are worth, and thus find them more difficult to get rid of.\"</p> </li> <li> <p>\"Resistance is not a peripheral opponent. Resistance arises from within. It is self-generated and self-perpetuated. Resistance is the enemy within.\"</p> </li> <li> <p>\"It is one thing to study war and another to live the warrior\u2019s life.\"</p> </li> <li> <p>\"My friend Tony Keppelman snapped me out of it by asking if I was gonna quit. Hell, no! \"Then be happy. You\u2019re where you wanted to be, aren\u2019t you? So you\u2019re taking a few blows. That\u2019s the price for being in the arena and not on the sidelines. Stop complaining and be grateful.\" That was when I realized I had become a pro. I had not yet had a success. But I had had a real failure.\"</p> </li> <li> <p>\"The professional, though he accepts money, does his work out of love. He has to love it. Otherwise he wouldn\u2019t devote his life to it of his own free will.\"</p> </li> <li> <p>\"The professional has learned, however, that too much love can be a bad thing. Too much love can make him choke. The seeming detachment of the professional, the cold-blooded character to his demeanor, is a compensating device to keep him from loving the game so much that he freezes in action.\"</p> </li> <li> <p>\"The sign of the amateur is overglorification of and preoccupation with the mystery.\"</p> </li> <li> <p>\"The professional shuts up. She doesn\u2019t talk about it. She does her work.\"</p> </li> <li> <p>\"The professional dedicates himself to mastering technique not because he believes technique is a substitute for inspiration but because he wants to be in possession of the full arsenal of skills when inspiration does come. The professional is sly. He knows that by toiling beside the front door of technique, he leaves room for genius to enter by the back.\"</p> </li> <li> <p>\"Boys,\" said Kulgan, shaking his head. \"You hold a festival, give them a badge of craft, and suddenly they expect to be men. But they're still boys, and no matter how hard they try, they still act like boys, not men.\"</p> </li> <li> <p>\"We live a very long time by your standards. We learn to appreciate the humor in the world, often finding amusement in places where men find little. Or you can call it simply a different way of looking at life.\"</p> </li> <li> <p>\"As human beings we belong to an extremely resilient species. Since time immemorial we have rebounded from our relentless wars, countless disasters (both natural and man-made), and the violence and betrayal in our own lives. But traumatic experiences do leave traces, whether on a large scale (on our histories and cultures) or close to home, on our families, with dark secrets being imperceptibly passed down through generations. They also leave traces on our minds and emotions, on our capacity for joy and intimacy, and even on our biology and immune systems.\"</p> </li> <li> <p>\"Some people\u2019s lives seem to flow in a narrative; mine had many stops and starts. That\u2019s what trauma does. It interrupts the plot.\u00a0.\u00a0.\u00a0. It just happens, and then life goes on. No one prepares you for it.\"</p> </li> <li> <p>\"The lack of literature on the topic was a handicap, but my great teacher, Elvin Semrad, had taught us to be skeptical about textbooks. We had only one real textbook, he said: our patients. We should trust only what we could learn from them\u2014and from our own experience. This sounds so simple, but even as Semrad pushed us to rely upon self-knowledge, he also warned us how difficult that process really is, since human beings are experts in wishful thinking and obscuring the truth. I remember him saying: \"The greatest sources of our suffering are the lies we tell ourselves.\" Working at the VA I soon discovered how excruciating it can be to face reality. This was true both for my patients and for myself.\"</p> </li> <li> <p>\"You live through that little piece of time that is yours, but that piece of time is not only your own life, it is the summing-up of all the other lives that are simultaneous with yours.\u00a0.\u00a0.\u00a0. What you are is an expression of History.\"</p> </li> <li> <p>\"If you do something to a patient that you would not do to your friends or children, consider whether you are unwittingly replicating a trauma from the patient\u2019s past.\"</p> </li> <li> <p>\"why they are only attracted to people who hurt them. Fear and aversion, in some perverse way, can be transformed into pleasure.\"</p> </li> <li> <p>\"You observe a lot by watching.\"</p> </li> <li> <p>\"Medications, drugs, and alcohol can also temporarily dull or obliterate unbearable sensations and feelings. But the body continues to keep the score.\"</p> </li> <li> <p>\"It is only that in these troubled hours things are seen more clearly. The lamps of cities blur many shadows that are plain beneath the moon.\"</p> </li> <li> <p>\"That way, home could never be taken from him. Was this what the doctor meant? To be the same person no matter where you went, no matter what madness occurred\"</p> </li> <li> <p>\"Power over others is weakness disguised as strength.\"</p> </li> <li> <p>\"It seems almost impossible to disidentify from the mind. We are all immersed in it. How do you teach a fish to fly? Here is the key: End the delusion of time. Time and mind are inseparable. Remove time from the mind and it stops unless you choose to use it.\"</p> </li> <li> <p>\"There is no salvation in time. You cannot be free in the future. Presence is the key to freedom, so you can only be free now.\"</p> </li> <li> <p>\"Everything is honored, but nothing matters. Forms are born and die, yet you are aware of the eternal underneath the forms. You know that \"nothing real can be threatened.\"</p> </li> <li> <p>\"A man isn\u2019t tiny or giant enough to defeat anything.\"</p> </li> <li> <p>\"Auri closed her eyes and put the sheet back in the drawer, shame burning in her chest. She was a greedy thing sometimes. Wanting for herself. Twisting the world all out of proper shape. Pushing everything about with the weight of her desire.\"</p> </li> <li> <p>\"There is a difference between the truth and what we wish were true.\"</p> </li> <li> <p>\"Humor opens closed hearts. Humor can free us from the grip of our thoughts. When we smile, we feel we can accept things we previously could not.\"</p> </li> <li> <p>\"Moving forward inevitably invites further loss, but also new encounters.\"</p> </li> <li> <p>\"People flee out of a desire to live on. And the desire to live on stems from a feeling of having unfinished business in life.\"</p> </li> <li> <p>\"Good things don't last forever. Everything changes, fades, disappears completely over the passage of time. And so, people must make the most of the life they have, seize the chance to enjoy it while it lasts, and have no regrets in the end\"</p> </li> <li> <p>\"Artist block is what happens when you start judging the outcome before it has a chance to come out.\"</p> </li> <li> <p>\"If one can realize the original substance in which there is neither good nor evil, one will know what absolute Nothing is. And then all will, knowledge, and things will emerge from Nothing. Once this is done, it settles everything. Effort is substance. This truth is simple and direct. It is neither too much nor too little. This is the secret to be passed from one mind to another.\"</p> </li> <li> <p>\"When the mind is in the absolute present it will be free from the departing of the past and the coming of the future, and will be unified.\"</p> </li> <li> <p>\"Sometimes when you are not getting the love you want, giving makes you feel like you will\"</p> </li> <li> <p>\"As you shout into the woods, so they echo back.\"</p> </li> <li> <p>\"What I like most about what I do is that this teaching does not belong to anyone, it could belong to anyone. What matters is how to transmit those teachings to others\"</p> </li> <li> <p>\"It is not good to listen to your mind. Let\u2019s not be enslaved by it\"</p> </li> <li> <p>\"Everything starts with observing\"</p> </li> <li> <p>\" I wouldn't change anything about my brain and the way it works. It's fucked up so many things for me over the years, lost me jobs, ruined relationships, got me in trouble with the law, caused me serious physical harm and damn near killed me, but it's all been anything but ordinary! Now I know more about the executive functions that ADHD impairs and understand the affect it has had on my life, I've learned to appreciate the good things. We're the ones who take a path for the first time, who swim in that water for the first time, who push the limits further than anyone else and the latest scientific evidence suggests we evolved for precisely this purpose. We're life's path-finders.\"</p> </li> <li> <p>\"Forty-five percent of what we do every day is habitual ,\" say the researchers,</p> </li> <li> <p>\" performed almost without thinking in the same location or at the same time each day, usually because of subtle cues .\"</p> </li> <li> <p>\"It\u2019s because when you start to suffer, you speed up. And then you get mad.\"</p> </li> <li> <p>\"As one child described it, being gifted can feel like an abandoned alien waiting for the mother ship to come and take them home\"</p> </li> <li> <p>\"When you have a grasp on eternity your eyes won\u2019t ever see the battle or the lost people that hurt you. You will see a beautiful story of hope, in every character.\"</p> </li> <li> <p>\"To love at all is to be vulnerable. Love anything, and your heart will be wrung and possibly broken. If you want to make sure of keeping it intact you must give it to no one, not even an animal. Wrap it carefully round with hobbies and little luxuries; avoid all entanglements. Lock it up safe in the casket or coffin of your selfishness. But in that casket, safe, dark, motionless, airless, it will change. It will not be broken; it will become unbreakable, impenetrable, irredeemable. To love is to be vulnerable\"</p> </li> <li> <p>\"It's precisely because these connections don't last that they are so meaningful. They exist in their own right. Their only value is what they are in the now. Not what is expected of them in the future.\"</p> </li> <li> <p>\"We\u2019re programmers. Programmers are, in their hearts, architects, and the first thing they want to do when they get to a site is to bulldoze the place flat and build something grand. We\u2019re not excited by incremental renovation: tinkering, improving, planting flower beds\"</p> </li> <li> <p>\"There\u2019s a subtle reason that programmers always want to throw away the code and start over. The reason is that they think the old code is a mess. And here is the interesting observation: they are probably wrong. The reason that they think the old code is a mess is because of a cardinal, fundamental law of programming It\u2019s harder to read code than to write it.\"</p> </li> <li> <p>\"Humans will \"create\" a field of study on top of a field of study, assign things categories and names, invent all of this stuff, become really good at it, and then conclude nothing is really known. Let's go back to the part where we created a field of study. Full stop.\"</p> </li> <li> <p>\"If the doors of perception were cleansed, everything would appear to man as it is, infinite\"</p> </li> <li> <p>\"Stress is the adult word for fear\"</p> </li> <li> <p>\"I\u2019ve spent so much time in my head and in my heart that I forgot to live in my body.\"</p> </li> <li> <p>\"As  a  storyteller  she  had  to  make  an  implicit  pledge  that  if  the sultan  followed along  on  the  journey,  he  would  be  rewarded.  She needed to  present  a  character with whom he could identify with on his quest. He could imagine that he himself was  on  the  journey.  To  keep  the sultan\u2019s continued  interest  she  would  have  to keep topping herself and keep the sultan guessing as to whether each character would succeed or fail in his or her quest. Another one of her tricks was to some- times  allow  the sultan more  knowledge  than  the  characters  knew  themselves. When  he knew  more than  the  characters  did,  he  was  led  to  anticipate  horrible things that might happen to them.\"</p> </li> <li> <p>\"Learning how to avoid pain itself is pleasurable.\"</p> </li> <li> <p>\"We are made of stories\"</p> </li> <li> <p>\"When people injure you, ask yourself what good or harm they thought would come of it. If you understand that, you\u2019ll feel sympathy rather than outrage or anger. Your sense of good and evil may be the same as theirs, or near it, in which case you have to excuse them. Or your sense of good and evil may differ from theirs. In which case they\u2019re misguided and deserve your compassion. Is that so hard?\"</p> </li> <li> <p>\"Liminal means 'Intermediate between two states, conditions, or regions,' So a 'liminal space' can be a threshold or borderland where we can pass from one area to another. As we move through such spaces in life, we may enter a 'liminal state,' an experience of ambiguity or disorientation, before we cross over, transformed.\"</p> </li> <li> <p>\"You know what your problem is? You're smart. Too smart. You over think, because your mind moves at a million miles a minute. You're sad, because you're not fooled by the world like everyone else. You don't get along with most people, because they just don't look at things the way you do. You think you're dumb, because you're smart enough to know you don't know everything. Your problem is you're too smart. And that's not a problem at all.\"</p> </li> <li> <p>\"The only reward for hard work is more work.\"</p> </li> <li> <p>\"People generally fail to understand that complexity does not arise from complexity. Rather, it arises from simplicity, the simplicity of the tools\"</p> </li> <li> <p>\"Theoretical knowledge is table stakes for research taste. You can\u2019t have research taste in a vacuum.\"</p> </li> <li> <p>\"When you identify such a mess, the natural inclination of many people is to shy away, to find something that is easier to understand. But a field that is a mess is really an opportunity. Chances are good that there are deep unifying and simplifying concepts still waiting to be understood and developed by someone - perhaps you.\"</p> </li> <li> <p>\"It's like we're launching expeditions with complex equipment to reach more and more remote islands and tall mountains... and the biology stops at measuring the size and weight of the animals we find.\"</p> </li> <li> <p>\"Every model is its own entire world of beautiful structure waiting to be discovered, if only we care to look.\"</p> </li> <li> <p>\"I suspect that a lot of \"brilliant insights\" are natural next steps from someone who has deep intimacy with a research topic. And that actually seems more profound.\"</p> </li> <li> <p>\"Why is fantasy (magic, the force, etc) so emotionally compelling to many of us? Why is actually getting magic-like abilities from technology less profound? I think this points to important unmet needs and failings of technology. The easy answer is that magic is a power fantasy: it would give one power or make one special. But that doesn\u2019t really ring true to me. I imagine magic being compelling if everyone had it. Conversely, not all fantastical powers I could imagine are emotionally resonant. Another possible answer is that we\u2019re deadened to the wonder of technology and science. We\u2019ve lost our sense of awe. If magic existed, it might lose awe too. I think that\u2019s closer to true, but something is still missing. I think the crucial thing is that I imagine magic as humane and intimate, while technology is often alienating and distant in practice. The Force is compelling because who doesn\u2019t want to be profoundly directly connected to the universe? I also feel like magic often gets at a desire for our feelings to fundamentally matter. When I feel deep emotions, it feels as though they ought to directly affect the world, but they don\u2019t. In many fantasy worlds, emotions are reified first class objects. (How would the experience of life be different if rooms shook when people experienced severe grief or anger? If lighting and subtle sound effects were different around someone who is deeply serene or joyful? This seems physically possible.)\"</p> </li> <li> <p>\"My day job is to speak in an arcane snake language to a crystal vibrating at 3,000,000,000 cycles per second sitting in a cloud so that it can alter probabilities in the real world. If that isn't magic what is.\"</p> </li> <li> <p>\"When I can inhabit this mindset of loneliness being sacred in some sense, it adds a kind of beauty to an otherwise quite sad experience. I also suspect it might protect against some of the ways loneliness can be corrosive.\"</p> </li> <li> <p>\"No artist tolerated reality.\"</p> </li> <li> <p>\"2 week experiment. 6 month plan\"</p> </li> <li> <p>\"And then one day, EVERYTHING that you planned will come across an UNPLANNED scenario. Things will CHANGE. The WORLD around you will change. CHOICES, Outcomes &amp; even Mindset's would change. Everything you were once HELLBENT about not doing, would be EASY feat for you. What once made you CONTENT, would not be ENOUGH. That's the only constant truth about LIFE. It will change. People, Minds, Hearts, Dreams, Best Friends, Status, Everything. Look back at your last decade &amp; you would know it's true. So Live it up TODAY, because TOMORROW, even what is today might CHANGE.\"</p> </li> <li> <p>\"Our minds are like furry little gibbons: always agitated, never at rest\"</p> </li> <li> <p>\"Another study, out of Yale, looked at the part of the brain known as the default mode network (DMN), which is active when we\u2019re lost in thought\u2014ruminating about the past, projecting into the future, obsessing about ourselves. The researchers found meditators were not only deactivating this region while they were practicing, but also when they were not meditating.\"</p> </li> <li> <p>\"It was a little embarrassing to be reading a self-help writer and thinking, This guy gets me. But it was in this moment, lying in bed late at night, that I first realized that the voice in my head\u2014the running commentary that had dominated my field of consciousness since I could remember\u2014was kind of an asshole.\"</p> </li> <li> <p>\"What the science was showing was that our levels of well-being, resilience, and impulse control were not simply God-given traits, our portion of which we had to accept as a fait accompli. The brain, the organ of experience, through which our entire lives are led, can be trained. Happiness is a skill.\"</p> </li> <li> <p>\"Studies showed that the best way to engineer an epiphany was to work hard, focus, research, and think about a problem\u2014and then let go. Do something else.\"</p> </li> <li> <p>\"between me and reality. As one Buddhist author put it, the \"craving to be otherwise, to be elsewhere\" permeated my whole life.\"</p> </li> <li> <p>\"According to the Buddha, we have three habitual responses to everything we experience. We want it, reject it, or we zone out. Cookies: I want. Mosquitoes: I reject. The safety instructions the flight attendants read aloud on an airplane: I zone out. Mindfulness is a fourth option, a way to view the contents of our mind with nonjudgmental remove. I found this theory elegant, but utterly unfeasible.\"</p> </li> <li> <p>\"the only way to tame the monkey mind, to truly glimpse impermanence and defeat our habitual tendency toward clinging, was to meditate\u2014and I had absolutely no intention of following their advice. Meditation struck me as the distillation of everything that sucked hardest about the granola lifestyle. I pictured myself seated in an unbearable cross-legged position (my disavowal of yoga having left me less limber than I would have liked) in a room that smelled like feet, with a group of smug \"practitioners\" ringing bells, ogling crystals, intoning om, and attempting to float off into some sort of cosmic goo. My attitude was summed up nicely by Alec Baldwin\u2019s character on 30 Rock, who said,</p> </li> <li> <p>\"Meditation is a waste of time, like learning French or kissing after sex.\" Compounding my resistance was my extremely limited attention span. (Another of the many reasons I went into TV.) I assumed there was no way my particular mind\u2014whirring at best, at worst a whirlwind\u2014could ever stop thinking.\"</p> </li> <li> <p>\"The ego thrives on drama. It keeps our old resentments and grievances alive through compulsive thought.\"</p> </li> <li> <p>\"Meditation suffers from a towering PR problem, largely because its most prominent proponents talk as if they have a perpetual pan flute accompaniment. If you can get past the cultural baggage, though, what you\u2019ll find is that meditation is simply exercise for your brain.\"</p> </li> <li> <p>\"When you\u2019re totally present, whatever the situation is, good or bad, it\u2019s gonna pass. The only thing that remains is the moment.\"</p> </li> <li> <p>\"When you have one foot in the future and the other in the past, you piss on the present.\"</p> </li> <li> <p>\"Striving is fine, as long as it\u2019s tempered by the realization that, in an entropic universe, the final outcome is out of your control. If you don\u2019t waste your energy on variables you cannot influence, you can focus much more effectively on those you can. When you are wisely ambitious, you do everything you can to succeed, but you are not attached to the outcome\u2014so that if you fail, you will be maximally resilient, able to get up, dust yourself off, and get back in the fray. That, to use a loaded term, is enlightened self-interest.\"</p> </li> <li> <p>\"We all have an innate feeling of being separate from the world, peering out at life from behind our own little self, and vying against other isolated selves. But how can we truly be separate from the same world that created us? \"Dust to dust\" isn\u2019t just something they say at funerals, it\u2019s the truth. You can no more disconnect from the universe and its inhabitants than a wave can extricate itself from the ocean.\"</p> </li> <li> <p>\"We can do more than just think; we also have the power simply to be aware of things\u2014without judgment, without the ego. This is not to denigrate thinking, just to say that thinking without awareness can be a harsh master.\"</p> </li> <li> <p>\"The Buddha embraced an often overlooked truism: nothing lasts\u2014including us. We and everyone we love will die. Fame fizzles, beauty fades, continents shift. Pharaohs are swallowed by emperors, who fall to sultans, kings, kaisers, and presidents\u2014and it all plays out against the backdrop of an infinite universe in which our bodies are made up of atoms from the very first exploding stars. We may know this intellectually, but on an emotional level we seem to be hardwired for denial.\"</p> </li> <li> <p>\"None of us has moved very far from the seven-year-old who vigilantly watches to see who got more.\"</p> </li> <li> <p>\"If you\u2019re never looking up, I now realized, you\u2019re always just looking around.\"</p> </li> <li> <p>\"It\u2019s not me telling you,\" she said. \"It\u2019s neuroscience that would say that our capacity to multitask is virtually nonexistent. Multitasking is a computer-derived term. We have one processor. We can\u2019t do it.\" \"I think that when I\u2019m sitting at my desk feverishly doing seventeen things at once that I\u2019m being clever and efficient, but you\u2019re saying I\u2019m actually wasting my time?\"</p> </li> <li>\"Yes, because when you\u2019re moving from this project to this project, your mind flits back to the original project, and it can\u2019t pick it up where it left off. So it has to take a few steps back and then ramp up again, and that\u2019s where the productivity loss is.\" This problem was, of course, exacerbated in the age of what had been dubbed the \"info-blitzkrieg,\" where it took superhuman strength to ignore the siren call of the latest tweet, or the blinking red light on the BlackBerry. Scientists had even come up with a term for this condition:</li> <li> <p>\"continuous partial attention.\" It was a syndrome with which I was intimately familiar, even after all my meditating.\"</p> </li> <li> <p>\"I was a frequent mental inventory taker, scanning my consciousness for objects of concern, kind of like pressing a bruise to see if it still hurts.\"</p> </li> <li> <p>\"Thoughts calcify into opinions, little seeds of discontent blossom into bad moods, unnoticed back pain makes me inexplicably irritable with anyone who happens to cross my path.\"</p> </li> <li> <p>\"The voice comes braying in as soon as we open our eyes in the morning, and then heckles us all day long with an air horn. It\u2019s a fever swamp of urges, desires, and judgments. It\u2019s fixated on the past and the future, to the detriment of the here and now. It\u2019s what has us reaching into the fridge when we\u2019re not hungry, losing our temper when we know it\u2019s not really in our best interest, and pruning our inboxes when we\u2019re ostensibly engaged in conversation with other human beings. Our inner chatter isn\u2019t all bad, of course. Sometimes it\u2019s creative, generous, or funny. But if we don\u2019t pay close attention\u2014which very few of us are taught how to do\u2014it can be a malevolent puppeteer.\"</p> </li> <li> <p>\"Do you know what normally happens after your funeral? In a few hours the cry sound will be completely stopped. Family will be busy ordering food from hotels for relatives.. Grandchildren running and playing. Some men would go to the tea shop for walk before going to bed. Your neighbour will be angry, thinking that your people may have thrown the Ritual leaves close to their gate. A relative will talk to your daughter on the phone about not being able to come in person due to an emergency situation. At the next day's dinner, few relatives get reduced, and few complains not having enough salt in the curry. Foreign relations would have secretly planned tourism, as if they had never looked so far on the way there. A relative may be complaining about funeral that he has spent a few hundred rupees more on his share. The crowd will slowly begin to dissolve.. In the coming days Some calls may come to your phone without knowing you are dead. Your office will be rushing to find someone to replace you. One week later, after hearing the news of your death, Some Facebook friends may search with curious sadness to know what your last post was. In two weeks your son and daughter will return to work after their emergency leave get over. By the end of the month, Your spouse will be watching a comedy show and laughing.  In the coming months, your close relationships will return to the cinema and the beach. Everybody's life will go back to normal Just as there is no difference between a withered leaf of a big tree and what you live and die for, it all happens so easily,so fast, without any movement. Rains have started, the election is coming, the crowds on the buses are as usual, an actress is getting married, the festival is coming, the World Cup cricket is going as planned, the flowers are in full bloom, and your pet gave birth to next puppy. You will be forgotten by this world at an astonishing pace. In the meanwhile your first year death anniversary will be celebrated in a grand manner. In the blink of an eye Years have passed and there is no one to talk about you. One day, just looking at old photos, one of your close friend may remember you, In your hometown, of the thousands of people you've become acquainted with, only one person may remember and talk about sometime. You maybe living elsewhere, as someone else, if reincarnation is true. Tell me now... Otherwise, you will be nothing and will be plunged into darkness for decades. People are waiting to forget you easily Then who are you running around for? And who are you worried for? For most part of your life, say 80%, you think about what your relatives and neighbors think about you.. Are you living a life to satisfy them? NO USE Life is only Once, just live it up Fully\"</p> </li> <li> <p>\"Be good to yourself first, then to others\"</p> </li> <li> <p>\"When we say that someone is \"good,\" we often mean that the person complies with the will of others and isn\u2019t self-assertive. In other words, people who are good at suppressing their own desires in deference to another\u2019s are the ones who frequently get called \"good.\"</p> </li> <li> <p>\"But the problem is that, by living in accordance with the demands of others, we unwittingly neglect our own desires and needs. If as a child you were indifferent to your own feelings, minimizing them or not considering them important, as an adult you will not be able to tell what it is you yourself want to do, or who you are as a person. And then when you encounter someone who treats you unfairly or makes things difficult for you, since you do not know how to properly express your own feelings, the anger that ought to be directed toward its instigator is trapped inside you and ends up attacking you instead.</p> </li> <li> <p>\"Why am I such an idiot, that I can\u2019t express my feelings properly, can\u2019t even speak up honestly?\"</p> </li> <li> <p>\"One of our common mistakes is to compare how we feel inside with how our friends appear outside.\"</p> </li> <li> <p>\"Compare yourself not with others, but with the old you\"</p> </li> <li> <p>\"Not everything that appears in your mind is true.\"</p> </li> <li> <p>\"If you hear a voice within you say, 'You cannot paint,' then by all means paint, and that voice will be silenced.\"</p> </li> <li> <p>\"Don't let the internet rush you. Nobody is posting their failures\"</p> </li> <li> <p>\"Any half-awake materialist well knows \u2013 that which you hold holds you.\"</p> </li> <li> <p>\"The more stuff you own, the more your stuff owns you\"</p> </li> <li> <p>\"You can\u2019t have everything. Where would you put it?\"</p> </li> <li> <p>\"Our actions will always follow the true desire of our heart. What our heart believes and loves always determines the path of our life. We can mask our true wants for only a short while. Without a true heart change, we always return to our heart\u2019s first love.\"</p> </li> <li> <p>\"Becoming minimalist has modeled for my children that personal belongings are not the key to happiness, that security is found in their character, and that the pursuit of happiness runs a different road than the pursuit of possessions.\"</p> </li> <li> <p>\"Madison Avenue has controlled our finances for too long. Since the day we were born, it has told us what needs to be bought, when it needs to be purchased, and what store we should visit to find the best value. When we chose freedom from material possessions, we broke the control that our consumer-driven, capitalistic society has had over us. Suddenly, we have been freed to use our finances to pursue endeavors far greater than those offered at our local department store.\"</p> </li> <li> <p>\"Everything has a home.\"</p> </li> <li> <p>\"The good life is a process, not a state of being. It is a direction, not a destination.\"</p> </li> <li> <p>\"Do not be tense, but ready; not thinking, but not dreaming; not being set, but flexible. It is being wholly and quietly alive, aware, and alert; ready for whatever may come.\u2026\"</p> </li> <li> <p>\" \"Never assert yourself against nature,\" he told him. \"Never be in frontal opposition to any problem, but control it by swinging with it.\"</p> </li> <li> <p>\"To be like water, then, is to realize your most whole, natural, and actualized self where you are living as much as possible in the slipstream of life as you forge your own path forward.\"</p> </li> <li> <p>\"Using no way as way, having no limitation as limitation.\"</p> </li> <li> <p>\"water basics that I want us to begin to sit with\u2014that water is undeterred. It will carve canyons into mountains over centuries.\"</p> </li> <li> <p>\"To be like water is not to be aspiring to perfection. Perfection is a difficult master. To be like water is not to be controlling of everything. Control is a tight yoke.\"</p> </li> <li> <p>\"But I decided to be present with what was happening and stop resisting it. I gave the future of the project to the universe, and I said, \"Show me the way.\" And like water, I began to follow the course of this new unfolding rather than try to build a thousand dams to enforce the direction of the stream.\"</p> </li> <li> <p>\"I\u2019m participating and cocreating, but no longer forcing.\"</p> </li> <li> <p>\"No man ever steps in the same river twice, for it\u2019s not the same river and he\u2019s not the same man.\"</p> </li> <li> <p>\"This ship is seeking knowledge. All of the things people tell you to seek out in life - a college degree, a job, a paycheck, awards, research publications, critical acclaim, etc. - all of these things happen as a result of seeking knowledge. If you live your life by this guiding principle, you'll never be lead astray. However, if you start to chase the wake of your ship - the job, the piece of paper that says you earned a college degree, etc. - you'll end up chasing your tail and halting any sense of forward progression.\" For example, if you go through college seeking a high GPA and the end overall degree, you tend to miss out on the most formative aspects of higher education. However, if you approach college seeking knowledge and challenging yourself, you'll typically end up with a good GPA and graduate with a degree - the \"wake\" which came as a result of knowing how to orient your \"ship.\"</p> </li> <li> <p>\"You will learn more about God on a bus stop, in an unemployment life, through the death of a loved one, than you ever will by just listening to a sermon.\"</p> </li> <li> <p>\"And every platform, especially image-conscious ones like Instagram, encourages a constant cosplay of the self \u2014 to project someone cooler, hotter, and happier than we really are. It\u2019s perhaps not surprising that we\u2019re losing track of who we are when we power down our screens.\"</p> </li> <li> <p>\"Machine learning methods change every year, solving problems stays the same.\"</p> </li> <li> <p>\"The evolution of human mentality has put us all in vitro now, behind the glass wall of our own ingenuity.\"</p> </li> <li> <p>\"No religion is the only religion, no church the true church.\"</p> </li> <li> <p>\"Perhaps nowhere is our human mania for possessing, our delusion that the owned cannot have a soul of its own, more harmful to us. This disanimation justified all the horrors of the African slave trade. If the black man is so stupid that he can be enslaved, he cannot have the soul of a white man, he must be a mere animal.\"</p> </li> <li> <p>\"Even the simplest knowledge of the names and habits of flowers or trees starts this distinguishing or individuating process, and removes us a step from total reality towards anthropocentrism.\"</p> </li> <li> <p>\"We shall never fully understand nature (or ourselves), and certainly never respect it, until we dissociate the wild from the notion of usability - however innocent and harmless the use. For it is the general uselessness of so much of nature that lies at the root of our ancient hostility and indifference to it.\"</p> </li> <li> <p>\"Man is a highly acquisitive creature, brainwashed by most modern societies into believing that the act of acquisition is more enjoyable than the fact of having acquired, that getting beats having got.\"</p> </li> <li> <p>\"Ordinary experience, from waking second to second, is in fact highly synthetic (in the sense of combinative or constructive), and made of a complexity of strands, past memories and present perceptions, times and places, private and public history, hopelessly beyond science's powers to analyse. It is quintessentially 'wild' ... unphilosophical, irrational uncontrollable, incalculable.\"</p> </li> <li> <p>\"These question-boundaries ...are ours, not of reality. We are led to them, caged by them not only culturally and intellectually, but quite physically, by the restlessness of our eyes and their limited field and acuity of vision.\"</p> </li> <li> <p>\"Evolution had turned man into a sharply isolating creature, seeing the world not only anthropocentrically but singly, mirroring the way we like to think of our private selves.\"</p> </li> <li> <p>\"We lack trust in the present, this moment, this actual seeing, because our culture tells us to trust only the reported back, the publicly framed, the edited, the thing set in the clearly artistic or the clearly scientific angle of perspective.\"</p> </li> <li> <p>\"People who live their lives in fear are destined to have uncomfortable feet\"</p> </li> <li> <p>\"You can't find happiness where you lost it\"</p> </li> <li> <p>\"You wouldn't care as much about what people think about you if you realize they seldom do.\"</p> </li> <li> <p>\"We give up , because we feel , we are getting judged , because that's what society does to us all the time.\"</p> </li> <li> <p>\"e, humans, find reasons for almost anything. We love the thought of giving meaning to things, especially to our existence. We are such creatures.  I think it stems from our fears. Fear of being insignificant, fear of being a victim of circumstances, fear of having no importance, etc. I believe it's a defense or coping mechanism. It's our go-to as thinking beings.\"</p> </li> <li> <p>\"We humans, we\u2019re all the same. Every last one of us. For some it\u2019s drinking, for some it\u2019s women, for some even religion, family, the king, dreams, children\u2026power. All of us had to spend our lives drunk on something else we\u2019d have no cause to keep pushing on. Everyone\u2026was a slave to something.\u201d</p> </li> <li> <p>\"I'm simply an accident. Why take it all so seriously?\"</p> </li> <li> <p>\"All those moments will be lost in time, like tears in the rain.\"</p> </li> <li> <p>\"What do you do from morning to night? I endure myself\"</p> </li> <li> <p>\"Man stands face to face with the irrational. He feels within him his longing for happiness and for reason. The absurd is born of this confrontation between the human need and the unreasonable silence of the world.\u201d</p> </li> </ul> <p>\"After having struggled madly to solve all problems, after having suffered on the heights of despair, in the supreme hour of revelation, you will find that the only answer, the only reality, is silence.\u201d</p> <ul> <li> <p>\"Everything that is formulated becomes more tolerable.\"</p> </li> <li> <p>\"Every man is happy until happiness is suddenly a goal\u201d</p> </li> <li> <p>\"The truth is, you are already worthy of being loved. You don\u2019t need to be convinced of your self-worth by taking on society\u2019s demands and living up to its expectations. You already are a precious being and deserve to be loved and cared for. Look inside and see if you can find the child within you, still shaking with anxiety because of his father. Send the energy of loving-kindness to that inner child, and look at him compassionately. How difficult it must have been, coping with your father\u2019s rage alone, trying to protect your siblings, without even your mother to help you.\"</p> </li> <li> <p>\"I sometimes believe my mom caused me to have ADHD or at least she worsened it. I can see a lot of correlations, like my \"laziness\u201d (her words) coming from her lack of parenting and holding me accountable in a normal way. Or the way that I zone out a lot / have issues focusing being because of a list of reasons including dissociation to protect myself or being use to being unheard. It\u2019s kind of hard to explain it all, but you get the point hopefully.\"</p> </li> <li> <p>\"I woke up yesterday at noon. but for today\u201d</p> </li> <li> <p>\"Life always waits for some crisis to occur before revealing itself at its most brilliant.\u201d</p> </li> <li> <p>\"Shower your child with attention, and make her feel secure in your love.  This way she won\u2019t grow up starved for other people\u2019s acknowledgment.\"</p> </li> <li> <p>\"Special moments are not separate from our everyday lives.  When you make use of something special, it makes the moment special.\"</p> </li> <li> <p>\"Are you looking to move onwards and upwards or run away? Look before you leap, you don't want to appear the fool do you?\"</p> </li> <li> <p>\"Lengthy deliberation often leads to a terrible decision. If you think and worry too much before doing something, your boat goes to the mountain instead of the ocean.\u201d</p> </li> <li> <p>\"We are so good at creating something from nothing that we make our own lives fantasy and give ourselves a hard time. Color dodge the shit out of your life. Only you can.\"</p> </li> <li> <p>\"No one is going to break the cycle until they accept who they are, and what they are, and what they\u2019ve done, and they forgive themselves. You can\u2019t move forward unless you forgive yourself. A lot of people don\u2019t know that. So they live in guilt and shame for so long.\"</p> </li> <li> <p>\"Nature does not hurry yet everything is accomplished\"</p> </li> <li> <p>\"O archon seeker, do you now understand? She and her wisdom have long been found by you. Along your journey we were in every flower and blade of grass, every ray of sparkling sun, and every breath of dancing wind. So long as you continue to think and ponder, well be wherever you go.\u201d</p> </li> <li> <p>\"Fate will only ever show you the beginning of a journey. It is up to you for forge your own ending.\u201d</p> </li> <li> <p>\"Analogies are wonderful tools. They let you use existing knowledge to understand unfamiliar things.\u201d</p> </li> <li> <p>\"I believe that the Archons revelations are never more than vague hints. Anything more specific is beyond the reach of mere mortals.\u201d</p> </li> <li> <p>\"If you trust your instincts and overcome your fears, the sun will surely rise\u201d</p> </li> <li> <p>\"Knowledge always comes at a price.\u201d</p> </li> <li> <p>\"Tomorrow will come. Everyone assumes this as common knowledge, but the only way you can know for sure is if you experience tomorrow. How many \u2018today\u2019s\u2019 has it been? Is it possible that today will be followed by yesterday? Does tomorrow truly exist as anything beyond a made up concept?\u201d</p> </li> <li> <p>\"That\u2019s why it makes no sense to waste your energy thinking about things you will learn tomorrow.\u201d</p> </li> <li> <p>\"Dreams are fantastical, complex and full of imagination. Peoples brains are most active when they\u2019re dreaming. In other words, the dreams are rich bundles of human wisdom.\u201d</p> </li> <li> <p>\"There will always be frustrations in life, but I know that the point of living is to not leave behind any regrets.\u201d</p> </li> <li> <p>\"When the north wind blows, some dandelion seeds are blown across the sea to Inazuma, while others get swept away to Liyue.\u201d</p> </li> <li> <p>\"Jeht: I don't have family traditions, and I don't even remember my mother's face. I only have you, and you only have me. There is no large tree and no branches that tie us together.  Jeht: You might have left the desert long ago, and this might be my first time seeing it for myself, but I have this feeling that we are like grains of sand here in the desert.  Jeht: No family, no objective... But what we are is pretty free. Haha!  Paimon: Jeht...  Jebrael: The desert holds only the past. It has no future. If what lies beneath the sand and wind can be described as the truth, then I can only say that it perhaps isn't something that will bring joy to everyone.  Jebrael: I gave up the path of seclusion, not because it's a mistaken path, but because I found a better path. Jeht, I hope you'll be able to take that bright path.  Jeht: I don't really understand you. If the path of sand isn't what you desire, then why accept Tirzad's commission? Don't tell me it's because you want to take a look at your past.  Jeht: I think you just can't forget the desert and the hot winds that sweep it.  Jeht: The strange thing is that I have no memories of the desert, but coming here makes me feel like I've returned home all the same. Jeht: I love the sand, just like I love Paimon and Benben.\u201d</p> </li> <li> <p>\"O stars high above the wasteland; O nightingales weary from the day; It's time to take off the crown of roses; Cleanse yourself with wine made from grapes. Sleep, close your eyes; Yon golden slumber summons thee, wandering sand; Drink not that bitter salt water; For the sorrows of tomorrow have gone away.\u201d</p> </li> <li> <p>\"Underestimate the sand and you'll pay with your life.\u201d</p> </li> <li> <p>\"The door is protecting something very important, and so much time has passed that it has almost forgotten how it used to open.\u201d</p> </li> <li> <p>\"Coming to the desert is like returning home, and in the end, I'm a grain of sand. I was born here, and I shall be buried here as well.\u201d</p> </li> <li> <p>\"Ufairah and I were like a bird and a fish, but Al-Ahmar's secrets allowed our fates to intertwine. Now, you and I, people from different lands, are again here for those very same secrets.\u201d</p> </li> <li> <p>\"A man chained by hatred cannot raise a daughter.\u201d</p> </li> <li> <p>\"There was the Door to which I found no Key; There was the Veil through which I might not see: Some little talk awhile of Me and Thee There was--and then no more of Thee and Me.\" \"Each Morn a thousand Roses brings, you say: Yes, but where leaves the Rose of Yesterday?\u201d</p> </li> <li> <p>\"Agree to disagree. But, your appearance just made this a whole lot more interesting.\"</p> </li> <li> <p>\"Every journey has its end. Don\u2019t rush.\"</p> </li> <li> <p>\"Some say a few are chosen and the rest are dregs; But I say we humans have our humanity. We will defy this world with a power from beyond.\"</p> </li> <li> <p>\"Then, the threads of all fate will be yours to reweave...\"</p> </li> <li> <p>\"Beauty is a waste when the beholder has no taste.\"</p> </li> <li> <p>\"Nobody ever feels alone when they set off a firework\u201d</p> </li> <li> <p>\"There will always be those who dare to brave the lightning's glow\".</p> </li> <li> <p>\"Even if an antique is priceless, the happiness it brings lasts for only the moment you obtain it.\"</p> </li> <li> <p>\"I know, I know, you can't get me out of your mind. But you really don't need to call my name all the time.\"</p> </li> <li> <p>\"Never stop searching, even for a brief flash of light\u201d</p> </li> <li> <p>\"We have always... had enough time\"</p> </li> <li> <p>\"People believe whatever they want to believe. Some things they do not see,simply because they do not wish to look.</p> </li> <li> <p>\"To endure hardship you must prepare for hardship\"</p> </li> <li> <p>\"What you might not realize is that all too often\u2026 people have far more to lose by chasing their dreams\u201d</p> </li> <li> <p>\"A heart made of stone is a heart nonetheless\"</p> </li> <li> <p>\"If you\u2019re not willing to communicate, then the problem just sits there. If you just keep staring at it without doing anything, eventually you\u2019ll watch every last opportunity to resolve it slip away before your eyes\"</p> </li> <li> <p>\"Where our legs cannot take us, maybe our tools can. And when tools fail us, perhaps wings can carry us instead.\"</p> </li> <li> <p>\"The spirit soars the mountains high, while the body rests as the world goes by...  By wave and storm I hunt for fish, by wind and snow I slay evil...\"</p> </li> <li> <p>\"Let this be a lesson to those who yesterday said, \"I'll do it tomorrow.\"</p> </li> <li> <p>\"As a Guuji, there's one thing I know very well: People believe whatever they want to believe. Some things you do not see, simply because you do not wish to look. And so... it falls to me to place the truth before your eyes, in all its ugliness.\"</p> </li> <li> <p>\"There are no coincidences in the world. Everything is the fruit of seeds planted long ago.Just like your appearance in that tavern.Time is just waiting for those seeds to sprout\".</p> </li> <li> <p>\"I'm all for work-life balance, but I think this is pushing it.\u201d</p> </li> <li> <p>\"For those that live too long, the friends of days gone by and scenes from their adventures live on in their memories. As such i have no regrets in meeting you, friend. Should the day ever come that we are not together, you will continue to shine like gold in my memories.\"</p> </li> <li> <p>\"You stand upon your tomb, though you know it not! \"</p> </li> <li> <p>\"When shall we meet again after this parting? For life is like the morning dew.\"</p> </li> <li> <p>\"What is more pure and free than than wish of a child?\"</p> </li> <li> <p>\"No matter what the days may bring,whichever roads we choose to take.While this oath remains observed,each of us remains the same....\"</p> </li> <li> <p>\"One is simply not partial to the tedium of social interaction, and wished to find some peace and quiet.\"</p> </li> <li> <p>\"Even I cannot avoid it. But there is something I understand better than most: When the door opens, it is time to leave. The greater the power, the greater the danger erosion may bring about. The millennia may come and go, but even a stone may tire.\"</p> </li> <li> <p>\"People who look for the flaws in others, expose theirs quickes\"</p> </li> <li> <p>\"Because maybe it doesn't matter so much if something's real or not. Maybe magic and awesomeness are what make something worth believing. Why should someone else get to take that away from you?\"</p> </li> <li> <p>\"Cast your fear of injury by the wayside and fight with all your might. I too did this during the Archon war\"</p> </li> <li> <p>\"If saving you is a sin, I\u2019ll gladly become a sinner\"</p> </li> <li> <p>\"To be alive is to seek, to set foot in every place that eye can see.\"</p> </li> <li> <p>\"In teyvat, the stars in the sky will always have a place for you\"</p> </li> <li> <p>\"Someday even bedrock returns to dust\"</p> </li> <li> <p>\"For dawn to come, there must be those willing to pierce the darkness with their light.\u201d</p> </li> <li> <p>\"When one's fervent ambition burns brightly, the gods will cast their gaze upon you. Some ambitions have the power to heal wounds. to bring victory. to inspire hope. But some ambitions outlive their masters, long after the soul ascends. They remain as they were in the beginning. Burning bright and true for all eternity.\"</p> </li> <li> <p>\"A blade embraces it\u2019s duty, as a jeweller cherished their gems\"</p> </li> <li> <p>\"A non-believer going into a church never ends well\"</p> </li> <li> <p>\"You've been with me for some time now. Have you learned to observe? Then observe me. Observe me right down to my very core.\"</p> </li> <li> <p>\"Hard work is all there is to the craft\"</p> </li> <li> <p>\"People show you whatever side of themselves they want you to see.\"</p> </li> <li> <p>\"I hear the voice of fate, speaking my name in humble supplication...\"</p> </li> <li> <p>\"Gamblers always place their bets on the next dice roll... But the bankers always have the last laugh, and they never touch a single die.\"</p> </li> <li> <p>\"Before demanding too many miracles from the gods, first consider if you are willing to pay the price they ask\"</p> </li> <li> <p>\"This scenery is wonderful... Surely enough to convince anyone to become a wanderer.\"</p> </li> <li> <p>\"My memory has all but faded completely\u2026 but I will always remember how she too, loved these flowers\"</p> </li> <li> <p>\"To be blind to the beauty that poets adore is to view the world from the ocean floor.\"</p> </li> <li> <p>\"The Crash of a Spear brought billowing dust. The mountains and waters made way at the sound. The sight of a dragon bestowed with a touch. The promise of rainwater blessing the ground.\"</p> </li> <li> <p>\"If only you could make one exception...things could have been easier for you.\"</p> </li> <li> <p>\"A foolish man complains of a hole in his pocket, I wise man uses it to scratch his balls.\"</p> </li> <li> <p>\"For how could a god, who never once resisted, even till the end, nurse hatred for her people in her heart?\"</p> </li> <li> <p>\"Sorry to also have you shoulder the grievances of the world, since you could endure my bitter cold, you must have desire to burn?\"</p> </li> <li> <p>\"The power of water is its ability to take any shape.\"</p> </li> <li> <p>\"And thus another spark of divinity departs from Liyue. My legacy shall now be left for those who come after to debate.\"</p> </li> <li> <p>\"The fate that brings people together is not a cord so easily cut.\"</p> </li> <li> <p>\"He\u201d is unhappy. \"He\u201d is displeased with the disturbance caused by \"words of the tone,\u201d which drown out the wisdom of the \"words of the heart\u201d. The \"words of the tongue\u201d are like pouring rain. They shake the eardrums and disrupt the heart. \"The words of the heart\u201d are like fog. They deep in naturally, enshrouding.. do not use your tongue do not use your ears, listen with your heart\u201d.\"</p> </li> <li> <p>\"There are so many disappointments to face. Some are huge, some are small, some are what they are.  Some are deep wounds that change the course of your life. They become the scar that everyone sees, no matter how much you try to hide it. Some are so small, there's no understanding why we give them any time at all, but we keep giving them center stage. Some are disappointing. We accept them for what they are and hope good comes out it. Once the ice cream hits the pavement, all we can do is hope the ants enjoy the treat\"</p> </li> <li> <p>\"I have lived places where black lives didn't matter. I have lived places where poor lives didn't matter. I have lived places where military lives didn't matter.  Those places will never live in me.\"</p> </li> <li> <p>\"When a child is bored, read them a book about far away places. Plant a dream of a peace filled world\"</p> </li> <li> <p>\"I'm often asked how I did it, how I got through the hard times. I wish there was a check list of things to help others get through their darkness, but there's not. Sometimes you have to shuffle your feet to keep your balance. Sometimes you have to take bold steps to get over a crevasse. Sometimes you just have to stand still and let the raging water pass in front of you. There's not a right answer, or even one answer. Just keep moving forward to find your light.\"</p> </li> <li> <p>\"Darkness may not always be evident, but it doesn't mean it's not there. But there is, also, still hope to shed light on those places.\"</p> </li> <li> <p>\"Impatient with actions, Patience with results.\"</p> </li> <li> <p>\"Past meets present, heritage becomes legacy, long into the future may we thrive.\"</p> </li> <li> <p>\"Aranishat, you should admit defeat. Don't be like a stubborn twig that refuses to bend against strong gusts. You will break just like it.\u201d</p> </li> <li> <p>\"The unseen and uncatchable that slips past the moon's gaze and encourages the growth of sprouts\u201d</p> </li> <li> <p>\"Hmm, the children of the forest aren't distinguished by age.\u201d</p> </li> <li> <p>\"Zhongli: I ended an era with my own two hands. I have always wondered how I should... remember that which I ended.  Zhongli: History records, but history may be changed. This incident proved that. Time is a mighty force, and histories twist in its flow...  Zhongli: I need to find a better way of recording history in order to engrave its truth.  Zhongli: Stone carvings were one such ancient method. But unchanging stone, immovable earth, even one such as myself... Someday, we may all disappear.  Paimon: Zhongli...  Zhongli: Therefore, I thought of you, Traveler.  Zhongli: You are one who crosses the celestial atlas, and who passes through countless worlds. If our history is engraved in your memory, it will one day accompany you into another world. Zhongli: As long as a Traveler like you is able to record what happened, then a backup of sorts will exist for times and tides of Teyvat.\u201d</p> </li> <li> <p>\"Life may exist in all kinds of unfathomable forms and in all manner of unthinkable environments. Mysterious, yet tenacious... Perhaps this is what makes life so special.\u201d</p> </li> <li> <p>\"To those who seek shall just reward be given in proportion to their wisdom and work.\"</p> </li> <li> <p>\"Yae Miko: The path of the swordmaster is filled with twists and turns. It is no small undertaking to pursue the position of greatest swordmaster in the world.  Yae Miko: It requires one to take their sword firmly in both hands and cut down the hopes and dreams of others... even those of one's closest companions.  Yae Miko: Only a deep commitment to his ambition to become the best made it possible for him to rise above the pain of these encounters \u2014 to focus on the way ahead.  Yae Miko: When that ambition disappeared, he began to doubt himself. As he battled his growing anxiety... he slowly descended into the state you see him in now.\u201d</p> </li> <li> <p>\"The wind that blows from afar carries fresh life to these shores...\u201d</p> </li> <li> <p>\"How else can you catch a thief except by being familiar with how a thief thieves?\u201d</p> </li> <li> <p>\"Only those who have traveled understand the meaning of a journey. I hope she'll find what she's been looking for...\u201d</p> </li> <li> <p>\"The essence of the Amenoma Art is to have the patience to move mountains and unrelenting willpower\u201d</p> </li> <li> <p>\"Then again, the memories of ore can shift with the passage of time and the changing of the environment\u201d</p> </li> <li> <p>\"He who bears the weight of memory is destined to shoulder the burden of truth. As it ought to be.\u201d</p> </li> <li> <p>\"In the wilderness, snow falls on a spring day. In an instant it will melt. Even where it is fleeting and leaves no trace. Even where it will never fall again...\u201d</p> </li> <li> <p>\" Kun Jun: Curious how swords and daggers are blind, yet their creators see so much. Perhaps empathy is mankind's proudest achievement after all?  Zhongli: Azhdaha. I am no longer the Geo Archon.  Kun Jun: ...I can sense it.  Zhongli: Today I am just an ordinary citizen of Liyue.  Kun Jun: Even you met such a fate... Let's get the difficult part out of the way. I cannot guarantee that I won't be awoken a second time.  Zhongli: No matter. If that day comes to pass, Liyue must prepare itself to face you.  Kun Jun: And how will Liyue fare without Rex Lapis?  Zhongli: Even without a god above, this remains a nation of men. I was once their god, I ought to be here to witness their rise and fall. Kun Jun: All life is shaped and then ground away by the endless flow of time. You were always the strongest among us, yet it would seem that even you have been eroded...  Kun Jun: That's unimportant... fate is ordained by heaven. Even if our mission had already concluded, it would be cowardly not to strike out on the road of departure.  Kun Jun: You may live forever, doomed to a lonely existence... yet even this is temporary. When you reach the end of time, those people, those past and future relationships predetermined by fate... They will be waiting for you.  Zhongli: I do not pretend to match your rhetoric when it comes to the subject of a life long-lived. I fear that the life of an elemental being is longer than any in this world.\u201d</p> </li> <li> <p>\"The greater the power, the greater the danger erosion may bring about. The millennia may come and go, but even a stone may tire.\u201d</p> </li> <li> <p>\"But as long as you firmly believe that you are on the right path... everything has meaning.\u201d</p> </li> <li> <p>\"A fleeting moment, a thousand years in the mortal world. The rocks feel it, and so too does the earth and the god\u201d</p> </li> <li> <p>\"Nachtigal: I think you're being too stubborn. There's always a choice in life. Nachtigal: I mean, just look at Bonifaz and I. We weren't born as traveling merchants, and no one in our families has even been to Sumeru...  Nachtigal: But we're still here with the northern wind at our backs. We don't regret our choice at all. Seeing the boundless world unfold before our eyes fills us with a sense of freedom.\u201d</p> </li> <li> <p>\"The desert holds only the past. It has no future. If what lies beneath the sand and wind can be described as the truth, then I can only say that it perhaps isn't something that will bring joy to everyone.\u201d</p> </li> <li> <p>\"Venti: \"Fill up the barrels and store them away, Then wait, wait for a windier day.  Wax the bottles, seal them tight, For the south wind that soothes, for the north wind that bites.\" \"How does this fine wine taste to the tongue?  As 'Mondstadt' to the ear: like a sweet dream of freedom.  And what are the fruits that went into the brew?  An explorer's courage, a love tender and true.\" \"A defender's will, strong as yesteryear, Joining the thousand winds in a song of good cheer, Turning sour into sweet, bitter notes fade away, As we wait, wait for a windier day.\" \"Pray tell, what treasure does this barrel hold?  'Tis wheat's greatest triumph, the true liquid gold.  As it flows from the keg, what sound drifts by?  Wind chimes in the boundless, immemorial sky.\" \"We raise up our glasses, and voices in song, As we wait, wait for the wind to sing along.  Where do we turn once the thousand winds     take flight?  To the tales of the lyre, to the sweet dream of     tonight.\"</p> </li> <li> <p>\"You know, no two waves are ever the same...\u201d</p> </li> <li> <p>\"The sun nurtures many good things, but it can't do anything about the problems lurking in the shadows.\u201d</p> </li> <li> <p>\"The ancient writers once emphasized the virtues of \"edification through immersion\" \u2014 that is to say that human temperament and character can be affected by being steeped in aromas and lovely scents.\u201d</p> </li> <li> <p>\"Dear young master, you still have a long life ahead of you. There shall be plenty of opportunities to drink \u2014 in the future, that is.\"</p> </li> <li> <p>\"The flesh resides in society, while the heart yearns for the natural world... Such has been the way of the Kaedeharas for many generations.\"</p> </li> <li> <p>\"To me, what is past is gone. Everything in the world is guided by its own rules, and as for people... we can never relive the past.\"</p> </li> <li> <p>\"If you ever grow tired of this tedious life, just drop everything and go off on a journey, see the world. Remember, Kazuha, don't let yourself get tied down in life.\"</p> </li> <li> <p>\"I yearn to hear the song of nightingale, my patient ears ready to attend. A veil of mist obscures the western skies, into its midst a silver moon descends.\"</p> </li> <li> <p>\"Life is a long journey, and that's why I must travel far and wide.\"</p> </li> <li> <p>\"Ambition is our power in its rawest form. We cannot live without it.\"</p> </li> <li> <p>\"Old things often carry around some form of regret.\"</p> </li> <li> <p>\"But that's okay. Partings produce reunions, if not at home then in a distant land.\"</p> </li> <li> <p>\"When the heart is clear, the world is too. And when the heart is unladen, the same is true.\"</p> </li> <li> <p>\"Only when you witness my whole story does it become truly consigned to history.\"</p> </li> <li> <p>\"What really matters in life is not how strict we are with ourselves, but the connections we make along the way. There's no future for those who linger on the past.\"</p> </li> <li> <p>\"I often travel during storms Which means my eyes are often blinded by the rain Many times, I couldn't even see what was right in front of me One day, I finally reached the top of the mountain I looked out with the clouds beneath my feet And only the gentle breeze murmuring in my ears The highest mountain is a clear and enlightened heart Here, there is no self, no hatred, no regrets, and no desires Let's embark on a journey, for I am the breeze We will meet again, no matter how far along the road Life has just begun, and maybe the whole world can be my home\"</p> </li> <li> <p>\"I wander like the autumn leaves that float to the mountains and seas afar.\"</p> </li> <li> <p>\"If an astrologist thinks that their arts can solve all problems, they will be forsaken by the starry ether.  Mona: Their divinations will lose the power to guide, and will not be able to pierce the fog of the unknown before them. Principles are principles.\"</p> </li> <li> <p>\"Haste is indeed a normal part of life, yes... but as we often put it, even a raging river must sometimes flow peacefully through a serene stream.\"</p> </li> <li> <p>\"The forest will remember. No good thing will ever fade away, and all suffering will come to nourish something beautiful...\"</p> </li> <li> <p>\"The battlefield is a treacherous place. Every opportunity you take, you put everything on the line for. If you fear sacrifice and failure, you can never be victorious.\"</p> </li> <li> <p>\"Ningguang: Breakfast sets the tone for the rest of the day. You can't compromise on it.  Ningguang: If you wake up to the same monotonous meal each day, you will start to feel fatigued even before you start working.\"</p> </li> <li> <p>\"Times flies and the good years slip away easily.\"</p> </li> <li> <p>\"Sorry, sorry! It's just that good conversation can be as fleeting as fireworks, sometimes, you know? So when I'm in the mood and I've got a lot to say, I just have to get it all out there in one go and leave no regrets!\"</p> </li> <li> <p>\"Yeah, no matter how close you and your friends are, there's always going to be some distance after being separated for a long time. But as soon as the fireworks lit up the sky, it'd instantly take us right back to our childhood, and we'd be chatting away like in the old days.\"</p> </li> <li> <p>\"Raiden Shogun: My form is a symbol of supreme majesty, in which has been vested power over all the realm. It is the cohesive embodiment of all that constitutes the \"Raiden Shogun.\" Raiden Shogun: It inherits Ei's pain \u2014 the pain of inevitable loss that comes as she moves forward. So too does it inherit her determination to reach eternity.  Raiden Shogun: Every action undertaken is for the sake of resisting erosion.  Raiden Shogun: Determination, courage, love, hatred... All of these will be degraded and distorted by the incessant flow of time.  Raiden Shogun: Only rules shall remain constant for eternity.\"</p> </li> <li> <p>\"Change will come to Inazuma, and with it, new possibilities. This will take time, but eventually, the future will bring healing to the scars of the past.\"</p> </li> <li> <p>\"The people's sacrifice has always caused me immense pain, but in dwelling on the tragedy, I overlooked their splendor... The grief blinded me to how brightly they shone in their final moments.\"</p> </li> <li> <p>\"Jean: Don't worry about it too much. The more flustered you become, the less likely you are to find it.  Jean: Pay attention to what you see in your peripheral vision, and you might just stumble upon what you're looking for.\"</p> </li> <li> <p>\"Stop cooping yourself up in your cabin. Get some of that sea breeze, it'll do you some good.\"</p> </li> <li> <p>\"When people see the object of their dreams, how many are really able to control their desire and follow the contract...?\"</p> </li> <li> <p>\"Drifting seeds are destined to flourish on nice soil... same for Nara! One day, the wind in Nara's hearts will stop, halting their steps.\"</p> </li> <li> <p>\"Don't worry, no memories will be lost! The forest will remember, just like the rivers emptying into the sea, before being turned into the rain splashing down unto the earth.\"</p> </li> <li> <p>\"The adepti leave the human world, find somewhere to go be a hermit, and then they research and invent all these amazing things...\"</p> </li> <li> <p>\"Yep! Work hard, play hard, and rest even harder. The two of you may need even more rest than you'd expect!\"</p> </li> <li> <p>\"Eternity stretches things out over a long time. But each moment within it becomes all the more fragile.\"</p> </li> <li> <p>\"A glutton, this Paimon is. A bite on the mushroom today, another bite tomorrow, and a hundred days later, there shall be no Paimon left in Paimon, but only mushrooms.\"</p> </li> <li> <p>\"A helping hand must see things to the end.\"</p> </li> <li> <p>\"May no regrets linger in the night bygone. May all shadows fade ere the dawn to come.\"</p> </li> <li> <p>\"Xamaran: ...Ignorance might be a blessing, and knowledge might bring forth calamity...  Xamaran: ...Only that which graced with the ambrosia of knowledge can flourish into the strong...  Xamaran: ...Only that which has been tested with the desolation of wandering can brave the wilderness...\"</p> </li> <li> <p>\"Faith doesn't ask for anything in return though, does it?\"</p> </li> <li> <p>\"Dainsleif: It's just my opinion, but a word of advice: Always be on your guard when around gods.  Dainsleif: You shouldn't place too much trust in them. But at the same time, don't go too far in the opposite direction... Don't go trying to overthrow them, or hunt them down.\"</p> </li> <li> <p>\"The ocean is good company... I hope we can all find some peace and happiness while we're here.\"</p> </li> <li> <p>\"Reply: \"Instant gratification has no place in the aesthetics of a wicked dragon! First comes expectation, and then comes patience! Once a dragon's yearning for golden dreams has reached its peak...\" Reply: \"...Ah, then would the taste of those dreams not be splendid beyond compare?\"</p> </li> <li> <p>\" Venti: It is people's shared will that brings them onto the same page. And surely, it is the wind of freedom that brought us together.  Venti: It comes from the end of the journey, the edge of the world, the depths of our heart. It is ceaseless.\"</p> </li> <li> <p>\"Who was it that stroked your bloodied, determined visage By stream flowing small By boulder standing large\" Venti: \"Who was it that embraced your weary yet noble soul In dreams deep In skies soaring\" Venti: \"Dear friend I am leading you by the hand Into the night where lanterns shine bright\" Venti: To tell you a tale of freedom and dreams The tale of where this festival begins\"</p> </li> <li> <p>\"Those who live by the sword know to listen to the voice of their blade. ...Hehe, she's nagging me to get on with it again.\"</p> </li> <li> <p>\"Warriors make friends best when their swords clash, rather than when they talk around a table.\"</p> </li> <li> <p>\"Truly fascinating. The harder they try to silence the situation, the greater the chaos that erupts...\"</p> </li> <li> <p>\"Pale flame, lay waste to this frozen shell and witness my suffering. In fires of sin and retribution, your soul will be incinerated!\"</p> </li> <li> <p>\"In the world of researchers, there's nothing more painful than writing a paper. If there is, it'll be getting stuck writing a paper.\"</p> </li> <li> <p>\"But as a wandering samurai, I find meaning in traveling and the sprawling beauty of nature that lies along the way, while still retaining the \"warrior way\" in my heart.\"</p> </li> <li> <p>\"The part of your journey that lies after the storm may well prove to be the most arduous.\"</p> </li> <li> <p>\"Arana: Arana made little Nara sleep and dream, then removed the bad stuff in their dreams. So when they grow, just like saplings growing into big trees, they won't become bad.  Arana: Otherwise, little Nara would be afraid. If always afraid, they would believe in the power of \"fear,\" and grow up to be scary bad Nara.\"</p> </li> <li> <p>\"The forest will remember. No good thing ever fades away. All pains will become the nourishment of something beautiful...\"</p> </li> <li> <p>\"Press forward and sing, even if the path is filled with flame...\"</p> </li> <li> <p>\"There are those who no longer dream and thus can no longer see us, those who have accepted fate and stopped searching for the way forward, and those who wallow in fear and pain. Their hearts have hardened, unable to get help from these flowers.\"</p> </li> <li> <p>\"Arama: The vegetation that once covered it had all died and been reduced to grains of sand. Just as Marana whispered: All good things must vanish.  Arama: But you should know that as dark as night is, the stars still shine and the sun will still rise. Death longs to dominate all, but life will not fade.  Arama: Just like the yellow leaves that fall down shall nourish Cuihua Trees, their fruits shall sustain Sumpter Beasts, foxes, and forest boars, while they shall feed Rishboland Tigers in turn. And so, the forest always teems with life. Arama: Once, the land wat status s polluted with toxic blood. Like Nara, Aranara too thought that was the end of the world, but now even the memory of it is gone.  The forest is even more luxuriant than it was in the time of Greater Lord Rukkhadevata.  Arama: In the end, all that remains is beautiful. Those who part will come to meet again in Sarva.  Arama: One day, our dreams and memories will intertwine and blossom on the numberless branches in Sarva. Wouldn't that be great?\"</p> </li> <li> <p>\"I believe in you. Like the clouds know they have to release rain, the rain knows that it must fall onto the ground. Meeting all of you made me realize... that the time has finally come. I'm very happy.\"</p> </li> <li> <p>\"Alhaitham: The Akademiya firmly believes that all human actions can be explained through logic.  Alhaitham: By sorting and analyzing entered data, the Akasha can derive behavioral logic, and predict the actions of those who fit an existing logic model.  Alhaitham: However, at the risk of sounding like an advocate for fallacies, can everyone truly be considered \"logical\" at all times?  Alhaitham: Emotions are a part of our behavioral logic. But can you guarantee that every experience of the same joy or pain would be equally intense? How can our feelings and opinions be predictable down to the letter in every single instance?\"</p> </li> <li> <p>\"But this also shows that humanity's worship of gods is a combination of blasphemy and exaltation. It's truly laughable.\"</p> </li> <li> <p>\"Just think about a sheet of paper... By itself, it holds no meaning. The content recorded on it is what gives it value.\"</p> </li> <li> <p>\"Humans are a species that can only find bliss in ignorance.\"</p> </li> <li> <p>\"That is the so-called \"pride\" of a scholar. If someone questions their academic facility, they will instantly feign understanding to keep up appearances.\"</p> </li> <li> <p>\"You all can only see the world in your mind, the one you think you know.\"</p> </li> <li> <p>\"Nahida: To me, everything we perceive in this world, everything we learn, and everything that happens to us is considered knowledge.  Nahida: And if it's a form of knowledge, then it can be understood.  Nahida: However, only fate is about that which has yet to occur, so it has always drawn my curiosity. Nahida: So to me, \"fate\" is the ultimate knowledge.  Nahida: That's also why I love observing humans and all the things that happen to them. It all brings me great satisfaction.  Nahida: And now, at long last, I'm not just an observer anymore.  Nahida: I will personally experience my own fate, with you by my side. Hehe, isn't this such a wonderfully exciting thing?\"</p> </li> <li> <p>\"Don't worry. The growth of wisdom is like that of a plant \u2014 you only need to wait quietly for the flower to bloom.\"</p> </li> <li> <p>\"We all nestle under the great tree of wisdom, peering out to perceive the world. From the earth, and from the rain, we perceive its wonders until we become a white bird to perch atop a branch... And finally snap off the most important leaf. Once upon a time, I alone dreamed in this world. In my dreams, everybody would also dream after they fell asleep. Wild and wonderful thoughts would emerge from their minds. Some tumbled to the ground, and others floated to the sky. Connecting all things in the world into one dazzling net. Amongst the plethora of worlds were numerous smaller worlds. All of fate finding within the tapestry their brilliant glow. I gradually understood that these indescribable and constantly changing things Are the most profound things in the world. Only they can completely repel the madness. Only dreams can awaken consciousness from the deepest darkness. I'm the one who posed this question, yet also the one who sought a solution Saving the world with the dreams of the people used to be my answer. And now you've also found your own answer. And I shall return all the dreams to the people. Goodbye, people of Sumeru. May you be blessed tonight with the sweetest of dreams.\"</p> </li> <li> <p>\"As a scholar, I respect all possibilities. This has always been my principle and is an essential trait as an experimenter.\"</p> </li> <li> <p>\"The stars have always guided caravans, thieves, soldiers, and travelers who get lost in the night. They lead those in the dark out of trouble and back to safety.\"</p> </li> <li> <p>\" Yae Miko: The bane of our existence: \"writer's block.\" It's your arch-nemesis for life, appearing without warning and inflicting a pain worse than death upon the writer. They sell their souls just to get their muse back.  Paimon: Sounds awful.  Yae Miko: When this happens, the best thing you can do is have a bite to eat and take a proper break.\"</p> </li> <li> <p>\"Sigh. I learned most of my socializing from books that were beyond my grade level and as a result had difficulty connecting with my peers.\"</p> </li> <li> <p>\"Yeah autism makes me not know how to respond to social prompts and adhd quickly makes connections out of things so I usually respond with something witty or funny or fun because of it.\"</p> </li> <li> <p>\"The road to hell is paved with good intentions.\"</p> </li> <li> <p>\"Nothing vast enters the life of mortals without a curse\"</p> </li> <li> <p>\"If you are not paying for the product, then you are the product.\"</p> </li> <li> <p>\"There are only two industries that call their customers users - illegal drugs and software\"</p> </li> <li> <p>\"Researchers are like children, always re-discovering things that are already known and make a big deal out of it.\"</p> </li> <li> <p>\"Are you the kind of guy who is so hung up on being nice he never really thinks about other people\"</p> </li> <li> <p>\"Like did you ever tell anyone how you felt did you ever ask them not to do something did you explain what was wrong and try to help resolve it?  No offense but it kind of seems like you always just expected people to know how you felt and to treat you right just because you were nice.  Another brief pause filled the space between them I mean I just don't like arguing or being mean or confrontational for no reason especially when people should kind of already know what's right.  Yeah but how does anyone know of a problem if the problem is hidden from them and why would anyone want to solve it if it benefits them and the other person doesn't seem to care.  I don't think niceness is always kind because kindness is not quietness, submissiveness or self-surrender.  I think it's the willingness to confront and deal with others and issues honestly and fairly for everyone's benefit even when it's difficult or uncomfortable for you\"</p> </li> <li> <p>\"To be autistic with ADHD is a huge contradiction. What one part of me wants the other cannot bear. Solitude, separation, quiet and stability, community, connection, busyness, and change. I have to try to find a way to balance the right amount of each or I\u2019ll be on the path to falling apart again. \"</p> </li> <li> <p>\"I don\u2019t think niceness is always kind\"</p> </li> <li> <p>\"Enthusiasm can become self sabotage\"</p> </li> <li> <p>\"The only gods out here are the odds\"</p> </li> <li> <p>\"The muse is shy. She wants to be seen but not stared at. If you expect too much, its like a date and she just wont show up.\u201d</p> </li> <li> <p>\"It's said that the gods favor fools as they were more entertaining to watch.\"</p> </li> <li> <p>\"You can't spell self assurance without ass\"</p> </li> <li> <p>\"We give too much attention to the glorified few claiming what they\u2019ve done have changed the world. There\u2019s some truth to that. But there are many many others, quietly, doing their best in their capacity to make the world a better place, asking very little in return. So at this holiday season, I\u2019d like to say</p> </li> <li> <p>thank you. When building a machine learning model, we can rely on a few strong features, but an ensemble of weak learners can be more performant and robust, but each one of them don\u2019t necessarily get the credits they deserve.\"</p> </li> <li> <p>\"Being enthusiastic is worth 25 IQ points.\"</p> </li> <li> <p>\"Always demand a deadline. A deadline weeds out the extraneous and the ordinary. It prevents you from trying to make it perfect, so you have to make it different. Different is better.\u201d</p> </li> <li> <p>\"Don\u2019t be afraid to ask a question that may sound stupid because 99% of the time everyone else is thinking of the same question and is too embarrassed to ask it.\u201d</p> </li> <li> <p>\"A worthy goal for a year is to learn enough about a subject so that you can\u2019t believe how ignorant you were a year earlier.\u201d</p> </li> <li> <p>\"Pros are just amateurs who know how to gracefully recover from their mistakes.</p> </li> <li> <p>\"Extraordinary claims should require extraordinary evidence to be believed.\u201d</p> </li> <li> <p>\"Don\u2019t take it personally when someone turns you down. Assume they are like you: busy, occupied, distracted. Try again later. It\u2019s amazing how often a second try works.\u201d</p> </li> <li> <p>\"The purpose of a habit is to remove that action from self-negotiation. You no longer expend energy deciding whether to do it. You just do it. Good habits can range from telling the truth, to flossing.\u201d</p> </li> <li> <p>\"Promptness is a sign of respect.\u201d</p> </li> <li> <p>\"To make something good, just do it. To make something great, just re-do it, re-do it, re-do it. The secret to making fine things is in remaking them.\u201d</p> </li> <li> <p>\"If you are looking for something in your house, and you finally find it, when you\u2019re done with it, don\u2019t put it back where you found it. Put it back where you first looked for it.\u201d</p> </li> <li> <p>\"Separate the processes of creation from improving. You can\u2019t write and edit, or sculpt and polish, or make and analyze at the same time. If you do, the editor stops the creator. While you invent, don\u2019t select. While you sketch, don\u2019t inspect. While you write the first draft, don\u2019t reflect. At the start, the creator mind must be unleashed from judgement.\u201d</p> </li> <li> <p>\"You are what you do. Not what you say, not what you believe, not how you vote, but what you spend your time on.\u201d</p> </li> <li> <p>\"Be prepared: When you are 90% done any large project (a house, a film, an event, an app) the rest of the myriad details will take a second 90% to complete.\u201d</p> </li> <li> <p>\"Before you are old, attend as many funerals as you can bear, and listen. Nobody talks about the departed\u2019s achievements. The only thing people will remember is what kind of person you were while you were achieving.\u201d</p> </li> <li> <p>\"For every dollar you spend purchasing something substantial, expect to pay a dollar in repairs, maintenance, or disposal by the end of its life.\u201d</p> </li> <li> <p>\"Anything real begins with the fiction of what could be. Imagination is therefore the most potent force in the universe, and a skill you can get better at. It\u2019s the one skill in life that benefits from ignoring what everyone else knows.\u201d</p> </li> <li> <p>\"On vacation go to the most remote place on your itinerary first, bypassing the cities. You\u2019ll maximize the shock of otherness in the remote, and then later you\u2019ll welcome the familiar comforts of a city on the way back.\u201d</p> </li> <li> <p>\"When you get an invitation to do something in the future, ask yourself: would you accept this if it was scheduled for tomorrow? Not too many promises will pass that immediacy filter.\u201d</p> </li> <li> <p>\"Art is in what you leave out.\u201d</p> </li> <li> <p>\"Rule of 7 in research. You can find out anything if you are willing to go seven levels. If the first source you ask doesn\u2019t know, ask them who you should ask next, and so on down the line. If you are willing to go to the 7th source, you\u2019ll almost always get your answer.\u201d</p> </li> <li> <p>\"Most really amazing or great things are done by people doing them for the first time.\u201d</p> </li> <li> <p>\"The universe is conspiring behind your back to make you a success. This will be much easier to do if you embrace this pronoia.\u201d</p> </li> <li> <p>\"It\u2019s not an apology if it comes with an excuse. It is not a compliment if it comes with a request\u201d</p> </li> <li> <p>\"Only imperfect beings can make art because art begins in what is broken.\u201d</p> </li> <li> <p>\"If someone is trying to convince you it\u2019s not a pyramid scheme, it\u2019s a pyramid scheme.\u201d</p> </li> <li> <p>\"The reward for good work is more work.\u201d</p> </li> <li> <p>\"The foundation of maturity: Just because it\u2019s not your fault doesn\u2019t mean it\u2019s not your responsibility.\u201d</p> </li> <li> <p>\"You are only as young as the last time you changed your mind.\u201d</p> </li> <li> <p>\"The worst evils in history have always been committed by those who truly believed they were combating evil. Beware of combating evil.\u201d</p> </li> <li> <p>\"Don\u2019t loan money to a friend unless you are ready to make it a gift\u201d</p> </li> <li> <p>\"If you can\u2019t tell what you desperately need, it\u2019s probably sleep.\u201d</p> </li> <li> <p>\"When playing Monopoly, spend all you have to buy, barter, or trade for the Orange properties. Don\u2019t bother with Utilities.\u201d</p> </li> <li> <p>\"If you borrow something, try to return it in better shape than you received it. Clean it, sharpen it, fill it up\u201d</p> </li> <li> <p>\"To quiet a crowd or a drunk, just whisper.\u201d</p> </li> <li> <p>\"You are given the gift of life in order to discover what your gift in life is. You will complete your mission when you figure out what your mission is. This is not a paradox. This is the way.\u201d</p> </li> <li> <p>\"Don\u2019t treat people as bad as they are. Treat them as good as you are.\u201d</p> </li> <li> <p>\"We are not bodies that temporarily have souls. We are souls that temporarily have bodies.\u201d</p> </li> <li> <p>\"If your goal does not have a schedule, it is a dream.\u201d</p> </li> <li> <p>\"The greatest breakthroughs are missed because they look like hard work.\u201d</p> </li> <li> <p>\"People can\u2019t remember more than 3 points from a speech.\u201d</p> </li> <li> <p>\"Many backward steps are made by standing still.\u201d</p> </li> <li> <p>\"You don\u2019t marry a person, you marry a family.\u201d</p> </li> <li> <p>\"When making something, always get a few extras \u2014 extra material, extra parts, extra space, extra finishes. The extras serve as backups for mistakes, reduce stress, and fill your inventory for the future. They are the cheapest insurance.\u201d</p> </li> <li> <p>\"To combat an adversary, become their friend.\u201d</p> </li> <li> <p>\"Take one simple thing \u2014 almost anything \u2014 but take it extremely seriously, as if it was the only thing in the world, or maybe the entire world is in it \u2014 and by taking it seriously you\u2019ll light up the sky.\u201d</p> </li> <li> <p>\"Advice like these are not laws. They are like hats. If one doesn\u2019t fit, try another.\u201d</p> </li> <li> <p>\"Painting is complete as a distraction. I know of nothing which, without exhausting the body, more entirely absorbs the mind.\u201d</p> </li> <li> <p>\"This beginning with Audacity, or being thrown into the middle of it, is already a very great part of the art of painting.\"</p> </li> <li> <p>\"Painting a picture is like trying to fight a battle.\"</p> </li> <li> <p>\"Painting is the same kind of problem as unfolding a long, sustained interlocked argument... It is a proposition commanded by a single unity of conception.\"</p> </li> <li> <p>\"Go out into the sunlight and be happy with what you see.\"</p> </li> <li> <p>\"We cannot aspire to masterpieces. We may content ourselves with a joy ride in a paint-box. And for this Audacity is the only ticket.\u201d</p> </li> <li> <p>\"The profoundest eternal questions are met only with a boundless and eternal silence.\"</p> </li> <li> <p>\"These things happen, honey. I'll tell you what I do. I have a little cry, then I pick myself up, dust myself off and keep going. The show must go on!\"</p> </li> <li> <p>\"When you try to be nice to everyone, you're not being nice to anyone\"</p> </li> <li> <p>\"Zhongli was corroded by time. Pain and suffering he saw and maybe even did gave him wisdom.  Cloud Retainer was most likely hardy and stubborn, but she too became corroded over time, becoming more like stone, not revealing how she feels to anyone.  Madame Ping always tried to see the beauty in things and loved her ways. But over time she realized everything is beautiful in its own right. Her wisdom is that she learned to cherish every moment.\"</p> </li> <li> <p>\"We think of human life as like a lantern that's lit one minute and extinguished the next.\"</p> </li> <li> <p>\"In the perpetual meantime of a sheltered eternity, most are content to live and not to dream. But in the hidden corners where the Gods' gaze does not fall, there are those who dream of dreaming. Some say a few are chosen and the rest are dregs, but I say we humans have our humanity. We will defy this world with a power from beyond.\"</p> </li> <li> <p>\"Though flowers bloom yet always fade, but people go yet return another day. I just knew that you'd be back to see me before long, hehe.\"</p> </li> <li> <p>\"Truth be told, the older you get, the more time you have on your hands, and the more you start contemplating the past... I do wonder how my old friends back in the mountains are getting on..\"</p> </li> <li> <p>\"For us desert people, this is an inescapable fate. We come from the soil and return to the sand. It is a simple matter of being born and dying.\"</p> </li> <li> <p>\"Pitiful child... How can one envisage paradise's shape without ever having feasted one's eyes upon it?\"</p> </li> <li> <p>\"O stars high above the wasteland, O nightingales weary from the day, It's time to take off your crowns of roses, Cleanse yourself with wine made from grapes.  Sleep, sleep.  The eternal oasis welcomes the lonely wanderer, And here the crisp springs flow, And the memories are forever sweet.  Sleep, sleep. Yon golden slumber summons thee, wandering sand, Drink not that bitter salt water, For the sorrows of tomorrow have gone away.\"</p> </li> <li> <p>\"A little get-together between friends, sipping the finest tea, and watching lanterns float into the sky. Bidding farewell to the past, and embracing the present with joy.\"</p> </li> <li> <p>\"The same truth will sound different coming from different people. As more bear witness to a story, feelings and interpretations expand in variety too.\"</p> </li> <li> <p>\"Madame Ping: Times change, and the music enjoyed by the youngsters of today is, no doubt, very different from the tunes I was accustomed to in my youth. Nevertheless, all fine things in life can be appreciated.\"</p> </li> <li> <p>\"The sky you yearn for is yet another abyss\"</p> </li> <li> <p>\"Sometimes the only way to experience the beauty of things is to think of them in a beautiful way.\"</p> </li> <li> <p>\"Only when we hold our breath and try to keep all the oxygen in, do we suffocate.\"</p> </li> <li> <p>\"Do not seek to follow in the footsteps of the wise; seek what they sought.\"</p> </li> <li> <p>\"The truth doesn\u2019t change according to your ability to stomach it.\"</p> </li> <li> <p>\"If you tidy up in one shot, rather than little by little, you can dramatically change your mind-set\"</p> </li> <li> <p>\"Don't aim for perfection. Start off slowly and discard just one item a day.\" What lovely words to ease the hearts of those who lack confidence in their ability to tidy.\"</p> </li> <li> <p>\"Many people get the urge to clean up when under pressure, such as just before an exam. But this urge doesn't occur because they want to clean their room. It occurs because they need to put \"something else\" in order. Their brain is actually clamoring to study, but when it notices the cluttered space, the focus switches to \"I need to clean up my room.\" The fact that the tidying urge rarely continues once the crisis is over proves my theory. Once the exam has ended, the passion poured into cleaning the previous night dissipates and life returns to normal. All thought of tidying is wiped from the person's mind. Why? Because the problem faced\u2014that is, the need to study for the exam\u2014has been \"tidied away.\"</p> </li> <li> <p>\"When a room becomes cluttered, the cause is more than just physical. Visible mess helps distract us from the true source of the disorder. The act of cluttering is really an instinctive reflex that draws our attention away from the heart of an issue.\"</p> </li> <li> <p>\"I have a habit of trying to categorize everything, probably because I have spent so much time pondering how to organize\"</p> </li> <li> <p>\"I came to the conclusion that it makes far more sense to categorize people by their actions rather than by some generalized personality trait.\"</p> </li> <li> <p>\"It's easy to get rid of things when there is an obvious reason for doing so. It's much more difficult when there is no compelling reason\"</p> </li> <li> <p>\"focusing solely on throwing things away can only bring unhappiness. Why? Because we should be choosing what we want to keep, not what we want to get rid of.\"</p> </li> <li> <p>\"Repetition and wasted effort can kill motivation, and therefore it must be avoided.\"</p> </li> <li> <p>\"The process of deciding what to keep and what to discard will go much more smoothly if you begin with items that are easier to make decisions about. As you gradually work toward the harder categories, you will be honing your decision-making skills. Clothes are the easiest because their rarity value is extremely low. Photographs and letters, on the other hand, not only have a high sentimental value but also are one of a kind; therefore, they should be left until last. This is true for photographs, in particular, because they tend to turn up at random while sorting through other categories and in the most unexpected places, such as between books and papers. The best sequence is this: clothes first, then books, papers, komono (miscellany), and lastly, mementos.\"</p> </li> <li> <p>\"There's nothing wrong with tidying. However, it's extremely stressful for parents to see what their children discard. The sheer volume of the pile can make parents anxious about whether their children can survive on what's left. In addition, despite knowing that they should rejoice at their child's independence and maturity, parents can find it very painful to see clothes, toys, and mementos from the past on the rubbish heap, especially if they are things they gave to their child. Keeping your garbage out of sight is considerate. It also protects your family from acquiring more than they need or can enjoy.\"</p> </li> <li> <p>\"The urge to point out someone else's failure to tidy is usually a sign that you are neglecting to take care of your own space.\"</p> </li> <li> <p>\"There are two reasons why younger sisters tend to collect clothes they don't really like. One is that it's hard to get rid of something received from family. The other is that they don't really know what they like, which makes it hard to decide whether they should part with it. Because they receive so much clothing from others, they don't really need to shop and therefore they have less opportunity to develop the instinct for what really inspires joy.\"</p> </li> <li> <p>\"You're right. There is still a little kid inside me, trembling with anxiety, unable to be loved. And he is pleading with me not to ignore him anymore. All this time, I made myself too busy worrying about the opinions of others while suppressing the inner wound from the past. I need to believe that I am worthy of love for who I am.\"</p> </li> <li> <p>\"Even if you never achieve anything big and significant, to me, your existence alone is already enough.\"</p> </li> <li> <p>\"use them whenever you get the chance. Special moments are not separate from our everyday lives. When you make use of something special, it makes the moment special.\"</p> </li> <li> <p>\"People sometimes express their longing through hate.\"</p> </li> <li> <p>\"Lengthy deliberation often leads to a terrible decision.\" If you think and worry too much before doing something, \"your boat goes to the mountain instead of the ocean.\" Now and then it is necessary\"</p> </li> <li> <p>\"Being alone makes the world pause for a moment and helps to restore harmony.\"</p> </li> <li> <p>\"When someone you love is in pain, the most meaningful gift you can give is your kind presence.\"</p> </li> <li> <p>\"We live longer now not because we do not get sick, but because we have learned to manage our illness.\"</p> </li> <li> <p>\"Some people come into our lives and quickly go. Some stay for a while and leave footprints on our hearts, and we are never, ever the same.\"</p> </li> <li> <p>\"The greatest gift that parents can give their child is to be happy themselves. If the parents are happy, then the child can grow up into a happy and confident adult. But if the parents are not happy, then the child can feel worthless\u2014 unable to make his parents happy no matter what. *\"</p> </li> <li> <p>\"Look back and see if you deluded yourself into believing that being obsessed with your children was a sacrifice. And consider whether your \"sacrifice\" did not rob your children of the opportunity to learn for themselves\"</p> </li> <li> <p>\"Children want to admire their parents. You won't win their admiration by being overprotective.\"</p> </li> <li> <p>\"Do not lose your grip on the reins of your own life and allow yourself to be dragged around by someone else.\"</p> </li> <li> <p>\"If we combine painful memories, the need for attention, and pride, the relationship can easily be ruined.\"</p> </li> <li> <p>\"Love needs no reason other than love itself\"</p> </li> <li> <p>\"When your self-esteem hits rock bottom, say to yourself: \"To my family and close friends, I'm just as precious as I've always been. I'm still capable of doing good in the world; a few people who don't really know me don't get to decide what I'm worth. In time, I believe I'll meet different people who will value me and my abilities.\"</p> </li> <li> <p>\"Though it comes from a good place, doing what you think someone needs can be the seed of wanting to control them, to make them a certain way to please yourself.\"</p> </li> <li> <p>\"With a little planning, you can continue to enjoy your life while looking after someone close to you. Sacrificing yourself completely won't be good in the long run,\"</p> </li> <li> <p>\"Change will last longer when it's not forced but when it comes about because they have been convinced of its need.\"</p> </li> <li> <p>\"If we think of the child as a stranger, we focus on the inconvenience to ourselves, but if we think of the child as a family member, we become merciful,\"</p> </li> <li> <p>\"If you take home a cat and care for it, even one that's been abandoned and is dirty, it won't be long before it becomes the cutest cat in the world.\"</p> </li> <li> <p>\"MAYBE YOU'VE HEARD it said that each time someone embraces you warmly, your life is extended by one more day?\"</p> </li> <li> <p>\"Though I am lacking in many ways, I want to be a person who can bring some small comfort to people, who can give them courage, like a ray of warm sunshine. If there is someone who needs a hug from me, I will do it willingly, gladly, and as often as they need.\"</p> </li> <li> <p>\"Because I have experienced pain, I am able to embrace the pain of others. Because I have made mistakes, I am able to forgive others their mistakes. May my suffering become the seed of compassion\"</p> </li> <li> <p>\"There are those who love you for who you are, and there are those who love you for what you do. There is no change in the love of those who love you for who you are, even when you make a mistake or fail. Such people are your true friends and family.\"</p> </li> <li> <p>\"When someone is tired, bring them a cup of herbal tea and just leave them be.\"</p> </li> <li> <p>\"Words can become the seed of reality.\"</p> </li> <li> <p>\"To a student monk, books are like the bread we eat or the air we breathe.\"</p> </li> <li> <p>\"I wish to be generous to the younger generation like they were to me.\"</p> </li> <li> <p>\"Listening openly, patiently, and attentively is one of the most significant expressions of love.\"</p> </li> <li> <p>\"I think this has to do with the fact that we want someone to listen to what we have to say, even if that someone is the impersonal online world.\"</p> </li> <li> <p>\"Children are eager to show off their scars because they like to receive loving attention from others.\"</p> </li> <li> <p>\"When we think we already know someone, we stop making an effort to know them better. When we do not know someone, we make an effort to get to know them. Love is the state of not knowing, and of wanting to know more.\"</p> </li> <li> <p>\"I saw an advertisement saying, \"People are like heaters.\" Our presence can warm each other. May you be a heater for someone today.\"</p> </li> <li> <p>\"Big world, some weirdos!\"</p> </li> <li> <p>\"All that pointless anguish over such a simple task; I could have done it without getting so worked up.\"</p> </li> <li> <p>\"WHAT DISTRESSES US IS LESS the circumstances we find ourselves in and more the energy we expend in resisting them. Once we actually do the work, we are often surprised that it was not as hard as we imagined it to be. But when we resist, we become preoccupied by an endless cycle of negative thoughts, and in turn feel harried and stressed.\"</p> </li> <li> <p>\"A person's behavior might not be motivated by any particular thought or feeling,\"</p> </li> <li> <p>\"In this fast-paced world, where so much gets done immediately, when you have to wait long enough for anticipation to build, the moment with that person will be very special.\"</p> </li> <li> <p>\"While love lets the other person be, obsession wants control.\"</p> </li> <li> <p>\"In other words, a feeling of disappointment is like a warning light, telling me that if I don't do something about it, the relationship could fail.\"</p> </li> <li> <p>\"Mastering more skills means that you will have a smoother road than the others\"</p> </li> <li> <p>\"So, Lang Ga and Ge both agreed on the theory that you should keep it going even when being yelled at like hell. You should grasp the opportunity and try to learn as much as possible. It's best to absorb all your master's skills!\"</p> </li> <li> <p>\"When you want to learn things from someone, you must acquire many qualities, and having no sense of shame must be the most important quality of yours.\"</p> </li> <li> <p>\"Old Ke said that every stone had its own story, and even the most excellent stoneware crafter might not be able to understand all stones' stories.\"</p> </li> <li> <p>\"After you catch something, you have to examine it first to see if it's ill. For example, that animal we caught earlier had uncolored eyes and bald spots in his fur. If you cut it open, you would smell a funny smell from its meat. Even if the prey lived, it wouldn't be alive for long. Any warrior would share its fate if he ate its meat.\"</p> </li> <li> <p>\"There was a saying, that the monkey reigns in the mountains when the tiger is absent.\"</p> </li> <li> <p>\"All earth returns to the mansion while all water belongs to the gully. Insects do not labor, by the blessing of nature\u2026\u2026\"</p> </li> <li> <p>\"Altering people's minds should always start with kids\"</p> </li> <li> <p>\"Shao Xuan had heard from someone that the earliest form of humans showing their feelings was through body movements and dancing gestures. Dance and moves were also a certain language of people expressing their passions and desires.\"</p> </li> <li> <p>\"They say that genius is an infinite capacity for taking pains,\"</p> </li> <li> <p>\"One's ideas must be as broad as Nature if they are to interpret Nature,\"</p> </li> <li> <p>\"I ought to know by this time that when a fact appears to be opposed to a long train of deductions, it invariably proves to be capable of bearing some other interpretation.\"</p> </li> <li> <p>\"It's interesting how a random event can change our lives in ways that would be impossible to imagine, isn't it?\"</p> </li> <li> <p>\"After Susie had been diagnosed, that excitement had dulled, but he'd soldiered on, somehow managing to continue to be all things to all people\u2014to their daughter, to her, to the other kids and parents. The question of what he'd left for himself sometimes kept her awake at night.\"</p> </li> <li> <p>\"Sweet or not, it's water from home\"</p> </li> <li> <p>\"When all phenomena are reduced to truth they follow a single pattern; Like the Tathagatha reaching nirvana under the two trees.\"</p> </li> <li> <p>\"If you try to ask about the dhyana Chapter 8 99 Journey to the West Or investigate the innumerable You will waste your life and achieve nothing.\"</p> </li> <li> <p>\"Polishing bricks to make mirrors, Or piling up snow to turn it into grain\u2212\u2212 However many years have you wasted like that? A hair can contain an ocean, A mustard\u2212seed can hold a mountain, And the golden Kasyapa only smiles. When you are awakened you will surpass the Ten Stages and the Three Vehicles, And stop the four kinds of birth and the six types of reincarnation.\"</p> </li> <li> <p>\"The meditating heart shines like the moon in a thousand rivers; The true nature embraces ten thousand miles of sky.\"</p> </li> <li> <p>\"If you want to have a future, don't do anything with no future in it?\"</p> </li> <li> <p>\"Brother Li,\" said Zhang Shao, \"it seems to me that people who struggle for fame kill themselves for it; those who compete for profit die for it; those who accept honors sleep with a tiger in their arms; and those who receive imperial favours walk around with snakes in their sleeves. Taking all in all, we are much better off living free among our clear waters and blue hills: we delight in our poverty and follow our destinies.\"</p> </li> <li> <p>\"An axe well honed on rock is sharper than a spear.\"</p> </li> <li> <p>\"He who does good in secret can always prolong his life; Heaven looks after the one who asks no pity.\"</p> </li> <li> <p>\"There is an Indian story about a grain of salt that wanted to know just how salty the ocean is, so it jumped in and became one with the water of the ocean.\"</p> </li> <li> <p>\"This is, because that is. This is not, because that is not. This is like this, because that is like that.\"</p> </li> <li> <p>\"The wealth of one society is made of the poverty of the other.\"</p> </li> <li> <p>\"It was just a computer. If you didn't keep that thought firmly in your mind it was too easy to start thinking of it as human, and that was the first step toward forgetting.\"</p> </li> <li> <p>\"He had created in passion, and passion isn't sane. If it were, nobody would ever have children. After all, while the outcome of that passion might be the doctor who cures a dreaded disease, it might also be the tyrant who despoils a continent or the criminal who murders for pleasure. In the grip of that passion no one could know and few bothered to care. They cared only about the passion, were driven by it and it alone, and if it drove them to ruin it would not matter; they would follow it again, into death for themselves and everybody around them if that was where it led. Because passion isn't sane.\"</p> </li> <li> <p>\"The Buddha is silent on that, and his silence implies that you'll have to find out for yourself. He uses a negative definition so that the mind cannot make it into something to believe in or into a superhuman accomplishment, a goal that is impossible for you to attain.\"</p> </li> <li> <p>\"The word God has become a closed concept. The moment the word is uttered, a mental image is created, no longer, perhaps, of an old man with a white beard, but still a mental representation of someone or something outside you, and, yes, almost inevitably a male someone or something.\"</p> </li> <li> <p>\"The compulsive thinker, which means almost everyone, lives in a state of apparent separateness, in an insanely complex world of continuous problems and conflict, a world that reflects the ever- increasing fragmentation of the mind.\"</p> </li> <li> <p>\"A belief may be comforting. Only through your own experience, however, does it become liberating.\"</p> </li> <li> <p>\"The beginning of freedom is the realization that you are not the possessing entity the thinker. Knowing this enables you to observe the entity. The moment you start watching the thinker, a higher level of consciousness becomes activated\"</p> </li> <li> <p>\"One day you may catch yourself smiling at the voice in your head, as you would smile at the antics of a child. This means that you no longer take the content of your mind all that seriously, as your sense of self does not depend on it.\"</p> </li> <li> <p>\"Every time you create a gap in the stream of mind, the light of your consciousness grows stronger.\"</p> </li> <li> <p>\"Thinking and consciousness are not synonymous. Thinking is only a small aspect of consciousness. Thought cannot exist without consciousness, but consciousness does not need thought.\"</p> </li> <li> <p>\"An emotion usually represents an amplified and energized thought pattern, and because of its often overpowering energetic charge, it is not easy initially to stay present enough to be able to watch it. It wants to take you over, and it usually succeeds unless there is enough presence in you.\"</p> </li> <li> <p>\"Basically, all emotions are modifications of one primordial, undifferentiated emotion that has its origin in the loss of awareness of who you are beyond name and form. Because of its undifferentiated nature, it is hard to find a name that precisely describes this emotion. \"Fear\" comes close, but apart from a continuous sense of threat, it also includes a deep sense of abandonment and incompleteness. It may be best to use a term that is as undifferentiated as that basic emotion and simply call it \"pain.\" One of the main tasks of the mind is to fight or remove that emotional pain, which is one of the reasons for its incessant activity, but all it can ever achieve is to cover it up temporarily. In fact, the harder the mind struggles to get rid of the pain, the greater the pain. The mind can never find the solution, nor can it afford to allow you to find the solution, because it is itself an intrinsic part of the \"problem.\"</p> </li> <li> <p>\"Pleasure is always derived from something outside you, whereas joy arises from within. The very thing that gives you pleasure today will give you pain tomorrow, or it will leave you, so its absence will give you pain. And what is often referred to as love may be pleasurable and exciting for a while, but it is an addictive clinging, an extremely needy condition that can turn into its opposite at the flick of a switch.\"</p> </li> <li> <p>\"If we address stories as archaeological sites, and dust through their layers with meticulous care, we find at some level there is always a doorway. A dividing point between here and there, us and them, mundane and magical. It is at the moments when the doors open, when things flow between the worlds, that stories happen.\"</p> </li> <li> <p>\"I say \"amateur\" only because it was fashionable for wealthy men to refer to their passions in this dismissive way, with a little flick of their fingers, as if admitting to a profession other than moneymaking might sully their reputations.\"</p> </li> <li> <p>\"On the third day, my room became a cell, which became a cage, which became a coffin, and I discovered the very deepest fear that swam through my heart like eels in undersea caves: to be locked away, trapped and alone.\"</p> </li> <li> <p>\"His expression as he surveyed me made me think of old-timey illustrations of God: severely paternal, bestowing the kind of love that weighs and measures before it finds you worthy. His eyes were stones, pressing down. \"You are going to mind your place and be a good girl.\"</p> </li> <li> <p>\"It's stupid to think things like that. It just gives you this hollow, achy feeling between your ribs, like you're homesick even though you're already home, and you can't read your magazine anymore because the words are all warped and watery-looking.\"</p> </li> <li> <p>\"Words and their meanings have weight in the world of matter, shaping and reshaping realities through a most ancient alchemy. Even my own writings\u2014so damnably powerless\u2014may have just enough power to reach the right person and to tell the right truth, and change the nature of things.\"</p> </li> <li> <p>\"Second, my long years of research have taught me that all stories, even the meanest folktales, matter. They are artifacts and palimpsests, riddles and histories. They are the red threads that we may follow out of the labyrinth.\"</p> </li> <li> <p>\"You see, doors are many things: fissures and cracks, ways between, mysteries and borders. But more than anything else, doors are change. When things slip through them, no matter how small or brief, change trails them like porpoises following a ship's wake. The change had already taken hold of Adelaide Lee, and she could not turn away.\"</p> </li> <li> <p>\"His books have been translated into 59 languages and published in 150 countries. He is also the recipient of numerous prestigious international awards, among them the Crystal Award by the World Economic Forum, France's Chevalier de l'Ordre National de la L\u00e9gion d'Honneur\"</p> </li> <li> <p>\"What man of you, having an hundred sheep, if he lose one of them doth not leave the ninety and nine in the wilderness, and go after that which is lost, until he find it\"</p> </li> <li> <p>\"Buying more had failed to make them happier. In fact, it was entrapping them, and they needed to find a new relationship to their possessions, usually by throwing most of them out.\"</p> </li> <li> <p>\"As the architect Pier Vittorio Aureli writes, the \"less is more\" attitude can be a form of capitalist exploitation, encouraging workers to produce more while getting by with less, creating more profit for their bosses at the cost of their own quality of life.\"</p> </li> <li> <p>\"I began thinking of this universal feeling as the longing for less. It's an abstract, almost nostalgic desire, a pull toward a different, simpler world. Not past nor future, neither utopian nor dystopian, this more authentic world is always just beyond our current existence in a place we can never quite reach. Maybe the longing for less is the constant shadow of humanity's self-doubt: What if we were better off without everything we've gained in modern society?\"</p> </li> <li> <p>\"The minimalist blogger Joshua Becker, an evangelical Christian and author of The More of Less, published in 2016, proposes Jesus as the original minimalist. When he instructed a rich man to \"sell everything you own and give it away to the poor,\" the commandment wasn't about self-sacrifice, according to Becker. It meant that the rich man would be happier without the possessions, so giving them away was a net gain\u2014a kind of minimalist prosperity gospel.\"</p> </li> <li> <p>\"Minimalism is thus a kind of last resort. When we can't control our material security or life path, the only possibility left is to lower our expectations to the point where they're easier to achieve, which could mean living in a train car, or a camper van.\"</p> </li> <li> <p>\"We like to think that we can do without, rough it to prove that we're not so soft or bound to the past.\"</p> </li> <li> <p>\"That's the whole meaning of life,9 isn't it\u2014just trying to find a place to put your stuff.\")\"</p> </li> <li> <p>\"Minimalism's lack of a coherent history is in part due to its nature\u2014it instinctively tends to erase its own background, as if starting anew in each iteration. If its practitioners admitted to being referential or reviving a past tradition, they wouldn't seem so radically minimal after all.\"</p> </li> <li> <p>\"Material simplicity will thus likely be manifest in consumption styles that are less ascetic \u2026 and more aesthetic,\" Elgin wrote\u2014in other words, not Spartan but stylized.\"</p> </li> <li> <p>\"He predicted the social media era's obsession with curated authenticity, the kind that we see displayed on Instagram accounts: \"Each person will consider whether his or her level and pattern of consumption fits, with grace and integrity,\"</p> </li> <li> <p>\"We take pride in the small details that we have actually chosen from our limited options, which might make us feel better about not being able to change our circumstances as a whole.\"</p> </li> <li> <p>\"When workers are separated from the products of their labor and compensated by an hourly wage, they can't find satisfaction in their jobs or the remainder of family life. Thus they turn to acquiring capital as the only form of self-fulfillment. We work only to accumulate stuff and in turn the accumulated stuff dominates us, further distancing us from non-commodified things like relationships, joy, and community.\"</p> </li> <li> <p>\"Labor \"is therefore not the satisfaction of a need, but only a means for satisfying needs external to it,\"</p> </li> <li> <p>\"The less you are,12 the less you express your own life, the more you have,\" Marx argued, \"the greater is your alienated life, the greater is the store of your estranged being.\"</p> </li> <li> <p>\"Stuff is therefore the enemy of happiness, and not just because it's crowding your apartment, but because it's part of this larger alienating system.\"</p> </li> <li> <p>\"The need for simplicity, taken to an extreme, can wipe function away entirely.\"</p> </li> <li> <p>\"We're taking advantage of a maximalist assemblage. Just because something looks simple doesn't mean it is; the aesthetics of simplicity cloak artifice or even unsustainable excess.\"</p> </li> <li> <p>\"Because there's an infinite amount of things we can now see or know, there are also an infinite number of ways we can discover that we don't measure up, that we're not good enough, that things aren't as great as they could be. And this rips us apart inside.\"</p> </li> <li> <p>\"Wanting positive experience is a negative experience; accepting negative experience is a positive experience.\"</p> </li> <li> <p>\"The lake was silent for some time. Finally, it said: \"I weep for Narcissus, but I never noticed that Narcissus was beautiful. I weep because, each time he knelt beside my banks, I could\"</p> </li> <li> <p>\"I weep for Narcissus, but I never noticed that Narcissus was beautiful. I weep because, each time he knelt beside my banks, I could see, in the depths of his eyes, my own beauty reflected.\"</p> </li> <li> <p>\"And he knew that shepherds, like seamen and like traveling salesmen, always found a town where there was someone who could make them forget the joys of carefree wandering.\"</p> </li> <li> <p>\"But ever since he had been a child, he had wanted to know the world, and this was much more important to him than knowing God and learning about man's sins\"</p> </li> <li> <p>\"When someone sees the same people every day, as had happened with him at the seminary, they wind up becoming a part of that person's life. And then they want the person to change.\"</p> </li> <li> <p>\"Everyone seems to have a clear idea of how other people should lead their lives, but none about his or her own\"</p> </li> <li> <p>\"What's the world's greatest lie?\" the boy asked, completely surprised. \"It's this: that at a certain point in our lives, we lose control of what's happening to us, and our lives become controlled by fate. That's the world's greatest lie.\"</p> </li> <li> <p>\"there is one great truth on this planet: whoever you are, or whatever it is that you do, when you really want something, it's because that desire originated in the soul of the universe. It's your mission on earth.\"</p> </li> <li> <p>\"The Soul of the World is nourished by people's happiness. And also by unhappiness, envy, and jealousy. To realize one's Personal Legend is a person's only real obligation. All things are one. \"And, when you want something, all the universe conspires in helping you to achieve it.\"</p> </li> <li> <p>\"he's an old man, he's going to spend a month in Africa. He never realized that\"</p> </li> <li> <p>\"He never realized that people are capable, at any time in their lives, of doing what they dream of\"</p> </li> <li> <p>\"People learn, early in their lives, what is their reason for being,\" said the old man, with a certain bitterness. \"Maybe that's why they give up on it so early, too. But that's the way it is.\"</p> </li> <li> <p>\"Treasure is uncovered by the force of flowing water, and it is buried by the same currents\"</p> </li> <li> <p>\"and for gold and adventure\u2014and for the Pyramids. The boy felt jealous of the freedom of the wind, and saw that he could have the same freedom. There was nothing to hold him back except himself.\"</p> </li> <li> <p>\"Because there is a force that wants you to realize your Personal Legend; it whets your appetite with a taste of success.\"</p> </li> <li> <p>\"Don't forget that everything you deal with is only one thing and nothing else. And don't forget the language of omens. And, above all, don't forget to follow your Personal Legend through to its conclusion.\"</p> </li> <li> <p>\"You cannot trust a man if you don't know his house.'\"</p> </li> <li> <p>\"I can give you,' said the wisest of wise men. 'The secret of happiness is to see all the marvels of the world, and\"</p> </li> <li> <p>\"The secret of happiness is to see all the marvels of the world, and never to forget the drops of oil on the spoon.'\"</p> </li> <li> <p>\"A shepherd may like to travel, but he should never forget about his sheep.\"</p> </li> <li> <p>\"I'm like everyone else\u2014I see the world in terms of what I would like to see happen, not what actually does.\"</p> </li> <li> <p>\"He had learned that there were certain things one shouldn't ask about, so as not to flee from one's own Personal Legend\"</p> </li> <li> <p>\"This candy merchant isn't making candy so that later he can travel or marry a shopkeeper's daughter. He's doing it because it's what he wants to do,\"</p> </li> <li> <p>\"But the sheep had taught him something even more important: that there was a language in the world that everyone understood, a language the boy had used throughout the time that he was trying to improve things at the shop. It was the language of enthusiasm, of things accomplished with love and purpose, and as part of a search for something believed in and desired.\"</p> </li> <li> <p>\"He still had some doubts about the decision he had made. But he was able to understand one thing: making a decision was only the beginning of things. When someone makes a decision, he is really diving into a strong current that will carry him to places he had never dreamed of when he first made the decision.\"</p> </li> <li> <p>\"The closer one gets to realizing his Personal Legend, the more that Personal Legend becomes his true reason for being, thought the boy.\"</p> </li> <li> <p>\"I've crossed these sands many times,\" said one of the camel drivers one night.</p> </li> <li> <p>\"But the desert is so huge, and the horizons so distant, that they make a person feel small, and as if he should remain silent.\"</p> </li> <li> <p>\"The boy was beginning to understand that intuition is really a sudden immersion of the soul into the universal current of life, where the histories of all people are connected, and we are able to know everything, because it's all written there.\"</p> </li> <li> <p>\"We are afraid of losing what we have, whether it's our life or our possessions and property. But this fear evaporates when we understand that our life stories and the history of the world were written by the same hand.\"</p> </li> <li> <p>\"Everything on earth is being continuously transformed, because the earth is alive .\u00a0.\u00a0. and it has a soul. We are part of that soul, so we rarely recognize that it is working for us. But in the crystal shop you probably realized that even the glasses were collaborating in your success.\"</p> </li> <li> <p>\"Because I don't live in either my past or my future. I'm interested only in the present. If you can concentrate always on the present, you'll be a happy man. You'll see that there is life in the desert, that there are stars in the heavens, and that tribesmen fight because they are part of the human race. Life will be a party for you, a grand festival, because life is the moment we're living right now.\"</p> </li> <li> <p>\"Because people become fascinated with pictures and words, and wind up forgetting the Language of the World.\"</p> </li> <li> <p>\"If he pushed forward impulsively, he would fail to see the signs and omens left by God along his path.\"</p> </li> <li> <p>\"Until then, he had considered the omens to be things of this world. Like eating or sleeping, or like seeking love or finding a job. He had never thought of them in terms of a language used by God to indicate what he should do.\"</p> </li> <li> <p>\"Don't be impatient,\" he repeated to himself. \"It's like the camel driver said: 'Eat when it's time to eat. And move along when it's time to move along.'\"</p> </li> <li> <p>\"The dunes are changed by the wind, but the desert never changes.\"</p> </li> <li> <p>\"Isn't wine prohibited here?\" the boy asked \"It's not what enters men's mouths that's evil,\" said the alchemist. \"It's what comes out of their mouths that is.\"</p> </li> <li> <p>\"Remember that wherever your heart is, there you will find your treasure. You've got to find the treasure, so that everything you have learned along the way can make sense.\"</p> </li> <li> <p>\"Camels are traitorous: they walk thousands of paces and never seem to tire. Then suddenly, they kneel and die. But horses tire bit by bit. You always know how much you can ask of them, and when it is that they are about to die.\"</p> </li> <li> <p>\"You must understand that love never keeps a man from pursuing his Personal Legend. If he abandons that pursuit, it's because it wasn't true love .\u00a0.\u00a0. the love that speaks the Language of the World.\"</p> </li> <li> <p>\"Men dream more about coming home than about leaving,\"</p> </li> <li> <p>\"what one finds is made of pure matter, it will never spoil. And one can always come back. If what you had found was only\"</p> </li> <li> <p>\"If what one finds is made of pure matter, it will never spoil. And one can always come back. If what you had found was only a moment of light, like the explosion of a star, you would find nothing on your return.\"</p> </li> <li> <p>\"There is only one way to learn,\" the alchemist answered. \"It's through action. Everything you need to know you have learned through your journey.\"</p> </li> <li> <p>\"The desert will give you an understanding of the world; in fact, anything on the face of the earth will do that. You don't even have to understand the desert: all you have to do is contemplate a simple grain of sand, and you will see in it all the marvels of creation\"</p> </li> <li> <p>\"Listen to your heart. It knows all things, because it came from the Soul of the World, and it will one day return there.\"</p> </li> <li> <p>\"Why do we have to listen to our hearts?\" the boy asked, when they had made camp that day. \"Because, wherever your heart is, that is where you'll find your treasure.\"</p> </li> <li> <p>\"My heart is a traitor,\" the boy said to the alchemist, when they had paused to rest the horses. \"It doesn't want me to go on.\" \"That makes sense,\" the alchemist answered. \"Naturally it's afraid that, in pursuing your dream, you might lose everything you've won.\"</p> </li> <li> <p>\"Well, then, why should I listen to my heart?\" \"Because you will never again be able to keep it quiet. Even if you pretend not to have heard what it tells you, it will always be there inside you, repeating to you what you're thinking about life and about the world.\"</p> </li> <li> <p>\"You will never be able to escape from your heart. So it's better to listen to what it has to say. That way, you'll never have to fear an unanticipated blow.\"</p> </li> <li> <p>\"He lost his fear, and forgot about his need to go back to the oasis, because, one afternoon, his heart told him that it was happy. \"Even though I complain sometimes,\" it said, \"it's because I'm the heart of a person, and people's hearts are that way. People are afraid to pursue their most important dreams, because they feel that they don't deserve them, or that they'll be unable to achieve them. We, their hearts, become fearful just thinking of loved ones who go away forever, or of moments that could have been good but weren't, or of treasures that might have been found but were forever hidden in the sands. Because, when these things happen, we suffer terribly.\"</p> </li> <li> <p>\"Tell your heart that the fear of suffering is worse than the suffering itself. And that no heart has ever suffered when it goes in search of its dreams, because every second of the search is a second's encounter with God and with eternity.\"</p> </li> <li> <p>\"Every second of the search is an encounter with God,\" the boy told his heart.</p> </li> <li> <p>\"When I have been truly searching for my treasure, every day has been luminous, because I've known that every hour was a part of the dream that I would find it. When I have been truly searching for my treasure, I've discovered things along the way that I never would have seen had I not had the courage to try things that\"</p> </li> <li> <p>\"Because a grain of sand is a moment of creation, and the universe has taken millions of years to create it. \"Everyone on earth has a treasure that awaits him,\" his heart said. \"We, people's hearts, seldom say much about those treasures, because people no longer want to go in search of them. We speak of them only to children. Later, we simply let life proceed, in its own direction, toward its own fate. But, unfortunately, very few follow the path laid out for them\u2014the path to their Personal Legends, and to happiness. Most people see the world as a threatening place, and, because they do, the world turns out, indeed, to be a threatening place.\"</p> </li> <li> <p>\"So, we, their hearts, speak more and more softly. We never stop speaking out, but we begin to hope that our words won't be heard: we don't want people to suffer because they don't follow their hearts.\" \"Why don't people's hearts tell them to continue to follow their dreams?\" the boy asked the alchemist. \"Because that's what makes a heart suffer most, and hearts don't like to suffer.\"</p> </li> <li> <p>\"What you still need to know is this: before a dream is realized, the Soul of the World tests everything that was learned along the way. It does this not because it is evil, but so that we can, in addition to realizing our dreams, master the lessons we've learned as we've moved toward that dream. That's the point at which most people give up. It's the point at which, as we say in the language of the desert, one 'dies of thirst just when the palm trees have appeared on the horizon.'\"</p> </li> <li> <p>\"When you possess great treasures within you, and try to tell others of them, seldom are you believed.\"</p> </li> <li> <p>\"Does a man's heart always help him?\" the boy asked the alchemist. \"Mostly just the hearts of those who are trying to realize their Personal Legends. But they do help children, drunkards, and the elderly, too.\" \"Does that mean that I'll never run into danger?\" \"It means only that the heart does what it can,\" the alchemist said.\"</p> </li> <li> <p>\"Trust in your heart, but never forget that you're in the desert. When men are at war with one another, the Soul of the World can hear the screams of battle. No one fails to suffer the consequences of everything under the sun.\"</p> </li> <li> <p>\"And then there were the others, who were interested only in gold. They never found the secret. They forgot that lead, copper, and iron have their own Personal Legends to fulfill. And anyone who interferes with the Personal Legend of another thing never will discover his own.\"</p> </li> <li> <p>\"The sea has lived on in this shell, because that's its Personal Legend. And it will never cease doing so until the desert is once again covered by water.\"</p> </li> <li> <p>\"Don't give in to your fears,\" said the alchemist, in a strangely gentle voice.</p> </li> <li> <p>\"If you do, you won't be able to talk to your heart.\"</p> </li> <li> <p>\"If a person is living out his Personal Legend, he knows everything he needs to know. There is only one thing that makes a dream impossible to achieve: the fear of failure.\"</p> </li> <li> <p>\"Usually the threat of death makes people a lot more aware of their lives.\"</p> </li> <li> <p>\"What is love?\" the desert asked. \"Love is the falcon's flight over your sands. Because for him, you are a green field, from which he always returns with game. He knows your rocks, your dunes, and your mountains, and you are generous to him.\" \"The falcon's beak carries bits of me, myself,\" the desert said. \"For years, I care for his game, feeding it with the little water that I have, and then I show him where the game is. And, one day, as I enjoy the fact that his game thrives on my surface, the falcon dives out of the sky, and takes away what I've created.\" \"But that's why you created the game in the first place,\" the boy answered. \"To nourish the falcon. And the falcon then nourishes man. And, eventually, man will nourish your sands, where the game will once again flourish. That's how the world goes.\" \"So is that what love is?\" \"Yes, that's what love is. It's what makes the game become the falcon, the falcon become man, and man, in his turn, the desert. It's what turns lead into gold, and makes the gold return to the earth.\"</p> </li> <li> <p>\"The wind has many names. In that part of the world, it was called the sirocco, because it brought moisture from the oceans to the east. In the distant land the boy came from, they called it the levanter, because they believed that it brought with it the sands of the desert, and the screams of the Moorish wars. Perhaps, in the places beyond the pastures where his sheep lived, men thought that the wind came from Andalusia. But, actually, the wind came from no place at all, nor did it go to any place; that's why it was stronger than the desert. Someone might one day plant trees in the desert, and even raise sheep there, but never would they harness the wind.\"</p> </li> <li> <p>\"You can't be the wind,\" the wind said. \"We're two very different things.\" \"That's not true,\" the boy said. \"I learned the alchemist's secrets in my travels. I have inside me the winds, the deserts, the oceans, the stars, and everything created in the universe. We were all made by the same hand, and we have the same soul. I want to be like you, able to reach every corner of the world, cross the seas, blow away the sands that cover my treasure, and carry the voice of the woman I love.\"</p> </li> <li> <p>\"When you are loved, you can do anything in creation. When you are loved, there's no need at all to understand what's happening, because everything happens within you, and even men can turn themselves into the wind. As long as the wind helps, of course.\"</p> </li> <li> <p>\"This is why alchemy exists,\" the boy said. \"So that everyone will search for his treasure, find it, and then want to be better than he was in his former life. Lead will play its role until the world has no further need for lead; and then lead will have to turn itself into gold.\"</p> </li> <li> <p>\"That's what alchemists do. They show that, when we strive to become better than we are, everything around us becomes better, too.\"</p> </li> <li> <p>\"A current of love rushed from his heart, and the boy began to pray. It was a prayer that he had never said before, because it was a prayer without words or pleas. His prayer didn't give thanks for his sheep having found new pastures; it didn't ask that the boy be able to sell more crystal; and it didn't beseech that the woman he had met continue to await his return. In the silence, the boy understood that the desert, the wind, and the sun were also trying to understand the signs written by the hand, and were seeking to follow their paths, and to understand what had been written on a single emerald. He saw that omens were scattered throughout the earth and in space, and that there was no reason or significance attached to their appearance; he could see that not the deserts, nor the winds, nor the sun, nor people knew why they had been created. But that the hand had a reason for all of this, and that only the hand could perform miracles, or transform the sea into a desert .\u00a0.\u00a0. or a man into the wind. Because only the hand understood that it was a larger design that had moved the universe to the point at which six days of creation had evolved into a Master Work. The boy reached through to the Soul of the World, and saw that it was a part of the Soul of God. And he saw that the Soul of God was his own soul. And that he, a boy, could perform miracles.\"</p> </li> <li> <p>\"But this payment goes well beyond my generosity,\" the monk responded. \"Don't say that again. Life might be listening, and give you less the next time.\"</p> </li> <li> <p>\"Everything that happens once can never happen again. But everything that happens twice will surely happen a third time.\"</p> </li> <li> <p>\"No matter what he does, every person on earth plays a central role in the history of the world. And normally he doesn't know it.\"</p> </li> <li> <p>\"But here he was, at the point of finding his treasure, and he reminded himself that no project is completed until its objective has been achieved\"</p> </li> <li> <p>\"While I was fighting, I heard other people speaking in the name of freedom, and the more they defended this unique right, the more enslaved they seemed to be to their parents' wishes, to a marriage in which they had promised to stay with the other person \"for the rest of their lives,\" to the bathroom scales, to their diet, to half-finished projects, to lovers to whom they were incapable of saying \"No\" or \"It's over,\" to weekends when they were obliged to have lunch with people they didn't even like. Slaves to luxury, to the appearance of luxury, to the appearance of the appearance of luxury. Slaves to a life they had not chosen, but which they had decided to live because someone had managed to convince them that it was all for the best. And so their identical days and nights passed, days and nights in which adventure was just a word in a book or an image on the television that was always on, and whenever a door opened, they would say: \"I'm not interested. I'm not in the mood.\"</p> </li> <li> <p>\"We want to think of families as safe havens in a heartless world and of our own country as populated by enlightened, civilized people. We prefer to believe that cruelty occurs only in faraway places like Darfur or the Congo. It is hard enough for observers to bear witness to pain. Is it any wonder, then, that the traumatized individuals themselves cannot tolerate remembering it and that they often resort to using drugs, alcohol, or self-mutilation to block out their unbearable knowledge?\"</p> </li> <li> <p>\"After you have experienced something so unspeakable, how do you learn to trust yourself or anyone else again? Or, conversely, how can you surrender to an intimate relationship after you have been brutally violated?\"</p> </li> <li> <p>\"It's hard enough to face the suffering that has been inflicted by others, but deep down many traumatized people are even more haunted by the shame they feel about what they themselves did or did not do under the circumstances. They despise themselves for how terrified, dependent, excited, or enraged they felt.\"</p> </li> <li> <p>\"Imagination is absolutely critical to the quality of our lives. Our imagination enables us to leave our routine everyday existence by fantasizing about travel, food, sex, falling in love, or having the last word\u2014all the things that make life interesting. Imagination gives us the opportunity to envision new possibilities\u2014it is an essential launchpad for making our hopes come true. It fires our creativity, relieves our boredom, alleviates our pain, enhances our pleasure, and enriches our most intimate relationships.\"</p> </li> <li> <p>\"Without imagination there is no hope, no chance to envision a better future, no place to go, no goal to reach.\"</p> </li> <li> <p>\"After trauma the world becomes sharply divided between those who know and those who don't.\"</p> </li> <li> <p>\"We have learned that trauma is not just an event that took place sometime in the past; it is also the imprint left by that experience on mind, brain, and body. This imprint has ongoing consequences for how the human organism manages to survive in the present.\"</p> </li> <li> <p>\"We have discovered that helping victims of trauma find the words to describe what has happened to them is profoundly meaningful, but usually it is not enough.\"</p> </li> <li> <p>\"For real change to take place, the body needs to learn that the danger has passed and to live in the reality of the present.\"</p> </li> <li> <p>\"The greater the doubt, the greater the awakening; the smaller the doubt, the smaller the awakening. No doubt, no awakening.\"</p> </li> <li> <p>\"Semrad taught us that most human suffering is related to love and loss and that the job of therapists is to help people \"acknowledge, experience, and bear\" the reality of life\u2014with all its pleasures and heartbreak.\"</p> </li> <li> <p>\"Scared animals return home, regardless of whether home is safe or frightening.\"</p> </li> <li> <p>\"At this point, just as with drug addiction, we start to crave the activity and experience withdrawal when it's not available. In the long run people become more preoccupied with the pain of withdrawal than the activity itself\"</p> </li> <li> <p>\"We concluded that Beecher's speculation that \"strong emotions can block pain\" was the result of the release of morphinelike substances manufactured in the brain. This suggested that for many traumatized people, reexposure to stress might provide a similar relief from anxiety.\"</p> </li> <li> <p>\"Manipulating a monkey into a lower position in the dominance hierarchy made his serotonin drop, while chemically enhancing\"</p> </li> <li> <p>\"The social environment interacts with brain chemistry. Manipulating a monkey into a lower position in the dominance hierarchy made his serotonin drop, while chemically enhancing serotonin elevated the rank of former subordinates.\"</p> </li> <li> <p>\"After conducting numerous studies of medications for PTSD, I have come to realize that psychiatric medications have a serious downside, as they may deflect attention from dealing with the underlying issues. The brain-disease model takes control over people's fate out of their own hands and puts doctors and insurance companies in charge of fixing their problems.\"</p> </li> <li> <p>\"The brain-disease model overlooks four fundamental truths: (1) our capacity to destroy one another is matched by our capacity to heal one another. Restoring relationships and community is central to restoring well-being; (2) language gives us the power to change ourselves and others by communicating our experiences, helping us to define what we know, and finding a common sense of meaning; (3) we have the ability to regulate our own physiology, including some of the so-called involuntary functions of the body and brain, through such basic activities as breathing, moving, and touching; and (4) we can change social conditions to create environments in which children and adults can feel safe and where they can thrive.\"</p> </li> <li> <p>\"You must make her hell-bent on being with you. Remember, the easier something is to get, the less precious it will be in the end\"</p> </li> <li> <p>\"I just\u2014' The thing with mental turmoil is that so many things that make you feel better in the short term make you feel worse in the long term. You distract yourself,\"</p> </li> <li> <p>\"The thing with mental turmoil is that so many things that make you feel better in the short term make you feel worse in the long term. You distract yourself, when what you really need is to know yourself.\"</p> </li> <li> <p>\"In the early days of my first experience of panic the only things I had taken away were booze and cigarettes and strong coffees. Now, though, years later, I realised that a more general overload was the problem. A life overload.\"</p> </li> <li> <p>\"As Nicholas Kristof pointed out in a 2017 New York Times article, 'if just about the worst thing that can happen is for a parent to lose a child, that's about half as likely as it was in 1990.'\"</p> </li> <li> <p>\"It sometimes feels as if we have temporarily solved the problem of scarcity and replaced it with the problem of excess.\"</p> </li> <li> <p>\"I want to know if one of the reasons I sometimes feel like I am on the brink of a breakdown is partly because the world sometimes seems on the brink of a breakdown.\"</p> </li> <li> <p>\"I am petrified of where my mind can go, because I know where it has already been.\"</p> </li> <li> <p>\"Anxiety, to quote the philosopher S\u00f8ren Kierkegaard, may be the 'dizziness of freedom', but all this freedom of choice really is a miracle.\"</p> </li> <li> <p>\"We don't need another world. Everything we need is here, if we give up thinking we need everything.\"</p> </li> <li> <p>\"He who fears he shall suffer, already suffers what he fears.'\"</p> </li> <li> <p>\"Ours is a world of nuclear giants and ethical infants. We know more about killing than we know about living.'\"</p> </li> <li> <p>\"Sex isn't really what sells. What sells is fear.\"</p> </li> <li> <p>\"The news unconsciously mimics the way fear operates \u2013 focusing on the worst things, catastrophising, listening to an endless, repetitive stream of information on the same worrying topic. So, it can be hard to tell these days where your anxiety disorder ends and where actual news begins.\"</p> </li> <li> <p>\"We seldom realise, for example, that our most private thoughts and emotions are not actually our own. For we think in terms of languages and images which we did not invent, but which were given to us by our society.'\"</p> </li> <li> <p>\"But this change \u2013 even within the last four millennia \u2013 is not a smooth, straight upward line. It is the kind of steepening curve that would intimidate a professional skateboarder. Change may be a constant, but the rate of change is not.\"</p> </li> <li> <p>\"Then there are other serious psychological concerns. To be constantly presenting ourselves, and packaging ourselves, like potatoes pretending to be crisps.\"</p> </li> <li> <p>\"So, modern life is, basically, slowly killing the planet. Small wonder that such toxic societies can damage us, too.\"</p> </li> <li> <p>\"The whole of consumerism is based on us wanting the next thing rather than the present thing we already have. This is an almost perfect recipe for unhappiness.\"</p> </li> <li> <p>\"To see the act of learning as something not for its own sake but because of what it will get you reduces the wonder of humanity.\"</p> </li> <li> <p>\"You will be happy when people like you. You will be happy when more people like you. You will be happy when everyone likes you. You will be happy when people dream of you.\"</p> </li> <li> <p>\"MAYBE HAPPINESS IS not about us, as individuals. Maybe it is not something that arrives into us. Maybe happiness is felt heading out, not in.\"</p> </li> <li> <p>\"People might be encouraged to feel inadequate, but they don't have to, as soon as they realise that the feeling is separate from the thing they are worried about.\"</p> </li> <li> <p>\"Just as being overly anxious about money can paradoxically result in compulsive spending, so worrying about our bodies is no guarantee we'll have better bodies.\"</p> </li> <li> <p>\"In some areas, in some kind of distorted idea of equality, we seem to be trying to make everyone equally anxious, rather than equally free.\"</p> </li> <li> <p>\"In nature,' wrote Alice Walker, 'nothing is perfect and everything is perfect. Trees can be contorted, bent in weird ways, and they're still beautiful.'\"</p> </li> <li> <p>\"Why don't you do what I do? Let it wash all over you. Allow yourself just to be as you are. Just be.\"</p> </li> <li> <p>\"Everybody dies,' wrote Nora Ephron. 'There's nothing you can do about it. Whether or not you eat six almonds a day.'\"</p> </li> <li> <p>\"Reframe your idea of beauty. Be a rebel against marketing. Look forward to being the wise elder. Be the complex elegance of a melting candle. Be a map with 10,000 roads. Be the orange at sunset that outclasses the pink of sunrise. Be the self that dares to be true.\"</p> </li> <li> <p>\"No one has ever found a Neolithic cave painting of someone waking up stressed because they slept through their alarm and missed their nine o'clock management meeting.\"</p> </li> <li> <p>\"having access to information gives you one kind of freedom at the expense of another.\"</p> </li> <li> <p>\"When the ability to check something turns into the compulsion to do so, we often find ourselves craving the time before, when there was no ability to check in the first place.\"</p> </li> <li> <p>\"For instance, in 2016, physicists in Germany built a clock so accurate that it won't lose or gain a second for 15 billion years. German physicists now have no excuse for being late for anything ever again.\"</p> </li> <li> <p>\"We are too aware of numerical time and not aware enough of natural time. People\"</p> </li> <li> <p>\"People for thousands of years may have woken up at seven in the morning. The difference with these last few centuries is that now we are waking up because it is seven in the morning.\"</p> </li> <li> <p>\"We often find ourselves wishing for more hours in the day, but that wouldn't help anything. The problem, clearly, isn't that we have a shortage of time. It's more that we have an overload of everything else.\"</p> </li> <li> <p>\"We have multiplied everything, but we are still individual selves. There\"</p> </li> <li> <p>\"To enjoy life, we might have to stop thinking about what we will never be able to read and watch and say and do, and start to think of how to enjoy the world within our boundaries. To live on a human scale. To focus on the few things we can do, rather than the millions of things we can't. To not crave parallel lives. To find a smaller mathematics. To be a proud and singular one. An indivisible prime.\"</p> </li> <li> <p>\"The world's brain is a common but fitting metaphor. We are the nerve cells of the world's brain, transmitting ourselves to all the other nerve cells. Sending the overload back and forth. Overloaded neurons on a nervous planet. Ready to crash.\"</p> </li> <li> <p>\"And things are happening too quickly for us to take stock of it all. Certainly quicker than in Tolstoy's time. All this falling out. All this information. All this technological connection. The world's brain is a common but fitting metaphor. We are the nerve cells of the world's brain, transmitting ourselves to all the other nerve cells. Sending the overload back and forth. Overloaded neurons on a nervous planet. Ready to crash.\"</p> </li> <li> <p>\"The Internet is the first thing that humanity has built that humanity doesn't understand, the largest experiment in anarchy that we have ever had.'\"</p> </li> <li> <p>\"LIFE OVERLOAD IS a feeling that partly stems from how contracted and concentrated the world seems to have become. The human world has sped up and has effectively shrunk, too.\"</p> </li> <li> <p>\"The trouble is that if we are plugged in to a vast nervous system, our happiness \u2013 and misery \u2013 is more collective than ever. The group's emotions become our own.\"</p> </li> <li> <p>\"The whole internet is one step removed from the physical world. The most powerful aspects of the internet are mirrors of the offline world, but replications of the external world aren't the actual external world. It is the real internet, but that's all it can be.\"</p> </li> <li> <p>\"Don't be steered towards being a caricature of yourself.\"</p> </li> <li> <p>\"Be a mystery, not a demographic. Be someone a computer could never quite know. Keep empathy alive. Break patterns. Resist robotic tendencies. Stay human.\"</p> </li> <li> <p>\"I used to think social media was harmless. I used to think I was on it because I enjoyed it. But then I was still on it even when I wasn't enjoying it. I remembered that feeling. It was the feeling you get at three in the morning in a bar after your friends have gone home.\"</p> </li> <li> <p>\"The internet age encourages choice and comparison, but don't do this to yourself. 'Comparison is the thief of joy,' said Theodore Roosevelt. You are you. The past is the past. The only way to make a better life is from inside the present. To focus on regret does nothing but turn that very present into another thing you will wish you did differently. Accept your own reality. Be human enough to make mistakes. Be human enough not to dread the future. Be human enough to be, well, enough.\"</p> </li> <li> <p>\"Accepting where you are in life makes it so much easier to be happy for other people without feeling terrible about yourself.\"</p> </li> <li> <p>\"We would do well to remember that this feeling we have these days \u2013 that each year is worse than the one previously \u2013 is partly just that: a feeling. We are increasingly plugged in to the ongoing travesties and horrors of world news and so the effect is depressing. It's a global sinking feeling. And the real worry is that all the increased fears we feel in themselves risk making the world worse.\"</p> </li> <li> <p>\"It is like someone who is ill with a compulsive disorder continually underlining their fears \u2013 staying indoors, or washing their hands 200 times a day. They are actually doing more to hurt themselves, in the name of protecting themselves. But this time the disorder isn't individual. It is social. It is global.\"</p> </li> <li> <p>\"Shock may be an unpleasant thing for an individual or a society to experience, but it can be a useful political tool.\"</p> </li> <li> <p>\"Naomi Klein coined the term the 'shock doctrine' to describe the cynical tactic of systematically using 'the public's disorientation following a collective shock' for corporate or political gain.\"</p> </li> <li> <p>\"We don't go into a state of shock when something big and bad happens,' she says. 'It has to be something big and bad that we do not yet understand.'\"</p> </li> <li> <p>\"I remember once, during depression, staring up at a clear sky of stars. The wonder of the universe. At the bottom of the pit, I always had to force myself to find the beauty, the goodness, the love, however hard it was. It was hard to do. But I had to try. Change doesn't just happen by focusing on the place you want to escape. It happens by focusing on where you want to reach. Boost the good guys, don't just knock the bad guys. Find the hope that is already here and help it grow.\"</p> </li> <li> <p>\"The medium isn't just the message, it's the emotional intensity of that message.\"</p> </li> <li> <p>\"Realise the world is not as violent as it feels. Many writers on this subject \u2013 such as the famed cognitive psychologist Steven Pinker \u2013 have pointed out that, despite all its horrors, society is less violent than it used to be.\"</p> </li> <li> <p>\"Some people talk to animals. Not many listen though. That's the problem.'\"</p> </li> <li> <p>\"Cynicism was a luxury for the non-suicidal.\"</p> </li> <li> <p>\"One thing mental illness taught me is that progress is a matter of acceptance. Only by accepting a situation can you change it. You have to learn not to be shocked by the shock. Not to be in a state of panic about the panic. To change what you can change and not get frustrated by what you can't.\"</p> </li> <li> <p>\"There is no panacea, or utopia, there is just love and kindness and trying, amid the chaos, to make things better where we can. And to keep our minds wide, wide open in a world that often wants to close them.\"</p> </li> <li> <p>\"sleep has traditionally been an enemy of consumerism. We can't shop in our sleep. We can't work or earn or post to Instagram in our sleep. Very few companies \u2013 beyond bed manufacturers and duvet sellers and makers of black-out blinds \u2013 have actually made money from our sleep.\"</p> </li> <li> <p>\"And now, at this later stage of capitalism, sleep has become seen not just as something that slows work down, but as an actual business rival. The chief executive of Netflix, Reed Hastings,\"</p> </li> <li> <p>\"We live in 24-hour societies but not 24-hour bodies.\"</p> </li> <li> <p>\"EVEN WHEN THE world is not overtly terrifying us, the speed and pace and distraction of modern existence can be a kind of mental assault that is hard to identify. Sometimes life just seems too complicated, too dehumanising, and we lose sight of what matters.\"</p> </li> <li> <p>\"Accentuating the things that make you feel good, cutting back the things that make you feel bad, and letting people feel truly connected to the world around them.\"</p> </li> <li> <p>\"That is the biggest paradox, I think, about the modern world. We are all connected to each other but we often feel shut out.\"</p> </li> <li> <p>\"Because often identifying a problem, being mindful of it, becomes the solution itself.\"</p> </li> <li> <p>\"individualism has replaced collectivism and community. We have face-to-face conversations less and less, and more interactions with avatars.\"</p> </li> <li> <p>\"The more stimulation we have, the easier it is to feel bored.\"</p> </li> <li> <p>\"She thought the cure to misery was to 'decorate one's inner house so richly that one is content there, glad to welcome anyone who wants to come and stay, but happy all the same when one is inevitably alone'.\"</p> </li> <li> <p>\"1.Don't feel you always have to be there. In the not-so olden days of letters and landlines, contacting someone was slow and unreliable and an effort. In the age of WhatsApp and Messenger it's free and easy and instant. The flipside of this ease is that we are expected to be there. To pick up the phone. To get back to the text. To answer the email. To update our social media. But we can choose not to feel that obligation. We can sometimes just let them wait. We can risk our social media getting stale.\"</p> </li> <li> <p>\"There is no final checking of your phone. Think of all the times you checked your phone yesterday. Did you really need to so often?\"</p> </li> <li> <p>\"Because there is no end to the uncertainty. There is no final checking of your phone.\"</p> </li> <li> <p>\"Illness has a lot to teach wellness.\"</p> </li> <li> <p>\"When it comes to our minds, awareness is very often the solution itself.\"</p> </li> <li> <p>\"This was an already familiar tactic of mine: trying to distract myself from one torment by finding another.\"</p> </li> <li> <p>\"In a world of a million distractions you are still left with only one mind.\"</p> </li> <li> <p>\"I SO WISH I could explain something to my younger self. I wish I could tell myself that it wasn't all me. I wish I could say that there were things I could do. Because my anxiety, my depression, wasn't just there. Illness, like injury, often has context.\"</p> </li> <li> <p>\"When I fall into a frantic or despairing state of mind, full of unwelcome thoughts that can't slow down, it is often the result of a series, a sequence of things. When I do too much, think too much, absorb too much, eat too badly, sleep too little, work too hard, get too frazzled by life, there it is. A repetitive strain injury of the mind.\"</p> </li> <li> <p>\"6.Don't grab life by the throat. 'Life should be touched, not strangled,'\"</p> </li> <li> <p>\"save lives. But, as C.S. Lewis once put it, 'The frequent attempt to conceal mental pain increases the burden: it is easier to say \"My tooth is aching\" than to say \"My heart is broken\".'\"</p> </li> <li> <p>\"this collision between one's image of oneself and what one actually is is always very painful and there are two things you can do about it, you can meet the collision head-on and try and become what you really are or you can retreat and try to remain what you thought you were, which is a fantasy, in which you will certainly perish.'\"</p> </li> <li> <p>\"Because there is, I suppose, a clear self doing the asking. But when I was ill these weren't simply abstract concerns. These were desperate mysteries to solve, as though my life depended on it. Because my life did depend on it. The feeling of me-ness had gone \u2013 it had been crowded out \u2013 and I felt like I could become trapped in the infinite I, silently floating in panic, with nowhere to land.\"</p> </li> <li> <p>\"Panic is there to help us. As it is for many other animals, panic is our mind and body telling us to do something. Fight or flight. Run from the predator or fight the predator.\"</p> </li> <li> <p>\"People who have never had a period of living with anxiety and panic don't understand that the realness of you is an actual feeling that you can lose. People take it for granted. You don't get up in the morning and think, as you spread peanut butter onto your toast, 'Ah, good, my sense of self is still intact, and the world is still real, I can now get on with my day.' It's just there. Until it isn't. Until you are in the cereal aisle, feeling inexplicable terror.\"</p> </li> <li> <p>\"Within a feeling of derealisation, I still knew I was me. I just didn't feel I was me. It is a feeling of disintegration. Like a sand sculpture crumbling away. And there is a paradox about this sensation. Because it feels like both an extreme intensity of self and a nothingness of self. A feeling of no return, as if you have suddenly lost something that you didn't know you had to look after, and that the thing you had to look after was you.\"</p> </li> <li> <p>\"And in unnatural settings, when your anxiety is raw enough, you can feel unnatural, too. You can feel as removed from yourself as a packet of toilet roll is removed from a tree.\"</p> </li> <li> <p>\"It helps to know I am just a caveman in a world that has arrived faster than our minds and bodies expected.\"</p> </li> <li> <p>\"Nothing I was worried about would fundamentally change anything. I would still be able to walk the dog. I would still be able to look at the sea. I would still be able to spend time with the people I love. The anxiety retreated, like a criminal under the spotlight of an investigation.\"</p> </li> <li> <p>\"Perhaps when we find ourselves wanting everything it is because we are dangerously near to wanting nothing.'\"</p> </li> <li> <p>\"WE ARE BEING sold unhappiness, because unhappiness is where the money is. Much of what is sold to us is the idea that we could be better than who we are if we tried to become something else.\"</p> </li> <li> <p>\"Life isn't a play. Don't rehearse yourself. Be yourself.\"</p> </li> <li> <p>\"8.If you're feeling bad about yourself, stay away from Instagram.\"</p> </li> <li> <p>\"9.Remember no one else is ever worried about what your face looks like.\"</p> </li> <li> <p>\"So we have to be careful of our wants and watch that they don't cause too many holes inside us, otherwise happiness will drip through us like water through a leaky bucket. The moment we want is the moment we are dissatisfied. The more we want, the more we will drip ourselves away.\"</p> </li> <li> <p>\"I have learned that however strong the craving gets the guilt afterwards will be stronger.\"</p> </li> <li> <p>\"That's the problem with mental illness. It's easy not to judge people for having an illness; it's a lot harder not to judge people for how the illness occasionally causes them to behave. Because people can't see the reasons.\"</p> </li> <li> <p>\"An evening of heaven in a glass doesn't outweigh a month of hell in a cage.\"</p> </li> <li> <p>\"If the whole planet is having a kind of collective breakdown, then unhealthy behaviour fits right in. When normality becomes madness, the only way to find sanity is by daring to be different. Or daring to be the you that exists beyond all the physical clutter and mind debris of modern existence.\"</p> </li> <li> <p>\"Even when the tide of society is pulling us in one direction it has to be possible \u2013 if that direction makes and keeps us unhappy \u2013 to learn how to swim another way. To swim towards the truth of ourselves, a truth our distractions might be hiding. Our very lives might depend on it.\"</p> </li> <li> <p>\"How many young college graduates have taken demanding jobs in high-powered firms, vowing that they will work hard to earn money that will enable them to retire and pursue their real interests when they are thirty-five? But by the time they reach that age, they have large mortgages, children to school, houses in the suburbs that necessitate at least two cars per family, and a sense that life is not worth living without really good wine and expensive holidays abroad. What are they supposed to do, go back to digging up roots? No, they double their efforts and keep slaving away.'\"</p> </li> <li> <p>\"I want to say, in all seriousness, that a great deal of harm is being done in the modern world by belief in the virtuousness of work, and that the road to happiness and prosperity lies in an organised diminution of work.'\"</p> </li> <li> <p>\"As our schoolchildren are also discovering, all this testing and evaluating makes us stress about the future rather than be comfortable with the present.\"</p> </li> <li> <p>\"Work culture can lead to low self-esteem. We are encouraged to believe that success is the result of hard work, that it is down to the individual. So, it is no surprise that when we feel as if we are failing \u2013 which is almost continually in an aspirational culture that thrives on raising the bar of our happiness \u2013 we take it personally. And think it is down to ourselves. We aren't encouraged to see the context.\"</p> </li> <li> <p>\"We like to work. It gives us purpose. But work can also be bad for physical health.\"</p> </li> <li> <p>\"It is hard to challenge our cultural obsession with work. Politicians and business leaders keep up the idea of relentless work as a moral virtue. They talk with misty-eyed sentiment and a dose of sycophancy about 'decent ordinary working people' and 'hard-working families'. We accept the five-day working week as if it was a law of nature. We are often made to feel guilty when we aren't working. We say to ourselves, like Benjamin Franklin did, that 'time is money', forgetting that money is also luck. A lot of people who work very long hours have far less money than people who have never worked in their life.\"</p> </li> <li> <p>\"and if it is what we can do about it. How much pressure are we actually putting on ourselves, simply because the way we work makes us feel continually behind? Like life is a race that we are losing? And in our struggle to keep up we don't dare to stop and think what might be good for us.\"</p> </li> <li> <p>\"Aim not to get more stuff done. Aim to have less stuff to do. Be a work minimalist. Minimalism is about doing more with less. So much of working life seems to be about doing less with more. Activity isn't always the same as achievement.\"</p> </li> <li> <p>\"One of the symptoms of an approaching nervous breakdown is the belief that one's work is terribly important.'\"</p> </li> <li> <p>\"Progress,' wrote C.S. Lewis, 'means getting nearer to the place you want to be. And if you have taken a wrong turning, then to go forward does not get you any nearer.'\"</p> </li> <li> <p>\"In a world that can get too much, a world where we are running out of mind space, fictional worlds are essential.\"</p> </li> <li> <p>\"For me, reading was never an antisocial activity. It was deeply social. It was the most profound kind of socialising there was. A deep connection to the imagination of another human being. A way to connect without the many filters society normally demands.\"</p> </li> <li> <p>\"Reading isn't important because it helps to get you a job. It's important because it gives you room to exist beyond the reality you're given. It is how humans merge. How minds connect. Dreams. Empathy. Understanding. Escape. Reading is love in action.\"</p> </li> <li> <p>\"I used to want to lose myself in the most intense experiences, as if life was simply a tequila to be slammed. But most of life can't be lived like this. To have a chance of lasting happiness, you have to calm down. You have to just be it as well as just do it.\"</p> </li> <li> <p>\"We crowd our lives with activity because in the West we often feel happiness and satisfaction are achieved by acquisition, by 'seizing' the day, or by going out and 'grabbing' life by the horns. We might sometimes do better to replace life as something to be grabbed at, or reached for, with something we already have. If we clear out the mental clutter we can surely enjoy it more.\"</p> </li> <li> <p>\"Even world news seemed like a background irrelevance when you were sitting in an intensive care unit hearing the wails of grief coming from beyond a thin hospital curtain as the patient in the next bed passes away.\"</p> </li> <li> <p>\"I am trying now, when my life gets too packed with unnecessary stressful junk, to remember that room in the hospital. Where patients were thankful just to look at the view out of a window. Some sunshine and sycamore trees. And where life, on its own, was everything.\"</p> </li> <li> <p>\"human to ask a turtle questions. So, when depression slugs over me I close my eyes and enter the bank of good days and think of sunshine and laughter and turtles. And I try to remember how possible the impossible can sometimes be.\"</p> </li> <li> <p>\"Anyway, if you really want to know, the advice I would give is stop it.' 'Stop what?' 'It. The rushing after nothing. Humans seem in such a rush to escape where they are. Why? Is it the air? Does it not hold you up well enough? Maybe you need more time in the sea. I would say: stop it. Don't just take your time, be your time. Move fast or slow, but be aware you will always take yourself with you. Be happy to paddle in the water of existence.'\"</p> </li> <li> <p>\"Look at my head. It's tiny. My brain-to-body-mass ratio is embarrassing. But it doesn't matter, you see. If you take life carefully, you can focus. You can be how you need to be. You can have an amphibious approach to life. You can be at one with the rhythms of the whole earth. The wet and the dry. You can tune in to the wind and the water. You can tune in to yourself. It's rather wonderful, you know, being a turtle.' 'I\"</p> </li> <li> <p>\"When looking at the sky, all our 21st-century worries can be placed in their cosmic context. The sky is bigger than emails and deadlines and mortgages and internet trolls. It is bigger than our minds, and their illnesses. It is bigger than names and nations and dates and clocks. All of our earthly concerns are quite transient when compared to the sky. Through our lives, throughout every chapter of human history, the sky has always been the sky.\"</p> </li> <li> <p>\"The world affects us, but it isn't quite us. There is a space inside us that is independent to what we see and where we are. This means we can feel pain amid external beauty and peace. But the flipside is that we can feel calm in a world of fear. We can cultivate a calmness inside us, one that lives and grows, and gets us through.\"</p> </li> <li> <p>\"The story is never just the words. It is also the reading of them. And that\"</p> </li> <li> <p>\"LIFE CAN SOMETIMES feel like an overproduced song, with a cacophony of a hundred instruments playing all at once. Sometimes the song sounds better stripped back to just a guitar and a voice. Sometimes, when a song has too much happening, it's hard to hear the song at all. And like that overcrowded song we, too, can feel a bit lost.\"</p> </li> <li> <p>\"There is only one corner of the universe you can be certain of improving, and that's your own self.'\"</p> </li> <li> <p>\"Nature does not hurry, yet everything is accomplished.'\"</p> </li> <li> <p>\"Don't try to pin yourself down. Don't try to understand, once and for all, who you are. As the philosopher Alan Watts said, 'trying to define yourself is like trying to bite your own teeth'.\"</p> </li> <li> <p>\"There is no future. Planning for the future is just planning for another present in which you will be planning for the future.\"</p> </li> <li> <p>\"No one can make you feel inferior without your consent.'\"</p> </li> <li> <p>\"And I did, like lots of people, get happy, fleetingly, at each career goal I set myself, but my mind quickly got used to the previous achievement and found a new goal. So, the more I got, the more I needed to get in order to stay level.\"</p> </li> <li> <p>\"The more 'success' you get, the easier it is to be disappointed by not getting things. The only difference is that now no one feels sorry for you.\"</p> </li> <li> <p>\"Simplify your life. Take away what doesn't need to be there.\"</p> </li> <li> <p>\"The thing is to free one's self,' wrote Virginia Woolf, struggling with the task. 'To let it find its dimensions, not be impeded.'\"</p> </li> <li> <p>\"Everything special about humans \u2013 our capacity for love and art and friendship and stories and all the rest \u2013 is not a product of modern life, it is a product of being a human. And so, while we can't disentangle ourselves from the transient and frantic stress of modern life, we can place an ear next to our human self (or soul, if you'd rather) and listen to the quiet stillness of being. And realise that we don't need to distract ourselves from ourselves. Everything we need is right here. Everything we are is enough. We don't need the bigger boat to deal with the invisible sharks around us. We are the bigger boat. The brain, as Emily Dickinson put it, is bigger than the sky. And by noticing how modern life makes us feel, by allowing that reality and by being broad-minded enough to change when change is healthy, we can engage with this beautiful world without being worried it will steal who we are.\"</p> </li> <li> <p>\"For after all,' wrote the poet Henry Wadsworth Longfellow, 'the best thing one can do when it is raining is let it rain.'\"</p> </li> <li> <p>\"overwhelm isn't having too much to do; it's not knowing where to start.\"</p> </li> <li> <p>\"Maybe you are like me\u2014an overachiever, a people pleaser, a perfecter\u2014so you believe success has been defined by what you do, not who you are. You fill your days in pursuit of this illusion of success, just as I did, but deep down you feel there must be a better way. And you are so right.\"</p> </li> <li> <p>\"we falsely believe that we need to be busy, that we are supposed to fill our days.\"</p> </li> <li> <p>\"When we try to do too much, we overfill our plates with a multitude of tiny tasks and chores. We check a hundred things off our to-do lists, but when we slip into bed at night and our heads hit the pillow, we think, Why didn't I get more done?\"</p> </li> <li> <p>\"That's why productivity may have failed you in the past\u2014it's the struggle to make your life fit the system when, in fact, it should be the system that fits your life. You can customize your productivity so that your life and your priorities are at the center.\"</p> </li> <li> <p>\"But too many of us tie our self-worth to our busyness. Stress and overwhelm are badges of honor declaring our worthiness. We falsely believe that if we are not busy, we are failing. In the pursuit of finding balance, we try to do everything, but the more we do, the less we succeed.\"</p> </li> <li> <p>\"Creating an extraordinary life for ourselves requires moving away from balance, because when we lean into a priority\u2014when we give time to the most important things\u2014we have to take that time away from something else. We cannot give equal time to all the tasks on our lists.\"</p> </li> <li> <p>\"In chasing this illusion of balance, we end up creating a life that feels busy\u2014not meaningful. We have to be willing to go out of balance. We need to be willing not to do everything. That's the real magic.\"</p> </li> <li> <p>\"Ask any kindergartner what they are good at, and you'll need to sit through a laundry list of topics: art, running, painting, climbing trees, eating potato chips\u2014seriously, five-year-olds think they are amazing at everything! But wait ten years and ask the very same child, and she'll think of almost nothing; at best you'll maybe hear one or two things she believes she excels in. What happens to us in this space of time? How do we lose our belief in ourselves? We've allowed the world to define us and reinforce these limiting beliefs, but it's time to break through.\"</p> </li> <li> <p>\"Sometimes it's just a limiting belief, the idea that you simply cannot do something, that restricts you.\"</p> </li> <li> <p>\"Too often we hand over the reins, allowing others to imprison us with their own agendas and urgent fires that need putting out. We think we don't have control over how our day runs, but we do. We've simply forgotten that we have the ability to choose to spend time on our own priorities.\"</p> </li> <li> <p>\"It's not reality that makes us feel stuck; it's the lens we use to view the world. Maybe you are tired of trying because it feels like it just doesn't seem to matter. I've felt this way too. There are times when we all just want to crawl back in bed and throw the covers over our heads because we are so overwhelmed with the chaotic rush of our days. We can lose sight of who we are deep inside and what is most important to us. We are so busy struggling and fighting to keep our heads above the proverbial water that we seem to forget we can choose to tread water for a moment. We can allow ourselves a deep breath and time to scan the horizon\u2014we can choose to swim to calmer waters. When we gift ourselves with the ability to step back and choose, something powerful begins to happen. We strengthen our internal locus of control3. In other words, we remember we have the ability to influence our own destiny instead of allowing the current to push us wherever it wants. People with a strong internal locus of control believe they have the freedom and ability to make their own choices and determine what happens to them. Because of that, they are significantly happier and more motivated. Psychologists have found that an</p> </li> <li> <p>\"internal locus of control has been linked with academic success\u00a0.\u00a0.\u00a0. higher self-motivation and social maturity\u00a0.\u00a0.\u00a0. lower incidences of stress and depression\u00a0.\u00a0.\u00a0. and longer life span.\" We want to strengthen our internal locus of control and begin to understand that we have choices. BUT I REALLY DON'T HAVE ANY CONTROL If you're still saying, \"That isn't true for me; I don't have any choices in my day.\" I hear you. You have a strict boss, an overbearing family member, an overly regimented schedule, a special-needs child, or something similar. Right? I met Rhonda when I was speaking at a workshop event\"</p> </li> <li> <p>\"Are you choosing to spend your time being busy, or are you choosing to focus your day on what matters most?\"</p> </li> <li> <p>\"When I look at this limited time I have, it reminds me that we all have seasons we live through. Seasons when our lives are hard and seasons where life comes easy, but in the scheme of 100 years, those seasons are a mere fraction of the time we have.\"</p> </li> <li> <p>\"Seasons pass, life ebbs and flows, but our priorities are what anchor us.\"</p> </li> <li> <p>\"Your happiness isn't defined by others, it is defined by you and the daily choices you make. Living a life centered on your priorities is making a choice to be happy, and it's okay to choose happy.\"</p> </li> <li> <p>\"am not afraid of storms, for I am learning how to sail my ship.\"</p> </li> <li> <p>\"When we live our life using our North Star, we take ownership of our legacy.\"</p> </li> <li> <p>\"If the mat was not straight, the Master would not sit.\"</p> </li> <li> <p>\"Still, its nature could be understood, and those who cared the most about it, and the life from which it was inseparable, understood it best\"</p> </li> <li> <p>\"Life itself, when understood and utilized for what it is, is sweet\"</p> </li> <li> <p>\"The essence of the principle of the Uncarved Block is that things in their original simplicity contain their own natural power, power that is easily spoiled and lost when that simplicity is changed.\"</p> </li> <li> <p>\"All that we are is a result of what we have thought.\"</p> </li> <li> <p>\"Nothing can prevent your picture from coming into concrete form except the same power which gave it birth\u2014yourself.\"</p> </li> <li> <p>\"Whatever the mind \u2026 can conceive it can achieve.\"</p> </li> <li> <p>\"Inside relationships it's important to first understand who's coming into the relationship, and not just your partner. You need to understand yourself first.\"</p> </li> <li> <p>\"We've got a thousand different diagnoses and diseases out there. They're just the weak link. They're all the result of one thing: stress. If you put enough stress on the chain and you put enough stress on the system, then one of the links breaks.\"</p> </li> <li> <p>\"I always say that incurable means \"curable from within.\"</p> </li> <li> <p>\"Man becomes what he thinks about.\"</p> </li> <li> <p>\"What you resist persists.\"</p> </li> <li> <p>\"So many times people say to me, \"Well, James, I have to be informed.\" Maybe you have to be informed, but you don't have to be inundated.\"</p> </li> <li> <p>\"Energy flows where attention goes.\"</p> </li> <li> <p>\"The essence of this law is that you must think abundance; see abundance, feel abundance, believe abundance. Let no thought of limitation enter your mind.\"</p> </li> <li> <p>\"A person who sets his or her mind on the dark side of life, who lives over and over the misfortunes and disappointments of the past, prays for similar misfortunes and disappointments in the\u00a0future. If you will see nothing but ill luck in the\u00a0future, you are praying for such ill luck and will surely get it.\"</p> </li> <li> <p>\"Whether you think you can or think you can't, either way you are right.\"</p> </li> <li> <p>\"So your purpose is what you say it is. Your mission is the mission you give yourself. Your life will be what you create it as, and no one will stand in judgment of it, now or ever.\"</p> </li> <li> <p>\"can never be all the people I want and live all the lives I want. I can never train myself in all the skills I want. And why do I want? I want to live and feel all the shades, tones and variations of mental and physical experience possible in my life. Sylvia Plath\"</p> </li> <li> <p>\"I can never be all the people I want and live all the lives I want. I can never train myself in all the skills I want. And why do I want? I want to live and feel all the shades, tones and variations of mental and physical experience possible in my life.\"</p> </li> <li> <p>\"Master, I understand that the body is the basis. A good body is like uncut jade, it can be cut into many good things. And a weak body is like impure jade, even with excellent craftsmanship, nothing good can come from it.'\"</p> </li> <li> <p>\"If a craftsman is to do a good job, he shall need good tools.\"</p> </li> <li> <p>\"Meteors \u2014 even though their lives are short, they radiate the brightest lights. They are dazzling. As for human, not even a Xiantian expert can live longer than several hundred years. Instead of living my whole life in mediocrity, why don't I learn from the meteors? In my limited life, I'll burn my passion of life and stimulate the blood in my veins, making my life radiate the most dazzling light. Only in this way will I die with no regret.'\"</p> </li> <li> <p>\"Generally, people who are alone are independent and self-reliant. This is because if a person is usually alone they will naturally ponder. Pondering about life, pondering about their own values, the more they ponder, the more thoroughly they can understand things.\"</p> </li> <li> <p>\"Perhaps I've been wrong since the beginning. A person can't always live for other people. If I live like that, not only will I be tired, father will be put under great pressure as well\"</p> </li> <li> <p>\"Alright, living in the world, why do I have to be afraid of something? Moreover, I've been living the wrong way. I mustn't live for other people. That kind of life has tired both me and father out. I must live for myself. Father, big brother, 2nd brother, I'll pursue my own life!\"</p> </li> <li> <p>\"This is just like how watched flowers never bloom but an unattended willow grows.\"</p> </li> <li> <p>\"You have to be true to your feelings no matter what happens later. To survive in this world, you'll have to restrain yourself on many occasions, but if you restrain yourself too much, something that makes you feel regretful for the rest of your life can happen. Remember \u2026 sometimes, you have to be true to yourself even if you'll die from this.\"</p> </li> <li> <p>\"The weak let their ideals control their actions, but the strong control their ideals with their actions.' If not for this saying supporting my inner world like a column at the bottom of my heart, perhaps \u2026 I would have collapsed long ago due to being unable to stand acting against my will.\"</p> </li> <li> <p>\"The outside world, we are looking at only a small part that interests us.\"</p> </li> <li> <p>\"The world we see is not the entire universe but a limited one that the mind cares about. However, to our minds, that small world is the entire universe. Our reality is not the infinitely stretching cosmos but the small part we choose to focus on. Reality exists because our minds exist. Without the mind, there would be no universe.\"</p> </li> <li> <p>\"But then I realize it isn't the outside world that is a whirlwind; it is only my mind. The world has never complained about how busy it is\"</p> </li> <li> <p>\"We feel unhappy not just because something bad has happened, but also because of the swirling thoughts about what happened.\"</p> </li> <li> <p>\"Too many choices make people unhappy.\"</p> </li> <li> <p>\"Those who don't believe in magic will never find it.\"</p> </li> <li> <p>\"How could you forgive until you're forgiven? Sparks fly upward, you're learning the hustle You're learning that everyone in a room is in love with their own tongue\"</p> </li> <li> <p>\"Still searching for trouble You wanted a tempt, but not a tempter Where'd they find you? Out looking for home that you don't remember Where did youth go?\"</p> </li> <li> <p>\"Your twenties are for spending hours and hours pretending We have plans and we have places we should visit But everybody knows your twenties are for wasting time\"</p> </li> <li> <p>\"I don't wanna take the world for granted While I'm still trying to understand it\"</p> </li> <li> <p>\"This world makes me dizzy, how'd we get so busy? No one tries to take the time it takes to turn your Love into a love or friends into a family\"</p> </li> <li> <p>\"Patience is fatal but pain is not weak\"</p> </li> <li> <p>\"Long nights to quiet my mind With empty conversations Destroyed the life in my eyes I swear I'm gonna change, yeah I won't be a casualty A product of my agony Break my bloodline Feel the pain and then kill it twice I won't be a casualty No, I won't go down like that\"</p> </li> <li> <p>\"They say one is too many When enough is enough\"</p> </li> <li> <p>\"Manifestation isn't about trying, it is about being. You don't try to be what you want. You choose and embody immanently what it is you want to be.\"</p> </li> <li> <p>\"17, and we got a dream to have a family A house, and everything in between And then, oh, suddenly, we turned 23 And now we got pressure for taking our life more seriously\"</p> </li> <li> <p>\"Is anybody there? Does anybody care What I'm feeling? I wanna disappear So nobody can hear Me when I'm screamin' 'Cause I could use a hand sometimes Yeah, I could use a hand sometimes They say pain is an illusion This is just a bruise And you are just confused But I am only human I could use a hand sometimes I am only human\"</p> </li> <li> <p>\"Let's make this fleeting moment last forever So, tell me what you're waiting for? I'm gonna keep it frozen here forever There's no regretting anymore It's worth the wait, even so far away I'm making the night mine until the day I die No lights to brake when you're hanging by fate You know what it feels like when you're dancing blind All alone, just the beat inside my soul Take me home, where my dreams are made of gold In the zone where the beat is uncontrolled I know what it feels like Come on make me feel alive\"</p> </li> <li> <p>\"We were born ready, ready to be free Chasin' every thrill we could see With our eyes steady, waking to the dream Aching to be thrown in the ring If nothing comes easy as long as we're breathing We'll go all the way or go home We were born ready, wherever it leads What we have is all we need 'Cause if it's fast or slow All I really know is I'm gonna enjoy the ride And if it's hard or soft before we get off I'm gonna enjoy the ride, enjoy the ride\"</p> </li> <li> <p>\"When I'm three feet from the edge Will I break before I bend? I'm only human, ashes to dust Making a mess of us Where the words fall from your lips To save this sinking ship Give me a sign to keep my heart beating Throw me a line in over my head\"</p> </li> <li> <p>\"I can hear the sound of a heartbeat before it goes out Won't ever leave my memory of bloodshed all around And I can see a tear on my father's face before it falls out Oh, my enemy, how could I have ever let you down? Oh When all these trees saw us grow Cut our teeth and make our bones right here We'd play with shields made of stone Share our dreams and sit our thrones Be still, 'cause I see smoke up ahead and I got steel in my hands We will return like warriors, I swear, that we'll find glory up ahead Tell me Where is my home? I don't recognize the faces anymore, no Where is my friend? The one I've known since I was only just a kid I think it's time to say goodbye Goodbye, goodbye\"</p> </li> <li> <p>\"Cause there\u2019s no one to love you When you build your walls Too high\"</p> </li> <li> <p>\"He'd trade his guns for love But he's caught in the crossfire And he keeps wakin' up But it's not to the sound of birds The tyranny The violent streets Deprived of all that we're blessed with And we can't get enough, no Heaven, if you sent us down So we can build a playground For the sinners To play as saints You'd be so proud of what we made I hope you got some beds around 'Cause you're the only refuge now For every mother Every child Every brother That's caught in the crossfire That's caught in the crossfire I'd trade my luck to know Why he's caught in the crossfire And I'm here wakin' up To the sun and the sound of birds Society's anxiety Deprived of all that we're blessed with We just can't get enough, no Heaven, if you sent us down So we can build a playground For the sinners To play as saints You'd be so proud of what we made I hope you got some beds around 'Cause you're the only refuge now\"</p> </li> <li> <p>\"Feeling lost in life means that you're totally free to go anywhere you want\"</p> </li> <li> <p>\"For years I thought I was looking for the meaning of life, one of my biggest revelations is when I realized I was actually seeking the meaning of suffering.\"</p> </li> <li> <p>\"In your ignorance you want to immortalize your body because you think that is you. Seek to immortalize your mind. Then you may have whatever body you wish, when you wish.\"</p> </li> <li> <p>\"Our feelings arise because we see pictures as extensions of the real world. Pictures that affect us strongly use structural principles based on the way we have to react in the real world in order to survive. As soon as you understand these principles, you will understand why pictures have such specific emotional effects. You will understand how pictures work.\"</p> </li> <li> <p>\"Pictures are usually read as though there is an invisible, emotional horizon line stretching across the middle of the space and dividing it into top and bottom.\"</p> </li> <li> <p>\"Cause it's not too late, it's not too late I, I see the hope in your heart And sometimes you lose and sometimes you're shooting Broken arrows in the dark We have to tear down walls that live in your heart To find someone you call home Now you see me for me and my beautiful scars So take my hand, don't let go\"</p> </li> <li> <p>\"For when joy passes its climax we are bound to revert to anger, and when anger passes its climax we always revert to joy, because in both cases we are off balance.\"</p> </li> <li> <p>\"Set your will on one aim, And be equal to the gods.\"</p> </li> <li> <p>\"What common knowledge knows is shallow\"</p> </li> <li> <p>\"The utmost in speech is to be rid of speech, the utmost doing is Doing Nothing\"</p> </li> <li> <p>\"When a man\u2019s inner integrity is not firm, something oozes  from his body and becomes an aura, which outside him presses  on the hearts of others; it makes other men honour him more  than his elders and betters, and gets him into difficulties.  The only motive of an innkeeper is to sell his rice and soup, and  increase his earnings; his profits are meagre, the considerations which sway him have little weight. If men with so little to gain  from me value me so highly as a customer, will it not be even  worse with the lord of ten thousand chariots, who has worn out his body and drained his knowledge in state affairs?\"</p> </li> <li> <p>\"If you act nobly and banish from your mind the thought that you are noble, where can you go and not be loved?\"</p> </li> <li> <p>\"Why should the place where you lived be different from your own palace, or the place of our excursion different from your own park? Your Majesty feels at home with the permanent, is suspicious of the sudden and temporary. But can one always measure how far and how fast a scene may alter and turn into something else?\"</p> </li> <li> <p>\"With rank high enough to distinguish you, and more property than you need, you are too far above other men. Dreaming at night that you are a slave, reverting from ease to toil, is fortune righting itself. Can you reasonably expect to have it both ways, dreaming as well as awake?\"</p> </li> <li> <p>\"What I mistake for ecstacy is simply the abscence of grief\"</p> </li> <li> <p>\"That funny feeling is the emptiness of everything that is supposed to fill the gaps. When all the gaps are filled with plastic, it still looks empty and cracked. We are fed too big a plate of nothing but empty calories, and the funny feeling is being hungry with a full stomach.\"</p> </li> <li> <p>\"People cry, not because they are weak. It is because they've been strong for too long\"</p> </li> <li> <p>\"Sometimes what we want is simpler and closer than we think\"</p> </li> <li> <p>\"She filled my head with dreams, telling me I could become anything I wanted. I believed her so much I thought I could be white.\"</p> </li> <li> <p>\"Part of you is obsessed with the mission to save your parents, while the other part is filled with anger and resentment because you know you were stunted by parents who were so helpless or dysfunctional that they could not be real parents to you\"</p> </li> <li> <p>\"I don\u2019t care what baggage they dragged over the ocean. They have no right to make me carry it the rest of my life\"</p> </li> <li> <p>\"Your true self can survive with just freedom and will. Your true self is fiercer, braver, purer, infinitely more adaptable, and at home with nature than you ever dreamed possible\"</p> </li> <li> <p>\"As I began to love myself I found that anguish and emotional suffering are only warning signs that I was living against my own truth. Today, I know, this is Authenticity\"</p> </li> <li> <p>\"Children who are respected learn respect. Children who are cared for learn to care for those weaker than themselves. Children who are loved for what they are cannot learn intolerance. In an environment such as this, they will develop their own ideals, which can be nothing other than humane, since they grew out of the experience of love.\"</p> </li> <li> <p>\"You are allowed to take up space. Own who you are and what you want for yourself. Stop downplaying the things you care about, the hopes you have. Own your passions, your thoughts, your perceptions. Own your fire. Stop putting your worth in the hands of others; stop letting them decide your value. Own saying no, saying yes. Own your mood, your feelings. Own your plans, your path, your success\"</p> </li> <li> <p>\"When interacting with others, practise simply relaxing in their presence. Try to experiment with not doing anything, saying anything, or impressing anyone. You are not asked to advise, be useful, or advise anyone. Even when others are expressing distress, you can practice \u2018just\u2019 listening and offering your quiet presence. This will help you gradually realize that your mere existence is sufficient and that \u201ddoing\u201d has its limits. \"</p> </li> <li> <p>\"I\u2019m not so weird to me.\"</p> </li> <li> <p>\"One of the most pertinent lessons of being a highly sensitive and intense person is learning to shrug your shoulders when you feel ostracised by the world, rejected by a friend, or abandoned by a lover.  We can start by acknowledging and accepting who we are to gain such strength.  Your trait as an atypical, sensitive, and intense person is a gift.  High functioning autism: You did nothing to get it, nor can you get rid of it.  It was given to you at birth. You are wired that way.  You love deeply, but you may not be able to say it.  You see beauty where others don\u2019t, but you may not have a pal who appreciates it alongside you.  You have a unique sense of humor, and those who understand it are delighted by your presence.  \"A normal day\u201d for you is a roller coaster ride for others. You have a million shades of emotions, nuanced observations, and complex thoughts at any given hour.  Your thoughts are deep and complex. When you read a book, listen to a song, or watch a movie, what you see or hear are not merely images or sounds. But rather multi-layered, interwoven meanings and existential questions. Your mind has the ability to travel a million miles even if you sit still.  You may not know it yourself; others certainly don\u2019t see it, but your heart breaks when you see the world\u2019s pain.  You love fiercely\u2014 not just humans but nature, science, the arts, a discipline, and the world.  As a child, you were not afraid to show it. But when you realize how much your passion threatens others, you learned to hide. How much do we adjust our intensity and oddity to match the world\u2019s frequency? Any intense and sensitive misfits across time and space ask this question.  If you tell the truth, others become frightened.  You are relentlessly giving, but not everyone can reciprocate.  You may be dismissed and judged when you try to reveal the real you, speak your mind, and express your true feelings.  People may blatantly say you are dramatic, arrogant, and extreme. Or, they quietly retreat and passively punish you.  It takes incredible courage to stand up for yourself and be who you are.  But Here is a crucial piece of wisdom for the neuro-atypical gifted soul that you are: Once you accept yourself, including everything that comes with high functioning autism, other people\u2019s judgment, criticism, and rejection\u2026 will hurt less.  If you can wholeheartedly accept your intensity and drive for what others see as odd, you will find it easier to navigate the world.  Your interpersonal fragility will decrease because you no longer depend on other people\u2019s love, acceptance, praise, approval, and appreciation.  In the past, if a friend went silent, you might immediately think you had done \"too much.\u201d You would wonder if you had said too much, revealed too much, acted too extremely, or acted in a way that elicited their judgment. You might have fallen into the trap of self-blame and shame. You might blame yourself for acting the way you did.  You might be unable to do anything else while you anxiously await their responses. You might wonder how you can edit your words and change your personality so that you will not be rejected again. If you had experienced family trauma in your childhood, intense feelings could arise. You might feel abandoned by the world and betrayed by those who are supposed to love you. You sink into a deep ditch of silent anger and hopelessness.  In some therapies, you are told to eradicate the thoughts and feelings because they are \u2018irrational\u2019 and that you are \u2018catastrophizing\u2019. But intellectually, knowing the rejection may or may not be true doesn\u2019t mean your nervous system can calm down. To the hurt inner child within you, even the mere chance that someone would dislike you can feel like the world is collapsing. Thus, rather than rationalizing and arguing with ourselves, the ultimate strategy is to parent yourself so well that you will no longer be dependent on other people\u2019s love and approval.  Here is a new path that will bring you more peace, freedom, and joy\u2014 the way of unconditional self-love. Having it, you no longer hinge on your peace and sanity on your other people\u2019s timely responses to you, what they think of you, or whether or not they like you.  Learn to be yourself \u2013 intense, sensitive, quietly empathetic, restless, curious, and passionate.  Do not pretend to know less than you do, do not hide the extent of your true feelings, and do not put yourself down before others say something . Make a joke even if it is not understood, cry when you feel the urge, and laugh out loud when you want to.  Call when you want to, be warm if you want to, and speak your mind without over-editing every word.  Express your strong opinions and respect others, tell them you are offended when you are, and it is okay to express your needs even you are not asking others to meet them.  Authenticity is your natural \u2018filter\u2019.  If someone loves the above, they are your person.  If not, you need not bow to their preferences and lovingly release them to find someone better suited to be their friend.  As long as you act honestly, the outcome is best for all. \" \"Feel in your body the deep knowledge that every animal, tree, and flower is your friend. You are anything but alone.  Look up into the sky and talk to \u2018God\u2019, the Buddha, Allah, any higher power that you believe in, or a departed loved one, knowing that they are forever in your heart and that love never ends.  Build a personal library and have virtual conversations with brilliant and like-minded souls near and far.  Create a piece of art or music that expresses your most profound truth, and know that the moment someone resonates with your work is a deep spiritual connection.  There are ways to take such good care of yourself that growing old means sage-ing up.  Know yourself so well that you say no to that which does not excite your heart.  Give yourself permission to receive nourishment and know that you are worth it.  Be so gentle, so loving, and compassionate with yourself that you feel safe in your own presence.  Be so encouraging and loving that you do not believe in mistakes, only in learning.  Accept the imperfection of friendships; enjoy what is there and let go of what is not.  Mourn the ideal parents you never had, but vow to be the best parents you can be, even to yourself.  Sylvia Plath did say the best way to get what you want is to be who you are.  So, starting today, when something has not gone the way you expected, when you feel judged, rejected, or abandoned, can you learn to be on your own side?  Shrug your shoulders.  Give yourself a big hug.  Then move on and Rock on.\"</p> </li> <li> <p>\"My feelings are too loud for words and too shy for the world.\"</p> </li> <li> <p>\"There might not have been any explicit trauma, but on a level deep inside, the parentified child did not feel welcome in the world.\"</p> </li> <li> <p>\"We may look like we are loved based on what can externally be seen, yet inside we feel like orphans\"</p> </li> <li> <p>\"Adulthood is an attempt to become the antithesis of the wounded child within us\"</p> </li> <li> <p>\"And as the ancient saying went, it is easy to dodge the spear in the open,   but hard to avoid a stab in the dark.\"</p> </li> <li> <p>\"Xiaochun\u2026\u201d he said softly. \"You\u2019re right. As long as we\u2019re alive, there are   endless possibilities. But just because we die doesn\u2019t mean that our hopes   and dreams die with us! \"I can\u2019t speak for anyone else, but I can say that   when I look at all of these graves, I'm absolutely certain\u2026 that these   disciples who died in battle did it because of the Dao that existed in their   hearts!\u201d</p> </li> <li> <p>\"You often found it easier just to adapt to their ideas of what was best for   you rather than trying to figure it out for yourself. But in all this   adapting to your society\u2019s attempts to make you fit in, and in your own   attempt to find less trouble, you have unwittingly relinquished your most   basic foundation: your total and absolute freedom to create.\"</p> </li> <li> <p>\"That is the optimal creative vantage point: To stand on the brink of what is   coming, feeling eager, optimistic anticipation\u2014with no feeling of impatience,   doubt, or unworthiness hindering the receiving of it\u2014that is the Science of   Deliberate Creation at its best.\"</p> </li> <li> <p>\"You cannot desire something, predominantly focus on the absence of it, and   then expect to receive it,\"</p> </li> <li> <p>\"You would not walk into a brightly lit room and look for the \"dark switch.\u201d   In other words, you would not expect to find a switch that would flood an   inky darkness into the room to cover the brightness of the light\u2014you would   find a switch that would resist the light, for in the absence of the light there is darkness.\"</p> </li> <li> <p>\"In a world that often seems too crowded or busy to notice beautiful things   or make meaningful connections, there is still room for each of us to grow in   the ways we were meant to.\"</p> </li> <li> <p>\"Conforming to convention is emptiness,\u201d replied Meng Hao. \"Yielding to and complying with the Heavens is well and good. Unending persistence is fine, too. However, I cannot choose either of those.\u201d</p> </li> <li> <p>\"It is hard for me to resent my parents, although I envy them their naivete.\"</p> </li> <li> <p>\"When Love cast me out, it was Cruelty who took pity upon me\"</p> </li> <li> <p>\"When you care for yourself first, the world will also find you worthy of care.\"</p> </li> <li> <p>\"But because of the weight of the secrets, we become more humble and understanding.\"</p> </li> <li> <p>\"Why should your life be destroyed by the easy criticism of those who do not know you or care about you?\u201d\"</p> </li> <li> <p>\"Just as a mother looks at her child with love, look at your own suffering with compassion. You will soon feel that you are not alone. There is a soft inner core of love and caring at the heart of every suffering. You are not thrown into this world alone.\"</p> </li> <li> <p>\"The greatest gift that parents can give their child is to be happy themselves. If the parents are happy, then the child can grow up into a happy and confident adult. But if the parents are not happy, then the child can feel worthless\u2014 unable to make his parents happy no matter what.\"</p> </li> <li> <p>\"The reason adolescents don\u2019t listen to their parents and stubbornly try to have their own way is that they are learning to be independent. It is normal, so don\u2019t worry too much.\"</p> </li> <li> <p>\"Do your best to give your children someone to look up to.\"</p> </li> <li> <p>\"It is nearly impossible for a son or daughter to change a parent\u2019s personality, values, or behavior. Even if children consider their parents problematic in some way, they have neither the right nor the responsibility to change them\"</p> </li> <li> <p>\"If you assume that, since you\u2019ve been together for so long, you should be able to read each other\u2019s minds, there are so many things you will fail to understand about each other.\"</p> </li> <li> <p>\"When someone is showing his temper, it could be because he wants us to hear about his current situation and empathize. Rather than arguing, try to understand his deeper needs\"</p> </li> <li> <p>\"If we think of the child as a stranger, we focus on the inconvenience to ourselves, but if we think of the child as a family member, we become merciful, wondering whether the child is uncomfortable or in pain\"</p> </li> <li> <p>\"If you give something your full attention, whatever it is, and examine it closely, it will come to attract your interest and care.\"</p> </li> <li> <p>\"My interest in philosophy started where I\u2019d imagine it starts for most people: a dissatisfaction with what I had been told about life combined with a curiosity about what I had not.\"</p> </li> <li> <p>\"My desire for knowledge is intermittent; but my desire to commune with the spirit of the universe, to be intoxicated with the fumes, call it, of that divine nectar, to bear my head through atmospheres and over heights\"</p> </li> <li> <p>\"My desire for knowledge is intermittent; but my desire to commune with the spirit of the universe, to be intoxicated with the fumes, call it, of that divine nectar, to bear my head through atmospheres and over heights unknown to my feet, is perennial and constant.\"</p> </li> <li> <p>\"the experience and effects of concrete knowledge can be fleeting, but the wonder found in the spirit of the unknown can be constant and enduring\"</p> </li> <li> <p>\"Nobody ever figures out what life is all about, and it doesn\u2019t matter. Explore the world. Nearly everything is really interesting if you go into it deeply enough,\"</p> </li> <li> <p>\"Through our eyes, the universe is perceiving itself. Through our ears, the universe is listening to its harmonies. We are the witnesses through which the universe becomes\"</p> </li> <li> <p>\"Through our eyes, the universe is perceiving itself. Through our ears, the universe is listening to its harmonies. We are the witnesses through which the universe becomes conscious of its glory, of its magnificence,\"</p> </li> <li> <p>\"As we experience more of life, and we are continually disappointed by our optimism\u2019s inability to align with the real conditions of the world, our optimism is beaten further and further into submission.\"</p> </li> <li> <p>\"healthy dose of pessimism is necessary in our ability to adequately deal with this life. It helps us mitigate our expectations and serves as padding that protects us from life\u2019s constant attempts to beat our spirit out of us. Pessimism counterbalances the ridiculously overly optimistic expectations of the culture we live in and helps us adapt out of the deeply detached, unrealistic perspective that we likely formed as children. It reminds us that things won\u2019t always go our way or always be that nice, but rather, things will go wrong a lot, but despite this, we can still be ok.\"</p> </li> <li> <p>\"To be completely optimistic about the rules always working in our favor would be foolish. However, to be completely pessimistic about the game as a whole simply because the rules don\u2019t always work in our favor would be equally foolish.\"</p> </li> <li> <p>\"the dirt of life, it is up to us to plant the seeds, watch the flowers grow, and enjoy their beauty, even in spite of the fact that we know that they will die.\"</p> </li> <li> <p>\"In the dirt of life, it is up to us to plant the seeds, watch the flowers grow, and enjoy their beauty, even in spite of the fact that we know that they will die.\"</p> </li> <li> <p>\"Perhaps all reality is a prison and time is its guard\"</p> </li> <li> <p>\"Perhaps what we should and only can do is to try to enjoy the process of playing with the blocks of philosophy like children playing with toy blocks for no reason other than the curiosity and fun of it; not because in the end the blocks will provide something that stays up forever, but because we inevitably will take the blocks down, put them away for a little while, and then play with them again on another day, in a different way.\"</p> </li> <li> <p>\"K\u014dans did not spring up out of lack of thought or contemplation, but rather, out of a specific sort of contemplation: a self-referential thinking that denies its ability to be a single, concrete, and universal thought that answers or understands what might exist beyond itself. Zen and the lesson of the k\u014dans suggest that we should flow with life, ask questions, contemplate them, but not become tricked by any singular idea or answer that might tempt us into a final resolution\"</p> </li> <li> <p>\"Just like how the center of a tornado is calm with little to no motion, despite it being surrounded by a coil of rapid, violent wind, we can live in the center of the tornado of knowing and unknowing and still remain calm and at ease.\"</p> </li> <li> <p>\"it takes no more than a sick stomach or migraine to realize just how heavy this corporeal weight is, how stricken and limited by it we are. We are stuck inside the body, captives to it, subject to its faulty and fragile mechanisms that do and will break, keeping us bound in space according to its condition\u2014until it finally turns itself off, and us with it.\"</p> </li> <li> <p>\"We can only think through the mind, and we can only think in the way our mind thinks.\"</p> </li> <li> <p>\"It is a demonstration of humanity\u2019s overzealous ego and anthropocentrism to think that so long as no other humans tell them what to do, they are free.\"</p> </li> <li> <p>\"Freedom can be manifested only in the void of beliefs, in the absence of axioms, and only where the laws have no more authority than a hypothesis,\"</p> </li> <li> <p>\"Like the desire for perfect, unending happiness, the desire for complete and absolute freedom is impossible. But like happiness, it is, in its true, ultimate form, a state that comes and goes, unattainable in the ideal but attainable in the moment\u2014in the moments when we surrender to the complete unified image of being, when we cease trying to square circles and placate everything that contests us, when we stop trying to escape what cannot be escaped. It is the classic lesson: the Chinese finger trap, the Tao in Taoism, Nirvana in Buddhism, the silence of Wittgenstein; the harder one tries, the harder one flails, the more entrenched one becomes.\"</p> </li> <li> <p>\"for you can only be free when even the desire of seeking freedom becomes a harness to you, and when you cease to speak of freedom as a goal and a fulfilment.\"</p> </li> <li> <p>\"In truth that which you call freedom is the strongest of these chains, though its links glitter in the sun and dazzle your eyes.\"</p> </li> <li> <p>\"When we persist with the belief that things outside of ourselves or things in the future will provide us with a form of ultimate happiness, we exchange the real moments of our lives for ones that do not exist. We become dependent on things outside of ourselves that we cannot control, and we endlessly run on a treadmill of unceasing desire.\"</p> </li> <li> <p>\"We can and should engage our nature to progress and pursue bigger, faster, better, and more interesting things, but we should ensure that in our pursuits, we are intentional about what we are doing so as to ensure that we are not being careless with our time and wasting our experience of life\"</p> </li> <li> <p>\"No matter what task we undertake, we will do it wastefully if we assume that anything beyond the task itself will provide anything better than the experience of focus and presence in the task.\"</p> </li> <li> <p>\"Until we have begun to go without them, we fail to realize how unnecessary many things are. We\u2019ve been using them not because we needed them but because we had them\"</p> </li> <li> <p>\"It is now that we must find time and it is now that we must find happiness if it is either that we are seeking, because if we do not focus the lens through which we view life right now, everything we see from this moment forward will remain out of focus\"</p> </li> <li> <p>\"Starting from birth, we seemingly run, if not sprint, through life, racing out of every moment, unsatisfied with what life is and constantly looking to the future for what life could be if we could just obtain something more or different. Our cultures overwhelm us with the reinforcement of this idea, convincing us that our duty is to achieve, buy, own, and live perfect, unaffected lives. This delusion, however, frenzies us with an anxiety that we are then told, by culture, that we can rid ourselves of if we just achieve a few more things, make a little more money, be a little more popular, and buy a little more stuff, creating an endless feedback loop of unsatisfied hunger. If we cave into this, we surrender our life, we give up our self.\"</p> </li> <li> <p>\"We don\u2019t have much, if any, control over what happens to us, how people see and treat us, or what happens because of what we do, and in the big picture, none of it really matters all that much anyway. And so, we must define our happiness not by what we own or achieve, not by how others see us, not by some bigger picture of life, but by how we think and see our self and live our own life through what we deem virtuous and relevant\"</p> </li> <li> <p>\"But of course, after a point, worrying about the future, the unknown, and the potential for things to go wrong is nothing but a useless handicap\"</p> </li> <li> <p>\"Once one has done everything that is rationally and realistically preventative, one should work to revert their attention back to the present, leaving all additional concern about the future for the future.\"</p> </li> <li> <p>\"But worrying about what one cannot know nor control in the future has no value to either, and comes at the cost of the present.\"</p> </li> <li> <p>\"We are more often frightened than hurt; and we suffer more from imagination than from reality.\"</p> </li> <li> <p>\"Man is not worried by real problems so much as by his imagined anxieties about real problems.\"</p> </li> <li> <p>\"There is a spectrum of human horrors, some far worse and more trying than others. In some cases, it is largely improbable to recover in the true sense of the term. But even if this is true, and one is worried about these sorts of horrible things happening, then again, they haven\u2019t happened yet.\"</p> </li> <li> <p>\"Human history is carved through trenches. We dip in and out of oscillating hardships, founded or unfounded. We are plagued by plagues and hatred and conflict and mortal fragility. But if we are fortunate enough to worry about something that is potentially not survivable happening to us as opposed to trying to survive something that already has, it is perhaps worth trying to be ok while we still are.\"</p> </li> <li> <p>\"Men are thrifty in guarding their private property, but as soon as it comes to wasting time, they are most extravagant with the one commodity for which it\u2019s respectable to be greedy,\"</p> </li> <li> <p>\"Seneca thought that because the present is so brief and immaterial, we mostly struggle to properly perceive and value\"</p> </li> <li> <p>\"Unlike the majority of possessions in life, you can\u2019t see, hold, or truly know time, making it incomprehensibly slippery and abstract. Seneca thought that because the present is so brief and immaterial, we mostly struggle to properly perceive and value it\"</p> </li> <li> <p>\"It is inevitable that life will be not just very short but very miserable for those who acquire by great toil what they must keep by greater toil\"</p> </li> <li> <p>\"It seems that, in this, the worthiest use of time is in some sense spending it on reflecting on time itself. By considering, or at least pondering time and how to best use it, one is paradoxically using it well.\"</p> </li> <li> <p>\"Wasted time or well-spent time is all the same when viewed from a sufficient distance, and it is only the individual who can examine, consider, and determine the best way to balance and claim their time in each moment. And, of course, all anyone can ever do is try their best.\"</p> </li> <li> <p>\"What makes the sad song that I listen to when I\u2019m in my worst of moods work is that it validates my feelings and transmutes them rather than denies them.\"</p> </li> <li> <p>\"We are perhaps the only stop on this evolutionary train that is outside the tunnel of darkness, able to take the material of everything and make it into something beautiful or helpful or interesting, to understand and create the meaning of meaning itself. And to do so just because we can, because the universe, for some reason, gave us a blank page to write on.\"</p> </li> <li> <p>\"As an assessment of the nature of reality, he would describe the Will as a sort of malevolent force that we, as individual selves, become victims of in its process of continuation, deceived by our own mind and body to go against our fundamental interests and yearnings in order to carry it out. Since the Will has no aim or purpose other than its perpetual continuation, then the Will can never be satisfied. And since we are expressions of it, neither can we. Thus, we are driven to consume beings, things, ideas, goals, circumstances, and all the rest, constantly hoping that we will feel satisfaction or happiness as a result, while constantly being left in the wake of each achievement unsatisfied.\"</p> </li> <li> <p>\"The safest way of not being very miserable is not to expect to be very happy,\u201d he wrote.\"</p> </li> <li> <p>\"There can be no turning against the Will if the Will is doing the turning.\"</p> </li> <li> <p>\"We are merely born into a crazy, sad, violent reality with a mind and body that are often all in conspiracy against us.\"</p> </li> <li> <p>\"There are no facts, only interpretations,\"</p> </li> <li> <p>\"If we have our own why in life, we shall get along with almost any how,\"</p> </li> <li> <p>\"My formula for greatness in a human being is amor fati: that one wants nothing to be different, not forward, not backward, not in all eternity. Not merely bear what is necessary, still less conceal it . . . but love it.\"</p> </li> <li> <p>\"But in this reality, the one we must live, there was no option to have done differently, and there is no other way for things to go. Every decision you\u2019ve made was the best and only decision you could\u2019ve made at the time with the information you had and the state of mind you were in. And every condition of life that either these decisions led to or that are fundamental to life in general, you have no control over and cannot change.\"</p> </li> <li> <p>\"I want to learn more and more to see as beautiful what is necessary in things; then I shall be one of those who make things\"</p> </li> <li> <p>\"I want to learn more and more to see as beautiful what is necessary in things; then I shall be one of those who make things beautiful. Amor fati: let that be my love henceforth! I do not want to wage war against what is ugly. I do not want to accuse; I do not even want to accuse those who accuse. Looking away shall be my only negation\"</p> </li> <li> <p>\"Ultimately, the question may not be how much you love your life right now, but how much you could and how. And perhaps sometimes the only way to experience the beauty of things is to think about things in a beautiful way.\"</p> </li> <li> <p>\"What\u2019s scarier than an opponent who smiles while being beaten?\"</p> </li> <li> <p>\"Even in writing about the futility and meaninglessness of life and its endeavors, the power of the creative process can, in some sense, save the writer from the very content of their own work, paradoxically making the futility and meaninglessness of life that they discuss somewhat less futile and meaningless.\"</p> </li> <li> <p>\"When all the current reasons\u2014moral, esthetic, religious, social, and so on\u2014no longer guide one\u2019s life, how can one sustain life without succumbing to nothingness? Only by a connection with the absurd, by love of absolute uselessness, loving something which does not have substance but which simulates an illusion of life. I live because the mountains do not laugh and the worms do not sing.\"</p> </li> <li> <p>\"Everything that is formulated becomes more tolerable\"</p> </li> <li> <p>\"Cursed with the gift of consciousness, we are all inescapably forced into a beautiful confrontation of the void and the absurd inevitability of creating meaning and somethingness out of it.\"</p> </li> <li> <p>\"In other words, one of the greatest writers and thinkers of the century lived his life with his work buried in some drawer, aware, unaware, or indifferent to the fact that he was sitting on some the most significant works in modern history. He was, in the eyes of his father, an inadequate disappointment\u2014and yet, in the eyes of history, he is an immensely important individual. One can only wonder how many individuals like Kafka have walked and continue to walk this earth, completely disconnected or restricted from ever seeing who they really are or could be. How many Kafkas have lived and died without ever sharing their voice with the world; voices that would have changed it forever?\"</p> </li> <li> <p>\"How many people never know who they\u2019ll be after they\u2019re gone?\"</p> </li> <li> <p>\"Perhaps in this, Kafka is suggesting that the struggle to find solace and understanding is both inescapable and impossible. As conscious, rational beings, we fight against the absurdity, trying to resolve the discrepancy between us and the universe. But ironically, we only serve to perpetuate the very struggle we are trying to resolve by trying to resolve the unresolvable. And in this sense, on some level, we almost want the struggle.\"</p> </li> <li> <p>\"Don\u2019t bend; don\u2019t water it down; don\u2019t try to make it logical; don\u2019t edit your own soul according to the fashion. Rather, follow your most intense obsessions mercilessly\"</p> </li> <li> <p>\"I think we ought to read only the kind of books that wound or stab us. If the book we\u2019re reading doesn\u2019t wake us up with a blow to the head, what are we reading for? So that it will make us happy . . . Good Lord, we would be happy precisely if we had no books. Kafka\u2019s\"</p> </li> <li> <p>\"Existence precedes essence.\u201d\"</p> </li> <li> <p>\"life exists for itself. Beyond itself, it is intrinsically meaningless.\"</p> </li> <li> <p>\"We each have our little flickers of time here. No one else will ever know much, if anything, of what it\u2019s like to be who we are. And for the most part, no one will ever really care. Our life is ultimately our life, and so long as we are not harming others in the process, we must create a life of our own meaning, determining our own objects of importance, committing to their pursuit, and reaping the significance and wonder of life along the way.\"</p> </li> <li> <p>\"However, perhaps it is less about getting a potential course of life right and more about attempting to do so with self-honesty and virtue\u2014to live a life that can be looked back on with the knowledge that some of our decisions were perhaps wrong in their effects but right in their intention not to sell ourselves short.\"</p> </li> <li> <p>\"At any street corner, the feeling of absurdity can strike any man in the face.\"</p> </li> <li> <p>\"Does such a thing as 'the fatal flaw,' that showy dark crack running down the middle of a life, exist outside literature? I used to think it didn't. Now I think it does. And I think that mine is this: a morbid longing for the picturesque at all costs.\"</p> </li> <li> <p>\"'Perhaps in certain ways it is a helpful construct in talking about\"</p> </li> <li> <p>\"'Psychology is a terrible word.' He agreed vigorously. 'Yes, it is terrible, isn't it?' he said, but with an expression that indicated that he thought it rather tasteless of me even to use it. 'Perhaps in certain ways it is a helpful construct in talking about a certain kind of mind. The country people who live around me are fascinating because their lives are so closely bound to fate that they really are predestined.\"</p> </li> <li> <p>\"Why does that obstinate little voice in our heads torment us so?' he said, looking round the table. 'Could it be because it reminds us that we are alive, of our mortality, of our individual souls \u2013 which, after all, we are too afraid to surrender but yet make us feel more miserable than any other thing? But isn't it also pain that often makes us most aware of self? It is a terrible thing to learn as a child that one is a being separate from all the world, that no one and no thing hurts along with one's burned tongues and skinned knees, that one's aches and pains are all one's own. Even more terrible, as we grow older, to learn that no person, no matter how beloved, can ever truly understand us. Our own selves make us most unhappy, and that's why we're so anxious to lose them, don't you think?\"</p> </li> <li> <p>\"'Aristotle says in the Poetics,' said Henry, 'that objects such as corpses, painful to view in themselves, can become delightful to contemplate in a work of art.'\"</p> </li> <li> <p>\"'Death is the mother of beauty,' said Henry. 'And what is beauty?' 'Terror,' 'Well said,' said Julian. 'Beauty is rarely soft or consolatory. Quite the contrary. Genuine beauty is always quite alarming.'\"</p> </li> <li> <p>\"'We don't like to admit it,' said Julian, 'but the idea of losing control is one that fascinates controlled people such as ourselves more than almost anything. All truly civilized people \u2013 the ancients no less than us \u2013 have civilized themselves through the willful repression of the old, animal self. Are we, in this room, really very different from the Greeks or the Romans? Obsessed with duty, piety, loyalty, sacrifice? All those things which are to modern tastes so chilling?'\"</p> </li> <li> <p>\"'And it's a temptation for any intelligent person, and especially for perfectionists such as the ancients and ourselves, to try to murder the primitive, emotive, appetitive self. But that is a mistake.' 'Why?' said Francis, leaning slightly forward. Julian arched an eyebrow; his long, wise nose gave his profile a forward tilt, like an Etruscan in a bas-relief. 'Because it is dangerous to ignore the existence of the irrational. The more cultivated a person is, the more intelligent, the more repressed, then the more he needs some method of channeling the primitive impulses he's worked so hard to subdue. Otherwise those powerful old forces will mass and strengthen until they are violent enough to break free, more violent for the delay, often strong enough to sweep the will away entirely.\"</p> </li> <li> <p>\"Pragma tists are often strangely superstitious.\"</p> </li> <li> <p>\"'Do you remember what we were speaking of earlier, of how bloody, terrible things are sometimes the most beautiful?' he said. 'It's a very Greek idea, and a very profound one. Beauty is terror. Whatever we call beautiful, we quiver before it. And what could be more terrifying and beautiful, to souls like the Greeks or our own, than to lose control completely? To throw off the chains of being for an instant, to shatter the accident of our mortal selves?\"</p> </li> <li> <p>\"Beauty is terror. We want to be devoured by it, to hide ourselves in that fire which refines us.'\"</p> </li> <li> <p>\"The chronological sorting of memories is an interesting business.\"</p> </li> <li> <p>\"Grown children (an oxymoron, I realize) veer instinctively to extremes; the young scholar is much more a pedant than his older counterpart.\"</p> </li> <li> <p>\"I suppose there is a certain crucial interval in everyone's life when character is fixed forever;\"</p> </li> <li> <p>\"Sometimes, when there's been an accident and reality is too sudden and strange to comprehend, the surreal will take over. Action slows to a dreamlike glide, frame by frame; the motion of a hand, a sentence spoken, fills an eternity. Little things \u2013 a cricket on a stem, the veined branches on a leaf- are magnified, brought from the background in achingly clear focus.\"</p> </li> <li> <p>\"It seemed my whole life was composed of these disjointed fractions of time, hanging around in one public place and then another, as if I were waiting for trains that never came.\"</p> </li> <li> <p>\"But, like the Invisible Man in H. G. Wells, I discovered that my gift had its price, which took the form of, in my case as in his, a sort of mental darkness. It seemed that people failed to meet my eye, made as if to walk through me; my superstitions began to transform themselves into something like mania.\"</p> </li> <li> <p>\"drink tonight?' One likes to think there's something in it, that old platitude amor vincit omnia. But if I've learned one thing in my short sad life, it is that that particular platitude is a lie. Love doesn't conquer everything. And whoever thinks it does is a fool.\"</p> </li> <li> <p>\"'I suppose that when anyone accustomed to working with the mind is faced with a straightforward action, there's a tendency to embellish, to make it overly clever. On paper there's a certain symmetry. Now that I'm faced with the prospect of executing it I realize how hideously complicated it is.'\"</p> </li> <li> <p>\"'I never realized, you know, how much we rely on appearances,'\"</p> </li> <li> <p>\"When the snow finally melted it went as quickly as it had come.\"</p> </li> <li> <p>\"'About a Hindu saint being able to slay a thousand on the battlefield and it not being a sin unless he felt remorse.'\"</p> </li> <li> <p>\"Alas, poor gentleman, He look'd not like the ruins of his youth But like the ruins of those ruins.\"</p> </li> <li> <p>\"You must know, a truly sincere heart is always lustrous!\u201d\"</p> </li> <li> <p>\"Punishing one\u2019s self for something one can no longer alter\u2026that is nothing more than being made a fool of by fate! The only one who rules over myself\u2026is myself!\u201d\"</p> </li> <li> <p>\"Live neither in the entanglements of outer things, nor in inner feelings of emptiness.\"</p> </li> <li> <p>\"When you try to stop activity by passivity your very effort fills you with activity.\"</p> </li> <li> <p>\"The more you talk and think about it, the further astray you wander from the truth.\"</p> </li> <li> <p>\"To return to the root is to find meaning, but to pursue appearances is to miss the source.\"</p> </li> <li> <p>\"Do not search for the truth; only cease to cherish opinions.\"</p> </li> <li> <p>\"A person\u2019s true nature is only revealed when he\u2019s pushed right to the edge, am I right? Now that their bellies are full, and they are feeling all nice and comfy, they are acting like a bunch of spoiled a.s.sholes. I don\u2019t like guys like Kang Seok, but that b.a.s.t.a.r.d\u2019s opinions aren\u2019t half wrong.\" \"\u2026.\" \"You continue being nice to them, they\u2019ll eventually end up thinking that it\u2019s their birthright or something. Well, in any case\u2026. Don\u2019t ever trust those two stinking b*tches, okay?\"</p> </li> <li> <p>\"He told himself, 'you find yourself in a such a favorable position, so much better than compared to other people, yet is this all you can do?\"</p> </li> <li> <p>\"When he was still addicted to gambling, he was constantly on edge. The victim mentality took center stage in his heart and caused him to choke up over nothing important; often, he\u2019d get defensive and angry even if he was in the wrong.\"</p> </li> <li> <p>\"Therefore whatever you desire for men to do to you, you shall also do to them; for this is the law and the prophets.\" \"Is that\u2026. the Golden Rule?\"</p> </li> <li> <p>\"Hiya~. And I heard that when a girl bears a grudge, even snow will fall in the middle of a Summer\"</p> </li> <li> <p>\"There will be other expeditions in the future. I pray that you don\u2019t bet everything on this one.\"</p> </li> <li> <p>\"Money and fame? Of course, they sounded nice. However, none of them compared to his own self-worth he had regained after such a struggle.\"</p> </li> <li> <p>\"Goodwill with goodwill, and malice with malice\u2026 I\u2019ve learned a lot during this expedition.\" \"I agree. After all, humans aren't the only race who possess intelligence.\"</p> </li> <li> <p>\"There is no right or wrong in matters of survival. In this world, whether you are a righteous man or of a wicked persuasion, you have to gather under one banner and pool your resources to survive. That is the case, even now.\"</p> </li> <li> <p>\"However, didn\u2019t Gula say it? The future was not that easy to change. That he\u2019d have to go through unimaginable trials and tribulations. That he needed to exceed his own limits\"</p> </li> <li> <p>\"Wait. Even if you don't do anything, there will be people who curse you. The more famous you get, the more hate you'll receive. Some people will even resent you. That's not the end of it. There will be a ton of people who are going to try to use you, even if you didn't do anything wrong.\"</p> </li> <li> <p>\"Just look at celebrities. Sure, some of them might deserve the hate they receive, but there are a lot more who don't. Do you know why haters leave mean comments or attack them on their social media? It's simple. Because they're unhappy, because they want attention, because they're bored, because they don't like the way someone looks, because they just want to argue, because they're jealous. There are countless reasons.\"</p> </li> <li> <p>\"What heals a wounded heart isn't time or medicine. It's sincerity\"</p> </li> <li> <p>\"Humans all have a limit to their vessel. The same goes for ghosts.\"</p> </li> <li> <p>\"I think life is like the four seasons. When spring pa.s.ses, summer comes. When summer leaves, autumn comes knocking. And when autumn departs, winter enters.\"</p> </li> <li> <p>\"In the four seasons of life, spring won't come just by waiting.\" \"\u2026.\" \"You have to endure the bitter cold and struggle to break through the frozen earth. Only then can you see the light of day and welcome spring.\"</p> </li> <li> <p>\"The moment the youth realized that he wasn't special, the only thing he could do was put in painstaking, bloodcurdling effort.\"</p> </li> <li> <p>\"You're right. It is hard. After all, you have to unite people who aren't like you and people who aren't like each other.\"</p> </li> <li> <p>\"They might think I'm just being c.o.c.ky.\" \"Only if you introduce yourself arrogantly. Depending on your att.i.tude or the situation, things might have gone in a different direction.\"</p> </li> <li> <p>\"Words have different weights depending on who says them. The words of a famous, authoritative person are different than the words of a nameless brat.\" Kazuki muttered endlessly. \"And fame is the strongest card in your possession. What's wrong about using something you've built up fair and square\"</p> </li> <li> <p>\"You need to know your value a bit more,\"</p> </li> <li> <p>\"You should find a style that suits your nature. You know, wear the clothes that fit you.\"</p> </li> <li> <p>\"He who wishes to wear the crown, bear its weight.\"</p> </li> <li> <p>\"The bigger your goals are, the bigger burden you must face.\"</p> </li> <li> <p>\"A leader is not someone who is placed in that position by someone else. A leader is someone who wishes to become a leader himself.\"</p> </li> <li> <p>\"People tend to get hasty when they aren't able to finish everything in time.\"</p> </li> <li> <p>\"In front of profit, justification changes depending on the situation and power at hand\"</p> </li> <li> <p>\"One could never predict everything in life, and life was bound to be full of ups and downs, but now that he had experienced this irony of fate, he couldn\u2019t help but feel bewildered.\"</p> </li> <li> <p>\"One could never predict everything in life, and life was bound to be full of ups and downs, but now that he had experienced this irony of fate, he couldn\u2019t help but feel bewildered. On the other hand, he felt a bit creeped out. Ian told him about this. That an action he considered insignificant might cause huge waves.\"</p> </li> <li> <p>\"Rather than struggling to overcome this emotion, he accepted it fully to get used to it\"</p> </li> <li> <p>\"You lose a war when you get scared.\u201d\"</p> </li> <li> <p>\"Life isn\u2019t a game you can see the ending of after clicking on one or two choices, is it?\"</p> </li> <li> <p>\"Because you\u2019re so uncomfortable with getting anything from my parents that they\u2019re too careful with doing anything for you\"</p> </li> <li> <p>\"Enduring an injustice makes you a person, but enduring a loss makes you a pushover\"</p> </li> <li> <p>\"A world where one only pursues their own freedom and success, throwing aside all morals and responsibilities. A world poisoned by self-indulgence.\u201d\"</p> </li> <li> <p>\"New wine has to be brewed in a new keg\"</p> </li> <li> <p>\"\u2018make the body learn if the brain can\u2019t understand\u2019.\"</p> </li> <li> <p>\"To grow, one must first face their flaws.\"</p> </li> <li> <p>\"That was just how human psychology worked. After hogging a jar of honey for a long time, they wouldn\u2019t feel comfortable sharing it with someone else.\"</p> </li> <li> <p>\"Seeing it once is better than hearing it a thousand times.\"</p> </li> <li> <p>\"There is no such thing as an eternal war. A war will end. Whether that be in a constructive way or a destructive way.\"</p> </li> <li> <p>\"There\u2019s no rule saying that battles have to be conducted with weapons. You can use words, money, or even law, religion, pen, and other things as well.\u201d\"</p> </li> <li> <p>\"Do you know what the most important thing is when a scammer is preparing to strike?\u201d Seol Jihu raised one of his eyebrows. Kim Hannah continued without batting an eye. \"It\u2019s simple \u2014 to make sure the person getting scammed doesn\u2019t know he\u2019s getting scammed.\u201d \"\u2026.\u201d \"Only when the scam is successful would they realize, \u2018Ah, that was a scam.\u2019\"</p> </li> <li> <p>\"When apologizing for a mistake, one should not be overly dignified, but one should also not lower oneself more than necessary\"</p> </li> <li> <p>\"When apologizing for a mistake, one should not be overly dignified, but one should also not lower oneself more than necessary either.\"</p> </li> <li> <p>\"Unless there was someone to say harsh words and correct mistakes, a child would grow up without knowing right and wrong.\"</p> </li> <li> <p>\"\u2014You\u2019re a terrifying man if you said that intentionally. But if you said that sincerely, then you\u2019re an even more terrifying person.\"</p> </li> <li> <p>\"I\u2019ve learned a lot this time and found a lot of things I have to keep learning.\u201d Seol Jihu candidly spoke. Hao Win peered at him from across the crystal. \u2014\u2026That\u2019s your scariest trait. It was an unexpected remark. \u2014You\u2019re a terrifying man if you said that intentionally. But if you said that sincerely, then you\u2019re an even more terrifying person. \"Huh?\u201d \u2014People change as their accomplishments stack and their position grows higher. They begin to think, \u2018I\u2019ve earned this much. I\u2019ve achieved all these things. What would you know?\u2019 They naturally begin to get full of themselves. He crossed his arms and continued in a tired voice. \u2014It\u2019s not easy to keep your initial resolve. I\u2019m no exception to this. Seol\"</p> </li> <li> <p>\"She remembered the saying, three men can speak a tiger into existence. Even a lie would seem real if enough people said it.\"</p> </li> <li> <p>\"There was a saying that people would confuse goodwill for privilege if it went on for too long\"</p> </li> <li> <p>\"I can\u2019t do something that goes against the law, but I also can\u2019t stand by and watch other people do things that go against the law. Being an unmoving spectator isn\u2019t a crime, but it is injustice.\"</p> </li> <li> <p>\"Being talented does not mean being smart or intelligent. It also has nothing to do with how they normally act.\"</p> </li> <li> <p>\"As someone once said, it was foolish to resent someone for their inborn talent; rather, one should try to take one step every day for ten, twenty years. Then one day, they would meet the person they always wanted to become.\"</p> </li> <li> <p>\"Just like how a genius had their own path, an ordinary person had their own path.\"</p> </li> <li> <p>\"I thought I could do it somehow, but\u2026 Sometimes I get so tired like today\u2026\"</p> </li> <li> <p>\"I thought I'd be fine\u2026\" He smacked his lips before continuing. \"I thought I could do it somehow, but\u2026 Sometimes I get so tired like today\u2026\"</p> </li> <li> <p>\"it was inevitable for amazing things to become familiar and new things to become worn-out. Such was the natural order of the world.\"</p> </li> <li> <p>\"I just was, actually. The past despair is what makes the present peace all the more precious, isn\u2019t it?\u201d Phi Sora flinched. She raised her head again\"</p> </li> <li> <p>\"Sure. Perhaps you really were trash like you say. I won\u2019t say the past is past. Wrongdoings of the past are wrongdoings nonetheless. But even if you committed a terrible sin, depending on whether you take that opportunity to learn from your mistakes or remain the same, you can either be recycled or become a waste.\u201d\"</p> </li> <li> <p>\"But laying one\u2019s weakness out in the open takes a lot of courage.\"</p> </li> <li> <p>\"Words, especially in philosophy, aren\u2019t used to logically explain that one plus one is two. No matter how nice something sounds, you need to ruminate over it and interpret it in such a way that it benefits you personally.\"</p> </li> <li> <p>\"Words, especially in philosophy, aren\u2019t used to logically explain that one plus one is two. No matter how nice something sounds, you need to ruminate over it and interpret it in such a way that it benefits you personally. Doubt is the origin of wisdom. Isn\u2019t that what Descartes said?\"</p> </li> <li> <p>\"Humans are not born for the sake of existing. Humans exist first. They decide on the meaning of life and their own values afterward. Through their own choice.\u201d\"</p> </li> <li> <p>\"Existentialism emphasizes the freedom of choice and the consequence of that choice. Depending on what you choose to do and how you choose to take responsibility, you can decide what life you will lead and what death you will meet.\u201d\"</p> </li> <li> <p>\"In other words, human beings are not trapped by destiny. They are existences capable of pioneering their own fate. They can decide for themselves by choosing and taking responsibility.\u201d\"</p> </li> <li> <p>\"There are countless people in this world. Naturally, countless fates are intertwined with each other in incomprehensible ways. Kind of like the stars in the night sky.\u201d\"</p> </li> <li> <p>\"Looking at the rising sun, Seol Jihu vowed internally. To become a sun that gives off the light on its own. To become a star that can share its light to other people. Both in Paradise and on Earth.\"</p> </li> <li> <p>\"Those Who Meet Eventually Bid Farewell While Those Who Have Parted Eventually Meet Again\"</p> </li> <li> <p>\"Look. There\u2019s a limit to improving your skills through simple repet.i.tive training. Even spear techniques like Thrust, Strike, and Cut have their limits. And of course, mindless repet.i.tion is even less effective for physical body skills like Intuition.\u201d\"</p> </li> <li> <p>\"Stop a.s.suming that if you keep trying, it will somehow work. Don\u2019t you have a brain? You\u2019ve walked this path more than a thousand times already.\u201d\"</p> </li> <li> <p>\"If your destination is far away, you need to think about getting there step\"</p> </li> <li> <p>\"Every flow has its ebbs, all that\u2019s fair must fade.\"</p> </li> <li> <p>\"You\u2019re an engineering major, right?\u201d \"Yes.\u201d \"I think sometimes you just think too hard. When you solve a problem, you expect each step to be logical and precise, like math.\u201d\"</p> </li> <li> <p>\"A soft answer turns away wrath. Sometimes the same word changes meaning depending on the context. You say one thing, and others will interpret it in hundreds of different ways.\"</p> </li> <li> <p>\"By lost, I mean that we momentarily lose touch with ourselves and with the full extent of our possibilities. Instead, we fall into a robotlike way of seeing and thinking and doing. In those moments, we break contact with what is deepest in ourselves and affords us perhaps our greatest opportunities for creativity, learning, and growing. If we are not careful, those clouded moments can stretch out and become most of our lives.\"</p> </li> <li> <p>\"We pay a high price for this mistaken and unexamined assumption, for our almost willful ignoring of the richness of our present moments. The fallout accumulates silently, coloring our lives without our knowing it or being able to do something about it. We may never quite be where we actually are, never quite touch the fullness of our possibilities. Instead, we lock ourselves into a personal fiction that we already know who we are, that we know where we are and where we are going, that we know what is happening\u2014all the while remaining enshrouded in thoughts, fantasies, and impulses, mostly about the past and about the future, about what we want and like, and what we fear and don\u2019t like, which spin out continuously, veiling our direction and the very ground we are standing on.\"</p> </li> <li> <p>\"Only that day dawns to which we are awake.\"</p> </li> <li> <p>\"understanding the nature of life and mind. Intelligence is the door to freedom and alert attention is the mother\"</p> </li> <li> <p>\"Intelligence is the door to freedom and alert attention is the mother of intelligence.\"</p> </li> <li> <p>\"expectations. So, in meditation practice, the best way to get somewhere is to let go of trying to get anywhere at all.\"</p> </li> <li> <p>\"If your mind isn\u2019t clouded by unnecessary things, This is the best season of your life.\"</p> </li> <li> <p>\"mistakes were often as revealing as the right answers.\"</p> </li> <li> <p>\"The truly correct proof is one that strikes a harmonious balance between strength and flexibility. There are plenty of proofs that are technically correct but are messy and inelegant or counterintuitive. But it's not something you can put into words\u2014explaining why a formula is beautiful is like trying to explain why the stars are beautiful.\"</p> </li> <li> <p>\"It was just a little puzzle,\" he would say, \"a game\"; and his tone sounded more sad than modest. \"The person who made the problem already knew the answer. Solving a problem for which you know there's an answer is like climbing a mountain with a guide, along a trail someone else has laid. In mathematics, the truth is somewhere out there in a place no one knows, beyond all the beaten paths. And it's not always at the top of the mountain. It might be in a crack on the smoothest cliff or somewhere deep in the valley.\"</p> </li> <li> <p>\"A problem has a rhythm of its own, just like a piece of music,\" the Professor said. \"Once you get the rhythm, you get the sense of the problem as a whole, and you can see where the traps might be waiting.\"</p> </li> <li> <p>\"Math has proven the existence of God, because it is absolute and without contradiction; but the devil must exist as well, because we cannot prove it.\"</p> </li> <li> <p>\"Eternal truths are ultimately invisible, and you won't find them in material things or natural phenomena, or even in human emotions. Mathematics, however, can illuminate them, can give them expression\u2014in fact, nothing can prevent it from doing so.\"</p> </li> <li> <p>\"So you think that zero was there waiting for us when humans came into being, like the flowers and the stars? You should have more respect for human progress. We made the zero, through great pain and struggle.\"</p> </li> <li> <p>\"Attention is the beginning of devotion\"</p> </li> <li> <p>\"Sometimes the things you hate are the things you need\"</p> </li> <li> <p>\"The absurd does not liberate; it binds.\"</p> </li> <li> <p>\"THE WISDOM OF LIFE CONSISTS IN THE ELIMINATION OF NONESSENTIALS.\"</p> </li> <li> <p>\"In this example is the basic value proposition of Essentialism: only once you give yourself permission to stop trying to do it all, to stop saying yes to everyone, can you make your highest contribution towards the things that really matter.\"</p> </li> <li> <p>\"It took courage, as it always does, to eliminate the nonessential.\"</p> </li> <li> <p>\"The way of the Essentialist means living by design, not by default.\"</p> </li> <li> <p>\"the pursuit of success can be a catalyst for failure.\"</p> </li> <li> <p>\"the more choices we are forced to make, the more the quality of our decisions deteriorates.\"</p> </li> <li> <p>\"It is not just the number of choices that has increased exponentially, it is also the strength and number of outside influences on our decisions that has increased.\"</p> </li> <li> <p>\"Instead of reacting to the social pressures pulling you to go in a million directions, you will learn a way to reduce, simplify, and focus on what is absolutely essential by eliminating everything else.\"</p> </li> <li> <p>\"If I didn't already own this, how much would I spend to buy it?\"</p> </li> <li> <p>\"One paradox of Essentialism is that Essentialists actually explore more options than their Nonessentialist counterparts.\"</p> </li> <li> <p>\"Remember, when we forfeit our right to choose, someone else will choose for us.\"</p> </li> <li> <p>\"There is tremendous freedom in learning that we can eliminate the nonessentials, that we are no longer controlled by other people's agendas, and that we get to choose.\"</p> </li> <li> <p>\"That's when I realized that in sacrificing my power to choose I had made a choice\u2014a bad one.\"</p> </li> <li> <p>\"The ability to choose cannot be taken away or even given away\u2014it can only be forgotten.\"</p> </li> <li> <p>\"My first act of free will shall be to believe in free will.\"</p> </li> <li> <p>\"MOST OF WHAT EXISTS IN THE UNIVERSE\u2014OUR ACTIONS, AND ALL OTHER FORCES, RESOURCES, AND IDEAS\u2014HAS LITTLE VALUE AND YIELDS LITTLE RESULT; ON THE OTHER HAND, A FEW THINGS WORK FANTASTICALLY WELL AND HAVE TREMENDOUS IMPACT.\"</p> </li> <li> <p>\"the Law of the Vital Few.\"2 His observation was that you could massively improve the quality of a product by resolving a tiny fraction of the problems.\"</p> </li> <li> <p>\"You cannot overestimate the unimportance of practically everything.\"9\"</p> </li> <li> <p>\"You have to look at every opportunity and say, 'Well, no \u2026 I'm sorry. We're not going to do a thousand different things that really won't contribute much to the end result we are trying to achieve.' \"</p> </li> <li> <p>\"A strategic position is not sustainable unless there are trade-offs with other positions.\"</p> </li> <li> <p>\"I didn't start out with the goal of devoting all of myself to my job. It crept in over time. Each year that went by, slight modifications became the new normal. First I spent a half-hour on Sunday organizing my e-mail, to-do list, and calendar to make Monday morning easier. Then I was working a few hours on Sunday, then all day. My boundaries slipped away until work was all that was left.\"</p> </li> <li> <p>\"to be acted upon. As economist Thomas Sowell wrote: \"There are no solutions. There are only trade-offs.\"7 Jim\"</p> </li> <li> <p>\"Trade-offs are not something to be ignored or decried. They are something to be embraced and made deliberately, strategically, and thoughtfully.\"</p> </li> <li> <p>\"Ironically, in a Nonessentialist culture these things\u2014space, listening, playing, sleeping, and selecting\u2014can be seen as trivial distractions. At best they are considered nice to have. At worst they are derided as evidence of weakness and wastefulness\"</p> </li> <li> <p>\"If somebody can't make the meeting because of too much going on, that tells me either we're doing something inefficiently or we need to hire more people.\"</p> </li> <li> <p>\"For some reason there is a false association with the word focus. As with choice, people tend to think of focus as a thing. Yes, focus is something we have. But focus is also something we do.\"</p> </li> <li> <p>\"Of course, nobody likes to be bored. But by abolishing any chance of being bored we have also lost the time we used to have to think and process.\"</p> </li> <li> <p>\"WHERE IS THE KNOWLEDGE WE HAVE LOST IN INFORMATION?\"</p> </li> <li> <p>\"As someone once said to me, the faintest pencil is better than the strongest memory.\"</p> </li> <li> <p>\"A LITTLE NONSENSE NOW AND THEN, IS CHERISHED BY THE WISEST MEN.\"</p> </li> <li> <p>\"We have sold ourselves into a fast-food model of education, and it's impoverishing our spirit and our energies as much as fast food is depleting our physical bodies.\u2026 Imagination is the source of every form of human achievement. And it's the one thing that I believe we are systematically jeopardizing in the way we educate our children and ourselves.\"2 In this he is correct. This idea that play is trivial stays with us as we reach adulthood and only becomes more ingrained as we enter the workplace. Sadly, not only do far too few companies and organizations foster play; many unintentionally undermine it. True, some companies and executives give lip service to the value of play in sparking creativity, yet most still fail to create the kind of playful culture that sparks true exploration. None of this should surprise us. Modern corporations were born out of the Industrial Revolution, when their entire reason for being was to achieve efficiency in the mass production of goods. Furthermore, these early managers looked to the military\u2014a rather less-than-playful entity\u2014for their inspiration (indeed, the language of the military is still strong in corporations today; we still often talk of employees being on the front lines, and the word company itself is a term for a military unit). While the industrial era is long behind us, those mores, structures, and systems continue to pervade most modern organizations. Play, which I would define as anything we do simply for the joy of doing rather than as a means to an end\u2014whether\"</p> </li> <li> <p>\"When I examine myself and my methods of thought, I come to the conclusion that the gift of fantasy has meant more to me than my talent for absorbing positive knowledge.\"</p> </li> <li> <p>\"Pushing oneself to the limit is easy! The real challenge for the person who thrives on challenges is not to work hard.\"</p> </li> <li> <p>\"If you think you are so tough you can do anything I have a challenge for you. If you really want to do something hard: say no to an opportunity so you can take a nap.\"</p> </li> <li> <p>\"If the answer isn't a definite yes then it should be a no.\"</p> </li> <li> <p>\"So why is it so hard in the moment to dare to choose what is essential over what is nonessential?\"</p> </li> <li> <p>\"So why is it so hard in the moment to dare to choose what is essential over what is nonessential? One simple answer is we are unclear about what is essential. When this happens we become defenseless.\"</p> </li> <li> <p>\"Nonessentialists say yes because of feelings of social awkwardness and pressure. They say yes automatically, without thinking, often in pursuit of the rush one gets from having pleased someone. But Essentialists know that after the rush comes the pang of regret. They know they will soon feel bullied and resentful\u2014both at the other person and at themselves.\"</p> </li> <li> <p>\"When people ask us to do something, we can confuse the request with our relationship with them. Sometimes they seem so interconnected, we forget that denying the request is not the same as denying the person.\"</p> </li> <li> <p>\"But part of living the way of the Essentialist is realizing respect is far more valuable than popularity in the long run.\"</p> </li> <li> <p>\"Saying no is its own leadership capability. It is not just a peripheral skill. As with any ability, we start with limited experience.\"</p> </li> <li> <p>\"Saying no is its own leadership capability. It is not just a peripheral skill. As with any ability, we start with limited experience. We are novices at \"no.\"</p> </li> <li> <p>\"HALF OF THE TROUBLES OF THIS LIFE CAN BE TRACED TO SAYING YES TOO QUICKLY AND NOT SAYING NO SOON ENOUGH.\"</p> </li> <li> <p>\"nobody in the history of the world has washed their rental car!\"</p> </li> <li> <p>\"Abandoning a project that you've invested a lot in feels like you've wasted everything, and waste is something we're told to avoid,\"</p> </li> <li> <p>\"It's natural not to want to let go of what we wasted on a bad choice, but when we don't, we doom ourselves to keep wasting even more.\"</p> </li> <li> <p>\"Instead of trying to budget your time on the basis of existing commitments, assume that all bets are off. All previous commitments are gone. Then begin from scratch, asking which you would add today.\"</p> </li> <li> <p>\"In a reverse pilot you test whether removing an initiative or activity will have any negative consequences.\"</p> </li> <li> <p>\"In other words, a good film editor makes it hard not to see what's important because she eliminates everything but the elements that absolutely need to be there.\"</p> </li> <li> <p>\"It's true that doing less can be harder, both in art and in life.\"</p> </li> <li> <p>\"The best surgeon is not the one who makes the most incisions; similarly, the best editors can sometimes be the least intrusive, the most restrained.\"</p> </li> <li> <p>\"NO IS A COMPLETE SENTENCE.\"</p> </li> <li> <p>\"But what most people don't realize is that the problem is not just that the boundaries have been blurred; it's that the boundary of work has edged insidiously into family territory. It is hard to imagine executives in most companies who would be comfortable with employees bringing their children to work on Monday morning, yet they seem to have no problem expecting their employees to come into the office or to work on a project on a Saturday or Sunday.\"</p> </li> <li> <p>\"Boundaries are a little like the walls of a sandcastle. The second we let one fall over, the rest of them come crashing down.\"</p> </li> <li> <p>\"Remember, forcing these people to solve their own problems is equally beneficial for you and for them.\"</p> </li> <li> <p>\"when we don't set clear boundaries in our lives we can end up imprisoned by the limits others have set for us.\"</p> </li> <li> <p>\"The only thing we can expect (with any great certainty) is the unexpected. Therefore, we can either wait for the moment and react to it or we can prepare. We can create a buffer.\"</p> </li> <li> <p>\"Instead of trying to improve every aspect of the facility he needs to identify the \"Herbie\": the part of the process that is slower relative to every other part of the plant\"</p> </li> <li> <p>\"Being good with a hammer, the Nonessentialist thinks everything is a nail. Thus he applies more and more pressure, but this ends up only adding more friction and frustration. Indeed, in some situations the harder you push on someone the harder he or she will push back.\"</p> </li> <li> <p>\"When we don't know what we're really trying to achieve, all change is arbitrary.\"</p> </li> <li> <p>\"Removing obstacles does not have to be hard or take a superhuman effort. Instead, we can start small. It's kind of like dislodging a boulder at the top of a hill. All it takes is a small shove, then momentum will naturally build.\"</p> </li> <li> <p>\"Each time a young person was recognized and commended for doing something good, he or she was that much more motivated to continue doing good until, eventually, doing good became natural and effortless.\"</p> </li> <li> <p>\"of all forms of human motivation the most effective one is progress.\"</p> </li> <li> <p>\"It is the process Pixar uses on their movies. Instead of starting with a script, they start with storyboards\u2014or what have been described as the comic book version of a movie. They try ideas out and see what works. They do this in small cycles hundreds of times. Then they put out a movie to small groups of people to give them advance feedback.\"</p> </li> <li> <p>\"We don't actually finish our films, we release them.\"</p> </li> <li> <p>\"ROUTINE, IN AN INTELLIGENT MAN, IS A SIGN OF AMBITION.\"</p> </li> <li> <p>\"This power of a routine grows out of our brain's ability to take over entirely until the process becomes fully unconscious.\"</p> </li> <li> <p>\"There is a difference between losing and being beaten. Being beaten means they are better than you. They are faster, stronger, and more talented.\" To Larry, losing means something else. It means you lost focus. It means you didn't concentrate on what was essential.\"</p> </li> <li> <p>\"Multitasking itself is not the enemy of Essentialism; pretending we can \"multifocus\" is.\"</p> </li> <li> <p>\"Suppose you are drinking a cup of tea. When you hold your cup, you may like to breathe in, to bring your mind back to your body, and you become fully present. And when you are truly there, something else is also there\u2014life, represented by the cup of tea. In that moment you are real, and the cup of tea is real. You are not lost in the past, in the future, in your projects, in your worries. You are free from all of these afflictions. And in that state of being free, you enjoy your tea. That is the moment of happiness, and of peace.\" Pay attention through the day\"</p> </li> <li> <p>\"BEWARE THE BARRENNESS OF A BUSY LIFE.\"</p> </li> <li> <p>\"Every choice we make to pursue the essential and eliminate the nonessential builds on itself, making that choice more and more habitual until it becomes virtually second nature.\"</p> </li> <li> <p>\"I continue to discover almost daily that I can do less and less\u2014in order to contribute more.\"</p> </li> <li> <p>\"If one's life is simple, contentment has to come. Simplicity is extremely important for happiness.\"</p> </li> <li> <p>\"The course of history is determined not by battles, by sieges, or usurpations, but by the actions of the individual. The strongest city, the largest army is, at its most basic level, a collection of individuals. Their decisions, their passions, their foolishness, and their dreams shape the years to come. If there is any lesson to be learned from history, it is that all too often the fate of armies, of cities, of entire realms rests upon the actions of one person. In that dire moment of uncertainty, that person's decision, good or bad, right or wrong, big or small, can unwittingly change the world. But history can be quite the slattern. One never knows who that person is, where he might be, or what decision he might make. It is almost enough to make me believe in Destiny.\"</p> </li> <li> <p>\"I think men who lust for power are capable of almost anything.\"</p> </li> <li> <p>\"When you reach my age, Amara, people show themselves to you very clearly. They write their intentions and beliefs through their actions, their lies.\"</p> </li> <li> <p>\"But the power to shake mountains does little good if the knife is already buried in one's throat\"</p> </li> <li> <p>\"There are some people who will never understand what loyalty means. They could tell you what it was, of course, but they will never know. They will never see it from the inside. They couldn't imagine a world where something like that was real.\"</p> </li> <li> <p>\"Courage.\" Tavi sighed. \"As near as I can figure it, all courage gets you is more of a beating than if you'd run away.\"</p> </li> <li> <p>\"There's two kinds of bad men in the world. I mean, there's all kinds of ways for a man to go bad, but when you get right down to it, there's only about two kinds of men who will hurt others with forethought. Premeditation. Men that don't figure there's anyone else alive who matters but them. And men who figure that there's something that matters more than anyone's life. Even their own.\" He shook his head. \"First one is common enough. Petty, small. They're everywhere. People who just don't give a scorched crow about anyone else. Mostly, the bad they do doesn't amount to much. \"The second kind is like your patriserus. People who hold something dear above their own lives, above anyone else's. They'll fight to protect it and kill to protect it, and the whole time they'll be thinking to themselves that it has to be done. That it's the right thing to do.\" Bernard glanced up at her and said, \"Dangerous those. Very dangerous.\"</p> </li> <li> <p>\"Sometimes,\" Bernard rumbled, \"the only smart thing to do is nothing. Sometimes you just have to be still and see how events begin to unfold before you move. Be patient.\"</p> </li> <li> <p>\"If the beginning of wisdom is in realizing that one knows nothing, then the beginning of understanding is in realizing that all things exist in accord with a single truth: large things are made of smaller things. Drops of ink are shaped into letters, letters form words, words form sentences, and sentences combine to express thought. So it is with the growth of plants that spring from seeds, as well as with walls built of many stones. So it is with mankind, as the customs and traditions of our progenitors blend together to form the foundation for our own cities, history, and way of life. Be they dead stone, living flesh, or rolling sea; be they idle times or events of world-shattering proportion, market days, or desperate battles, to this law, all things hold: Large things are made from small things. Significance is cumulative\u2014but not always obvious.\"</p> </li> <li> <p>\"Don't struggle to heal your wounds. Just pour time into your heart and wait\"</p> </li> <li> <p>\"you've been unable to change a bad situation, even after many attempts, you should\"</p> </li> <li> <p>\"If you've been unable to change a bad situation, even after many attempts, you should change how you look at the situation\"</p> </li> <li> <p>\"Awareness is inherently pure, like the open sky. Stress, irritation, and anger can temporarily cloud the sky, but they can never pollute it.\"</p> </li> <li> <p>\"The martial path was lonely. It was a source of great happiness if one found a confidant.\"</p> </li> <li> <p>\"The Azure Yang Lord's uninhibited life was filled with ups and down. Having felt both extreme happiness and sadness, he knew how difficult it was to earn happiness. If he could make this moment last forever, that would be a blissful matter\u2026 However, be it the Azure Yang Lord or the ancient Great Empress, they knew that these days were not going to last.\"</p> </li> <li> <p>\"Warriors had to suffer hardship and experience numerous life and death encounters. If they were not careful, they would lose their lives. They had to restrain their desires and endure lonely decades of reclusive training. Wasn't all this for them to lead a free life and do as they pleased when their power succeeded on reaching unprecedented heights!? Everything in the world depended on one's preference. To do as the heart pleased!\"</p> </li> <li> <p>\"The ways of the world are full of vicissitudes, and in it, there is the grief at separation and joy in union, the suffering of life and death. No matter how thick a history book is, it would not be able to record everything down. However, it is such infinite matters of the past that can pass by with a finger snap. In one's old age, while looking back at the past, only then would you feel like everything was ephemeral.\"</p> </li> <li> <p>\"The further he walked, the tinier he felt.\"</p> </li> <li> <p>\"Against the vast cosmos, the lives of people were like ants. It was like how bacteria did not know what it meant for the first and last day of the month, or how mole crickets did not know the seasons. What was a mortal's life to the Universe? Yi Yun did not want to remain like a speck of dust in the Universe.\"</p> </li> <li> <p>\"In a warrior's world, we may have the power to cause great destruction, have long lifespans, and are able to lead extravagant lives, but the pressure is intense. Be it life-and-death trials or breakthroughs that require great risks, or the sense of urgency of being killed by someone else at any moment in time, it forces us to continuously forge ahead.\" \"The accumulation of all these pressure naturally need an opportunity for it to be released.\"</p> </li> <li> <p>\"Before one's heart reduced to mediocrity, Great Dao lies within one's heart!\"</p> </li> <li> <p>\"Those without sufficient strength but can bear disgrace and a heavy burden are people who I appreciate as well.\"</p> </li> <li> <p>\"Time is like a flowing river. Everything and anything can be washed away by that river.\"</p> </li> <li> <p>\"Everyone had their own time, but time treated everyone equally.\"</p> </li> <li> <p>\"Were destruction and finality the end? Matter in the Universe could not remain eternal. They would eventually proceed towards destruction, including the Universe. But what happened after destruction? Could it be that all that was left was eternal 'nothingness'? Everything in the world underwent birth and death. A drop of water could evaporate and become part of a cloud before condensing into new drops of rain. Plants would wither, but the fruits that they bore could give rise to seeds. Mortals would die of age, but babies would grow up into adults. Stars could be destroyed, but new stars would eventually be born\u2026 Everything in the world underwent a cycle, so it definitely included the Universe. The destruction of the Universe was the beginnings of a new Universe. It was just that the cycle was immensely long that it was beyond the imagination of mere mortals. New Universe\u2026 Yi Yun suddenly seemed to realize something. What were the beginnings of the Universe? Dao begets One, One begets Two\u2026 Before Yin-Yang and Space-time was Chaos! Rebirth after destruction was Chaos and Major Destruction respectively. They were both two Great Dao of Supremacy! Why were there two Great Dao of Supremacy? They might be like Yin-Yang, Space-time, Water-Fire, just two sides of the Universe. The two could supplement each other and not a single one was dispensable.\"</p> </li> <li> <p>\"But if a warrior does not have any aspirations, he won't be able to go far either.\"</p> </li> <li> <p>\"To what end do we practice martial arts for? If we can't depend on the sword, so what about death? One's true richness of heart is not to be annihilated!\"</p> </li> <li> <p>\"Helping a man once gains gratitude, but not helping that man again gains hatred.\"</p> </li> <li> <p>\"grinding a chopper will not hold up the work of cutting firewood\"</p> </li> <li> <p>\"As the saying goes, he who gets other's kindness but does not repay is not a gentleman.\"</p> </li> <li> <p>\"History changes erratically. Time is enough to wipe away many things.\"</p> </li> <li> <p>\"Chaos in the world leads to the suffering of all life, but it is something some people are willing to see. Heroes are born in difficult times.\"</p> </li> <li> <p>\"Humans were warlike, to begin with. It was common among humans to fight unceasingly for their interests. Furthermore, there were some perverse people who wanted revenge on the world. Such people were even more dangerous. There was no limit to what they would do. Yi Yun knew that there was evil deeply rooted in human nature. However, he was not a person who would bemoan the state of the universe and mankind, much less the kind who would question life after seeing the ugly nature of humans and eventually decide to destroy the entire world in a crazy fit. He was only Yi Yun, an ordinary person that pursued the martial path, wanting his life to escape the cycle of samsara.\"</p> </li> <li> <p>\"When one postures to impress a girl, his failure becomes all the more foolish.\"</p> </li> <li> <p>\"When warriors took lives or destroyed an item, or even shattered a world, they could not avoid violence. Only time could turn everything into dust in an infinitely calm manner simply by passing. It was silent from beginning to end. Time was the most unique power of destruction. Yi\"</p> </li> <li> <p>\"A man who loses position and influence may be subjected to much indignity. It's all fated\u2026\"</p> </li> <li> <p>\"He who understands the times is a wise man.\"</p> </li> <li> <p>\"Yi Yun refused to believe that someone would forgo their lives for a master who had not won the hearts of people.\"</p> </li> <li> <p>\"We warriors have been cultivating our entire lives. What was it for? It's not to enjoy riches or sex. Nor is it about being placed on a pedestal while enslaving those beneath us! We cultivate to fight against our fate! We do not wish to to let Samsara run its course, so we cultivate for years! Our martial heritage has been passed down for millions of years, billions of years, and will be so for trillions of years! It's not for us to kneel down to beg for mercy after gaining mastery. With the backbone broken, there's no way one can straighten one's back.\"</p> </li> <li> <p>\"The Heavenly Dao's evolution is unending. Creation and Destruction are interchangeable, forming a complete circle. Be it life or a universe, they have formation, existence, disintegration, and emptiness; birth, aging, illness, and death. You wanted to devour the Heavenly Dao, robbing and changing the fate of the universe. You wanted to empower yourself by initiating the deaths of millions; hence, you were destined to be abandoned by the Heavenly Dao.\"</p> </li> <li> <p>\"Legends were typically like this. They would not be eclipsed with the passage of time, but instead, they became histories that one tried to live up to.\"</p> </li> <li> <p>\"Life, from lifeforms as large as towering trees to bugs as small as ants, the reason for all they do is for the continuation of their bloodline.\"</p> </li> <li> <p>\"In this Sinkhole that was filled with despair, a bunch of seniors were forging ahead bearing the burdens, so as to hold up the sky for the young. Although these seniors had their backs hunched from the pressures of time, to the point of not being able to bear the weight any further, that was already sufficient, no matter how tiny that piece of sky they held up was. They had already done everything they could have done.\"</p> </li> <li> <p>\"The crests and troughs of life are all but ephemeral mists. How nice if reunion and separation were fixed in place of that first meeting. A thousand years pass and happiness a certainty, but how much was sadness in exchange?\"</p> </li> <li> <p>\"Every artist has thousands of bad drawings in them and the only way to get rid of them is to draw them out. - Chuck Jones\"</p> </li> <li> <p>\"I spent years trying to behave \"appropriately\" so that other people would accept me, because underneath I felt like my true self was unworthy and underserving. Once I unravelled this ball I realized that I was just as worthy and deserving as anyone else, and I could start being myself\u2014my true self.\"</p> </li> <li> <p>\"Realize that 9 times out of 10, when you're worried about what other people think - it's a projection. You're projecting your own fears and your own internalized self-judgment onto other people. You're pinning on them what you yourself think. So when we take responsibility for letting go of other people's judgments we empower ourselves to stop being harsh and judgmental with ourselves too. Because ultimately they go hand-in-hand.\"</p> </li> <li> <p>\"Often when we get lost in worrying about what everyone else thinks it's because we're existing in a state of perpetual comparison. We look at what everyone else is doing and think that unless we're doing similarly we failed\"</p> </li> <li> <p>\"For me I think the lack of \"off leash\" non-self-regulation time also ties directly into the \"revenge bedtime procrastination\" phenom. I often find myself doing practically nothing or the mindless scrolling even though I am physically and mentally tired and WANT to sleep, but my brain is like \"I HAVENT HAD A RUN AROUND TODAY WE MUST STAY UP\"</p> </li> <li> <p>\"The absurd does not liberate; it binds.\"</p> </li> <li> <p>\"The wisdom of life consists in the elimination of nonessentials.\"</p> </li> <li> <p>\"In this example is the basic value proposition of Essentialism: only once you give yourself permission to stop trying to do it all, to stop saying yes to everyone, can you make your highest contribution towards the things that really matter.\"</p> </li> <li> <p>\"It took courage, as it always does, to eliminate the nonessential.\"</p> </li> <li> <p>\"The way of the Essentialist means living by design, not by default.\"</p> </li> <li> <p>\"the pursuit of success can be a catalyst for failure.\"</p> </li> <li> <p>\"the more choices we are forced to make, the more the quality of our decisions deteriorates.\"</p> </li> <li> <p>\"It is not just the number of choices that has increased exponentially, it is also the strength and number of outside influences on our decisions that has increased.\"</p> </li> <li> <p>\"Instead of reacting to the social pressures pulling you to go in a million directions, you will learn a way to reduce, simplify, and focus on what is absolutely essential by eliminating everything else.\"</p> </li> <li> <p>\"If I didn't already own this, how much would I spend to buy it?\"</p> </li> <li> <p>\"One paradox of Essentialism is that Essentialists actually explore more options than their Nonessentialist counterparts.\"</p> </li> <li> <p>\"Remember, when we forfeit our right to choose, someone else will choose for us.\"</p> </li> <li> <p>\"There is tremendous freedom in learning that we can eliminate the nonessentials, that we are no longer controlled by other people's agendas, and that we get to choose.\"</p> </li> <li> <p>\"That's when I realized that in sacrificing my power to choose I had made a choice\u2014a bad one.\"</p> </li> <li> <p>\"The ability to choose cannot be taken away or even given away\u2014it can only be forgotten.\"</p> </li> <li> <p>\"My first act of free will shall be to believe in free will.\"</p> </li> <li> <p>\"Most of what exists in the universe\u2014our actions, and all other forces, resources, and ideas\u2014has little value and yields little result; on the other hand, a few things work fantastically well and have tremendous impact.\"</p> </li> <li> <p>\"the Law of the Vital Few.  His observation was that you could massively improve the quality of a product by resolving a tiny fraction of the problems.\"</p> </li> <li> <p>\"You cannot overestimate the unimportance of practically everything.</p> </li> <li> <p>\"You have to look at every opportunity and say, 'Well, no \u2026 I'm sorry. We're not going to do a thousand different things that really won't contribute much to the end result we are trying to achieve.' \"</p> </li> <li> <p>\"A strategic position is not sustainable unless there are trade-offs with other positions.\"</p> </li> <li> <p>\"I didn't start out with the goal of devoting all of myself to my job. It crept in over time. Each year that went by, slight modifications became the new normal. First I spent a half-hour on Sunday organizing my e-mail, to-do list, and calendar to make Monday morning easier. Then I was working a few hours on Sunday, then all day. My boundaries slipped away until work was all that was left.\"</p> </li> <li> <p>\"to be acted upon. As economist Thomas Sowell wrote: \"There are no solutions. There are only trade-offs.\"7 Jim\"</p> </li> <li> <p>\"Trade-offs are not something to be ignored or decried. They are something to be embraced and made deliberately, strategically, and thoughtfully.\"</p> </li> <li> <p>\"Ironically, in a Nonessentialist culture these things\u2014space, listening, playing, sleeping, and selecting\u2014can be seen as trivial distractions. At best they are considered nice to have.\"</p> </li> <li> <p>\"Ironically, in a Nonessentialist culture these things\u2014space, listening, playing, sleeping, and selecting\u2014can be seen as trivial distractions. At best they are considered nice to have. At worst they are derided as evidence of weakness and wastefulness\"</p> </li> <li> <p>\"If somebody can't make the meeting because of too much going on, that tells me either we're doing something inefficiently or we need to hire more people.\"</p> </li> <li> <p>\"For some reason there is a false association with the word focus. As with choice, people tend to think of focus as a thing. Yes, focus is something we have. But focus is also something\"</p> </li> <li> <p>\"For some reason there is a false association with the word focus. As with choice, people tend to think of focus as a thing. Yes, focus is something we have. But focus is also something we do.\"</p> </li> <li> <p>\"Of course, nobody likes to be bored. But by abolishing any chance of being bored we have also lost the time we used to have to think and process.\"</p> </li> <li> <p>\"Where is the knowledge we have lost in information?\"</p> </li> <li> <p>\"As someone once said to me, the faintest pencil is better than the strongest memory.\"</p> </li> <li> <p>\"A little nonsense now and then, is cherished by the wisest men.\"</p> </li> <li> <p>\"We have sold ourselves into a fast-food model of education, and it's impoverishing our spirit and our energies as much as fast food is depleting our physical bodies.\u2026 Imagination is the source of every form of human achievement. And it's the one thing that I believe we are systematically jeopardizing in the way we educate our children and ourselves.\"2 In this he is correct. This idea that play is trivial stays with us as we reach adulthood and only becomes more ingrained as we enter the workplace. Sadly, not only do far too few companies and organizations foster play; many unintentionally undermine it. True, some companies and executives give lip service to the value of play in sparking creativity, yet most still fail to create the kind of playful culture that sparks true exploration. None of this should surprise us. Modern corporations were born out of the Industrial Revolution, when their entire reason for being was to achieve efficiency in the mass production of goods. Furthermore, these early managers looked to the military\u2014a rather less-than-playful entity\u2014for their inspiration (indeed, the language of the military is still strong in corporations today; we still often talk of employees being on the front lines, and the word company itself is a term for a military unit). While the industrial era is long behind us, those mores, structures, and systems continue to pervade most modern organizations. Play, which I would define as anything we do simply for the joy of doing rather than as a means to an end\u2014whether\"</p> </li> <li> <p>\"When I examine myself and my methods of thought, I come to the conclusion that the gift of fantasy has meant more to me than my talent for absorbing positive knowledge.\"</p> </li> <li> <p>\"Pushing oneself to the limit is easy! The real challenge for the person who thrives on challenges is not to work hard.\"</p> </li> <li> <p>\"If you think you are so tough you can do anything I have a challenge for you. If you really want to do something hard: say no to an opportunity so you can take a nap.\"</p> </li> <li> <p>\"If the answer isn't a definite yes then it should be a no.\"</p> </li> <li> <p>\"So why is it so hard in the moment to dare to choose what is essential over what is nonessential?\"</p> </li> <li> <p>\"So why is it so hard in the moment to dare to choose what is essential over what is nonessential? One simple answer is we are unclear about what is essential. When this happens we become defenseless.\"</p> </li> <li> <p>\"Nonessentialists say yes because of feelings of social awkwardness and pressure. They say yes automatically, without thinking, often in pursuit of the rush one gets from having pleased someone. But Essentialists know that after the rush comes the pang of regret. They know they will soon feel bullied and resentful\u2014both at the other person and at themselves.\"</p> </li> <li> <p>\"When people ask us to do something, we can confuse the request with our relationship with them. Sometimes they seem so interconnected, we forget that denying the request is not the same as denying the person.\"</p> </li> <li> <p>\"But part of living the way of the Essentialist is realizing respect is far more valuable than popularity in the long run.\"</p> </li> <li> <p>\"Saying no is its own leadership capability. It is not just a peripheral skill. As with any ability, we start with limited experience. We are novices at \"no.\"</p> </li> <li> <p>\"Half of the troubles of this life can be traced to saying yes too quickly and not saying no soon enough.\"</p> </li> <li> <p>\"nobody in the history of the world has washed their rental car!\"</p> </li> <li> <p>\"Abandoning a project that you've invested a lot in feels like you've wasted everything, and waste is something we're told to avoid,\"</p> </li> <li> <p>\"It's natural not to want to let go of what we wasted on a bad choice, but when we don't, we doom ourselves to keep wasting even more.\"</p> </li> <li> <p>\"Instead of trying to budget your time on the basis of existing commitments, assume that all bets are off. All previous commitments are gone. Then begin from scratch, asking which you would add today.\"</p> </li> <li> <p>\"In a reverse pilot you test whether removing an initiative or activity will have any negative consequences.\"</p> </li> <li> <p>\"In other words, a good film editor makes it hard not to see what's important because she eliminates everything but the elements that absolutely need to be there.\"</p> </li> <li> <p>\"It's true that doing less can be harder, both in art and in life.\"</p> </li> <li> <p>\"The best surgeon is not the one who makes the most incisions; similarly, the best editors can sometimes be the least intrusive, the most restrained.\"</p> </li> <li> <p>\"No is a complete sentence.\"</p> </li> <li> <p>\"But what most people don't realize is that the problem is not just that the boundaries have been blurred; it's that the boundary of work has edged insidiously into family territory. It is hard to imagine executives in most companies who would be comfortable with employees bringing their children to work on Monday morning, yet they seem to have no problem expecting their employees to come into the office or to work on a project on a Saturday or Sunday.\"</p> </li> <li> <p>\"Boundaries are a little like the walls of a sandcastle. The second we let one fall over, the rest of them come crashing down.\"</p> </li> <li> <p>\"Remember, forcing these people to solve their own problems is equally beneficial for you and for them.\"</p> </li> <li> <p>\"When we don't set clear boundaries in our lives we can end up imprisoned by the limits others have set for us.\"</p> </li> <li> <p>\"The only thing we can expect (with any great certainty) is the unexpected. Therefore, we can either wait for the moment and react to it or we can prepare. We can create a buffer.\"</p> </li> <li> <p>\"Instead of trying to improve every aspect of the facility he needs to identify the \"Herbie\": the part of the process that is slower relative to every other part of the plant\"</p> </li> <li> <p>\"Being good with a hammer, the Nonessentialist thinks everything is a nail. Thus he applies more and more pressure, but this ends up only adding more friction and frustration. Indeed, in some situations the harder you push on someone the harder he or she will push back.\"</p> </li> <li> <p>\"When we don't know what we're really trying to achieve, all change is arbitrary.\"</p> </li> <li> <p>\"Removing obstacles does not have to be hard or take a superhuman effort. Instead, we can start small. It's kind of like dislodging a boulder at the top of a hill. All it takes is a small shove, then momentum will naturally build.\"</p> </li> <li> <p>\"Each time a young person was recognized and commended for doing something good, he or she was that much more motivated to continue doing good until, eventually, doing good became natural and effortless.\"</p> </li> <li> <p>\"of all forms of human motivation the most effective one is progress.\"</p> </li> <li> <p>\"It is the process Pixar uses on their movies. Instead of starting with a script, they start with storyboards\u2014or what have been described as the comic book version of a movie. They try ideas out and see what works. They do this in small cycles hundreds of times. Then they put out a movie to small groups of people to give them advance feedback.\"</p> </li> <li> <p>\"We don't actually finish our films, we release them.\"</p> </li> <li> <p>\"Routine, in an intelligent man, is a sign of ambition.\"</p> </li> <li> <p>\"This power of a routine grows out of our brain's ability to take over entirely until the process becomes fully unconscious.\"</p> </li> <li> <p>\"There is a difference between losing and being beaten. Being beaten means they are better than you. They are faster, stronger, and more talented.\" To Larry, losing means something else. It means you lost focus. It means you didn't concentrate on what was essential.\"</p> </li> <li> <p>\"Multitasking itself is not the enemy of Essentialism; pretending we can \"multifocus\" is.\"</p> </li> <li> <p>\"Suppose you are drinking a cup of tea. When you hold your cup, you may like to breathe in, to bring your mind back to your body, and you become fully present. And when you are truly there, something else is also there\u2014life, represented by the cup of tea. In that moment you are real, and the cup of tea is real. You are not lost in the past, in the future, in your projects, in your worries. You are free from all of these afflictions. And in that state of being free, you enjoy your tea. That is the moment of happiness, and of peace.\" Pay attention through the day\"</p> </li> <li> <p>\"Beware the barrenness of a busy life.\"</p> </li> <li> <p>\"Every choice we make to pursue the essential and eliminate the nonessential builds on itself, making that choice more and more habitual until it becomes virtually second nature.\"</p> </li> <li> <p>\"I continue to discover almost daily that I can do less and less\u2014in order to contribute more.\"</p> </li> <li> <p>\"If one's life is simple, contentment has to come. Simplicity is extremely important for happiness.\"</p> </li> <li> <p>\"The course of history is determined not by battles, by sieges, or usurpations, but by the actions of the individual. The strongest city, the largest army is, at its most basic level, a collection of individuals. Their decisions, their passions, their foolishness, and their dreams shape the years to come. If there is any lesson to be learned from history, it is that all too often the fate of armies, of cities, of entire realms rests upon the actions of one person. In that dire moment of uncertainty, that person's decision, good or bad, right or wrong, big or small, can unwittingly change the world. But history can be quite the slattern. One never knows who that person is, where he might be, or what decision he might make. It is almost enough to make me believe in Destiny.\"</p> </li> <li> <p>\"I think men who lust for power are capable of almost anything.\"</p> </li> <li> <p>\"When you reach my age, Amara, people show themselves to you very clearly. They write their intentions and beliefs through their actions, their lies.\"</p> </li> <li> <p>\"But the power to shake mountains does little good if the knife is already buried in one's throat\"</p> </li> <li> <p>\"There are some people who will never understand what loyalty means. They could tell you what it was, of course, but they will never know. They will never see it from the inside. They couldn't imagine a world where something like that was real.\"</p> </li> <li> <p>\"Courage.\" Tavi sighed. \"As near as I can figure it, all courage gets you is more of a beating than if you'd run away.\"</p> </li> <li> <p>\"There's two kinds of bad men in the world. I mean, there's all kinds of ways for a man to go bad, but when you get right down to it, there's only about two kinds of men who will hurt others with forethought. Premeditation. Men that don't figure there's anyone else alive who matters but them. And men who figure that there's something that matters more than anyone's life. Even their own.\" He shook his head. \"First one is common enough. Petty, small. They're everywhere. People who just don't give a scorched crow about anyone else. Mostly, the bad they do doesn't amount to much. \"The second kind is like your patriserus. People who hold something dear above their own lives, above anyone else's. They'll fight to protect it and kill to protect it, and the whole time they'll be thinking to themselves that it has to be done. That it's the right thing to do.\" Bernard glanced up at her and said, \"Dangerous those. Very dangerous.\"</p> </li> <li> <p>\"Sometimes,\" Bernard rumbled, \"the only smart thing to do is nothing. Sometimes you just have to be still and see how events begin to unfold before you move. Be patient.\"</p> </li> <li> <p>\"If the beginning of wisdom is in realizing that one knows nothing, then the beginning of understanding is in realizing that all things exist in accord with a single truth: large things are made of smaller things. Drops of ink are shaped into letters, letters form words, words form sentences, and sentences combine to express thought. So it is with the growth of plants that spring from seeds, as well as with walls built of many stones. So it is with mankind, as the customs and traditions of our progenitors blend together to form the foundation for our own cities, history, and way of life. Be they dead stone, living flesh, or rolling sea; be they idle times or events of world-shattering proportion, market days, or desperate battles, to this law, all things hold: Large things are made from small things. Significance is cumulative\u2014but not always obvious.\"</p> </li> <li> <p>\"Don't struggle to heal your wounds. Just pour time into your heart and wait\"</p> </li> <li> <p>\"If you've been unable to change a bad situation, even after many attempts, you should change how you look at the situation\"</p> </li> <li> <p>\"Awareness is inherently pure, like the open sky. Stress, irritation, and anger can temporarily cloud the sky, but they can never pollute it.\"</p> </li> <li> <p>\"Having critics means what you're doing is getting people's attention\"</p> </li> <li> <p>\"To be happy, it's not necessary to expend great effort so we get somewhere else. Instead, relax into the present moment while finding humor in your life. With humor, life becomes light and leisurely. And laughter always brings people to experience openness and joy\"</p> </li> <li> <p>\"Humor opens closed hearts.\"</p> </li> <li> <p>\"as frequently as you can as a family. Although we see our family every day, we don't really get to be with\"</p> </li> <li> <p>\"Although we see our family every day, we don't really get to be with one another. A change in environment can do wonders and can bring families closer. A good family trip can prevent divorce. What makes music beautiful is the distance between one note and another. What makes speech eloquent is the appropriate pause between words. From time to time we should take a breath and notice the silence between sounds. When you have to make an important decision,\"</p> </li> <li> <p>\"The world will keep turning even without you. Let go of the idea that your way is the only way, that you are the only one who can make it happen\"</p> </li> <li> <p>\"Therefore, much like a mirror reflects what is before it without judgment or identification with the image, simply reflect the negative emotion\u2014let's say it's anger\u2014and watch dispassionately. You will see the anger slowly changing shape, either revealing a deeper layer of emotion or disappearing on its own. If another layer of emotion is revealing itself, attend to it the way you did with your anger.\"</p> </li> <li> <p>\"pure attention without judgment is not only the highest form of human intelligence, but also the expression of love\"</p> </li> <li> <p>\"No person can be found Who has been, is, or will be Only criticized Or only praised.\"</p> </li> <li> <p>\"When someone criticizes another, you might think he deserves it. But if you look more closely, you'll see that the critic is complaining because he did not get his way.\"</p> </li> <li> <p>\"As we resist, we are in constant motion trying to adjust, and yet we still remain unhappy about what is\"</p> </li> <li> <p>\"When you cannot control even your own mind, what makes you think you can control others?\"</p> </li> <li> <p>\"Whether it is an object, a thought, or a feeling, if it has emerged out of emptiness, it will soon change its form and eventually retreat back to emptiness. Seekers in search of the eternal Truth must look beyond its impermanent nature and become aware of \"that\" which knows impermanence\"</p> </li> <li> <p>\"Spirituality must be practiced not just in solitude but also among people. Open up to people around you and feel connected. This is the true challenge of spiritual practice.\"</p> </li> <li> <p>\"Feelings are often born from a matrix of conditions beyond your control. Just like you can't control the weather, or your boss's mood, you can't control the feelings in your body. They are just passing through, like clouds in the sky. They, too, dissipate on their own. But if you take them too seriously and start internalizing them as part of your identity, then you will resuscitate them every time you think about the past. Remember that you are neither your feelings nor the story your mind tells about you to make sense of them. You are the vast silence that knows of their emergence and their disappearance\"</p> </li> <li> <p>\"Of all the words that pour out of our mouths every day, how many are really ours, and how many are borrowed from others?\"</p> </li> <li> <p>\"Everything in this universe is evanescent. Because it is evanescent, it is also precious. Spend this precious moment wisely and beautifully. The mind cannot have two thoughts at once. See if you can think two thoughts at exactly the same time. Well? Is it possible? We can be consumed by anger for a long time without realizing we have been angry. Similarly, we are easily lost in thought without knowing we have been thinking. Even when we are awake we are no different from a sleepwalker. We do things without the awareness of doing them. Just because our eyes are open does not mean we are awake. Being awake means that\"</p> </li> <li> <p>\"When I gaze upon water, I become water. When I look at a flower, I become the flower. The flower riding on the water, yippee!\"</p> </li> <li> <p>\"A long time ago, there was only one mind, which became bored by being alone for so long. So it decided to split into two. But since the two knew they were originally one, playing together was not much fun\u2014 as if playing both sides of a chess game. So the two minds agreed to forget where they came from; they pretended not to know each other. As time passed, they also forgot about their agreement. They forgot they were actually one and the same. This is the condition of our existence. We forget that we are originally from one mind.\"</p> </li> <li> <p>\"Life is like theater. You are assigned a role. If you don't like the role, keep in mind that you have the power to re-create the role you want\"</p> </li> <li> <p>\"something I should have known all along. When we're first given a job, especially one we've been working toward for a long time, it's easy to become overly enthusiastic, as we are eager to prove ourselves. But in our excitement, we make the mistake of equating our own eagerness with effectiveness\"</p> </li> <li> <p>\"When we're first given a job, especially one we've been working toward for a long time, it's easy to become overly enthusiastic, as we are eager to prove ourselves. But in our excitement, we make the mistake of equating our own eagerness with effectiveness. Getting the job done well is more important than one's feelings of doing a good job. It takes wisdom to discern that these two are not always related. In some cases, one's zealous efforts can get in the way of achieving the desired outcome, especially if one is unable to see the needs of the others working toward it together\"</p> </li> <li> <p>\"The world notices your efforts more quickly than you think\"</p> </li> <li> <p>\"It is important that you work hard, but don't be enamored of the feeling of working hard. If you are drunk on that feeling, then you care less about the actual work than about how you appear to others to be working hard.\"</p> </li> <li> <p>\"A person does not live the way he says he would. He lives the way he has been living\"</p> </li> <li> <p>\"A vow to help others can summon immense energy from within.\"</p> </li> <li> <p>\"When you are making a decision, try to assess how many people it will benefit. If it satisfies only your ego and unnecessarily hurts many, then it is the wrong decision\"</p> </li> <li> <p>\"Isn't it better to be happy together than to be right alone?\"</p> </li> <li> <p>\"One lesson of maturity is that we should not take our thoughts too seriously, and must learn to curb our ego and see the bigger picture.\"</p> </li> <li> <p>\"Criticism without a solution is merely an inflation of the critic's ego.\"</p> </li> <li> <p>\"When you ask a question and there is no response, then that is the answer.\"</p> </li> <li> <p>\"Don't try to make it perfect. Instead, make it interesting!\"</p> </li> <li> <p>\"After mastering eighteen levels of kung fu, you can hurt someone with the flick of a finger. But if you go on to master all thirty-six levels, you choose to retreat when the weak foolishly come to fight\"</p> </li> <li> <p>\"From this experience I realized that the art of maintaining a good relationship can be compared to sitting by a fireplace. If we sit too close for too long, we become hot and possibly burned. If we sit too far away, we cannot feel the warmth. Similarly, no matter how well we get along with someone, if we stick too close without building in some personal space, we soon feel trapped and burned out; it is easy to take the relationship for granted and feel resentful about not having enough privacy and independence. On the other hand, if we put in too little effort to stay in touch with friends and family, we can't feel the warmth of their love. Striking a balance is key\"</p> </li> <li> <p>\"cup was full. Perplexed, Maeng demanded to know what he was doing. \"You seem to know that too much tea will ruin the floor,\" the master answered, \"but how do you not know that too much knowledge will ruin one's character?\"</p> </li> <li> <p>\"If you lower your head, you won't bump into trouble.\"</p> </li> <li> <p>\"Do not expect others to follow your way. When things always go your way, it is easy to become arrogant.\"</p> </li> <li> <p>\"The end of a sushi roll, with the filling sticking out, is often tastier than a piece sliced neatly from the middle. Someone slick and well-put-together can come across as cold and alienating, while an average guy without pretense is more genuine and attractive\"</p> </li> <li> <p>\"People say hurtful things because they themselves have been hurt.\"</p> </li> <li> <p>\"If you wish to communicate effectively with others, better to describe what you are feeling rather than go on the offensive. For instance, say, \"I am very sad to hear that,\" not, \"Why do you always make me sad?\"</p> </li> <li> <p>\"When you criticize someone, see if you are doing so out of envy. Your criticism reveals more about yourself than you realize. Even if you are correct, people still may find you unappealing. If you wish to communicate effectively with others, better to describe what you are feeling rather than go on the offensive. For instance, say, \"I am very sad to hear that,\" not, \"Why do you always make me sad?\" You\"</p> </li> <li> <p>\"You want people to hear you rather than have to defend themselves from you\"</p> </li> <li> <p>\"When blinded by anger, we make choices we later regret. Leaving the room before the bridge is burned is a sign of maturity\"</p> </li> <li> <p>\"The best revenge is love\"</p> </li> <li> <p>\"Paper wrapped around incense smells of incense, and string binding fish smells of fish.\"</p> </li> <li> <p>\"The best way to hide your wealth is to give it away. If you are generous with your wealth, the money that would have disappeared sooner or later\"</p> </li> <li> <p>\"Whether we like it or not, we are all connected, and it is unthinkable to be happy all by oneself.\"</p> </li> <li> <p>\"Inside of us there is a steep mountain of fear and a deep river of grief. But there is also the compassionate eye witnessing your inner landscape. May you find your inner witness, the source of freedom and healing.\"</p> </li> <li> <p>\"Does the person you hate deserve to be carried around in your heart?\"</p> </li> <li> <p>\"Humans are like mirrors: We reflect each other.\"</p> </li> <li> <p>\"When you lower yourself, the world elevates you. When you elevate yourself, the world lowers you\"</p> </li> <li> <p>\"When you keep clashing with someone, it may be the world's way of asking you to look closely at yourself. When you don't like someone, try to figure out what it is you don't like; see whether you have a similar flaw within yourself. The flaw that you immediately notice in someone you meet is probably a flaw of yours, too. If you didn't have it, you wouldn't have noticed it so quickly.\"</p> </li> <li> <p>\"For spiritual practitioners, relationships are the final test. Even if you have awakened to your enlightened nature, there is still further to go in your spiritual journey if you're not living harmoniously with others\"</p> </li> <li> <p>\"Demonstrations of love are small, compared with the great thing that is hidden behind them\"</p> </li> <li> <p>\"Love is like an uninvited guest. Love will come when it wants to. Love will leave when you ask more of it\"</p> </li> <li> <p>\"If you look for love, in pursuit of what it can give you, it will hide itself. If you ask love to arrive because you are now ready, it will skip your door. Love is like an uninvited guest. Love will come when it wants to. Love will leave when you ask more of it. If you attempt to find a love that meets certain criteria, your new love may also make certain demands of you. Drop your demands quickly when love knocks on your door. Love is warm and freeing. It is innocent, like a child without a hidden agenda. We\"</p> </li> <li> <p>\"We can determine how close we are to someone by asking, \"Can I act like a little kid in front of that person?\" When we love someone, we feel like a little kid in our heart\"</p> </li> <li> <p>\"Why can't I give her a gift and tell her I love her?\" Your words and gifts will mean more to her when she is ready. Love her, not your feelings.\"</p> </li> <li> <p>\"Love needs to be balanced. If you like him more than he likes you, give him time and space to catch up. It is important to hold back your emotions when your feelings are not in balance with his.\"</p> </li> <li> <p>\"I want you to know that I love your ordinariness, because I, too, am ordinary. The truth is, we are all ordinary\"</p> </li> <li> <p>\"No matter how famous or beautiful one is, no matter how much money or power one has, no matter how many wonderful accomplishments one has had, we all have our share of setbacks, heartbreak, and loss. We have to face challenges we have no control over. Loneliness and the fear of death will accompany us to our final days. Everyone is on the same treacherous journey of life's tainted glory.\"</p> </li> <li> <p>\"When we are in love, we like to do nice things for the one we love. But it is equally important to refrain from doing unnecessary things. We often overlook that part\"</p> </li> <li> <p>\"We like to get involved in other people's business, thinking we are doing so for them. We offer unsolicited help and interfere with their lives. We take away their power and make them feel incapable. This stems from our desire for control and recognition. It has little to do with love\"</p> </li> <li> <p>\"Moreover, when I meet someone new, do I make an effort to see who he is beneath his social markers? Or am I reducing people to their background and failing to see who they really are? I am reminded again that anyone, including those young boys, can be our spiritual teacher if we are willing to open our hearts to them.\"</p> </li> <li> <p>\"Life is like a slice of pizza. It looks delicious in an advertisement, but when we actually have it, it is not as good as we imagined. If you envy someone's life, remember the pizza in the ad. It always looks better than it is.\"</p> </li> <li> <p>\"Always go with your first choice if you can afford it. It is better than a life filled with regrets.\"</p> </li> <li> <p>\"It makes sense that Scandinavia should be famous for furniture design, since people in a cold climate spend more time inside their homes. Similarly, Italy is renowned for designer apparel; it makes sense that people in a warm climate should pay more attention to how they appear outdoors. Where you live shapes you. Do you live in a place conducive to the pursuit of your dreams\"</p> </li> <li> <p>\"The biggest obstacle to learning is pretending to know even when you don't. It is better to admit you don't know something; if you pretend, you have to act as if you knew all along. It is easier to learn when you set aside your pride and are honest. The compassionate gaze of the wounded soul is\"</p> </li> <li> <p>\"if we are brutally honest with ourselves, most things we do for others are in fact for ourselves. We pray for the well-being of our family because we need them to be around. We shed tears when our partner dies because of the impending loneliness. We sacrifice for our children in the hope that they will grow up the way we want. Unless we become enlightened like the Buddha or Jesus, it is difficult to abandon our deeprooted preoccupation with ourselves.\"</p> </li> <li> <p>\"Stop worrying about what others think and just do what your heart wishes. Do not crowd your mind with \"what ifs.\" Uncomplicate your life and own up to your desires. Only when you are happy can you help to make the world a happier place\"</p> </li> <li> <p>\"A majestic tree is the first to be cut down and used for lumber, whereas a modest one lives on. Likewise, a real master conceals his virtue and never boasts of his excellence\"</p> </li> <li> <p>\"If someone shares his problems with you, don't feel the need to have the solutions. Just listen sincerely. This is often more helpful.\"</p> </li> <li> <p>\"A foolish person thinks, \"I already know that.\" He keeps anything new from coming into his mind. A wise person thinks, \"I don't know the whole story.\" She opens herself up to even greater wisdom. An ordinary person mainly notices particular things he likes or dislikes. A wise person notices both the whole and the particulars. When you share your problems with your friends, you do not expect them to have the solutions. You are just grateful they are there for you and willing to listen. If someone shares his problems with you, don't feel the need to have the solutions. Just listen sincerely. This is often more helpful. When\"</p> </li> <li> <p>\"When you share your problems with your friends, you do not expect them to have the solutions. You are just grateful they are there for you and willing to listen. If someone shares his problems with you, don't feel the need to have the solutions. Just listen sincerely. This is often more helpful. When I look deeply within myself, I realize what it is that I really want from others: attentive ears that listen to what I am saying, kind words that acknowledge my existence and worth, gentle eyes that accept my flaws and insecurities. I resolve to be that person for those around me\"</p> </li> <li> <p>\"When our greed is awakened, we are cheated\"</p> </li> <li> <p>\"The reward for someone who works hard is more work.\"</p> </li> <li> <p>\"If we're quick to grant a favor, then people quickly forget their gratitude. If we grant a favor with several conditions, then people express immense gratitude\"</p> </li> <li> <p>\"According to the Lotus Sutra, the Buddha makes the prophesy about his disciples because he has a supernatural ability to foresee when they would achieve the final stage of buddhahood. But I do not think they automatically attained enlightenment because they received the Buddha's prophesy; I think it had a lot to do with the Buddha's faith in them, which motivated them to work harder to accomplish what their teacher predicted. Like Ms. Lee's words to me, the Buddha's trusting words and his loving gaze transformed the lives of his five hundred disciples. One word of encouragement, said with kindness and hope, can change a person's future, the way it did for the five hundred disciples and for me\"</p> </li> <li> <p>\"No matter how famous, powerful, or rich some people are, they are not very different from anyone else. We long for deep connection and unconditional acceptance. We have the same insecurities and need for approval. There is no reason to feel inferior\"</p> </li> <li> <p>\"A restaurant specializing in a few good dishes is more likely to develop a good reputation than one with a lengthy menu.\"</p> </li> <li> <p>\"When it comes to learning a new skill, there are two kinds of people. One kind prefers to first study the typewriter, while the other starts by pounding on the keys. One kind likes to first master the grammar of a foreign language, while the other learns in the trenches, using body language if they must. Generally speaking, the second type tends to learn faster than the first, because the latter is not afraid of making mistakes. There is no such thing as being completely prepared. Life is an adventure, through which we learn and mature. Of course, we must consider all our options carefully. But if we wait for 100 percent certainty, then it is often too late.\"</p> </li> <li> <p>\"The college you graduated from is not that important. The life you have chosen to live after college is.\"</p> </li> <li> <p>\"When you look for a job, try to find out how long a company's employees stay at the company. This is more important than the size of the company or the salary offered. If people keep leaving, then that says a lot.\"</p> </li> <li> <p>\"Dedication to one's job should not be measured by how late one works or how often one forgoes a vacation but by how effectively one works and what kind of contribution one makes to the business.\"</p> </li> <li> <p>\"The vaguest and least effective statement: \"I will have whatever.\"</p> </li> <li> <p>\"Those who have not realized their True Self live like the blind, unintentionally scratching someone else's leg. If you would like to scratch your own leg, first awaken to your True Self.\"</p> </li> <li> <p>\"Some may think that life in such a community is repressed, strict, and difficult, but that is not the case. A monastic life is characterized by simple beauty and unexpected joy. Monks find happiness in things that may seem trivial to those who pursue the material trappings of success. Watching the seasons change\u2014the blossoming of the magnolias, the dazzling fall foliage, the first snowfall\u2014brings indescribable joy and gratitude. A simple meal made with fresh ingredients from the nearby mountains is a source of great contentment. Because our monastic brothers are our friends, teachers, and family, we are never lonely\"</p> </li> <li> <p>\"If our faith can be shaken from merely learning about a different tradition, then that faith is not worth keeping\"</p> </li> <li> <p>\"when the essence is forgotten, ritual takes over.\"</p> </li> <li> <p>\"He who knows only one religion knows none.\"</p> </li> <li> <p>\"A spiritual leader is a finger pointing at the moon. If the finger attempts to become the moon, this can lead to a grave sin.\"</p> </li> <li> <p>\"Above all, please understand that what makes you feel tense and awkward is not the spirituality itself but the pressure from your family to conform. You may resent their coerciveness and self-righteousness\"</p> </li> <li> <p>\"Above all, please understand that what makes you feel tense and awkward is not the spirituality itself but the pressure from your family to conform. You may resent their coerciveness and self-righteousness. You may feel their spiritual path is strange and unorthodox.\"</p> </li> <li> <p>\"In the beginning, our prayer takes the shape of, \"Please grant me this, please grant me that,\" and then develops into, \"Thank you for everything,\" and then matures into, \"I want to resemble you.\" Eventually it transcends language\"</p> </li> <li> <p>\"then try to pray this way as well\u2014 \"Enlarge my heart to hold and accept the things I cannot.\" Do not bargain with God, Buddha, or any divine being to give you what you want in exchange for material offerings. If you do not know how to solve a problem in your life, give prayer a try. As you bring your attention inward and sincerely seek an answer, something sacred within you unlocks the door of inner wisdom. If you are desperately looking to meet someone special, send your prayer out to the universe. The universe is an amazing matchmaker. Monastics can pray for many years because their prayers of happiness for others make them happy. As I prepare to officiate at my friend's wedding, I become joyous. For unenlightened people, not every day is a good day, because they feel happy only when things happen the way they want them to. For enlightened people, every single day is a good day, because they feel free knowing that nothing can take away their wisdom. When an unenlightened person does good, he tries to leave his mark. When an enlightened person does good, he leaves no marks. The holier a person is, the more likely it is that she describes herself as a sinner. This is because she doesn't lie to herself. \"</p> </li> <li> <p>\"The saints are what they are not because their sanctity makes them admirable to others but because the gift of sainthood makes it possible for them to admire everybody else.\"</p> </li> <li> <p>\"Everything is impermanent, including the world's most comfortable posture.\"</p> </li> <li> <p>\"If you begin to believe what others say about you, they will begin to control you. Not everything that appears in your mind is true. Do not let someone else's opinion rule your life.\"</p> </li> <li> <p>\"If children do not receive enough attention, psychological problems often emerge.\"</p> </li> <li> <p>\"If I like myself, it is easy for me to like people around me. But if I am unhappy with myself, it is easy to feel unhappy with those around me. May you become your own biggest fan!\"</p> </li> <li> <p>\"The absurd is essentially a divorce. It lies in neither of the elements compared; it is born of their confrontation.\"</p> </li> <li> <p>\"neither the human nor the universe are necessarily absurd on their own, but rather, their relationship is absurd. As humans, we exist with an innate desire for meaning, reason, and order, but yet, we simultaneously exist in a universe that appears to lack all of the above. So far as we can tell, the universe is completely indifferent. Thus, what we want and expect from the universe is fundamentally in contradiction with what we get. In this conflict, the absurdity of the human experience is found.\"</p> </li> <li> <p>\"Unlike anything else in the known universe, we are able to consciously observe, consider, reason, and act. As a result of our unique abilities, we ask ourselves why. We desperately try to find the answer. We get increasingly clever in our attempts, yet every time, just like the rock in The Myth of Sisyphus, at some point, we return to the bottom of the hill, leaving us to start anew.\"</p> </li> <li> <p>\"The struggle itself towards the heights is enough to fill a man's heart.\"</p> </li> <li> <p>\"Everyone is experiencing the same dissonance of being, living their own story through the nauseating rollercoaster of ups and downs to nowhere. It is both banal and almost hollow to say that we should be compassionate and kind to others because of this. Every first-grade child knows this in fewer words. The notion of togetherness and compassion is sold to us in soda and fast-food commercials as well as nearly every Disney movie. It is so commodified, clich\u00e9d, and obvious that it's hard to even take seriously the idea of needing to consider it further. Life isn't a soda commercial nor a Disney movie, and it isn't anywhere near as clean as a first-grade child could likely even imagine. There is a world filled with malevolence and anger and greed and impatience and all the rest. But for this very reason\u2014because compassion is so trite and yet still seemingly so hard and absent\u2014it is perhaps all the more essential and rational to give it serious focus and effort.\"</p> </li> <li> <p>\"There is but one thing that seems to have any positive effect against such absurdity: a sort of compassion for the whole. We must try to remember that everyone is in it, and everyone is flailing against it for the same reasons as everyone else. Thus, within limits perhaps, everyone deserves such consideration and compassion.\"</p> </li> <li> <p>\"Man can do what he wills but he cannot will what he wills.\"</p> </li> <li> <p>\"We see the world not as it is, but as we are,\"</p> </li> <li> <p>\"In all cases, for the most part, knowing what the real color of things are (metaphorically speaking) is perhaps minimally relevant to living and thriving as an individual and as a species. Perhaps what matters more is that we can agree and disagree on subjective things sufficiently well enough, cordially enough, and often enough. And it seems as though that in order to do so, if such a feat is possible, the prerequisite is a willingness to embrace often being wrong.\"</p> </li> <li> <p>\"We so often take personally what the world does without us in mind.\"</p> </li> <li> <p>\"Those who are often angered reveal themselves to be a strange sort of optimist, still in denial of the tragedies of this life and the death of their youthful innocence\u2014the belief that life can be what it can't.\"</p> </li> <li> <p>\"A theory in psychology known as appraisal theory, initially developed by psychologist Magda Arnold, suggests that our emotional responses are in large part created by our conscious evaluations of events\u2014how we view, interpret, and label stimuli rather than the stimuli themselves. In other words, in between our primary experience of an event and our emotional experience of an event, there is a filtering process that occurs through and is based on our cognitive faculties. In this space, how we think based on our experiences, perceptions, views, and values determines what we feel.\"</p> </li> <li> <p>\"For the stoics, events in the world are objective and neutral, and our qualitative emotional experiences are merely a product of the narratives we tell ourselves. \"It doesn't hurt me unless I interpret it's happening as harmful to me. I can choose not to,\" wrote Marcus Aurelius.\"</p> </li> <li> <p>\"Rather, if we realize that the world has not singled us out, that most people are good people trying their best, that ignorance is far more often behind the curtain and not malice, that our emotions are not the result of being made victims by others but by us not taking ownership of them ourselves, that life is inherently difficult and suffering is fundamental to everyone, we can perhaps more accurately evaluate if what we are angered by is worthy of being angry about, and how.\"</p> </li> <li> <p>\"Knowing how to know and be yourself versus actually knowing and being it is like knowing the mechanics of how to surf on paper and then going out into the ocean and encountering an actual wave.\"</p> </li> <li> <p>\"Of course, it feels very nice to be liked. In certain cases, it is essential. Our wellbeing depends to some degree on the quality of our social relations, which require us to be sufficiently liked by at least some people some amount of the time.\"</p> </li> <li> <p>\"In infancy and early childhood, we are inadvertently conditioned by our parents, teachers, and other people we encounter to feel like we are the center of all attention, the most important thing in the world and beyond. Everything we do is relevant, consequential, or impressive. When we walk for the first time, it's the most important thing that could have happened in the world that day. If we draw on the wall, it's the worst thing. But of course, the world did not care about either of those things that day at all. As we age and are further socialized into the world, we slowly but surely realize that the world mostly has never and will never care about what just about anyone does, including us. We are not really at the center of anything at all, not even our own minds. We are not important in any grand sense. No one really cares.\"</p> </li> <li> <p>\"In his famous twentieth-century play, No Exit, Jean-Paul Sartre wrote, \"You remember all we were told about the torture-chambers, the fire and brimstone, the \"burning marl.\" Old wives' tales! There's no need for red-hot pokers. Hell is other people!\"</p> </li> <li> <p>\"Even on the highest throne in the world, we are still sitting on our ass,\"</p> </li> <li> <p>\"I am not who you think I am; I am not who I think I am; I am who I think you think I am,\"</p> </li> <li> <p>\"I have sometimes thought that, in order to be a good minister, it was necessary to leave the ministry,\"</p> </li> <li> <p>\"No man,\" he wrote, \"can antedate his experience or guess what faculty or feeling a new object shall unlock, any more than he can draw today the face of a person whom he shall see tomorrow for the first time.\" In other words, no one can know what life will be like tomorrow nor what such life may cause one to think or feel. However, one must move with it and live according to the present now.\"</p> </li> <li> <p>\"Arguably, great artists and writers aren't popular because they say something no one has thought of or experienced before, but because they say something that most of us have but weren't sure we were right in doing so. Emerson\"</p> </li> <li> <p>\"Perhaps so long as one authentically stands in their own position of confusion and limitation, they have still remained in accordance with their own relative truth and greatness, and the notion of self-reliance holds steady.\"</p> </li> <li> <p>\"One's shadow does not disappear by looking away from it. In the same way that one cannot literally evade the shadow of their body by outrunning it, there is no move or evasive tactic that separates the individual from their psychological shadow. The danger, rather, is in the attempt to do so\u2014the ignorance and denial of it. Jung wrote: Good does not\"</p> </li> <li> <p>\"One must know of a problem to be able to fix it, and it is an act of healing to admit that one is sick.\"</p> </li> <li> <p>\"man is a worm and food for worms. This is the paradox: he is out of nature and hopelessly in it; he is dual, up in the stars and yet housed in a heart-pumping, breath-gasping body that once belonged to a fish and still carries the gill-marks to prove it.\"</p> </li> <li> <p>\"What does it mean to be a self-conscious animal? The idea is ludicrous, if it is not monstrous. It means to know that one is food for worms. This is the terror: to have emerged from nothing, to have a name, consciousness of self, deep inner feelings, an excruciating inner yearning for life and self-expression and with all this yet to die. It seems like a hoax.\"</p> </li> <li> <p>\"One must be careful to not make the singularness of their shot at existence a pressure to get it all right\u2014to do all the right things and think all the right thoughts and feel all the right feelings.\"</p> </li> <li> <p>\"The point is quite the opposite; you will mostly do a lot of the wrong things, think a lot of the wrong thoughts, and feel a lot of the wrong feelings. But precisely because this is your one shot at life, this must be ok. You are driving blind through the most impossibly complex, strange maze that you know ends in a head-on collision with a wall. What use is getting more upset or guilty about feeling upset or guilty in an existence that set you up? Of course, this is far easier said than done, but perhaps in true, deep contemplations of one's mortality, at least on occasion, this reminder can sometimes serve more as a sedative and not merely a stimulant.\"</p> </li> <li> <p>\"It is strange and rather terrifying to consider that we can be something for now and nothing forever\u2014but perhaps it is only because of the fact that we are nothing forever that we can be something for now.\"</p> </li> <li> <p>\"We might never know what nothing is until we know nothing at all. And even then, we might not. We are all free to imagine nothing however we like. Because if nothingness is in fact the source and destiny that connects us all, then perhaps, through nothing, anything is possible.\"</p> </li> <li> <p>\"If we are to be fully human and fully alive and aware, it seems that we must be willing to suffer for our pleasures.\"</p> </li> <li> <p>\"the more one tries to remove or escape the negative experience of life, the more negative it becomes. Rather, the more one faces it willingly and intentionally, the stronger and more equipped one becomes\u2014the more meaningful and positive the pain and hardship can be made to feel .\"</p> </li> <li> <p>\"However, beyond this area of exceptional misery, there still exists a realm of suffering and unhappiness entrenched in human life that appears to be unshakeable, even when one's circumstances are relatively good. This realm can draw the healthy, decent, prosperous person to self-hatred and self-sabotage, to addiction and suicide. It is the realm of misery in the background of any and every moment that should be enjoyed simply and happily but isn't. It is the mental pain that is specific to no one but applicable to everyone.\"</p> </li> <li> <p>\"The person who depends on their ability to accomplish away the struggle, sadness, and uncertainty of life, could accomplish the whole world just to be met with a disappointment so intense that it would destroy whatever is left of them. Perhaps, then, our quality of life is not found in the heights of our happiness or pleasures but in how we choose to consider and look at what surrounds these extremes, how we attempt to create a life of personal intention, meaning, and decency, and justify the inevitable lows rather than always trying to escape them.\"</p> </li> <li> <p>\"every exhalation, there is a breath to come so long as we keep breathing. In every moment of hardship, pain, confusion, or weakness, there is a story taking place filled with the potential for triumph and vitality worthy of tears bursting with wonder and fondness for life, so long as we keep moving. So long as there is life in us, there is the rare and exclusively human\"</p> </li> <li> <p>\"In every exhalation, there is a breath to come so long as we keep breathing. In every moment of hardship, pain, confusion, or weakness, there is a story taking place filled with the potential for triumph and vitality worthy of tears bursting with wonder and fondness for life, so long as we keep moving. So long as there is life in us, there is the rare and exclusively human opportunity to take this chaotic, thrashing existence, this strange nothingness, and make it something. There is the chance to connect and love and help, to feel and think and live, to experience the cosmic everything. And at some point, perhaps that is enough.\"</p> </li> <li> <p>\"When you get the shit kicked out of you long enough . . . you will have a tendency to say what you really mean,\" said\"</p> </li> <li> <p>\"Too many writers write for the wrong reasons. They want to get famous or they want to get rich or they want to get laid by the girls with the bluebells in their hair . . . When everything works best, it's not because you chose writing, but because writing chose you. It's when you're mad with it. When it's stuffed in your ears, nostrils, under your finger nails. It's when there's no hope but that.\"</p> </li> <li> <p>\"There are degrees of madness, and the madder you are the more obvious it will be to other people. Most of my life I have hidden my madness within myself but it is there,\"</p> </li> <li> <p>\"Men are so necessarily mad, that not to be mad would amount to another form of madness,\"</p> </li> <li> <p>\"Like a wild elephant, the untamed mind can inflict enormous damage on ourselves and those around us.\"</p> </li> <li> <p>\"One traditional Tibetan doctor whom I know once commented on people living in the West, \"From the perspective of Tibetan medicine, you are all suffering from nervous disorders. But given how ill you are, you are coping remarkably well!\"</p> </li> <li> <p>\"Physicians don't heal abrasions, and surgeons don't mend bone fractures. Instead, they do whatever they can to allow the body to heal itself\u2014by keeping the wound clean, setting the broken bone, and so on.\"</p> </li> <li> <p>\"The reason we don't devote more time to balancing our minds is that we are betting our lives that we can find the happiness we seek by chasing fleeting pleasures. Psychologists have called this the hedonic treadmill,11 and the first step to escaping from this exhausting grind is to seek a vision of genuine happiness that draws on our own, largely untapped inner resources.\"</p> </li> <li> <p>\"During the path of cultivation, he would meet enemies one by one. If he wanted to improve, he would have to constantly look towards the future and review the past. Only then, he would be able to improve slowly.\"</p> </li> <li> <p>\"When there are too many debts, one stops to worry.'\"</p> </li> <li> <p>\"The martial path was lonely. It was a source of great happiness if one found a confidant.\"</p> </li> <li> <p>\"The Azure Yang Lord's uninhibited life was filled with ups and down. Having felt both extreme happiness and sadness, he knew how difficult it was to earn happiness. If he could make this moment last forever, that would be a blissful matter\u2026 However, be it the Azure Yang Lord or the ancient Great Empress, they knew that these days were not going to last.\"</p> </li> <li> <p>\"Warriors had to suffer hardship and experience numerous life and death encounters. If they were not careful, they would lose their lives. They had to restrain their desires and endure lonely decades of reclusive training. Wasn't all this for them to lead a free life and do as they pleased when their power succeeded on reaching unprecedented heights!? Everything in the world depended on one's preference. To do as the heart pleased!\"</p> </li> <li> <p>\"The ways of the world are full of vicissitudes, and in it, there is the grief at separation and joy in union, the suffering of life and death. No matter how thick a history book is, it would not be able to record everything down. However, it is such infinite matters of the past that can pass by with a finger snap. In one's old age, while looking back at the past, only then would you feel like everything was ephemeral.\"</p> </li> <li> <p>\"The further he walked, the tinier he felt.\"</p> </li> <li> <p>\"Against the vast cosmos, the lives of people were like ants. It was like how bacteria did not know what it meant for the first and last day of the month, or how mole crickets did not know the seasons. What was a mortal's life to the Universe? Yi Yun did not want to remain like a speck of dust in the Universe.\"</p> </li> <li> <p>\"In a warrior's world, we may have the power to cause great destruction, have long lifespans, and are able to lead extravagant lives, but the pressure is intense. Be it life-and-death trials or breakthroughs that require great risks, or the sense of urgency of being killed by someone else at any moment in time, it forces us to continuously forge ahead.\" \"The accumulation of all these pressure naturally need an opportunity for it to be released.\"</p> </li> <li> <p>\"Before one's heart reduced to mediocrity, Great Dao lies within one's heart!\"</p> </li> <li> <p>\"Those without sufficient strength but can bear disgrace and a heavy burden are people who I appreciate as well.\"</p> </li> <li> <p>\"Everyone had their own time, but time treated everyone equally.\"</p> </li> <li> <p>\"Were destruction and finality the end? Matter in the Universe could not remain eternal. They would eventually proceed towards destruction, including the Universe. But what happened after destruction? Could it be that all that was left was eternal 'nothingness'? Everything in the world underwent birth and death. A drop of water could evaporate and become part of a cloud before condensing into new drops of rain. Plants would wither, but the fruits that they bore could give rise to seeds. Mortals would die of age, but babies would grow up into adults. Stars could be destroyed, but new stars would eventually be born\u2026 Everything in the world underwent a cycle, so it definitely included the Universe. The destruction of the Universe was the beginnings of a new Universe. It was just that the cycle was immensely long that it was beyond the imagination of mere mortals. New Universe\u2026 Yi Yun suddenly seemed to realize something. What were the beginnings of the Universe? Dao begets One, One begets Two\u2026 Before Yin-Yang and Space-time was Chaos! Rebirth after destruction was Chaos and Major Destruction respectively. They were both two Great Dao of Supremacy! Why were there two Great Dao of Supremacy? They might be like Yin-Yang, Space-time, Water-Fire, just two sides of the Universe. The two could supplement each other and not a single one was dispensable.\"</p> </li> <li> <p>\"But if a warrior does not have any aspirations, he won't be able to go far either.\"</p> </li> <li> <p>\"To what end do we practice martial arts for? If we can't depend on the sword, so what about death? One's true richness of heart is not to be annihilated!\"</p> </li> <li> <p>\"Helping a man once gains gratitude, but not helping that man again gains hatred.\"</p> </li> <li> <p>\"grinding a chopper will not hold up the work of cutting firewood\"</p> </li> <li> <p>\"As the saying goes, he who gets other's kindness but does not repay is not a gentleman.\"</p> </li> <li> <p>\"speaking.\"History changes erratically. Time is enough to wipe away many things.\"</p> </li> <li> <p>\"Chaos in the world leads to the suffering of all life, but it is something some people are willing to see. Heroes are born in difficult times.\"</p> </li> <li> <p>\"Humans were warlike, to begin with. It was common among humans to fight unceasingly for their interests. Furthermore, there were some perverse people who wanted revenge on the world. Such people were even more dangerous. There was no limit to what they would do. Yi Yun knew that there was evil deeply rooted in human nature. However, he was not a person who would bemoan the state of the universe and mankind, much less the kind who would question life after seeing the ugly nature of humans and eventually decide to destroy the entire world in a crazy fit. He was only Yi Yun, an ordinary person that pursued the martial path, wanting his life to escape the cycle of samsara.\"</p> </li> <li> <p>\"When one postures to impress a girl, his failure becomes all the more foolish.\"</p> </li> <li> <p>\"When warriors took lives or destroyed an item, or even shattered a world, they could not avoid violence. Only time could turn everything into dust in an infinitely calm manner simply by passing. It was silent from beginning to end. Time was the most unique power of destruction. Yi\"</p> </li> <li> <p>\"A man who loses position and influence may be subjected to much indignity. It's all fated\u2026\"</p> </li> <li> <p>\"He who understands the times is a wise man.\"</p> </li> <li> <p>\"Yi Yun refused to believe that someone would forgo their lives for a master who had not won the hearts of people.\"</p> </li> <li> <p>\"We warriors have been cultivating our entire lives. What was it for? It's not to enjoy riches or sex. Nor is it about being placed on a pedestal while enslaving those beneath us! We cultivate to fight against our fate! We do not wish to to let Samsara run its course, so we cultivate for years! Our martial heritage has been passed down for millions of years, billions of years, and will be so for trillions of years! It's not for us to kneel down to beg for mercy after gaining mastery. With the backbone broken, there's no way one can straighten one's back.\"</p> </li> <li> <p>\"The Heavenly Dao's evolution is unending. Creation and Destruction are interchangeable, forming a complete circle. Be it life or a universe, they have formation, existence, disintegration, and emptiness; birth, aging, illness, and death. You wanted to devour the Heavenly Dao, robbing and changing the fate of the universe. You wanted to empower yourself by initiating the deaths of millions; hence, you were destined to be abandoned by the Heavenly Dao.\"</p> </li> <li> <p>\"Legends were typically like this. They would not be eclipsed with the passage of time, but instead, they became histories that one tried to live up to.\"</p> </li> <li> <p>\"Life, from lifeforms as large as towering trees to bugs as small as ants, the reason for all they do is for the continuation of their bloodline.\"</p> </li> <li> <p>\"In this Sinkhole that was filled with despair, a bunch of seniors were forging ahead bearing the burdens, so as to hold up the sky for the young. Although these seniors had their backs hunched from the pressures of time, to the point of not being able to bear the weight any further, that was already sufficient, no matter how tiny that piece of sky they held up was. They had already done everything they could have done.\"</p> </li> <li> <p>\"The crests and troughs of life are all but ephemeral mists. How nice if reunion and separation were fixed in place of that first meeting. A thousand years pass and happiness a certainty, but how much was sadness in exchange?\"</p> </li> <li> <p>\"Imagination comes from limitations. When you can do anything it gets debilitating\"</p> </li> <li> <p>\"Every storm runs out of rain\"</p> </li> <li> <p>\"Writing is nature's way of letting you know how sloppy your thinking is\"</p> </li> <li> <p>\"Faith is a gift, not a reward\"</p> </li> <li> <p>\"Where there is a will, there grows a forest\"</p> </li> <li> <p>\"It's frustrating navigating my feelings because they are all self-imposed - the only person I can get angry at is, well, myself. \"</p> </li> <li> <p>\"The Heavens and Earth will not move; neither will the stone turn in the flowing river. There is still a long journey ahead of us. It's just as you have always said. There's no need to force yourself to do anything. We just hope Teacher can return safely; that is our only request.\"</p> </li> <li> <p>\"You can try to run from the sun as hard as you can, but you can never outrun the sunlight\"</p> </li> <li> <p>\"A sect's decline is not due to the external pressures but due to the internal disputes and lack of unity\"</p> </li> <li> <p>\"Literature lasts for eternity,</p> </li> <li> <p>A Martial artist retires at death.\"</p> </li> <li> <p>\"When things are moving so fast, it's good to remember that sometimes you'll waste a lot of effort or get scooped. The best thing you can do is to just accept it and keep going on your process. You're not alone in this one.\"</p> </li> <li> <p>\"Am I the creator if I simply role the dice until I win the lottery?\"</p> </li> <li> <p>\"If you write a piece of code and it seems simple to you, but others think it is complex, then it is complex.\"</p> </li> <li> <p>\"Ironically, there never seems to be enough time to do something as idle as contemplate the very nature of time.\"</p> </li> <li> <p>\"In work, he writes, time is horizontal, a pattern of forward-leaning labor time punctuated by little gaps of rest that simply refresh us for more work. For Pieper, those little gaps are not leisure. True leisure, instead, exists on a \"vertical\" axis of time, one whose totality cuts through or negates the entire dimension of workaday time, \"run[ning] at right angles to work.\" If such moments happen to refresh us for work, that is merely secondary.\"</p> </li> <li> <p>\"As long as slowness is invoked merely to make the machine of capitalism run faster, it risks being a cosmetic fix, another little gap on the horizontal plane of work time.\"</p> </li> <li> <p>\"What first appears to be a wish for more time may turn out to be just one part of a simple, yet vast, desire for autonomy, meaning, and purpose.\"</p> </li> <li> <p>\"There is a lonely absurdity in the idea of racing against the clock at the end of time, as evidenced in a headline by the parody site Reductress: \"Woman Waiting for Evidence That World Will Still Exist in 2050 Before She Starts Working Toward Goals.\"</p> </li> <li> <p>\"What I find in chronos is not comfort but dread and nihilism, a form of time that bears down on me, on others, relentlessly. Here, my actions don't matter. The world worsens as assuredly as my hair is graying, and the future is something to get over with. In contrast, what I find in kairos is a lifeline, a sliver of the audacity to imagine something different. Hope and desire, after all, can exist only on the differential between today and an undetermined tomorrow.\"</p> </li> <li> <p>\"Tomorrow was growing raw out of the husk of today, and in it, I'd be different. All of us would.\"</p> </li> <li> <p>\"How much someone's time is valued is not measured simply by a wage, but by who does what kind of work and whose temporality has to line up with whose, whether that means rushing or waiting or both.\"</p> </li> <li> <p>\"The lava moves, and it's not because of us.\"</p> </li> <li> <p>\"The future is always over the horizon, and to be alive is to be in transit. For a few minutes, a sunrise collects all that ineffable bittersweetness into a single burning point.\"</p> </li> <li> <p>\"In turn, looking for kairos while living largely in chronos puts you in that difficult gray area between personal agency and structural limits, an area long explored by social theorists but also simply experienced by anyone negotiating life in a social world.\"</p> </li> <li> <p>\"Sometimes the best muse is the thing you're so afraid of you almost cannot speak it.\"</p> </li> <li> <p>\"Landes suggests that a crucial deviation happened with the development of Christian canonical hours, particularly under the sixth-century Rule of Saint Benedict. The Rule, which subsequently spread to other orders, specified seven times during the day when Benedictine monks should pray, as well as an eighth in the middle of the night. Determining that \"idleness is the enemy of the soul,\" the Rule also described punishments for monks who failed to hurry sufficiently upon the signal for work or prayer.\"</p> </li> <li> <p>\"A clock hour was meant to be an hour, no matter where or what the season, just as a man-hour would be expected to be an hour, no matter who the man. This was as useful for regulating labor as it was for conquering land.\"</p> </li> <li> <p>\"Clocks arrived as tools of domination.\"</p> </li> <li> <p>\"On a larger scale, they graded native populations as being more or less \"progressed\" into modernity based on how removed their systems of time seemed from nature\u2014a\"</p> </li> <li> <p>\"As would be the case in many different contexts going forward, the science of recording labor days was inextricable from the project of intensifying them.\"</p> </li> <li> <p>\"none of us who toil for our daily bread are free. At one time\u2026we were chattel slaves; today we are, one and all, white and black, wage slaves.\"</p> </li> <li> <p>\"When the relationship of time to literal money is expressed as a natural fact, it obscures the political relationship between the seller of time and its buyer. This may seem obvious, but if time is money, it is so in a way that's different for a worker than for an employer. For the worker, time is a certain amount of money\u2014the wage. But the buyer, or employer, hires a worker to create surplus value; this excess is what defines productivity under capitalism. From an employer's point of view, purchased time could always yield more money.\"</p> </li> <li> <p>\"The only reward for working faster is more work.\"</p> </li> <li> <p>\"In this way, Taylorism rendered labor more abstract and fungible, hastening a process that has often been referred to as \"de-skilling.\" Among other things, this deepened the divide between how different kinds of time are valued. As Braverman puts it, \"Every step in the labor process is divorced, so far as possible, from special knowledge of training and reduced to simple labor. Meanwhile, the relatively few persons for whom special knowledge and training are reserved are freed so far as possible from the obligations of simple labor. In this way a structure is given to all labor processes that at its extremes polarizes those whose time is infinitely valuable and those whose time is worth almost nothing.\"</p> </li> <li> <p>\"The more fragmented and minutely timeable work becomes, the more meaningless it becomes.\"</p> </li> <li> <p>\"A psychopath would make a terrible content moderator.\"</p> </li> <li> <p>\"At Cognizant, where humans keep coming in for work despite the conditions, one worker tells Newton that they are merely \"bodies in seats.\"</p> </li> <li> <p>\"The tragedy of fungible labor time lies first in its historical association with coercion, exploitation, and the imagining of people as machines. Time is the punitive dimension in which the wage worker is both measured and squeezed. But beyond that, an overemphasis on fungible time upholds an impoverished view of what time and labor are in the first place.\"</p> </li> <li> <p>\"Just because you're going forward doesn't mean I'm going backward.\"</p> </li> <li> <p>\"As a form of Protestantism, seventeeth-century Puritanism invited introspection and constant evaluation of the self against a high moral standard, a practice that included the use of daily journals where self-observation and measurement could take place.\"</p> </li> <li> <p>\"A feeling of time pressure can result from constantly having to switch tasks or coordinate with external factors. Here,\"</p> </li> <li> <p>\"Self-help has generally promised to revolutionize your life, not the social or economic hierarchy\u2014and you can't really blame anyone for not fulfilling a promise they never made. At the same time, even seemingly practical self-help can read as an invitation to find a niche in a brutal world and wait for the storm to pass you over.\"</p> </li> <li> <p>\"If time management is not simply an issue of numerical hours but of some people having more control over their time than others, then the most realistic and expansive version of time management has to be collective:\"</p> </li> <li> <p>\"Excess work and performance escalate into auto-exploitation.\"</p> </li> <li> <p>\"Trained to set her sights on infinity, she never experiences the feeling of having actually reached a goal and, instead, exhibits the \"auto-aggression\" of the master and mastered rolled into one. She is forever \"jumping over [her] own shadow,\" frustrated at the impossible gap between what is and what could be.\"</p> </li> <li> <p>\"Social comparison is probably as old as time, but to compare a wide range of people using the same grades, you have to be able to turn those people into data and decide what you're optimizing for.\"</p> </li> <li> <p>\"If, in Taylorism, the measurement of work was an attempt to intensify it, then, in eugenics, the measurement of people was an attempt to \"mold\" them in a specific direction, a mechanistic combination of Mendelian genetics and social Darwinism.\"</p> </li> <li> <p>\"this is \"a terrible time to have a midlife crisis.\" But advice for winning the rat race assumes that you're running\"</p> </li> <li> <p>\"But advice for winning the rat race assumes that you're running in it, rather than peeling away from a vanishing dream.\"</p> </li> <li> <p>\"Slow living is now 'for sale' and approaches a consumerist lifestyle mostly for middle-class metropolitan dwellers\u2014the majority of whom are probably far from holding transformative, progressivist or even socialist agendas. Arguably, many would admit that 'it all needs to slow down,' but such slowness would then be, more often than not, consumed, and consumed privately.\"</p> </li> <li> <p>\"It's just that, as the experience economy expands to include commodified notions of things like slowness, community, authenticity, and \"nature\"\u2014all while income inequality yawns wider and the signs of climate change intensify\u2014I feel the panic of watching possible exits blocked. I keep wanting to do something instead of consume the experience of it. But seeking new ways of being, I find only new ways of spending.\"</p> </li> <li> <p>\"Whether conspicuous, compensatory, or both, consumption has long had a relationship to leisure, which can make leisure a strange kind of circumscribed freedom.\"</p> </li> <li> <p>\"Sociologists have observed that once assembly-line jobs made it difficult to see how well or hard someone had worked, what became visible instead was how much someone was able to consume. This consumption, in turn, became the new way to signal how hard one had worked.\"</p> </li> <li> <p>\"What makes you unique?\" is a standard interview question. As a result, what once looked like leisure so easily becomes the arena both of the eternal self-upgrade and the search for some uniqueness to exploit. Marketing advice formerly given to companies\u2014for example to \"find your niche\"\u2014is now applicable to individuals during every moment of the day.\"</p> </li> <li> <p>\"true leisure requires the kind of emptiness in which you remember the fact of your own aliveness.\"</p> </li> <li> <p>\"Leisure is not refreshment-for-work but something completely different that exists for its own sake.\"</p> </li> <li> <p>\"If I exhibited the leisure mindset while in line for groceries, it was at least in part because I wasn't worried about paying for them.\"</p> </li> <li> <p>\"Pieper's definition of leisure emphasizes wholeness; it is \"when a man is at one with himself, when he acquiesces in his own being.\"</p> </li> <li> <p>\"Heartbreak did not make me love the birds less; it did not make the ocean less beautiful; it only suffused my seeing them with a deep desire for things to be different.\"</p> </li> <li> <p>\"momentary pattern of light. Perhaps this is precisely what Pieper meant with his \"vertical\" time\u2014maybe it is vertical not just in that it's the opposite of horizontal, but also in that it reaches deep into the recesses of history even as it stretches up toward an infinite and utopian ideal.\"</p> </li> <li> <p>\"Rest is not some cute lil luxury item you grant to yourself as an extra treat after you've worked like a machine and are now burned out,\" Hersey tweeted in October 2020. \"Rest is our path to liberation. A portal for healing. A right.\"</p> </li> <li> <p>\"Hersey uses social media for work but is critical of the way it encourages a grind culture with historical roots in capitalism and white supremacy.\"</p> </li> <li> <p>\"introduced\"\u2014for example, indentured or wage labor. Whereas\"</p> </li> <li> <p>\"Whereas the source of boredom for the leisure class was free time, the source of boredom for everyone else was work, and working people had no problem deciding what to do with whatever leisure time they were allotted.\"</p> </li> <li> <p>\"In its least useful form, the concept of leisure time reflects an undignified process: working to buy the temporary experience of freedom and then faithfully breathing air in the little gaps that are allowed in the horizontal plane of work. Rest and recreation are applied like maintenance, the leisure machine to the feeding machine.\"</p> </li> <li> <p>\"At its most useful, however, leisure time is an interim means of questioning the bounds of the work that surrounds it. Like a stent in a culture that can't stand what looks like emptiness, it might provide that vertical crack in the horizontal scale of work and not-work\u2014that critical pause during which the worker wonders why she works so much, where collective grief is processed, and where the edges of something new start to become visible.\"</p> </li> <li> <p>\"What songs are audible when the wind stops? What has been kept alive in the time snatched from work and sheltered from ongoing destruction\u2014what moments of recognition, what ways of relating, what other imagined worlds, what other selves? What other kinds of time?\"</p> </li> <li> <p>\"In his 2021 special, Inside, Bo Burnham deadpans that \"the outside world, the non-digital world, is merely a theatrical space in which one stages and records content for the much more real, much more vital, digital space. One should only engage with the outside world as one engages with a coal mine. Suit up, gather what is needed, and return to the surface.\"</p> </li> <li> <p>\"For Bergson, time was duration\u2014something creating, developing, and somewhat mysterious, as opposed to abstract and measurable. According to him, all our problems conceiving of the true nature of time stemmed from wanting to imagine discrete moments sitting side by side in space. He further noted that this \"space\" was not concrete environmental space, but something purely conceptual: Think of that green-on-black grid that sometimes shows up in the virtual nonspace of sci-fi movies, and think of moments in this kind of time as cubes existing in that space. (This conception also provided the grounds for the concept of fungible time I mention in chapters 1 and 2.) Bergson thought that our predisposition toward thinking of time in these kinds of spatial terms came from our experience manipulating inert matter; we wanted to see time in the same way, as something we could cut up, stack, and move around.\"</p> </li> <li> <p>\"Time as expressed in these processes\u2014which Bergson explains using what he calls the \u00e9lan vital (usually translated as \"vital impetus\" or \"life force\")\u2014is not an abstract quantity to be counted up and measured. Instead, it's another irreversible turn of the kaleidoscope, something driving division, reproduction, growth, decay, and complexity. The old adage \"You never step in the same river twice\" also speaks quite well to what Bergson is describing, especially if you go on to consider the shifts in evolution of the riverbank, the canyon that the river may be slowly carving, and maybe even the cellular processes in your foot.\"</p> </li> <li> <p>\"Meanwhile, as you stand there thinking about it, the live edge of the lava is moving forward into the future, which is imminent in every present moment but also contains the history of everything that happened before. Another example would be a seed that has fallen from one individual in a generation of plants and that contains the instructions for a future plant.\"</p> </li> <li> <p>\"Clock time is not the only form of time reckoning we experience, but it is certainly primary in how many of us think about the \"stuff\" of time. And it was an allegiance to clock time that allowed colonists, anthropologists, and contemporary Western observers in general to view non-Western and indigenous cultures as being without, or outside, time.\"</p> </li> <li> <p>\"We don't have a word for nonlinear in our languages because nobody would consider traveling, thinking, or talking in a straight line in the first place. The winding path is just how a path is, and therefore it needs no name.\"</p> </li> <li> <p>\"by every subsequent wave. Look again at the pebbles. Make no mistake: They are neither signs nor symbols of time. No\u2014they really are two things at once: seafloor from the last ice age, and future sand.\"</p> </li> <li> <p>\"Resting here gives us a very different sense of being \"on time.\" Rather than avatars passing through an empty calendar square, we are actually on top of the material outcome of processes that span millions of years into both the past and the future. Suddenly, everything we look at is suffused with concrete time: not just the pebbles, crags, and cliffs, but also the fog's slow movement to the south; each wave's unrepeatable expression of tides and wind; the frenetic activity of the beach flies; the dispersion of air and water through our bodies; and even the chemicals flashing across our synapses as we think these very thoughts. They, too, will never repeat, and they, too, make the world anew.\"</p> </li> <li> <p>\"ROCKS WILL TEACH you the inseparability of time and space.\"</p> </li> <li> <p>\"I see that the events of the past are still present\u2026.This impression is a glimpse not of timelessness but timefulness, an acute consciousness of how the world is made by\u2014indeed, made of\u2014time.\"</p> </li> <li> <p>\"Newtonian time is the kind of time that can be measured, bought, and sold. Wage work requires us to see time as \"stuff\" divorced from bodies and environmental context.\"</p> </li> <li> <p>\"There is no inherent reason for a season to be any length of time, much less of four equal, mutually exclusive lengths. Until relatively recently, the naming and recognition of seasons or seasonal entities was an indicator of some action to be taken: collecting, hunting, harvesting.\"</p> </li> <li> <p>\"If, as Deloria puts it, each place exhibits a \"personality,\" then it is made out of as much when as who: a string of overlapping developments like the tracks of a song. This song sounds slightly different in each place:\"</p> </li> <li> <p>\"invisibility is part of the very nature of habit.\"</p> </li> <li> <p>\"In the translator's afterword to a 2010 edition of An Attempt at Exhausting a Place in Paris, Marc Lowenthal emphasizes the \"attempt\" in Perec's toc: true title, writing that \"time, unarrestable, works against [Perec's] project\u2026.Every bus that passes, every person who walks by, every object, thing, and event\u2014everything that happens and that does not happen ultimately serves no other function than that of so many chronometers, so many signals, methods, and clues for marking time, for eroding permanence.\"</p> </li> <li> <p>\"The Birds Are Not on Lockdown, and More People Are Watching Them,\"</p> </li> <li> <p>\"it might \"give us peace and calm to see that even though our rhythm is interrupted, there is a larger rhythm that continues to go on.\"</p> </li> <li> <p>\"Most living entities and systems on this planet obviously do not live by the Western human clock (though some, like the crows who memorize a city's daily garbage truck route, do of course adapt to the timing of human activities). To watch a brown creeper as it inches up and down, peering into crevices and extracting bugs with its little dentist beak, is thus a way of catching a ride out of the grid and toward a time sense so different that it is barely imaginable to us.\"</p> </li> <li> <p>\"The literal tree in front of you is encoding time and change at this literal moment.\"</p> </li> <li> <p>\"This exercise of unfreezing something in time is not hard to do. If you want to see time that isn't fungible, just pick a point in space\u2014a branch, a yard, a sidewalk square, a webcam\u2014and simply keep watch. A story is being written there. Like the larger and larger wind patterns on Windy.com, this story is inseparable from the story of all life, even yours. This story is, finally, the signature of \"it\": the restless, unstoppable, constantly overturning thing that makes it all go.\"</p> </li> <li> <p>\"The world, just like the architecture of a city, becomes a patchwork of outcomes from different weeks, decades, and centuries, all of it being built upon and eroded\u2014pushing, trickling, and winging forward into the unknown.\"</p> </li> <li> <p>\"In a display case, a thing becomes only a facsimile of itself, like a drum hung on the gallery wall,\" Kimmerer writes. \"A drum becomes authentic when human hand meets wood and hide. Only then do they fulfill its intention.\"</p> </li> <li> <p>\"Having specifically studied how mosses \"decide\" to grow on a rock, Kimmerer knows that the mosses that grow on rocks are \"inordinately resistant to domestication.\"</p> </li> <li> <p>\"Owning diminishes the innate sovereignty of the thing,\"</p> </li> <li> <p>\"To see something in time is to allow that it has a life and to allow that this life entails more than the mechanistic cause-and-effect of a Newtonian world. In this way of thinking, mosses \"decide\" which rocks to live on, and even rocks have lives.\"</p> </li> <li> <p>\"The specifically disorienting part, for me, was when it showed Canada geese passing over New York City. Seen as part of a journey the geese had taken for thousands of years, the skyline looked suddenly alien to me; \"New York\" became an odd conglomeration of hard shapes and protrusions along a particular riverbank. The city existed for the geese, too, but they read it differently, perhaps as a signpost on a path of other signposts that may have included other rivers. Their flight path tied these places together into one big calendar. As\"</p> </li> <li> <p>\"THE word experience has a common origin with experiment. To experience something is to be present for it, to be the responsive co-creator of something that is happening\u2014like the ducks and geese who make migration happen by sensing the weather and deciding when to leave.\"</p> </li> <li> <p>\"Experience isn't merely the best teacher; it's the only teacher. If she's learned anything raising Jax, it's that there are no shortcuts; if you want to create the common sense that comes from twenty years of being in the world, you need to devote twenty years to the task. You can't assemble an equivalent collection of heuristics in less time; experience is algorithmically incompressible.\"</p> </li> <li> <p>\"The real paradox is a mind that conceives of the world as inert but that may come to see itself as bound to the same laws of determinism as everything else\u2014in a way, the ultimate self-own.\"</p> </li> <li> <p>\"Freedom is choice, and choice is scattered throughout the universe, pushing forward and acting upon what would constrain it.\"</p> </li> <li> <p>\"For Bergson, the everyday experience of learning and recognition demonstrates both the freshness of each moment and the irreversibility of time. He describes walking through a familiar town where the buildings don't seem to change. But as he thinks back to the first time he ever observed those buildings, a comparison emerges that momentarily unfreezes the world: \"It seems that these objects, continually perceived by me and constantly impressing themselves on my mind, have ended by borrowing from me something of my own conscious existence; like myself they have lived, and like myself they have grown old. This is not a mere illusion: for if today's impression were absolutely identical with that of yesterday, what difference would there be between perceiving and recognizing, between learning and remembering?\"</p> </li> <li> <p>\"Like rocks pushing up out of the depths and the water that wears them down; like browned and ripened buckeye fruits falling off the tree and rolling down the hill; like poetry, which strains the boundaries of an ossified language; or like Bergson's cascading rocket that can never be arrested\u2014the co-creation events of our lives do not play out in an external, homogenous time. They are the stuff of time itself.\"</p> </li> <li> <p>\"the future can cease to look like an abstract horizon toward which your abstract ego plods in its lonely container of a body. Instead, \"it,\" that irrepressible force that drives this moment into the next, is a thing that is speaking back to you always\u2014even and especially from unexpected places. The task for many of us is to learn once more how to hear.\"</p> </li> <li> <p>\"it is one thing to acknowledge the past and future losses that follow from what has occurred; it is another to truly see history and the future proceeding with the same grim amorality as the video playhead, where nothing is driving it except itself. In failing to recognize the agency of both human and nonhuman actors, such a view makes struggle and contingency invisible and produces nihilism, nostalgia, and ultimately paralysis.\"</p> </li> <li> <p>\"some relationships arguably end in the first place because partners have stopped seeing each other in time, one partner having replaced the living, changing other with a static image that can impart no surprises, only a comforting presence.\"</p> </li> <li> <p>\"a Westerner's attempt to arrive at the idea of how things are \"supposed to be\" is usually fraught, because it doesn't take into account who is doing the supposing.\"</p> </li> <li> <p>\"that?\u2026Mountain time and city time appear to be bifocal. Even with geology functioning at such remarkably short intervals,\"</p> </li> <li> <p>\"A super-event in 1934? In 1938? In 1969? In 1978? Who is going to remember that?\u2026Mountain time and city time appear to be bifocal. Even with geology functioning at such remarkably short intervals, people have ample time to forget it.\"</p> </li> <li> <p>\"Fire was part of a reciprocal responsibility between one subject (humans) and another (land).\"</p> </li> <li> <p>\"The land is not really the place (separate from ourselves) where we act out the drama of our isolate destinies. It is not a means of survival, a setting for our affairs\u2026.It is rather a part of our being, dynamic, significant, real. It is our self.\"</p> </li> <li> <p>\"To think deterministically is to take things for granted, both forward and backward in time. Just as I misunderstood the forested mountains as a child, projecting them into a supposedly uniform past, the concept of the Anthropocene has the potential to make the outcomes of specific actions by specific people seem like a natural and inevitable condition.\"</p> </li> <li> <p>\"Human beings were rendered economic machines that seek to maximize their share of sparse natural resources. The inscription of a bio-evolutionary and thus inevitable impulse behind the ascent of Western Man\u2014\"we all want to grab more resources, Europeans just did it better than everyone else\"\u2014came to vindicate capitalism, white supremacy, and imperial expansion. The West invented Man and projected Him onto the past as natural and timeless, rather than historical and cultural.\"</p> </li> <li> <p>\"The story of Enlightenment Man teaches me an all-too-common truth: that the people who stand to gain the most from determinism (in others) are typically the people doing the determining.\"</p> </li> <li> <p>\"We just sell the cigarettes; you're the ones smoking them.\"</p> </li> <li> <p>\"In the meantime, energy companies' emphasis on consumption is disingenuous. This rhetoric echoes Big Tobacco's effort to portray itself as a neutral purveyor of what consumers just can't seem to help but demand. In other words, We just sell the cigarettes; you're the ones smoking them. A framing like this one portrays climate change as solely\"</p> </li> <li> <p>\"A framing like this one portrays climate change as solely \"our\" fault, where the \"our\" is an aggregate of consumers who should attend to their carbon footprint calculators. All the while, as Aronoff writes, \"every shred of evidence suggests the [energy] industry is moving full speed ahead in the opposite direction, pushing more exploration and more production as temperatures rise, seas swell, and fires burn.\" One smoky day while I was writing this chapter, a Wells Fargo ATM asked me if I wanted to donate to help with the wildfires. I stared back at the screen. Wells Fargo is one of the largest funders of fossil fuels, having invested $198 billion into the coal, oil, and gas industry in the four years following the Paris Agreement. Just as the industry of individual time management resells the idea of time as money to the isolated bootstrapper, energy companies sell the idea of the carbon footprint to conceal larger and more significant avenues of change. These include both technological and political tools to which we already have access. For Klein, Aronoff, and others, some of those tools would be public regulation and oversight\u2014things like the Green New Deal\u2014and standing up to the global trade agreements that favor the suicidal time horizon of energy companies. Indeed, Klein has an entire chapter toc: true titled \"Planning and Banning.\" Klein acknowledges that this is an uphill battle in the United States, where both planning and banning are currently decried as government overreach. Nevertheless, she writes, \"we should be clear about the nature of the challenge: it is not that 'we' are broke or that we lack options. It is that our political class is utterly unwilling to go where the money is (unless it's for a campaign contribution), and the corporate class is dead set against paying its fair share.\" For her part, Aronoff takes great pains throughout her book to remind us that the hill in the uphill battle is historically specific: \"In positing all of human existence as an endless striving toward market society, neoliberals had to erase not just the possibility of a future but all memory of a past when humans managed to organize themselves in other ways. The kinds of tools needed to navigate out of the climate crisis\u2014things like public ownership, full employment, or even just tough regulations\u2014have receded into memory.\" Aronoff is talking mostly about policies of the New Deal era, before a globalized economy took hold and the perception of government regulation soured in a neoliberal atmosphere. But one could extend this notion of political amnesia even further back, as an echo of what serynada describes: rewriting the history of Man as an economic machine. Again, purgatory is enervating. Like a fog machine spewing a priori dystopia, energy companies are still selling their certain future, still designing targets and portraying us as drifting helplessly toward them. I think back on my nightmares, about how the future looks there. Who wrote that scenario? \u2014 A PIER JUTS out from the promenade into that uncompromising ocean. The moment we move past the\"</p> </li> <li> <p>\"Without suppressing grief, there has to be a different way of thinking about time than the one in which\"</p> </li> <li> <p>\"Rather, to the nihilist who cannot imagine the future, I am highlighting a perspective that has survived, and continues to survive, the long-ago end of the world. There are many people and places that could accept neither Enlightenment Man's march of progress nor the billiard ball declinism of the Anthropocene\u2014because that narrative was inherently premised upon their destruction, commodification, and relegation to a state of nonbeing. For those people and places, the historical past can never be an object of nostalgia, and the future has always been in jeopardy. If you don't want to kick the can down the road, look to those who never recognized the road in the first place. BACK ON THE seawall, there is a circle of five wooden posts that looks like a miniature Stonehenge, that most iconic of calendrical tools.\"</p> </li> <li> <p>\"The land is chief, man is its servant.\"</p> </li> <li> <p>\"NEVER TURN YOUR BACK ON THE OCEAN. That sign always puts me in my place. It reminds me that the beach is not an amenity for humans\u2014that I can be there, but I'd better learn the laws of the ocean if I want to stay alive.\"</p> </li> <li> <p>\"I grew up on a false plateau I took for infinity.\"</p> </li> <li> <p>\"Observing that the Greek word apokalypsis meant \"through the concealed,\" Washuta writes that \"apocalypse has very little to do with the end of the world and everything to do with vision that sees the hidden, that dismantles the screen.\"</p> </li> <li> <p>\"We live according to the sun, not the clock.\"</p> </li> <li> <p>\"Cynicism and nihilism will make you dry up, like soil compacted by neglect and abuse.\"</p> </li> <li> <p>\"As Marx writes in Capital, \"Apr\u00e8s moi, le d\u00e9luge [After me, the flood] is the watchword of every capitalist and of every capitalist nation.\"</p> </li> <li> <p>\"Language is dynamic, unruly, always splintering. It has to be, because in order to use it, we take words and constructions we never chose and make them do what we\u2014as collectives, however big or small\u2014want them to do.\"</p> </li> <li> <p>\"Just because a language is imposed, it doesn't mean it can be controlled; and just because it's spoken, it doesn't mean it's been internalized.\"</p> </li> <li> <p>\"An inside joke makes a new inside, a new center.\"</p> </li> <li> <p>\"Time was never a specific minute, but rather spaces of time, like early morning, just afternoon, or just before midnight. The real meaning of Indian time comes from\u2026nake nula waun yelo, a phrase in traditional songs that means 'I'm ready for whatever, any place, always prepared.'\u2009\"</p> </li> <li> <p>\"But if, just for a moment, we leave behind historically and culturally specific notions of clock-based punctuality and time as money, then Filipino time actually doesn't appear to be a problem at all. If you and everyone you know are on it, then it's just time.\"</p> </li> <li> <p>\"Speaking a language is a way of participating in the making, preservation, and evolving of worlds.\"</p> </li> <li> <p>\"Study is what you do with other people. It's talking and walking around with other people, working, dancing, suffering, some irreducible convergence of all three, held under the name of speculative practice\u2026.The point of calling it \"study\" is to mark that the incessant and irreversible intellectuality of these activities is already present.\"</p> </li> <li> <p>\"In this partitioned, soundproof, PCB lined office jungle, truly the worst fate is to believe in your boss's dream, to strive for the company good.\"</p> </li> <li> <p>\"Mould writes that, in either case, creativity is not actually creative, because it merely \"produces more of the same form of society.\" If it makes progress, it is the progress of capitalist logic into ever-more-minute corners of our daily lives, making what Braverman calls \"the universal market\" even more universal.\"</p> </li> <li> <p>\"Why are individuals expected to be \"resilient\" when corporations are not?\"</p> </li> <li> <p>\"The demand for less work might be made \"not so that we can have, do, or be what we already want, do, or are, but because it might allow us to consider and experiment with different kinds of lives, with wanting, doing, and being otherwise.\"</p> </li> <li> <p>\"What does one do when one finds oneself marking time on the job? One develops a lot of cynicism, apathy, and anger to which there is no outlet.\"</p> </li> <li> <p>\"To keep walking is to keep living, to keep inquiring, and to keep hoping.\"</p> </li> <li> <p>\"This simple gesture, and the story of the beans, made me realize how broken my mental mechanisms were for thinking about anything beyond the transactional exchange.\"</p> </li> <li> <p>\"Time can have many rhythms, and rhythms can take on many meanings.\"</p> </li> <li> <p>\"Tempo and intensity surround us at every level: we know that a birthday tomorrow can feel like an eternity to a little child whilst a birthday one year ago can seem like only yesterday to an old person. The dormant period of winter is followed by a burst of growth in spring\u2026.'Our' social time as it emerges from common usage is inseparable from the rhythms of the earth. Complexity reigns supreme.\"</p> </li> <li> <p>\"Saying it meant that you could take time and give time, but also that you could plant time and grow more of it and that there were different varieties of time. It meant that all your time grew out of someone else's time, maybe out of something someone planted long ago. It meant that time was not the currency of a zero-sum game and that, sometimes, the best way for me to get more time would be to give it to you, and the best way for you to get some would be to give it back to me. If time were not a commodity, then time, our time, would not be as scarce as it seemed just a moment ago. Together, we could have all the time in the world.\"</p> </li> <li> <p>\"In \"Why Time Management Is Ruining Our Lives,\" Oliver Burkeman observes that keeping a detailed log of your time use, in an effort to save time or spend it more wisely, ironically \"heightens your awareness of the minutes ticking by, then lost forever.\" Whether on the level of minutes or of life stages and benchmarks, the more you stare at time, the more cruelly it seems to slip through your fingers.\"</p> </li> <li> <p>\"the product offered by a capitalist version of wellness is \"the means to remake oneself into an ever more perfect self-correcting machine capable of setting goals and moving toward them with smooth determination.\"</p> </li> <li> <p>\"How long does it take, or should it take, for a body to move through the world, the forty-plus-hour work week, the demands of caregiving for ailing parents, the daily commute of the body with its changing needs over the life span\u2014a pregnant body, an aging one, a body in recovery after a bad injury?\" Hendren asks. \"Is the clock of industrial time built for bodies at all?\"</p> </li> <li> <p>\"It's actually okay to be on a spectrum of reality. It means that there are times when it's juicier, there are times when it's drier, there's times when I'm gonna be tired, there's times when I'm going to have a lot of energy. It's actually part of being alive. It is being alive.\"</p> </li> <li> <p>\"Too worn out to grasp, and forced to sit back, the tired and resigned person finds that something else floods in: the world, in all its detail, its constantly acting and infinitely dispersed agents, and its minute-by-minute changes.\"</p> </li> <li> <p>\"deep tiredness loosens the strictures of identity. Things flicker, twinkle, and vibrate at the edges.\"</p> </li> <li> <p>\"Maybe \"the point\" isn't to live more, in the literal sense of a longer or more productive life, but rather, to be more alive in any given moment\u2014a movement outward and across, rather than shooting forward on a narrow, lonely track.\"</p> </li> <li> <p>\"Disability highlights something that is true for all of us: No matter how independent and fit we may feel, we are not simply alive but, rather, kept alive\u2014against odds that some people are nonetheless privileged enough to ignore.\"</p> </li> <li> <p>\"People do not spring up from the soil like mushrooms,\" she writes. \"People need to be cared for and nurtured throughout their lives by other people.\"</p> </li> <li> <p>\"For me, death is when I can no longer engage with the world around me; when I can no longer take anything in and, therefore, can no longer connect.\"</p> </li> <li> <p>\"what's the use of building your body if you can't build your mind?'\"</p> </li> <li> <p>\"It is, therefore, a severe and grave misinterpretation of man to deal with him as if he were a closed system.\"</p> </li> <li> <p>\"A lack of \"direct access\" to the mental states of those selves makes us less prone to see them as having evolving inner lives.\"</p> </li> <li> <p>\"No matter how optimized, healthy, and productive I am, I simply will not become more or better forever, which means there are things I will never do and never be. Just like this book, which could have been anything when I started it, my life will take some paths and not others\u2014and then it will end, the thread pulled out of the ball, with no witch to indulge me by taking it back. Realizing that I cannot be everything is in one sense incredibly freeing: It means I am not responsible for being everything. Yet the fact that life ends, for anyone who enjoys being alive and in the world, is also inherently sorrowful.\"</p> </li> <li> <p>\"I feel alive if I'm not alone in the air, but embraced by it. I feel alive when someone's eyes light up, and mine do too. I feel alive if I can look at a deer and see it looking back at me; if, when geese speak, it sounds like language; if, when I walk on the ground, I feel it pushing back against me.\"</p> </li> <li> <p>\"No one is responsible for an emergence; no one can glory in it, since it always occurs in the interstice.\"</p> </li> <li> <p>\"But when I understand that this glass is already broken, every minute with it is precious.\"</p> </li> <li> <p>\"With nothing but distance between you and your destination, it may as well have already taken place. It's as though you had an amazing set of binoculars that let you see something far away in such detail that you didn't actually need to go there. Let's just get it over with, says the heartbroken subject, unable to enjoy her already-broken cup.\"</p> </li> <li> <p>\"You're turning time into space, he would say. You're imagining empty blocks of time stretching out in front of you, mentally crossing that distance toward the thing you think has already happened, instead of admitting the creative aspect of time that is ever evolving and shifting, each second heaving the world\u2014and you\u2014through the crust of the present and into the future.\"</p> </li> <li> <p>\"Could it be that the opposite of looking assuredly through binoculars at a flat space would be the perspective you get when rounding a mountain trail\u2014one where, even though you know where you are, things look different at every turn?\"</p> </li> <li> <p>\"Though my episodic memory goes back only so far, my existence is explained by older things: my mother's immigration, a war whose exigencies threw my grandparents together, and the fish swimming off the coast of Estancia, on the eastern tip of Iloilo. The people who fished there have something to do with me, just as I continue to have something to do with them.\"</p> </li> <li> <p>\"Kinship moves in cycles, the land moves in seasonal cycles, the sky moves in stellar cycles, and time is so bound up in those things that it is not even a separate concept from space. We experience time in a very different way from people immersed in flat schedules and story-less surfaces. In our spheres of existence, time does not go in a straight line, and it is as tangible as the ground we stand on.\"</p> </li> <li> <p>\"Compared to chronos, kairos sounds like the domain of those wayfarers who knew that time is inseparable from space and that every place-moment demands close attention, lest you miss your opportunity. It's not that you can't plan, but that the time in the plan doesn't appear flat, dead, inert. Instead, in the \"meantime,\" you wait with your ear to the ground for patterns of vibration that will never repeat themselves. Faced with flatness, you look for an opening. When it comes, you take it, and you don't look back.\"</p> </li> <li> <p>\"You can make the same mistake in the opposite direction, forgetting that the future will contain many such moments of doubt\u2014or even neglecting to notice when you're in one.\"</p> </li> <li> <p>\"The past would crush you with tradition, and the future would crush you with determinism. Hence the importance and fragility of the \"gap\" (another term for \"non-time\") in the toc: true title of Arendt's preface, \"The Gap between Past and Future.\" To live in the gap between past and future is quite simply the human condition, even if culturally dominant and politically convenient views of time, history, and the future obscure it from us. Looking mournfully to the future in which something new can never happen, we can't see ourselves standing in the gap, the only place where anything new is capable of happening. It makes me wonder if one meaning of \"having time\" is to halve time\u2014to make a cut in chronos and hold the past and the future apart as much as hope will allow.[*5] \u2014 EVERY PIECE OF writing is a time capsule. It assembles fragments of its own world and sends them onward to a reader who exists in a different one, not just in space but also in time. Even writing privately in a journal presupposes a future self who will be reading it\u2014and a future at all. In the case of this book, I cannot know what has happened between the time I am writing this and the time in which you are encountering it. But I can tell you that I am living in a moment of doubt. Perhaps you are, too. That evening when I saw the indistinguishable figure, I had been headed to the place where the road ends, a designated \"natural area\" called Raab's Lagoon. There, after the pavement turns to grass, you pass under alder and fir trees and come to a bench dedicated to a man who died in 2016. If you keep going, the pathway juts out into the water, part of an artificial barrier between the waters of Quartermaster Harbor and the smaller lagoon. Across a small breach through which the harbor water flows, the barrier continues on until it hits the other side of the lagoon. The first time I visited, the water in the breach didn't seem to be moving in any particular direction. It was high tide, though I didn't know that at the time; having just arrived, I thought the area always looked like that. Over the course of a few weeks, I inevitably became familiar with the tides, because Quartermaster Harbor was right outside the door of my room. When the tide was high, you could hear the water plopping and the plastic canoe docks banging against the wooden posts, something I started to call \"the song of the dock.\" When the tide was lower, white-winged scoters, migratory diving ducks with a surreal flourish of a white feather under their eyes, would appear in loose flocks and dive for the mussels at the bottom. When the tide was all the way out, the mussel shells were maximally revealed, and both people\"</p> </li> <li> <p>\"The mind always wants to categorize and compare,\"</p> </li> <li> <p>\"A belief may be comforting. Only through your own experience, however, does it become liberating.\"</p> </li> <li> <p>\"So the single most vital step on your journey toward enlightenment is this: learn to disidentify from your mind. Every time you create a gap in the stream of mind, the light of your consciousness grows stronger.\"</p> </li> <li> <p>\"Emotion arises at the place where mind and body meet.\"</p> </li> <li> <p>\"If you really want to know your mind, the body will always give you a truthful reflection, so look at the emotion or rather feel it in your body. If there is an apparent conflict between them, the thought will be the lie, the emotion will be the truth.\"</p> </li> <li> <p>\"doorway into Being. \u00a4 An emotion usually represents an amplified and energized thought pattern, and because of its often overpowering energetic charge, it is not easy initially to stay present enough to be able to watch it. It wants to take you over, and it usually succeeds unless there is enough presence in you.\"</p> </li> <li> <p>\"Basically, all emotions are modifications of one primordial, undifferentiated emotion that has its origin in the loss of awareness of who you are beyond name and form. Because of its undifferentiated nature, it is hard to find a name that precisely describes this emotion. \"Fear\" comes close, but apart from a continuous sense of threat, it also includes a deep sense of abandonment and incompleteness.\"</p> </li> <li> <p>\"the harder the mind struggles to get rid of the pain, the greater the pain.\"</p> </li> <li> <p>\"Pleasure is always derived from something outside you, whereas joy arises from within.\"</p> </li> <li> <p>\"Even when the sky is heavily overcast, the sun hasn't disappeared. It's still there on the other side of the clouds.\"</p> </li> <li> <p>\"All cravings are the mind seeking salvation or fulfillment in external things and in the future as a substitute for the joy of Being.\"</p> </li> <li> <p>\"Pain is inevitable as long as you are identified with your mind, which is to say as long as you are unconscious, spiritually speaking.\"</p> </li> <li> <p>\"The pain that you create now is always some form of nonacceptance, some form of unconscious resistance to what is.\"</p> </li> <li> <p>\"In other words, the more you are identified with your mind, the more you suffer.\"</p> </li> <li> <p>\"Yes, we need the mind as well as time to function in this world, but there comes a point where they take over our lives, and this is where dysfunction, pain, and sorrow set in.\"</p> </li> <li> <p>\"The accumulation of time in the collective and individual human mind also holds a vast amount of residual pain from the past.\"</p> </li> <li> <p>\"Always say \"yes\" to the present moment. What could be more futile, more insane, than to create inner resistance to something that already\"</p> </li> <li> <p>\"What could be more futile, more insane, than to create inner resistance to something that already is?\"</p> </li> <li> <p>\"By watching the mechanics of the mind, you step out of its resistance patterns, and you can then allow the present moment to be.\"</p> </li> <li> <p>\"Accept then act. Whatever the present moment contains, accept it as if you had chosen it. Always work with it, not against it. Make it your friend and ally, not your enemy. This will miraculously transform your whole life.\"</p> </li> <li> <p>\"Pain can only feed on pain. Pain cannot feed on joy. It finds it quite indigestible.\"</p> </li> <li> <p>\"Once the pain-body has taken you over, you want more pain. You become a victim or a perpetrator. You want to inflict pain, or you want to suffer pain, or both. There isn't really much difference between the two.\"</p> </li> <li> <p>\"Where there is anger, there is always pain underneath.\"</p> </li> <li> <p>\"your own light will quickly grow stronger. When a log that has only just started to burn is placed next to one that is burning fiercely, and after\"</p> </li> <li> <p>\"When a log that has only just started to burn is placed next to one that is burning fiercely, and after a while they are separated again, the first log will be burning with much greater intensity. After all, it is the same fire.\"</p> </li> <li> <p>\"an emotion is the body's reaction to your mind.\"</p> </li> <li> <p>\"To the ego, death is always just around the corner.\"</p> </li> <li> <p>\"Power over others is weakness disguised as strength. True power is within, and it is available to you now.\"</p> </li> <li> <p>\"The secret of life is to \"die before you die\" and find that there is no death.\"</p> </li> <li> <p>\"Studying the complexities of the mind may make you a good psychologist, but doing so won't take you beyond the mind, just as the study of madness isn't enough to create sanity.\"</p> </li> <li> <p>\"The ego's needs are endless. It feels vulnerable and threatened and so lives in a state of fear and want.\"</p> </li> <li> <p>\"When you are present, you can allow the mind to be as it is without getting entangled in it. The mind in itself is not dysfunctional. It is a wonderful tool. Dysfunction sets in when you seek your self in it and mistake it for who you are. It then becomes the egoic mind and takes over your whole life.\"</p> </li> <li> <p>\"The eternal present is the space within which your whole life unfolds, the one factor that remains constant. Life is now. There was never a time when your life was not now, nor will there ever be.\"</p> </li> <li> <p>\"What you think of as the past is a memory trace, stored in the mind, of a former Now. When you remember the past, you reactivate a memory trace and you do so now. The future is an imagined Now, a projection of the mind.\"</p> </li> <li> <p>\"Time is what keeps the light from reaching us. There is no greater obstacle to God than time.\"</p> </li> <li> <p>\"The mind cannot know the tree. It can only know facts or information about the tree. My mind cannot know you, only labels, judgments, facts, and opinions about you. Being alone knows directly.\"</p> </li> <li> <p>\"heavy burden of psychological time. If you set yourself a goal and work toward it, you are using clock time. You are aware of where you want to go, but you honor and give your fullest attention to the\"</p> </li> <li> <p>\"If you set yourself a goal and work toward it, you are using clock time. You are aware of where you want to go, but you honor and give your fullest attention to the step that you are taking at this moment. If you then become excessively focused on the goal, perhaps because you are seeking happiness, fulfillment, or a more complete sense of self in it, the Now is no longer honored. It becomes reduced to a mere stepping stone to the future, with no intrinsic value. Clock time then turns into psychological time. Your life's journey is no longer an adventure, just an obsessive need to arrive, to attain, to \"make it.\" You no longer see or smell the flowers by the wayside either, nor are you aware of the beauty and the miracle of life that unfolds all around you when you are present in the Now.\"</p> </li> <li> <p>\"belief in a future heaven creates a present hell.\"</p> </li> <li> <p>\"Guilt, regret, resentment, grievances, sadness, bitterness, and all forms of nonforgiveness are caused by too much past, and not enough presence.\"</p> </li> <li> <p>\"If all your problems or perceived causes of suffering or unhappiness were miraculously removed for you today, but you had not become more present, more conscious, you would soon find yourself with a similar set of problems or causes of suffering, like a shadow that follows you wherever you go.\"</p> </li> <li> <p>\"There is no salvation in time. You cannot be free in the future. Presence is the key to freedom, so you can only be free now.\"</p> </li> <li> <p>\"Hope is what keeps you going, but hope keeps you focused on the future, and this continued focus perpetuates your denial of the Now and therefore your unhappiness.\"</p> </li> <li> <p>\"The mind unconsciously loves problems because they give you an identity of sorts.\"</p> </li> <li> <p>\"Problem\" means that you are dwelling on a situation mentally without there being a true intention or possibility of taking action now and that you are unconsciously making it part of your sense of self. You become so overwhelmed by your life situation that you lose your sense of life, of Being. Or you are carrying in your mind the insane burden of a hundred things that you will or may have to do in the future instead of focusing your attention on the one thing that you can do now.\"</p> </li> <li> <p>\"If you cannot be present even in normal circumstances, such as when you are sitting alone in a room, walking in the woods, or listening to someone, then you certainly won't be able to stay conscious when something \"goes wrong\" or you are faced with difficult people or situations, with loss or the threat of loss. You will be taken over by a reaction, which ultimately is always some form of fear, and pulled into deep unconsciousness. Those challenges are your tests.\"</p> </li> <li> <p>\"When you learn to be the witness of your thoughts and emotions, which is an essential part of being present, you may be surprised when you first become aware of the background \"static\" of ordinary unconsciousness and realize how rarely, if ever, you are truly at ease within yourself. On the level of your thinking, you will find a great deal of resistance in the form of judgment, discontent, and mental projection away from the Now. On the emotional level, there will be an undercurrent of unease, tension, boredom, or nervousness. Both are aspects of the mind in its habitual resistance mode.\"</p> </li> <li> <p>\"Unhappiness spreads more easily than a physical disease.\"</p> </li> <li> <p>\"Once you realize that a certain kind of food makes you sick, would you carry on eating that food and keep asserting that it is okay to be sick?\"</p> </li> <li> <p>\"When you complain, you make yourself into a victim. When you speak out, you are in your power.\"</p> </li> <li> <p>\"is there something that you \"should\" be doing but are not doing it? Get up and do it now. Alternatively, completely accept your inactivity, laziness, or passivity at this moment, if that is your choice. Go into it fully. Enjoy it. Be as lazy or inactive as you can. If you go into it fully and consciously, you will soon come out of it. Or maybe you won't. Either way, there is no inner conflict, no resistance, no negativity.\"</p> </li> <li> <p>\"Stress is caused by being \"here\" but wanting to be \"there,\" or being in the present but wanting to be in the future. Its a split that tears you apart inside.\"</p> </li> <li> <p>\"Waiting is a state of mind. Basically, it means that you want the future; you don't want the present. You don't want what you've got, and you want what you haven't got.\"</p> </li> <li> <p>\"So give up waiting as a state of mind. When you catch yourself slipping into waiting . . . snap out of it. Come into the present moment.\"</p> </li> <li> <p>\"Your outer journey may contain a million steps; your inner journey only has one: the step you are taking right now.\"</p> </li> <li> <p>\"gain the world and lose your soul,\" as Jesus puts it. Ultimately, of course, every outer purpose is doomed to \"fail\" sooner or later, simply because it is subject to the law of impermanence of all things.\"</p> </li> <li> <p>\"Ultimately, of course, every outer purpose is doomed to \"fail\" sooner or later, simply because it is subject to the law of impermanence of all things. The sooner you realize that your outer purpose cannot give you lasting fulfillment, the better. When you have seen the limitations of your outer purpose, you give up your unrealistic expectation that it should make you happy, and you make it subservient to your inner purpose.\"</p> </li> <li> <p>\"The past cannot survive in your presence. It can only survive in your absence.\"</p> </li> <li> <p>\"What do you mean by \"rooted within yourself\"? It means to inhabit your body fully. To always have some of your attention in the inner energy field of your body. To feel the body from within, so to speak. Body awareness keeps you present.\"</p> </li> <li> <p>\"If a fish is born in your aquarium and you call it John, write out a birth certificate, tell him about his family history, and two minutes later he gets eaten by another fish thats tragic. But ifs only tragic because you projected a separate self where there was none. You got hold of a fraction of a dynamic process, a molecular dance, and made a separate entity out of it.\"</p> </li> <li> <p>\"Consciousness takes on the disguise of forms until they reach such complexity that it completely loses itself in them.\"</p> </li> <li> <p>\"The teacher and the taught together create the teaching.\"</p> </li> <li> <p>\"Even if there is noise, there is always some silence underneath and in between the sounds. Listening to the silence immediately creates stillness inside you.\"</p> </li> <li> <p>\"You can study and talk about honey for as long as you like, but you won't really know it until you taste it. After you have tasted it, the word becomes less important to you. You won't be attached to it anymore.\"</p> </li> <li> <p>\"An image, no matter how beautiful or powerful, is already defined in form, so there is less scope for penetrating more deeply.\"</p> </li> <li> <p>\"The light of their consciousness was not yet strong enough to make friends with their animal nature, to allow it to be and even enjoy that aspect of themselves let alone to go deeply into it to find the divine hidden within it, the reality within the illusion. So they did what they had to do. They began to disassociate from their body. They now saw themselves as having a body, rather than just being it.\"</p> </li> <li> <p>\"Forgiveness is to offer no resistance to life to allow life to live through you.\"</p> </li> <li> <p>\"Before you enter the temple, forgive.\"</p> </li> <li> <p>\"In any thought activity, make it a habit to go back and forth every few minutes or so between thinking and an inner kind of listening, an inner stillness. We could say. don't just think with your head, think with your whole body.\"</p> </li> <li> <p>\"opening up. Every sound is born out of silence, dies back into silence, and during its life span is surrounded by silence. Silence enables the sound to be.\"</p> </li> <li> <p>\"Every sound is born out of silence, dies back into silence, and during its life span is surrounded by silence. Silence enables the sound to be. It is an intrinsic but unmanifested part 0fevery sound, every musical note, every song, every word.\"</p> </li> <li> <p>\"Everybody pays attention to the things in space, but who pays attention to space itself?\"</p> </li> <li> <p>\"Once you have a theory, ifs not too hard to find evidence to substantiate it, at least until some other theory comes along.\"</p> </li> <li> <p>\"At least two points of reference are needed for distance and space to come into being. Space comes into being the moment the One becomes two, and as \"two\" become the \"ten thousand things,\" as Lao Tse calls the manifested world, space becomes more and more vast. So world and space arise simultaneously.\"</p> </li> <li> <p>\"If there were no illusion, there would be no enlightenment.\"</p> </li> <li> <p>\"You see time as the means to salvation, whereas in truth it is the greatest obstacle to salvation.\"</p> </li> <li> <p>\"The positive already contains within itself the as yet unmanifested negative. Both are in fact different aspects of the same dysfunction.\"</p> </li> <li> <p>\"The reason why the romantic love relationship is such an intense and universally sought-after experience is that it seems to offer liberation from a deep-seated state of fear, need, lack, and incompleteness that is part of the human condition in its unredeemed and unenlightened state.\"</p> </li> <li> <p>\"Every addiction starts with pain and ends with pain.\"</p> </li> <li> <p>\"To disidentify from thinking is to be the silent watcher of your thoughts and behavior, especially the repetitive patterns of your mind and the roles played by the ego.\"</p> </li> <li> <p>\"The bond that connects you with that person is the same bond that connects you with the person sitting next to you on a bus, or with a bird, a tree, a flower. Only the degree of intensity with which it is felt differs.\"</p> </li> <li> <p>\"when you know there is disharmony and you hold that \"knowing,\" through your knowing a new factor has come in, and the disharmony cannot remain unchanged.\"</p> </li> <li> <p>\"You cannot transform yourself, and you certainly cannot transform your partner or anybody else. All you can do is create a space for transformation to happen, for grace and love to enter.\"</p> </li> <li> <p>\"Judgment is either to confuse someone's unconscious behavior with who they are or to project your own unconsciousness onto another person and mistake that for who they are.\"</p> </li> <li> <p>\"It is not easy to live with an enlightened person, or rather it is so easy that the ego finds it extremely threatening.\"</p> </li> <li> <p>\"As a general rule, the major obstacle for men tends to be the thinking mind, and the major obstacle for women the pain-body, although in certain individual cases the opposite may be true, and in others the two factors may be equal.\"</p> </li> <li> <p>\"if you are trapped in a nightmare you will probably be more strongly motivated to awaken than someone who is just caught in the ups and downs of an ordinary dream.\"</p> </li> <li> <p>\"A victim identity is the belief that the past is more powerful than the present, which is the opposite of the truth.\"</p> </li> <li> <p>\"In Being, male and female are one. Your form may continue to have certain needs, but Being has none. It is already complete and whole. If those needs are met, that is beautiful, but whether or not they are met makes no difference to your deep inner state. So it is perfectly possible for an enlightened person, if the need for the male or female polarity is not met, to feel a sense of lack or incompleteness on the outer level of his or her being, yet at the same time be totally complete, fulfilled, and at peace within. In\"</p> </li> <li> <p>\"Acute unhappiness can be a great awakener.\"</p> </li> <li> <p>\"Happiness depends on conditions being perceived as positive; inner peace does not.\"</p> </li> <li> <p>\"For example, when a loved one has just died, or you feel your own death approaching, you cannot be happy. It is impossible. But you can be at peace. There may be sadness and tears, but provided that you have relinquished resistance, underneath the sadness you will feel a deep serenity, a stillness, a sacred presence. This is the emanation of Being, this is inner peace, the good that has no opposite.\"</p> </li> <li> <p>\"Accept whatever comes to you woven in the pattern of your destiny, for what could more aptly fit your needs?\"</p> </li> <li> <p>\"You cannot have an argument with a fully conscious person.\"</p> </li> <li> <p>\"No one who is at one with himself can even conceive of conflict,\"</p> </li> <li> <p>\"Growth is usually considered positive, but nothing can grow forever.\"</p> </li> <li> <p>\"The cyclical nature of the universe is closely linked with the impermanence of all things and situations.\"</p> </li> <li> <p>\"The happiness that is derived from some secondary source is never very deep.\"</p> </li> <li> <p>\"Have you ever seen an unhappy flower or a stressed oak tree? Have you come across a depressed dolphin, a frog that has a problem with self-esteem, a cat that cannot relax, or a bird that carries hatred and resentment? The only animals that may occasionally experience something akin to negativity or show signs of neurotic behavior are those that live in close contact with humans and so link into the human mind and its insanity.\"</p> </li> <li> <p>\"When you have reached a certain degree of presence, you don't need negativity anymore to tell you what is needed in your life situation. But as long as negativity is there, use it. Use it as a kind of signal that reminds you to be more present.\"</p> </li> <li> <p>\"Even the slightest irritation is significant and needs to be acknowledged and looked at; otherwise, there will be a cumulative build-up of unobserved reactions.\"</p> </li> <li> <p>\"As an alternative to dropping a negative reaction, you can make it disappear by imagining yourself becoming transparent to the external cause of the reaction.\"</p> </li> <li> <p>\"When you accept what is, every piece of meat every moment is the best. That is enlightenment.\"</p> </li> <li> <p>\"You don't resist change by mentally clinging to any situation. Your inner peace does not depend on it. You abide in Being unchanging, timeless, deathless and you are no longer dependent for fulfillment or happiness on the outer world of constantly fluctuating forms. You can enjoy them, play with them, create new forms, appreciate the beauty of it all. But there will be no need to attach yourself to any of it.\"</p> </li> <li> <p>\"Compassion is the awareness of a deep bond between yourself and all creatures.\"</p> </li> <li> <p>\"Surrender is a purely inner phenomenon. It does not mean that on the outer level you cannot take action and change the situation.\"</p> </li> <li> <p>\"\u00a4 If you find your life situation unsatisfactory or even intolerable, it is only by surrendering first that you can break the unconscious resistance pattern\"</p> </li> <li> <p>\"If you find your life situation unsatisfactory or even intolerable, it is only by surrendering first that you can break the unconscious resistance pattern that perpetuates that situation.\"</p> </li> <li> <p>\"Surrender is perfectly compatible with taking action, initiating change or achieving goals. But in the surrendered state a totally different energy, a different quality, flows into your doing.\"</p> </li> <li> <p>\"Look at the lilies, how they grow; they neither toil nor spin.\"</p> </li> <li> <p>\"Any action you take may not bear fruit immediately. Until it does do not resist what is. If there is no action you can take, and you cannot remove yourself from the situation either, then use the situation to make you go more deeply into surrender, more deeply into the Now, more deeply into Being. When you enter this timeless dimension of the present, change often comes about in strange ways without the need for a great deal of doing on your part. Life becomes helpful and cooperative.\"</p> </li> <li> <p>\"In Taoism, there is a term called wu wei, which is usually translated as \"actionless activity\" or \"sitting quietly doing nothing.\" In ancient China, this was regarded as one of the highest achievements or virtues. It is radically different from inactivity in the ordinary state of consciousness, or rather unconsciousness, which stems from fear, inertia, or indecision. The real \"doing nothing\" implies inner nonresistance and intense alertness. On the other hand, if action is required, you will no longer react from your conditioned mind, but you will respond to the situation out of your conscious presence. In that state, your mind is free of concepts, including the concept of nonviolence. So who can predict what you will do?\"</p> </li> <li> <p>\"Withdraw time from the illness. Do not give it any past or future. Let it force you into intense present-moment awareness and see what happens.\"</p> </li> <li> <p>\"The condition that is labeled \"illness\" has nothing to do with who you truly are.\"</p> </li> <li> <p>\"If you cannot accept what is outside, then accept what is inside. If you cannot accept the external condition, accept the internal condition. This means: Do not resist the pain. Allow it to be there. Surrender to the grief, despair, fear, loneliness, or whatever form the suffering takes. Witness it without labeling it mentally. Embrace it. Then see how the miracle of surrender transmutes deep suffering into deep peace.\"</p> </li> <li> <p>\"Suffering does not diminish in intensity when you make it unconscious.\"</p> </li> <li> <p>\"The mind, conditioned as it is by the past, always seeks to re- create what it knows and is familiar with. Even if it is painful, at least it is familiar. The mind always adheres to the known. The unknown is dangerous because it has no control over it. Thats why the mind dislikes and ignores the present moment. Present-moment awareness creates a gap not only in the stream of mind but also in the past-future continuum. Nothing truly new and creative can come into this world except through that gap, that clear space of infinite possibility.\"</p> </li> <li> <p>\"What comes to mind when we ask \"Who am I?\" consists of those things we have been paying attention to over the years. The same goes for our impressions of other people. The reality that appears to us is not so much what's out there as it is those aspects of the world we have focused on.\"</p> </li> <li> <p>\"Before we can develop attentional stability, we first need to learn to relax.\"</p> </li> <li> <p>\"We are all aware of the way the body heals itself. Physicians don't heal abrasions, and surgeons don't mend bone fractures. Instead, they do whatever they can to allow the body to heal itself\u2014by keeping the wound clean, setting the broken bone, and so on. These are so common that it's easy to lose sight of the extraordinary nature of the body's own healing power.\"</p> </li> <li> <p>\"When a stream is polluted, one may try to add antidotes to the toxins in the water, hoping such additives will neutralize the damage. But the more straightforward and sensible approach is simply to stop the flow of contamination into the stream. When this is done, over time the flow of the water through soil, stones, and vegetation can purify the stream completely.\"</p> </li> <li> <p>\"Genuine happiness is a symptom of a balanced, healthy mind, just as a sense of physical well-being is a sign of a healthy body.\"</p> </li> <li> <p>\"We do not exist independently from others, so our well-being cannot arise independently of others either.\"</p> </li> <li> <p>\"The reason we don't devote more time to balancing our minds is that we are betting our lives that we can find the happiness we seek by chasing fleeting pleasures.\"</p> </li> <li> <p>\"However busy we may be, or think we are, no one is paying us enough to have demands on our minds every single moment of the day.\"</p> </li> <li> <p>\"In the seen there is only the seen; in the heard, there is only the heard; in the sensed, there is only the sensed; in the mentally perceived, there is only the mentally perceived.\"</p> </li> <li> <p>\"to divide your attention, consider your priorities. If something's worth doing, it's worth doing well, and if something's not worth doing, it's not worth doing at all.\"</p> </li> <li> <p>\"When you start to experience the inner calm, simplicity, and quietude of shamatha practice, you may become attached to this state of mind, and that can result in apathetic indifference to those around you and the world at large. You've got your own quiet space of serenity, and you may not want to be disturbed. The worthy venture of meditative training becomes derailed when it results in such complacency; it can become little more than a substitute for Prozac or Valium. The real aim of this practice is to cultivate mental balance that results in genuine happiness, and indifference to others is not a sign of genuine happiness or mental health.\"</p> </li> <li> <p>\"The quality of our lives reflects the ways we have cultivated our minds until now.\"</p> </li> <li> <p>\"Virtually anything may catalyze unhappiness, but its true source is always in the mind.\"</p> </li> <li> <p>\"Solitary meditation doesn't cause mental imbalances, but uncovers them. Boredom may set in, especially when the mind succumbs to laxity, and restlessness often comes in the wake of excitation. With perseverance you can move beyond these imbalances and begin to discover the well-being that arises from a balanced mind. But this requires courage to face your own inner demons and persist in the practice despite the emotional upheavals that are bound to occur in the course of this training.\"</p> </li> <li> <p>\"those who have accustomed themselves to having few desires and contentment can find joy in solitude, whereas those who have not found such equilibrium are bound either to sink into laxity and depression or to float up into excitation and restlessness.\"</p> </li> <li> <p>\"What you make doesn't have to be witnessed, recorded, sold, or encased in glass for it to be a work of art.\"</p> </li> <li> <p>\"by the mere fact of being alive, we are active participants in the ongoing process of creation.\"</p> </li> <li> <p>\"Attuned choice by attuned choice, your entire life is a form of self-expression. You exist as a creative being in a creative universe. A singular work of art.\"</p> </li> <li> <p>\"The taste and beauty are in the eye of the beholder.\"</p> </li> <li> <p>\"If you have an idea you're excited about and you don't bring it to life, it's not uncommon for the idea to find its voice through another maker. This isn't because the other artist stole your idea, but because the idea's time has come.\"</p> </li> <li> <p>\"The best artists tend to be the ones with the most sensitive antennae to draw in the energy resonating at a particular moment. Many great artists first develop sensitive antennae not to create art but to protect themselves. They have to protect themselves because everything hurts more. They feel everything more deeply.\"</p> </li> <li> <p>\"Artists who are able to continually create great works throughout their lives often manage to preserve these childlike qualities. Practicing a way of being that allows you to see the world through uncorrupted, innocent eyes can free you to act in concert with the universe's timetable.\"</p> </li> <li> <p>\"Clouds never truly disappear. They change form. They turn into rain and become part of the ocean, and then evaporate and return to being clouds. The same is true of art.\"</p> </li> <li> <p>\"As soon as you label an aspect of Source, you're no longer noticing, you're studying.\"</p> </li> <li> <p>\"Analysis is a secondary function. The awareness happens first as a pure connection with the object of your attention. If something strikes me as interesting or beautiful, first I live that experience. Only afterward might I attempt to understand it.\"</p> </li> <li> <p>\"The universe is only as large as our perception of it.\"</p> </li> <li> <p>\"doesn't fit easily within the limits of our belief system. The more raw data we can take in, and the\"</p> </li> <li> <p>\"The more raw data we can take in, and the less we shape it, the closer we get to nature.\"</p> </li> <li> <p>\"One can think of the creative act as taking the sum of our vessel's contents as potential material, selecting for elements that seem useful or significant in the moment, and re-presenting them. This is Source drawn through us and made into books, movies, buildings, paintings, meals, businesses\u2014whatever projects we embark on. If we choose to share what we make, our work can recirculate and become source material for others.\"</p> </li> <li> <p>\"What we create allows us to share glimpses of an inner landscape, one that is beyond our understanding. Art is our portal to the unseen world.\"</p> </li> <li> <p>\"The world of reason can be narrow and filled with dead ends, while a spiritual viewpoint is limitless and invites fantastic possibilities. The unseen world is boundless.\"</p> </li> <li> <p>\"The practice of spirituality is a way of looking at a world where you're not alone. There are deeper meanings behind the surface. The energy around you can be harnessed to elevate your work. You are part of something much larger than can be explained\u2014a world of immense possibilities.\"</p> </li> <li> <p>\"If a piece of work, a fragment of consciousness, or an element of nature is somehow allowing us to access something bigger, that is its spiritual component made manifest. It awards us a glimpse of the unseen.\"</p> </li> <li> <p>\"If we aren't looking for clues, they'll pass by without us ever knowing. Notice connections and consider where they lead.\"</p> </li> <li> <p>\"the universe is nudging you with little reminders that it's on your side and wants to provide everything you need to complete your mission.\"</p> </li> <li> <p>\"Look for what you notice but no one else sees.\"</p> </li> <li> <p>\"Awareness needs constant refreshing. If it becomes a habit, even a good habit, it will need to be reinvented again and again. Until one day, you notice that you are always in the practice of awareness, at all times, in all places, living your life in a state of constant openness to receiving.\"</p> </li> <li> <p>\"Living life as an artist is a practice. You are either engaging in the practice or you're not.\"</p> </li> <li> <p>\"The real work of the artist is a way of being in the world.\"</p> </li> <li> <p>\"Because there's an endless amount of data available to us and we have a limited bandwidth to conserve, we might consider carefully curating the quality of what we allow in.\"</p> </li> <li> <p>\"Of all the great works that we can experience, nature is the most absolute and enduring. We can witness it change through the seasons. We\"</p> </li> <li> <p>\"We don't have to understand nature to appreciate it. This is true of all things. Simply be aware of moments when your breath\"</p> </li> <li> <p>\"We don't have to understand nature to appreciate it. This is true of all things. Simply be aware of moments when your breath gets taken away by something of great beauty.\"</p> </li> <li> <p>\"Nature transcends our tendencies to label and classify, to reduce and limit.\"</p> </li> <li> <p>\"It is said the ocean provides a closer reflection of who we are than any mirror.\"</p> </li> <li> <p>\"Even if an element seems static, whether a work of art in a museum or an everyday object in a kitchen, when we look at it deeply, we can see a newness. We recognize aspects unnoticed before. Reread the same book over and over, and we'll likely find new themes, undercurrents, details, and connections.\"</p> </li> <li> <p>\"You can't step into the same stream\"</p> </li> <li> <p>\"Our inner world is every bit as interesting, beautiful, and surprising as nature itself. It is, after all, born of nature.\"</p> </li> <li> <p>\"Ultimately, it doesn't make a difference whether your content originates on the inside or the outside. If a beautiful thought or phrase comes to mind, or if you see a beautiful sunset, one's not better than the other. Both are equally beautiful in different ways. It's helpful to consider there are always more options available to us than we might realize.\"</p> </li> <li> <p>\"It isn't uncommon, out of the gibberish, for a story to unfold or key phrases to appear.\"</p> </li> <li> <p>\"sleep. Memories can also be thought of as dreamlike. They're more a romantic\"</p> </li> <li> <p>\"Memories can also be thought of as dreamlike. They're more a romantic story than a faithful document of a life event.\"</p> </li> <li> <p>\"Tomorrow presents another opportunity for awareness, but it's never an opportunity for the same awareness.\"</p> </li> <li> <p>\"It helps to realize that it's better to follow the universe than those around you.\"</p> </li> <li> <p>\"Self-doubt lives in all of us. And while we may wish it gone, it is there to serve\"</p> </li> <li> <p>\"Flaws are human, and the attraction of art is the humanity held in it. If we were machinelike, the art wouldn't resonate. It would be soulless. With life comes pain, insecurity, and fear.\"</p> </li> <li> <p>\"If a creator is so afraid of judgment that they're unable to move forward, it might be that the desire to share the work isn't as strong as the desire to protect themselves. Perhaps art isn't their role. Their temperament might serve a different pursuit. This path is not for everyone. Adversity is part of the process.\"</p> </li> <li> <p>\"One of the reasons so many great artists die of overdoses early in their lives is because they're using drugs to numb a very painful existence. The reason it's painful is the reason they became artists in the first place: their incredible sensitivity.\"</p> </li> <li> <p>\"If you see tremendous beauty or tremendous pain where other people see little or nothing at all, you're confronted with big feelings all the time. These emotions can be confusing and overwhelming. When those around you don't see what you see and feel what you feel, this can lead to a sense of isolation and a general feeling of not belonging, of otherness.\"</p> </li> <li> <p>\"All art is a work in progress.\"</p> </li> <li> <p>\"some things are too important to be taken seriously.\"</p> </li> <li> <p>\"the Buddhist concept of papancha, which translates as preponderance of thoughts. This speaks to the mind's tendency to respond to our experiences with an avalanche of mental chatter.\"</p> </li> <li> <p>\"The imperfections you're tempted to fix might prove to be what make the work great. And sometimes not.\"</p> </li> <li> <p>\"Distraction is one of the best tools available to the artist when used skillfully. In some cases, it's the only way to get where we are going.\"</p> </li> <li> <p>\"Nothing begins with us. The more we pay attention, the more we begin to realize that all the work we ever do is a collaboration.\"</p> </li> <li> <p>\"The inspired-artist aspect of your self may be in conflict with the craftsperson aspect, disappointed that the craftsperson is unable to create the physical embodiment of the inspired artist's vision.\"</p> </li> <li> <p>\"A painting is just a painting until you put a frame on it and hang it on the wall, then it's called art. What's considered art is simply an agreement. And none of it is true.\"</p> </li> <li> <p>\"A completed project is only made up of our intention and our experiments around it. Remove intention and all that's left is the ornamental shell.\"</p> </li> <li> <p>\"Not all projects take time, but they do take a lifetime.\"</p> </li> <li> <p>\"Most creators think of themselves as the conductor of the orchestra. If we zoom out of our small view of reality, we function more as an instrumentalist in a much larger symphony the universe is orchestrating. We may not have a great understanding of what this magnum opus is because we only see the small part we play.\"</p> </li> <li> <p>\"Similarly, the total output of human creativity, in all its kaleidoscopic breadth, pieces together the fabric forming our culture. The underlying intention of our work is the aspect allowing it to fit neatly into this fabric. Rarely if ever do we know the grand intention, yet if we surrender to the creative impulse, our singular piece of the puzzle takes its proper shape.\"</p> </li> <li> <p>\"Intention is all there is. The work is just a reminder.\"</p> </li> <li> <p>\"Rules, by their nature, are limitations.\"</p> </li> <li> <p>\"Rules direct us to average behaviors. If we're aiming to create works that are exceptional, most rules don't apply. Average is nothing to aspire to. The goal is not to fit in. If anything, it's to amplify the differences, what doesn't fit, the special characteristics unique to how you see the world. Instead of sounding like others, value your own voice. Develop it. Cherish it.\"</p> </li> <li> <p>\"The reason to make art is to innovate and self-express, show something new, share what's inside, and communicate your singular perspective.\"</p> </li> <li> <p>\"In the beginning, we approach our craft with a template of what's come before.\"</p> </li> <li> <p>\"As soon as you use a label to describe what you're working on, there's a temptation to conform to its rules.\"</p> </li> <li> <p>\"Often, the most innovative ideas come from those who master the rules to such a degree that they can see past them or from those who never learned them at all.\"</p> </li> <li> <p>\"Rules obeyed unconsciously are far stronger than the ones set on purpose.\"</p> </li> <li> <p>\"Holding every rule as breakable is a healthy way to live as an artist. It loosens constraints that promote a predictable sameness in our working methods.\"</p> </li> <li> <p>\"Once you have a new framework, some elements of your older process may find their way back into the work, and that's okay.\"</p> </li> <li> <p>\"For any rules you accept of what you can and cannot do as an artist\u00a0.\u00a0.\u00a0. of what your voice is and isn't\u00a0.\u00a0.\u00a0. of what's required to do the work and what you don't need\u00a0.\u00a0.\u00a0. it would be worthwhile to try the opposite.\"</p> </li> <li> <p>\"Think of a rule as an imbalance.\"</p> </li> <li> <p>\"Though to say that we listen with the ears, or the mind, might be a misconception. We listen with the whole body, our whole self.\"</p> </li> <li> <p>\"Many of us experience life as if we're taking it in through a pair of headphones. We strip away the full register. We hear information, but don't detect the subtler vibrations of feeling in the body.\"</p> </li> <li> <p>\"If it's music you're listening to, consider closing your eyes. You may find yourself getting lost in the experience. When the piece ends, you might be surprised by where you find yourself. You've been transported to another place. The place where the music lives.\"</p> </li> <li> <p>\"Formulating an opinion is not listening. Neither is preparing a response, or defending our position or attacking another's. To listen impatiently is to hear nothing at all.\"</p> </li> <li> <p>\"Listening is suspending disbelief.\"</p> </li> <li> <p>\"More often than not, there are no right answers, just different perspectives.\"</p> </li> <li> <p>\"Many of our beliefs were learned before we had a choice in what we were taught. Some of them might go back generations and may no longer apply. Some may never have applied.\"</p> </li> <li> <p>\"The lottery winner isn't ultimately happy after their sudden change of fortune. The home built hastily rarely survives the first storm. The single-sentence summary of a book or news event is no substitute for the full story.\"</p> </li> <li> <p>\"Re-reading even a well-understood paragraph or page can be revelatory.\"</p> </li> <li> <p>\"Our continual quest for efficiency discourages looking too deeply.\"</p> </li> <li> <p>\"Impatience is an argument with reality.\"</p> </li> <li> <p>\"When it comes to the creative process, patience is accepting that the majority of the work we do is out of our control. We can't force greatness to happen. All we can do is invite it in and await it actively. Not anxiously, as this might scare it off. Simply in a state of continual welcoming.\"</p> </li> <li> <p>\"If we remove time from the equation of a work's development, what we're left with is patience.\"</p> </li> <li> <p>\"Even the masterpieces that have been produced on tight timelines are the sum of decades spent patiently laboring on other works.\"</p> </li> <li> <p>\"What was it that allowed a machine to devise a move no one steeped in the game had ever made in thousands of years of play? It wasn't necessarily its intelligence. It was the fact that the machine learned the game from scratch, with no coach, no human intervention, no lessons based on an expert's past experience. The AI followed the fixed rules, not the millennia of accepted cultural norms attached to them. It didn't take into account the three-thousand-year-old traditions and conventions of Go. It didn't accept the narrative of how to properly play this game. It wasn't held back by limiting beliefs.\"</p> </li> <li> <p>\"One Go expert commented, \"After humanity spent thousands of years improving our tactics, computers tell us that humans are completely wrong\u00a0.\u00a0.\u00a0. I would go as far as to say not a single human has touched the edge of the truth of Go.\"</p> </li> <li> <p>\"To see what no human has seen before, to know what no human has known before, to create as no human has created before, it may be necessary to see as if through eyes that have never seen, know through a mind that has never thought, create with hands that have never been trained.\"</p> </li> <li> <p>\"Did the computer win because it knew more than the grandmaster or because it knew less?\"</p> </li> <li> <p>\"Experience provides wisdom to draw from, but it tempers the power of naivete.\"</p> </li> <li> <p>\"The more ingrained your adopted approach, the harder it is to see past it.\"</p> </li> <li> <p>\"Just as an infant is selfish, they're protective of their art in a way that's not always cooperative.\"</p> </li> <li> <p>\"A child has no set of premises it relies on to make sense of the world. It may serve you to do the same. Any label you assume before sitting down to create, even one as foundational as sculptor, rapper, author, or entrepreneur, could be doing more harm than good. Strip away the labels. Now how do you see the world?\"</p> </li> <li> <p>\"If you spent your whole life living near the ocean, your experience of it would almost certainly be less dramatic.\"</p> </li> <li> <p>\"As artists, we aim to live in a way in which we see the extraordinary hidden in the seemingly mundane. Then challenge ourselves to share what we see in a way that allows others a glimpse of this remarkable beauty.\"</p> </li> <li> <p>\"For the lungs to draw in air, they must first be emptied. For the mind to draw inspiration, it wants space to welcome the new. The universe seeks balance. Through this absence, you are inviting energy in.\"</p> </li> <li> <p>\"To vary your inspiration, consider varying your inputs. Turn the sound off to watch a film, listen to the same song on repeat, read only the first word of each sentence in a short story, arrange stones by size or color, learn to lucid dream.\"</p> </li> <li> <p>\"The work yielded may not be used in the current project, but it may be of use another time. Or it may not. The task of the artist is simply to recognize the transmission and stay with it in gratitude, until it truly runs its course.\"</p> </li> <li> <p>\"In terms of priority, inspiration comes first. You come next. The audience comes last.\"</p> </li> <li> <p>\"A full, imperfect version is generally more helpful than a seemingly perfect fragment.\"</p> </li> <li> <p>\"Wooden often said the only person you're ever competing against is yourself. The rest is out of your control.\"</p> </li> <li> <p>\"If you set a routine that is oppressive, you'll likely find excuses not to show up. It's in the interest of your art to create an easily achievable schedule to start with.\"</p> </li> <li> <p>\"As if catching fish, we walk to the water, bait the hook, cast the line, and patiently wait. We cannot control the fish, only the presence of our line.\"</p> </li> <li> <p>\"The work reveals itself as you go.\"</p> </li> <li> <p>\"Not every seed must grow. But it may be there is a right time for each one. If a seed does not seem to be developing or responding, consider storing it rather than discarding it. In nature, some seeds lie dormant in anticipation of the season most conducive to their growth. This is true of art as well. There are ideas whose time has not yet come. Or perhaps their time has come, but you are not yet ready to engage with them. Other times, developing a different seed may shed light on a dormant one.\"</p> </li> <li> <p>\"As we lose enthusiasm, we often continue to labor on a seed, believing that the work has to turn out for the better because we've invested so much time in it. If the energy continues to drop, it does not necessarily mean that the seed is bad. We just may not have found the right experiment for it. Perhaps we need to step away for a time and shift perspective.\"</p> </li> <li> <p>\"Excitement tends to be the best barometer for selecting which seeds to focus on. When something interesting starts to come together, it arouses delight. It's an energizing feeling of wanting more. A feeling of leaning forward. Follow that energy.\"</p> </li> <li> <p>\"There is a gap between imagination and reality. An idea might seem brilliant in our mind. But once employed, it might not work at all. Another might seem dreary at first. Then, upon execution, it might be exactly what's called for. To dismiss an idea because it\"</p> </li> <li> <p>\"Descriptions do not do ideas justice.\"</p> </li> <li> <p>\"Art may only exist, and the artist may only evolve, by completing the work.\"</p> </li> <li> <p>\"While crafting, make deadlines for your own motivation, not necessarily to be shared with others unless it helps with accountability. Once the Craft phase is nearing an end, then we might start thinking in terms of fixed deadlines.\"</p> </li> <li> <p>\"Art is a reflection of the artist's inner and outer world during the period of creation. Extending the period complicates the artist's ability to capture a state of being. The result can be a loss of connection and enthusiasm for the work over time.\"</p> </li> <li> <p>\"To avoid demo-itis, there is a simple technique. Unless actively working to make something better, avoid listening to it, reading it, playing it, looking at it, or showing it to friends. Work as far forward as you can while crafting and then step away, without repetitively consuming the unfinished work. By not accepting the work-in-progress as the standard version, we leave room for growth, change, and development to continue.\"</p> </li> <li> <p>\"We mistake the fantasy version of the work in our minds for what the actual work has the possibility to become. There may indeed be times when our mental conception of a piece translates almost directly into the physical realm. At other times, it's an unrealistic idealized version. And sometimes, our vision for the work is a goal to work toward, and in the process we come to learn we'll reach a new and unexpected destination.\"</p> </li> <li> <p>\"Falling short of grander visions might actually put the work exactly where it wants to be.\"</p> </li> <li> <p>\"Artists allow us to see what we are unable to see, but somehow already know.\"</p> </li> <li> <p>\"The reason we create art isn't with the intention of making something useful for someone else. We create to express who we are. Who we are and where we are on our journey.\"</p> </li> <li> <p>\"A point of view is different from having a point.\"</p> </li> <li> <p>\"It's impossible to imitate another artist's point of view. We can only swim in the same waters. So feel free to copy the works that inspire you on the road to finding your own voice. It's a time-tested tradition.\"</p> </li> <li> <p>\"Whatever the situation, if a task is challenging to accomplish, there's often a way to design the surroundings to naturally encourage the performance you're striving for.\"</p> </li> <li> <p>\"We interrogate ourselves when we offer our work up to others.\"</p> </li> <li> <p>\"If someone chooses to share feedback, listen to understand the person, not the work. People will tell you more about themselves than about the art when giving feedback. We each see a unique world.\"</p> </li> <li> <p>\"Art doesn't get made on the clock. But it can get finished on the clock.\"</p> </li> <li> <p>\"When the last chapter is about to end, we may create excuses to put off the completion of the work.\"</p> </li> <li> <p>\"Hanging on to your work is like spending years writing the same entry in a diary. Moments and opportunities are lost. The next works are robbed of being brought to life.\"</p> </li> <li> <p>\"In an environment where nothing is permanent, we produce static artifacts. Mementos of spirit. We hope they'll live forever, holding resonance through each passing decade. Some might, many won't. It's impossible to know. We can only keep building.\"</p> </li> <li> <p>\"If the mind creates a world that is limited, where we think we don't have enough worthwhile ideas or material, we will not see the inspiration the universe is providing.\"</p> </li> <li> <p>\"Finishers might benefit from taking more time in the early phases. Writing beyond the minimum requirement, experimenting with other materials, considerations, and perspectives. Allowing themselves space for improvisation and surprise in the process. Experimenters might benefit from taking an aspect of the work through to completion. It might be a drawing, a song,or the chapter of a book. Even making one foundational decision from which to build can help.\"</p> </li> <li> <p>\"As artists, we get to create a new set of rules each and every time we play. After careful consideration, we may choose to break them in the midst of a project if a discovery impels us.\"</p> </li> <li> <p>\"We create our art so we may inhabit it ourselves.\"</p> </li> <li> <p>\"And any story beyond \"I want to make the best thing I can make, whatever it is\" are all undermining forces in the quest for greatness.\"</p> </li> <li> <p>\"It's not uncommon to long for outward success, hopeful it will fill a void inside ourselves. Some imagine achievement as a remedy to fix or heal a sense of not being enough.\"</p> </li> <li> <p>\"If you are living in the belief that success will cure your pain, when the treatment comes and doesn't work, it can lead to hopelessness. A depression can accompany the realization that what you've spent most of your life chasing hasn't fixed your insecurities and vulnerabilities. More likely, with the stakes and consequences now higher, it has only amplified the pressure. And we are never taught how to handle this epic disappointment.\"</p> </li> <li> <p>\"Art has the power to snap us out of our transfixion, open our minds to what's possible, and reconnect with the eternal energy that moves through all things.\"</p> </li> <li> <p>\"The ecstatic is our compass, pointing to our true north. It arises genuinely in the process of creation. You're working and struggling, and suddenly you notice a shift. A revelation. A small tweak is made, a new angle is revealed, and it takes your breath away.\"</p> </li> <li> <p>\"So little was needed to make the leap from mediocrity to greatness. The leap can't always be understood, but when it happens, it's clear and enlivening.\"</p> </li> <li> <p>\"Many artists come to realize long after their work is released that it was actually a shockingly vulnerable and cryptic form of public confession.\"</p> </li> <li> <p>\"When we don't have context, new ideas appear foreign or awkward.\"</p> </li> <li> <p>\"Be aware of strong responses. If you're immediately turned off by an experience, it's worth examining why. Powerful reactions often indicate deeper wells of meaning. And perhaps by exploring them, you'll be led to the next step on your creative path.\"</p> </li> <li> <p>\"Art is about the maker. Its aim: to be an expression of who we are. This makes competition absurd.\"</p> </li> <li> <p>\"comparison is the thief of joy.\"</p> </li> <li> <p>\"No system exists that can rank which work is most reflective of the maker. Great art is an invitation, calling to creators everywhere to strive for still higher and deeper levels.\"</p> </li> <li> <p>\"Perfection is finally obtained not when there is no longer anything to add, but when there's no longer anything to take away.\"</p> </li> <li> <p>\"From a distance, what can we know to be true?\"</p> </li> <li> <p>\"We live in a mysterious world full of uncertainties. And we regularly make assumptions to explain them. Coming to terms with the complexity of our human experience allows us to exit our natural state of confusion. To survive. Generally our explanations are guesses. These vague hypotheticals become fixed in our minds as fact. We are interpretation machines, and this process of labeling and detaching is efficient but not accurate. We are the unreliable narrators of our own experience.\"</p> </li> <li> <p>\"Each artist works with their own balance of strengths and weaknesses. And there is no rule that more praiseworthy strengths or romanticized self-destruction equals better art. Expressing yourself is all that matters.\"</p> </li> <li> <p>\"We will never know a work's true meaning. It's helpful to remember that there are forces at work beyond our comprehension. Let's make art, and let others make the stories.\"</p> </li> <li> <p>\"If any distractions come along during that period, don't ignore them or focus on them. Don't give them any energy at all. Let them pass, like clouds parting around a mountain.\"</p> </li> <li> <p>\"As artists, we are on a continual quest to get closer to the universe by getting closer to self. Moving ever nearer to the point where we can no longer tell where one begins and the other ends. We're on a distant metaphysical journey from the here to the now. It's helpful to work as if the project you're engaged in is bigger than you.\"</p> </li> <li> <p>\"When you acknowledge a weakness, always consider how it could either be removed or improved before discarding the entire piece.\"</p> </li> <li> <p>\"Many of us are taught to create through sheer will. If we choose surrender, the ideas that want to come through us will not be blocked.\"</p> </li> <li> <p>\"For the artist, whose job is testing possibilities, success is as much ruling out a solution as finding one that works.\"</p> </li> <li> <p>\"In the process of experimentation, we allow ourselves to make mistakes, to go too far, to go even further, to be inept. There is no failure, as every step we take is necessary to reach our destination, including the missteps. Each experiment is valuable in its own way if we learn something from it. Even if we can't comprehend its worth, we are still practicing our craft, moving ever so much closer to mastery.\"</p> </li> <li> <p>\"Humanity breathes in mistakes.\"</p> </li> <li> <p>\"Making great art may not always require great effort, but without it, you'll never know.\"</p> </li> <li> <p>\"Creativity is something you are, not only something you do.\"</p> </li> <li> <p>\"Quality isn't based on the amount of time invested.\"</p> </li> <li> <p>\"If you sit down to write with no preparation or forethought, you might bypass the conscious mind and draw from the unconscious. You may find that what emerges holds a charge that cannot be duplicated through rational means.\"</p> </li> <li> <p>\"If we were to learn anything, it would be to free ourselves from any beliefs or baggage or dogma that gets in the way of us acting according to our true nature. The closer we get to a childlike state of free self-expression, the purer our test and the better our art.\"</p> </li> <li> <p>\"Once a work is complete, no amount of testing can guarantee we've made the best possible version. These qualities are not measurable. We test to identify which is the best version from the options at hand.\"</p> </li> <li> <p>\"When the work has five mistakes, it's not yet completed. When it has eight mistakes, it might be.\"</p> </li> <li> <p>\"If we like what we are creating, we don't have to know why. Sometimes the reasons are obvious, sometimes not. And they can change over time. It could be good for any of a thousand different reasons. When we're making things we love, our mission is accomplished. There's nothing at all to figure out.\"</p> </li> <li> <p>\"Holding your work hostage to meaning is a limitation.\"</p> </li> <li> <p>\"is far more powerful than our plans\"</p> </li> <li> <p>\"Art is far more powerful than our plans for it.\"</p> </li> <li> <p>\"Art is above and beyond judgment. It either speaks to you or it doesn't. The artist's only responsibility is to the work itself. There are no other requirements. You're free to create what you will.\"</p> </li> <li> <p>\"Whether you have a powerful passion or a tortured compulsion, neither makes the art any better or worse. If you are able to choose between these paths, consider selecting the more sustainable one. An artist earns the toc: true title simply through self-expression, as they work in their own way at their own pace.\"</p> </li> <li> <p>\"Established artists generally draw from their personal experience and recommend the solutions that worked for them. These tend to be specific to their journey, not yours. It's worth remembering that their way is not the way.\"</p> </li> <li> <p>\"The passive element of practice is as important as the active one.\"</p> </li> <li> <p>\"I'm both a professor and student, because if you're no longer a student, you don't have the right to call yourself a professor.\"</p> </li> <li> <p>\"If you feel unable to hit a note or faithfully paint an image, it's helpful to remember that the challenge is not that you can't do it, but that you haven't done it yet. Avoid thinking in impossibilities.\"</p> </li> <li> <p>\"Having the knowledge won't hurt the work. How you use the knowledge may. You have new tools. You don't have to use them.\"</p> </li> <li> <p>\"If we train ourselves to step away from the work, to truly detach from it, to distract ourselves completely, to dive fully into something else\u00a0.\u00a0.\u00a0. After being away for a long enough period of time, when we come back, we just may be able to see it as if for the first time.\"</p> </li> <li> <p>\"A way to practice keeping a clean slate is to avoid looking at the work too often. If you finish a section or come to a sticking point, consider putting the project away and not engaging with it for a period of time. Let it sit for a minute, a week, or longer, while you go get lost.\"</p> </li> <li> <p>\"The context changes the content.\"</p> </li> <li> <p>\"The social norms of any time and place are another contextual box that art lives in.\"</p> </li> <li> <p>\"When a piece isn't living up to your expectations, consider changing the context. Look past the principle element, examine the variables around it. Play with different combinations. Place it next to other works. Surprise yourself.\"</p> </li> <li> <p>\"If the work is thrilling one day and isn't for a long while after, you may have experienced a false indicator. When the moments of joy seem like a distant memory and the work feels like an obligation to a past idea, this could mean you've either gone too far or that particular seed wasn't actually ready to germinate yet.\"</p> </li> <li> <p>\"Every artist creates a dynamic history. A living museum of finished objects. One work after another. Begun, completed, released. Begun, completed, released. Over and over again. Each a time stamp commemorating a moment of passage. A moment filled with energy, now forever embodied in a work of art.\"</p> </li> <li> <p>\"Within every artist, there's a child emptying a box of crayons onto the floor, searching for just the right color to draw the sky.\"</p> </li> <li> <p>\"If you're looking for the work to support you, you may be asking too much of it. We create in service to art, not for what we can get from art.\"</p> </li> <li> <p>\"Creativity is contagious.\"</p> </li> <li> <p>\"If asked to participate in a fellow creator's project, proceed delicately.\"</p> </li> <li> <p>\"Sometimes the most valuable touch a collaborator can have is no touch at all.\"</p> </li> <li> <p>\"Believing an idea is best because it's ours is an error of inexperience. The ego demands personal authorship, inflating itself at the expense of the art. It can reject new methods that appear counterintuitive and protect familiar ones.\"</p> </li> <li> <p>\"Great decisions aren't made in a spirit of sacrifice. They're made by the mutual recognition of the best solution available.\"</p> </li> <li> <p>\"The more clinical the feedback, the better it will be received.\"</p> </li> <li> <p>\"Our ego can perceive assistance as interference.\"</p> </li> <li> <p>\"It helps to keep in mind that language is an imperfect means of communication.\"</p> </li> <li> <p>\"We like to think of ourselves as consistent, rational beings, possessing certain attributes and not others. Yet a person who is completely consistent, who possesses no contradictions, comes across as less real. Wooden. Plastic.\"</p> </li> <li> <p>\"Art goes deeper than thought. Deeper than the stories about yourself. It breaks through inner walls and accesses what's behind. If we get out of the way and let the art do its work, it may yield the sincerity we seek. And sincerity may look nothing like we expected.\"</p> </li> <li> <p>\"The editor's role is to gather and sift. Amplifying what's vital and whittling away the excess. Culling the work down to the best version of itself.\"</p> </li> <li> <p>\"The editor is required to set ego aside. Ego pridefully attaches to individual elements of a work. The editor's role is to remain unattached and see beyond these passions to find unity and balance. Talented artists who are unskilled editors can\"</p> </li> <li> <p>\"The editor is required to set ego aside. Ego pridefully attaches to individual elements of a work. The editor's role is to remain unattached and see beyond these passions to find unity and balance. Talented artists who are unskilled editors can do subpar work and fail to live up to their gift's promise.\"</p> </li> <li> <p>\"As we move closer to the completion of a project, it can be helpful to drastically cut the work back to only what's necessary, to conduct a ruthless edit.\"</p> </li> <li> <p>\"Making the simple complicated is commonplace,\" Charles Mingus once said. \"Making the complicated simple, awesomely simple, that's creativity.\"</p> </li> <li> <p>\"Art is a reverberation of an impermanent life.\"</p> </li> <li> <p>\"Just as each small stroke on a canvas can't step aside to see the whole painting, we're unable to take in the great whole of relationships and counterbalance that surrounds us in all directions.\"</p> </li> <li> <p>\"The magic is not in the analyzing or the understanding. The magic lives in the wonder of what we do not know.\"</p> </li> <li> <p>\"The widespread use of chopsticks shaped the development of Chinese cuisine\u2014the reason there's so much preparatory chopping involved in making a Chinese meal is because dishes had to consist of bite-size pieces that could easily be grasped with chopsticks, since  nothing was sliced at the table.\"</p> </li> <li> <p>\"As she fingered the pamphlets, I realized it was new to her, this idea of vegetarianism not as a mark of poverty but a conscious lifestyle choice, and coming from my place of privilege, I hadn't understood her wariness about it.\"</p> </li> <li> <p>\"The golden rule of beauraucracy, give me a problem, and Im willing to spend any amount of someone elses money to solve it\"</p> </li> <li> <p>\"the less money the higher the expectations\"</p> </li> <li> <p>\"Life feels more romantic when life is a performance when youre mimicking what that romantic scene is in the film that you saw.\"</p> </li> <li> <p>\"It's harder to see than to paint.\"</p> </li> <li> <p>\"When you're a people-pleaser, you unconsciously wear a facade of niceness that hides your true feelings from your family, colleagues, friends, lovers \u2014 essentially giving up your needs for the sake of everyone else's. For years I thought that niceness was one of my best, most pure qualities. Only recently have I realized that this was how I tried to protect myself and, in fact, was an attempt to control what other people thought of me.\"</p> </li> <li> <p>\"People-pleasing had so fundamentally shaped my relationship to myself and was a deep layer that had kept me from living authentically for the vast majority of my life. I'd been playing a role instead of being a person.\"</p> </li> <li> <p>\"Do you dedicate more time to other people than yourself? Have you neglected self-care, because you're just too busy taking care of others? If the answer is yes, then it's time to re-evaluate your priorities.\"</p> </li> <li> <p>\"The more action you take, the more you want to take action\"</p> </li> <li> <p>\"When you add value to people's lives, they are eager to share your story with everyone\"</p> </li> <li> <p>\"It seems evident that very few people can simply sit still. Children spin in circles until they collapse with dizziness.\"</p> </li> <li> <p>\"Pretend its like eating the last candy you will ever eat in your life\"</p> </li> <li> <p>\"ather than just accepting, what I learned is that you have to also appreciate what's right in front of you including the simple things. It's the small details that actually matter.\"</p> </li> <li> <p>\"Creative people do not have the gift of novelty, they have the gift of being able to turn large amounts of chaotic information into order\"</p> </li> <li> <p>\"Growing up we learn feeling words from adults who simultaneously shame us for using them.\"</p> </li> <li> <p>\"Young man, don't be too rampant. The road of life is still very long\"</p> </li> <li> <p>\"Some would say. \"All problems that could be solved with money are not problems.\" Clearly those who say that are all rich people.\"</p> </li> <li> <p>\"The greatness of any artform cannot be in the technique, as important as technique is. Nobody loves a song because the singer hit all the notes correctly. They love it because the melodies and rhythms and interactions of the instruments give them a feeling. It's the same with imagery. Good composers know how to create an image that haunts, or entertains, or somehow emotionally involves a viewer, and that happens on a primal level through compositional choices. And even though I believe it is a talent, it is realized through practice and training. As with music. Musicians and artists both compose. The good ones move our emotions\"</p> </li> <li> <p>\"A wound can only begin healing when it's noticed and attended to.\"</p> </li> <li> <p>\"History only seems simple, unified and natural when we forget about all the voices that go unheard.\"</p> </li> <li> <p>\"People are strange when you're a stranger Faces look ugly when you're alone Women seem wicked when you're unwanted Streets are uneven when you're down When you're strange faces come out of the rain When you're strange no one remembers your name\"</p> </li> <li> <p>\"Kant saw humanity as a race mature enough to leave home but not mature enough to know how to live well alone\"</p> </li> <li> <p>\"The world is but a stage. Why cry, when you can laugh instead? For laughter is humanity's preserve. Laugh it all off, fret not, Let's just enjoy the moment.\"</p> </li> <li> <p>\"Dread is anxiety on steroids,\"</p> </li> <li> <p>\"For us vertebrates, the core of the stress-response is built around the fact that your muscles are going to work like crazy.\"</p> </li> <li> <p>\"The stress response cycle needs to complete, and just eliminating the stressor isn't enough to do that.\"</p> </li> <li> <p>\"This is the upside-down world we live in: in most situations in the modern, post-industrial West, the stress itself will kill you faster than the stressor will\u2014unless you do something to complete the stress response cycle.\"</p> </li> <li> <p>\"Just don't forget that these survival strategies do not deal with the stress itself. They postpone your body's need to complete the cycle; they don't replace it.\"</p> </li> <li> <p>\"If anxiety starts, it ends.\" \"It just ends?\" \"Yeah. If you let it, it just ends.\"</p> </li> <li> <p>\"Wellness is not a state of being, but a state of action.\"</p> </li> <li> <p>\"When something feels uncomfortable, you're probably doing something that creates more and better progress than if it were easy.\"</p> </li> <li> <p>\"Or, as Douglas Adams's character Dirk Gently puts it, \"I rarely end up where I was intending to go, but often I end up somewhere that I needed to be\"</p> </li> <li> <p>\"Part of recovering from a loss is turning toward your grief with kindness and compassion, as well as completing the cycle of stress brought on by failure. But another part is recognizing failing's unintended positive outcomes.\"</p> </li> <li> <p>\"Heck no. Sometimes you need to close the door on the world and allow yourself to feel comfortable and safe\u2014as long as it's not the only thing you're doing. Think of it as a short-term survival strategy. You also need a plan and a sense of what value there is in the struggle.\"</p> </li> <li> <p>\"When you paint the dingiest wall in a room, it just makes the other walls look dingier.\"</p> </li> <li> <p>\"It's normal for change to be difficult. Sometimes it gets worse before it gets better. Sometimes a solution to one problem creates another. Sometimes there's not enough organization and positive attitude in the world to save a marriage. Sometimes\u2014as Julie would eventually find\u2014what it takes to save a marriage is saving yourself.\"</p> </li> <li> <p>\"We have been taught that letting go of a goal is the same as failing. We share stories of people overcoming the odds to achieve remarkable things in the face of great resistance, which is inspiring. But these stories too often imply that we are the controllers of our destinies\u2014as if we control the amount of nuts and seeds in a particular patch of forest. If we \"fail\" to achieve a goal, it's because there is something wrong with us. We didn't fight hard enough. We didn't \"believe.\"</p> </li> <li> <p>\"But there is a deep, wide chasm between us and the realization of those possibilities. Our default action in the face of that chasm is to do whatever it takes to get to the other side, and keep on doing it, no matter what, until we get there. But then we get exhausted and we wonder if we can accomplish any of the things we hope for, without destroying ourselves in the process.\"</p> </li> <li> <p>\"That freedom comes when we have abundance enough and safety enough to let go of what is broken and reach for something new.\"</p> </li> <li> <p>\"You can chart the progress of women in America by the things Disney heroines sing about in their \"I Want\" songs.\"</p> </li> <li> <p>\"Meaning is the feeling that you \"matter in some larger sense. Lives may be experienced as meaningful when they are felt to have significance beyond the trivial or momentary, to have purpose, or to have a coherence that transcends chaos.\"</p> </li> <li> <p>\"But rarely is meaning something that we find at the end of a long, hard journey. For most of us, meaning is what sustains us on the long, hard journey, no matter what we find at the end. Meaning is not found; it is made.\"</p> </li> <li> <p>\"When an airplane bounces into a sudden pocket of turbulence, you grab the arms of your seat, as if by holding your seat, you can hold the plane steady. You, of course, know it doesn't work that way, but your hands don't. They will hold on to anything they can reach, and the very fact of holding on makes the turbulence more tolerable.\"</p> </li> <li> <p>\"We are not our own worst enemy. Nor is the enemy the other people in the game. The enemy is the game itself, which tries to convince us that it's not the enemy.\"</p> </li> <li> <p>\"Self-care\" is, indeed, selfish because it uses personal resources to promote a giver's well-being, rather than someone else's.\"</p> </li> <li> <p>\"In so many ways, most of us tend to ignore or forget about advantages we've received, but remember the obstacles we've overcome, because the struggle against the obstacles requires more effort and energy than the easy parts.\"</p> </li> <li> <p>\"Just because the road looks flat doesn't mean it is. Just because you can't see the ocean doesn't mean it's not there. You can infer the landscape by looking at the shapes of the people who grew in those environments. Instead of wondering why they aren't thriving on the level playing field, imagine how the field can be changed to allow everyone to thrive.\"</p> </li> <li> <p>\"The truth will set you free, but first it will piss you off.\"</p> </li> <li> <p>\"All your body requires of you is that you turn toward it with kindness and compassion, with nonjudgment and plain-vanilla acceptance of all your contradictory emotions, beliefs, and longings.\"</p> </li> <li> <p>\"Everyone is the new hotness. You are the new hotness. So is she. So are they. So are we.\"</p> </li> <li> <p>\"Many of us have grown into world-class ignorers of our own needs, just as we were taught to be. We don't even notice that we're ignoring our needs. Our bodies are sending us all kinds of signals, but we live from the neck up, only attending to the noise in our heads and shutting out the noise coming from the other 95 percent of our internal experience.\"</p> </li> <li> <p>\"Contact with another person is a basic biological need; loneliness is a form of starvation.\"</p> </li> <li> <p>\"We're made of energy. The nature of energy is to be shared, to spread, to connect one thing to another. Sharing space with other people means that our energy influences theirs, and theirs influences ours. It's physics. And psychology. And unavoidable. And amazing.\"</p> </li> <li> <p>\"people tend to take better care of themselves when they're in a high-quality relationship. In other words, our \"self-care\" is facilitated by the ways we care for and are cared for by someone else.\"</p> </li> <li> <p>\"Rage gives you strength and energy and the urge to fight, and sharing that energy in the Bubble changes it from something potentially dangerous to something safe and potentially transformative.\"</p> </li> <li> <p>\"The pleasure of synchronized movement is built into our biology, and it's a powerful tool to access your greatest well-being.\"</p> </li> <li> <p>\"When it's inconvenient, it's probably doing the most for you.\"</p> </li> <li> <p>\"What makes you stronger is whatever happens to you after you survive the thing that didn't kill you. What makes you stronger is rest.\"</p> </li> <li> <p>\"You don't have to set yourself on fire to keep other people warm.\"</p> </li> <li> <p>\"Caring for myself is not self-indulgence, it is self-preservation, and that is an act of political warfare.\"</p> </li> <li> <p>\"Mental rest is not idleness; it is the time necessary for your brain to process the world.\"</p> </li> <li> <p>\"Boredom is the discomfort you experience when your brain is in active-attention mode, but can't latch on to anything to attend\"</p> </li> <li> <p>\"Everybody knows a muscle that isn't used will atrophy. We all know a muscle that is worked constantly, without rest, will grow fatigued and eventually fail in exhaustion. And we all know a muscle that gets worked and rested and worked and rested will grow stronger.\"</p> </li> <li> <p>\"Our whole body, including our brain, is working hard as we sleep, to accomplish life-preserving tasks that can be best achieved when we're not around to interfere.\"</p> </li> <li> <p>\"If you've dealt with the stressors but haven't dealt with the stress itself, your brain won't let you rest. It will constantly scan for the lion that's about to\"</p> </li> <li> <p>\"If you've dealt with the stressors but haven't dealt with the stress itself, your brain won't let you rest. It will constantly scan for the lion that's about to come after you, so when you try to go to sleep, your brain won't let you fall asleep, or it will wake you up over and over, checking for that lion. Complete the cycle, so your brain can transition into rest.\"</p> </li> <li> <p>\"I don't want a doctor who's been awake for twenty hours; I don't want a lawyer who bills more than twelve hours a day\u2014I know how sloppy work gets when somebody is fatigued\u2014and you shouldn't want an engineer who isn't sleeping seven hours a night. Your work is crap if your brain isn't rested.\"</p> </li> <li> <p>\"Hi, rage. I know our family raised us to believe we didn't matter unless we were perfect, and perfect means we never stop working, and it's right to be angry that we didn't get the warm, unconditional acceptance every child is born deserving. Let's treat ourselves as we wanted to be treated, granting ourselves permission to be human.\"</p> </li> <li> <p>\"Mine is more like a teenage version: the smart, quiet, yet sad and downtrodden girl who always sat in the back of class and no one talked to\u2026.When something goes wrong, I can hear her 'told you so' voice in the back of my mind.\"</p> </li> <li> <p>\"This uncomfortable, fragile part of ourselves serves a very important function. She grew inside us, to manage the chasm between who we are and who Human Giver Syndrome expects us to be. She is the part of us that has the impossible, tormenting task of bridging the unbridgeable chasm between us and this \"expected-us.\" It's a form of torture, like Sisyphus rolling a rock up a hill only to have it roll back down each time. She's forever oscillating from rage to helpless despair.\"</p> </li> <li> <p>\"Listen to her stories\u2014never forgetting she's a madwoman. Remind her that you are the grown-up, the homeowner, or the teacher, and she can trust you to maintain the attic so that she always has a safe place to stay. Thank her for the hard work she has done to help you survive.\"</p> </li> <li> <p>\"Guilt is, 'I made a mistake.' Shame is, 'I am a mistake.'\u2009\" With guilt, as opposed to shame, there is at least a pretense that one day you might deserve to participate fully in the human experience. With shame, your core self is judged.\"</p> </li> <li> <p>\"Are we really working toward our goals only because we'll torture ourselves if we stop, so that as soon as we put down the whip we'll sink into eternal apathy? Of course not. In fact, it's the opposite: We only whip ourselves because our goals matter so much that we're willing to suffer this self-inflicted pain if that's what it takes. And we believe that because we've always done it that way, it must be why we've accomplished as much as we have.\"</p> </li> <li> <p>\"When people with depression try to be self-reassuring, their brains respond with threat activation.12 In fact, fear of compassion for self is linked to fear of compassion from others. That means that somewhere inside them, they believe that if they're isolated, that's good; isolation protects others from their real, core badness.\"</p> </li> <li> <p>\"And she realized \"Perfect Julie\" was just a defense she had constructed, to protect her real madwoman\u2014who wasn't a woman at all, but a little girl. This little girl was sensitive and afraid of rejection. She loved books and theater. She put on \"Perfect Julie\" the way a little girl might put on her mother's shoes and lipstick, playing pretend. She wore \"adulting\" as a costume. It had been a game at first, like playing house, back when she was Diana's age. But as Julie had gotten older, the Perfect Julie costume became necessary to disguise the fact that she was, underneath it all, just a girl who didn't want to make anyone mad.\"</p> </li> <li> <p>\"Beating ourselves up results in pain, obviously, so at the same time that we're beating ourselves up, we're looking for ways to manage that pain, to make it bearable.\"</p> </li> <li> <p>\"Whichever metaphor you prefer, self-compassion isn't always a comfortable or peaceful experience, but it does help us grow mightier.\"</p> </li> <li> <p>\"lot of us have a quiet little voice worrying that we'll get up in that corporate office and have no idea what we're actually doing. As a person with a hobby, you're not ready for all of that now, and it's difficult to imagine what it will feel like and how ready you could be after you go through the process of growing. The difficulty of imagining ourselves with the knowledge, expertise, and strengths we will gain in the future can stop us entirely from moving toward that future.\"</p> </li> <li> <p>\"It's really strange when we're doing our best, and our best falls short of what the world expects from us. When we can turn toward that strangeness with observational distance, then we are best enabled to be the change we want to see in the world.\"</p> </li> <li> <p>\"Being grateful for good things doesn't erase the difficult things\"</p> </li> <li> <p>\"The cure for burnout is not \"self-care\"; it is all of us caring for one another. So we'll say it one more time: Trust your body. Be kind to yourself. You are enough, just as you are right now. Your joy matters. Please tell everyone you know.\"</p> </li> <li> <p>\"Humans are not built to do big things alone; we are built to do them together.\"</p> </li> <li> <p>\"even if I felt like a social pariah in my classes, at least I would have a better vocabulary than these philistines\"</p> </li> <li> <p>\"I realized that there was some prestige in being smart, or at least appearing smart. Sounding smart was not the same social Teflon as being good-looking or athletic or funny, but hell, if someone could give me some props for being good at school, I would take nerd props over no props at all.\"</p> </li> <li> <p>\"They belonged in a way that I never could, and their regard for me was sweet and sour. How Asian.\"</p> </li> <li> <p>\"But in the course of reading great books, something happened. My reading molded me, the tool hammering its hand into shape. By some miracle\u2014and by miracle, I mean great teachers\u2014I pushed past the shallowness and stupidity of my own motivations. I fell in love with the actual literature and the actual ideas of great literature.\"</p> </li> <li> <p>\"The medium has no depth, but the content does.\"</p> </li> <li> <p>\"If you catch me in my off-guard moments, I'll tell you that at some points in my life, I wanted to be white. It's not a proud feeling, but it's not a feeling that comes from the shame of being brown. It's a tired feeling. Tired of the crushing racism. Tired of not belonging. It's the exhaustion from fighting for your right to exist.\"</p> </li> <li> <p>\"Faith. Knowledge. Doubt. They weaved in and out of our lives with a baroque intricacy, a background fugue to our stumblings on the stage.\"</p> </li> <li> <p>\"What do you have control over? And what is beyond your control? As Camus's protagonist, Dr. Rieux offers an answer: when the world is coming apart, you do your job.\"</p> </li> <li> <p>\"That was the delusion. We weren't like everybody else. I now had the menace of knowing, and it infected everything I did. I was reminded of it constantly in ways large and small: my parents' wobbly accents as my English became arrow-straight, the long and confusing searches in the grocery stores for simple items, the stares from strangers at the mall. These reminders that my family was not a normal American family\u2014that we didn't look like the rest of our town, that we were from somewhere else\u2014wove into my very fabric a need to belong, a need that was a glittering and slippery yarn. I would never be able to untangle it from who I was and who I wanted to be, and it seemed that if I tugged on this thread, everything would unravel and leave me exposed.\"</p> </li> <li> <p>\"B\u00e0 Ngo\u1ea1i's ire wasn't the anger of personal damages but the anger of being shamed, a singular dishonor that she and my parents bore heavily. If our elders felt that we kids had done something to embarrass them or to cause them to lose face, our punishment was administered as if the entire town were watching and judging them as parents. Puritanical in its purity and unflinching in its deliverance. The severity of our punishment was commensurate to their own perception of their parenting.\"</p> </li> <li> <p>\"B\u00e0 Ngo\u1ea1i, my grandmother. Gentle one moment, violent in the next. Violence was sometimes kindness. Sometimes it was love. Sometimes it was rage. But it was everywhere, always.\"</p> </li> <li> <p>\"But if I allowed myself to be harmed by words, I was showing them that I belonged at least by virtue of understanding their language. And all I wanted was to belong.\"</p> </li> <li> <p>\"Kids covet things. They see something that other kids have, and they want that thing. They see a cool T-shirt with Darth Vader on it, and they want that shirt, too. Soon they want the house, the hair, the skin color.\"</p> </li> <li> <p>\"As an adult, I can explain and even understand where his anger came from (PTSD as a refugee, his own abuse as a child, the cycle of abuse that can perpetuate itself in a culture that equated obedient children with great parenting). As a second grader, I knew this violence as my only reality. If I spilled something, disobeyed, did something too quickly or too slowly.\"</p> </li> <li> <p>\"The wish for different parents fuels the archetypal fairy tales about evil stepmothers and children left in the woods. These fairy tales pivot around the wish that our parents, irascible and imperfect, aren't even our real parents, that a fairy godmother will reveal to us our true royal bloodline or magical lineage. Whether you're Harry Potter or Luke Skywalker or Cinderella, the fantasy is that the adults who are raising you aren't even your real parents, that your real parents are kinder and magical.\"</p> </li> <li> <p>\"My past was worse than my present, and if my present indicated my future, I could live with that.\"</p> </li> <li> <p>\"As an adult, I've been able to understand that my father was not as trapped by his past as I thought he was. He was often violent and angry, but now I can look back and see that he tried to do fun things from time to time, things that didn't fit into the narrow, cartoonish image that I formed of him.\"</p> </li> <li> <p>\"But even if the past is unchangeable, maybe our perspective of the past can change. And maybe the way we see past events can change, and if that can change, maybe the past event itself does change\u2014not in action or outcome but in purpose and intent.\"</p> </li> <li> <p>\"How could I explain to Lou that we were symbols? That some people would never be able to see us as just people? That we were symbols of a painful and confusing war? Symbols of the refugees they saw on TV? Symbols of what they were afraid of? Symbols of the people who had shot at them and killed their friends, brothers, and sons? Symbols of whatever they wanted to see?\"</p> </li> <li> <p>\"I did learn a lesson that night. In the void of their departure, I learned to appear greater than I was. My brother needed me to be more than his nine-year-old brother. I learned that even if I didn't have a clue about driving or having a job or being a parent, the symbolism of being a parent\u2014the basic act of making toast and washing plates\u2014was enough for Lou. That was the power of the symbol.\"</p> </li> <li> <p>\"Kids don't have a euphemistic or subtle way of speaking about life.\"</p> </li> <li> <p>\"Symbolism in our waking Jungian dream was a two-way mirror. We were symbols for our American neighbors, but our neighbors\u2014with their polished cars, grand homes, backyard swing sets\u2014they symbolized something for us, too. They glittered as goals, mirages toward which we endlessly stumbled.\"</p> </li> <li> <p>\"Did I think that I could upend their expectations without any resistance? Of course, I was technically the same kid, but I had gotten the message: I couldn't try too hard to change or fit in, especially if it involved something as dramatic as changing my name. That was too much. Too symbolic. Too real.\"</p> </li> <li> <p>\"Jung says that the process of becoming an individual begins with a wounding of the ego, and mine was undeniably wounded.\"</p> </li> <li> <p>\"But if literature moves you deeply, does it matter where it comes from? Does it matter that it's trashy or lowbrow? Isn't that emotional connection one of the purposes of art? To make you feel\u2014really feel\u2014emotions? To resonate with your life? And perhaps, in that connection, to introduce you to a world that lies beyond your own perspective, the utopia beyond your myopia?\"</p> </li> <li> <p>\"Emma Bovary's books made her yearn for a dreamworld of emotional dramas and searing affairs. They seeded a delusion in her that grew quickly and blinded her, choking out the light except for the glow of fictitious hope. She was not ready for the quiet boredom of a married woman's life, and the yearning that flourished inside her made her own life repulsive to her. Could art do that? Could it make you long and loathe at the same time?\"</p> </li> <li> <p>\"It would be decades before I diagnosed the lump of alienation, dual consciousness, and self-hatred, but it was already growing quickly, bilious and caustic. I only saw myself as the piece that did not fit in the puzzle.\"</p> </li> <li> <p>\"Our imaginations, our self-reflection, were circumscribed by what we saw, limited and funneled into someone else's view of who we were. We saw ourselves as others saw us, and when we were in the media (which was not frequent), our stereotypes were reinforced in the books we read, the movies we saw, the things our friends said to us.\"</p> </li> <li> <p>\"With my mother, I lacked the words to tell her what I needed. With my father, I lacked the trust to tell him, the trust that he wouldn't respond with violence or disappointment, the trust that he could give me heartfelt advice, that he could see the olive branch I was extending to him if I shared an intimate and personal experience with him. I didn't believe that he would be anyone different from who he had been (no matter how much I wanted or needed him to be different).\"</p> </li> <li> <p>\"In Vietnamese, the word for country and the word for water are the same: n\u01b0\u1edbc. Context obviously makes it clear if you're talking about the former or the latter, but in Vietnamese, your country is not the terra firma or the nationality; it's the water. The waters that feed the soil. The waters that lap your shores. If you ask someone where they're from, you're asking them literally from what waters do they come.\"</p> </li> <li> <p>\"Old water. New water. Old country. New country. Aqua vitae. Giver of life. Destroyer of memories.\"</p> </li> <li> <p>\"My perceived need to read changed, slowly and surprisingly, into a desire to read\u2014a desire that I didn't fight.\"</p> </li> <li> <p>\"Their kindness was confusing for me, and it was easier for me to play the simple role of a teenager being angry with his parents. It was easier for me to fixate on the cool new stereo and not to think about why I got a cool new stereo from my parents. In the midst of my own changes, I wasn't able to change my perspective on my mom and dad, to consider that my parents might be changing. Maybe they wanted to change the story of parents being the antagonists in their children's lives. We didn't have the script for that scene. I missed the cues for the dialogue, and the curtain closed on another moment of disconnection.\"</p> </li> <li> <p>\"Hatred required calories that I didn't have.\"</p> </li> <li> <p>\"Punk rock had paved a way for me through my first two years of high school, but I was beginning to realize that maybe anarchy and nihilism were not a blueprint for building a future. Punk rock was an explosive for detonating the present so that I could rebuild my future from the rubble.\"</p> </li> <li> <p>\"It is a terrible thing for a man to find out suddenly that all his life he has been speaking nothing but the truth.\"</p> </li> <li> <p>\"This was the real lesson I learned from Malcolm X, the one I had been avoiding, and like Malcolm, I had to evolve my own thinking. But for me, that meant confronting a hideous truth about who the racists were. This was the hardest thing he had written about. It would be a long time before I could begin to understand how big racism was and how it affected me, but I had to take the first step, to acknowledge the reality of life, to tackle the hardest truth if I wanted to fight it. We all were the racists.\"</p> </li> <li> <p>\"In retrospect, I realized how my parents draped the hopes of college and greatness upon me, their eldest born. They snuffed out their own ambitions, exchanging their dreams for their children's, hoping that our lives would be full of possibilities and free from devastation. My vague but lustrous potential would be built upon the heavy shards of their broken futures.\"</p> </li> <li> <p>\"My aspirations for greatness were the antithesis of punk, and I knew it. And for the first time I realized that the most punk thing for me to do was to be who I was without pretention or preamble or grandiose posturing. I had read it in Nietzsche but didn't know what it really meant: become who you are. But becoming who you are required throwing away who you thought you were, unloading expectations both internal and external.\"</p> </li> <li> <p>\"I just never understood the logic behind buying souvenirs. After all, it's the memory we want, not the souvenir, and once the memory goes, what meaning does the souvenir have? That's like keeping training wheels on your bicycle. I think most of us spend far too much time looking back at our past anyway and not worrying enough about the future without an attic full of old prom dresses, dried corsages, books, toys you don't play with anymore and photo albums of pictures we had thought were long gone.\"</p> </li> <li> <p>\"I don't need souvenirs, and I don't want souvenirs. None of you need souvenirs either. As long as you laugh, won't you carry all the good times with you? And as long as you cry, won't you carry all the bad times with you? So wherever we all end up and wherever we are all going, I know we don't need souvenirs because laughter will always be laughter, and tears will always be tears.\"</p> </li> <li> <p>\"Oh, I don't know about that. It was okay. I messed it up a little from my nerves, I guess. I feel\u00a0\u2026 I feel weirdly let down. So much hype around everything, you know?\" I reflexively shrugged at Molly's compliment, deflecting praise as I always did because I was so unaccustomed to hearing earnest accolades. Any kind remark made me feel vulnerable, forced me to confront myself and my purported excellence, a task that felt impossible and undeserved.\"</p> </li> <li> <p>\"Teenagers and truck drivers: We're all on our way to somewhere else. We're all sitting at these booths, knowing that we're not at our final destination. This is not the last stop for any of us. We're all en route to far-off places, but our arrival? Who knows? Our arrival will be dictated by things we both can and can't control, unforeseen things. I'm going to college to study English and art, but who knows if that'll happen? Conor's joined the army, but what if he gets killed in Iraq? What about you or my brother? What's next? And we might get to our destination directly, but maybe it'll be in a roundabout, crazy way.\"</p> </li> <li> <p>\"In a world that often seems too crowded or busy to notice beautiful things or make meaningful connections, there is still room for each of us to grow in the ways we were meant to.\"</p> </li> <li> <p>\"Whenever you meditate, bear in mind the phrase \"without distraction and without grasping,\" and put this into practice.\"</p> </li> <li> <p>\"If you fill a gourd with just a little water and shake it, it makes a lot of noise. But if you fill it to the brim and shake it, it makes no sound.\"</p> </li> <li> <p>\"Let your mind be a gracious host in the midst of unruly guests.\"</p> </li> <li> <p>\"Like Einstein's theory that physical space is warped by bodies of matter within it, it sometimes feels as if the space of awareness is warped by the contents of the mind.\"</p> </li> <li> <p>\"At times, when we become fixated on something, our minds seem to become very small. Trivial issues loom up in our awareness as if they were very large and important. In reality, they haven't become large. Our minds have become small. The experienced magnitude of the contents of the mind is relative to the spaciousness of the mind.\"</p> </li> <li> <p>\"Let the space of your mind be emotionally neutral, like physical space, which could not care less whether bullets or hummingbirds streak through it.\"</p> </li> <li> <p>\"What we observe is not nature in itself but nature exposed to our method of questioning.\"</p> </li> <li> <p>\"As an analogy, consider a researcher who measured only the vibrations created by the musical instruments as an orchestra played Beethoven's Pastoral Symphony. He would find that before anyone heard any music, the instruments vibrated in specific ways, so he might very well conclude that those vibrations are the sole cause of the symphony. What he will have left out is the role of the composer, the conductor, the skills and emotional states of the musicians, the audience, and so on. While he's right that the vibrations of the instruments played a critical role in producing the music, his eliminative approach has blinded him to a myriad of other influences, and he will be oblivious of the fact that many people can compose and play tunes in their minds, with no vibrating musical instruments exerting any causal role.\"</p> </li> <li> <p>\"All phenomena are preceded by the mind. When the mind is comprehended, all phenomena are comprehended. By bringing the mind under control, all things are brought under control.\"</p> </li> <li> <p>\"'The mind that is established in equipoise comes to know reality as it is.'\"</p> </li> <li> <p>\"One of the ways of stopping science would be only to do experiments in the region where you know the law. But experimenters search most diligently, and with the greatest effort, in exactly those places where it seems most likely that we can prove our theories wrong. In other words, we are trying to prove ourselves wrong as quickly as possible, because only in that way can we find progress.\"</p> </li> <li> <p>\"a person whose mind is distracted lives between the fangs of mental afflictions.\"</p> </li> <li> <p>\"The success of the McDonald's model suggests that many people have come to prefer a world in which there are few surprises.\"</p> </li> <li> <p>\"'If you want to be happy, you mustn't fear the following truths but confront them head-on: one, that we are always unhappy, and that our sadness, suffering and fear have good reasons for existing. Two, that there is no real way to separate these feelings completely from ourselves.'\"</p> </li> <li> <p>\"I've always thought that art is about moving hearts and minds. Art has given me faith: faith that today may not have been perfect but was still a pretty good day, or faith that even after a long day of being depressed, I can still burst into laughter over something very small.\"</p> </li> <li> <p>\"I've also realised that revealing my darkness is just as natural a thing to do as revealing my light.\"</p> </li> <li> <p>\"I was very serious about friendships when I was little, like most children. But after being bullied in elementary school and middle school, I think by the time I reached high school I'd developed a fear of straying from the herd, and was nervous about friendships in general. That fear was reflected in my romantic relationships, and I decided not to expect too much from friends or friendships anymore. Psychiatrist: I see. Do you find your\"</p> </li> <li> <p>\"Perhaps you're co-dependent on your work as well. When you get good results, your worth is realised and you relax, but that satisfaction doesn't last long \u2013 that's the problem. It's like you're running inside a hamster wheel.\"</p> </li> <li> <p>\"Sometimes the best thing to do with people who would never listen to you in the first place is to avoid them altogether.\"</p> </li> <li> <p>\"If it doesn't make you feel good, don't go out of your way to do it.\"</p> </li> <li> <p>\"I'd like you not to give too much credit to what people say about you. The moment you set out to be more empathic is the moment it becomes a chore. That would result in your empathy decreasing, if anything. It's good not to fake interest in things you're not interested in.\"</p> </li> <li> <p>\"Because there's really no end to worrying once you set your mind to it. If you shift your perspective from their past to your present, you can start perceiving your personal experiences in a more positive manner. From 'How sad they didn't realise this' to 'How lucky it is that I realise this.'\"</p> </li> <li> <p>\"It's like with your guilt. You want to strangle someone, and then you automatically feel guilty about having had that thought. Your own anger turns you into a guilty person. There's a desire to punish yourself, shall we say. You have this superego that exerts control over you, a superego built not only from your own experiences but cobbled together from all sorts of things that you admire, creating an idealised version of yourself. But that idealised version of yourself is, in the end, only an ideal. It's not who you actually are. You keep failing to meet that ideal in the real world, and then you punish yourself. If you have a strict superego, the act of being punished eventually becomes gratifying. For example, if you're suspicious of the love you're receiving, and so act out until your partner lashes out and leaves you, you feel relief. You eventually become controlled more by imaginary outside forces than anything that is actually you.\"</p> </li> <li> <p>\"when your life satisfaction falls, it's natural to retreat into primitive measures. And eating and sleeping happen to be our most instinctive base measures.\"</p> </li> <li> <p>\"I'm needlessly harsh towards myself, so I need comforting, someone who is on my side.\"</p> </li> <li> <p>\"I'm very good at immersing myself emotionally, and I'm very empathic; I also feel pressured to be empathic, which means whenever someone would share an experience with me, I'd find myself lying and saying I'd been through the same thing. I would lie to make others laugh or to get attention, while simultaneously chastising myself for lying.\"</p> </li> <li> <p>\"We often lie when our cognitive abilities become impaired for whatever reason. Like when we're drunk, for instance. You know how our memory or judgement falters after a few drinks, right? We subconsciously start lying to fill in the blanks. How many times have you seen drunk people insist they're not drunk? We also find ourselves announcing things that have nothing to do with the context.\"</p> </li> <li> <p>\"Psychiatrist: Why are you so aware of all the hardships others are going through? Me: (Realisation hits.) You're right. Wouldn't it be more natural for me not to know? Psychiatrist: So, complain. Let others know how hard things are for you. Me: I wouldn't know what to say. Psychiatrist: Observe how other people are saying it. They're saying they're having a hard time \u2013 that's how you know, so clearly, that they are. But I think you're the kind of person who would ask someone who wasn't having a hard time if they were having a hard time. Me: (I burst into tears at this point.) You mean I was just pretending to be kind all this time? Psychiatrist: You are kind. There's nothing you can do about that. Me: But I don't think it's kindness, I think it's just . . . being pathetic. Psychiatrist: You're attempting to silence your own complaints by thinking, At least I'm better off than them. And the world is full of so much suffering that it's the easiest thing to find people who are having a harder time than you are. But once you do, you then insist on taking the extra step of berating yourself: How could I have been so blind to that person's hardships until now?\"</p> </li> <li> <p>\"Psychiatrist: I feel like you're not very interested in yourself. Me: Even when I keep a diary of my feelings? Psychiatrist: Is that not more of a record of yourself in the third person?\"</p> </li> <li> <p>\"When you're having a hard time, it's natural to feel like you're having the hardest time in the world. And it's not selfish to feel that way. Just because certain conditions in your life are relatively better, it doesn't mean you're better off in general\"</p> </li> <li> <p>\"It's not the pills that make people addicted to them.\"</p> </li> <li> <p>\"It's just your opinion. It's not like there's any right or wrong to it. Of course, others may have their own expectations, or you may feel pressured to sound impressive in your critiques because of your studies and your job. But the moment you think to yourself, Well, this is the way I am, and what can you do about it, you'll feel much freer. Me: Oh. Just the thought of\"</p> </li> <li> <p>\"Forgetfulness can be liberating, you know.\"</p> </li> <li> <p>\"You put a lot of stock in what other people think. It's because your satisfaction with yourself is so low. But your life is your life, your body is your body \u2013 and you have responsibility over it. Right now, you don't process the input that comes to you through a mechanism of rationality or mediation, you go straight to the extreme. Self-surveillance isn't necessarily a bad thing, but there is so much you can do with the input, such as rationalising or finding a different way to think about things \u2013 but you only do one thing with it. There can be so many reasons for something, but you're so focused on the result of it that you don't see the reasons. You keep focusing on, I'm sad, I want to cry, I'm angry, which only amplifies these emotions.\"</p> </li> <li> <p>\"I think you need to spatially separate your work and your rest. If you were stressed at work, you ought to be relaxing when you're home,\"</p> </li> <li> <p>\"Your mood is extremely important. It determines how you interpret the random events of life.\"</p> </li> <li> <p>\"It's just a hobby after all. You mustn't let your hobby become stressful. But I hope if you don't do it isn't out of fear.\"</p> </li> <li> <p>\"Usually before a dream becomes reality, we tend to think we'll wish for nothing else if only the dream is realised. Imagine how you'd feel if you always remembered that your dream has already been fulfilled. Everything that comes after would be like a lovely bonus. When you feel envious of something, try to imagine how you would look to your twenty-year-old self.\"</p> </li> <li> <p>\"But the you of the present is looking at your life and past as if you're a failure. When in truth, from the perspective of a younger you, you're the very picture of success.\"</p> </li> <li> <p>\"when my face looked like a bleak black-and-white film still in the mirror \u2013 could that girl have imagined she would become me one day?\"</p> </li> <li> <p>\"I've worked hard to get here. And now I make a living doing what I enjoy. I've no anxieties about whether this is the right path for me. All I want is to get better at it. That's enough for me \u2013 why did I torture myself by comparing myself to someone else? If twenty-year-old me met me today, she would cry with joy. And that's enough for me.\"</p> </li> <li> <p>\"more you sacrifice, the more you'll begin to expect a payback.\"</p> </li> <li> <p>\"You keep obsessively holding yourself to these idealised standards, forcing yourself to fit them. It's another way, among many, for you to keep punishing yourself.\"</p> </li> <li> <p>\"You try to hide your obsession because you are aware of it, I mean.\"</p> </li> <li> <p>\"Your self-esteem determines how you feel about the sincerity of others.\"</p> </li> <li> <p>\"You have sympathy for social minorities. Perhaps that comes from seeing yourself as disadvantaged?\"</p> </li> <li> <p>\"We are so bad at mourning in our society. Maybe it's a failure of respect.\"</p> </li> <li> <p>\"I think it's good to experience complete solitude in an unfamiliar environment. You're not hitting rock bottom right now. When we're sinking in water, it can be a relief to feel the ground beneath our feet, the rock bottom, because we know we can kick against it to rise again. But if you can't feel the ground in life, the fear can be overwhelming. So maybe it's good to find your rock bottom.\"</p> </li> <li> <p>\"Mother clearly hated how she had passed on this part of herself to us, which was why she was always angry at our faults.\"</p> </li> <li> <p>\"Accepting your burdens and putting them down isn't an occasional posture; it's something you need to practise for the rest of your life.\"</p> </li> <li> <p>\"Books never tire of me. And in time they present a solution, quietly waiting until I am fully healed.\"</p> </li> <li> <p>\"We always put modifiers in front of ourselves, and I'm no exception to that.\"</p> </li> <li> <p>\"to expect someone to always be a certain way or consistently do a certain thing can be a huge burden on them.\"</p> </li> <li> <p>\"When life becomes something one just lives through, when the demands of survival take up all of our time and effort, leaving no strength for any other demands, and when time rushes by drying up or rotting whatever we have had to neglect, expecting someone to carry on being the same is truly too much of a burden.\"</p> </li> <li> <p>\"There are days when I wish I were numb, when I'm desperate to feel nothing. I want to be simple and cold and totally without feeling. Empathy has a large presence in my life, and it can cast a very long shadow. I can be watching a television drama or a movie, listening to a song or looking at a photograph, listening to someone's story or writing my own, and my heart and mood will sink. Like a punctum they pierce me without context, a feeling I am very used to now and tired of.\"</p> </li> <li> <p>\"Life is as messy as a bag whose owner never cleans it out. You have no idea when you might reach in and pull out a piece of old trash, and you're afraid someone is going to look through your bag someday. Maybe your 'baggage' is like an old bag, too. You toss it around any which way, not caring how worn it gets or where it lands, and no one notices. You can't afford a new bag so you carefully and painstakingly hold it so the rough patches don't show.\"</p> </li> <li> <p>\"Changing your mindset takes some work, but the beauty is when you begin to understand there's a huge difference between being busy and being productive. This is something so many of us struggle with because we falsely believe that we need to be busy, that we are supposed to fill our days.\"</p> </li> <li> <p>\"Balance is just one of the stories we tell ourselves. We all have a library of folklore filled with stories about ourselves that we believe: we are supposed to be a certain way, have a certain job, or live a certain life.\"</p> </li> <li> <p>\"I quieted the stories in my head and reset my expectations to make them realistic for my life. I'm not going to say I've completely gotten rid of the guilt, but I feel so much better because I changed my way of thinking.\"</p> </li> <li> <p>\"Ask any kindergartner what they are good at, and you'll need to sit through a laundry list of topics: art, running, painting, climbing trees, eating potato chips\u2014seriously, five-year-olds think they are amazing at everything! But wait ten years and ask the very same child, and she'll think of almost nothing; at best you'll maybe hear one or two things she believes she excels in. What happens to us in this space of time? How do we lose our belief in ourselves? We've allowed the world to define us and reinforce these limiting beliefs, but it's time to break through.\"</p> </li> <li> <p>\"Sometimes we have to let go of our old stories.\"</p> </li> <li> <p>\"Because so many of us live in a state of either/or, we tend to push aside other things we really want to do. Far too many of us have pushed aside our aspirations because we believe we don't have time or don't have the right to pursue them.\"</p> </li> <li> <p>\"Too often we hand over the reins, allowing others to imprison us with their own agendas and urgent fires that need putting out. We think we don't have control over how our day runs, but we do. We've simply forgotten that we have the ability to choose to spend time on our own priorities.\"</p> </li> <li> <p>\"Have you ever experienced that feeling of having no control over your day? As if your world is so rigid and made up of so many rules you don't really get to choose the life you live? That, my friend, is learned helplessness.\"</p> </li> <li> <p>\"It's not reality2 that makes us feel stuck; it's the lens we use to view the world.\"</p> </li> <li> <p>\"We want to believe our kids need us, and sometimes in the busy rush of our everyday life, we forget they are capable of being more independent.\"</p> </li> <li> <p>\"We all have these invisible choices, don't we?\"</p> </li> <li> <p>\"Have you ever watched a squirrel aiming to get something she wants? Perched in a tree, tail twitching, she sees a bird feeder and is drawn to it. The homeowners, though, are smart, and they've added all kinds of obstacles to make it \"squirrel-proof.\" Does our squirrel take a look, decide she has no chance of getting to the seeds, and toss in the towel? Absolutely not. A squirrel will attack the problem from all angles, testing and pushing the boundaries of what she knows she can and cannot do, until she sits triumphantly atop that feeder with a belly full of birdseed.\"</p> </li> <li> <p>\"Finding choices isn't only possible, it's essential to thrive. You just have to start actively looking for them\u2014that's a choice in and of itself.\"</p> </li> <li> <p>\"It's possible for your future to look brighter, for you to focus on the things that are important to you. But to do that, your priorities have to take priority. It's possible to have a job that makes you happy and to spend time on the things you really want.\"</p> </li> <li> <p>\"Our North Star is a combination of our mission, vision statement, and core values. Each one answers the question of who you are at your heart. The mission statement tells us what we are doing now, the vision statement tells of where we want to be, and the core values tell us how these can be defined through our actions. Like pieces of a puzzle, they come together to create the completed picture of why we make the choices we do. They become the North Star we need to guide us and help us navigate through decisions.\"</p> </li> <li> <p>\"Human beings are works in progress2 that mistakenly think they are finished. The person you are right now is transient, as fleeting and as temporary as all the people you've ever been. The one constant in our lives is change.\"</p> </li> <li> <p>\"Your mission statement isn't about your job itself\u2014it's about what your job does and why you do it.\"</p> </li> <li> <p>\"Remembering that I'll be dead soon15 is the most important tool I've ever encountered to help me make the big choices in life.\" We don't have to wait until we receive bad news from the doctor or read our obituary in the paper. We can begin to make those big choices now, using our North Star to help guide us.\"</p> </li> <li> <p>\"Don't spend time beating on a wall, hoping to transform it into a door.\"</p> </li> <li> <p>\"For too long, I had no idea where to spend my time or how to spend my energy. I wasn't productive\u2014I was simply running around being busy, filling my days but not my soul.\"</p> </li> <li> <p>\"It seems like this abundance of information should make life easier, but when we are bombarded with so much of it, the paradox is that decision making becomes more difficult. This is when the feeling of overwhelm begins to settle in and we simply don't know where to start.\"</p> </li> <li> <p>\"We have to cut in order to really grow and flourish. I know this seems counterintuitive, but think of a garden: Do you plant the flowers one on top of another? Do you squeeze so many in that there is no room? Or do you allow each plant to have space\u2014space to receive the rain and the sun, space to spread their leaves and grow? That's what we need: space to allow ourselves to focus. The only way to have that space is to actively create it for ourselves. We need boundaries.\"</p> </li> <li> <p>\"Perfectionism is just fear in fancy shoes and a mink coat.\"</p> </li> <li> <p>\"Remember, efficiency is doing a lot of work; effectiveness is doing the important work. Quality wins every time. And yes, we want to use less energy and time, but not at the expense of quality. Sometimes we are so caught up in deadlines, we don't realize that the processes we believe make us faster are working against us.\"</p> </li> <li> <p>\"Writing on paper deepens the relationship between the information and your brain, and it creates the ability for you to see your bread crumbs to help uncover patterns. It allows you to see the bigger picture, which can sometimes feel abstract\u2014it helps you uncover what's important, which is where you really want to spend your time.\"</p> </li> <li> <p>\"No matter which bowl I choose, I will end up eating the amount of ice cream that fills it. My idea of how much ice cream I need expands to the size of the bowl I have. Time works in exactly the same way.\"</p> </li> <li> <p>\"We don't realize that without failure we wouldn't be as successful as we are. Our shortcomings and mistakes are all part of our path.\"</p> </li> <li> <p>\"Instead of saying, \"I don't have time,\" try saying, \"It's not a priority,\" and see how that feels.\"</p> </li> <li> <p>\"Overwhelm isn't having too much to do; it's not knowing where to start. Our long checklist doesn't show us where to start. Instead, it confuses us more, spinning us in circles as we feverishly scan our tasks, wondering how we will possibly get it all done. Yes, it makes us feel busy, but it doesn't make us productive\"</p> </li> <li> <p>\"You see, dopamine doesn't distinguish between important and unimportant; it just knows that crossing items off our lists feels good.\"</p> </li> <li> <p>\"if you prioritize the important tasks, you get to a place where you don't have any urgent tasks.\"</p> </li> <li> <p>\"Oftentimes we feel that something is important because we believe it's something we are supposed to do\u2014even if it's not something we really want. These tasks are so deeply entwined with our stories and our need for perfection that we don't even realize it. We feel tied to the obligation, and we lose sight of why we are even doing the task in the first place.\"</p> </li> <li> <p>\"Are we allowing our stories to dictate our days?\"</p> </li> <li> <p>\"A good plan includes the three Rs\u2014record, reward, and redirect.\"</p> </li> <li> <p>\"You see, traditions are systems\u2014they take the thinking out of tasks. Routines and rituals do that for us, too, but on a daily basis\u2014they help streamline our days and make it easier for us to enjoy each day.\"</p> </li> <li> <p>\"Decision fatigue loves laundry stress; they're best friends.\"</p> </li> <li> <p>\"How did the river go from intimidating to entertaining? All it took was structuring our run. We took some time to create a plan, and suddenly the crushing power of the river didn't seem so out of control. We owned the river that day, and it felt good.\"</p> </li> <li> <p>\"One of the biggest mistakes I see people make is planning out the entire week in one sitting,\"</p> </li> <li> <p>\"It's amazing the deep connections we can make when we strip away everything else.\"</p> </li> <li> <p>\"As long as you can start9, you are all right.\"</p> </li> <li> <p>\"important to count the marbles in our jars.\"</p> </li> <li> <p>\"The world will see you the way you see you, and treat you the way you treat yourself.\"</p> </li> <li> <p>\"We've all experienced that vague sense of dissatisfaction with our day. Time passes in a blur as we sit at our desks without really paying attention to the tasks or even the people around us. We punch the clock, getting work done, but when the day closes we feel like we accomplished nothing. This is why we feel unsatisfied when we lay our heads on our pillows, why we wonder where the day has gone.\"</p> </li> <li> <p>\"Harmony can be found in the 168 hours we have each week, but so many people choose to focus\u2014almost hawklike\u2014on just the 24 hours of each day. Twenty-four hours is such a tiny snapshot of the whole picture, literally one-seventh of our week. And yet each day is treated as if it stands alone, so there's a tendency to look at this tiny snapshot as our chance at achieving this mythical balance.\"</p> </li> <li> <p>\"Any given 24 hours might not be balanced, but the 168-hour week as a whole can be.\"</p> </li> <li> <p>\"We have a tendency to beat ourselves up and to notice only the things we didn't do well, when in reality we are doing much better than we think.\"</p> </li> <li> <p>\"It's all about effectiveness over efficiency.\"</p> </li> <li> <p>\"Sharks glide through the salty water at the top of the food chain, but they are burdened with the constant task of movement. For sharks to breathe, oxygen-rich water must continually flow over their gills. Their fins act like the wings of a fighter jet, giving them lift. If a shark stops moving, it will sink to the sandy bottom of the ocean floor and suffocate. Sharks are predators in constant motion, which has led scientists for years to wonder, If sharks can never stop moving, how do they sleep?\"</p> </li> <li> <p>\"We have the time, but the idea of intentionally creating space for this unstructured time feels uncomfortable. It feels silly because we are grown-ups and we don't think we need recess. But we do. Whitespace is essential for our own well-being.\"</p> </li> <li> <p>\"the beauty of acknowledging our stories is that we have the ability to rewrite our own endings.\"</p> </li> <li> <p>\"We are taught by society\u2014by our upbringing\u2014to be givers. We give, we give, we give, and we feel guilty taking.\"</p> </li> <li> <p>\"To bring out the best in others7, I first have to bring out the best in me. I cannot give what I do not have.\"</p> </li> <li> <p>\"We have a thousand words for busy13 but no single word for the true opposite\u2014at least not a positive one. There isn't an English word for slowing down and savoring time.\"</p> </li> <li> <p>\"We all want to be acknowledged. We falsely believe we have to be everywhere in order to be seen. I think we all worry about being forgotten. We all want to make our mark on this world.\"</p> </li> <li> <p>\"Committing to nothing means you're distracted by everything.\"</p> </li> <li> <p>\"Sometimes yes is the very best word.\"</p> </li> <li> <p>\"every time we say yes, we say no to something else.\"</p> </li> <li> <p>\"You may not control all the events that happen to you, but you can decide not to be reduced by them.\"</p> </li> <li> <p>\"Our brain can overlook countless items in our surroundings, but once our brain takes notice of something it considers significant (in my case, pregnant women), it starts to pull those occurrences out of the background noise. Because of our selective attention,1 it feels as if they are appearing again and again in our world. Really, the truth is, those things were there all along; we just didn't take notice. It's our mindset kicking in.\"</p> </li> <li> <p>\"While I love the crystal-clear waters of the beaches, it does limit me from seeing the mountains and rivers.\"</p> </li> <li> <p>\"If I spent all my time in the mountains,3 I would miss diving with sea turtles, but if I only swam the warm waters of the Caribbean, I'd never get to see the sun set on the mountains.\"</p> </li> <li> <p>\"The world has arrived at an age of cheap complex devices of great reliability; and something is bound to come of it. -VANNEVAR BUSH\"</p> </li> <li> <p>\"Very few tools transform their culture.\"</p> </li> <li> <p>\"Humans often anthropomorphize the objects they use, especially when they become fond of their interaction with those objects.\"</p> </li> <li> <p>\"As with most media from which things are built, whether the thing is a cathedral, a bacterium, a sonnet, a fugue or a word processor, architecture dominates material. To understand clay is not to understand the pot. What a pot is all about can be appreciated better by understanding the creators and users of the pot and their need both to inform the material with their meaning and to extract meaning from the form.\"</p> </li> <li> <p>\"You're doing this because that's the dream,\" he said. \"Don't mess with my dream, and I'll like you.\"</p> </li> <li> <p>\"You know, we don't grow most of the food we eat. We wear clothes other people make. We speak a language that other people developed. We use a mathematics that other people evolved  I mean, we're constantly taking things. It's a wonderful, ecstatic feeling to create something that puts it back in the pool of human experience and knowledge.\"</p> </li> <li> <p>\"Crusades are not completed in a day, even in a year.\"</p> </li> <li> <p>\"improve its abilities to wrestle problems into submission. Something to augment human powers. That was the word he used, augment. The other word he would come to use was crusade. Engelbart was embarking on a crusade to augment human capabilities by applying new technologies and developing ways to interact with that technology. He ultimately would realize, and even surpass, what Vannevar Bush had written in his terribly important yet unappreciated essay in the Atlantic. Crusades are not completed in a day, even in a year.\"</p> </li> <li> <p>\"The territory you see through the augmented window in your new vehicle is not the normal landscape of plains and trees and oceans, but an informationscape in which the features are words, numbers, graphs, images, concepts, paragraphs, arguments, relationships, formulas, diagrams, proofs, bodies of literature and schools of criticism.\" We now have a term for this informationscape: cyberspace.\"</p> </li> <li> <p>\"The tablet become a page become a screen become a world, a virtual world. Its depths increase with every image and word or number, with every addition, every contribution, of fact or thought. Its corridors form wherever electricity runs with intelligence. Its chambers bloom wherever data gathers and is stored . \"</p> </li> <li> <p>\"His vision was at the mercy of those he inspired.\"</p> </li> <li> <p>\"intimately. He found himself reading Marshall McLuhan's Understanding\"</p> </li> <li> <p>\"The medium is the message.\"</p> </li> <li> <p>\"The computer is a medium! I had always thought of it as a tool, perhaps a vehicle-a much weaker conception. What McLuhan was saying is that if the personal computer is truly a new medium then the very use of it would actually change the thought patterns of an entire civilization.\"</p> </li> <li> <p>\"The Alan Kay style of virtual designing, which he continued long after visualizing the Dynabook, consists of creating imaginative abstractions of what can be, going through the motions of gathering a team to build the thing, and discovering important new techniques and innovations in the process. The real product is the body of ideas that circulate from the vision.\"</p> </li> <li> <p>\"Metaphor, it turns out, is the key to making computers comprehensible.\"</p> </li> <li> <p>\"if it didn't hit the streets, it wasn't worth doing. Ideas were useless if they didn't get out there.\"</p> </li> <li> <p>\"people are more important than computers, and that computer systems should be designed to alleviate human frailties, rather than have the human succumb to the needs of the machine\"</p> </li> <li> <p>\"How can you believe any criticism when everything you do turns to\"</p> </li> <li> <p>\"How can you believe any criticism when everything you do turns to gold?\"</p> </li> <li> <p>\"The proper lesson from all this was that personal computer companies are just as well off letting others produce great software.\"</p> </li> <li> <p>\"when you start looking at a problem and it seems really simple, with simple solutions, you don't really understand the complexity of the problem. Your solutions are way over-simplified. Then you get into the problem, and you see that it's really complicated, and you come up with all these convoluted solutions. That's sort of the middle, and that's where most people stop, and the solutions tend to work for a while. But the really great person will keep on going and find the key, the underlying principle of the problem. And come up with an elegant, really beautiful solution that works.\"</p> </li> <li> <p>\"A lot of times people don't do great things because great things really aren't expected of them and because nobody really demands they try and nobody says, 'Hey, that's the culture here, to do great things\"</p> </li> <li> <p>\"What did I learn from Steve Jobs?\" he repeated. \"That ignorance [of what you can't do] is great. We learned to keep on trying and trying. We weren't the best, but we tried the hardest. We were just a bunch oflucky nerds.\"</p> </li> <li> <p>\"Real artists ship.\"</p> </li> <li> <p>\"When you're trying to spread a religion you have to be pretty strict at first. After you get them converted, you can relax,\"</p> </li> <li> <p>\"Those in charge of the marketplace regarded computing as a rite of passage, a sort of hazing. Only by acquiring knowledge in this needlessly arcane system could one gain admittance to the society of adepts. It was not a joyous society, but one of stiffupper-lips.\"</p> </li> <li> <p>\"What I didn't understand was that most people didn't get to make their own decisions.\"</p> </li> <li> <p>\"Breakthroughs like PageMaker have two sorts of effects. The first is to increase the ease and reduce the cost of performing previously expensive, time-consuming tasks. The second, and possibly more significant, is to empower people who otherwise could never afford to do the task in the first place.\"</p> </li> <li> <p>\"When the going gets weird, the weird turn pro.\"</p> </li> <li> <p>\"What's the difference between Apple and Boy Scouts? The Boy Scouts have adult supervision.\"</p> </li> <li> <p>\"There was a time, I know, when I conducted much of the same sorts of business that I currently engage in, without requiring a machine that makes more calculations in a morning's work than all the combined arithmetical operations of humanity performed by hand, over the span of recorded history.\"</p> </li> <li> <p>\"Still, I am hard pressed for proof that, for all its magic, Macintosh has enabled me to be more productive. I feel that it has, with every inch of my being. But after my recent fiasco with On Location and Word, I sometimes question whether this is an illusion.\"</p> </li> <li> <p>\"This gap between accepted reality (computers make us more productive) and the quantifiable result (they don't), has come to be known as the Productivity Paradox. A true puzzler: If computers enable us to get so much work done, in a much shorter period of time  why can't we measure it? Where did the productivity go?\"</p> </li> <li> <p>\"But maybe productivity is not the main benefit from computers. As its designers understood, the point of Macintosh was not to prod you into piling up x more reams of paper, but to change the way you interact with information, to empower you to manipulate information with confidence, to augment your creative powers, and to change the very way you think.\"</p> </li> <li> <p>\"Something happens to companies when they get to be a few billion dollars,\" he said. \"They sort of turn into vanilla companies. They add a lot of layers of management. They get really into process rather than result, rather than products. They lose touch with their customers. Their soul goes away.\"</p> </li> <li> <p>\"Macintosh tells people as they use it, 'You don't have to take things too seriously.'\"</p> </li> <li> <p>\"Each new purchase brought its small dopamine rush that faded as soon as the thing was out of its box and taking up space.\"</p> </li> <li> <p>\"Minimalism was a brand to identify with as much as a way of coping with mess.\"</p> </li> <li> <p>\"Every advertisement for a new product implied that you should dislike what you already had.\"</p> </li> <li> <p>\"There was really nothing wrong with our lives at all.\"</p> </li> <li> <p>\"Minimalism also seemed sometimes to be a form of individualism, an excuse to put yourself first by thinking, I shouldn't have to deal with this person, place, or thing because it doesn't fit within my worldview.\"</p> </li> <li> <p>\"It makes sense that millennials embrace minimalism. My generation has never had a healthy relationship with material stability. There are always too few resources at hand or too much competition for what's left, a scenario that's engulfing not just one age group but a wider swath of people every year. Even as the traditional economy falls apart, we're awash in social media noise and new platforms competing for our attention, labor, and cash. Stability is no longer the default.\"</p> </li> <li> <p>\"Maybe the longing for less is the constant shadow of humanity's self-doubt: What if we were better off without everything we've gained in modern society? If the trappings of civilization leave us so dissatisfied, then maybe their absence is preferable, and we should\"</p> </li> <li> <p>\"Maybe the longing for less is the constant shadow of humanity's self-doubt: What if we were better off without everything we've gained in modern society? If the trappings of civilization leave us so dissatisfied, then maybe their absence is preferable, and we should abandon them in order to seek some deeper truth.\"</p> </li> <li> <p>\"We should not believe the lack of silver and gold to be proof of the simple life.\"</p> </li> <li> <p>\"Your bedroom might be cleaner, but the world stays bad.\"</p> </li> <li> <p>\"Minimalism is thus a kind of last resort. When we can't control our material security or life path, the only possibility left is to lower our expectations to the point where they're easier to achieve, which could mean living in a train car, or a camper van.\"</p> </li> <li> <p>\"We like to think that we can do without, rough it to prove that we're not so soft or bound to the past.\"</p> </li> <li> <p>\"If we don't establish our identities with the volume of things we consume, then we feel more attuned to the way we consume them and the careful decisions we make between one thing and another. It's a species of the narcissism of small differences. We take pride in the small details that we have actually chosen from our limited options, which might make us feel better about not being able to change our circumstances as a whole.\"</p> </li> <li> <p>\"Consumerism causes a kind of alienation, in the Marxist sense: When workers are separated from the products of their labor and compensated by an hourly wage, they can't find satisfaction in their jobs or the remainder of family life. Thus they turn to acquiring capital as the only form of self-fulfillment. We work only to accumulate stuff and in turn the accumulated stuff dominates us, further distancing us from non-commodified things like relationships, joy, and community. Labor \"is therefore not the satisfaction of a need, but only a means for satisfying needs external to it,\" Karl Marx wrote in 1844.\"</p> </li> <li> <p>\"Minimalism is a perfect fit because it allows for just enough character to make a space interesting but not too much. The rest gets smoothed over into blankness.\"</p> </li> <li> <p>\"When a word or style spreads everywhere, it tends to lose its original meaning.\"</p> </li> <li> <p>\"The veneer of minimalist style becomes like an organic food label, expensive green juices, or complex skin treatments being sold as a \"no-makeup\" look. It's another class-dependent way of feeling better about yourself by buying a product, as Spartan as the product might be. It takes a lot of money to look this simple.\"</p> </li> <li> <p>\"It was better to go without a couch than buy one that wasn't perfect. That commitment to taste might be rarified, but it probably didn't endear Jobs to his family, who might have preferred a place to sit.\"</p> </li> <li> <p>\"The need for simplicity, taken to an extreme, can wipe function away entirely.\"</p> </li> <li> <p>\"Minimalist design encourages us to forget everything a product relies on and imagine, in this example, that the internet consists of carefully shaped glass and steel alone.\"</p> </li> <li> <p>\"For the sake of narrative it's always tempting to link a biographical cause to an artist's work, like a stem to a flower.\"</p> </li> <li> <p>\"Curation by definition is not an original act.\"</p> </li> <li> <p>\"Minimalism can be oppressive. The style can make you feel like you don't belong in a space unless you conform to it, as in upscale caf\u00e9s or severe hotel lobbies.\"</p> </li> <li> <p>\"(The problem with being both a critic and an artist is that you'll probably like work that resembles yours.)\"</p> </li> <li> <p>\"It isn't necessary for a work to have a lot of things to look at, to compare, to analyze one by one, to contemplate,\" Judd wrote in 1964. \"The thing as a whole, its quality as a whole, is what is interesting.\"</p> </li> <li> <p>\"Writing about emptiness is difficult because words document presence. As soon as you point to something in writing,\"</p> </li> <li> <p>\"Writing about emptiness is difficult because words document presence. As soon as you point to something in writing, it's there, even if what you point to is empty floor.\"</p> </li> <li> <p>\"You have to know what to look for, even if you're looking for absence.\"</p> </li> <li> <p>\"According to Minimalist principles, we have to fight the need to anthropomorphize or impose a metaphorical meaning on the installation. The boxes do not symbolize anything.\"</p> </li> <li> <p>\"This is Minimalism's most powerful and frightening insight. It has nothing to do with the aesthetic cues associated with lowercase-m minimalism, the consumer products, interior decoration, the curated items of clothing. Minimalism doesn't need to look good. It tries to make us understand that the sense of artistic beauty humanity has built up over millennia\u2014the varieties of colors, stories recounted, and bodies represented\u2014is also an artificial creation, not as inevitable as we think it is.\"</p> </li> <li> <p>\"A definition of art finally occurred to me. Art is everything at once.\"</p> </li> <li> <p>\"you don't act, someone will decide everything\"</p> </li> <li> <p>\"Art becomes retail surprisingly quickly.\"</p> </li> <li> <p>\"Our heads are victims of the prevailing clutter as much as our spaces.\"</p> </li> <li> <p>\"Silence can be a kind of nothingness, an erasure of the world in favor of a more manageable blankness, an absense of perception. We use silence to paper over experiences we don't like, creating a blockade between ourselves and sensation. It's a natual response to the excess of information that we confront every day in the form of emails, texts, advertising, and noise.\"</p> </li> <li> <p>\"As the prestige of language falls, that of silence rises.\" Sontag's evocation\"</p> </li> <li> <p>\"One good thing about extreme simplicity to the point of boredom is that it makes you focus on whatever is available to you,\"</p> </li> <li> <p>\"The simplest tune in the world can become grating just the same over hundreds of listens, the way even the most elegant, seamless design gets boring if you see it everywhere.\"</p> </li> <li> <p>\"all art is made from preexisting material, and any change that one makes is a creative act.\"</p> </li> <li> <p>\"The Generic City is what is left after large sections of urban life crossed over to cyberspace.\" Instead of marking the walls with graffiti, we type on our screens. We post photos of things on Instagram instead of creating them for ourselves. We end up in a desiccated malaise: According to Koolhaas, ambience inspires only \"weak and distended sensation, few and far between emotions, discreet and mysterious like a large space lit by a bed lamp.\"</p> </li> <li> <p>\"To escape the ambience\u2014to feel anything\u2014we have to be willing to risk hearing something unpleasant and being taken out of our familiar comfort zones. We need to recapture the awe and the surprise of silence.\"</p> </li> <li> <p>\"In Zen they say: If something is boring after two minutes, try it for four. If still boring, try it for eight, sixteen, thirty-two, and so on. Eventually one discovers that it's not boring at all but very interesting,\"</p> </li> <li> <p>\"applause. As Cage wrote, \"The\"</p> </li> <li> <p>\"The best purpose is no purpose at all.\"</p> </li> <li> <p>\"Conversation strives toward silence,\"23 Walter Benjamin wrote, \"and the listener is really the silent partner.\"</p> </li> <li> <p>\"What we require is silence; but what silence requires is that I go on talking,\"</p> </li> <li> <p>\"Minimalism can often lead to a stultifying sameness as everything becomes as simple as possible\u2014the elegant, ambient, blank style that I've described. It whitewashes both literally and metaphorically, at times privileging the Westernized, sanitized versions of external influences while deemphasizing their origins. Minimalism's sources get rebranded as high-minded art made by solo geniuses instead of the products of a globalized culture, even if the artists themselves readily acknowledged their debts.\"</p> </li> <li> <p>\"Minimalism as it appears in the West is inherently oppositional, posing itself against something, as a departure from a current state\u2014cleanliness against mess, absence against presence, and silence against noise.\"</p> </li> <li> <p>\"minimalism itself is not a homogenous thing. It's the combination of what might at first seem to be opposites, the way light is inextricable from shadow.\"</p> </li> <li> <p>\"We look all around ourselves for instructions on how to live only to be confronted with the basic unknowability of the world. And so we turn to some new mode of control, such as minimalism, only to be infected with the suspicion that it, too, is unreal, a map to no territory.\"</p> </li> <li> <p>\"Anyone who explains this or that, yes and no, is himself the man of yes and no.\" To echo the ending of so many of the monk's analyses: When you understand that, you will understand nothing.\"</p> </li> <li> <p>\"Mono no aware is the beauty of transience, the way a falling leaf or sunlight gilding the edge of a rock at the end of the day can incite a sudden gut-punch awareness that life is evanescent.\"</p> </li> <li> <p>\"The Buddhist acceptance of ephemerality didn't necessarily kill desire but made it all the more intense by giving the Heians a taste for ephemerality itself; they pursued the most beautiful evanescence possible.\"</p> </li> <li> <p>\"If life was so arbitrary then one may as well embrace the contradictions and the possibilities.\"</p> </li> <li> <p>\"The desire that everything be just right, matched with everything else around it in a unified whole, leads easily to intolerance.\"</p> </li> <li> <p>\"Man first of all exists, encounters himself,24 surges up in the world\u2014and defines himself afterwards,\"</p> </li> <li> <p>\"To do is to be.\"</p> </li> <li> <p>\"In the midst of existence, most living things deny time. They grow and reproduce in order to fight the inevitable. Life strives to be permanent, though it cannot be. Even the slow natural decay of a flower in the ground is a consequence of this struggle to survive as long as possible.\"</p> </li> <li> <p>\"It's not about consuming the right things or throwing out the wrong; it's about challenging your deepest beliefs in an attempt to engage with things as they are, to not shy away from reality or its lack of answers. To believe or commit too strongly to one particular way of seeing or being is to miss out on all the other possibilities and to allow yourself to be defined too much by one thing.\"</p> </li> <li> <p>\"No wonder that in the twenty-first century, when so many feel modernity has failed the West\u2014that our civilization has come close to destroying itself and our lifestyles appear gaudy and pointless\u2014absence is appealing once more. Embracing it reflects the need for a new way of thinking as well as consuming, one that makes a virtue of incompleteness and irresolution. Minimalism is\"</p> </li> <li> <p>\"Languages, it seemed, did not only sprout in continuity like new branches from the same tree from where they started, but were like different trees that happened to be neighbours stretching their branches, touching each other and sharing structure.\"</p> </li> <li> <p>\"The first slave languages to appear were pidgins\u2014stripped down, unstable codes made up on the spot. It was just adults throwing new words together\u2014words they heard from the white people who owned the estates. But it was children, with the genetic ability to pick up a first language out of all the talk they hear, who pieced together the pidgin words and made them into creoles that could do everything natural languages did. When parents, and indeed a whole community, is reduced to connecting through a pidgin, that pidgin becomes the only input the children get for working out their first language. Fortunately, children are able to take this raw material and impose a regular structure on it, with rules for grammar and syntax and a standardized vocabulary, turning it into a creole. A creole, according to this model, is simply a pidgin that has\u2014due to the innate ability of young children\u2014evolved into a native language and, in the process, fleshed out and become stable. Creole languages were like evolution happening before our eyes.\"</p> </li> <li> <p>\"A story always starts before it can be told.\"</p> </li> <li> <p>\"TODAY, INDIAN AMERICAN FAMILIES like ours represent an American success story. But it is easy to forget that, long before they called us \"the good immigrants,\" they called us \"the bad immigrants.\"</p> </li> <li> <p>\"For much of their history, Canada and America barred Asians from entry. In 1882, America enacted the Chinese Exclusion Act, the first significant race-based immigration ban in the country's history. America later extended the ban to all of Asia. Canada passed a similar set of laws, and both countries curbed citizenship, land, and other rights for Asian laborers already within their borders. While America's racial segregation was more explicit, both countries shared a commitment to building a white nation. That changed during the Cold War, when America wanted to promote itself as a liberal democracy capable of leading the world. Politicians reversed decades of discriminatory policy, reinventing America as a melting pot.\"</p> </li> <li> <p>\"In India's highly stratified society, middle- and upper-class Indians from dominant castes typically access the best schools and jobs that feed into opportunities in America, which favor immigrants who bring specialized skills in tech and science. The result: an American diasporic community that is roughly nine times more educated than Indians in India. These conditions enabled Indian families like ours\u2014families that had been thrice-filtered and stratified\u2014to prosper like few other immigrant groups have ever done in America.\"</p> </li> <li> <p>\"I was, as historian Vijay Prashad observed in The Karma of Brown Folk, \"unaware of how we are used as a weapon by those whom we ourselves fear and yet emulate.\"</p> </li> <li> <p>\"When we had nothing to throw back at the slurs thrown at us, when we had to silently swallow the humiliation of knowing that we were inferior in our own country, Yush and I found solace in the idea that success was part of our destiny. The belief that we were exceptional protected us. Until it didn't. Because stories designed to uphold hierarchies protect only one group\u2014those at the very top.\"</p> </li> <li> <p>\"Myths imbue the ordinary and mundane with celestial meaning. But this is also what makes them so dangerous: They do not reveal truths. Rather, they obscure any part of our realities that do not conform to the fantastical narrative\"</p> </li> <li> <p>\"It is not hard to see how the myth reinforces America's existing social and racial order, then, seducing its adherents with the promise of belonging in a country where their position remains tenuous and their acceptance is always in question. Rather than fostering solidarity over the ways in which white America disenfranchises those who look unlike them, the myth sows division among Asian ethnic communities. The myth encourages those at the top of the economic ladder to reinforce it, pushing those at the bottom further down. The privilege of the few sets constraints upon the many. The myth erases the legacy of racial exclusion from America's collective consciousness while perpetuating racial exclusion. The myth creates cognitive dissonance and then tells us that this dissonance does not exist. The myth splits our psyches, then calls this violence peace. The myth forces our minds to forget that which our bodies cannot: that belonging is always conditional.\"</p> </li> <li> <p>\"The problems between you and me began when I started trying to create context around things that were meant to be forgotten. Our problems began when I started searching for a way to explain everything that felt so inexplicable. Our problems began when I was expected to shrink myself, as you had been forced to do, but instead I insisted on expanding.\"</p> </li> <li> <p>\"The world we live in, which demands perfection and achievement, teaches us we cannot love ourselves as we are. The myth teaches us to think greatness always resides outside us instead of within\"</p> </li> <li> <p>\"I used to think that memories followed a straight line, starting at one point and ending at another, held together by the backbone of the strong linear narrative of cause and effect that takes each of us from birth to death. Now I think of memories as haphazard blots of ink in a Rorschach test that we assemble along the spine of the story we are told about who we are. If given enough space, time, and support, we can arrange the memories along a story that we write for ourselves, extracting new meaning from events experienced one way and later understood as another.\"</p> </li> <li> <p>\"I had underestimated the power and the depth of that desire and how the force of that current swept up the rest of us.\"</p> </li> <li> <p>\"There was a time when my outspokenness brought us together instead of tearing us apart. There was a time when speaking my mind was received not as a threat but as an act of love.\"</p> </li> <li> <p>\"I didn't know how to get the girls in my class to see me as special or good, but I learned that winning over adults was easy.\"</p> </li> <li> <p>\"Even though my friends were not always nice to me, I felt good about myself because I excelled in school.\"</p> </li> <li> <p>\"Now I wonder who we could have been if we saw our ethnicity not as something to manipulate into belonging in white America but as an opportunity to understand why we were treated differently in the first place.\"</p> </li> <li> <p>\"Until then, I thought adults always told the truth. I thought that the rules adults enforced existed to keep us safe, and I thought that adults followed all the rules that they made us follow. I saw this as the distinction between childhood and adulthood: Kids didn't know the rules for how to behave, and being an adult meant following the rules well. I wondered, then, if sometimes adults told us things that they thought were good for us because they wanted us to behave one way, but they acted another, because that was more convenient for them. This struck me as the most unfair, wrong, unjust thing in the world.\"</p> </li> <li> <p>\"I do not know what India represented to Papa, but I suspect he carried nostalgia for a place that never existed, a utopia created by the frozen impressions and desires of a nine-year-old boy who moved to a white country that shunned him.\"</p> </li> <li> <p>\"In the forgotten history of this influential board game, I recognize the arc of my own obscured cultural past. I see a deep self-knowledge abandoned and forgotten, replaced with a story that asserts the power of the very people who ensured our history's erasure, then marketed it back to us as our truth. I wonder now how this shaped his psyche and spirit: When, even in his own country, his people's stories did not matter, he was forced to study his oppressor's greatness, and learned to deny his\u00a0own.\"</p> </li> <li> <p>\"In Dadaji's story, I see how Papa's ancestors grasped for security by seeking educational attainment, specifically through math and science, and by learning the ways of the white man. In Papa's lineage, I see people who strove to ascend to feel secure. It is under these auspices that Dadaji rose from poverty and that Papa rose from a lower-class upbringing in Canada to the upper-middle class as an adult. Papa followed this common immigrant road map and imprinted the map upon Yush and me. But along the way, we forgot that this is not necessarily who we are\u2014it is who we felt pressured to become.\"</p> </li> <li> <p>\"A deeply sensitive, wounded brown boy grew into a deeply sensitive, wounded brown man who sought to gain respect, status, and security by embracing the only role that embraced him: that of the high-achieving Indian kid.\"</p> </li> <li> <p>\"The difference in treatment between son and daughter would ripple through generations, one learning entoc: true titlement, the other learning injustice. One sibling would lean into nostalgia for lost culture to justify his behavior, while the other would struggle to reclaim her lost culture, observing how tradition was so often invoked to evade accountability and prevent change.\"</p> </li> <li> <p>\"I saw that on the page, my words mattered as much as those of someone like Shel Silverstein. The page could not ignore me or treat me differently just because I was small or dark-skinned or a girl. On the page, I could show people things that I had trouble showing them any other way.\"</p> </li> <li> <p>\"Creativity poured out of me as a natural expression, touching everything that I did.\"</p> </li> <li> <p>\"It's not that I wanted to be white, Mummy. I loved my bronze skin. There was no food better than your jeera-and-haldi-spiced aloo gobi. I felt glamorous in the deep-blush silver-lined lehenga that Naniji and Nanaji sent me from India. But I yearned for the freedom that I associated with whiteness. I felt like a simile, my personhood contextualized by whatever popular image I conjured in the minds of others\u2014usually, Apu from The Simpsons. \"Thank you, come again!\" kids joked, asking if my parents owned a Kwik-E-Mart. They wondered out loud why my hands were brown on one side and white on the other and wanted to know where I was really from. I was envious that white people didn't have to liken themselves to something else in order to be understood. They could appear as they wanted to appear, without question or comparison.\"</p> </li> <li> <p>\"AS I STROVE TO meet Papa's expectations, the joy I had once taken from my hobbies faded. Reading, writing, and even painting started to feel rote and mechanical. The fact that things I loved could seem tedious scared me. I read books to extract facts and words, guzzling them like Papa's nutrient-rich Ensure. I doubt that you or Papa noticed my creativity clamping shut, because I barely noticed. I continued to paint and draw\u2014only now I did it to impress the hypothetical white Harvard admissions officers of Papa's imagination.\"</p> </li> <li> <p>\"If I could answer Papa's question today, I would say this: Art kept my spirit alive. Expressing myself, whether by drawing, writing, or dancing, was an assertion of my existence that enabled me to connect to something deeper than simply what I was expected to produce in the world. Later, when I felt too blocked to create, consuming art broke my sense of isolation and helped me see parts of myself in work created by others. When I forgot who I was, creating art helped me find my way back. Art was my entry point to learning how to love myself. Now I feel sad that Papa might not know what it means to connect with oneself or with someone else in this way.\"</p> </li> <li> <p>\"But my treatment of you wasn't simply mimicry, either. It was a clumsy expression of anger over how mother was raising daughter to learn that to be good is to betray oneself, to forever contort oneself to fit into impossible, contradictory expectations of womanhood that felt stifling.\"</p> </li> <li> <p>\"Papa wanted me to remain invisible. But from what I could tell, dating relied upon being seen, noticed, and chosen. America, too, sat high up on a stage, forcing the rest of the world to behold its spectacle. Being seen\u2014well, that was about the most American thing I could think of. Unfortunately, I was seen as little more than the mule\"</p> </li> <li> <p>\"As I began to love my body, I understood myself beyond my capacity for academic performance. I saw that I was so much more than what others perceived me to be.\"</p> </li> <li> <p>\"Papa's anger was not new, but this was the first time that I did not see any part of his rage toward me as justifiable. And it was the first time that I recall you piling on, berating me the way that he did. Your words hurt far more than what Papa said. After he was done yelling at me, you yelled for another hour. You said hurtful things, things that sounded like what Papa would say. I knew that you didn't mean any of it, but I didn't understand where your anger came from. From you, hateful words sounded clunky and unnatural. It was as if you needed a place to express your anger, and this was the only forum available. I think Papa's words to me gave you a template for your rage.\"</p> </li> <li> <p>\"He could have shown Yush and me how to love ourselves in the face of whiteness. But he could not teach us what he did not know himself.\"</p> </li> <li> <p>\"The truth is, I had no idea if Drew could have appreciated me for who I really was. I never gave him the chance. I couldn't accept myself, so how could I let Drew?\"</p> </li> <li> <p>\"I think I know why you busted me: My defiance hurt you. You had become a casualty in the war between Papa and me. You worked so hard to keep the peace at home. And here I was, poking the bull to get him to charge. My antics made a mockery of all that you had put up with to provide stability. I wonder now if you perceived my behavior as a personal rejection, not just of your efforts as a mother but of my duty within the family. Everyone had a role to play, and everyone continued to play their part, except for me. It is true that I took out my anger in ways that were hurtful. I spat in the face of your sacrifice, and for that, I am sorry.\"</p> </li> <li> <p>\"I resented that whenever I succeeded, Papa credited himself and his Indian values, but when I failed, that failure was uniquely mine, a product of my Americanness. I felt so ashamed that I was\u2014as I put it then\u2014\"bad at being Indian.\" At the time I thought I was abdicating my identity. Now I see that I was asserting\"</p> </li> <li> <p>\"resented that whenever I succeeded, Papa credited himself and his Indian values, but when I failed, that failure was uniquely mine, a product of my Americanness. I felt so ashamed that I was\u2014as I put it then\u2014\"bad at being Indian.\" At the time I thought I was abdicating my identity. Now I see that I was asserting it.\"</p> </li> <li> <p>\"Yush's love taught me that a fight does not have to become a war that ends in the total annihilation of another.\"</p> </li> <li> <p>\"I viewed Yush's talent in science and math as a gift and wished that, like him, I was naturally skilled in the exact ways that capitalism rewards. I never thought about the toll that his success took on him or what kind of pressure he must have felt to maintain it. I thought Yush\u2014whose name means \"glory\" in Sanskrit\u2014was blessed. Now I know that he was cursed.\"</p> </li> <li> <p>\"Papa said that he valued achievement, but it seemed like he was willing to bend the rules to appear that way\u2014even if that involved cheating.\"</p> </li> <li> <p>\"I thought Papa was in pain because I had been such a bad student in high school. I thought that if I became a Good Indian Girl, our relationship would improve and he would be at peace. I want you to remember that I tried to be that daughter, Mummy. And I want you to know that trying taught me that achieving perfection would not have kept our family whole.\"</p> </li> <li> <p>\"was nervous about my best friends seeing my family life so intimately, and I was nervous about what Papa might find when seeing me with these white friends up close. I felt a dissonance that I could not yet articulate, a tear in what W.E.B. Du Bois called the \"double-consciousness\" of race, not knowing how to meld my distinct identities. I understood these two versions of myself as Indian\u2014my home self\u2014and American\u2014my outside self. I was anxious that either I would not be Indian enough for Papa or I would not be American enough for Nancy and Marin. Ultimately, I'd be outed as a fraud by everyone I cared about.\"</p> </li> <li> <p>\"EVERYWHERE I WENT, PEOPLE saw me as Indian. But India was the only place in the world I felt American. The specter of India loomed so large over my life, yet my entire actual lived experience with a vast country of over one billion people and hundreds of spoken tongues was probably no more than about three months, total. I do not know how long we stayed when you took me as a baby, when I learned the Hindi that I can still speak in choppy waves.\"</p> </li> <li> <p>\"Your dad would hate to have me as a daughter,\" she said. \"Why?\" I asked. \"Because I would tell him exactly what I think, and I don't think he'd like that.\" Then she asked me, \"Why do you act like a child when you're with your dad?\" \"What do you mean?\" I said, getting defensive. I received her question as judgment from a white woman who didn't understand anything about the stress of navigating life with two different identities. Nancy had crossed a line that she wasn't supposed to cross. \"You pretend to not know things that you know. You ask him questions when you already know the answer to them. You're smart, but around your dad, you play dumb.\" The truth of Nancy's words hit something deep inside me, a place that I had numbed. In that moment, I felt humiliated\u2014but also recognized. Something I had put to sleep had been awakened, and I could not ignore it.\"</p> </li> <li> <p>\"At the time, I scolded Yush for passing on an opportunity for success that I would never have, a chance to be among the truly elite. But Yush was happier at home. I think Yush would have been happy with a simple life. What I think he didn't feel sure about was whether, if he chose that simple life, he'd still be loved and respected.\"</p> </li> <li> <p>\"None of us knew then that what Yush dealt with was not an anomaly but a tragically common symptom of the pressures he faced. We didn't know that Asian American college students are more likely to deal with suicidal thoughts and attempt suicide than white students\u2014straddling multiple cultures, experiencing racism, and living up to narrow expectations of achievement exerts extreme stress on the mind and body. To navigate those pressures, Yush and I learned to repress our feelings and forge onward,\"</p> </li> <li> <p>\"There was no way for us to talk about any of this, because we did not know these problems even existed. We found out about a problem like most families do, when it became so big that it exploded in front of us and we could no longer avoid dealing with it. And we dealt with it the way most families do: quickly and quietly. We swept up the mess, put things back as best we could, and continued to live in the same way, as if nothing had ever happened. We didn't know that by trying to forget, we were more deeply committing ourselves to the very circumstances and problems that had caused the explosion in the first place. We didn't know that we were teaching Yush not to resolve his pain but to find more-creative ways to hide it. Now I wonder what decisions Yush would later have made if he had been encouraged to talk about his mental health, rather than feel pressured to stay quiet.\"</p> </li> <li> <p>\"But as our family struggled to find some sense of normalcy, I began to question the idea of normal. Yush's best friend, who also lived with depression, said, \"This is a dumb analogy, but it sort of fits. It's like in Men in Black. If you don't believe in aliens, you walk around like everything is normal. But once you become aware of depression and how it lies to your mind, it's like you know about the aliens. You can't go back to the way you used to think, and you can't believe how uninformed you were.\" It was not the most eloquent analogy, but it captured my sentiments. For the first time in my life, I began to wonder what else I had failed to see because I had blocked it from view.\"</p> </li> <li> <p>\"Writing demands conviction. But the last thing that I could put on my page was me\u2014not that I even really knew who that was. I prided myself on my ability to be a chameleon: to change myself to reflect what others needed of me when they needed it. This, I thought, was the quality that made me unique\u2014that was what made me me.\"</p> </li> <li> <p>\"I had originally listened to Buaji because I respected her. But that summer, I began to see how owning my reactions and behavior liberated me. By not responding to Papa's tantrums, I took myself out of them entirely, to the point where I could recognize the absurdity of his actions. I started to understand the directionality of the movement, how it traveled from one source and then stopped at another. His outbursts were a pattern\u2014not an anomaly. I didn't understand what caused his anger, but I was no longer willing to submit to the repetitive cycle.\"</p> </li> <li> <p>\"Questions are dangerous. Questions lead to dissent.\"</p> </li> <li> <p>\"In our family, loving someone meant rescuing them or letting yourself be rescued by them. But when I needed help to cope with work and the chaos at home, no one in our family had the capacity to support me, because everyone was dealing with their own, bigger problems. As I rescued myself, I wondered if that could be a form of love, too: the ability to take care of oneself well enough to not require saving.\"</p> </li> <li> <p>\"I would not be able to write or paint anything authentic for years, plagued by that question. I would struggle to believe that anything I created could ever really matter, because it didn't seem to matter to the people who were supposed to love me the most.\"</p> </li> <li> <p>\"In a capitalist society, the measure of wellness isn't a person's actual health or happiness but how far one can rise or how much wealth one can accumulate. Somebody seen as \"unwell\" is unable to produce and to achieve.\"</p> </li> <li> <p>\"I had spent a good portion of my life feeling cheated out of the exceptional family I was told I had. I believed that if I held the same values and followed the rules laid before me, I could make that perfect family materialize. When that didn't happen, and most of the people around me doubled down on that message\u2014to suggest that we were not happy because I was not adhering to the rules closely enough\u2014I felt like I was losing my mind. Now I had learned that the secret of having a happy family was pretending to be perfect. I felt robbed. I didn't want to do that, and I couldn't accept that as the answer. I didn't understand how no one else in our family felt the same level of indignation that I did over living a lie.\"</p> </li> <li> <p>\"But wasn't society a little ill, too, for normalizing the idea that the rules didn't apply to him because of his status?\"</p> </li> <li> <p>\"NO ONE IN OUR family had died, yet I felt an emotional death. My grief wasn't just about losing my relationship with you. The rickety bridge to my cultural identity had also collapsed. I had mostly participated in Indian culture through family events, like Diwali celebrations or weddings, where I could wear lehengas and speak unsteady Hindi among relatives. As I distanced myself from family, without many friends with whom to create my own traditions, I withdrew from all things Indian. I had once prided myself on being a devoted daughter, but I was ashamed that I could no longer call myself that, either.\"</p> </li> <li> <p>\"I'd been raised to believe that comfort was the result of hard work or innate intellect, but I was starting to understand that fulfillment of these basic human needs was tied to a person's body, bloodline, and the origins of their birth. Papa's wealth had made me feel entoc: true titled to a level of security that no one is owed or guaranteed. I had a simplistic understanding of the world and how it worked because it worked well enough for me, and it was only when it stopped working for me that I began to think about the ways in which it failed to work for others.\"</p> </li> <li> <p>\"I began to think of success not as a job toc: true title, wealth, prestige, or social network but as the ability to be myself in the world. To know that, as a woman who had been taught that I needed to serve a man to be complete, I could instead build a life for myself that I loved, and that I could sustain that life by myself. I hoped that, maybe if you saw me live this way, you might choose to come back to me.\"</p> </li> <li> <p>\"At the very moment I started seeing myself as an equal and asked for the same opportunities and rights as my mostly white peers, I was cut down to size, put in my place, reminded that I should be grateful to be allowed among them at all. I saw that I was not valued for my perspectives, only for what I could produce.\"</p> </li> <li> <p>\"MUMMY, I HAD WANTED to think that fame and wealth\u2014conventional notions of success\u2014didn't matter to me anymore. But they did. I didn't get approval from you or Papa or Yush, and the desire to be validated was so deep in me that now I sought it on an even larger stage: the whole world, demanding that everyone look at the very thing that no one in our home could acknowledge\u2014my perspective. But now I could see that, while the world loved what I did, it still didn't love me. I didn't know what to do with my ugly desire for validation or the world's ugly response to it.\"</p> </li> <li> <p>\"It's a strange thing to miss someone who is right there. When I talk to you is when I miss you the most, because I am confronted by what I cannot have.\"</p> </li> <li> <p>\"WE HAD EACH BEEN raised to believe that every unknown could be resolved through willpower and intellect, a message reinforced by America's rigid conception of who we are supposed to be. The truth is, society doesn't raise people to aspire to be kind or compassionate or happy. It pressures adults to achieve and accomplish. It teaches people that what matters more than their character or how they treat others or how they feel about themselves is how much money they can hoard, who they know, how famous they can get, and how much power they wield over others. Emotions have no basis in this framework. They are a nuisance, a hindrance, a distraction, a weakness.\"</p> </li> <li> <p>\"I HAD THOUGHT OF love as a taut chain with a tight clasp that carried our weight as we clutched one another, no matter what dragged any of us down. I had believed that when I love someone, I should hold on regardless of what else I have to give up in order to keep them. The more one gives up, the greater the love, I thought. To love someone well was to perform perfection for them, and to be loved well was for them to perform perfection for me. But that is not true love. That is self-abandonment masquerading as love.\"</p> </li> <li> <p>\"I had once thought that I came from a line of Gods, and I had punished myself for failing to be Godlike. But we were not Gods, and I was not the avatar for our family's unraveling. I was just another product of inherited trauma, unresolved grief, and reactive survival mechanisms, like everyone else who came before me. We were mortals who felt ashamed when we failed to appear omnipotent. Now I see that my job was to release my ancestors from this burden, to allow those who come next the freedom to be ordinary.\"</p> </li> <li> <p>\"Language was always the companion of empire, and as such, together they begin, grow, and flourish. And later, together, they fall.\"</p> </li> <li> <p>\"He buried his past life, not because it was so terrible but because abandoning it was the only way to survive.\"</p> </li> <li> <p>\"'Every language is complex in its own way. Latin just happens to work its complexity into the shape of the word.\"</p> </li> <li> <p>\"Words and phrases you think are carved into your bones can disappear in no time.'\"</p> </li> <li> <p>\"A lie was not a lie if it was never uttered; questions that were never asked did not need answers.\"</p> </li> <li> <p>\"'Whenever the English see me, they try to determine what kind of story they know me from,' Ramy said. 'Either I'm a dirty thieving lascar, or I'm a servant in some nabob's house. And I realized in Yorkshire that it's easier if they think I'm a Mughal prince.'\"</p> </li> <li> <p>\"If they're going to tell stories about you, use it to your advantage.\"</p> </li> <li> <p>\"The English are never going to think I'm posh, but if I fit into their fantasy, then they'll at least think I'm royalty.'\"</p> </li> <li> <p>\"Travel sounds fun until you realize what you really want is to stay at home with a cup of tea and a stack of books by a warm fire.'\"</p> </li> <li> <p>\"'Translation, from time immemorial, has been the facilitator of peace. Translation makes possible communication, which in turn makes possible the kind of diplomacy, trade, and cooperation between foreign peoples that brings wealth and prosperity to all.\"</p> </li> <li> <p>\"'That's the thing about secret societies,' said Griffin. 'They're easy to romanticize. You think it's this long courting process \u2013 that you'll be inducted, shown a whole new world, shown all the levers and people at play. If you've formed your only impression of secret societies from novels and penny dreadfuls, then you might expect rituals and passwords and secret meetings in abandoned warehouses.\"</p> </li> <li> <p>\"'Language does not exist as a nomenclature for a set of universal concepts,'\"</p> </li> <li> <p>\"So you see, translators do not so much deliver a message as they rewrite the original. And herein lies the difficulty \u2013 rewriting is still writing, and writing always reflects the author's ideology and biases.\"</p> </li> <li> <p>\"He was a child starved of affection, which he now had in abundance \u2013 and was it so wrong for him to cling to what he had?\"</p> </li> <li> <p>\"'What makes the English superior is guns. Guns, and the willingness to use them on innocent people.'\"</p> </li> <li> <p>\"Unpretty women were so much easier to deal with in some ways\u2014you didn't have to face the pain of their probable unattainability.\"</p> </li> <li> <p>\"For so accustomed are we to electric lights that the sight of a naked bulb beneath an ordinary milk glass shade seems simpler and more natural than any gratuitous attempt to hide\"</p> </li> <li> <p>\"For so accustomed are we to electric lights that the sight of a naked bulb beneath an ordinary milk glass shade seems simpler and more natural than any gratuitous attempt to hide it.\"</p> </li> <li> <p>\"The cleanliness of what can be seen only calls up the more clearly thoughts of what cannot be seen.\"</p> </li> <li> <p>\"An insignificant little piece of writing equipment, when one thinks of it, has had a vast, almost boundless, influence on our culture.\"</p> </li> <li> <p>\"And so we distort the arts themselves to curry favor for them with the machines.\"</p> </li> <li> <p>\"In making for ourselves a place to live, we first spread a parasol to throw a shadow on the earth, and in the pale light of the shadow we put together a house.\"</p> </li> <li> <p>\"If the roof of a Japanese house is a parasol, the roof of a Western house is no more than a cap, with as small a visor as possible so as to allow the sunlight to penetrate directly beneath the eaves.\"</p> </li> <li> <p>\"A light room would no doubt have been more convenient for us, too, than a dark room. The quality that we call beauty, however, must always grow from the realities of life, and our ancestors, forced to live in dark rooms, presently came to discover beauty in shadows, ultimately to guide shadows towards beauty's ends.\"</p> </li> <li> <p>\"This was the genius of our ancestors, that by cutting off the light from this empty space they imparted to the world of shadows that formed there a quality of mystery and depth superior to that of any wall painting or ornament. The technique seems simple, but was by no means so simply achieved. We\"</p> </li> <li> <p>\"This was the genius of our ancestors, that by cutting off the light from this empty space they imparted to the world of shadows that formed there a quality of mystery and depth superior to that of any wall painting or ornament. The technique seems simple, but was by no means so simply achieved. We can imagine with little difficulty what extraordinary pains were taken with each invisible detail\u2014the placement of the window in the shelving recess, the depth of the crossbeam, the height of the threshold. But for me the most exquisite touch is the pale white glow of the shoji in the study bay; I need only pause before it and I forget the passage of time.\"</p> </li> <li> <p>\"But I see why in ancient times statues of the Buddha were gilt with gold and why gold leaf covered the walls of the homes of the nobility. Modem man, in his well-lit house, knows nothing of the beauty of gold; but those who lived in the dark houses of the past were not merely captivated by its beauty, they also knew its practical value; for gold, in these dim rooms, must have served the function of a reflector. Their use of gold leaf and gold dust was not mere extravagance. Its reflective properties were put to use as a source of illumination.\"</p> </li> <li> <p>\"Beautiful though such a face may be, it is after all made up; it has nothing of the immediate beauty of the flesh.\"</p> </li> <li> <p>\"The unseen for us does not exist. The person who insists upon seeing her ugliness, like the person who would shine a hundred-candlepower light upon the picture alcove, drives away whatever beauty may reside there.\"</p> </li> <li> <p>\"As even this trifle suggests, pitch darkness has always occupied our fantasies, while in the West even ghosts are as clear as glass.\"</p> </li> <li> <p>\"we Orientals tend to seek our satisfactions in whatever surroundings we happen to find ourselves, to content ourselves with things as they are; and so darkness causes us no discontent, we resign ourselves to it as inevitable. If light is scarce then light is scarce; we will immerse ourselves in the darkness and there discover its own particular beauty. But the progressive Westerner is determined always to better his lot. From candle to oil lamp, oil lamp to gaslight, gaslight to electric light\u2014his quest for a brighter light never ceases, he spares no pains to eradicate even the minutest shadow.\"</p> </li> <li> <p>\"The older we get the more we seem to think that everything was better in the past.\"</p> </li> <li> <p>\"Yet of this I am convinced, that the conveniences of modern culture cater exclusively to youth, and that the times grow increasingly inconsiderate of old people.\"</p> </li> <li> <p>\"One of the oldest and most deeply ingrained of Japanese attitudes to literary style holds that too obvious a structure is contrivance, that too orderly an exposition falsifies the ruminations of the heart, that the truest representation of the searching mind is just to \"follow the brush.\"</p> </li> <li> <p>\"'We'll keep making the wrong decisions,' a friend told me, 'and we'll keep enjoying the consequences.'\"</p> </li> <li> <p>\"When a person meets misfortune, even drinking water would get stuck in the teeth.\"</p> </li> <li> <p>\"He envied the disciples of the larger sects. No matter what spell, it required self-comprehension after it reached a certain level. But learning from the experiences of the people that had studied it before them would greatly decrease the detours that they had to take.\"</p> </li> <li> <p>\"Work and relax, that was the right way.\"</p> </li> <li> <p>\"Do within the limits, and depend on the heavens.\"</p> </li> <li> <p>\"Behind the most beautiful and exquisite things, was the most dullness and loneliness.\"</p> </li> <li> <p>\"The joy after surviving a calamity made everything seem so beautiful.\"</p> </li> <li> <p>\"To cultivate the sword, what cannot be lost is purity. But the five elements birth and defeat each other, and are difficult to make pure.\"</p> </li> <li> <p>\"Ha ha, cultivation is long and difficult. If there isn't a strong and resolute heart, how can one achieve the path?\"</p> </li> <li> <p>\"the existing official wasn't as good as the existing manager.\"</p> </li> <li> <p>\"A clever companion was much better than a stupid one.\"</p> </li> <li> <p>\"Anything that required study, it had to be built from the ground up, there were no tricks.\"</p> </li> <li> <p>\"All kinds of comprehension, it wasn't a building in the sky. Without a solid base, even if you understood it, you could not produce it.\"</p> </li> <li> <p>\"Cultivation, it was to have a steady heart, and not waver!\"</p> </li> <li> <p>\"In any case, the barefoot weren't afraid then those wearing shoes.\"</p> </li> <li> <p>\u201cStop trying to convince everyone that you suck, focus on the positives\u201c</p> </li> <li> <p>\"As you get better, the goalposts get further away\"</p> </li> <li> <p>\"Your eye for mistakes grows as your skills do\"</p> </li> <li> <p>\"Sticky notes are a great way of telling you what you failed to do\"</p> </li> <li> <p>\"Relationships are about mutual giving -- not about just avoiding everything you don't both like equally.\"</p> </li> <li> <p>\u201cPeople, generally speaking, want outcomes. They don\u2019t care how it\u2019s done or what is used to get there. No one goes to the hardware store to buy a drill. They go there to buy holes.\"</p> </li> <li> <p>\"What's the point of living your life with your hands and feet tied? You should create a sky shaking, earth shattering way for yourself!\"</p> </li> <li> <p>\"According to the history books, most of the falls of any ancient emperor were caused by their suspicions of their ministers; their suspicions made them ill and therefore led to their death\"</p> </li> <li> <p>\"The waves in the back always push the ones in the front in the Yangtze river, so of course each generation has to be stronger than the next\"</p> </li> <li> <p>\"The hardest part is not learning how to use the tools but know what to do with them\"</p> </li> <li> <p>\"The universe will never give you peace in something you were not meant to settle in\"</p> </li> <li> <p>\"When I was a teen, I'd self harm, but now I just occasionally inconvenience myself in different ways when I feel bad or guilty about something I've said or done.\"</p> </li> <li> <p>\"When we're in a dangerous situation as a child, we're not allowed to get angry because the abusers are dangerous. So we turn our anger back at ourselves. The abusers contribute to this on purpose, making us feel like we had some control over the situation when we did not. That's what abusers do.\"</p> </li> <li> <p>\"You're hurting yourself in an attempt to soothe yourself. And because you had abusive parents who were probably prone to punishment, you're doing that to yourself. You are imitating them, what they did to you.\"</p> </li> <li> <p>\"They see me ho'ing, they hatin\"</p> </li> <li> <p>\"Thousands of miles fly by in a dream and thousands of years like a racing steed\"</p> </li> <li> <p>\u201cTaking rejections personally is the biggest enemy of a creative professional. Don\u2019t let your work become your whole identity.\u201d</p> </li> <li> <p>\"This is your job, and as long as you\u2019re being paid for it, just let it go.\"</p> </li> <li> <p>\"What horrifies me most is the idea of being useless: well-educated, brilliantly promising, and fading out info an idifierent middle age.\"</p> </li> <li> <p>\"we have kitchens to clean because our bellies are full. we have beds to make because we did not have to sleep on floors. our laundry is piling because we have so many clothes to choose from and so many ways to make them dirty. our arms are full because our hearts are full. celebrate the messy. celebrate every little thing that needs to be done. life is too short and too beautiful to let the little things slip away.\"</p> </li> <li> <p>\u201cIt\u2019s easy to say I wish my partner did more for me. It\u2019s hard to do more for your partner\u201d</p> </li> <li> <p>\"If you stop and think about it, your life is a lot longer as an old guy than as a kid.\"</p> </li> <li> <p>\"To her, reuniting with her Aranara friend is the \"result.\" But recapturing her past joy and belief in herself is the \"process,\" and that's where our help is needed.I'm guessing that her sudden illness made her feel like she may not be able to realize her dreams anymore. It also made it difficult for her to hold onto the happy memories and dreams she had.Everyone has their own imagination. After some chance coincidence, she met an \"Aranara.\"So as long as we help her rediscover that same feeling she once had, her \"Aranara\" will return naturally.Oh, so that's what you're thinking...Adults only want to believe in objective reality. In doing so, they may unintentionally do harm to the innocent fantasies of children.But I think there are ways to get even subjective things back.\"</p> </li> <li> <p>\"I'm so happy... I almost forgot how it feels to be this happy...You know, at first, it felt like my world had shrunk down to a tiny space.But as long as I continue moving forward, new sights will always appear in front of me, and my world will keep expanding before my eyes.Even though I don't know how I did it, I know I have you all to thank.Oh, that's not important. What's important is that you've remembered the joy of going through the world.Our memories don't just symbolize our past. They can also shine a light on our future.Once you find the hope in your heart again, that happiness will come back to you.\"</p> </li> <li> <p>\"Dreams themselves may be imaginary, but they're also experiences that can never be relived or replicated.If we were sticklers about truth and fiction, we would've missed out on so much beauty and emotion.\"</p> </li> <li> <p>\"That might sound silly to you... Like, why do you have to be happy just because it is? But that's the magic of a smile. If you don't believe me, try it. Look at it a few times every day, and you'll understand.\"</p> </li> <li> <p>\"People use fireworks to remember their most precious memories, and these memories sparkle and shine each time the fireworks fly. In other words, fireworks symbolize the past. And shooting stars make people think of wishes because wishes carry people's brilliant hopes and expectations for the future. One represents the past, and the other the future. They both bloom in the sky, but have completely different meanings behind them.\"</p> </li> <li> <p>\"Underneath their hard shell is often a vulnerable human, who fails to provide you with nurture because they never received it themselves. Their dysfunctional behaviours are rooted in a painful past. To these parents, their fundamental experience in life is that of being groundless. From a young age, they did not feel protected or guided but were \u2018thrown into\u2019 a precarious and scary world. They had to survive challenges, protect themselves and seek direction in the world while their parents remained weak or absent. At some point in their life, perhaps on an unconscious level, they decided they would make better parents to themselves than their real parents could. They took over the role and became the powerful figure they had been searching for. Since their own sense of invincibility is the only thing that they have ever been able to count on, they fiercely protect it with all they have. This is why they demand compliance from others to reinforce their authority and are extremely defensive and reactive to anything that threatens their sense of control. \"</p> </li> <li> <p>\"One has never found oneself lacking in basic comforts. On the contrary, it is the gesture that one values above all else. So long as you've shown proper respect and consideration, the quantity or quality of the gift is but a trivial matter.\"</p> </li> <li> <p>\"A name is but a simple label we carry with us on our journey through the world. Why would one be offended by such a trivial matter?\"</p> </li> <li> <p>\"That is not to say that your words paint an inaccurate picture. One has always lived by a single ideal: eschew all action and abide by no rule. One does as one pleases and speaks as one pleases. Others may critique or praise as they see fit, yet one places little weight in such judgments.\"</p> </li> <li> <p>\"When dwelling between mountain and forest, away from the struggles and troubles of the mortal world, a mortal form is hardly the most fitting of choices.\"</p> </li> <li> <p>\"'Tis a truth most evident: One always recognizes one's own... no matter what form they may take.\"</p> </li> <li> <p>\"When it is time for one's progeny to leave the nest, it is the responsibility of an elder to let them fly free. Yet when your wings grow weary and the night grows dark, just know that you always have a place to which to return. Tis a refuge referred to by many a name in mortal writing: \"Home,\" \"nest,\" \"haven\"... Whatever its denomination may be, its essence remains quite unchanged. One speaks, of course, of a place not unlike one's own abode. One's disciples are free to come and go as they wish, yet the door remains forever open to those who wish to return... One rather hopes you count yourself among them.\"</p> </li> <li> <p>\"Tears are a necessary part of maturation. Sometimes, there is scarcely a better vehicle to wash away the toll of stress and misery. Now that the issue has been resolved, you should also take a moment to relax. Give yourself some time to rest, take a nap if you must. One will wake you in due time.\"</p> </li> <li> <p>\"Every individual must find their own path to enlightenment. So long as one retains a pureness of spirit, one's dietary proclivities are quite irrelevant.\"</p> </li> <li> <p>\"Not unlike the ocean tides, so too shall the movement of people ebb and flow. From turmoil to peace, enlightenment to aspiration \u2014 human society possesses limitless potential. In another thousand years, the scene we witness here may change in ways that are impossible for either of us to imagine.\"</p> </li> <li> <p>\"I\u2019m a self-sufficient adult and abandonment no longer means the end of my life.\"</p> </li> <li> <p>\"It can be both aggravating and overwhelming when your parents repeatedly raise groundless fears, make false claims or subscribe to conspiracy theories. Perhaps you have realised by now that no amount of reassurance will ease their worries, but you may still be tempted to challenge their thinking or try to eradicate their fears with logic. Besides being futile, these efforts will likely backfire as your parents\u2019 fears are real to them. In fact, these are the pillars of their existence. For many years, they have relied on a rigid and absolute way of feeling safe in the world. They hold onto their defensive system so tightly because if they don\u2019t, their sense of self will crumble. Therefore, the more you try to challenge their views, the more defensiveness and pushback you will face from them. To have a productive interaction, try not to ridicule, tease or undermine their paranoia, or convince them that they may be wrong. Instead, allow them to have their say. If they try to force you to agree with them, it is within your rights to remain firm and honest. You do not have to share their beliefs, but you can validate their feelings, or remain non-reactive. On the other hand, bear in mind that when your parents are in a fearful place, their cognitive abilities will tend to regress, and they may not be capable of abstract thinking or logical reasoning. Therefore, when you speak, try to be clear, explicit and non-metaphorical, to reduce the chances of misinterpretation.\"</p> </li> <li> <p>\"It's amazing how a little tomorrow can make up for a whole lot of yesterday\"</p> </li> <li> <p>\"To survive the lack of or inconsistent parenting input, we learned to withdraw our needs from others and even ourselves.\"</p> </li> <li> <p>\"We fear the thing we want the most.If our experience had taught us that being angry would lead to someone deserting us, or that our sadness was a burden, it makes sense that we default to hiding our feelings. We learn to shut off our emotions \u2013 first to others, then to ourselves, to prevent potential rejection or exile from the family and community\"</p> </li> <li> <p>\"As our need for love has been frustrated, we construct a facade of pretending not to have any needs, and eventually, we start to believe we really don't need love. Then, we feel our lives to be flat and numb. To make up for our inner emptiness, we try to establish our values through 'doing' rather than 'being'. We might be high-achievers in the professional arenas or appear successful, independent, and self-contained, but deep down our battle with perfectionism, shame and loneliness keep us away from living life fully. Our loneliness is perpetuated as we continue to live with a facade, rather than letting others see our raw, unedited self.\"</p> </li> <li> <p>\"When you have a grasp on eternity your eyes won't ever see the battle or the lost people that hurt you. You will see a beautiful story of hope, in every character.\"</p> </li> <li> <p>\"We feel that we are not a big enough container for our dreams, and we are so used to the disquiet longings in solitude that the idea of getting what we want terrifies us.\"</p> </li> <li> <p>\"Instead of being fixated on the wrong that had been done to me\u2014 the obsession to return to innocence\u2014 I began to see my heartbreaks as necessary. Without them, I would never have known true belonging, which is inclusive of exile, not in spite of it.\"</p> </li> <li> <p>\"It may seem paradoxical at first glance, but the answer to healing from defensive non-attachment is actually to affirm our ultimate autonomy and resilience. We push away good things in life because deep down, we worry that we would not survive losses and heartbreaks. If we know we are strong enough to go through grieve, disappointment and heartbreaks, then placing our trust in someone's hand would become much less threatening. To melt away our armour, we ought to feel safe and grounded within ourselves. We could allow ourselves to graduate from a child-like way of need, into a mature, grounded way of relating. As an adult, the basis of our courage to trust and to love does not lie in the hands of others but our strengths. It is not that we have the blind faith that others will not hurt, disappointment or betray us, but we trust that we could grieve, digest the disaster, and bounce back from it. Unlike the helpless child we once were, we are more resourceful, resilient and adaptable than we think we are. We do not have to fear dependency, for we are never truly dependent on another. We are both dependent and independent\u2014 and when the time comes, we can summon the strength that is needed to adapt. As children, we need from others utmost reliability, consistency and availability. As adults, we rely on our ability to self-contain and self-soothe. Unlike a child, we know that people can break promises, withhold their love, and change the way they act. But rather than counting on others to create a haven for us, we do that for ourselves. We no longer need our partner to guess our needs, fulfil our desires or stand up for us, but we can assert ourselves to the world. We may also become aware of our deprived needs as a child and the longings, and become our own best parents. We no longer live in fear of 'being dropped' as a baby would be; we stand on our own two feet. Rather than being pulled by insatiable hunger, we simply appreciate the love, attention and respect offered by others when they are freely given. Then, our understanding of relationships becomes much more nuanced We do not need absolute safety and certainty, we can hold the paradoxes of trust and disappointment, separation and attachment, and find our ways in the flux of life.\"</p> </li> <li> <p>\"To love at all is to be vulnerable. Love anything, and your heart will be wrung and possibly broken. If you want to make sure of keeping it intact you must give it to no one, not even an animal. Wrap it carefully round with hobbies and little luxuries; avoid all entanglements. Lock it up safe in the casket or coffin of your selfishness. But in that casket, safe, dark, motionless, airless, it will change. It will not be broken; it will become unbreakable, impenetrable, irredeemable. To love is to be vulnerable.\"</p> </li> <li> <p>\"He is terribly afraid of dying because he hasn't yet lived.\"</p> </li> <li> <p>\"We can easily forgive a child who is afraid of the dark; the real tragedy of life is when men are afraid of the light.\"</p> </li> <li> <p>\"In Hyper-criticalness, you have designed your life to meet very high standards about most things. These might have been standards you have internalized from other sources like your parents or competitive schooling, but they now feel like 'yours'. You constantly feel like you must be doing something, producing something, and achieving something. You struggle to slow down or relax. In order to meet your own standards, you may sacrifice health, leisure, and relationships. You are perfectionistic and would notice the smallest thing that does not align with the bigger picture. You might also be preoccupied with speed and efficiency and feel anxious if you think you might be wasting time. You may impose a lot of rules, moral standards, and 'shoulds' on yourself and others. Even you know being critical of others is detrimental to your relationship, you cannot help yourself.\"</p> </li> <li> <p>\"Things ain't really been sweet for me, I lost that piece of me, I don't think that's peace for me, that might not be meant for me, my heart not something they need and your love not something I need, tough love when you come around me, I'm the bad guy if that's what they need\"</p> </li> <li> <p>\"Are you looking to move onwards and upwards or run away? Look before you leap, you don't want to appear the fool do you?\"</p> </li> <li> <p>\"The suffering manifested in your life is you taking on a portion of the collective darkness, you do not deserve this suffering, this is the same as a firefighter going to fight the flames Its even harder if you dont remember you are a firefighter and you find yourself amidst the flames, if you can face the pain in your life with positivity, with light, you are helping this entire planet, every single human being is being helped by that, does this make sense?\"</p> </li> <li> <p>\"You are the Universe in the way that a wave is to the ocean. You are of the ocean but a wave.\"</p> </li> <li> <p>\"We seldom see where the chapters of our lives begin and end until we are gifted the benediction of hindsight. So I\u2019m having my adventures and moving further on the path so I can get that hindsight.\"</p> </li> <li> <p>\"Something I remind myself often is that rejection is simply a redirection.\"</p> </li> <li> <p>\"Dreams are like paper kites, with them do our hopes take flight, sailing high above the clouds, they yearn for something more profound,,yet try we may and try we might, a deeper truth waits in plain sight, though we hang our hopes in skies abound, many joys lie on the ground.\"</p> </li> <li> <p>\"Humans have nothing but unknowns. Even if they act like they know everything, that's surely a lie. That's why there's no way but to spend your whole life learning it. There's plenty of wisdom you won't find in a book, and I agree with your opinion, Lyle.\"</p> </li> <li> <p>\"Humans, you know. Someone who wasn't standing out up to now, when you leave work to them, you see they can suddenly accomplish it? Yeah, that happens. Up to that point, they thought it was fine if they didn't do anything. But when work's left to them, they suddenly feel no one but them can do it. That type.\"</p> </li> <li> <p>\"Lyle, don't think everyone's the same as you. Without thinking of the consequences, there will surely be some who'll attack you just because you look like you have money. Make sure you're firm with monetary exchanges. There were lots of times when I had to give out rewards, and when you end up in that position, it's easy to understand. If you're not reliable in such fields, it will affect your credibility.\"</p> </li> <li> <p>\"Don't just assume that everyone around you is a wise guy like you.\"</p> </li> <li> <p>\"Even here in the Underworld, everybody\u2014even monsters\u2014needed a little attention once in a while.\"</p> </li> <li> <p>\"For some reason sugar and caffeine always calmed down my hyperactive brain.\"</p> </li> <li> <p>\"Percy, the hardest part about being a god is that you must often act indirectly, especially when it comes to your own children. If we were to intervene every time our children had a problem \u2026 well, that would only create more problems and more resentment. But I believe if you give it some thought, you will see that Poseidon has been paying attention to you. He has answered your prayers.\"</p> </li> <li> <p>\"My point is you heroes never change. You accuse us gods of being vain. You should look at yourselves. You take what you want, use whoever you have to, and then you betray everyone around you.\"</p> </li> <li> <p>\"The most dangerous flaws are those which are good in moderation\"</p> </li> <li> <p>\"You see, in times of trouble, even gods can lose faith. They start putting their trust in the wrong things. They stop looking at the big picture and start being selfish. But I'm the goddess of marriage, you see. I'm used to perseverance. You have to rise above the squabbling and chaos, and keep believing. You have to always keep your goals in mind.\"</p> </li> <li> <p>\"Maybe that's why monsters fade,\" I said. \"Maybe it's not about what the mortals believe. Maybe it's because you give up on yourself.\"</p> </li> <li> <p>\"It isn't easy being a brilliant inventor,\" Hephaestus rumbled. \"Always alone. Always misunderstood. Easy to turn bitter, make horrible mistakes. People are more difficult to work with than machines. And when you break a person, he can't be fixed.\"</p> </li> <li> <p>\"I don't know if Daedalus will help you, lad, but don't judge someone until you've stood at his forge and worked with his hammer, eh?\"</p> </li> <li> <p>\"A real artist must be good at many things.\"</p> </li> <li> <p>\"I picked up Pandora's jar. The spirit of Hope fluttered inside, trying to warm the cold container. \"Hestia,\" I said, \"I give this to you as an offering.\" The goddess tilted her head. \"I am the least of the gods. Why would you trust me with this?\" \"You're the last Olympian,\" I said. \"And the most important.\" \"And why is that, Percy Jackson?\" \"Because Hope survives best at the hearth\"</p> </li> <li> <p>\"there are times when you have to light one fire to put out another. There are no drugs that will make you immune to stress or to pain, or that will by themselves magically solve your life's problems or promote healing. It will take conscious effort on your part to move in a direction of healing, inner peace, and well-being. This means learning to work with the very stress and pain that are causing you to suffer.\"</p> </li> <li> <p>\"You can't sail straight into the wind, and if you only know how to sail with the wind at your back, you will only go where the wind blows you. But if you know how to use the wind's energy and are patient, you can sometimes get where you want to go. You can still be in control.\"</p> </li> <li> <p>\"To a great extent, our ability to influence our circumstances depends on how we see things. Our beliefs about ourselves and about our own capabilities as well as how we see the world and the forces at play in it all affect what we will find possible. How we see things affects how much energy we have for doing things and our choices about where to channel what energy we do have.\"</p> </li> <li> <p>\"Some of our biggest stresses actually come from our reactions to the smallest, most insignificant events when they threaten our sense of control in one way or another: the car breaking down just when you have someplace important to go, your children not listening to you for the tenth time in as many minutes, long lines at the supermarket checkout.\"</p> </li> <li> <p>\"As is so often the case, the public hero that others admire can leave quite a trail of private hurt in his wake.\"</p> </li> <li> <p>\"life is always in flux, that everything we think is permanent is actually only temporary and constantly changing. This includes our ideas, our opinions, our relationships, our jobs, our possessions, our creations, our bodies, everything.\"</p> </li> <li> <p>\"Each person, without exception, has a unique story that gives meaning and coherence to that person's perception of his or her life, illness, and pain, and what he or she believes is possible.\"</p> </li> <li> <p>\"You can observe a lot by just watching.\"</p> </li> <li> <p>\"a map is not the territory it portrays. \"</p> </li> <li> <p>\"Much of the time you may get away with being only partially conscious like this. At least it seems that way. But what you are missing is more important than you realize. If you are only partially conscious over a period of years, if you habitually run through your moments without being fully in them, you may miss some of the most precious experiences of your life, such as connecting with the people you love, or with sunsets or the crisp morning air.\"</p> </li> <li> <p>\"In reality we are being driven by our likes and dislikes, totally unaware of the tyranny of our own thoughts and the self-destructive behaviors they often result in.\"</p> </li> <li> <p>\"The means and the end of meditation are really the same.\"</p> </li> <li> <p>\"Patience can be a particularly helpful quality to invoke when the mind is agitated. It can help us to accept this wandering tendency of the mind while reminding us that we don't have to get caught up in its travels. Practicing patience reminds us that we don't have to fill up our moments with activity and with more thinking in order for them to be rich. In fact, it helps us to remember that quite the opposite is true. To be patient is simply to be completely open to each moment, accepting it in its fullness, knowing that, like the butterfly, things can only unfold in their own time.\"</p> </li> <li> <p>\"open, \"beginner's\" mind allows us to be receptive to new possibilities and prevents us from getting stuck in the rut of our own expertise, which often thinks it knows more than it does. No moment is the same as any other. Each is unique and contains unique possibilities. Beginner's mind reminds us of this simple truth.\"</p> </li> <li> <p>\"Perhaps it's time to acknowledge that escaping into the woods as a response to a typical, innocently asked Monday-morning question is not a viable option. Instead, I will have to respond.\"</p> </li> <li> <p>\"Goodness me, the social faux pas were I to respond honestly!\"</p> </li> <li> <p>\"After all, if they truly wanted me to do something, wouldn't they ask, rather than just hint in such a vague way? The whole thing is so fraught with uncertainty: even if I had spotted the implication, it's likely I'd then spend a frantic few moments second-guessing myself in a panic \u2013 'But what if they don't mean that and I end up looking presumptuous?' \u2013 by which time they've probably given up and closed the window themselves.\"</p> </li> <li> <p>\"By responding with a 'Fine, thanks', I will have lied twice. Once with the 'fine' \u2013 my weekend was awful and I'm still feeling terrible about it (hence the huge coffee) \u2013 and second with the 'thanks' \u2013 I've nothing to be thankful for here: they've just forced me to lie about my feelings when I would rather have said nothing at all.\"</p> </li> <li> <p>\"It's a process I'm very familiar with, whereby I consider every possible likely outcome that I can imagine, and try to figure out how I'll cope with it should it come to pass, rather like when Doctor Strange visits millions of future timelines searching for the one where the Avengers win the day.\"</p> </li> <li> <p>\"We tend to slide from crisis to crisis when talking to people, and behind it all is a brain whirring over the potential problems, analysing every facet.\"</p> </li> <li> <p>\"The fact is, there's no discernible logic to turn-taking in neurotypical conversation. It just happens, and it happens fairly well, with interactions only occasionally going wrong. If\"</p> </li> <li> <p>\"The problem is that the earnest zeal with which we approach our favourite things is very rarely matched by the neurotypical listener. I've often pondered whether neurotypical people are even capable of the same intense level of interest in a topic.\"</p> </li> <li> <p>\"We may struggle to identify others' emotions (and our own, truth be told), but I wager most autistic people will eventually notice the boredom on the face of the person we're sharing with \u2013 usually because it's paired with them telling us to shut the hell up. This hurts. We love our interests and much of the time see them as one of the only topics worth discussing \u2013 I mean, surely it's better than small talk? \u2013 and talking about them is so intensely joyful, as well as being cathartic and stress-relieving.\"</p> </li> <li> <p>\"It always feels to me that the neurotypical world puts arbitrary limits on how passionate one is 'allowed' to be about a subject. Crossing this line is a social faux pas that ranks somewhere around telling inappropriate jokes at a funeral, but it isn't based on anything real or important.\"</p> </li> <li> <p>\"though autistic people may struggle to understand neurotypical viewpoints, neurotypicals have just as much difficulty understanding us. The difference is that we're hyper-aware of our struggle and go out of our way to compensate for the difference, while you lot (with the greatest respect) don't seem to have a bloody clue.\"</p> </li> <li> <p>\"There's something about eye contact in Western society that's peculiar, at least to my autistic eyes. It seems to be held in such high regard for something so fleeting and ambiguous, and the general rule of thumb appears to be that eye contact equals trustworthiness. Far be it from me to question such a bizarre belief (as if liars are incapable of eye contact, and that's their singular weakness \u2026); it's enough to note that there are many good reasons why eye contact may be impossible at any given moment, and that placing such high value upon it might therefore be rather ill-advised.\"</p> </li> <li> <p>\"Masking is something that almost all autistic people will learn to do at some point in their life. It often begins in childhood when we realise that something is apparently 'wrong' with us. We notice that our social skills don't seem to cut it, that we're frequently at a loss to understand what's going on, and that our attempts to make and keep friends are clumsier or less successful than our peers. We learn that the depth of our interests and the way we express that passion is unacceptable to everyone else, and that our sensory sensitivity annoys people who don't seem to ever want to understand it. Frequently, we're mistreated because of all or some of these things; sometimes we're bullied; occasionally even abused. In this apparently life-or-death situation, it becomes clear to us that we're going to have to adapt, and so, usually by ourselves and with very little assistance from anyone else, we learn to mask. We learn to adopt a kind of persona \u2013 based on all the things our extremely observant brains have noticed in other people \u2013 in order to please those around us so they stop bullying us or causing us harm.\"</p> </li> <li> <p>\"Autistic people frequently report using elements of personalities they observe \u2013 a friend, perhaps, or even a favourite fictional character \u2013 as building blocks for their mask, almost as if we're constructing them out of LEGO bricks, and I can certainly empathise with this. I would study (still do, though at least now I'm more aware of what I'm doing) personalities with the care of a collector, trying things on like a shopper in the market for a new pair of jeans.\"</p> </li> <li> <p>\"Often \u2013 and I did this myself, without being aware of it \u2013 we instinctively relax a little on finding out we're autistic. There's a strange catharsis in finding out you're neurodivergent, a kind of epiphany that there's a reason why things are the way they are. As a result, we exhale for the first time in years, lean into our autistic traits a little, let our mask slip and \u2026 well, we pay the price almost immediately. We learn very quickly that our unmasked selves are simply not welcome and so we hurriedly fix our masks back on \u2013 nail them firm for fear of them dislodging \u2013 and realise we'll never be free to be ourselves. I think of all the concepts elaborated in this book,\"</p> </li> <li> <p>\"(it's amazing how cruel a person can be to themselves when trying to explain behaviour caused by a disability they don't know they have).\"</p> </li> <li> <p>\"Autistic people must be allowed to self-isolate in order to recuperate.\"</p> </li> <li> <p>\"Phone calls are like entertainment radio: dead air is a crime.\"</p> </li> <li> <p>\"Autistic people regularly report feeling like 'emotional sponges' \u2013 upon walking into a room where some kind of conflict has taken place, we'll so frequently immediately take on board all of that negative emotion (some might call it the 'vibe' or 'atmosphere') that it can result in our having to sit down, or even bursting into tears.\"</p> </li> <li> <p>\"Many autistic people report having what we've collectively labelled 'hyper-empathy' \u2013 a kind of extreme set of emotional responses to people and animals in dangerous or upsetting situations. I mentioned my strong response to seeing children in distress earlier, but it's by no means limited to that. Other interesting features of this type of autistic empathy might include extreme empathy (and I mean extreme) towards animals.\"</p> </li> <li> <p>\"For now, the myth of autistic introversion endures, and sociable autistic people continue to be tarred by that brush, from school age all the way up to retirement. Autistic children at school, spending every lunch and breaktime alone hiding in the library or in some undiscovered nook under the stairs, are not seen as sources for concern. 'It's OK,' teachers may reason, 'they're autistic.' As such they fly low and under the radar, their intense loneliness eventually metastasising into something more dangerous \u2013 depression.\"</p> </li> <li> <p>\"we seek to replicate success when we experience it, right down to the minutiae.\"</p> </li> <li> <p>\"Everyone has a fairly standard morning routine of course \u2013 the classic 'shit, shower, shave' is testament to that, though why anyone would shave after a shower is beyond me. But how many of these people would fear their entire day is going to come crashing down if they accidentally or by necessity swap around the order a little, or, worse, miss something out altogether? If I miss a segment of my morning ritual \u2013 for example, the bit where I sit down on the living-room sofa with a coffee and check Twitter groggily \u2013 then I'll feel intensely uncomfortable for hours after, a similar feeling to knowing you've left the gas hob on and you're two hours from home, a kind of jumpy, extreme anxiety based on a fear that something truly terrible will ensue from your own foolishness.\"</p> </li> <li> <p>\"It takes enormous amounts of time and energy to switch focus as an autistic person. I've likened it in the past to turning circles for vehicles. Neurotypicals are able to switch tasks as easily as a car can make a U-turn. Autistic people, on the other hand, seem to make U-turns at the same pace as an ocean liner, requiring huge amounts of patience.\"</p> </li> <li> <p>\"An autistic person will have their issues around changing tasks and changing focus, but will eventually manage these on their own terms (with care and a peaceful setting, ideally). Interrupt that slow, gentle process with an external question, demand or event (a partner asking for something, a phone ringing, a knock at the door), however, and all hell breaks loose internally. That slow process, the cruise liner turning about \u2013 as painstaking as carefully untangling Christmas lights in early December \u2013 is suddenly broken. Our hyperfocus is disturbed and our mood follows a predictable path. The result is likely to be anger, irritation, despair or actual pain; the social relationship with the person making the demand is tarnished and possibly broken, and the cycle continues towards desperately trying to avoid that situation ever, ever happening again. PDA as we know it is born.\"</p> </li> <li> <p>\"I suppose this is a big part of the problem: we autistic people find little workarounds, tricks and bespoke solutions to our personal difficulties. Yet these are often ever-so-slightly odd, meaning that when neurotypical people spot us in the act they may assume that we're up to no good, in that peculiarly pessimistic way that they have.\"</p> </li> <li> <p>\"Beyond the need for a place to hide and recuperate, special interests enable us to focus our brains in a strangely pleasurable way. When the constant demand of looking at the 'big picture' in life gets too much and too boring, the ability to tweak our brain's lens to precisely focus our laser-like attention on something specific is a wonderful feeling, rather like it's allowing our brain to do what's natural for it, rather than expecting it to cope with the wide view, which can feel so \u2026 false.\"</p> </li> <li> <p>\"We approach the world like laser beams, I suppose, rather than wider car headlights or floodlights, with everything within the narrow focus of our attention drilled down into its very depths. And this\"</p> </li> <li> <p>\"Autism is called an 'invisible disability', and sometimes I think that term might be more literal than we realise.\"</p> </li> <li> <p>\"Because of how poorly the school was accommodating my particular neurodivergence, I was forced to rebel and lie and dissemble, despite the fact that doing so went against every law-abiding, if clumsy, bone in my body. Why couldn't they allow me to play sports that weren't team games \u2013 like badminton or tennis \u2013 or ones that were more ordered and structured, like athletics? Why was it always football and rugby, for goodness's sake?\"</p> </li> <li> <p>\"No one ever asked me if I really wanted to do it; but then, I didn't ask myself either.\"</p> </li> <li> <p>\"Authority and hierarchy are social constructs and, as I've been at pains to point out, autistic people have our own, different, culture that doesn't seem to include it.\"</p> </li> <li> <p>\"And so, like an archaeologist drawing conclusions about the past from the evidence of the present day, I can say with some certainty that I must have realised that I had to hide my stims at some point. Why else would they be so subtle, so 'inoffensive'?\"</p> </li> <li> <p>\"Autistic people often seem to have a very deep and strong sense of what's right, what's reasonable and what's fair. This is not to say that we're unerring moral arbiters; after all, our sense of what's fair may be affected by any number of factors, such as privilege, experience, upbringing and so on, and therefore not match others' opinions and values. Nevertheless, the strength of feeling and conviction is likely to be a feature for many autistic people.\"</p> </li> <li> <p>\"In my experience, autistic people are good pattern spotters and often excellent at working out the rules of any given situation. This is what makes us so good at masking, after all. We figure out the rules, and then we play the game. The problem is that figuring out the rules doesn't prepare you for how to handle those who decide to cheat.\"</p> </li> <li> <p>\"I find that when my stress levels reach a particular point, my voice begins to falter as a tool, becoming less reliable and less focused, and I begin to lose my vocabulary and grammar. The spoken word is by no means guaranteed in the autistic community, and we don't deserve to be overlooked as a result of this.\"</p> </li> <li> <p>\"When the ears of the student are ready to hear, then cometh the lips to fill them with wisdom.\"</p> </li> <li> <p>\"The lips of Wisdom are closed, except to the ears of Understanding.\"</p> </li> <li> <p>\"Everything is Dual; everything has poles; everything has its pair of opposites; like and unlike are the same; opposites are identical in nature, but different in degree; extremes meet; all truths are but half-truths; all paradoxes may be reconciled.\"</p> </li> <li> <p>\"Everything flows, out and in; everything has its tides; all things rise and fall; the pendulum-swing manifests in everything; the measure of the swing to the right is the measure of the swing to the left; rhythm compensates\"</p> </li> <li> <p>\"To the pure, all things are pure; to the base, all things are base.\"</p> </li> <li> <p>\"Nothing endures but Change.\"</p> </li> <li> <p>\"And still more presumptuous are those who attempt to ascribe to THE ALL the personality, qualities, properties, characteristics and attributes of themselves, ascribing to THE ALL the human emotions, feelings, and characteristics, even down to the pettiest qualities of mankind, such as jealousy, susceptibility to flattery and praise, desire for offerings and worship, and all the other survivals from the days of the childhood of the race. Such ideas are not worthy of grown men and women, and are rapidly being discarded.\"</p> </li> <li> <p>\"Nothing can rise higher than its source\u2014nothing is evolved unless it is involved\u2014nothing manifests in the effect, unless it is in the cause.\"</p> </li> <li> <p>\"But do not yield to the temptation which, as The Kybalion states, overcomes the half-wise and which causes them to be hypnotized by the apparent unreality of things, the consequence being that they wander about like dream-people dwelling in a world of dreams, ignoring the practical work and life of man, the end being that \"they are broken against the rocks and torn asunder by the elements, by reason of their folly.\"</p> </li> <li> <p>\"Transmutation, not presumptuous denial, is the weapon of the Master.\"</p> </li> <li> <p>\"And, in the degree that Man realizes the existence of the Indwelling Spirit immanent within his being, so will he rise in the spiritual scale of life. This is what spiritual development means\u2014the recognition, realization, and manifestation of the Spirit within us.\"</p> </li> <li> <p>\"I must create a system or be enslaved by another man's; I will not reason and compare: my business is to create.\"</p> </li> <li> <p>\"Disney had reinterpreted Christianity for mass culture.\"</p> </li> <li> <p>\"In numerous ways Disney struck what may be the very fundament of entertainment: the promise of a perfect world that conforms to our wishes.\"</p> </li> <li> <p>\"In an idealized world where wish fulfillment prevailed, Disney had consistently concretized the ideal and provided the pleasure of things made simple and pure the way one imagined they should be, or at least the way one imagined they should be from childhood.\"</p> </li> <li> <p>\"Whether in his movies or in his theme parks, Disney always promised a fantasy in which one could exercise the privileges of childhood\u2014privileges he never abandoned in his own life. This will to power also explained why animation was his preferred medium. In animation one took the inanimate and brought it to life, or the illusion of life. In animation one could exercise the power of a god.\"</p> </li> <li> <p>\"Disney's best animations\u2014Snow White and the Seven Dwarfs, Pinocchio, Bambi, and Dumbo\u2014were archetypal expressions of this idea. In large measure, they were about the process of a child making his or her claim upon the world, about the process of overcoming obstacles to become whatever he or she wanted to be.\"</p> </li> <li> <p>\"'In this life you only have a set number of chances. If you grab them when they appear, you'll succeed. If you don't, you'll be doomed to a life of mediocrity.'\"</p> </li> <li> <p>\"Isn't it enough to see that a garden is beautiful without having to believe that there are fairies at the bottom of it too?\"</p> </li> <li> <p>\"I mean, what's the use of our sitting up half the night arguing that there may or may not be a God if this machine only goes and gives you his bleeding phone number the next morning?\"</p> </li> <li> <p>\"Perhaps I'm old and tired,\" he continued, \"but I always think that the chances of finding out what really is going on are so absurdly remote that the only thing to do is to say hang the sense of it and just keep yourself occupied. Look at me: I design coastlines. I got an award for Norway.\"</p> </li> <li> <p>\"The History of every major Galactic Civilization tends to pass through three distinct and recognizable phases, those of Survival, Inquiry and Sophistication, otherwise known as the How, Why and Where phases. \"For instance, the first phase is characterized by the question How can we eat? the second by the question Why do we eat? and the third by the question Where shall we have lunch?\"</p> </li> <li> <p>\"if life is going to exist in a Universe of this size, then the one thing it cannot afford to have is a sense of proportion.\"</p> </li> <li> <p>\"The trouble with most forms of transport, he thought, is basically that not one of them is worth all the bother.\"</p> </li> <li> <p>\"Life was, in short, ridiculously easy and for a while at least they were able to cope with the problems of aimlessness and isolation by deciding to ignore them. When the craving for company became too great they would know where to find it, but for the moment they were happy to feel that the Golgafrinchans were hundreds of miles behind them.\"</p> </li> <li> <p>\"History is never altered you see, it just fits together like a jigsaw. Funny old thing, life, isn't it?\"</p> </li> <li> <p>\"Sometimes, all it takes is taking a leap of faith and enjoying the adventure.\"</p> </li> <li> <p>\"Elden Ring's story will still have its special place in my heart. The whole story about this world is a story of gods, greater beings so above the little mortals they pretend to protect, but the end if the game is precisely about the opposite, those small beings each having their own wishes and desires, and deciding what the world should be instead of those eldritch entities. You can rule by yourself an imperfect world, after the greater will is forced to renounce his control over life or death to keep itself here. A scorned woman can choose her own god of undeath, to change the place of the tarnished as oppressed to rulers. The mad prisoner can take his revenge upon the world, by cursing all things so the greater being lose all control over the souls of this land. A silent prophet, with no name for himself, can repare the golden order by himself at the cost of his life, when a goddess like Marika was never capable of it. You and Ranni, the demigoddess spurning the control of the greater will, can together take the gods out of this land to travel far away, and let the Lands Between decide its own fate. Or you can make true the wish of the burning eyed believers, and scorch the whole world to return to the origin of life itself, the ultimate price to shatter the greater will invasion.\"</p> </li> <li> <p>\"The game make you think it's a story about gods, Marika's bloodline, heroes of forgotten time, but it's in fact a story of how those small nobodies spurned by grace that are the Tarnished will have the last words, at the end of a long journey.\"</p> </li> <li> <p>\"Not putting your heart and mind into sword practice makes one merely a slave of the sword\"</p> </li> <li> <p>\"King Calm Sea once told me\"\u2014Fairy Meng looked at Meng Chuan and continued\u2014\"that cultivation requires one to follow one's intuition and follow what one likes the most before forging forward. You will go further and further. When you look back after a few decades, you would've far surpassed your former self. I'll share this saying with you as well. Follow your heart and proceed down what you like the most.\"</p> </li> <li> <p>\"Qi will only move when the mind moves. If the mind does not move, then Qi will also remain still!\"</p> </li> <li> <p>\"Okay, stop getting downcast. If you can't figure things out at the moment, stop mulling over it and think about it again when your head is clearer. Like the old people say, even if the sky collapses, there's nothing to be afraid of. If worst comes to worst, may it be.\"</p> </li> <li> <p>\"To elevate yourself as a sheepdog amongst a herd of sheeps, you have to understand the rules set by the shepherd. Only if you can understand the rules, can you become a shepherd. If you can't do either, then your only fate is to toil all your life in a sheep pen. If the shepherd is cold, your wool will be shaved for him. This is called selflessness. If the shepherd is hungry, you shall lay on the butcher block and scream your devotion for his cause\"</p> </li> <li> <p>\"Three millennia of recorded history, fraught with power, lust, and greed. Ninety thousand miles of meditation, only to return to gardening, wine and poetry\"</p> </li> <li> <p>\"A man does not mature into pragmatism; he simply accepts reality more readily. \"</p> </li> <li> <p>\"If love lives on sharing and chains you like fetters Then hate, more than anything, depends on freedom.\" Love and hate coiling and twisting together. Tell me, what can I do to save you? If love is spilt milk, Then who can protect whom? For whom will my heart wait? Tell me, what can I do to save you?  If passion is a fatal poison, Then who can protect whom? How can I make this love immortal?\"</p> </li> <li> <p>\"The maturity of a man ought not to come from his own pragmatism, but rather from his ability to accept this trait shown in others. To become gentle, gentle toward others, to let go of grudges and to look at the world with a pair of sympathetic eyes and a compassionate heart. It was not about how many epigrams one could spew out to indicate that they had reached a higher level of wisdom, or about one's ability to convince others with impressive speech, but rather about the habit of blaming others less and understanding them more. The true sign of maturity was tolerance and the absence of animosity... Those from the top did not compete, whereas those at the bottom fought for every inch. A man of virtue does not show it, whereas those purporting it will flaunt constantly.\"</p> </li> <li> <p>\"the freight of friendship sails for the distance, and the solidarity between brothers outlives heaven and earth...\"</p> </li> <li> <p>\"He had learnt that the most important trait of maturity was to be able to joke about everyone, including himself.\"</p> </li> <li> <p>\"Being a guardian is all about protecting the way, seeing the way and focusing on it. If Heaven's Laws shows you the way, then what is there to doubt, even when facing death? Good luck\"</p> </li> <li> <p>\"When it comes to helping others, it is the thought that matters. Kindness, no matter how insignificant it can seem at the moment, can often steer one's life into another, and usually better direction.\"</p> </li> <li> <p>\"Though bones and minds were chained You cut down the thorns again and again Your pride will not be slain From the heart to the veins\"</p> </li> <li> <p>\"Our journey begins anew. Life passes like a fleeting rain, eventually merging with the ground. May our next encounter be... under a clear sky.\"</p> </li> <li> <p>\"Our existence is fleeting as dawn's dew, destined for oblivion. On the still waters of oblivion, I guide the wandering souls. \"</p> </li> <li> <p>\"I weep for the departed... Stream forth... The gleam of old blades Restore this lost memory... Apply, your color.\"</p> </li> <li> <p>\"Everyone has a past. But for some, their past is a silent abyss filled with those who drowned in it\"</p> </li> <li> <p>\"Do not go searching for what doesn't want to be found. For in order to not be found, what doesn't want to be seen will go through extreme measures to make sure that all who go searching... will wind up not being found.\"</p> </li> <li> <p>\u201cThe sun sets above the blue mountain, the autumn moon with the wind of spring. The morning is fine like hair and night is like snow, whether you succeed or fail when you look back there\u2019s nothing left.\u201d</p> </li> <li> <p>\"Painting is just that. Taking what looks shit, look less shit until it suddenly starts to look good.\"</p> </li> </ul>"},{"location":"KB/random%20dump/","title":"Random Dump","text":""},{"location":"KB/random%20dump/#random-dump","title":"Random Dump","text":""},{"location":"KB/regularize/","title":"Regularize","text":""},{"location":"KB/regularize/#categories-anchor","title":"categories: ['anchor']","text":"<ul> <li>./AdaIn.md</li> <li>./Adam.md</li> <li>Batch Normalization.md</li> <li>./DeepNorm.md</li> <li>./Dropout.md</li> <li>Effects of Regularization.md</li> <li>Fine Tuning Based Pruning.md</li> <li>Global Gradient Magnitude Based Pruning.md</li> <li>Global Magnitude Based Pruning.md</li> <li>He Initialization.md</li> <li>Label Smoothing.md</li> <li>Layer Normalization.md</li> <li>Layerwise Gradient Magnitude Based Pruning.md</li> <li>Layerwise Magnitude Based Pruning.md</li> <li>LeCun Init.md</li> <li>Leaky Relu.md</li> <li>Learning Rate Range Test.md</li> <li>Lp Regularization.md</li> <li>./Mixup.md</li> <li>Modality Dropout.md</li> <li>No bias decay.md</li> <li>./Optimizers.md</li> <li>Orthogonal Initialization.md</li> <li>./Pruning.md</li> <li>Random Pruning.md</li> <li>Regularization Term.md</li> <li>./Regularization.md</li> <li>./Scheduling.md</li> <li>Scoring Pruning Approaches.md</li> <li>Structure Based Pruning.md</li> <li>Tuning Model Flexibility.md</li> <li>VariationalRecurrent Dropout.md</li> <li>Weight Decay Vs L2 Regularization.md</li> <li>Xavier Initialization.md</li> </ul>"},{"location":"KB/robotics/","title":"Robotics","text":""},{"location":"KB/robotics/#categories-anchor","title":"categories: ['anchor']","text":"<ul> <li>Action Component.md</li> <li>Active Compliant Robot.md</li> <li>./Actuator.md</li> <li>Affordance Detection Task Specific.md</li> <li>./Anthropomorphic.md</li> <li>Articulated Manipulator.md</li> <li>./Articulation.md</li> <li>Assembly Robot.md</li> <li>Average Number of Stored Instances per Category.md</li> <li>Bag of Words robotics.md</li> <li>Base Link.md</li> <li>./Burn-in.md</li> <li>./Carousel.md</li> <li>Centrifugal Force.md</li> <li>Circular Motion Type.md</li> <li>./Clamp.md</li> <li>./Clamping.md</li> <li>Compliant Robot.md</li> <li>Contact Sensor.md</li> <li>Continuous Path.md</li> <li>Cyclo Drive.md</li> <li>Cylindrical Topology.md</li> <li>Degrees of Freedom.md</li> <li>./Direct-drive.md</li> <li>Drop Delivery.md</li> <li>Dual-memory Approach.md</li> <li>Enabling Device.md</li> <li>./End-effector.md</li> <li>./Endpoint.md</li> <li>Ensemble of Shape Functions.md</li> <li>Eye-to-hand System.md</li> <li>Familar Object Grasping Object Viiew recog.md</li> <li>Fine-grained Object Recognition.md</li> <li>./Forgetting.md</li> <li>Forward Kinematic Solution.md</li> <li>Forward Kinematics.md</li> <li>./GGCNN.md</li> <li>./GRConvNet.md</li> <li>Gantry Robot.md</li> <li>Global Classification Accuracy.md</li> <li>Grasp Point Detection.md</li> <li>Gravity Loading.md</li> <li>./Gripper.md</li> <li>Hand Guiding.md</li> <li>Harmonic Drive.md</li> <li>./Harness.md</li> <li>Heightmaps Kinesthetic.md</li> <li>Humanoid Vision Engine.md</li> <li>Inductive Sensor.md</li> <li>Instance-based Learning.md</li> <li>Instruction Cycle.md</li> <li>Inverse Kinematics.md</li> <li>Inverse Reinforcement Learning.md</li> <li>Iterative Closest Point.md</li> <li>Joint Interpolated Motion.md</li> <li>Joint Motion Type.md</li> <li>Joint Space.md</li> <li>Joint Velocity.md</li> <li>Kalman Filter.md</li> <li>Kinesthetic Teaching.md</li> <li>Ladle Gripper.md</li> <li>Learning Component.md</li> <li>Learning to Detect Grasp Affordance.md</li> <li>Linear Interpolated Motion.md</li> <li>Load Cycle Time.md</li> <li>Local Descriptor.md</li> <li>Local Reference Frame.md</li> <li>Local-LDA Object Representation.md</li> <li>./MVCNN.md</li> <li>./MVGrasp.md</li> <li>Magnetic Detectors.md</li> <li>./Manipulator.md</li> <li>Material Processing Robot.md</li> <li>Mirror Shift Function.md</li> <li>Mode Switch.md</li> <li>./MoreMVCNN.md</li> <li>Neural Radiance Field.md</li> <li>./Occlusion.md</li> <li>Opportunistic Learning.md</li> <li>Optical Encoder.md</li> <li>Optical Proximity Sensors.md</li> <li>./OrthographicNet.md</li> <li>./Palletizing.md</li> <li>Parallel Shift Function.md</li> <li>Particle Filter.md</li> <li>Pendant Teaching.md</li> <li>Perception Component.md</li> <li>Perceptual Messages.md</li> <li>Phases of Simulated User Experiments.md</li> <li>Pick and Place Cycle.md</li> <li>Pinch Points.md</li> <li>./Point-to-Point.md</li> <li>Polynomial Trajectories.md</li> <li>Power and Force Limiting (PFL).md</li> <li>Presence-sensing Safeguarding Device.md</li> <li>Prismatic Joint.md</li> <li>Programmable Logical Controller (PLC).md</li> <li>Proximity Sensor.md</li> <li>Pulse Coordinates.md</li> <li>Quadratic Potential Field.md</li> <li>Quasi-static Clamping.md</li> <li>./RANSAC.md</li> <li>Reasoning Component.md</li> <li>Revolute Joint.md</li> <li>Risk Mitigation.md</li> <li>Robot Range Limit Monitoring.md</li> <li>Robotic Joints.md</li> <li>./Roll.md</li> <li>Rotary Joint.md</li> <li>Rotary Vector Drive (RV).md</li> <li>./Safeguard.md</li> <li>Safety Integrity Level.md</li> <li>Safety Logic Circuit.md</li> <li>Semantic Data.md</li> <li>Sense-Plan-Act Model.md</li> <li>Sensory Feedback.md</li> <li>Servo Control.md</li> <li>Servo Motor.md</li> <li>Servo Pack.md</li> <li>Servo-controlled Robot.md</li> <li>./Servo-system.md</li> <li>Shock Detection Function.md</li> <li>./Singularity.md</li> <li>Softlimit Setting Function.md</li> <li>Spline Motion Type.md</li> <li>./Spline.md</li> <li>./TSDF.md</li> <li>Task (endeffector) Space Vs Joint Space.md</li> <li>Teach Lock.md</li> <li>The Repulsive Potential.md</li> <li>./Through-beam.md</li> <li>Time Measuring Function.md</li> <li>Trajectory Planning.md</li> <li>./Transducer.md</li> <li>Trapezoidal Trajectory.md</li> <li>Unet Grasping.md</li> <li>Vacuum Cup Hand.md</li> <li>Viewpoint Feature Histogram.md</li> <li>Visual Servo System.md</li> <li>Volumetric Grasping Network.md</li> <li>Work Envelope.md</li> <li>./Wrist.md</li> <li>./Yaw.md</li> </ul>"},{"location":"KB/sacred%20values/","title":"sacred values","text":""},{"location":"KB/sacred%20values/#sacred-values","title":"Sacred Values","text":"<ul> <li>morally forbids the commitment of certain actions regardless of consequences</li> </ul>"},{"location":"KB/swap-dominance/","title":"swap-dominance","text":""},{"location":"KB/swap-dominance/#swap-dominance","title":"Swap-dominance","text":"<ul> <li>when ranking alternatives to form a model of ethical preferences</li> <li>When new decisions need to be made, the summarized model is used to compute a collective decision that results in the best possible outcome</li> </ul>"},{"location":"KB/textless-lib/","title":"textless-lib","text":""},{"location":"KB/textless-lib/#textless-lib","title":"Textless-lib","text":"<ul> <li>textless-lib: a Library for Textless Spoken Language Processing</li> <li>Textless spoken language processing research aims to extend the applicability of standard NLP toolset onto spoken language and languages with few or no textual resources</li> <li>PyTorch</li> <li>speaker probing, (ii) speech resynthesis and compression, and (iii) speech continuation.</li> </ul>"},{"location":"KB/todo/","title":"Todo","text":""},{"location":"KB/todo/#todo","title":"ToDO","text":"<ul> <li>graphs for every loss function and it\u2019s derivative</li> <li>reflow gradient descent document</li> <li>https://github.com/kennethleungty/MLOps-Specialization-Notes</li> </ul>"},{"location":"KB/treecoverSegmentation/","title":"Tree Cover Segmentation","text":""},{"location":"KB/treecoverSegmentation/#tree-cover-segmentation","title":"Tree Cover Segmentation","text":"<ul> <li>treecover segmentation PointNet++<ul> <li>Data collected from above</li> <li>Normalization : height, xy</li> <li>Rotation</li> <li>Jiggling ??</li> <li>Labeling<ul> <li> Segmentation algorithm. Canopy hide model</li> <li>Weighted loss + Focal Loss</li> </ul> </li> </ul> </li> </ul>"},{"location":"KB/treecoverSegmentation/#2d-methods","title":"2d Methods","text":"<ul> <li>Watershed + Unet</li> <li></li> <li><ul> <li>\\(\\Theta\\) is just clippingpng]</li> <li>The sqrt makes it a little smoother</li> </ul> </li> </ul>"},{"location":"KB/treecoverSegmentation/#ref","title":"Ref","text":"<ul> <li>Max Freudenberg - Gottingen Uni Germany</li> <li>Adrian Stroker - Gottingen Uni Germany</li> </ul>"},{"location":"KB/trolley%20scenario/","title":"trolley scenario","text":""},{"location":"KB/trolley%20scenario/#trolley-scenario","title":"Trolley Scenario","text":"<ul> <li>making a participant actively cause harm to an innocent bystander by pushing him on to the train track in order to save the lives of five people</li> </ul>"},{"location":"KB/usermodel/","title":"Usermodel","text":""},{"location":"KB/usermodel/#categories-anchor","title":"categories: ['anchor']","text":"<ul> <li>Algebra Cognitive Tutor.md</li> <li>./Andes.md</li> <li>./AutoTutor.md</li> <li>Coarse-grained assessment.md</li> <li>Collaborative Recommender.md</li> <li>Content Based Recommender.md</li> <li>DT Tutor.md</li> <li>Declarative memory.md</li> <li>Effects of Contextual Cues on Inferring and Remembering Meanings of New Word.md</li> <li>Extensions to SlimStampen.md</li> <li>Eye Tracking.md</li> <li>Filter Bubble Problem.md</li> <li>Final Paper User Models.md</li> <li>Fine Grained assesment.md</li> <li>./GOMS.md</li> <li>Game Based Learning.md</li> <li>./Gamification.md</li> <li>Gaze position.md</li> <li>Grey sheep problem.md</li> <li>Group Modeling Approach.md</li> <li>Help Abuse.md</li> <li>Help Refusal.md</li> <li>./IRT.md</li> <li>Ideas for Fact Learning.md</li> <li>Individual Modeling.md</li> <li>Knowledge Component.md</li> <li>Latent Semantic Analysis.md</li> <li>Learning Event.md</li> <li>Learning L2 German Vocabulary Through Reading.md</li> <li>./Macroadaptation.md</li> <li>Mastery learning.md</li> <li>Modeling Driver Behavior with Cognitive Architecture.md</li> <li>Modeling Transfer.md</li> <li>Predicting Student learning Curve.md</li> <li>Pupil Dilation.md</li> <li>Ramp up problem.md</li> <li>Rational inference.md</li> <li>Recommender System.md</li> <li>./SQL-Tutor.md</li> <li>Satisficing Heuristic.md</li> <li>Second Language Vocabulary Learning , The role of context  versus translation.md</li> <li>Serious Games.md</li> <li>./Sherlock.md</li> <li>./SlimStampen.md</li> <li>./Steve.md</li> <li>The Behavior of Tutoring Systems.md</li> <li>The Effect of Three Consecutive Context Sentences on EFL Vocabulary-Learning.md</li> <li>./Tutor.md</li> <li>plan recognition problem.md</li> </ul>"},{"location":"KB/visualization/","title":"Visualization","text":""},{"location":"KB/visualization/#categories-anchor","title":"categories: ['anchor']","text":"<ul> <li>1D piecewise linear interpolation.md</li> <li>Area Minimization.md</li> <li>Asymptotic Decider.md</li> <li>Average Filter.md</li> <li>Back To Front Raycasting.md</li> <li>Barycentric Interpolation.md</li> <li>Bend Minimization.md</li> <li>Bilinear Interpolation.md</li> <li>Change Blindness.md</li> <li>Characteristics of Visual Variables.md</li> <li>Classification Ray Casting.md</li> <li>Clutter In Visualisation.md</li> <li>Color Compositing.md</li> <li>Color Spaces.md</li> <li>./ColorMap.md</li> <li>Complex Geometry.md</li> <li>./Contour.md</li> <li>Conv Based Noise Reduction.md</li> <li>Countouring with Transparency.md</li> <li>Critical Points.md</li> <li>Cross Minimization.md</li> <li>Cross angle Maximization.md</li> <li>./Cuboids.md</li> <li>Curl And Vorticity.md</li> <li>./Cylinders.md</li> <li>Data Structures.md</li> <li>Diffusion Tensor.md</li> <li>./Divergence.md</li> <li>Divide Oriented.md</li> <li>Early Ray Termination.md</li> <li>./Eigenvector.md</li> <li>./Ellipsoids.md</li> <li>Entourage Plot.md</li> <li>Euler Integration.md</li> <li>Eulerian Grid.md</li> <li>./Filtering.md</li> <li>Finite Differences.md</li> <li>First order integration.md</li> <li>Force Directed Graph Layout.md</li> <li>Fractional Anisotropy.md</li> <li>Front to Back Raycasting.md</li> <li>Gaussian Filter.md</li> <li>Gestalt Laws.md</li> <li>./Glyphs.md</li> <li>./Graphs.md</li> <li>./Grids.md</li> <li>H3 View.md</li> <li>Height Plots.md</li> <li>Helmholtz Theorem.md</li> <li>Hierarchial Refinement.md</li> <li>Hierarchical Edge Bundling.md</li> <li>High pass filter.md</li> <li>./HyperStreamlines.md</li> <li>ICA Noise Removal.md</li> <li>Inattentional Blindness.md</li> <li>./Inceptionism.md</li> <li>Indirect Volume Visualization.md</li> <li>Information Visualization.md</li> <li>Integral Lines.md</li> <li>./Interpolation.md</li> <li>Intuitive Color spaces.md</li> <li>./Isoline.md</li> <li>./Isosurface.md</li> <li>Lagrangian Coherent Structure.md</li> <li>Lagrangian Grid.md</li> <li>Laplacian Grid Smoothing.md</li> <li>Length Optimization.md</li> <li>Line Integral Convolution.md</li> <li>Mapping to Geometry.md</li> <li>Marching Cubes.md</li> <li>Marching Squares.md</li> <li>Marching Tetrahedra.md</li> <li>Mean Diffusivity.md</li> <li>Median Filter.md</li> <li>Mesh Smoothing.md</li> <li>Mesh refinement.md</li> <li>Midpoint Decider.md</li> <li>Midpoint Method.md</li> <li>Node Link Diagram.md</li> <li>Noise Suppression.md</li> <li>Notch filter.md</li> <li>Oblique Slicing.md</li> <li>Opacity Correction.md</li> <li>Orthogonal Slicing.md</li> <li>Parallel Coordinate Plots.md</li> <li>Particle Visualization.md</li> <li>./Pathlines.md</li> <li>./Perception.md</li> <li>Perceptually Uniform.md</li> <li>Phong Lighting.md</li> <li>Post Classification.md</li> <li>Postattentive Amnesia.md</li> <li>Pre Classification.md</li> <li>Pre Integrated Volume Rendering.md</li> <li>Radial Plot.md</li> <li>./Raycasting.md</li> <li>Region Growing.md</li> <li>Runge Kutta.md</li> <li>Sampling Ray Casting.md</li> <li>Scalar Color Coding.md</li> <li>./Shading.md</li> <li>Shepard Interpolation.md</li> <li>Slice Based Volume Rendering.md</li> <li>./Spectrogram.md</li> <li>Stream Ribbons.md</li> <li>Stream Surfaces.md</li> <li>Streamline Stopping Criterion.md</li> <li>./Streamlines.md</li> <li>./SuperQuadrics.md</li> <li>Symmetries Node Link.md</li> <li>Time Dependant Vector Field.md</li> <li>Transfer Function.md</li> <li>./Treemap.md</li> <li>Visual Associative.md</li> <li>Visual Encoding.md</li> <li>Visual Length.md</li> <li>Visual Ordered.md</li> <li>Visual Quantitative.md</li> <li>Visual Selective.md</li> <li>Visualization Of Layers.md</li> <li>Volume Rendering Equation.md</li> <li>Volume Visualization.md</li> <li>Volumetric Illumination.md</li> <li>Voxel Projection.md</li> </ul>"},{"location":"KB/wave2vec/","title":"wave2vec","text":""},{"location":"KB/wave2vec/#wave2vec","title":"wave2vec","text":"<ul> <li>wav2vec: Unsupervised Pre-training for Speech Recognition</li> <li>Reducing the need for manually annotated data is important for developing systems that understand non-English languages, particularly those with limited existing training sets of transcribed speech</li> <li>first application of unsupervised pre-training to speech recognition using a fully convolutional model that learns representations of raw, unlabeled audio</li> <li>trained on large amounts of unlabeled audio data and the resulting representations are then used to improve acoustic model training</li> <li>pre-train a simple multi-layer convolutional neural network optimized via a noise contrastive binary classification task</li> <li>learn the difference between original speech examples and modified versions, often repeating this task hundreds of times for each second of audio, and predicting the correct audio milliseconds into the future</li> <li>beats traditional ASR systems that rely solely on transcribed audio</li> <li>experiments on WSJ reduce WER of a strong character-based log-mel filterbank baseline</li> <li>more data for pre-training improves performance and that this approach not only improves resource-poor setups, but also settings where all WSJ training data is used</li> </ul>"},{"location":"articles/","title":"Articles","text":""},{"location":"articles/#articles","title":"Articles","text":"<ul> <li>This section has open source no paywall versions of every article I write (unless requested for closed source of course)</li> <li>They might not have the images required as those are only available on the source website. BUT if you search for those topics in the Knowledge base, you will find all the material there anyway, with images (most of them)</li> <li>I use this KB as a gateway into writing these articles as well.</li> </ul>"},{"location":"articles/BookNotes/Summary%20-%20Notes%20on%20a%20Nervous%20Planet%20by%20Matt%20Haig/","title":"Summary - Notes on a Nervous Planet by Matt Haig","text":""},{"location":"articles/BookNotes/Summary%20-%20Notes%20on%20a%20Nervous%20Planet%20by%20Matt%20Haig/#chapterwise-summary-30-ways-to-take-back-control-notes-on-a-nervous-planet-by-matt-haig","title":"Chapterwise summary + 30+ ways to take back control : Notes on a Nervous Planet by Matt Haig","text":"<p>Notes on a nervous planet is a book that brings a lot of important points about the collective overwhelm that we as a \u201cmodern\u201d society face. Social media, lack of sleep, odd working hours, loneliness. Neither of these were aspects that we were really prepared to deal with. But before treating a disease, we must know what the symptoms are and why they showed up in the first place. (At the end of the article, there is a long is list of what you can do to avoid overwhelm.)</p> <p>This is a summary and my thoughts (chapter wise, mostly) on the book. I try to cover what stuck out to me the most and in turn, hope that it helps someone out. If you like the summary, you will like the book more. </p> <p>Go support the author here.</p> <p>(Note: This is not sponsored by the author and is a personal opinion that just reflects my own views. Since this is an interpretation, the author might have thought something different in a few places.)</p>"},{"location":"articles/BookNotes/Summary%20-%20Notes%20on%20a%20Nervous%20Planet%20by%20Matt%20Haig/#a-stressed-out-mind-in-a-stressed-out-world","title":"A stressed-out mind in a stressed-out world","text":"<p>As society progresses, we face an overwhelming increase in everything from groceries to people to jobs and somewhere down the line it takes a huge toll on our mental health. Humans weren\u2019t meant to deal with this constant barrage of information. If you stop and look around you, you can almost feel this underlying quit panic. The rush of everyday life, the endless calling out for attention by companies, all of these things wear you down little by little.  Before, if you wanted to find out about what was happening in the world, you would look at the news and be presented with a limited selection of it. These days however, the more attention grabbing headlines are what you see. There is always something horrible happening and this triggers the part of our brains that make us feel unsafe.  You might think that social media is different, but it still does the same thing doesn\u2019t it? It keeps triggering the fear and panic that makes you feel FOMO (fear of missing out), or that someone else\u2019s life is better. After even a few minutes, you might have noticed the guilt and sadness you feel but you can\u2019t stop.  All of these, and the added loneliness it brings, makes us feel like we are in a 24x7 catastrophe. </p>"},{"location":"articles/BookNotes/Summary%20-%20Notes%20on%20a%20Nervous%20Planet%20by%20Matt%20Haig/#the-big-picture","title":"The big picture","text":"<p>Some people blame this on time and modernisation. Which is true, but at the end of the day the main reason for this insanity is just\u2026 consumerism and capitalism. Companies need to grow, and get the \u201cbig bucks\u201d and what better way to do that but constantly keep expanding.  But every expansion has a price, and in this case it\u2019s the sanity of society and the slow extortion of our planet. In time, this mentality has seeped into every aspect of society. Our politicians glorify the \u201chard working families\u201d and our companies glorify endless work hours. To what end? These goalposts are endless. And the constant comparison with everyone else that social media brings just feeds the fire. It\u2019s come to the point that nobody is really ever satisfied. You spend years to work on a degree, and social media convinces you that traveling the world would have been a better idea. You get a great job, a new car, move to a bigger house etc, and your device shows you pictures of even more. The fuel is dissatisfaction and the fire is the need to buy. The need to keep creating and producing.  Doesn\u2019t this remind you of a factory line?</p>"},{"location":"articles/BookNotes/Summary%20-%20Notes%20on%20a%20Nervous%20Planet%20by%20Matt%20Haig/#a-feeling-is-not-your-face","title":"A feeling is not your face","text":"<p>Social media has added a lot to the constant insecurity that we face, and beauty standards have reached an almost ridiculous peak. It\u2019s not just a couple of magazines anymore. We are constantly surrounded by unrealistic body standards. Regardless of your gender, you are shown endless options and made to subconsciously identify with either the \u201cbarbie\u201d, \u201csuperhuman\u201d or some other stereotype based on what you see online. Neither of these are achievable.  If you go to a beach, you might think that the people around you are so concerned with how you look with your shirt off. But in all honesty, most people are thinking the same way. Most people are too concerned with their own appearance to care about yours. And then the beach itself does not care. It\u2019s nature after all. Regardless of what your body looks like, you\u2019re a part of it. It bears no judgement.  Accepting yourself the way you are, and realising that what you see online in unreasonable, goes a pretty long way.</p>"},{"location":"articles/BookNotes/Summary%20-%20Notes%20on%20a%20Nervous%20Planet%20by%20Matt%20Haig/#notes-on-time","title":"Notes on time","text":"<p>Cavemen didn\u2019t particularly care if they were 5 minutes late to a hunting meeting. Time was not quantified to this precision. At some point the sun and the moon guided time. There was day and night, maybe afternoon. Some times were good for the hunt, the others were good for rest and community. As technology marches on, the concept of time becomes ever refined. Now not only are you always \u201clate\u201d, you know exactly how badly you failed within a nanosecond of accuracy. Hello guilt! Deadlines came to exist, and the constant need to check your watch or phone.  Society made time an enemy. \u201cFinish everything before the timer runs out\u201d. Suddenly, you could never achieve enough in the time that you had. Because the more divisions we make, the more we are expected to do to fill them up. We stopped listening to our bodies and became a slave to a ticking clock. It\u2019s time we started going back to a simpler time.</p>"},{"location":"articles/BookNotes/Summary%20-%20Notes%20on%20a%20Nervous%20Planet%20by%20Matt%20Haig/#life-overload","title":"Life overload","text":"<p>It\u2019s not just your sink that gets filled with dishes, your poor brain is struggling to keep up with all this work and information. There is an unnecessary excess in everything and thus your brain needs to constantly make decisions. In turn, everyone around you faces the same thing. If you look it from the outside, it\u2019s almost as if we are all feeding that collective frenzy. The world is heading for a collective breakdown, and in our heart of hearts, we know that we are not just a part of it, we are feeding the fire too. It\u2019s not just life, but an overload of it.</p>"},{"location":"articles/BookNotes/Summary%20-%20Notes%20on%20a%20Nervous%20Planet%20by%20Matt%20Haig/#internet-anxieties","title":"Internet anxieties","text":"<p>Ah the internet. Humanities craziest information. A way to \u201cforever\u201d and almost instantly look up anything. Any think you wanted to know, feel, see or find, all up for grabs. The biggest fuel we have added to the frenzy. But the internet is not always a bad thing is it? So many people have learnt skills, built families, found similar people, started a business and found partners through it. But they have also been pushed opinions that they never knew of. They have been fed with a constant diet of hate, choice, games of power, games of \u201cratings\u201d and a desire for pretence.  On the internet, nobody knows if you are a human or a dog. And it\u2019s so much easier to bully someone if you know you are a continent away and can\u2019t be held accountable. These exacerbate the collective overload. Because now not only do people have the power to play either the victim or the bully, they can see millions of the these stories playing out everyday.  A slowly spreading poison doesn\u2019t kill very fast, but withers you away in time. The only way to go about it is empathy. You cannot avoid the internet but you can choose what you want to actively look for. Simplify, and leave the fighting to the real world.</p>"},{"location":"articles/BookNotes/Summary%20-%20Notes%20on%20a%20Nervous%20Planet%20by%20Matt%20Haig/#shock-of-the-news","title":"Shock of the news","text":"<p>Fear does sell though, and the news profits on that. Wars and death have always been common, but these days? You almost feel like the violence of the world has increased to a ridiculous point. You feel unsafe everywhere you go, 24x7.  A few decades ago, you would get your news twice a day maybe. Now you get it every second, from every possible angle, all across the world. There\u2019s more than 7 billion people and the stories are endless. You don\u2019t hear about one robbery, you hear about them from 10 countries, 300 people and commented on by thousands more. Feeding the flame of anxiety again. Remember, fear sells.  Try to limit your exposure to it. If something truly important happens, you will get to know. </p>"},{"location":"articles/BookNotes/Summary%20-%20Notes%20on%20a%20Nervous%20Planet%20by%20Matt%20Haig/#a-small-section-on-sleep-priorities","title":"A small section on sleep priorities","text":"<p>The part that really stuck out to me here was this \u201cSleep is the enemy of consumerism\u201d. Who\u2019s the biggest competition of Netflix? It\u2019s SLEEP. You can\u2019t watch a show if you\u2019re asleep. Neither can you buy the next \u201cgreatest phone\u201d.  Likewise, you cannot produce these things. The endless factory \u201cneeds\u201d to grow. Working hours keep getting later and later, working on weekends is a normal thing, working 16 hours is a badge of pride, we all know these don\u2019t we?  And the lesser we sleep, the more health issues we have. Catch my drift? (Hint: Healthcare is a product too you know?) Apart from healthcare, the constant panic and fear leads us to the other large businesses - Drugs and Weapons.  Might as well get those good hours of sleep in right? Routines do help. And a little light movement, a warm shower, turning off the devices etc do help quite a bit.</p>"},{"location":"articles/BookNotes/Summary%20-%20Notes%20on%20a%20Nervous%20Planet%20by%20Matt%20Haig/#phone-fears","title":"Phone fears","text":"<p>I think we all have heard a lot about how our devices are affecting our lives negatively. That being the case, the more important aspect of that is understanding how to tackle it. A selection is as follows. Notifications do suck. Turn them off except for the most important ones. Spend some time away from your devices, especially before sleep. Multitasking is an illusion.  Social media breeds unnecessary uncertainty. You are always left \u201cwondering\u201d. What is my friend doing? Did my favourite artist upload a new comic? Are there any new TikTok\u2019s on the thing I\u2019m currently obsessing about? The answer of course, is yes. The problem is, we cannot have everything can we? Accepting that uncertainty is a part of life helps drastically.</p>"},{"location":"articles/BookNotes/Summary%20-%20Notes%20on%20a%20Nervous%20Planet%20by%20Matt%20Haig/#the-detective-of-despair","title":"The detective of despair","text":"<p>All the effects so far seem almost too general? The best way to see how something affects you is to look at what your body is feeling. Listen to what it says. Is it telling you to stop watching people making food and go eat dinner? Is it saying that hey, I\u2019m so tired, can you stop looking at people waking up at 6 am and taking cold showers? Listen. Breathe.</p>"},{"location":"articles/BookNotes/Summary%20-%20Notes%20on%20a%20Nervous%20Planet%20by%20Matt%20Haig/#the-thinking-body","title":"The thinking body","text":"<p>One rather interesting point the author makes is that of a \u201cunit\u201d to how much mental toll something takes : a \u201cpsychogram\u201d. I find it a very interesting notion. Some examples the author gave are (negative and lower is better): - The sun appearing unexpectedly from behind a cloud : -57pg - Dancing : -1350pg - Arriving home after a terrible train journey : -398pg - Watching the news : 222pg - A worrying symptom you have googled : 672pg Trying to at least vaguely quantify how much we can deal with in a day before snapping can help us set better boundaries and listen to our body more. We all start off with a limited amount of energy, and some things drain more than the others.  Of course, the actual quantification of it is not very useful. It\u2019s the idea that makes it interesting to me. A reminder that we have limited resources. Like a Health Bar in a game, ours keeps going down too. We just can\u2019t see it.</p>"},{"location":"articles/BookNotes/Summary%20-%20Notes%20on%20a%20Nervous%20Planet%20by%20Matt%20Haig/#the-end-of-reality","title":"The end of reality","text":"<p>The more the virtual creeps in, the more choices are presented to us. Instead of going to your local store to buy a new phone, you look it up online first. Instead of being presented with one shampoo, you have 40 in a store, and 4000 online.  All these choices can lead your brain to want to not compute and choose. So it turns part of itself off. It hides in \u201cDerealisation\u201d. Reality seems a bit wonky. The virtual world feels more like home, an uncertain, panic filled home, but home nonetheless. We must take steps to protect ourselves from this frenzy before it drowns us.</p>"},{"location":"articles/BookNotes/Summary%20-%20Notes%20on%20a%20Nervous%20Planet%20by%20Matt%20Haig/#wanting","title":"Wanting","text":"<p>This section ties in a lot the \u201cbeauty\u201d one that came before. It serves as a reminder to be kinder to yourself, consider that age and time are a natural function of life itself and realise that \u201ctoo much\u201d of anything is not always a good thing. More is not a solution. The solution is acceptance and being grateful for what you have.  We can never stop wanting, but if we can draw the line between what we truly \u201cwant\u201d and what we are made to believe that we do by our consumerist economy, then we can get some control back.</p>"},{"location":"articles/BookNotes/Summary%20-%20Notes%20on%20a%20Nervous%20Planet%20by%20Matt%20Haig/#two-lists-about-work","title":"Two lists about work","text":"<p>As a society, we like work. We base our worth on it sometimes, which is not great though. The cultural obsession we have with \u201chard working families\u201d is not always a good thing though. Statistics show that the \u201chardest workers\u201d aren\u2019t always the happiest or the wealthiest. Does that say something?  Choosing to have less stuff to do vs choosing to constantly be \u201cbusy\u201d is a lot healthier. Never forget that deadlines are a product of consumerism. Imperfection is a part of humanity itself, it\u2019s a feature, not a bug. One quote that I really liked in the book :  \u2018One of the symptoms of an approaching nervous breakdown is the belief that one\u2019s work is terribly important.\u2019 - Bertrand Russell</p>"},{"location":"articles/BookNotes/Summary%20-%20Notes%20on%20a%20Nervous%20Planet%20by%20Matt%20Haig/#shaping-the-future","title":"Shaping the future","text":"<p>Of course, change is hard. Most of these changes are easier said than done. And many of them are not even fully achievable by you yourself. Remembering that the space around you matters quite a bit, is also very important. We are a part of nature, and the vast openness and freedom that it brings is in our blood. Having more open space, parks and clean  workspaces makes our days a little better. When we can\u2019t escape into the woods, sometimes a good fiction book can serve that purpose. Progress is not something that happens overnight, it takes effort and time. But the peace is worth it.</p>"},{"location":"articles/BookNotes/Summary%20-%20Notes%20on%20a%20Nervous%20Planet%20by%20Matt%20Haig/#the-song-of-you","title":"The song of you","text":"<p>Another important reminder here, the sky is always there for you. Wherever you may be, whoever you may be. We are not separate from nature, we are nature. Your inside world is important too. Tend to the garden that is you, sing the songs that are your very being.</p>"},{"location":"articles/BookNotes/Summary%20-%20Notes%20on%20a%20Nervous%20Planet%20by%20Matt%20Haig/#everything-you-are-is-enough","title":"Everything you are is enough","text":"<p>The key takeaway really, is acceptance. Accepting that you cannot be everything, do everything, go everywhere, have everything. And even if you did, it would not really fill the void. What would is accepting the present moment, prioritising living over just existing, taking back the power and freedom that society so desperately wants to take away from us. Accepting that our failures are a part of life. Accepting that after a point, putting more work into something only has diminishing returns.  Accepting that, people aren\u2019t forever. If you want to show your love, what are you waiting for?</p>"},{"location":"articles/BookNotes/Summary%20-%20Notes%20on%20a%20Nervous%20Planet%20by%20Matt%20Haig/#a-list","title":"A list","text":"<p>That ends my summary and thoughts about the book.  The author gives quite a few helpful tips dispersed among the chapters, and I thought I would list my favourites in one place. (Some are verbatim and I take no credit for them.)</p> <ol> <li>Happiness is felt heading out, not in</li> <li>Happiness is about what we already have</li> <li>Maybe the point of life is to embrace life\u2019s beautiful uncertainty.</li> <li>Products that make us ashamed of our age, don\u2019t actually help us not age</li> <li>The beach does not care what you look like</li> <li>Young people are more worried about age than young</li> <li>Acceptance &gt; Denial in the long run</li> <li>Feeling something doesn\u2019t mean that it\u2019s the absolute truth. It\u2019s just a feeling</li> <li>The empty joy of likes is\u2026 empty</li> <li>Posting about experiences instead of having experiences is not great</li> <li>Don\u2019t type your symptoms into Google</li> <li>What is real on the Internet, isn\u2019t always true</li> <li>Social media abstinence is good for you</li> <li>You cannot understand someone through Intsagram</li> <li>Ratings are not worth the judgement </li> <li>Don\u2019t be steered towards being a caricature of yourself by the internet </li> <li>Algorithms eat empathy</li> <li>Limit the number of times you get the news</li> <li>The world is not as violent as it feels</li> <li>Bad news doesn\u2019t mean good news doesn\u2019t happen</li> <li>Sleep is the enemy of consumerism </li> <li>The imperfections of the real world fill the void that the perfections of the virtual do not</li> <li>Being lonely sometimes is not bad</li> <li>You don\u2019t always have to be available </li> <li>Uncertainty is not going to go away</li> <li>Be your own friend </li> <li>Don\u2019t grab life by the throat.</li> <li>Too many choices trigger your fight or flight response.</li> <li>You cannot be everything</li> <li>Work isn\u2019t the point of life. It\u2019s the point of capitalism. You are replaceable to your work, not your family.</li> <li>Aim to have less stuff to do.</li> <li>Nature is always there for you. So are animals</li> </ol>"},{"location":"articles/BookNotes/Summary%20-%20Notes%20on%20a%20Nervous%20Planet%20by%20Matt%20Haig/#fin","title":"Fin","text":"<p>And again, if you liked my summary, you will like the original book more. You wouldn\u2019t read Wikipedia and feel like you watched a movie would you? Support the author!</p> <p>This article is in the hopes that it will help someone out. Maybe have the help that I did not. I do not know who it will reach. But to whoever it does, best of luck :)</p> <p>Like these/Want more? Buy me a coffee! Kofi</p> <p>Want articles on something specific? Just ask!</p> <p>You can always contact me on LinkedIn, or drop me an Email</p>"},{"location":"articles/DL/AI%20and%20Doom/","title":"AI and Doom","text":"<p>toc: true title: AI and Doom</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/DL/AI%20and%20Doom/#ai-and-doom-the-real-fear-and-some-hope","title":"AI and Doom : The Real Fear and Some Hope","text":""},{"location":"articles/DL/AI%20and%20Doom/#ideas","title":"Ideas","text":"<ul> <li>Why do we work : society</li> <li>The pursuit of art </li> <li>Luddites</li> <li>Malthusian mindset</li> </ul>"},{"location":"articles/DL/AI%20and%20Doom/#research","title":"Research","text":"<ul> <li> <p>Why be an artist when there is AI?</p> <ul> <li>Just because we have cars, should we stop walking?</li> <li>We taught machines how to speak, but now that they have, why should we stop?</li> </ul> </li> <li> <p>AI and Rumors of Impending Doom</p> <ul> <li>Another week, another story about how artificial intelligence (AI) is an existential threat to the human race</li> <li>discouraging to see so many pronouncements of AI\u2019s existential threat to humanity by people who should know better</li> <li>one technology that poses existential risk and whose creation undermined the enlightenment narrative of progress in science and technology improving human life. Global nuclear war</li> <li>A long series of movies produced after the explosions of 1945\u2014beginning with The Day the Earth Stood Still, On the Beach, Fail Safe, Dr. Strangelove, even Godzilla\u2014entertained us with apocalyptical tales and created a narrative whose theme (humanity is at risk from uncontrolled science) continues to shape thinking in unhelpful ways.</li> <li>loss of faith in the ability of democratic societies to manage themselves.</li> <li>seemingly intractable domestic issues, undercut the belief that change can be managed.</li> <li>The perception of failure does not inspire confidence and undercuts the legitimacy of leaders and institutions.</li> <li>The internet has made discourse chaotic.</li> <li>the internet puts rumor and conspiracy before a giant audience.</li> <li>Competition for attention in an intensely commercial society inclines people to tell horror stories\u2014reflecting the inherent bias in human cognition, where a scary story commands larger audiences than a happy one</li> <li>If predictions of doom were only for entertainment and PR purposes, they would not be a problem, but exaggerated fear can lead to bad policy.</li> <li>fears about AI-created unemployment</li> <li>That automation will cause jobs to disappear is a fear that goes back to the early nineteenth century and the Luddites</li> <li>AI is the latest phase in the automation of human activity that began in the eighteenth century, and automation creates wealth and innovation. Some jobs disappear; more jobs are created. With these new jobs will come increased wealth and leisure.</li> <li>It would be better to reinterpret the challenge of AI as deciding how to allocate increased wealth and leisure, but income distribution has not been a shining success for social policy for the last 30 years.</li> </ul> </li> <li> <p>AI Dooms Humanity But Not In The Way You Think</p> <ul> <li>If you want to get people to read your material there is no better way than to highlight the negativity.</li> <li>I tend to think the basis for this is largely influenced by the well-established \u201cMalthusian\u201d mindset that constantly states we are about to be out of resources and the four horseman are just around the corner. Malthus simply stated that population rises until all resources are consumed creating a boom bust dynamic similar to what we today often see in markets. Too many people equates to too much consumption which results in unavoidable catastrophe.</li> <li>So we should nonetheless worry about climate change and therefore we need to worry about energy use because if \u201cclimate change is a thing,\u201d if energy use is not carefully curated, it\u2019s not that we perish because we run out of energy, we all perish because we run out of environment.</li> <li>AI equates to power equates to CO2.</li> <li>If ChatGPT really is the beginning of transhuman intelligence, then that\u2019s it for the decarbonization strategy because any country not prepared to run its energy at full blast to fuel its AI</li> <li>But for even a skeptic like me, ChapGPT writing my bio in the style of the old testament is enough to prove it\u2019s smarter than 95% of people I know, so how long before that the full 100%?</li> </ul> </li> <li> <p>ChatGPT creator says there\u2019s 50% chance AI ends in \u2018doom\u2019 | The Independent</p> <ul> <li>Former OpenAI worker Paul Christiano, who now runs AI research non-profit Alignment Research Center, said he believed there was a significant chance that the technology would lead to the destruction of humanity.</li> <li>The main danger, he claimed, will come when AI systems reach and surpass the cognitive capacity of a human. Dr Christiano predicts there is a \u201c50/50 chance of doom\u201d once this moment arrives.</li> <li>The most likely way we die involves \u2013 not AI comes out of the blue and kills everyone \u2013 but involves we have deployed a lot of AI everywhere... [And] if for some reason, God forbid, all these AI systems were trying to kill us, they would definitely kill us.\u201d</li> <li>godfather of AI Geoffrey Hinton quitting Google to sound the alarm about the dangers of AI</li> </ul> </li> <li> <p>(2) One in the AI for the prophets of doom | LinkedIn</p> <ul> <li>When experts like Hinton speak on the subject of AI we should, of course, listen.</li> <li>But I would argue that the fears currently being expressed around AI amount to little more than scaremongering and are consistent with an approach towards technology that has existed for centuries, perhaps longer.</li> <li>The advent of technologies as diverse as the printing press, the steam engine and the computer have all been accompanied by fears over what they might bring</li> <li>Indeed, I wonder whether some of the warnings around AI can be reduced to fears and frustrations about the pace of its development, and the fact that generative AI, based on large language models (LLM), remains firmly the hands of the usual big tech players. How much of this is sour grapes?</li> <li>We are surely right to be concerned about the potential of AI to eradicate jobs. But how many more jobs will be created as workers are redeployed to do the things that AI cannot, and will not, be able to do?</li> <li>Should there be guardrails in place to govern the development of such a powerful technology as AI? Of course. But we place regulations around loads of technologies \u2013 such as the installation of electrical wiring, the roadworthiness of cars, or the use and storage of our data.</li> <li>Does anyone seriously suggest switching off every computer around the globe just because \u2018bad actors\u2019 can take control of corporate networks and steal money from bank accounts? Of course not.</li> </ul> </li> <li> <p>Will Life Be Worth Living in a World Without Work? Technological Unemployment and the Meaning of Life - Science and Engineering Ethics</p> <ul> <li>Simple Subjectivist Theories</li> <li>life is meaningful to the extent that the individual living it experiences certain subjective states, typically conscious well-being and desire satisfaction</li> <li>Simple Objective Theories</li> <li>individual living it brings about certain objectively good or valuable states of affairs</li> <li>Aim-Achievement Theories</li> <li>combination of subjective and objective states are needed in order to make life meaningful</li> <li>Fitting-Fulfillment Theories</li> <li>combination of subjective and objective states are needed in order to make life meaningful</li> <li>under a simple subjectivist theory, there is reason to think that technological unemployment could enhance the overall level of meaning in our lives, but only if we make use of the right kinds of technological advances</li> <li>reason to think that technological unemployment could undermine the overall level of meaning in our lives, but this impact could lessened with the right kind of technological developments</li> <li> <ul> <li>The Subjective Satisfaction of Non-work </li> </ul> </li> <li>The idea is that compulsory work takes us away from the things that we are really passionate about and that would confer upon us the most subjective satisfaction</li> <li>I cannot do these things because the productivist ethos of modern academia demands that I produce more peer-reviewed publications to pad out my CV.</li> <li>This argument assumes that if we control our own time we will spend it in a way that induces the right subjective states.</li> <li>Dan Gilbert\u2019s work on mis-wanting, for example, suggests that we often don\u2019t really know what makes us truly happy and often stumble upon happiness (Gilbert 2005; Gilbert et al. 1998 </li> <li>75, 617\u2013638.\"), 2004 </li> <li>15, 14\u201319.\")).</li> <li>Findings like this can be exploited by critics of automation and technological unemployment. A recent example of this is Carr (2015). Carr contends that without the pressures and incentives of work we may live a life of listless and unsatisfied boredom.</li> <li>Cskikszentmihalyi (1990, 1997, 2007)</li> <li>studies reveal that people are generally more focused, happier and more satisfied at work than at play</li> <li>Indeed, they often report feeling anxious and bored outside of work when they are presumably free to engage in their preferred activities.</li> <li>\u2018paradox of work</li> <li>Cskikszentmihalyi\u2019s theory holds that entering into a flow state is a function of how difficult the task is and how much pressure is associated with it.</li> <li>Work is often an excellent way to provide the right kind of pressure and difficulty.</li> <li>There is a limited utility to studies, such as Cskikszentmihalyi\u2019s, which compare work and leisure in a world that is dominated by work.</li> <li>When I come home from a busy day at the office, I\u2019m usually drained and lethargic. I\u2019m often not physically able to engage in the kinds of activity I would prefer. I\u2019m conscious of the fact that I need to recover before going back to the office again. In an era of rampant technological unemployment, in which the shadow of work is removed, things could be very different.</li> <li>It is paternalistic to assume that people will lack sufficient self-motivation if they are unemployed.</li> <li>This paternalism is behind much of the traditional ideological glorification of the work ethic.</li> <li>the argument ignores the ways in which modern technology can greatly assist in providing these alternative sources of pressure.</li> <li>although technology could be leveraged in ways that make us more likely to achieve flow states through our activities, there are also ways in which we could use technology to trick ourselves into such subjectively pleasurable states without any associated activity</li> <li>if we are to think seriously about meaning and personal fulfillment in an age of technological unemployment, we probably need to take into consideration the link between our actions and the objective world, and how technology might mediate the relationship between our actions and the objective world.</li> <li>antiwork positions</li> <li>it is too dismissive of the potential for the market to direct human activity towards objectively valuable outcomes.</li> <li>production of art and intellectual discovery, both of which are subject to significant market forces in the modern world</li> <li>If automating technology renders human contribution to such market-based activities unnecessary, then we may be robbed of something that is conducive to the good life.</li> <li>the antiwork camp will simply respond by saying that nonwork is better at allowing us to do these things.</li> <li>It assumes that the kinds of technological advance that make widespread technological unemployment possible will occur in a vacuum\u2014that the impact of automating technologies will be felt solely in our economic lives.</li> <li>If this trend continues, and we rely on those technologies in these other domains, we could sever the necessary causal and mental link between our actions and the outcomes that are said to be constitutive of meaning.</li> <li>Science is increasingly a \u2018big data\u2019 enterprise, reliant on algorithmic, and other forms of automated assistance, to process large datasets and make useful inferences from those datasets. Humans are becoming increasingly irrelevant to the process of discovery.</li> <li>The machines start doing much of the work themselves; the logic of their decision-making becomes more and more opaque to those who interact with them</li> <li>Thus, once again, the rise of automation reduces the space in which humans can engage in meaningful and fulfilling moral activities.</li> <li>Now, you might dispute this characterisation. You might argue that there is still room for human input in all of these automated systems. For one thing, such systems would seem to require human designers, programmers and overseers; for another, humans would still have to contribute to the smooth functioning of such systems, e.g. by becoming kidney donors or by providing crucial data</li> <li>not everyone is going to be equipped or trained to design or program such systems</li> <li>advances in technology may be such that human designers, programmers and overseers will become less needed over time</li> <li>even if humans will always participate in such systems, the participation in question has to be of the right type in order to facilitate meaningfulness in the objective or hybridist sense.</li> <li>even if machines are better at achieving certain objective outcomes there is nothing to stop humans from achieving them too</li> <li>why would you waste time and risk lives if the machines are better</li> <li>it assumes that if machines get better and better at doing things they will take away from the fixed lump of potentially meaningful activities that are open to human beings.</li> <li>But why couldn\u2019t more and more objectively meaningful activities open up</li> </ul> </li> <li> <p>https://www.history.com/news/who-were-the-luddites</p> <ul> <li>\u201cLuddite\u201d is now a blanket term used to describe people who dislike new technology, but its origins date back to an early 19th-century labor movement that railed against the ways that mechanized manufacturers and their unskilled laborers undermined the skilled craftsmen of the day</li> <li>Most were trained artisans who had spent years learning their craft, and they feared that unskilled machine operators were robbing them of their livelihood</li> <li>cheap competition of early textile factories particularly threatening to the artisans, a few desperate weavers\u00a0began breaking into factories and smashing textile machines</li> <li>Machine-breaking Luddites attacked and burned factories, and in some cases, they even exchanged gunfire with company guards and soldiers</li> <li>It wasn\u2019t until the 20th century that their name re-entered the popular lexicon as a synonym for \u201ctechnophobe.\u201d</li> </ul> </li> </ul>"},{"location":"articles/DL/Artists%20vs%20AI/","title":"Artists vs AI","text":"<p>toc: true title: Artists vs AI</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/DL/Artists%20vs%20AI/#artists-vs-ai-companies-the-real-battle-under-the-hype","title":"Artists vs AI (companies) : The real battle under the hype","text":""},{"location":"articles/DL/Experiments%20with%20LLM%20temperature/","title":"Experiments with Temperature","text":""},{"location":"articles/DL/Experiments%20with%20LLM%20temperature/#experimenting-with-temperature-llms","title":"Experimenting With Temperature (LLMs)","text":"<p>Over the past few months at OpenML, we have been experimenting with LLM models in an attempt to improve the search experience for our users. While our existing implementation uses ElasticSearch, we wanted to also have the option of having a more \"semantic\" search experience. </p> <p>Aside from the usual RAG pipeline that everyone and their grandparents seems to be using these days, we also wanted to experiment with using an LLM to semi-automatically generate filters for our search queries. While it may not seem like a big feature, it is something that has always been a bit of an annoyance for some of our users. </p> <p>So what does this entail? Consider the interface we have at the moment. We have a search bar at the top, and subsequently a bunch of filters that users can use to narrow down their search. While this works pretty well as is, how about trying to automate it a bit.</p> <p>In summary, we want a query like \"find me a large dataset with multiple classes of flowers\" to automatically generate filters like \"classification\", \"multiclass\", \"sort by size of dataset\" etc.</p> <p></p>"},{"location":"articles/DL/Experiments%20with%20LLM%20temperature/#temperature","title":"Temperature","text":"<p>Think about the first time you used ChatGPT. What stood out to you? Was it how well it could elaborate on a topic? Or was it how creative it could be? The temperature parameter in LLMs is what controls this. </p> <p>How can we control creativity? Well, saying that we can directly control creativity is a bit of a stretch. We can however use a workaround.</p> <p>Do you remember the softmax function? The function that takes a vector of arbitrary real-valued scores and squashes it into a vector of probabilities that sum to 1. The inputs to the softmax function are the unnormalized log likelikhoods or the raw per class score assigned by the model. </p> <p>The softmax function is defined as:</p> \\[\\text{softmax}(x_i) = \\frac{e^{x_i}}{\\sum_{j=1}^{k} e^{x_j}}\\] <p>If we want more control over the distribution of the probabilities, we can use a temperature parameter. This would look like:</p> \\[ \\text{softmax}(x_i) = \\frac{e^{x_i/T}}{\\sum_{j=1}^{k} e^{x_j/T}} \\] <p>where \\(T\\) is the temperature parameter.</p> <ul> <li> <p>If \\(T = 1\\), the softmax function is the same as the original softmax function.</p> </li> <li> <p>If \\(T &gt; 1\\), the probabilities will become \"flatter\". Since the difference between the probabilities will be less, the model can be more exploratory aka more creative.</p> </li> <li> <p>If \\(T &lt; 1\\), the distribution of the probabilities are \"peakier\". There will be a higher difference between the probabilities, leading to the model being more confident in its predictions, but also less creative.</p> </li> </ul>"},{"location":"articles/DL/Experiments%20with%20LLM%20temperature/#visualizing-temperature-using-softmax","title":"Visualizing Temperature Using Softmax","text":"<pre><code>from tqdm import tqdm\nimport regex as re\n# LangChain supports many other chat models. Here, we're using Ollama\nfrom langchain_community.chat_models import ChatOllama\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom typing import List, Dict, Any\nimport numpy as np  \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd \nsns.set_theme(style=\"white\")\n</code></pre> <pre><code>def softmax(input, t=1.0):\n  ex = np.exp(input/t)\n  sum = np.sum(ex, axis=0)\n  return ex / sum\n</code></pre> <pre><code># plot softmax over a range of inputs\nx = np.arange(0,1.0, 0.01)\nt = np.array([0.1,.5, .8, 1.0])\ny = np.array([softmax(x, ti) for ti in t])\n\n# Create a DataFrame for Seaborn\ndata = pd.DataFrame({\n    'x': np.tile(x, len(t)),\n    'softmax': np.concatenate(y),\n    't': np.repeat(t, len(x))\n})\n\n# Plotting with Seaborn\nplt.figure(figsize=(8, 6))\nsns.lineplot(data=data, x='x', y='softmax', hue='t', palette='viridis')\nplt.xlabel('x')\nplt.ylabel('softmax(x)')\nplt.toc: true\ntitle('Softmax Function for Different Values of t')\nplt.legend(toc: true\ntitle='t')\nplt.show()\n</code></pre>"},{"location":"articles/DL/Experiments%20with%20LLM%20temperature/#creating-the-experimental-setup","title":"Creating the Experimental Setup","text":"<p>Now, we can focus on testing the effects of temperature for our use case. We are using the <code>llama3</code> model for our experiments. The experiments are being run on a 2023 MacBook Pro with an M3 chip and 18GB memory.</p>"},{"location":"articles/DL/Experiments%20with%20LLM%20temperature/#defining-a-prompt","title":"Defining a Prompt","text":"<p>We need to first think of a prompt that we can use for our experiments. This prompt can be thought of as an instruction that the model uses along with the query to generate answers. To make it easier for us to use, we only want one/two word answers and for now we are only focusing on a small subset of the filters that we want our model to understand.</p> <pre><code>prompt = \"\"\"User Query : {query}\nBased on the query, answer the following questions one by one in one or two words only and a maximum of two with commas only if asked for. Use only the information given and do not make up answers - \nDoes the user care about the size of the dataset? Yes/No and if yes, ascending/descending.\nDoes the user want to sort by number of downloads? Yes/No.\nDoes the user care about missing values? Yes/No.\nIf it seems like the user wants a classification dataset, is it binary/multi-class/multi-label? If not, say none.\n\"\"\"\n</code></pre> <pre><code>query = \"Find me a big classification dataset about mushrooms\"\n</code></pre>"},{"location":"articles/DL/Experiments%20with%20LLM%20temperature/#creating-a-chain","title":"Creating a Chain","text":"<p>Since we are using the <code>langchain</code> and <code>ollama</code> libraries for our experiments, we follow their API and create a chain. The template uses string formatting to insert the prompt and the query into the chain.</p> <pre><code>def create_chain(prompt , temperature, llm_model = \"llama3\"):\n    prompt = ChatPromptTemplate.from_template(prompt)\n    llm = ChatOllama(model=llm_model, temperature=temperature)\n    chain = prompt | llm | StrOutputParser()\n    return chain\n</code></pre>"},{"location":"articles/DL/Experiments%20with%20LLM%20temperature/#parsing-the-results","title":"Parsing the Results","text":"<p>To make it easier for us to analyze the results, we generate an example answer and then see see if any further processing is needed.</p> <pre><code># functiont to parse responses like this to a list of yes/no/none/yes,aescending/no etc\ndef parse_response(response):\n    # split by new line and remove first two lines (here are the answers:)\n    response = response.split('\\n')[2::]\n    # if response has a question mark, split by question mark and remove empty strings\n    for i in range(len(response)):\n        if '?' in response[i]:\n            response[i] = response[i].split('?')[1].strip()\n    # replace full stops with empty strings\n    response = [x.replace('.','') for x in response]\n    response = [x for x in response if x]\n    return response\n</code></pre> <pre><code>chain = create_chain(prompt, 0.5)\nresponse = chain.invoke({\"query\": query})\nprint(response)\n</code></pre> <pre><code>Here are the answers:\n\n1. Does the user care about the size of the dataset?\nYes, ascending.\n\n2. Does the user want to sort by number of downloads?\nNo\n\n3. Does the user care about missing values?\nNo\n\n4. Is it a classification dataset? If so, is it binary/multi-class/multi-label?\nYes, multi-class\n</code></pre> <p>Yay, it works. We now write a function to generate results for different temperatures.</p> <pre><code>def generate_results_for_temp(query:str, range_of_temps : np.ndarray) -&gt; List[List[str]:\n    results = []\n    for temperature in tqdm(range_of_temps):\n        chain = create_chain(prompt, temperature)\n        response = chain.invoke({\"query\": query})\n        results.append(parse_response(response))\n    return results\n\n</code></pre>"},{"location":"articles/DL/Experiments%20with%20LLM%20temperature/#running-the-experiments-and-plotting-results","title":"Running the Experiments and Plotting Results","text":"<p>It is time to run the experiments and plot the results.  We write a function to plot the results in a <code>stripplot</code> to see the distribution of the answers for different temperatures.</p> <pre><code>def plot_yes_no(df: pd.DataFrame, toc: true\ntitle:str) -&gt; None:\n    fig, axs = plt.subplots(2, 2, figsize=(15, 15))\n    fig.suptoc: true\ntitle(toc: true\ntitle)\n    sns.stripplot(data=df, x='size', y='temperature', ax=axs[0, 0], hue='size')\n    sns.stripplot(data=df, x='sort_by_downloads', y='temperature', ax=axs[0, 1], hue='sort_by_downloads')\n    sns.stripplot(data=df, x='missing_values', y='temperature', ax=axs[1, 0], hue='missing_values')\n    sns.stripplot(data=df, x='classification_type', y='temperature', ax=axs[1, 1], hue='classification_type')\n    # tilt x axis labels\n    for ax in axs.flat:\n        ax.set_xticklabels(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n    plt.show()\n</code></pre> <p>Sometimes, the model returns an extra field, we combine the last two fields to plot the results. (This is a bit of a hack, but it works for now and is ONLY used for plotting)</p> <pre><code>def combine_last_two_elements(lst):\n    # Check if the list has at least two elements\n    if len(lst) &gt; 4:\n        # Combine the last two elements with a space separator\n        combined_element = lst[-2] + ' ' + lst[-1]\n\n        # Create a new list with combined element instead of the last two\n        return lst[:-2] + [combined_element]\n    else:\n        return lst\n</code></pre>"},{"location":"articles/DL/Experiments%20with%20LLM%20temperature/#experiment-1","title":"Experiment 1","text":"<p>Out first experiment is a rather simple query, \"Find me a big classification dataset about mushrooms\". As you can probably guess, we are looking for a dataset that is large, is a classification dataset and is about mushrooms.</p> <pre><code>range_of_temps = np.linspace(0, 1, 20)\nquery = \"Find me a big classification dataset about mushrooms\"\nresults1 = generate_results_for_temp(query, range_of_temps)\n</code></pre> <pre><code>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:49&lt;00:00,  2.49s/it]\n</code></pre> <pre><code>results1 = [y for y in x if all(sub not in y for sub in [\"If\", \":\"])] for x in results1]\n</code></pre> <pre><code>df = pd.DataFrame(results1, columns = ['size', 'sort_by_downloads', 'missing_values', 'classification_type'])\ndf['temperature'] = range_of_temps\nplot_yes_no(df, toc: true\ntitle = query)\n</code></pre> <p></p> <p>Rather interesting don't you think? At higher temperatures, the model gets the answers wrong. Even at a temperature slightly above 0.1, the model starts adding extra information to it's answers.</p> <p>Did you notice that I tried to remove sentences that started with \"If\"? There are more examples of this later, but this is because at higher temperatures, the model tends to add random sentences to the answers and this makes it quite hard to plot them.</p>"},{"location":"articles/DL/Experiments%20with%20LLM%20temperature/#experiment-2","title":"Experiment 2","text":"<p>Our second experiment is super easy. \"Find me a dataset that has a lot of missing values and order by number of downloads\". As you can obviously guess, we are looking for a dataset that has a lot of missing values and we want to order the results by the number of downloads.</p> <pre><code>range_of_temps = np.linspace(0, 1, 20)\nquery = \"Find me a dataset that has a lot of missing values and order by number of downloads\"\nresults2 = generate_results_for_temp(query, range_of_temps)\nresults2 = [y for y in x if \"so\" not in y] for x in results2]\n\n</code></pre> <pre><code>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:34&lt;00:00,  1.74s/it]\n</code></pre> <pre><code>df = pd.DataFrame(results2, columns = ['size', 'sort_by_downloads', 'missing_values', 'classification_type'])\ndf['temperature'] = range_of_temps\nplot_yes_no(df, toc: true\ntitle = query)\n</code></pre> <p></p> <p>Hmm, same as before. The model starts adding extra information at higher temperatures and starts getting the answers wrong. (Yes, No?? ) What kind of answer is that?</p>"},{"location":"articles/DL/Experiments%20with%20LLM%20temperature/#experiment-3","title":"Experiment 3","text":"<ul> <li>Now a slightly more complex query. \"Find me a dataset that has 10 classes and sort by number of downloads\". We want it to understand that we want a multiclass classification dataset and we want to sort the results by the number of downloads.</li> </ul> <pre><code>range_of_temps = np.linspace(0, 1, 20)\nquery = \"Find me a dataset that has 10 classes and sort by number of downloads\"\nresults3 = generate_results_for_temp(query, range_of_temps)\n</code></pre> <pre><code>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:55&lt;00:00,  2.80s/it]\n</code></pre> <pre><code>results3 = [combine_last_two_elements(x) for x in results3]\n</code></pre> <pre><code>df = pd.DataFrame(results3, columns = ['size', 'sort_by_downloads', 'missing_values', 'classification_type'])\ndf['temperature'] = range_of_temps\nplot_yes_no(df, toc: true\ntitle = query)\n</code></pre> <p>This seems to have been very easy for the model. But as always, the model starts adding extra information at higher temperatures. A lot of extra information in fact. Even though the prompt says to ONLY answer with one or two words</p>"},{"location":"articles/DL/Experiments%20with%20LLM%20temperature/#experiment-4","title":"Experiment 4","text":"<ul> <li>\"Find me a dataset that 2 classes and is a big dataset\". You know the drill by now. We want a binary classification dataset that is large.</li> </ul> <pre><code>range_of_temps = np.linspace(0, 1, 20)\nquery = \"Find me a dataset that 2 classes and is a big dataset\"\nresults4 = generate_results_for_temp(query, range_of_temps)\n</code></pre> <pre><code>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:42&lt;00:00,  2.14s/it]\n</code></pre> <pre><code>results4 = [combine_last_two_elements(x) for x in results4]\n</code></pre> <pre><code>df = pd.DataFrame(results4, columns = ['size', 'sort_by_downloads', 'missing_values', 'classification_type'])\ndf['temperature'] = range_of_temps\nplot_yes_no(df, toc: true\ntitle = query)\n</code></pre> <p>Notice how some things changed? At higher temperatures, we get extended answers.</p>"},{"location":"articles/DL/Experiments%20with%20LLM%20temperature/#conclusion","title":"Conclusion","text":"<p>In conclusion, we can see that we should probably stick to lower temperatures for our use case. As we go higher, the model starts being more \"creative\" and either adds extra information to the answers or gets them wrong. While this behaviour might be useful in cases like creative writing, it is not something we want in our search.</p> <p>Using LLMs can sometimes be a bit of a hit or miss. But of course, learning to control it's parameters can help us get the most out of it. This blog post was just a simple experiment, but in the deluge of content made by people who have no idea what Softmax is, I hope this was helpful.</p>"},{"location":"articles/DL/Experiments%20with%20LLM%20temperature/#fin","title":"Fin","text":"<p>This article is in the hopes that it will help someone out. Maybe have the help that I did not. I do not know who it will reach. But to whoever it does, best of luck :)</p> <p>Like these/Want more? Buy me a coffee! Kofi</p> <p>Want articles on something specific? Just ask!</p> <p>You can always contact me on LinkedIn, or drop me an Email</p>"},{"location":"articles/DL/Parsing%20and%20Querying%20Tensorboard%20logs%20-%20A%20Mini%20Tutorial/","title":"Parsing and Querying Tensorboard logs   A Mini Tutorial","text":"<p>toc: true title: Parsing and Querying Tensorboard logs - A Mini Tutorial</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/DL/Parsing%20and%20Querying%20Tensorboard%20logs%20-%20A%20Mini%20Tutorial/#parsing-and-querying-tensorboard-logs-a-mini-tutorial","title":"Parsing and Querying Tensorboard logs: A Mini Tutorial","text":"<p>So, you wanted to parse your Tensorboard logs, didn\u2019t you? Did you try using GPT-3? OH! GPT-4? Well. Guess that didn\u2019t give you what you wanted.  Yeah, me neither. So here we are. Read on and you will find out how to take all the runs you logged to Tensorboard, clean them up, and put them in a single DataFrame. From there, you can query it as you would any other table. </p>"},{"location":"articles/DL/Parsing%20and%20Querying%20Tensorboard%20logs%20-%20A%20Mini%20Tutorial/#what-do-we-want","title":"What do we want?","text":"<p>Tensorboard is one of the more popular means of logging your deep learning experiments. The issue though, is that it is hard to run custom queries over the already-created graphs. Now, if you were saving your results separately, this would not be an issue. But you probably weren\u2019t were you? (Yeah, me neither.) So we want to iterate over all the logs, for every file we create rows and then columns for each of the tags you saved (eg: Loss, accuracy, etc.) And as a bonus, this script also takes into account all those juicy images you saved from the last time you wanted to try running a DCGAN, again. (Or a cats and dogs classifier, I don't know)</p>"},{"location":"articles/DL/Parsing%20and%20Querying%20Tensorboard%20logs%20-%20A%20Mini%20Tutorial/#shush-and-show-me-the-code","title":"Shush and show me the code?!","text":"<p>Yes, I know this could just be a code snippet on Stack Overflow and there was no real need for this article. If you are an intermediate/advanced programmer, honestly just skip ahead and grab the code here. </p> <p>Now if you did go and skip ahead and realized that it made no sense, welcome back. Read on and hopefully, your doubts will be answered.</p>"},{"location":"articles/DL/Parsing%20and%20Querying%20Tensorboard%20logs%20-%20A%20Mini%20Tutorial/#imports","title":"Imports","text":"<p>As usual, we need to grab some libraries for this to work. You probably have most of them anyway. We need os and pathlib to read the files, pandas for the dataframe, and numpy if you want to further process your data. Tqdm is a little progress bar helper that prints a pretty little progress bar as you wait for your loop to finish running. PIL will be used to read the Image files. BytesIO and base64 will be used to decode the images from Tensorboard so we can save them to the dataframe. Finally, we also do need the Tensorboard package, but if you didn\u2019t have that already then what are you doing here?  Why pickle you might ask? You will see.</p> <p>All of these packages are available either as a pip or a conda/mamba install. So just run <code>pip install &lt;x&gt;</code> and it should hopefully work.</p> <p>Now that we have that out of the way, let\u2019s define the path where your logs are. (The same one you pass to the \u2014logdir argument on Tensorboard)</p> <pre><code>import os\nimport pandas as pd\nfrom tensorboard.backend.event_processing.event_accumulator import EventAccumulator\nfrom tqdm import tqdm\nfrom pathlib import Path\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport base64\nfrom io import BytesIO\nfrom PIL import Image\nimport pickle\n\nmain_path = './runs/' # CHANGE THIS\n</code></pre>"},{"location":"articles/DL/Parsing%20and%20Querying%20Tensorboard%20logs%20-%20A%20Mini%20Tutorial/#find-tfevent-files","title":"Find TFevent files","text":"<p>Tensorboard uses a custom format that it calls a \u2018tfevent\u2019. If you do look at your logs, you will see that the format of the files is either \u2018tfevent\u2019, \u2018checkpoint\u2019, and of course whatever else you have saved.</p> <p>The first step is then to just read all the tfevent files from the directory. We will use the walk function and pathlib to find all of the relevant files.  Why convert it to a Path object? Using the Path function from the pathlib instead of just a string for the directories will allow us to quickly perform operations on the directory if we need it. (For path.name will give us the file name from the full path.)  We just save the complete paths of each of the files to an array here.</p> <pre><code>def get_event_files(main_path):\n    \"\"\"Return a list of event files under the given directory\"\"\"\n    all_files = []\n    for root, _, filenames in os.walk(main_path):\n        for filename in filenames:\n            if \"events.out.tfevents\" in filename:\n                all_files.append(str(Path(root) / Path(filename)))\n    return all_files\n</code></pre>"},{"location":"articles/DL/Parsing%20and%20Querying%20Tensorboard%20logs%20-%20A%20Mini%20Tutorial/#create-dataframe","title":"Create DataFrame","text":"<p>Our objective is to collect all the metadata from the logs and convert it to a single DataFrame. To this accord, we get a list of all the relevant tfevents using the previous function. We then create an empty dictionary to store file-wise information. The EventAccumulator function uses the Tensorboard API to read the tfevent file and so we run every file through it. To make sure we read the logs from the start, we also reload the object.  Once we have this object, we can pass it to a function that will return the relevant tags to a dictionary with the file name as a key and the tags as a value. This function will be discussed in the next section. Once we run over all the files, we have a dictionary of dictionaries with all the information we need. Now, pandas provides a function to convert a nested dictionary to a DataFrame, so we use it directly.  If you look at this output, you will see that the rows are the tags while the columns are individual files. If this version works for you, then do use it!  I find it easier to have the tags as column names and each row of the DataFrame for file information. I also wish to access the file names later so I use the reset_index() function that will essentially make sure all the columns have names here. (In this case, the file names will be named \u2018index\u2019. You can change this if you want by passing in a columns=[] that you want to the from_records function.) <pre><code>def process_runs(main_path):\n    all_files = get_event_files(main_path=main_path)\n    all_dict = {}\n    for files in tqdm(all_files, total = len(all_files)):\n        event_acc = EventAccumulator(files)\n        event_acc.Reload()\n        temp_dict = process_event_acc(event_acc)\n        all_dict[files] = temp_dict\n    return pd.DataFrame.from_records(all_dict).T.reset_index()\n</code></pre>"},{"location":"articles/DL/Parsing%20and%20Querying%20Tensorboard%20logs%20-%20A%20Mini%20Tutorial/#process-an-event","title":"Process an Event","text":"<p>Now for the main bit. Depending on what you were training, you probably have many types of logs that you saved. In my case, these are Scalars, Tensors, or Images. The following function processes these, but it is easy enough to extend to whatever you want. From the process_runs function, we pass in the EventAccumulator object to this function. This object contains the tags that we saved each of our logs as. (For eg: \u2018Train/Acc\u2019, \u2018Train/Loss\u2019 etc.)  I do not want to manually type these every time, and would rather use a function to do that for me.</p> <p>These tags are first divided into the category of object it is, for instance, \u201cimages\u201d, \u201cscalars\u201d, \u201chistogram\u201d etc. We will need to write a separate pre-processing step for each object depending on what information we want from them.</p> <p>Note that for each of the tags, the subtags are the names of the actual values that we want. (Eg: For the tag \u2018scalars\u2019, we have \u2018Train/Acc\u2019).</p>"},{"location":"articles/DL/Parsing%20and%20Querying%20Tensorboard%20logs%20-%20A%20Mini%20Tutorial/#scalars","title":"Scalars","text":"<p>These are probably numerical values that you saved. Say the loss, accuracy, number of classes, etc. For this type of data, we first read the Scalar value using the event_acc.Scalars command. We need to pass in the name of the subtag that we want to look at (eg: \u2018Train/Acc\u2019).  Now, if you were looking at values that change throughout training, you will probably get a list here. For instance, you will get an epoch-wise accuracy list. Since I only want the final accuracy/loss etc, I am only returning the final index.  Feel free to customize it to whatever you need.</p>"},{"location":"articles/DL/Parsing%20and%20Querying%20Tensorboard%20logs%20-%20A%20Mini%20Tutorial/#tensors","title":"Tensors","text":"<p>The name gives it away, but these are the values that you might find have the extra tag \u2018/text_summary\u2019. We can access these by using the event_acc.Tensors command. Now if you inspect the object, you will see that the actual value can be found in the first index of this object. The value is stored in the \u2018string_val\u2019 field of this object, so we take that out and again index it into the first element. (You will see why if you print the object. No further explanations are given because that\u2019s just how the API is. It also depends on what exactly you want to save of course.)  Now if you look at the final output, you will find that it looks something like b\u2019some value\u2019. This is an encoded string, and to convert it to a normal string, we have to decode it as an ASCII character string. Pretty easily done.</p>"},{"location":"articles/DL/Parsing%20and%20Querying%20Tensorboard%20logs%20-%20A%20Mini%20Tutorial/#images","title":"Images","text":"<p>Images are a bit of a complicated case here. If you look at the tensor board object that we get from event_acc.Images, you will see that it is a Bytes object and not a numpy array/PIL image. This is just the format Tensorboard chose, so all we can do is accept it and convert it to our needs. After indexing into the correct component of the object, the field \u2018encoded_image_string\u2019 holds, well, the encoded image string. We take that and convert it to a BytesIO object. This is a format that PIL can read as an image, so we read it as one. </p>"},{"location":"articles/DL/Parsing%20and%20Querying%20Tensorboard%20logs%20-%20A%20Mini%20Tutorial/#other-formats","title":"Other formats","text":"<p>Now if you have something like a histogram, you hopefully get how to process it. Use event_acc.Histogram for instance, and then apply whatever transform you want to it. I do not need them yet, but I might add them to this article later on. </p> <pre><code>def process_event_acc(event_acc):\n    \"\"\"Process the EventAccumulator and return a dictionary of tag values\"\"\"\n    all_tags = event_acc.Tags()\n    temp_dict = {}\n    for tag in all_tags.keys():\n        if tag == 'scalars':\n            for subtag in all_tags[tag]:\n                temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][-1]\n        if tag == 'tensors':\n            for subtag in all_tags[tag]:\n                temp_dict[subtag.replace('/text_summary', \"\")] = [tag[-1] for tag in event_acc.Tensors(tag=subtag)][0].string_val[0].decode('ascii')\n        if tag == 'images':\n            for subtag in all_tags[tag]:\n                temp_dict[subtag] = Image.open(BytesIO(event_acc.Images(subtag)[1].encoded_image_string))\n    return temp_dict\n</code></pre>"},{"location":"articles/DL/Parsing%20and%20Querying%20Tensorboard%20logs%20-%20A%20Mini%20Tutorial/#a-caveat","title":"A Caveat","text":"<p>Now, there is a catch. After creating the DataFrame, if you save it as a \"csv\" object, it becomes impossible to load the images back. This happens because the object is saved as a string like \u2018` instead of the actual image.  Instead of that, you can save the DataFrame as a pickled object.  <pre><code>import pickle\nwith open(\"pickled_df.pkl\", \"wb+\") as f:\n    pickle.dump(combined_df, f)\n\nwith open(\"pickled_df.pkl\", \"rb+\") as f:\n    combined_df = pickle.load(f)\n</code></pre>"},{"location":"articles/DL/Parsing%20and%20Querying%20Tensorboard%20logs%20-%20A%20Mini%20Tutorial/#load-and-clean-dataframe","title":"Load and clean DataFrame","text":"<p>To get the DataFrame we so badly desire, we just run the functions we wrote before. And hopefully, if everything worked fine, you can go home and sleep. (Or if not, sorry! I hope you only have a few hours of your workday left.) Another step I want to mention is the ability to ignore failed runs. If you were tracking failure, then just use that object. If you weren\u2019t, then just look at the columns that are written at runtime. For instance, I always write the name of the experiment, and if even a single epoch was completed, then there should be a validation loss as well.  To filter the data, I just take the rows that have values for these. (As usual, depends on what you want.)</p> <pre><code>combined_df = process_runs(main_path=main_path)\ncombined_df = combined_df[(~pd.isnull(combined_df['experiment_name'])) &amp; (~pd.isnull(combined_df['Loss/Val']))]\ncombined_df.head()\n</code></pre>"},{"location":"articles/DL/Parsing%20and%20Querying%20Tensorboard%20logs%20-%20A%20Mini%20Tutorial/#display-images","title":"Display images","text":"<p>The final part of the code is looking at the images. Filter out what you want, and pick the row and column name as you would index a text object. Done! If you are using a Jupyter notebook, then you should see the image pop up. If you are running this program as a script, you will have to use .show()  <pre><code>filtered_df = combined_df[(~pd.isnull(combined_df['converted_proxy'])) &amp; (~pd.isnull(combined_df['original_images']))]\nfiltered_df.iloc[0].original_images\n</code></pre>"},{"location":"articles/DL/Parsing%20and%20Querying%20Tensorboard%20logs%20-%20A%20Mini%20Tutorial/#what-next","title":"What next?","text":"<p>Depends on how much you are getting paid. :) Jokes aside, this is just a regular DataFrame now. So you can write all the queries you want. Do you want to know how badly your model did? Sure, look at the columns. Did you write some complex logic and now forgot what your actual project was? Oops. Open the DataFrame in Excel and cry. But I am sure you will manage. After all, you\u2019ve got this far haven\u2019t you?</p>"},{"location":"articles/DL/Parsing%20and%20Querying%20Tensorboard%20logs%20-%20A%20Mini%20Tutorial/#why-not-wandbwb-etc-etc","title":"Why not Wandb/W&amp;B etc etc","text":"<p>I do want to mention that I am not against any of the other logging platforms. Honestly, they do some pretty great work. But I am used to Tensorboard, and having my data offline and not on someone else\u2019s cloud (jokes on me, this article is on someone else\u2019s cloud) is nice.  Use whatever works for you. Or write your own. Heck, use a CSVLogger and save what you want directly to a CSV. </p>"},{"location":"articles/DL/Parsing%20and%20Querying%20Tensorboard%20logs%20-%20A%20Mini%20Tutorial/#fin","title":"Fin","text":"<p>This article is in the hopes that it will help someone out. Maybe have the help that I did not. I do not know who it will reach. But to whoever it does, best of luck :)</p> <p>Like these/Want more? Buy me a coffee! Kofi</p> <p>Want articles on something specific? Just ask!</p> <p>You can always contact me on LinkedIn, or drop me an Email. For all the code, drop by my Github.</p>"},{"location":"articles/DL/Tree%20of%20Thoughts%20Explained%20Simply%20%28LLMs%20Dehyped%20-%201%29/","title":"Tree of Thoughts Explained Simply (LLMs Dehyped   1)","text":"<p>toc: true title: Tree of Thoughts Explained Simply (LLMs Dehyped - 1)</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/DL/Tree%20of%20Thoughts%20Explained%20Simply%20%28LLMs%20Dehyped%20-%201%29/#tree-of-thoughts-explained-from-foundations-llms-unhyped-1","title":"Tree of Thoughts Explained From Foundations (LLMs Unhyped - 1)","text":"<p>\u201cProgrammers are, in their hearts, architects, and the first thing they want to do when they get to a site is to bulldoze the place flat and build something grand.\u201d : Joel Spolsky, co-founder of Stack Overflow</p>"},{"location":"articles/DL/Tree%20of%20Thoughts%20Explained%20Simply%20%28LLMs%20Dehyped%20-%201%29/#introduction","title":"Introduction","text":"<p>Large language models like GPT4 have taken over the world and has left every second IT person to scramble towards the next great AI solution. Given the monetary benefits, a lot of research has popped up in a very short time. While this is very exciting, it is wise to look a little deeper beneath the hype. The \u201cnew groundbreaking research from {X} that will change your company\u201d is sometimes a tiny change or a creative use of an existing concept.  This is not to pour cold water over your dreams, but a way to help you understand these concepts better. If you did not come from a technical computer science background, this constant influx of \u201cgroundbreaking research\u201d can get very overwhelming.</p> <p>So here is a more sober, in depth view of how the \u201cTree of thoughts\u201d [1] paradigm came into being from concepts that have been around for decades and creatively applied to LLMs.</p> <p>Note : Both the research and my understanding of it fluctuates over time and if something changes, I will try to come back and correct it. If you notice something weird, do drop a comment!</p>"},{"location":"articles/DL/Tree%20of%20Thoughts%20Explained%20Simply%20%28LLMs%20Dehyped%20-%201%29/#what-is-the-tree-of-thought","title":"What is the Tree of Thought?","text":"<p>If you have not already encountered it, the Tree of Thoughts claims to help an LLM arrive at a more logical conclusion and also generate the steps it took to come to it.</p> <p>It was first mentioned in a paper by Yao et al. [1] and was further expanded on by a LOT of articles and papers. As the authors say, it is a way of \u201cDeliberate Problem Solving with Large Language Models\u201d.</p> <p>But you might ask, why do we care? I just want my assignment done for me.</p>"},{"location":"articles/DL/Tree%20of%20Thoughts%20Explained%20Simply%20%28LLMs%20Dehyped%20-%201%29/#why-bother-adding-it-to-an-llm","title":"Why Bother Adding it to an LLM?","text":"<p>To better understand why we care about algorithms like this, we need to dig into some of the shortcomings behind LLMs. - Fixed Knowledge : A LLM is trained on a large text database encompassing a huge chunk of the web. But the web is not a fixed resource, neither is the information in it. Unless the model is trained with new data or an external data source is given to it, it\u2019s \u201cknowledge\u201d is essentially fixed. - Cost of training : Training a LLM like ChatGPT is extremely costly, and it is just not possible to keep updating the model everytime something new pops up on the internet.  - Knowing everything is not the point : At it\u2019s heart, an LLM is not meant to know everything. It is just a text model - it predicts the next word in a sentence. Using it as a model that can understanding text and it\u2019s underlying relations is a better and cheaper way to use it. - Logic : It is not easy to understand the steps an LLM took to arrive at an answer. Neither is it easy to make it follow logical steps without knowing the logic in the first place. - Structured Data : LLMs are great at making sense of large amounts of unstructured data. But it is not meant to be good at working with structured data like graphs by itself. There are workarounds, but it is not something an LLM can do by itself.</p> <p>Given these shortcomings, the Tree of Thought is an attempt at combining classical \u201clogical search algorithms\u201d with LLMs. How? Well, read on.</p>"},{"location":"articles/DL/Tree%20of%20Thoughts%20Explained%20Simply%20%28LLMs%20Dehyped%20-%201%29/#theoretical-background","title":"Theoretical Background","text":"<p>This section is for you, the reader who want to dig deeper and understand the actual concepts that led to the research. If you just want to mash together models and don\u2019t really care how they work. Just skip to the next section.</p> <p>Now, if you have a background in computers, you will recognize these terms. If you don\u2019t, then pay attention. It will help you understand a lot of research in this domain.</p>"},{"location":"articles/DL/Tree%20of%20Thoughts%20Explained%20Simply%20%28LLMs%20Dehyped%20-%201%29/#chain-of-thought","title":"Chain of Thought","text":"<p>The Tree of Thought is derived from a theoretical computer science concept - the \u201cChain of Thought\u201d.  Simply put, the Chain of Thought is a logical breakdown of a task into it\u2019s simplest steps. Instead of trying to solve a problem as a whole, we try to solve it in parts and then combine the result. Why? Well, it is a lot easier to do and writing it formally makes it possible for others to understand how you arrived at the solution. (Think of trying to solve for x in a math equation.) It also adds in error checking. If something went wrong, you can backtrack and find the bug.</p> <p>Eg: You want to check if it\u2019s raining outside. How would you break down the steps? Look outside the window -&gt; Check for rain clouds -&gt; Check if there are raindrops -&gt; Check the ground to see if it is wet -&gt; If all the conditions are satisfied, you know it is raining.</p>"},{"location":"articles/DL/Tree%20of%20Thoughts%20Explained%20Simply%20%28LLMs%20Dehyped%20-%201%29/#trees","title":"Trees","text":"<p>In computing, a tree is a way of representing this chain of thought. It\u2019s main advantage is that once we create a tree of steps, it is possible to iterate over it and reach a logical conclusion or explore options.</p> <p>A tree has a root node (eg: Is it raining) and leaf nodes (eg: rain clouds, wetness). The leaf nodes are arranged in levels and are connected to previous levels (eg: clouds -&gt; ((present) , (absent)) )</p>"},{"location":"articles/DL/Tree%20of%20Thoughts%20Explained%20Simply%20%28LLMs%20Dehyped%20-%201%29/#traversing-a-tree","title":"Traversing a Tree","text":"<p>Once we have a tree, there are many ways of traversing on it. Choosing an algorithm usually depends on what you need, and how much compute you are willing to use. Some of the approaches used in the paper are as follows (high level explanations): </p> <ul> <li>Breadth First Search : This is used to find the shortest path from the root to a leaf. The tree is traversed layer by layer and all nodes at each level are evaluated. If a match is found, the algorithm stops. This is quite fast.</li> <li>Depth First Search : This is used if you want to explore your options and find new possibilites. The tree is traversed by starting at a node and going as deep as possible from there until the end. If a match is found, the algorithm stops. If not, it backtracks and goes to the next node. This is much slower, but is useful in certain cases.</li> <li>Other Options : Covering the whole lot (like A*) is beyond the scope of this article, but you can refer to [4] if you want to learn more.</li> </ul>"},{"location":"articles/DL/Tree%20of%20Thoughts%20Explained%20Simply%20%28LLMs%20Dehyped%20-%201%29/#ensemble-learning","title":"Ensemble Learning","text":"<p>A large portion of ML algorithms are stochastic (if you run it again, you will get a different result). While this is good for tasks like creative writing, it is not great if you want logical answers.  One way around this is to use multiple similar models on the same data and then \u201caverage\u201d out the results. This somewhat helps to counter the randomness and usually leads to better performance. </p> <p>There are many ways of combining these results - Weight them and use a mix of them, use a majority vote, use a separate model to evaluate which result is better etc. </p> <p>Can you see how this would be useful for an LLM when trying to solve a logical problem?</p> <p>Want to learn more? Refer to [3].</p>"},{"location":"articles/DL/Tree%20of%20Thoughts%20Explained%20Simply%20%28LLMs%20Dehyped%20-%201%29/#tricking-an-llm","title":"Tricking an LLM","text":"<p>Now that you understand the background, let us dive into how this works with an LLM.  So, what do we want to do? Simply put, we want the LLM to come up with different answers that we can then put into a graph. We can then use this graph to arrive at a more logical solution. Spoiler : Can you see why this would not always be a good idea?</p>"},{"location":"articles/DL/Tree%20of%20Thoughts%20Explained%20Simply%20%28LLMs%20Dehyped%20-%201%29/#prompts","title":"Prompts","text":"<p>How do we do it? Quite simple really, we first define a format such as \u201cthe answer is {n} because {x1} and {x2} lead to {n}\u201d. We then prompt multiple times using a prompt like \u201csolve it in multiple ways while pretending to be three different experts\u201d and save the results. We also add a prompt like \u201conly use the information give\u201d, and voila! We have a graph.</p> <p>Well, mostly. The answers you get might or might not be useful.</p>"},{"location":"articles/DL/Tree%20of%20Thoughts%20Explained%20Simply%20%28LLMs%20Dehyped%20-%201%29/#ensemble","title":"Ensemble","text":"<p>Now that you have the answers, provided your prompt has the logic you want, you can decide how to traverse the graph and find the best answer. You can also then repeat this multiple times and vote on the best result from multiple graphs.</p>"},{"location":"articles/DL/Tree%20of%20Thoughts%20Explained%20Simply%20%28LLMs%20Dehyped%20-%201%29/#evaluation","title":"Evaluation","text":"<p>If you know exactly how to evaluate the task (eg: The best step for a robot to take when choosing to get left or right depends on if it will hit something or not), then you can use that as a criteria. But well, this is neither always possible. If you already knew what you wanted, then you would probably not be using an LLM.</p> <p>The paper asks the model to evaluate how well it did itself. Respectfully, this might be a bit dubious for real world issues if unchecked.</p>"},{"location":"articles/DL/Tree%20of%20Thoughts%20Explained%20Simply%20%28LLMs%20Dehyped%20-%201%29/#immediate-shortcomings","title":"Immediate Shortcomings","text":"<p>While the Tree of Thought is quite a nice idea, there are quite a few issues that immediately crop up. - Evaluation : How can we decide if the answer is correct. Say for a math problem, if you knew how to get to the right step, why would you use an LLM? And for say a creative writing task, how can you even evaluate if the answer was correct? - Manual Effort : Using a Tree of Thought in practise requires a bit of manual effort in creating the perfect logical prompt, and knowing the evaluation steps beforehand. This might not always be useful. - Bias : Asking a model to evaluate how well it did is to ask a math student to see if they got the problem right. If they knew how to check, why would they want to explore other paths? But perhaps it could encourage them to think deeper about other aspects of a problem. - Computation : This is a big one. Running an LLM is expensive. For most tasks, running a model multiple times and then further algorithms is not exactly compute friendly.  - Not everything needs an LLM : As they say, \u201cwhen you have a hammer, everything starts looking like a nail\u201d. An LLM is useful, but not everywhere.</p>"},{"location":"articles/DL/Tree%20of%20Thoughts%20Explained%20Simply%20%28LLMs%20Dehyped%20-%201%29/#perks","title":"Perks","text":"<p>So when would you actually want to use them? - Generating Data : An LLM comes with a lot of knowledge inbuilt. Perhaps this is a good way to generate data for a different task. Using a Tree of Thought would enable an LLM to come up with much better and more logical examples. - Forcing an LLM to think more : Instead of taking the first result for granted, you can force the LLM to think a step deeper. Like a kid asking \u201cwhy?\u201d multiple times, perhaps a better answer can be reached. - Combining with Knowledge Bases : Combining the language understanding capabilites of LLMs with existing knowledge bases is pretty useful. While this area is a little different from the Tree of Thought, they are related concepts. Perhaps in the future these ideas will be combined to improve LLMs even further [6]. - Domain Specific Information : This could be used as a means of injecting domain specific logical steps to the results obtained from an LLM.</p>"},{"location":"articles/DL/Tree%20of%20Thoughts%20Explained%20Simply%20%28LLMs%20Dehyped%20-%201%29/#why-llms-unhyped","title":"Why \u201cLLMs Unhyped\u201d?","text":"<p>This is the first article in the series LLMs Unhyped. A rather weird name, I know. But why even have this series in the first place? LLMs are amazing, but they are still in the research phase. With companies like OpenAI and Hugging face, it is now possible for a lot of people to work with these massive AI pipelines without much effort.</p> <p>While that is an amazing feat in itself, and so many great ideas come out of it, it also leads to a lot of misinformation. In the hype of AI, many people who don\u2019t fully understand the background research end up  using these massive models in places where they were probably not needed. </p> <p>Sometimes, it\u2019s awesome. But in other times, it is a massive waste of money. Now ultra large corporations want you to spend your money on them, why wouldn\u2019t they? But occasionally it\u2019s like using a helicopter to get to a supermarket 100m away. </p> <p>AI has it\u2019s uses. But not everywhere. By no means is this a critique against research or enjoying the magic of AI. Please, continue to do that! But consider your options too. At the end of the day, this is just yet another tool.</p>"},{"location":"articles/DL/Tree%20of%20Thoughts%20Explained%20Simply%20%28LLMs%20Dehyped%20-%201%29/#some-more-resources-for-you","title":"Some More Resources for You :)","text":"<ul> <li>[1] Tree of Thoughts : https://arxiv.org/abs/2305.10601</li> <li>[2] Graph of Thoughts : https://arxiv.org/abs/2308.09687</li> <li>[3] Voting Algorithms : https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier</li> <li>[4] Graph Search Algorithms : https://en.wikipedia.org/wiki/Graph_traversal , https://en.wikipedia.org/wiki/Pathfinding</li> <li>[5] Roadmap of KB + LLM : https://arxiv.org/abs/2306.08302</li> </ul>"},{"location":"articles/DL/Tree%20of%20Thoughts%20Explained%20Simply%20%28LLMs%20Dehyped%20-%201%29/#fin","title":"Fin","text":"<p>This article is in the hopes that it will help someone out. Maybe have the help that I did not. I do not know who it will reach. But to whoever it does, best of luck :)</p> <p>Like these/Want more? Buy me a coffee! Kofi</p> <p>Want articles on something specific? Just ask!</p> <p>You can always contact me on LinkedIn, or drop me an Email</p>"},{"location":"articles/Drafts/What%20I%20learnt%20from%20an%20AI%20Masters%20Part%202/","title":"What I learnt from an AI Masters Part 2","text":"<p>Part 2 : Planning your thesis Part 3 : Setting up your writing, programming, and research environment for success Part 4 : Tips for writing your thesis</p> <p>What I learned from an AI masters degree - Part 2 (Setting up your writing, programming, and research environment)</p>"},{"location":"articles/Drafts/What%20I%20learnt%20from%20an%20AI%20Masters%20Part%202/#setting-up-your-programming-environment","title":"Setting up your programming environment","text":"<p>If you are a programmer, this part might not be something you are particularly afraid of. But if you are not as comfortable with programming, it would help you to set up your environment before you start. This might include things like creating a GitHub repository, installing all the packages that you need, making sure that you have the resources that you might require (such as a GPU) etc. In future parts of the article, I will try to detail as much of this as I can based on my experience. (Depending on when you are reading this, these parts of the article might be already posted, so refer to them.)</p>"},{"location":"articles/Drafts/What%20I%20learnt%20from%20an%20AI%20Masters%20Part%202/#setting-up-your-writing-environment","title":"Setting up your writing environment","text":"<p>A thesis is a rather long document, but by this point, you hopefully have written enough assignments to be comfortable with writing technical articles. If you have not, or you are reading this before doing a Master, it would serve you to be a little familiar with LaTEX. It's took me about a few hours to get everything set up and running, but it might take you longer. (Refer to a detailed guide in future articles.)</p>"},{"location":"articles/Drafts/What%20I%20learnt%20from%20an%20AI%20Masters%20Part%202/#programming-your-idea","title":"Programming your idea","text":"<p>Not every thesis would require a lot of programming. Depending on what you're doing, you might have to spend more time writing analysis scripts instead. In my case, I created a solution from scratch and also wrote the analysis scripts so it definitely took me a lot of experimentation and time. But to be honest, it took me longer because I hesitated quite a lot, and did not spend enough time trying to refine what I already had. </p>"},{"location":"articles/Drafts/What%20I%20learnt%20from%20an%20AI%20Masters%20Part%202/#running-experimentsstudies","title":"Running experiments/studies","text":"<p>Again, depending on the kind of thesis, you are working on the time taken for you to run, experiments or studies might differ considerably. If you are running experiments where you collect data yourself, from different systems or from human studies, it might take you a lot longer. In my case, I used datasets that were already available but since I ran a lot of experiments, the running took longer. </p>"},{"location":"articles/Drafts/What%20I%20learnt%20from%20an%20AI%20Masters%20Part%202/#analysing-the-experimentsstudies","title":"Analysing the experiments/studies","text":"<p>Just like the previous one, analysing your results might take you longer. I personally found it useful to have the analysis scripts written as early as possible. I started writing the scripts around the same time that I started programming my solution. This allowed me to be able to run quick experiments just to make sure that my code was working and saved me quite a lot of time in the long run. It also meant that as my code changed, and I thought of new things, I could add them directly to my analysis without having to wait till I was finished running my experiments.</p>"},{"location":"articles/Drafts/What%20I%20learnt%20from%20an%20AI%20Masters%20Part%202/#actually-writing-the-thesis","title":"Actually writing the thesis","text":"<p>So, you made it to having your experiments and data and literature survey now you actually want to start writing the thesis. I will warn you though, it will probably take more time than you think it would. No matter how good you are at writing long form, there will be many things that will crop up that you did not probably think of. It took me probably the longest to write my thesis compared to every other step. But, although it took a long time, it was not very painful as I had planned ahead and made preparations. Many of the little things such as making notes while reading papers, setting up the environments, beforehand, etc significantly cut down the mental effort it would have required otherwise.  As for all the parts that helped me out, there will be detailed articles about the same. Depending on when you read, this, you could probably refer to them already.</p>"},{"location":"articles/Drafts/What%20I%20learnt%20from%20an%20AI%20Masters%20Part%202/#changes","title":"Changes","text":"<p>Another thing that you probably should be warned about is having to change things. Like any project, a thesis is not straightforward. There will be many times when you need to redo a part of the project or rewrite a section. This may take a decent amount of time as well. You might also get a lot of feedback that you need to implement as you go along.  Before I started my project, I made sure that I had systems in place that would let me quickly change things if required. This article would be too long if I also listed them, so future parts will follow up on these.</p> <p>As you can tell by now, none of these steps are linear. There are many things that you need to go back and forth between. But now that you know what to expect, it will be quite a lot easier for you to plan the same.</p>"},{"location":"articles/Drafts/What%20I%20learnt%20from%20an%20AI%20Masters%20Part%202/#checkpoints","title":"Checkpoints","text":"<p>I think it\u2019s important to have checkpoints along the way to help guide you and make sure that you are on the right track. The process of finding these checkpoints was quite a bit of trial and error on my part, but perhaps they may come easier to you.  These checkpoints are like deciding a day when you want to complete your literature survey or have a prototype ready etc. They might also be ones where you update your supervisor on your progress or take a little break. I admit these are a bit hard to plan for until you are sure of where your project is headed, but it is nice to keep it in mind.</p>"},{"location":"articles/Drafts/What%20I%20learnt%20from%20an%20AI%20Masters%20Part%202/#recovery-time","title":"Recovery time","text":"<p>There are a million articles on how to do your thesis. If you went looking for them, you probably found some more. But what I don\u2019t see a lot of them talking about is recovery. Doing a thesis is hard. For many of us (including me), it is the first time we have had to do such a long project without any external motivation. It\u2019s your project, after all. Unless you choose a company internship, in which case you will have stricter deadlines, of course. There are bound to be days, sometimes even weeks, where you have literally 0 motivation to even look at your thesis.  And while that is pretty normal, I think many of us don\u2019t factor that into our plans. Make sure you keep some extra time on hand for these days because you will really need them. </p>"},{"location":"articles/Drafts/What%20I%20learnt%20from%20an%20AI%20Masters%20Part%202/#supervisor","title":"Supervisor","text":""},{"location":"articles/Drafts/What%20I%20learnt%20from%20an%20AI%20Masters%20Part%202/#what-can-you-expect-from-them","title":"What can you expect from them","text":""},{"location":"articles/Drafts/What%20I%20learnt%20from%20an%20AI%20Masters%20Part%202/#updating","title":"Updating","text":""},{"location":"articles/Drafts/What%20I%20learnt%20from%20an%20AI%20Masters%20Part%202/#extra-tips","title":"Extra tips","text":""},{"location":"articles/Drafts/Writing%20your%20own%20Markdown%20to%20LaTEX%20parser/","title":"Writing your own Markdown to LaTEX parser","text":""},{"location":"articles/Drafts/Writing%20your%20own%20Markdown%20to%20LaTEX%20parser/#writing-your-own-markdown-to-latex-parser","title":"Writing your own Markdown to LaTEX parser","text":""},{"location":"articles/Drafts/Writing%20your%20own%20Markdown%20to%20LaTEX%20parser/#what-we-want","title":"What we want","text":""},{"location":"articles/Drafts/Writing%20your%20own%20Markdown%20to%20LaTEX%20parser/#disclaimers","title":"Disclaimers","text":""},{"location":"articles/Drafts/Writing%20your%20own%20Markdown%20to%20LaTEX%20parser/#overview-of-steps","title":"Overview of Steps","text":""},{"location":"articles/Drafts/Writing%20your%20own%20Markdown%20to%20LaTEX%20parser/#lets-make-it","title":"Let\u2019s Make It!","text":""},{"location":"articles/Drafts/Writing%20your%20own%20Markdown%20to%20LaTEX%20parser/#libraries","title":"Libraries","text":"<pre><code>import markdown\nimport argparse as ap\nfrom pathlib import Path\nimport re\nfrom html.parser import HTMLParser\nfrom html.entities import name2codepoint\n</code></pre>"},{"location":"articles/Drafts/Writing%20your%20own%20Markdown%20to%20LaTEX%20parser/#base-templates","title":"Base Templates","text":"<pre><code>default_template = \"\"\"\n\\\\documentclass[12pt]{article}\n\\\\usepackage[a4paper, total={6in, 8in}]{geometry}\n\\\\usepackage[utf8]{inputenc}\n\\\\usepackage[T1]{fontenc}\n\\\\usepackage[english]{babel}\n\\\\usepackage{graphicx}\n\\\\usepackage[dvipsnames]{xcolor}\n\\\\usepackage{hyperref}\n\\\\usepackage{listings}\n\n\\\\newcommand\\myshade{85}\n\\\\colorlet{mylinkcolor}{violet}\n\\\\colorlet{mycitecolor}{YellowOrange}\n\\\\colorlet{myurlcolor}{Aquamarine}\n\n\\\\hypersetup{\n  linkcolor  = mylinkcolor!\\\\myshade!black,\n  citecolor  = mycitecolor!\\\\myshade!black,\n  urlcolor   = myurlcolor!\\\\myshade!black,\n  colorlinks = true,\n}\n\\\\author{}\n\"\"\"\n</code></pre>"},{"location":"articles/Drafts/Writing%20your%20own%20Markdown%20to%20LaTEX%20parser/#html-parser","title":"HTML Parser","text":"<pre><code>class MyHTMLParser(HTMLParser):\n    def __init__(self):\n        super().__init__()\n        self.attrs = []\n    def handle_starttag(self, tag, attrs):\n        for attr in attrs:\n            self.attrs.append(attr)\n    def get_attrs(self):\n        return self.attrs\n    def handle_endtag(self, tag):\n        pass\n\n    def handle_data(self, data):\n        print(\"Data     :\", data)\n\n    def handle_comment(self, data):\n        print(\"Comment  :\", data)\n\n    def handle_entityref(self, name):\n        c = chr(name2codepoint[name])\n        print(\"Named ent:\", c)\n\n    def handle_charref(self, name):\n        if name.startswith('x'):\n            c = chr(int(name[1:], 16))\n        else:\n            c = chr(int(name))\n        print(\"Num ent  :\", c)\n\n    def handle_decl(self, data):\n        print(\"Decl     :\", data)\n</code></pre> <pre><code>def get_html_attributes(text):\n    parser = MyHTMLParser()\n    parser.feed(text)\n    return parser.get_attrs()\n</code></pre>"},{"location":"articles/Drafts/Writing%20your%20own%20Markdown%20to%20LaTEX%20parser/#replace-strings","title":"Replace strings","text":"<pre><code>replacer_dict = {\n    \"&lt;head&gt;\" : \"\",\n    \"&lt;/head&gt;\" : \"\",\n    \"&lt;html&gt;\" : \"\",\n    \"&lt;/html&gt;\" : \"\",\n    \"&lt;p&gt;\" : \"\",\n    \"&lt;/p&gt;\" : \"\",\n    \"&lt;h1&gt;\" : \"\\\\begin{document}\\n\\\\toc: true\ntitle{\",\n    \"&lt;/h1&gt;\" : \"}\\n\\\\maketoc: true\ntitle{}\\n\",\n    \"&lt;h2&gt;\" : \"\\\\section{\",\n    \"&lt;h3&gt;\" : \"\\\\subsection{\",\n    \"&lt;h4&gt;\" : \"\\\\subsubsection{\",\n    # \"&lt;body&gt;\" : \"\\\\begin{document}\\n\",\n    \"&lt;/body&gt;\" : \"\\\\end{document}\\n\",\n    \"&lt;ul&gt;\" : \"\\\\begin{itemize}\\n\",\n    \"&lt;/ul&gt;\" : \"\\\\end{itemize}\\n\",\n    \"&lt;il&gt;\" : \"\\\\begin{enumerate}\\n\",\n    \"&lt;/il&gt;\" : \"\\\\end{enumerate}\\n\",\n    \"&lt;code&gt;\" : \"\\\\begin{lstlisting}[language=Python]\\n\",\n    \"&lt;/code&gt;\" : \"\\\\end{lstlisting}\\n\",\n    \"&lt;li&gt;\" : \"\\\\item \",\n    \"&lt;/li&gt;\" : \"\",\n    \"%\": \"\\%\",\n    \"&amp;\": \"\\&amp;\",\n}\n</code></pre>"},{"location":"articles/Drafts/Writing%20your%20own%20Markdown%20to%20LaTEX%20parser/#close-tags","title":"Close Tags","text":"<pre><code>def add_end_brace(list_of_vals, replacer_dict):\n    list_of_vals = [x.strip() for x in list_of_vals.split(\",\")]\n    for i in list_of_vals:\n        replacer_dict[i.replace(\"&lt;\", \"&lt;/\")] = \"}\\n\"\n</code></pre> <pre><code>add_end_brace(\n    list_of_vals=\"&lt;h2&gt;, &lt;h3&gt;, &lt;h4&gt;\", \n    replacer_dict=replacer_dict\n)\n</code></pre>"},{"location":"articles/Drafts/Writing%20your%20own%20Markdown%20to%20LaTEX%20parser/#images","title":"Images","text":"<pre><code>def figure_code(text):\n    found_links = re.findall('\\&lt;img .* \\/&gt;' , text)\n    for link in found_links:\n        attrs = get_html_attributes(link)\n        caption_data = \"\"\n        file_path = \"\"\n        for i in attrs:\n            if i[0] == \"alt\":\n                caption_data = i[1]\n            if i[0] == \"src\":\n                file_path = i[1]\n        gen_latex = \"\\\\begin{figure}[!htbp]\\n\\centering\\n\\includegraphics[width=.75\\columnwidth]{\"+file_path+\"}\\n\\caption{\"+caption_data+\"}\\n\\label{}\\n\\end{figure}\"\n        text = text.replace(link, gen_latex)\n    return text\n</code></pre>"},{"location":"articles/Drafts/Writing%20your%20own%20Markdown%20to%20LaTEX%20parser/#cli-input","title":"CLI input","text":"<pre><code>ags = ap.ArgumentParser(\"md2tex\")\nags.add_argument(\"-f\", help=\"Full file path\", required=True)\nags.add_argument(\"-d\", help=\"Insert default formatting code\", action='store_true')\naps = ags.parse_args()\n\nf_name = Path(aps.f)\n</code></pre>"},{"location":"articles/Drafts/Writing%20your%20own%20Markdown%20to%20LaTEX%20parser/#running-the-pipeline","title":"Running the pipeline","text":"<pre><code># Read the file\nwith open(f_name, 'r') as f:\n    text = f.read()\n    html = markdown.markdown(text)\n\n# Replacing things\ntext = figure_code(html)\nfor key in replacer_dict.keys():\n    text = text.replace(key, replacer_dict[key])\n\n# Write the file\nwith open(f_name.parent/f\"{f_name.stem}.tex\", 'w') as f:\n    if aps.d:\n        f.write(default_template)\n    f.write(text)\n    if aps.d:\n        f.write(\"\\\\end{document}\")\n</code></pre>"},{"location":"articles/Drafts/Writing%20your%20own%20Markdown%20to%20LaTEX%20parser/#fin","title":"Fin","text":"<p>This article is in the hopes that it will help someone out. Maybe have the help that I did not. I do not know who it will reach. But to whoever it does, best of luck :)</p> <p>Like these/Want more? Buy me a coffee! Kofi</p> <p>Want articles on something specific? Just ask!</p> <p>You can always contact me on LinkedIn, or drop me an Email. For all the code, drop by my Github.</p>"},{"location":"articles/FAQ/Commission%20FAQ/","title":"Commission FAQ","text":""},{"location":"articles/FAQ/Commission%20FAQ/#commission-faq","title":"Commission FAQ","text":""},{"location":"articles/FAQ/Commission%20FAQ/#name","title":"Name","text":"<p>Full form article about anything related to AI/Neural networks/Technical writing.</p>"},{"location":"articles/FAQ/Commission%20FAQ/#description","title":"Description","text":"<p>Want an article on something in AI? Go ahead and ask me for it.  If there are specific questions you want answered, you can request them as well. </p> <p>Topics you can request for (my expertise) - AI, Computer Vision, Deep learning, Neural Networks, Shell scripting, Python, Scientific Writing</p> <p>My previous blogs :  https://msubhaditya.medium.com https://subhadityamukherjee.github.io/AI-knowledge-base/</p> <p>I\u2019d suggest you contact me first before you pay. You can either drop me an email here : msubhaditya@gmail.com Text me on LinkedIn : https://www.linkedin.com/in/subhaditya-mukherjee-a36883100/</p> <p>Word count isn't really my thing but it would be a medium sized article - around 1k-1.5k words. Please read the FAQs!</p>"},{"location":"articles/FAQ/Commission%20FAQ/#instructions-and-faq","title":"Instructions and FAQ","text":"<p>The more specific your request, the better you will get an answer to them.  Please Please drop your name and email. It would make it so much easier to contact you. FAQ: - Will you do my homework?     - Probably not. I take no responsibility for the grades you get. </p> <ul> <li> <p>How long will it take you to write my article?</p> <ul> <li>That depends on your topic. Around 3 days is a good estimate. Although I would be able to give you a better estimate once I see the topic.</li> </ul> </li> <li> <p>Can I distribute this article freely?</p> <ul> <li>Generally yes. You must link to my page and have my name on it though. If you are going to monetise it, well. I can\u2019t really stop you but then I will monetise it too.</li> </ul> </li> <li> <p>Will it be public?</p> <ul> <li>That is your choice. Generally, yes. But if you want it on your website/company website, then just inform me before. As long as you credit me properly wherever you post it, I\u2019m okay with that.</li> </ul> </li> <li> <p>Will you make a whole framework for me?</p> <ul> <li>Nope. You will get demo code. Full code etc will be a lot more time intensive so the rate will be decided based on the request.</li> </ul> </li> <li> <p>How many rewrites do I get?</p> <ul> <li>Minor changes : two times.</li> <li>Major changes : once. </li> <li>Delays suck for both of us. So if you want something specific, it\u2019s better you tell me before I start.</li> </ul> </li> <li> <p>Delays</p> <ul> <li>I am not GPT-3, and sometimes I do face delays in getting work done. If I do though, I will keep you informed.</li> </ul> </li> <li> <p>Refunds</p> <ul> <li>Oops, you didn\u2019t like what you got. Apologies. If you can convince me that it was a badly written article, even after 2 minor and 1 major change, I will send you half your money back. After all, it did take a lot of my time. I don\u2019t want to encourage scams, so I hope you understand.</li> </ul> </li> </ul>"},{"location":"articles/FAQ/Commission%20FAQ/#thank-you","title":"Thank you!","text":"<p>I hope we can both enjoy this article. If you have any further questions, don't hesitate to drop me a message or email at msubhaditya@gmail.com </p>"},{"location":"articles/FAQ/Commission%20FAQ/#linkedin-post","title":"LinkedIn Post","text":"<p>TL;DR AI Article Commissions - Open!</p> <p>https://ko-fi.com/subhadityamukherjee/commissions I'm going to take a deep breath, and tell you that I'm now open to article commissions. Want an article on something in AI? Go ahead and ask me for it.  If there are specific questions you want answered, you can request them as well. </p> <p>Topics you can request for (my expertise) - AI, Computer Vision, Deep learning, Neural Networks, Shell scripting, Python, Scientific Writing</p> <p>More info on the page linked here. This is not a free article. Although, if you do want one but can't afford it, you can still drop me a message. I can't guarantee it though.</p> <p>PS: This took a lot more than one deep breath. Let's see how it goes.</p>"},{"location":"articles/FAQ/Commission%20FAQ/#commission-computervision-python-neuralnetworks-ai-deeplearning-shellscripting-article-request-scientificresearch","title":"commission #computervision #python #neuralnetworks #ai #deeplearning #shellscripting #article #request #scientificresearch","text":""},{"location":"articles/FAQ/Commission%20FAQ/#prices","title":"Prices","text":"<ul> <li>Minimum. Short article. 500 ish words : 30 euro</li> <li>Medium sized article. More in depth. Around 1k-1.5k words. : 50 euro</li> <li>Longer article. Fully in-depth. Around 2k-2.5k words. : 100 euro</li> <li>Along with working code. : 200 euro</li> </ul>"},{"location":"articles/Mental%20Health/ADHD%20%2B%20Autism%20-%20Challenges%20and%20hopeful%20workarounds/","title":"ADHD + Autism - Challenges and hopeful workarounds","text":""},{"location":"articles/Mental%20Health/ADHD%20%2B%20Autism%20-%20Challenges%20and%20hopeful%20workarounds/#adhd-autism-challenges-possible-reasons-and-hopeful-workarounds","title":"ADHD + Autism - Challenges, possible reasons and hopeful workarounds","text":""},{"location":"articles/Mental%20Health/ADHD%20%2B%20Autism%20-%20Challenges%20and%20hopeful%20workarounds/#motivation","title":"Motivation","text":"<p>Finally, a manual for why I am such a wreck and how to salvage it! (Kind of.) Think of this as a lab notebook. You can pick whichever chapter you want to read. This obscenely long post is intended to be an experience log of workarounds that I have found over the years that have worked, most times atleast and their possible reasons. It is not intended to be a \u201coh if I do XYZ I will be free of my head~\u201d but more of \u201coh~~, maybe that\u2019s why doing XYZ broke my brain! I should remember that.\u201d.  I wrote down whatever I could (clearly hyper focusing on this now don\u2019t judge me please) in the hopes that sharing my understanding helps you find your own.  Feel free to critique (politely thank you, don\u2019t make me cry). But more importantly, feel free to start a discussion. I\u2019m on a journey as well. I have too much left to learn. I would love to hear your stories too.</p>"},{"location":"articles/Mental%20Health/ADHD%20%2B%20Autism%20-%20Challenges%20and%20hopeful%20workarounds/#disclaimers","title":"Disclaimers","text":"<ul> <li>This is not scientifically backed but is purely anecdotal. </li> <li>I do \u201cnot\u201d have my s**t together at all. Just because I wrote this huge article doesn\u2019t mean all these points always work. Sometimes the Autism side of my head takes over and breaks down, sometimes the other. It\u2019s a war, baby :)</li> <li>It is a \u201cspectrum\u201d and you probably won\u2019t relate to a few of them.</li> <li>Conversely, relating to these doesn\u2019t automatically make you have ADHD/ASD. Get a diagnosis if you can! But either ways. If it helps you, then that\u2019s all that matters to me.</li> <li>I would love to add scientific literature to these points, but I\u2019m scared it will take long enough for me to lose motivation and never end up posting. (Help me out please?)</li> <li>If you disagree with anything, comment! I\u2019m learning too. I fully admit that I might be wrong. </li> <li>I would love to have a discussion on these. Especially if you have more tips!!</li> <li>Today is one of the good days. And I am writing this whole article in one go. I don\u2019t have the courage to do it in parts.</li> <li>I admit I do not have extreme symptoms. They ruin my life, but subtly sabotage it. I do not have any visible effects unless someone lives with me or sees me crying in the corner after my fourth breakdown when all I wanted to do was wash two plates so I could have lunch. My family does not know of my diagnosis. Some friends and my girlfriend do. My birth society would not accept me if they did. I am studying in a different country, so.. I have my privacy here. </li> </ul>"},{"location":"articles/Mental%20Health/ADHD%20%2B%20Autism%20-%20Challenges%20and%20hopeful%20workarounds/#somewhat-categorised-choose-your-own-adventure","title":"Somewhat categorised - Choose your own adventure","text":""},{"location":"articles/Mental%20Health/ADHD%20%2B%20Autism%20-%20Challenges%20and%20hopeful%20workarounds/#time","title":"Time","text":"<p>Time blindness affects every little part of my life. But I have come to some workarounds to help me with it. Turns out, our brains update their internal clocks by changes in the environment. That was an important realisation for me. The following points relate to that. - I used to listen to a lot of lofi music while working and always felt like time would stretch out to infinity. Well, turns out it does. Because it repeats, and doesn\u2019t change enough. Now I actively try to switch up the music a bit. - I have tried time blocking a bunch of times. But it inevitably always fails. It\u2019s still useful though. I just have to forgive myself for not always being able to stick to it. But I tried you know? - You can use this to your advantage. If you want to slow down, make sure you have repeating things. If you want to speed up, do the opposite. - I tried having clocks everywhere but only \u201canalog\u201d clocks helped. Maybe because they are more visual.  - Telling yourself \u201cOkay this will take 1 hour\u201d and then seeing that it actually took 3 is probably a good way to realise that you are setting yourself up for failure. - I have tried to explain to people that my sense of time is a little warped. I don\u2019t think they always understand, but atleast some of them try.</p>"},{"location":"articles/Mental%20Health/ADHD%20%2B%20Autism%20-%20Challenges%20and%20hopeful%20workarounds/#adhd-meds","title":"ADHD Meds","text":"<p>I made it through 21 years without a diagnosis and forever wondering if I was completely looney. But yeah, a while back I did get one and was prescribed Ritalin. It changed my life, but it then ASD side started showing up a little more frequently. And I realized even more how chaotic my poor brain was. I am on my meds as I write this manual of course.  What it helped me with: - Getting my work done, the ones I don\u2019t care about but still have to do. - Slowing down a bit. - Having the space to see just how badly I was wrecking my life. (Cue. Also maybe helping me heal a little) - Realising that the ASD side had been suppressed a lot and maybe that\u2019s why nothing was working out. I was focusing too much on \u201cfixing\u201d the ADHD side but the other side wanted all the opposites. - Helping me separately understand what the ADHD and ASD sides wanted. Not that I can fully balance their needs yet. It\u2019s a work in progress. What it somewhat made worse - Regular meals become harder because the meds suppress my hunger. - Sometimes I forget to take the right dosage and then oh god it\u2019s down to the bottom of the emotional well.  - Now that I realise how badly the neurodivergent \u201cspice\u201d affected every part of my life, I\u2019m almost angry. But I have to remember to be grateful too. Without it, I don\u2019t think I would have come this far. - I sometimes expect it to \u201cfix\u201d me. But it doesn\u2019t of course. It does help a lot though.  - I have to remember to set an intention before I take them. Or I end up wasting my time anyway. But more focused.</p>"},{"location":"articles/Mental%20Health/ADHD%20%2B%20Autism%20-%20Challenges%20and%20hopeful%20workarounds/#rejections","title":"Rejections","text":"<p>I don\u2019t want to throw terms around, but RSD (Rejection Sensitive Dysphoria) has shadowed me all my life. Like it probably has many of you. More than anything, I realise it hurts more because we are always trying to play \u201ccatch up\u201d with everyone else. And.. honestly\u2026 it\u2019s very unfair.  - Recently, I have been trying to have the courage to speak up and say \u201chey, that kind of hurt. I would appreciate some empathy.\u201d Sometimes, it helps. - I realize the ADHD side wants to talk a lot, keep talking and enjoy. But the ASD side can\u2019t keep up with it. It gets very overwhelmed. I talk a lot, but when someone asks me something, I freeze. Then I stutter something or just, want to disappear into the ground.  - I think a lot of times, we are just expected to be able to do something. But we can\u2019t and everyone just says \u201cyou are just lazy\u201d when I\u2019m not. I really want to do it. But the other side of my head wants to shut down forever.  - I\u2019m learning to take breaks. Give my ADHD side conversation but then also take my time to soothe and recover. </p>"},{"location":"articles/Mental%20Health/ADHD%20%2B%20Autism%20-%20Challenges%20and%20hopeful%20workarounds/#people-and-forgetting-them","title":"People.. and.. forgetting them","text":"<p>Another rather interesting and sad feeling I\u2019ve had is that if I don\u2019t interact with someone for a few days, they kind of.. disappear. I stop feeling anything for them. It\u2019s not permanent of course. I still care a lot, and love the people I do. But, I forget to reach out. And.. they get hurt. - Most of my life, I blamed myself for being well, I dunno what. \u201cYou forgot to even text your girlfriend today, come on man. You love her right? You can\u2019t even remember she\u2019s there because she\u2019s in a different country right now? Such a dumbass\u201d.  - At some point, I realized that it\u2019s the same thing with me and cupboards. If I wanted to stop eating chips or cookies, I would keep them at the back of a cupboard and then forget they ever existed. I vaguely know they are there, I just don\u2019t act on it or feel anything towards it. - Note to self. If you care, try to make semi regular contact. It will help you \u201crenew the connection\u201d. - Note to self P2. You are not a sociopath. You are neurodivergent. You still have feelings. Too many of them lol.</p>"},{"location":"articles/Mental%20Health/ADHD%20%2B%20Autism%20-%20Challenges%20and%20hopeful%20workarounds/#organisation-and-planning","title":"Organisation and Planning","text":"<p>Gods. I\u2019m so bad at this it is not even funny. Some things arguably make it slightly easier though. - I realise I get frustrated because I don\u2019t have parts of the puzzle and  in spending time trying to find them, I lose all my motivation to work. So instead, I first try to collect all the information I might need for something in one place. I do not start actual work before I do.  - I try not to do things in parts. I sit down and finish things in one go. If I can. - Simplify, simplify, and simplify some more. The more choices you have, the harder you make something. Pick the essentials. You cannot plan everything and you will get overwhelmed.  - Ask for help. I know, I know. But it\u2019s okay. Pick someone who might understand if you can? In time, maybe we can be better at it too.</p>"},{"location":"articles/Mental%20Health/ADHD%20%2B%20Autism%20-%20Challenges%20and%20hopeful%20workarounds/#masking-general","title":"Masking - General","text":"<p>I admit, I don\u2019t fully understand to what extent this affects me. It is a lot, but maybe in time I will understand it more. - It started ages ago in school - when I didn\u2019t look people in the eye, or when I spoke in monotone, or when I would not talk at all, or when I spoke too softly. My mom, or teachers would tell me I wasn\u2019t \u201cnormal\u201d and tell me what to do instead. And they would be \u201cvery\u201d upset about it if I didn\u2019t. So I started pretending. I would look people in the eye, I would talk louder, I would \u201cemphasise\u201d, heck I pretended to be emotional too sometimes.  - I didn\u2019t realise it was slowly taking over though. In time, nobody believed me anymore when I said I was different. They\u2019d say, no you cannot have ADHD/ASD. You are too \u201cnormal\u201d. Well, another one bites the dust I suppose. - Who are you when the dust settles and you are alone in your room crying your eyes out because it hurts so badly that nobody ever understands you? Give that person a long hug because oh god, they tried their best.  - I tried so hard, and go so far, but in the end it doesn\u2019t even matter~ . There is always a price. At the end of the day, who are you living for?</p>"},{"location":"articles/Mental%20Health/ADHD%20%2B%20Autism%20-%20Challenges%20and%20hopeful%20workarounds/#masking-adhdasd","title":"Masking - ADHD/ASD","text":"<p>Ah this is a nice little cocktail. Do they cancel each other out? Not really. I just feel like I am always at war with myself. I do not have workarounds yet, so I will just list down what I face instead. - I really want to do the dishes because warm soapy water is fun, but the other side wants to shut down forever and scream. - I make plans to hang out with new people, but the other side wants comfort and people I know already. - I want to plan novel experiences, new trips, new food etc, but the other side wants to do none of them and sit at home and have ramen. - I am horrible at conversations and I die inside each time someone asks me something I don\u2019t know, but the other side of me learns to adapt so fast nobody even realises that I\u2019m screaming inside. - One side of me has gotten too good at pretending to be normal, while the other needs days to recover from all this masking. - I technically should not be able to work as much as I do, but when I hyper focus, I am unstoppable. When I don\u2019t, I am a carrot.  - I like working on new projects, new hobbies etc, but the other side wants to sit and do the same thing everyday because new things are scary. - I beat myself up so badly and get good grades so everyone thinks I\u2019m a genius and have it so easy because I get so much done. Ah. Well. Madame, there is always a price</p> <p>(I think my motivation is running out now. Or maybe it\u2019s because I didn\u2019t have lunch yet.)</p>"},{"location":"articles/Mental%20Health/ADHD%20%2B%20Autism%20-%20Challenges%20and%20hopeful%20workarounds/#social-media","title":"Social Media","text":"<p>I think this kinda applies to everyone. But more so to us. Doom scrolling is the bane of my existence. But I am trying to use what I have learnt about my brain to make it easier to cope. - Brain loves dopamine right? Stop giving it that. Make social media a chore. Open instagram on your browser, step back and see how \u201cboring\u201d all the reels are. Do you really want to watch someone make a coffee for the fourth time today? No you don\u2019t. - Shove it in a cupboard. Forget it exists. For a while atleast. - Write instead. I would never have been able to write so much before. But ever since I replaced my doom scrolling with writing, it\u2019s easier. - It doesn\u2019t always work. Yeah. Sorry. You can\u2019t fully forget about it. It\u2019ll come back. You\u2019ll waste hours on it. But\u2026 atleast you saved a couple.</p>"},{"location":"articles/Mental%20Health/ADHD%20%2B%20Autism%20-%20Challenges%20and%20hopeful%20workarounds/#a-thank-you-note","title":"A thank you note","text":"<p>There are so many people I want to thank here. I sadly do not know who most of them are.  - Jessica and their team from HowToADHD (https://www.youtube.com/@HowtoADHD). I am so grateful to you I want to run to you from the other end of the world and give you one huge huge huge hug. Thank you. Thank you so so much. (Am I really tearing up now? Yes.) I don\u2019t have words but you have my eternal gratitude. - Reddit and all of you. Feeling like I am not alone here makes things a lot easier to handle. I am very grateful to you for giving me that. - Every website that gave me tips on how to manage my life. Not all of them helped of course, but they were a start.</p>"},{"location":"articles/Mental%20Health/What_I_learnt_about_myself_after_two_years/","title":"What I Learnt About Myself the Past Two Years","text":""},{"location":"articles/Mental%20Health/What_I_learnt_about_myself_after_two_years/#what-i-learnt-about-myself-the-past-two-years","title":"What I Learnt About Myself the Past Two Years","text":"<ul> <li>Irrational rage with task interruptions : probably because I am not sure if I can come back to the task now or ever, or how long the interruption will last.</li> <li>Being told to do things right when I am just about to do them makes me feel like control is being taken away from me. And since I barely have control usually, that just frustrates me a lot.</li> <li>Cleaning is hard because it feels like a big thing. This could be also similar with things I suck at, and the energy cost for it is crazy.</li> <li>If I clean everything, the next time I have to do it, it feels like it's a brand new task. And brand new tasks take a lot of energy</li> <li>I always only do upto 80$ of something. Just by this point if I knew about ADHD as a kid I would have been diagnosed already.</li> <li>I am slowly learning that masking does take a lot of energy, and when I don't have it it pisses me off</li> <li>When I get hungry my ADHD is at max</li> <li>ADHD is not really about not being able to focus but more of being unable to regulate it</li> <li>If I change the food I want slightly then it makes it a looot better. Even if that means adding some tiny sauce to it</li> <li>Exercise REALLY helps</li> <li>Sometimes simple things that you don't consider to solve anything solves anything : like the breathe right nasal strips?</li> <li>Showers help me regulate</li> <li>I love running, a lot</li> <li>Travelling on trains is not bad if I take care of noise and have something to do</li> <li>If I plan my day before doing anything or have something to look forward to, it really helps</li> <li>Long conversations are also fine if I am drawing or have something to regulate my emotions</li> <li>Low energy people are so nice to be around though. Esp other neurodivergent people. Gods.</li> <li>I have more friends than I think I do</li> <li>People love talking about things they care about. I asked Manon for running shoe recs and it's one of her special interests apparently</li> <li>I get angry a lot because I feel like my boundaries are being crossed but I have grown up ignoring them</li> <li>Mayu needs space in between things like space when she comes back home. </li> <li>Mom likes to talk and she does not super care if someone pays that much attention but atleast cares enough to give her some attention. Makes sense right?</li> <li>I dont actually hate TV. I just need something else on the side to regulate because my empathy kicks in a lot of times</li> <li>I sometimes get too much input from things and then need to take some of it out. Like write something, draw something whatever</li> <li>If I start getting annoyed with something that I love, it means that I probably hyperfocuses the absolute shit out and should probably give myself a break before it gets too much</li> </ul>"},{"location":"articles/Others/A%20letter%20to%20my%20junior%20school%20art%20teacher/","title":"A letter to my junior school art teacher","text":""},{"location":"articles/Others/A%20letter%20to%20my%20junior%20school%20art%20teacher/#a-letter-to-my-junior-school-art-teacher-david-fitzgerald","title":"A letter to my junior school art teacher - David Fitzgerald","text":"<p>Dear David sir,  This is Subhaditya, or Vishal as you knew me back then. I barely remember how many years ago it was. You had recently started teaching art in my class then. I have these vague memories of awe when I saw you draw on the blackboard with a marker. It seemed like magic almost, you would draw some lines and suddenly, presto! It was a horse. Or a dragon. Or a face.  Did you know I have loved dragons since then? You always started them with the letter 5.  I remember pestering my parents about art. Back then I used to doodle and draw all the time. When I went to Kolkata for the summer break, my parents enrolled me in a class for painting. It was with my cousin brother, and I hated it. It felt so stifling. I do not remember the chronology of this, of course, I was in the fourth grade I think. A little boy who just wanted to draw dragons. </p> <p>At some point, mom decided to ask you if you were willing to teach me art after school. Once a week. I think it was on weekends, I cannot remember. You did not take tuitions, and I was just a child anyway. But somehow you agreed. I remember going to your place the first day with an art book. You had a pet chameleon that was fascinating to me. I remember that it jumped on me. I can still feel its tiny claws on my shirt. You showed me a tattoo machine. An airbrush. You painted horses. You painted dragons. You made me paint a dragon.</p> <p>I loved those days. At least, I think I did. After all, I had forgotten about them until now.  You gave me a little pebble with a white horse painted on it. I still have it back at home. </p> <p>I started painting properly during the pandemic in 2019 when I found art videos online. It\u2019s been a few years since then. But if I think back, I remember traces of me trying to draw all my life. I never did it properly though. I did not realize it was something that I could do. </p> <p>It is almost the end of 2023 as I write this, I graduated with a masters degree in AI a few days ago. In my hunt for a job, I came across one that had the toc: true title of \u201cCreative Technologist\u201d. It was an entry to art! As I write this, I am waiting to know if they accepted me for the job. It will be my first one. </p> <p>While trying to find my way of art and thinking about the job, I suddenly remembered those days with you. And then I realized why I had stopped drawing. And\u2026 what made me fall in love with it in the first place. </p> <p>Will you take a guess? Of course. It was. You.</p> <p>You, David sir. You.</p> <p>But life is not easy is it? I wonder if things had not gone the way it did, and you had stayed, perhaps this life of mine would have been very different.</p> <p>I remember walking into class one day and seeing a new lady. Maybe she was a nice person, I do not know. I remember her trying to teach shadows with a coat hangar.  I missed you. I wanted to know where you went.</p> <p>I don\u2019t remember how but I found out that you had tried to kill yourself. I remember hearing that you set yourself on fire, that your skin had melted off. I remembered those hushed conversations.  I vaguely remember seeing a picture, or did I actually see you? I do not remember. As a kid, I did not understand what it meant. I thought you left because they thought you looked like a monster.</p> <p>As an adult, I wonder how it must have felt. Many years after that, I had long forgotten these things, wiped away in the warm embrace of forgetfulness. I blocked off my art without realizing it. It broke me I think. There were many factors, of course. But that is not the point of this letter. In my darkest times, I wanted to kill myself many, many, many times. I wonder how it felt when it didn\u2019t work. When you were left with the ashes of a broken life. I wonder how you are now, more than a decade later. </p> <p>I wonder if you were made to feel like a monster for the gift that you had. I wonder if it tore you apart. I wonder what set you on fire. Was it you? Or was it them? </p> <p>The real demons are not us are they? You were not a monster then, they were. </p> <p>After I rediscovered art, I started getting better you know? I no longer wanted to die. I didn\u2019t realize that that was what saved me in the end. I just did while writing this letter to you. Art showed me the world for what it was, not what I was told it was.</p> <p>I tried to find you online, but I can\u2019t. I wonder where you are now. If you are even alive. I don\u2019t know. Maybe one day our paths will cross. Maybe they won\u2019t.</p> <p>I want you to know that I have been painting almost everyday for the past few years. I have a long way to go, but I am getting there. Art has made my life brighter. I wish I could show you my work. I wish I could tell you that I went to two art conferences and got to meet some of my favorite artists. I wish I could tell you that my friends have my art hanging on their walls. Yes, i gave it to them. But they cherish it, I think. Yes, I still do not feel like I am at a point where I can accept those compliments. </p> <p>I suddenly remember something you said once. A classmate had drawn something poorly and he expected anger, like all of our other teachers had. You stood in front of the class and said, \u201cLet nobody tell you that your art is bad. There is no bad art.\u201d I wonder if you feel the same way about yourself.</p> <p>I realized that art is not just our work, it is us. We are creatives. We live, breathe and exude creation. I do not know why. I don\u2019t think anyone does. I realized that if we stopped creation, it either destroys us, or finds the cracks in our soul and gets out somehow. </p> <p>You will probably never see this. Even if you did, I doubt you remember any of these. But, I do now. I see you sir, Mr.David Fitzgerald. I see you. I see your pain. I was a child then, but I\u2019m all grown up now. </p> <p>This is making me cry, so I will end this here. </p> <p>Thank you sir, you started this journey for me without me realizing it. There are so many things I want to say that I can\u2019t. If you are out there somewhere, I want you to know that you made a difference in my life. Perhaps this journey towards art was complicated by your pain, but perhaps it was the only way I could process it. After all, you were my art hero. As a little kid, what could hurt more than knowing that heros could die too? </p> <p>Thank you David sir, for the horses, dragons and the magic. Thank you. </p> <p>Wherever you are, I send you my love and affection. Little Vishal to you. I hope the fire that consumed you showed you the road you were scared to take, and I hope you followed it. </p> <p>Thank you. For everything. Subhaditya Mukherjee 17th October 2023</p>"},{"location":"articles/Others/Ai_for_startups/","title":"Ai for startups","text":"<p>toc: true title: Ai_for_startups</p> <p>categories: [\"article\"] date modified:  date created: </p> <p>AI For startup #ai</p>"},{"location":"articles/Others/Ai_for_startups/#hitchhikers-guide-to-ai-for-startups","title":"Hitchhikers Guide to AI for Startups","text":"<p>Are you part of a startup, or want to start one? Want to have AI superpowers but don't know where to start? Want to make sure you don't sink your boat before it floats? Make sure you hire the right people and avoid blowing your budget out of the water. This article is for you.  A helpful guide on what to focus on, resources you need, and punching common myths in the face. Sounds interesting? Read on.</p> <p>(This is a long article. Skip to what you need. But if you are just starting, I would recommend reading the whole thing. Take your time. Take notes. Drop me an email with your questions. msubhaditya@gmail.com)</p> <p>Okay, now, DONT PANIC.</p>"},{"location":"articles/Others/Ai_for_startups/#a-definition","title":"A definition","text":"<p>Before we move on, let us first define what we mean by AI. Of course, there are quite a few definitions but for our purposes, we can define it as \u201cany means of injecting a form of semi-automated intelligence that either performs a task previously impossible for computers or does a task as good as/better/faster than a human. An AI is used to learn how to perform a task, and can be thought of as a more advanced software.\u201d Note for AI experts: The term AI is used in the article as a general word, interchangeably with deep learning, neural networks, etc. Yes, technically this is inaccurate. But this is an article for people with not much in the way of experience.</p>"},{"location":"articles/Others/Ai_for_startups/#some-useful-terms-you-might-need","title":"Some useful terms you might need","text":"<ul> <li>AI model/architecture: The brain that makes up an AI</li> <li>GPU: A specialized computing unit that accelerates intensive computation, like training an AI</li> <li>Neural Networks: Inspired by the brain, what makes \"AI\" tick</li> <li>Latency: How long does your model take to give results</li> <li>SOTA: State of the Art. What is the best model for the task, right now?</li> <li>Training: The process where the AI learns how to perform a task</li> <li>Inference: Using a trained AI to predict some results</li> <li>Cluster: A group of computers used to parallelly perform a task</li> </ul>"},{"location":"articles/Others/Ai_for_startups/#a-little-index","title":"A little index","text":"<p>This article is divided into three major sections.  - If you want to dive into this field for the first time, or find ways to inject some AI into your companies, the first section is for you. - If you already have an AI startup, and are looking for ways to improve your infrastructure so you can grow, the second section is for you. - The third section talks about some of the pitfalls that one might face when they first dive into this space. Take it as a word of caution. </p>"},{"location":"articles/Others/Ai_for_startups/#section-1-the-beginning-stages-or-how-should-i-care-about-ai","title":"Section 1 - The beginning stages Or How should I care about \u201cAI\u201d?","text":""},{"location":"articles/Others/Ai_for_startups/#cutting-through-the-hype","title":"Cutting through the hype","text":"<ul> <li>Unrealistic expectations At the end of the day, AI is not a magic mushroom. It cannot solve everything you want, and neither can it evolve and take over the planet. Yet. Can you use it for your needs? Undoubtedly. So what can it do? It can categorize images, translate text, understand what it hears, recognize tumors, and anything your creativity allows.  The key is to set realistic expectations. Think of it this way, if you can get a team of experts to do the task, then it might be possible to have an AI do it (Terms and conditions apply). Ask an AI consultant, or if you cannot afford one, look at this website [insert paperswithcode] for a list of tasks that are possible. If nothing else, it can give an idea of what can be done. Sometimes it might be possible for your idea to work in the long run, but it might just take more time and resources than you imagined. Only an expert would be able to tell you if it is a feasible plan. Expecting your developers to come up with something impossible is great, but only if you can afford it. For example, instead of trying to make an \"AI that will take humans to Mars\", break it down into smaller tasks - \"AI that recognizes space debris\" + \"AI that would identify system faults\" + \"AI that might predict what a type of rock found was\" + ... etc</li> <li>Data requirements It is a myth that to \"train\" an AI, you need massive amounts of data. Yes, technically you do. But recently, there has been a lot of research conducted on \"transfer learning\", which is a technology that allows you to start with an AI trained on large amounts of data, and fine-tune it to your specific use case. This is very helpful, especially if you are working on tasks similar to those that exist. For instance, if you want to train an AI to recognize different types of cars, this might not need a massive amount of data, because similar \"recognition\" tasks exist. But if you want to classify a hundred types of new tumors, that might require a little more data. </li> <li>Extreme requirements The Tech giants want everyone to think that we need extreme computing power for our AI needs. But in reality, most companies can start with minimal requirements. Even if you cannot afford huge computing clusters or lots of computers, you can use online services to run the code. There are quite a few such services that provide \"GPUs\" (special computing units that accelerate running compute-intensive code). They charge you a fee by the hour, which is often quite cheaper, even at scale. As long as you have skilled workers, decent computers, and funds to support it. A word of warning, AI is still an experimental field. If your staff does not deliver, it would serve to try and understand if the task handed to them is realistic, or needs more resources. An AI expert/consultant would be helpful here.</li> </ul>"},{"location":"articles/Others/Ai_for_startups/#so-you-want-to-be-an-ai-startup","title":"So you want to be an AI startup?","text":"<ul> <li>Is AI needed? The rush to say \"We use AI in our products to do XYZ\" is very intense. Do not fall into peer pressure. It serves to first understand and identify where you need AI. Does a specific part of the infrastructure need to be revamped? Is there something you want to do that just normal programming cannot handle? Have you tried other options first? AI is expensive in the long run. Can you afford the staff? Pay for the time taken to research? Test some ideas, you might be able to hire a freelancer to make some mockups before diving in headfirst.</li> <li>AI products vs AI as part of your existing infrastructure You might not need to fully use AI, maybe only some parts of your idea need it. If you are a new startup, please note that just AI will not be the end of all. Even if your idea is a pure AI product, there are quite a few software engineering components in it as well. It serves to understand the pipeline before starting, just so you do not fall into common traps and end up wasting time and money.</li> <li>Domain knowledge Does your product revolve around a specific domain? Hire/Consult an expert. You will suffer badly otherwise. Yes, an AI model will give you results. But you will have no way of knowing how well they do. Just having numbers is not enough. In return, this will help you make even better software.</li> <li>Survey Understanding your customer base is even more important here. The better you understand the requirements, the better you can make use of AI. The more you can flesh out your ideas, the more specific you can get with your software.</li> <li>Competition Who is your competition? Do you have the time to revamp your software? Everyone wants AI these days. Some companies can spend millions on it, while others can't. If you are in a field that has cutthroat technology developments, just starting up might be harder for you if you cannot afford it. If you are a new startup, try to focus on fields that need solutions but do not have larger corporations working on them. Domain expertise is great here.</li> <li>Using products from Google/Microsoft/Amazon You will find every big company these days offering AI support. Should you use them? In my opinion, these are useful if you are planning on performing a very common task. If you have a domain-specific idea, making your own is probably the better bet. But do not hesitate to make use of the resources that they offer. Google Colab, Amazon AWS, and Microsoft Azure are great services. Using them, especially at the start, is a good idea. They could be a cheaper way of testing out your ideas.</li> </ul> <p>Remember, AI is a tool. Not a complete product.</p>"},{"location":"articles/Others/Ai_for_startups/#section-2-the-mid-stages-or-how-can-i-make-sure-i-make-my-best-ai","title":"Section 2 - The mid stages ,Or, How can I make sure I make my best \u201cAI\u201d?","text":""},{"location":"articles/Others/Ai_for_startups/#focus","title":"Focus","text":"<p>Being an AI startup, you have a lot of things to look out for. Some of the main focus points to keep in mind are as follows. - Clear goals of what you want to achieve With any endeavor, knowing exactly what you want is imperative. More so in fields where testing takes up quite a lot of time and money. The better and more fine-grained your explanation, the better your results. - Clear expectations on what is possible within a time frame I repeat, AI is a research field. Just because Google can make a huge product in a matter of months, does not guarantee you can too. An expert can help you set more realistic goals. You can, of course, try it out on your own, but only if you have the time and the risk appetite for the same. - Easy of use Make sure your service is easy to use. Using AI will suddenly show you how many knobs and switches you need to control. Do not overwhelm your poor users. Specific research in understanding what your customer wants is essential. - Multiple large platforms Scaling up is probably not a major concern for you right now. If it is though, make sure you can afford it. If you can't, see if you can outsource it, or use an online service. Perhaps also consider other ways of optimizing your workflow. - Quick, rough tests Before you work on a final product, try out some small ideas. Hire freelancers if you do not have full-time staff on hand. Try out different models with any data you have on hand. Making sure you have a good baseline will save you quite some headache later on. - Validation testing By this point, you might have heard me say \"test your ideas\" quite a lot. But again, test your models. Use new data, use crappy data. Does it still work? If not, keep working.</p>"},{"location":"articles/Others/Ai_for_startups/#people","title":"People","text":"<p>Aside from being able to build AI models, you also need people who would be able to support the infrastructure. Make sure you have domain experts you can call on. Also find people who would be able to deploy the model onto a chosen service, and can maintain them. Of course, the usual requirements of making an interface, servers, etc still stay based on the type of project you have in mind. Budget and requirements play a key role here and are specific to your idea and scale.</p>"},{"location":"articles/Others/Ai_for_startups/#section-3-a-word-of-caution-how-can-i-make-sure-my-boat-does-not-sink","title":"Section 3 - A word of caution How can I make sure my boat does not sink?","text":""},{"location":"articles/Others/Ai_for_startups/#capacity","title":"Capacity","text":"<p>Oh? So you made an AI model? Congratulations. Now you need to get your users on board. Regardless of if you have an app, a website, or a device, make sure you can estimate how many users you will have. AI models tend to take more resources than classical computer software.  Identify how long your model takes to get results. Will your users be fine with that? Do you need more resources to ensure faster outputs? Will they be able to reliably access your service? Test, test, test. There are quite a few optimizations possible. It is beyond the scope of this article, but you can drop me an email if you want to know more.</p>"},{"location":"articles/Others/Ai_for_startups/#model-drift","title":"Model drift","text":"<p>Over time, how good your results are will drift. This might be because the data your model learned differs from the model it is getting now. For example, in a fashion-related product, the trend of clothing changes over time. Using an old model that has not seen new data will not be great. Periodically checking for a spike in errors, and retraining the model on new data is essential. Make sure your employees know how to do that.</p>"},{"location":"articles/Others/Ai_for_startups/#bias-and-ethical-concerns","title":"Bias and ethical concerns","text":"<p>If you teach a kid that colored people are evil, that's what they will learn. Similarly, an AI model can learn mistaken assumptions. The larger the data, the more such assumptions are automatically made. Identifying these would help you understand if your product would have unintended consequences. The more variation you can provide to your model, the better in the long run.  Make sure your data is inclusive. Especially if it contains hints of the biases of age, gender, ethnicity, etc. Test for these biases specifically. Make sure that you can explain if your model goes wrong and does something stupid. There is a great course on how to do this Ethics for AI by Rachel Thomas from fast.ai.</p>"},{"location":"articles/Others/Ai_for_startups/#fin","title":"Fin","text":"<p>So, will you use AI, or will AI use you Feel free to reach out or leave your comments. Email: msubhaditya@gmail.com</p>"},{"location":"articles/Others/An%20understanding%20of%20will%20-%20Part%201/","title":"An understanding of will - Part 1","text":""},{"location":"articles/Others/An%20understanding%20of%20will%20-%20Part%201/#an-understanding-of-will-part-1","title":"An understanding of will - Part 1","text":"<p>Willpower is illusive. In essence, it would be something that you don\u2019t encounter unless you see an extreme. Someone going through insane hardships to make ends meet, a mother lifting a car up to save her child, people struggling through all odds to escape oppression. But in real life, sometimes you encounter people like that. Ones that have lived entire lives with the ability to drag through. Hell, high water or drought. They will pull through anything. The question of course, is.. how? How can someone pull through being a 95 year old grandmother with every last living direct family member having passed on; in the last decade? How can one push through holding their husband, their child, their siblings as they took their final breath? It truly shows how strong we are , when we want to be.</p> <p>Willpower is fleeting, yet all pervasive. Sometimes it only lasts for a few moments. Sometimes it lasts for years. Sometimes it is that frantic burst of energy we get to clean our rooms and get our life straight at 3 am when we cannot sleep. Other times, it is people working towards a common goal for years on end, building schools, cities, empires.  How do any of these people prevail through ages of discomfort, misery, pain and what would seem like an inhuman amount of suffering?</p> <p>I think it boils down to a few core ideas. 1 - A reason For someone to get up at 6 am everyday to go for a run, there must be a reason. Without one, they are not better than a caged animal pacing around. Be it making a difference in someones lives, or as penance, or as a way of redeeming something that was lost. These are motives we hear all around us. But there are other, more subtle motives that show up from time to time. One persons dream of bringing their poor parents into a new home. Another person\u2019s dream of building a school for women who were never given a chance to learn. Another of providing wartime health services. All of them have something in common - emotion. Long, deep, slow. An ache that must be massaged.  2 - Challenges Through time immemorial, we have never faced a lack of problems. Most people wait for someone to solve them, some try and some others succeed. Through all of these stories, we see that most of these people were not exactly taught the hardcore perseverance that they show. Some had it beaten into them, others had no choice but to get their shit together, others were running from something they were too scared to face.  3 - Beliefs At the end of the day, we are the sum of our thoughts. The first time you realise, just how much your life is influenced by your perspective on life, it changes you. There are people who are not willing to believe that they would lie down and let their fate drag them. You see people like this, they stick out like a sore thumb. You know people like this, maybe a grandmother who faced war and famine but still is the nicest person you know. Or a parent, who against all odds, raised healthy and successful children. Or even a friend, who went against everyone and everything to pursue a career nobody approved of.  4 - Consistency  The person who wakes up at 6 am and goes for a run everyday, would be hard pressed to be eating chips the minute they wake up. But if they let themselves go for long enough, the efforts of years of discipline is lost. It is truly strange if you think about it isn\u2019t it?</p> <p>From these ideas, what can we think of that will make us\u2026 mentally stronger over time? If you start looking, you will find countless pieces of text that try to answer this question. This particular article does not aim to be more definitive than any that preceded it, but collects the stories the author has had the fortune of hearing.</p> <p>1 - Do something hard every day.  2 - Document your day, to yourself, honestly. Keep a journal.  3 - Find a few things that truly matter to you. Be it a sunset, or people, or that book you\u2019ve been reading. Beware though, that this will change in time. You will not have the same thoughts forever. What you like and care about will change. The point is to just have something that matters. 4 - Discipline really does matter. In times where sticking to a routine does not really seem feasible, look at the tiny things that you do. Did you tuck in your blanket? Drink water right after you wake up? Light a candle? Wind down? In times where all else fails, these little things give you the sanity that you would not find otherwise. Look inside, you will find your own little routine. 5 - Being part of a community. We need people. Hopefully some of those people need us too. It also helps if those people share a hobby with you.  6 - Finding the joy in the little things. It goes a long way. Sometimes a warm bowl of soup gives you the motivation to continue.  7 - Light your own candles. If you keep waiting, they will just remain dark and cold. 8 - Give yourself a little reward, if you can. If you learn to love the hardships, then you can be better at facing them 9 - Learning some form of meditation or prayer seems to help tremendously.</p>"},{"location":"articles/Others/Duolingo%20is%20a%20platform%20for%20language%20learning/","title":"Duolingo is a platform for language learning","text":"<p>toc: true title: Duolingo is a platform for language learning</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Others/Duolingo%20is%20a%20platform%20for%20language%20learning/#my-take-on-some-ml-interview-questions-p1-ai-inprogress","title":"My Take on Some ML Interview Questions - P1 #ai #inprogress","text":"<p>Chip Huyen is one of my favourite authors in the space of MLOps. She has some great blogs, and a really useful book. In one of them, she asks the following questions. This blog post is my answer to the ones I felt I could contribute interesting points to. Since there are quite a few, I will probably split them up into parts. </p> <p>Note: These are my views on these questions. They are not a comprehensive resource by any means. Just me thinking out loud on how I would go about solving the problem. Like any research project, as more time passes, these answers might change. They are here as a way for someone starting out to get a feel for approaching problems posed to them.</p> <ol> <li>Duolingo is a platform for language learning. When a student is learning a new language, Duolingo wants to recommend increasingly difficult stories to read.<ol> <li>How would you measure the difficulty level of a story?</li> <li>Given a story, how would you edit it to make it easier or more difficult?</li> </ol> </li> <li>You run an e-commerce website. Sometimes, users want to buy an item that is no longer available. Build a recommendation system to suggest replacement items.</li> <li>When you enter a search query on Google, you're shown a list of related searches. How would you generate a list of related searches for each query?</li> <li>Each question on Quora often gets many different answers. How do you create a model that ranks all these answers? How computationally intensive is this model?</li> <li>How to you build a system to display top 10 results when a user searches for rental listings in a certain location on Airbnb?</li> <li>When you type a question on StackOverflow, you're shown a list of similar questions to make sure that your question hasn't been asked before. How do you build such a system?</li> <li>On social networks like Facebook, users can choose to list their high schools. Can you estimate what percentage of high schools listed on Facebook are real? How do we find out, and deploy at scale, a way of finding invalid schools?</li> <li>How would you build a trigger word detection algorithm to spot the word \"activate\" in a 10 second long audio clip?</li> <li>If you were to build a Netflix clone, how would you build a system that predicts when a user stops watching a TV show, whether they are tired of that show or they're just taking a break?</li> <li>Facebook would like to develop a way to estimate the month and day of people's birthdays, regardless of whether people give us that information directly. What methods would you propose, and data would you use, to help with that task?</li> <li>Imagine you were working on iPhone. Everytime users open their phones, you want to suggest one app they are most likely to open first with 90% accuracy. How would you do that?</li> <li>How would you train a model to predict whether the word \"jaguar\" in a sentence refers to the animal or the car?</li> <li>How would you create a model to recognize whether an image is a triangle, a circle, or a square?</li> <li>Given only [../../CIFAR|CIFAR]-10 dataset, how to build a model to recognize if an image is in the 10 classes of ../../CIFAR|CIFAR-10 or not?</li> </ol>"},{"location":"articles/Others/Easier%20Deep%20Learning%20Research%20for%20Beginners/","title":"Easier Deep Learning Research for Beginners","text":"<p>toc: true title: Easier Deep Learning Research for Beginners</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Others/Easier%20Deep%20Learning%20Research%20for%20Beginners/#starting-deep-learning-research-part-1-a-start-using-fastai-dl","title":"Starting Deep Learning Research (PART 1): A start using FastAI #dl","text":"<p>{{TOC}} So, you took your first steps into Deep Learning. Maybe you read a few articles, did a course or two, and watched a bunch of videos. Or maybe you just heard so much about it that you wanted to learn more.  Welcome.  This is a beautiful world. It is also very overwhelming. There is so much to learn and understand. But we need to start somewhere. This is your ticket. Enjoy the ride.</p> <p>Note: This will be very long-winded as it is meant for complete beginners. It might seem very scary at first. But don\u2019t panic. The hardest part is getting started. Hold on. Come back to it. It will take time. Slow down. Read through it. It will save you a lot of pain later on.</p>"},{"location":"articles/Others/Easier%20Deep%20Learning%20Research%20for%20Beginners/#entry-requirements","title":"Entry Requirements","text":"<ul> <li>Go to this link for the code and follow along kaggle_notebook. Once that opens up, click the button next to \u201cAccelerator\u201d and choose GPU. Accept the terms.</li> <li>You have learned some Python. If not, go to YouTube and learn as much as you can first. Do as many examples and problems as you deem enough to understand. Come back.</li> <li>You know what a GPU is and if you have one.</li> <li>You have a computer and an internet connection.<ul> <li>If you have a powerful computer, you can set this up locally. fastai<ul> <li>You will need an editor. I would recommend VSCode. </li> <li>If you do not, that\u2019s alright. You can still follow along.</li> </ul> </li> <li>Watch a small tutorial on how to use a Jupyter Notebook here.</li> </ul> </li> </ul>"},{"location":"articles/Others/Easier%20Deep%20Learning%20Research%20for%20Beginners/#what-we-want-to-do","title":"What we want to do","text":"<p>Today we will be teaching our little \u201cAI\u201d how to categorize different fruits. To do that, we need to give examples - aka the \u201cdataset\u201d. You can grab it from Kaggle.  We will show our little \u201cAI\u201d quite a lot of images and tell it \u201chey, this is an Apple, this is not one\u201d and so on, in the hope that it will learn. The exact algorithms are not important at this stage. I believe it is first good to be able to see where to use it in practice and play around with it before diving deep.  In the end, we want our \u201cAI\u201d to accurately classify the fruits that it has learned about.</p>"},{"location":"articles/Others/Easier%20Deep%20Learning%20Research%20for%20Beginners/#libraries-we-will-use","title":"Libraries we will use","text":"<ul> <li>Major Framework : Pytorch. Deep learning is quite a vast field, which means that code quickly starts to become complicated. There is a lot of boilerplate code that needs to be written every time you want to make something. Writing the same 200 lines of code every time is not efficient, and leads to bugs and weird errors. To avoid that, we use a framework that handles most of the hard work for us so we can focus on innovation and application. There are quite a few of these frameworks, PyTorch and Tensorflow/Keras are the two major ones in Python. \\     I prefer Pytorch. There are many reasons for that. Instead of me adding to this blog about them, read this little article by the creator of the next library we will use, link</li> <li>fastai FastAI was one of my first introductions to research grade Deep Learning. It is a wrapper around Pytorch that does live up to its name. Pytorch, being a general framework, focuses on the core components of Deep Learning. FastAI was made to provide a lot of ease-of-use functions that Pytorch did not. But because it\u2019s just a wrapper, any functions that Pytorch offers can be easily accessed. </li> </ul>"},{"location":"articles/Others/Easier%20Deep%20Learning%20Research%20for%20Beginners/#grab-the-data-and-set-everything-up","title":"Grab the Data and Set Everything Up","text":"<ul> <li>Make an account on Kaggle. This is not promoted or anything. It is probably one of the biggest hubs for AI code, and you will make an account sooner or later. Better to do it now.</li> <li>If you are using this link, click the 3 dots, and then click \u201cCopy and Edit\u201d. That will set up the data and the code for you. </li> <li>If you are working on your machine, you can download the notebook by clicking the 3 dots, and then clicking \u201cDownload code\u201d. Open this up in VSCode. The data can be found from Kaggle. </li> </ul>"},{"location":"articles/Others/Easier%20Deep%20Learning%20Research%20for%20Beginners/#code-imports","title":"Code Imports","text":"<p>We will need to first import the libraries we will use.</p> <pre><code>import os\nfrom fastai.vision.all import *\nfrom fastai.vision.widgets import *\n\n# Set the base directory where Kaggle saves its data. Change this if you are on your machine.\nroot_dir = \"../input/fruits/fruits-360_dataset/fruits-360/Training\"\n</code></pre>"},{"location":"articles/Others/Easier%20Deep%20Learning%20Research%20for%20Beginners/#load-data","title":"Load Data","text":"<p>Fastai provides quite a few convenient functions to load data. Now slow down. What do we have? Think about it for a second. We have an image and a label right? And we need to \u201cmap\u201d the image to the label. If this does not make sense. Think about it some more. This is important. Okay. </p> <p>Now, what does the file path for an image look like? Something like : \"../input/fruits/fruits-360_dataset/fruits-360/Test/Cantaloupe 1/r_140_100.jpg\u201d. What will the label be? \u201cCantaloupe 1\u201d right? This is the \u201cparent\u201d of the path, aka the parent folder. This fully depends on how the data is structured. More on that later.</p> <pre><code>def get_parent_name(x): \n    return x.parent.name\n</code></pre> <p>Okay, now we need to tell the system the kind of data we are giving it.   In this case, it is Image -&gt; Category (Label). Then we can find all the image files in the folders, and use the \u201cget_parent_name\u201d function to assign labels to all our data.</p> <p>When we learn something in school, we are tested on it with questions we have never seen right? This helps us understand if we comprehended the topic or not. Similarly, we split the data into Train and Test sets. We also resize the images to a single size (for convenience).  Since we want our little \u201cAI\u201d to recognize objects from any angle, lighting condition, etc, we provide some \u201caugmentation\u201d to the data. Things like randomly changing the brightness, rotating the image, etc. The objective is to provide variation, that further improves how well our network learns.</p> <p>We can then pass these instructions are create a \u201cData-loader\u201d. The definition is the name itself.</p> <pre><code>path = Path(root_dir) # base path\nfields = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    get_y=get_parent_name,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    item_tfms=RandomResizedCrop(64, min_scale=0.5),\n    batch_tfms=aug_transforms(),\n)\ndls = fields.dataloaders(path)\n</code></pre> <p>\u200c Okay. Does this work? Let us get a sample (or a batch as it is called in this field.) </p> <pre><code>dls.show_batch()\n</code></pre> <p>How many categories of fruits do we have?</p> <pre><code>dls.c # no of categories\n</code></pre>"},{"location":"articles/Others/Easier%20Deep%20Learning%20Research%20for%20Beginners/#teaching-our-ai-part-1","title":"Teaching our AI: Part 1","text":"<p>We have the data. Now we need the \u201cAI\u201d. You must be wondering why the word has been in quotes the whole time. It is because what we are training is not an \u201cAI\u201d, but just a component of it, called a \u201cNeural Network\u201d. </p> <pre><code>learn = vision_learner(dls,\n                resnet18, #architecture\n                loss_func=LabelSmoothingCrossEntropy(), #loss function/objective\n                opt_func=partial(OptimWrapper, opt=torch.optim.AdamW), # Optimizer\n                metrics=[accuracy, error_rate],\n                cbs=[MixUp]).to_fp16() #callbacks, mixed precision\n</code></pre> <p>The only things you need to know about it for now are :  - There are many types of networks, each better at something else. These are called \u201carchitectures\u201d. ResNet18 is one of them. - You can train a network to learn a specific type of mapping. Be it an image -&gt; text, audio -&gt; labels , image -&gt; image etc.  - This training takes time and is mathematically pretty hard. Which is why this field is still in research. Further explanations about all of this will be given in later articles. (And others that I have written about in the past, linked at the end.) - In addition to the architectures, we have algorithms called \u201cOptimisers\u201d that enable smoother learning. This will not make any sense right now. But all in due time. - A \u201closs function\u201d is fancy speak that is a way of seeing how well our network is doing while it\u2019s learning. A mini exam if you will, in the sense that the network tries to \u201coptimise\u201d for this exam. The better it gets, the better your final results. - Metrics give us somewhat precise values. Such as the grade in an exam. The \u201cAccuracy\u201d. Etc. - The other weird things that you see here are:     - cbs: [MixUp]. And to_fp16(). The first is to make sure that the network trains better, like the augmentations we spoke about. The second is an interesting paradigm that lets us train our models faster and with lower memory. More on that here. These are advanced topics. More on that later.</p>"},{"location":"articles/Others/Easier%20Deep%20Learning%20Research%20for%20Beginners/#teaching-our-ai-part-2","title":"Teaching our AI : Part 2","text":"<p>Let the Neural network.. drumroll.. learn!</p> <pre><code>learn.fine_tune(1, wd=0.5)\nlearn.export(\"model.pkl\") # Save the model\n</code></pre> <p>Fine-tune? Huh? 1? Huh? Don\u2019t worry too much about that right now. It is called Transfer Learning. And we are training the model for 1 epoch. (One run over all the data.). More epochs generally lead to better results.</p> <p>AND WE ARE DONE!! We have a working model already. This can recognize fruits. Congratulations!!!! </p> <p>(Too many words and terms. How will I ever learn them all? I should just give up now. Breathe. One thing at a time. Go through this. Come back. Go through bits you do not understand. More intermediate articles will follow. But in the meanwhile, the links are excellent resources on getting started.)</p>"},{"location":"articles/Others/Easier%20Deep%20Learning%20Research%20for%20Beginners/#how-well-did-we-do","title":"How Well Did We Do?","text":"<pre><code>from fastai.interpret import *\nfrom fastai.vision.widgets import *\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_top_losses(5, nrows=1)\n</code></pre> <p>We can use this to see what our model gets confused about. This will change as you train it more.</p> <pre><code>interp.most_confused()\n</code></pre>"},{"location":"articles/Others/Easier%20Deep%20Learning%20Research%20for%20Beginners/#using-the-model","title":"Using The Model","text":"<p>Okay, the last little bit here. We now need to use this trained model on images the network has never seen. (They were in a different folder. Also called the Validation set.) Fine, It\u2019s an exam. Best of luck little model. I hope you do well.</p> <pre><code>predictions_path = \"../input/fruits/fruits-360_dataset/fruits-360/Test\"\n\ndef predict_batch(self, item, rm_type_tfms=None, with_input=False): # this bit is slightly complicated. ignore it for now\n    dl = self.dls.test_dl(item, rm_type_tfms=rm_type_tfms, num_workers=15)\n    ret = self.get_preds(dl=dl, with_input=False, with_decoded=True)\n    return ret\nimport random\npredictions_path = Path(predictions_path)\nLearner.predict_batch = predict_batch\n\n# This is important\nlearn = load_learner(\"model.pkl\")\n\ntst_files = get_image_files(predictions_path) #same as before\ntst_files = tst_files.shuffle() \n</code></pre> <p>Now running the predictions. </p> <pre><code>preds = learn.predict_batch(tst_files)\nclasses = learn.dls.vocab # the original categories\npreds_mapped = list(map(lambda x: classes[int(x)], preds[2])) #just saving them out\n</code></pre> <p>So did it work? tst_files are the images we gave it. Preds is the output. Would you look at that?? It got most of them right :)</p>"},{"location":"articles/Others/Easier%20Deep%20Learning%20Research%20for%20Beginners/#fin","title":"Fin","text":"<p>What\u2019s next? More articles. In the meanwhile, you can look at this little link with resources I have collected over the years.</p> <p>You have a long way to go. But I do hope this was a good start. I know you didn\u2019t read the whole thing. Maybe you didn\u2019t make it till here either. I get that. I also did that when I was starting.  This article is in the hopes that it will help someone out. Maybe have the help that I did not. I do not know who it will reach. But to whoever it does, best of luck :)</p> <p>You can contact me on LinkedIn, drop me an Email</p>"},{"location":"articles/Others/GRAD/","title":"GRAD","text":"<p>toc: true title: GRAD</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Others/GRAD/#grad-cam-dl","title":"GRAD-Cam #dl","text":"<p>Note: This is a slightly advanced article. If you are not comfortable with training neural networks, this is probably not for you yet. Start here instead.</p>"},{"location":"articles/Others/GRAD/#intro","title":"Intro","text":"<p>So you want to train a Neural Network to classify images. Woah. That\u2019s awesome! How well did it do? Did you get a good score? Oh? You want to do better? I hear you. What if you could see what the network sees to make the choice? That would help understand how to make it perform better right? Read on!</p> <p>A few years ago, a paper toc: true titled \u201cGrad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization\u201d by Selvaraju et al. talked about how we could visually see the activation maps of a trained CNN by looking at the gradients in the final layer. This post will show you how to use that for your own needs. </p> <p>Note: We will be using PyTorch and the fast.ai library. But the concepts stay the same, so you should be able to use it in any other library.</p>"},{"location":"articles/Others/GRAD/#the-objective-and-data","title":"The Objective and Data","text":"<p>Before we can go to the code, what exactly are we trying to achieve? In short, we want to first train a network such as the \u201cresnet34\u201d architecture on any kind of data. In today\u2019s example, I will be using the Fish Dataset. This dataset has 9 types of sea creatures. You can of course, use any other image based classification data that you want. Knowing how the Dataset is structured is essential, so let\u2019s see that.</p> <p>Once the training is completed, we want to be able to give the trained network any image for inference and then have it spit out a visual heat map of exactly what it saw in the image. The brighter the color, the more the network focused on that particular spot to make it\u2019s decision. Have a look at the below example. </p> <p>In this image, we can see a yellow border around the fish. (Apologies if it is a disturbing image. Feel free to use any other dataset.) This shows that the network has identified the boundary of the fish and probably tried to use that information to decide what kind of fish it is.</p> <p>Examining these, we can see if the network is looking at the wrong thing, and find ways to show it what we want it to see. </p>"},{"location":"articles/Others/GRAD/#code","title":"Code","text":""},{"location":"articles/Others/GRAD/#training","title":"Training","text":"<p>Okay, let\u2019s not waste any more time and delve right into the code. If you are not familiar with fastai, you can look at this tiny blog for reference. The complete code can be found here on github.</p> <p>First, we import fastai as the deep learning library, matplotlib for plots, and IPython.display.Image to display the image inline. https://gist.github.com/SubhadityaMukherjee/grad_imports.py</p> <p>Training a classifier in fastai is just a few lines. We first decide where the dataset is.  Then we create a DataBlock. (Think of it as a constructor for a dataloader). This DataBlock is given the following information - Type of task : Image -&gt; Label - What to do : get the images from the directory - How to label the images : use the folder where the images are. For example, if the file name is \u201c/media/hdd/Datasets/Fish_Dataset/Fish_Dataset/Shrimp/Shrimp/00001.png\u201d , then it\u2019s parent is \u201cShrimp\u201d.  - How to split the data: Randomly with an 80/20 train/test split. - Transforms : Basic vision transforms, Crop and resize to 224x224 px.</p> <p>Once we have that, we can pass it to the main trainer class - the \u201cvision_learner\u201d. To it, we pass in the network we want to use (You can use any other as well), and the metrics we care about. The to_fp16() enables Mixed Precision Training that would further increase the training speed and decrease the memory consumption.</p> <p>Awesome! Now let\u2019s train the network. We are using a pre-trained resnet34 and performing transfer learning, so we use fine_tune. If you want to train from scratch, you can use \u201clearn.fit(1)\u201d instead. I trained it for a single epoch as a demo.</p> <p>https://gist.github.com/SubhadityaMukherjee/grad_train.py</p>"},{"location":"articles/Others/GRAD/#hooks","title":"Hooks","text":"<p>I mentioned previously that we would be looking at the gradients of the trained network. But how do we access them?  In PyTorch, we can modify the components of the training loop using the concept of \u201cHooks\u201d. As the name suggests, it involves inserting a hook in the training loop and execute arbitrary code. Using that, we need to save the gradients during training. PyTorch has functions for the same called \u201cregister_forward_hook\u201d for the forward pass, and \u201cregister_backward_hook\u201d for the backward pass. We can take this information and write the following classes as a wrapper around our training loop. </p>"},{"location":"articles/Others/GRAD/#plotting-activations","title":"Plotting Activations","text":"<p>Now for the intense bit. Let\u2019s pick a random image from the dataset. The original image is slightly disturbing so I blurred it a bit. </p> <p>Okay, we need to now pass the image through the model. The FastAI syntax for this kind of patching is slightly complicated. But let us walk through it. We first create the test data loader with the new image that we picked. We can then convert that into a Tensor. Once we pass the image to the network, it performs a full forward and backward pass on that image through every layer. Now for every layer in the model, we can get the computed gradients that we stored away using the Hook class.  Selvaraju et al. defined the activation map as the weighted combination of the forward activation maps. Which is what we perform.  The rest of the code is just matplotlib convenience functions to plot the nice grid heatmap that you see. The only weird line of code you might see is \u201ccam_map.detach().cpu()\u201d. This is done because we cannot plot a Tensor on the GPU, so we first detach it from the computational graph, then bring it back to the CPU to plot it.</p> <p>Well, yay! You made it. Try it with your own network and/or data. Just a word of warning, the 0 in line \u201cwith HookBwd(learn.model[0][layer]) as hookg\u201d, needs to be modified based on the network architecture. If you get errors, try with a 1 and so forth.</p> <p>https://gist.github.com/SubhadityaMukherjee/grad_plot.py</p>"},{"location":"articles/Others/GRAD/#whats-next","title":"What\u2019s next?","text":"<p>Firstly, good job on making it so far! Pat yourself on the back or go grab something nice to eat. Then look at what the network sees. Does it make sense? Is the model looking at something weird? Train for a few more epochs, rinse and repeat. Try it for different images. You might find examples that make no sense. Sometimes it might be because of random augmentation, other times it might be because of model bias or the data itself being not okay. You will find ways to improve on it eventually. If you can, look for examples that the model gets wrong, and apply GRADCam on those.</p>"},{"location":"articles/Others/GRAD/#fin","title":"Fin","text":"<p>Woah. That was long. What\u2019s next? More articles. In the meanwhile, you can look at this little link with resources I have collected over the years. You have a long way to go. But I do hope this was a good start. I know you didn\u2019t read the whole thing. Maybe you didn\u2019t make it till here either. I get that. I also did that when I was starting. This article is in the hopes that it will help someone out. Maybe have the help that I did not. I do not know who it will reach. But to whoever it does, best of luck :) You can contact me on LinkedIn, drop me an Email</p>"},{"location":"articles/Others/Ideas/","title":"Ideas","text":"<p>toc: true title: Ideas</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Others/Ideas/#blog-ideas","title":"Blog Ideas","text":"<ul> <li>FastAI/Pytorch tricks : Shorts </li> <li>GRADCAM</li> </ul>"},{"location":"articles/Others/Learnings%20from%20this%20time%20back%20home/","title":"Learnings from this time back home","text":"<p>toc: true title: Learnings from this time back home</p> <p>categories: [\"article\"] date modified:  date created: </p> <p>Lessons for future me : Part 1 - 31st Aug 2022 #learnings</p> <p>This is a time of change, and this trip was the period of rest between what my life was, and what it will become soon. I needed it. A break. A space between me and everything that I thought mattered. It gave me the time and environment to learn a lot more about myself and what I want to do in my life from now on until whenever my time comes. This is a list of the things that I realised in this holiday. It is probably not an exhaustive list, but it is something to look back on in the future and see how much this changed my life.</p> <ol> <li>Time. Time is the biggest helper. But it doesn\u2019t exist. And we give it the power to. The more we are attached to the clock, the lesser we give ourselves permission to actually enjoy life.</li> <li>Our whole lives, we had been used to a very confusing relationship with money. We either thought that we had enough, when dad bought something expensive, or were led to think that we didn\u2019t and wanting things was very wrong, when mom would remind us that wanting too many things was a bad and almost evil thing. When I realised that we had enough. We really did. But what parents wanted me to realise is that, we should forever be grateful for what we have. Nothing else. There is enough for me. And for everyone else around. If I have the ability to use a bit of what I have to make life slightly better for someone else, then I should do my best to enable them. If it is the right moment.</li> <li>Creativity is stumped by so many things. But mostly by the belief in not having it. Every time I sat down to paint, I should be grateful, and feel something first. A good emotion. A strong feeling. Without which, creation is not possible. It is the first step to manifestation. The same way I manifested winning an impossible choice in the Cover draw, or the way I manifested good weather and a beautiful trip. Or parents not coming there so I could have more time to heal. It is the first step </li> <li>In effect, many things stop us from doing things. One of them, and probably the greatest of them all, is fear. Fear of not having enough, fear of failure, fear of being rejected, an outcast. Probably also aggravated by ADHD. We have been different our whole lives, and have been shamelessly mocked for it. It made me resent everything and stopped me from starting things just for that fear.</li> <li>In the age of content and the internet, it is hard to say that you are the first person to come up with something. Me being me, that stops me from starting. Which is a waste of time. Once there is power, and an emotion, work must be done. Creation must come into being. There will be many obstacles to this. But creation cannot be stopped, one way or the other, through one person or the other, it will come into being. Remember the war of art?</li> <li>Relationships are made by understanding and effort. Over time, we lose track of who we were and who we fell in love with in the first place. Life shows us so many things, we take it for granted, and keep asking for things that do not exist. In essence, we take what was beautiful, and mar it. Over the past few months, neither me nor her have been okay. And instead of offering support, we ended up fighting not only life, but ourselves and our demons too. All empathy was lost. So was the understanding that neither of us wanted the other to solve our problems, or babysit each other. We have our own lives and ways of dealing with things. </li> <li>In the headlong rush to get over what has dragged me down all these years, I sometimes forget what the past has led to. Everything happens for a reason. This period has let me realise that, at the end of the day, people matter. So much. And so do I. But in the attempt to make a space of rmyself, I must realise that not everyone is in the same space as me. Maybe they will get there, maybe this is not their road. We can only be there on the way. </li> <li>Maybe my destiny is just this. To live. To guide when I am called. To provide for when it is needed. To make others realise how to make their lives flow forward. To create. To spread my light. Everything else is.. secondary. That\u2019s all that I am truly good at isn\u2019t it? Spreading my light. Telling people that they are enough, that they matter. That life is going to turn out okay. I am a guide. And I have been called for so many times. Along the way, I stopped listening. A guide doesn\u2019t have to take the person all the way does he? His only objective is to show the way. Point to what would be  a good place to go.</li> <li>So much changes with time, but I remain. So much happens around me, but I alone am unchanging. Forever present. Eternal. One thought for a thousand years.</li> <li>Parents did their best for me. Maybe they got lost too. They were children once too. I think there is no real adult here. Just kids. Very lost kids, with voices that so few people hear anymore. Nobody showed them how to live. And they made mistakes. A lot of mistakes. So will I. There remains no time to blame anyone. Just accept, take what serves me, give back what doesn\u2019t.</li> <li>Games and shared experiences bind us together. We forgot how to be together. A simple game of Uno brings so many people joy. No matter how old or young they are. Baking cookies, brings a smile on everyones face. </li> <li>Being part of an experience with people around you, bring satisfaction. Be it baking, or painting, or just walking. But the real question is, how much of their attention is directed towards what you are doing together. </li> <li>Long journeys are frustrating, only because we think of how long it will take. We keep looking at the time. But the miracle of it all, is just.. breathtaking sometimes. A few \u201chours\u201d and everything you know and love changes. New people, new places, new experiences. The only cost is some unrest. And even that fades in time. This journey will take 18 \u201chours\u201d. But its a journey between two eras in my life. In the moment, it really is not too bad is it?</li> <li>There are an infinite streams of energy around us, all the time. Maybe you can call it the Dao. They are us. We are them. Streams do not flow backwards. They keep moving forward. Regardless. That\u2019s how life goes too. We move from places of stagnation and rot, to life and change. </li> <li>We have an intimate relationship with food. Whatever it may be, being involved in the process of making something nourishing is something I greatly enjoy. I would like to spend many hours in my life, creating and enjoying these creations. </li> <li>Art. Art came out of nowhere and took over everything. Or so I thought. It was always there. Everywhere. Doodles. Those fake tattoos from School that mom would have me wipe off everyday, all those scribbled doodles across my notebooks, the random urges to create, make something, draw and colour. It was something I did not fully understand until recently. Now I just need to speak the language. I am learning it, it will take time. But I will let it flow and see where it takes me. It\u2019s a journey after all.</li> <li>Travelling is something I very much want to do. In time. And whenever I can. The experiences and the ideas that flow through, are unmatched. </li> <li>The idea of impermanence is something that I want to focus on. Every time I feel sad about not being too close to someone. Or anything. I know that its not going to last. Nothing does. Its a cycle of lows and highs. Or whatever we choose to perceive. My time here is not permanent. Neither are my grudges, or discomfort with people. </li> <li>Everyone, deep down, wants similar things. Even people who appear cold and uncaring, turn out to be the most broken and confused souls. They too just want a warm hug and someone to tell them that it will be okay. Especially when they are drunk.</li> <li>People regret saving up a lot and never spending it when they have the time to. Mainly because they are dead.</li> <li>../../Resistance|Resistance is the biggest killer of anything. The more you resist something, the more it might be an indicator of what you truly want to do.</li> <li>With old age and too much power, comes a sense of ego. A sense of \u201cI am the best\u201d.</li> <li>Journalling is life changing. Especially micro journaling</li> <li>Don\u2019t forget to backup!</li> <li>Sometimes you need to negotiate. People are not always extremely nice, or honest.</li> <li>Plain text files rule. Ease of use, simplicity, universal support, easy to backup. What else can one want? Pictures? Oops, use markdown.</li> <li>Having a knowledge base of information is amazing. And probably the best first step to truly.. doing research. Your own personal interconnected search. How truly beautiful. A whole second brain.</li> <li>Doing something everyday, no matter how tiny, leads to massive changes over time.</li> <li>Sometimes all you need to do to start writing is to set a timer of 10 minutes on an app that erases your work if you stop. </li> <li>Minimalism is not always the answer. Neither is it always a good question.</li> <li>Resentment builds up over a long time, from sacrificing things that you need not have, for reasons that were not clear at the time.</li> <li>Emotions, pure emotions, are a good indicator of if your choices are right.</li> <li>Destiny.. oh sweet destiny, how intricate your works are.</li> <li>Friends.. sometimes do not seem to really exist. But they have their own lives. That does not mean they do not want you in theirs.</li> <li>Moving abroad is.. hard. Extremely hard. Especially because you\u2019re in a place where almost everyone has a community already. And you barging in is almost never going to work. It will take a very long time. Better get used to looking at yourself in the mirror.</li> <li>When people tell you, hey, you could look a lot more professional and smart if you gave a shit. Please give a shit. Please. At least try.</li> <li>If you do not meditate for a very long time, prepare for the consequences. </li> <li>Instead of just stretching, some yoga will go a very long way.</li> <li>Trust the process. </li> <li>Pour your time into things. In the majority of cases, that is what is lacking. Both with art and with life.</li> <li>Not eating meat is probably a good idea. That doesn\u2019t mean cutting it out, it means not treating it like the most important part of the meal. This comes from your Bengali upbringing and you can feel free to get over it.</li> <li>So many things in your past have been tainted, no the better word is influenced, by your ADHD. From time blindness, to forever forgetting things, to taking time to process things, to auditory overload. People dont understand it yet, its okay though. Its not their fault. Neither is it yours. </li> <li>We should be grateful to YouTube for everything it has taught us so far. Who knows what will come later. But they did give us a good base.</li> <li>Focus on giving time to research. You never really have. Maybe because of your ADHD, or maybe because of your fear of failure. Things take time. Give it the time it deserves.</li> <li>The things that you are the most afraid of, thinking that it would take the longest, will actually get over pretty fast. Just try it okay?</li> <li>Your inner child needs a lot more love than you think. But remember that like all children, and like anything else, too much of anything leads to ruin. Heal the parts that need it, let the others go.</li> <li>Most emotions are temporary. Watching them go by is probably the best course of action before doing anything about it.</li> <li>Try to remember names. People really like it</li> <li>Dale Carnige was a goddamn genius.</li> <li>The Pareto principle applies every single place</li> <li>Use your calendar a little more. It really helps out.</li> </ol>"},{"location":"articles/Others/Myself/","title":"Myself","text":"<p>toc: true title: Myself</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Others/Myself/#myself-learnings","title":"Myself : Learnings","text":""},{"location":"articles/Others/Myself/#-when-you-are-slogging-on-something-and-feel-like-not-doing-it-consider-if-it-is-worth-it-to-start-over-sometimes-that-is-what-you-need","title":"- When you are slogging on something and feel like not doing it, consider if it is worth it to start over. Sometimes that is what you need.","text":""},{"location":"articles/Others/Notes%20-%20Machine%20Learning%20System%20Design/","title":"Notes   Machine Learning System Design","text":"<p>toc: true title: Notes - Machine Learning System Design</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Others/Notes%20-%20Machine%20Learning%20System%20Design/#notes-on-machine-learning-system-design-for-interviews-by-chip-huyen-ai","title":"Notes on \u201cMachine Learning System Design\u201d (for Interviews) by Chip Huyen #ai","text":"<p>These are my notes on this article by Chip Huyen. </p> <p>The article that these notes are based on, talks about some factors that are involved in designing machine learning systems, and what to watch out for in interviews on the same. I wanted to write a summary of what I read and add my take on it for future reference.</p> <p>As a note, I found Chip\u2019s book Designing Machine Learning Systems an excellent resource for anyone starting or willing to improve their skills in this field. I would recommend a read. (This is not sponsored by any means.)</p>"},{"location":"articles/Others/Notes%20-%20Machine%20Learning%20System%20Design/#interviews","title":"Interviews","text":"<ul> <li>The major issue with Machine Learning interviews seems to be the lack of a standard criterion by which to judge a candidate. This makes a lot of sense considering how varied the requirements of each project are.</li> <li>Interviewers generally look for what they are familiar with and often this means that an ideal candidate would be someone who thinks along similar lines. This is especially interesting in ML because there are an infinite number of ways to approach a problem.</li> <li>It would be helpful for the candidate to understand what kind of answers the company would be looking for based on their previous work. </li> </ul>"},{"location":"articles/Others/Notes%20-%20Machine%20Learning%20System%20Design/#compute-requirements","title":"Compute requirements","text":"<ul> <li>Contrary to the vast amount of research in the ML space on improving models and focusing on metrics, in production, users might barely notice a tiny improvement in accuracy. In return, this would further increase the complexity of the system and thus its latency.</li> <li>It is important to first understand exactly what you wish to achieve and what you need to optimize for. </li> <li>You cannot do everything.</li> </ul>"},{"location":"articles/Others/Notes%20-%20Machine%20Learning%20System%20Design/#setting-up-the-project","title":"Setting Up The Project","text":"<ul> <li>At the end of the day, an ML system also requires skills from Software Engineering. A complete system is not just a model but a lot of moving parts. Thus there are quite a few tradeoffs to consider.</li> <li>An initial thought process<ul> <li>Pick the top 2 goals that your solution needs</li> <li>What does the user interaction look like?<ul> <li>Do you care about personalized results? </li> <li>Does latency matter?</li> <li>How much of your system relies on ML?</li> <li>What kind of devices are you looking at for deployment?</li> <li>Does privacy matter?</li> </ul> </li> <li>Data<ul> <li>Do you have the data? </li> <li>Is it usable? Is it clean?</li> <li>Where is it stored? How much of it is stored?</li> </ul> </li> <li>What metrics are useful in this context? (Domain expertise would be very helpful here)</li> <li>What resources do you have/can acquire? People, time, users, etc</li> </ul> </li> </ul>"},{"location":"articles/Others/Notes%20-%20Machine%20Learning%20System%20Design/#baselines","title":"Baselines","text":"<ul> <li>These systems can get complex pretty fast. So start with the simplest possible algorithm. You might not even need a very complex Deep learning system. And it might not be feasible at the start.</li> <li>To evaluate if it is worth shifting to a more complex implementation, looking at baselines is essential.<ul> <li>Random Baseline: How well would a random guess do?</li> <li>How well does a human do on this task? (If that is feasible)</li> <li>What minimum results do you need for a functioning solution?</li> </ul> </li> </ul>"},{"location":"articles/Others/Notes%20-%20Machine%20Learning%20System%20Design/#debugging-models","title":"Debugging Models","text":"<p>This is one endless minefield.  In my experience, this list by Andrej Karpathy is a pretty comprehensive guide. I do not have anything to add to it so I will skip this section.</p> <p>As a recommendation though, I would suggest considering the use of a framework such as fast.ai. These are built with a lot of issues in mind and take care of a lot of them. </p>"},{"location":"articles/Others/Notes%20-%20Machine%20Learning%20System%20Design/#model-scaling","title":"Model Scaling","text":"<ul> <li>Most large-scale systems these days use Parallel and Distributed computing. Multiple GPUs/TPUs etc.</li> <li>If your data does not fit into memory, there are many ways of getting it - Gradient checkpointing, Mixed Precision, and Parallelism are some of them. (Future blogs will go a lot more in-depth. Putting it here will make it pretty huge.)</li> </ul>"},{"location":"articles/Others/Notes%20-%20Machine%20Learning%20System%20Design/#inference","title":"Inference","text":"<ul> <li>There are a lot of steps and tradeoffs involved in inference. <ul> <li>Where will you run your model? How long does it take? Can you say with certainty why a particular result is obtained? Can you retrain it? </li> <li>Before deployment, it is advisable to turn off all the modifications one by one and test how well the system performs without them.</li> <li>Check for biases in the results. (For example: Does your model prefer colored people?)</li> <li>Does your data remain constant? Or keep changing?</li> </ul> </li> </ul>"},{"location":"articles/Others/Notes%20-%20Machine%20Learning%20System%20Design/#fin","title":"Fin","text":"<p>The list of things to consider to make an efficient and thought-out model is endless. I do not think it is possible to take everything into account in the real world, but the more you think these through and follow these guidelines, the better and more stable your implementation will be. Of course, this is more of a short primer rather than a comprehensive guide. Future articles will cover more details.</p> <p>This article is in the hopes that it will help someone out. Maybe have the help that I did not. I do not know who it will reach. But to whoever it does, best of luck :)</p> <p>You can contact me on LinkedIn, drop me an Email</p>"},{"location":"articles/Others/Professional%20Reports%20and%20Papers%20with%20LaTEX/","title":"Professional Reports and Papers with LaTEX","text":"<p>toc: true title: Professional Reports and Papers with LaTEX</p> <p>categories: [\"article\"] date modified:  date created: </p> <p>Writing Professional Reports and Papers at 2x speed - A LaTeX tutorial + tips</p> <p>At some point in your study or career, you will be required to write a report or an article, perhaps even a research paper. You start writing your content down in Word or your favourite text editor. After a little while, some issues crop up. Maybe you don\u2019t like how it looks, or you want to change the format to a two column layout. Maybe you moved an image and the entire document went crazy. Maybe you wrote a long article, but have to change your citations manually. Or heaven forbid, you need to create a table of contents.  Ugh, you think. I don\u2019t have time for this. Just let me work on the content. If only there was a better way.</p> <p>Sounds familiar? Read on.</p>"},{"location":"articles/Others/Professional%20Reports%20and%20Papers%20with%20LaTEX/#latex-vs-word","title":"LaTEX vs Word","text":"<p>At the heart of everything, what you are struggling with is the issue of change. If you had a small article, with barely any changes or styling, Word is great. But for anything more than 5 pages? Ouch. LaTeX is a complete document preparation system, with the added advantage of a different \u201clanguage\u201d that makes your life a lot easier. It sounds and looks very strange at first. But once you get the hang of it, it will change the way you write content. Think of it as a more advanced template that is infinitely customisable. All you do is set things up once. Then you can focus on your content. Oh no! Something changed? That\u2019s okay. Add a few lines to your document and you are good to go. I do all my reports, articles, homework, projects everything using it and it has saved me days of effort. It looks professional right off the bat.</p> <p>(Note: You do NOT need to be a programmer to use this. Just go with it. And google to your heart\u2019s content.)</p>"},{"location":"articles/Others/Professional%20Reports%20and%20Papers%20with%20LaTEX/#intro-to-overleaf","title":"Intro to Overleaf","text":"<p>So how do you use this magic mushroom? Well, luckily we have Overleaf. This website allows you to write anything you want, provides a lot of templates, live collaboration, and so much more. Mostly for free as well. Just open the site and make an account. If your institution provides premium access, use your official email ID to register. (You don\u2019t really need it for most use cases.)</p> <p>(Note: This is not a sponsored post. I just use it everyday and want to make sure it helps more people.)</p> <p>Everything I show can be viewed at this link.</p>"},{"location":"articles/Others/Professional%20Reports%20and%20Papers%20with%20LaTEX/#choosing-a-template","title":"Choosing A Template","text":"<p>Okay great, now it\u2019s time to start working on a project. I will demonstrate with a small article : \u201cComputer Vision in Pytorch - A Primer\u201d.  - Click \u201cNew project\u201d - Based on what kind of work you are writing this article for, pick a section. For this article, I picked Academic Journal.  - Look around and find the look you are going for. Click on it, and then click \u201cUse as template\u201d. If you are a University, look for an official template, most of them have one. - I picked this - IEEE template Perfect! You are halfway there. </p>"},{"location":"articles/Others/Professional%20Reports%20and%20Papers%20with%20LaTEX/#initial-setup","title":"Initial Setup","text":"<p>Before we start, let\u2019s just get used to the interface.  On the left you can see a sidebar with all your files and folders.  To it\u2019s right, there is the main editor window. If you look closely, the text seems a little strange? Don\u2019t worry, more on that later. After that you will see a preview of your article. Every time you hit save or \u201crecompile\u201d, this preview will update. You can latex export this as a PDF. - In the sidebar, I like to make a folder for images by click the little icon that looks like a folder. - Now, copy paste the first few lines until the line before \u201cbegin document\u201d. Think of these as extra functionality. For example: highlighting your links, structuring your document etc. - Make a new document toc: true titled \u201cmain.tex\u201d using the file icon.  - Paste the contents there.</p> <p>Great job! Now we can get to writing everything.</p>"},{"location":"articles/Others/Professional%20Reports%20and%20Papers%20with%20LaTEX/#understanding-the-components","title":"Understanding The Components","text":"<p>Now the following might seem slightly too complicated. And you will probably feel like it\u2019s not worth the effort. But, trust the process okay? So far, you should have something like this. ```tex,latex_report_modules,latex_report_modules \\documentclass[conference]{IEEEtran} \\IEEEoverridecommandlockouts % The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out. \\usepackage{cite} \\usepackage{amsmath,amssymb,amsfonts} \\usepackage{algorithmic} \\usepackage{graphicx} \\usepackage{textcomp} \\usepackage{xcolor} \\def\\BibTeX{{\\rm B\\kern-.05em{\\sc i\\kern-.025em b}\\kern-.08em     T\\kern-.1667em\\lower.7ex\\hbox{E}\\kern-.125emX}}</p> <pre><code>Now we define a basic template.\n```tex,latex_report_template,latex_report_template\n\\begin{document}\n\n\\toc: true\ntitle{Computer Vision in Pytorch - A Primer\\\\\n\\thanks{I thank Overleaf for this template}\n}\n\n\\author{\\IEEEauthorblockN{1\\textsuperscript{st} Subhaditya Mukherjee}\n\\IEEEauthorblockA{\\textit{Faculty of Science and Engineering } \\\\\n\\textit{University Of Groningen}\\\\\nGroningen, Netherlands \\\\\nmsubhaditya@gmail.com}\n}\n\\maketoc: true\ntitle\n\n\\begin{abstract}\n\\end{abstract}\n\n\\begin{IEEEkeywords}\n\n\\end{IEEEkeywords}\n\n\\section*{}\n\\subsection*{}\n\n\\begin{thebibliography}{00}\n\n\\end{thebibliography}\n\n\\end{document}\n\n</code></pre> <p>You will only need to do this once to get a feel for what\u2019s happening. It\u2019s scary I am sure. But hold on. Keep trying. You\u2019ve got this! Look at the following code snippets twice. Do you see a pattern?</p>"},{"location":"articles/Others/Professional%20Reports%20and%20Papers%20with%20LaTEX/#title-abstract-keywords","title":"Title, Abstract, Keywords","text":"<p>We now need a toc: true title. So we put it in this line. If you notice the little {}, that is required by LaTeX to know where to start and end something. ```tex,latex_report_toc: true title, latex_report_parts \\toc: true title{Computer Vision in Pytorch - A Primer}</p> <pre><code>Are you required to write an abstract or a summary of sorts?\n```tex,latex_report_abstract, latex_report_parts\n\\begin{abstract}\nThis paper is a short introduction to Pytorch, a deep learning framework. Special focus will be given to applications of Computer Vision. This is a demo paper, and has no particular significance.\n\\end{abstract}\n</code></pre> <p>Sometimes, a template will have keywords. You can just enter the ones you think are relevant.</p>"},{"location":"articles/Others/Professional%20Reports%20and%20Papers%20with%20LaTEX/#authors","title":"Authors","text":"<p>Every template you copy, will have a section for the author. Just fill it in the way you want.</p>"},{"location":"articles/Others/Professional%20Reports%20and%20Papers%20with%20LaTEX/#sections-and-subsections","title":"Sections and Subsections","text":"<p>Now for the actual content. Here we use the commands \u201csection\u201d, \u201csubsection\u201d, \u201csubsubsection\u201d. You do not need to bother about giving them numbers. LaTeX will take care of it. Something like this is a good start. ```tex,latex_report_section, latex_report_parts \\section{What is Computer Vision?} A study of the techniques used to extract meaning from image or video related data. The applications are endless, starting from face recognition, to self driving cars. \\subsection{Computer Vision in the field of Deep Learning} Deep learning has revolutionised the field of Computer Vision by giving it superpowers. The ability to learn from billions of images come as a huge leap forward in the field. \\subsubsection*{A note} Classicial CV is still very relevant today.</p> <pre><code>\n### Figures\nDoesn\u2019t seem too hard does it? Let\u2019s add some figures. Woah. What is happening here??\nWe are defining how we want our figure to look! We tell the system where the image is, how want it to look - centered, fit inside the line, have a caption, and a label. Just change the text to what is relevant to you.\nThink about it once. Makes sense right?\n```tex,latex_report_fgure, latex_report_parts\n\\begin{figure}[h]\n\\includegraphics[width=\\linewidth]{figures/2560px-PyTorch_logo_black.svg.png}\n\\centering\n\\caption{Representation in the Simulation}\n\\label{fig:colors}\n\\end{figure}\n</code></pre> <p>If you want to change the size, replace \u201c\\linewidth\u201d with something like \u201c0.2\\linewidth\u201d which makes the figure 0.2 times the size of the line.</p>"},{"location":"articles/Others/Professional%20Reports%20and%20Papers%20with%20LaTEX/#formatting-text","title":"Formatting Text","text":"<p>Okay how about formatting such as bold italics and the like? Super simple. Look at these lines.</p> <p>```tex,latex_report_form, latex_report_parts \\section{Formatting} This \\textbf{will be bold}, then \\textit{italic}, and also \\textcolor{red}{red}. </p> <p>To add a line break, simply add \\ this will be a new line</p> <pre><code>See? That was not too bad was it? Now we have colours as well!\n\n### Code\nIf you are a programmer, or need to have any bits of code, this is how you can do it.\nTo the section where the packages were imported, add the following line.\n```tex,latex_report_code,latex_report_code\n\\usepackage{listings}\n</code></pre> <p>Now wherever you want to add code, just use it like this. Change the language to what you need of course. Viola! Syntax highlighting!</p> <p>```tex,latex_report_code_2, latex_report_parts \\begin{lstlisting}[language=Python] import numpy as np print(np.random.rand(10)) \\end{lstlisting}</p> <pre><code>\n### Equations\nHave you ever had to add equations in Word? I feel sorry for you. LaTeX lets you do it in a breeze. \n```tex,latex_report_equations, latex_report_parts\n\\section{Equations}\nWe can have three types of these - An inline equation : $2x+3 = 10$, or a proper block , $$2 \\sin(x)+10 = 100$$ or a long form one such as this.\n\\begin{equation}\nE[g^{2}]_{t}= 0.9E[g^{2}]_{t-1}+ 0.1g^{2}_{t}\\\\\n\\theta_{t+1}= \\theta_{t}- \\frac{\\eta}{\\sqrt{E[g^{2}])_{t}+\\epsilon}}g_{t}\n\\end{equation}\n</code></pre> <p>It would be impossible to explain the intricacies of using these, but as you can see, it almost feels like writing the equation down as it is. And it looks gorgeous as well. For more information, refer to this nice page.</p>"},{"location":"articles/Others/Professional%20Reports%20and%20Papers%20with%20LaTEX/#cover-page","title":"Cover page","text":"<p>Hopefully you picked a template that already had one. But if you did not, add this before \u201c\\begin{document}\u201d. Replace the text however you feel like.  ```tex,latex_report_cover, latex_report_parts \\begin{toc: true titlepage}    \\begin{center}        \\vspace*{1cm}</p> <pre><code>   \\textbf{Thesis Title}\n\n   \\vspace{0.5cm}\n    Thesis Subtoc: true\n</code></pre> <p>title</p> <pre><code>   \\vspace{1.5cm}\n\n   \\textbf{Author Name}\n\n   \\vfill\n\n   A thesis presented for the degree of\\\\\n   Doctor of Philosophy\n\n   \\vspace{0.8cm}\n\n   \\includegraphics[width=0.4\\textwidth]{university}\n\n   Department Name\\\\\n   University Name\\\\\n   Country\\\\\n   Date\n</code></pre> <p>\\end{center} \\end{toc: true titlepage}</p> <pre><code>\n### Table Of Contents\nAdding a TOC is even easier. It also updates automatically. Just add.\n```tex,latex_report_toc, latex_report_parts\n\\tableofcontents\n</code></pre>"},{"location":"articles/Others/Professional%20Reports%20and%20Papers%20with%20LaTEX/#appendix","title":"Appendix","text":"<p>Want a list of images and/or tables you have used throughout your document? With page numbers. ```tex,latex_report_appendix, latex_report_parts %\\newpage %add this if you want it to be on a separate page \\begin{appendix}   \\listoffigures   \\listoftables \\end{appendix}</p> <pre><code>\n### Tables\nTables are a bit complicated in LaTeX, but there is an easier way. Just open this website - [Table generator](https://www.tablesgenerator.com). \nThis is a very user friendly UI, so just add whatever you want. And click generate. \nCopy paste that into your Overleaf editor. Done!\nNotice the auto numbering? Cool right?\n\n### Citations\nCitations are one of the most powerful features of working in LaTeX. The best part? Only the ones you cited will show up in your bibliography! You do not need to worry if you missed any, or forgot to remove any. All you need to do is paste all your citations in a bib file.\n- Create a file called references.bib\n- Paste all your references in \u201cBibTex\u201d format in the file. Google scholar or any reference manager you use will have that option.\n- Cite them like this\n```tex,latex_report_cite, latex_report_parts\n\\section{Citation Example}\nTwo interesting libraries are Kornia \\cite{riba2020kornia} and fast.ai \\cite{howard2020fastai}. If you want it inline then : \\citep{howard2020fastai}.\n</code></pre>"},{"location":"articles/Others/Professional%20Reports%20and%20Papers%20with%20LaTEX/#bibliography","title":"Bibliography","text":"<p>Once you have added all your citations, you would need to have a Bibliography. The file \u201creferences.bib\u201d you created? Remember the name. Right before \u201c\\end{document}\u201d you can add these lines. (Change the first one to what you need. Your template mostly will define it already.) ```tex,latex_report_bib, latex_report_parts \\bibliographystyle{IEEEtran} \\bibliography{references}</p> <p>\\end{document} ``` Looking good!</p>"},{"location":"articles/Others/Professional%20Reports%20and%20Papers%20with%20LaTEX/#comments","title":"Comments","text":"<p>Want to make comments that you or a fellow author can refer to in the future? Just select any bit of text in the editor, you will get a pop up for adding a comment.</p>"},{"location":"articles/Others/Professional%20Reports%20and%20Papers%20with%20LaTEX/#exporting","title":"Exporting","text":"<p>Congratulations! Looks like you made it to the end. Now how do you export your awesome document?  See the little button that has a downward arrow? Click that. You can also click the \u201cMenu\u201d button and find more options there.</p>"},{"location":"articles/Others/Professional%20Reports%20and%20Papers%20with%20LaTEX/#collaboration","title":"Collaboration","text":"<p>Want to work with colleagues/teammates? Just hit Share and send them the link.</p>"},{"location":"articles/Others/Professional%20Reports%20and%20Papers%20with%20LaTEX/#general-principles-and-how-to-get-help","title":"General Principles and How To Get Help","text":"<p>That\u2019s about it for the basics. Feel free to come back to this document for your reference. You will face problems. Just remember the following things. - Google is your best friend. - This website is a good place to start looking for what\u2019s possible. - It will take a few tries. But it is definitely worth it. - If you can say what you want in English, you mostly know the commands already. - There are a lot of commands. You do NOT need to remember them. You will passively pick them up. Overleaf also has autocomplete which helps. - Give it some time, it will change your life.</p>"},{"location":"articles/Others/Professional%20Reports%20and%20Papers%20with%20LaTEX/#fin","title":"Fin","text":"<p>This article is in the hopes that it will help someone out. Maybe have the help that I did not. I do not know who it will reach. But to whoever it does, best of luck :)</p> <p>You can contact me on LinkedIn, drop me an Email</p> <p>Like my work? Buy me a coffee :) </p>"},{"location":"articles/Others/Sigh%2C%20Gone%20-%20My%20Thoughts%20on%20the%20Book/","title":"Sigh, Gone   My Thoughts on the Book","text":"<p>toc: true title: Sigh, Gone - My Thoughts on the Book</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Others/Sigh%2C%20Gone%20-%20My%20Thoughts%20on%20the%20Book/#sigh-gone-phuc-tran-my-thoughts-on-the-book","title":"Sigh, Gone ; Phuc Tran - My Thoughts on the Book","text":"<p>At some point in life, we stop reading and shift to faster content - articles, videos, and now \u201creels.\u201d This year, I decided to go the other way and read as many books as possible. And perhaps write about some of them. Summarizing a book, though, is an exercise in futility and encourages more \u201cfast content,\u201d which is the opposite of what I want to do. Instead, I want to explore some of my thoughts while reading these books as a note to you, my dear reader, and future me.</p>"},{"location":"articles/Others/Sigh%2C%20Gone%20-%20My%20Thoughts%20on%20the%20Book/#introduction","title":"Introduction","text":"<p>This article is about the book Sigh, Gone: A Misfit's Memoir of Great Books, Punk Rock, and the Fight to Fit In by Phuc Tran. The book is a journey through the author\u2019s life as a second-generation immigrant in America and his struggle to fit in. Phuc talks about many things: kind families, racism, trying to blend in, books, and what influenced him growing up. I loved the writing style and how every chapter was the name of a book. It was an enjoyable read, although some parts did make me want to cry.</p> <p>Okay, that\u2019s enough of an introduction\u2014time for a more serious discussion.</p>"},{"location":"articles/Others/Sigh%2C%20Gone%20-%20My%20Thoughts%20on%20the%20Book/#blending-in","title":"Blending In","text":"<p>I think it makes sense to start with the actual premise of the book, without which the context is impossible to understand. Immigrants face many challenges wherever they go, some harder than others. While this is hard for adults, it is even more challenging for children. Growing up, they not only have to live in a society that does not want them there but also understand what shaped their families. Many children experience a different life before moving to a foreign country, and the change is sometimes too difficult for them to understand. More often than not, they grow up with many conceptions about the world and themselves that are not helpful to them as adults. </p> <p>But everyone is different, so why not just be yourself? Well, that is easier said than done. Growing up, the author tries to fit in with a society his family is unfamiliar with. He faces blatant racism, violence, and impossible expectations. As a kid, this led to a lot of confusion. Perhaps the only way to fit in is to be a misfit? </p>"},{"location":"articles/Others/Sigh%2C%20Gone%20-%20My%20Thoughts%20on%20the%20Book/#cultures","title":"Cultures","text":"<p>From personal experience, culture is the biggest source of my confusion in understanding my identity. Growing up as a part of two different cultures is genuinely confusing. For the author, this, too, was a significant source of confusion. Who was he? In his community, he was an Oriental, a highly fetishized term. According to some of his siblings from larger cities, he was an Asian, someone who could be cool. But perhaps he was an American too? But he could never be what they were - White.</p> <p>We often struggle to blend in because we don\u2019t have a fixed identity. All these parts of us blend in to be a mix of everything. But society loves putting people and concepts in rigid boxes. If you are a punk rocker, you are not a good student. If you are a person of color, you can never be as cool as the others. </p> <p>This affects us all the way down, from food to clothing to our self-image and worth. Perhaps inherently, we believe that parts of us are bad and the parts that fit in are good. We forget that everyone is different. We try to fit in by erasing all the parts of us that are bad but end up erasing many that are good too.</p>"},{"location":"articles/Others/Sigh%2C%20Gone%20-%20My%20Thoughts%20on%20the%20Book/#we-are-the-racists","title":"We Are the Racists","text":"<p>As a kid, everyone is the same. There is no \u201cother\u201d. But as adults, we believe in our tribe to the point of excluding everyone else. The author experiences a lot of racism, from his classmates to teachers and even the police.</p> <p>When he was a little older, he realized everyone, including himself, was a little racist. Not in the traditional sense of the word - to distinguish between white and people of color but in the much broader sense. His family thought that hard-working people were a lot better than those who did not. People with a good education were better than those without, etc.</p> <p>Now that I think about it, we tend to categorize everyone as tribe and not tribe. This may be useful to some extent, but on a broader scale, it leads to alienation both within and without. </p> <p>We are the racists. All of us are. One way or the other. </p>"},{"location":"articles/Others/Sigh%2C%20Gone%20-%20My%20Thoughts%20on%20the%20Book/#kindness","title":"Kindness","text":"<p>Amid all the struggle, there are always moments of joy and love. The author notes that without the help of families that supported them, there was no way they would have been able to survive. Some people help others unconditionally; perhaps they are why we still have faith in humanity. </p> <p>Neither I nor the author intend to say we should unquestioningly trust everyone. But being careful is different from excluding everyone different.</p>"},{"location":"articles/Others/Sigh%2C%20Gone%20-%20My%20Thoughts%20on%20the%20Book/#great-expectations","title":"Great Expectations","text":"<p>Ask any children whose parents struggled to be where they were, and you will find great expectations. Perhaps this is only natural. Our parents faced a lot of hardship to give us the life that we have. In that, we must be grateful. That being said, a certain expectation trickles down to the generations that come after.  \u201cWe worked so hard to raise you. You must be the best.\u201d Perhaps this is our parents trying to live their dreams through us. Or maybe everything seems worth it to them when we are happy.</p> <p>The intent is filled with love and kindness, but the effects might not be. The outside world is not always kind to those who are different, but what if family makes it worse? Growing up, the author\u2019s family wanted him to be someone he was probably not\u2014good grades, showing the world that the family was okay and much more. </p> <p>Hard work does not always equate to a successful life. But trying to live the American Dream, makes it feel like that is the only way to get there. Exchange your life and dreams to be someone you are not.</p> <p>Sometimes, children need to be told that they are doing well. We can see that we must be more, but hearing that a hundred times does not make us want to do it.</p>"},{"location":"articles/Others/Sigh%2C%20Gone%20-%20My%20Thoughts%20on%20the%20Book/#violence","title":"Violence","text":"<p>More often than not, violence is born from pain. A lot of pain. For immigrant families, the drastic change from home to elsewhere is a significant source of this pain. New cultures, hard work, loneliness, and fitting in all lead to a lot of frustration. Sometimes, this pain stays with people and only bursts out at points where they cannot hold it in anymore. The author experiences physical abuse from his parents, being beaten to the point he could not sit down, being forced to sit on uncooked rice, etc. </p> <p>One can say that these are manifestations of a large amount of pain that has not been processed. Therapy helps here, but many of our parents have never had the chance to have that. </p> <p>I think that, as children, it helps to know that these bouts of rage are not because of us. While that does not change anything, it does help us accept it a little more. Perhaps in the future, when we have the space to process these emotions, we can forgive our past and present.</p>"},{"location":"articles/Others/Sigh%2C%20Gone%20-%20My%20Thoughts%20on%20the%20Book/#this-is-not-your-home","title":"This Is Not Your Home","text":"<p>The author and his brother faced many instances where their parents pretended to leave to discipline them. They left the author stranded on a road, packed their bags, and left them alone at home, etc.</p> <p>Some part of me wants to talk about my experiences here, but I am not ready to do that yet. </p> <p>In some ways, these experiences inspire discipline in children but also make them trust their families less. To some extent, they end up growing up faster than they should. When everyone around you already does not want you, if your parents show that they don\u2019t, it breaks you. It really does. </p>"},{"location":"articles/Others/Sigh%2C%20Gone%20-%20My%20Thoughts%20on%20the%20Book/#books","title":"Books","text":"<p>Ah, books. I, for one, would never be where I am without them. Growing up, they were more than just stories. They were my mentors, friends, and confidants. </p> <p>Phuc talks about how we found a book called the Lifetime Reading Plan, a list of books that every civilized American must read before they die. He initially starts reading some of them as a means of fitting in and being more American, but he slowly starts to enjoy them. They show him a world beyond his own, ways of living and understanding.  He realizes that he can be a Punk but also a good student.</p> <p>To a large extent, this is also my own journey with books. I started reading to escape and also because I hoped it would help me understand my fellow humans a bit better. I was a misfit too and that will never change. But without books, I do not think I would have ever had the confidence to be myself, learn so much about the world and want to live in it.</p>"},{"location":"articles/Others/Sigh%2C%20Gone%20-%20My%20Thoughts%20on%20the%20Book/#symbols","title":"Symbols","text":"<p>I did not realize the concept of symbols in this fashion before I read the chapter on it. Phuc talks about how sometimes we treat people as symbols. For instance, we might think of Vietnamese people as those affected by the war. The author bumps into many people who fought in the war and probably lost loved ones there. He realizes that they look at him and his family as symbols\u2014a concept, not a human.</p> <p>I think this is one way we, as humans, try to make sense of the world. We categorize everyone we see. Indians are the ones with butter chicken, and Middle Easterns are terrorists. Are they? NO. Every single person is different. Every single person has a long, complex history that ranges back generations before them. But perhaps thinking of this is not easy, and we try to define people as a singular concept. </p> <p>It is nice to be mindful of these thought patterns, I think. But it is a major shift in perspective too.</p>"},{"location":"articles/Others/Sigh%2C%20Gone%20-%20My%20Thoughts%20on%20the%20Book/#black-and-white","title":"Black and White","text":"<p>One of the things I love about this book is that the author does not take a black-and-white approach when talking about his past. Hard boundaries do not define people. </p> <p>He talks about how his father had great expectations and showed them in not very calm ways, but also how he tried to let his kids enjoy life. He did take them to the movies. He did try to let them become who they were.</p> <p>This is the part that confused me the most growing up. Society tells us that people are either good or bad. But everyone is a mix of both. People can hurt us but also love us. As a child, these mixed signals might lead to some of us shutting everyone out. How can you trust anyone if they are not consistent? </p> <p>Our parents love us, but they have their demons too. Perhaps if we understand their pain, we can try to forgive them and soothe our own.</p>"},{"location":"articles/Others/Sigh%2C%20Gone%20-%20My%20Thoughts%20on%20the%20Book/#disclaimer","title":"Disclaimer","text":"<p>I said many things in the blog, most of which are around acceptance. I think these views reflect what the author talks about, but I do not want to make the claim that they fully portray his views. These opinions are my own, and perhaps this is a way of showing my thoughts about the book without spoiling the story for those who decide to read it.</p> <p>I understand that acceptance seems like a scam for anyone facing many of these issues now. For now, it probably is. If you are being abused, please get help!  I do not intend to say that you should sit back and accept everything happening to you. Instead, this is for when you are out of the situation. Life moves on, and we must all make friends with our demons.</p>"},{"location":"articles/Others/Sigh%2C%20Gone%20-%20My%20Thoughts%20on%20the%20Book/#resources-for-second-generation-immigrants","title":"Resources For Second Generation Immigrants","text":"<p>If you are like me, a second-generation immigrant, this book might resonate quite deeply with you. In my journey to learn more about these struggles and how they affect me, I came across a blog post that made a difference. If I am being honest, it made me bawl my eyes out.</p> <p>Check it out, maybe?</p> <p>Egg Shell Therapy</p>"},{"location":"articles/Others/Sigh%2C%20Gone%20-%20My%20Thoughts%20on%20the%20Book/#fin","title":"Fin","text":"<p>This article is not a conclusive overview of the book or all the emotions I felt while reading it. But by putting it out there, I wanted to share a different perspective. </p> <p>I would love to talk some more about it, so please do reach out if that is something you want to do too!</p> <p>Like these/Want more? Buy me a coffee! Kofi</p> <p>Want articles on something specific? Just ask!</p> <p>You can always contact me on LinkedIn, or drop me an Email. For all the code, drop by my Github.</p>"},{"location":"articles/Others/What%20I%20learnt%20from%20an%20AI%20Masters%20Part%201/","title":"What I learnt from an AI Masters Part 1","text":"<p>toc: true title: What I learnt from an AI Masters Part 1</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Others/What%20I%20learnt%20from%20an%20AI%20Masters%20Part%201/#what-i-learned-from-an-ai-master-degree-part-1-finding-a-project-and-supervisors-creating-the-proposal","title":"What I learned from an AI master degree - Part 1 (Finding a Project and Supervisors; Creating the Proposal)","text":"<p>Part 1 : Starting  Troubles - Finding a Project, Supervisors ; Creating a proposal (This article) Part 2 : Timelines  - Optimal Planning and Breakdowns  Part 3 : Setup and Tools - Setting up Writing, Programming, and research to prevent tears Part 4 : Writing and Programming Advice</p>"},{"location":"articles/Others/What%20I%20learnt%20from%20an%20AI%20Masters%20Part%201/#introduction","title":"Introduction","text":"<p>So you decided to pursue a master degree? It must be scary to know that you have to write some obscure research thesis on a niche topic that your friends will give you weird looks about. Welcome to the club. I was pretty terrified too, but it all worked out in the end, and I now have a master in Artificial Intelligence from the University of Groningen, Netherlands. (Yay for me!)</p> <p>This is a series of articles where I share what I learned from the project and what I would do differently if I were to start again. This is no definitive guide, but I hope it helps you, my dear reader.</p> <p>This article is Part 1 : How to find a project and supervisors, plan your idea, and pitch it without going crazy. Depending on when you read this, the other parts will be out, and the links will be updated at the start of the article.</p> <p>Pick your adventure. I am proud of you for whatever you do.</p>"},{"location":"articles/Others/What%20I%20learnt%20from%20an%20AI%20Masters%20Part%201/#finding-a-project","title":"Finding a Project","text":"<p>The first hurdle you will face is finding a project. Of course, there is no point in thinking about the rest of the steps if you don't know what exactly you want to do. So, how do you find a project? You have approximately three options.</p> <ol> <li>You can find a project on your own by finding a problem you want to solve or an idea you want to explore.</li> <li>You can find supervisors who have projects that you find interesting and ask them if you can work on them.</li> <li>You can find a company hiring interns and working on a project they have as the thesis.</li> </ol> <p>Each of them has their own advantages and drawbacks. For instance, if you are not particularly comfortable in the field you chose, it would be harder for you to judge what kind of projects are feasible for you. In that case, you might be better off finding an existing project. That way you will be able to learn faster and also have a supervisor that is already familiar with the field.</p> <p>On the other hand, if you are particularly interested in a field, you can find a research gap that you want to explore. In that case, you might be better off finding a supervisor who is interested in the same field and pitching your idea to them. If they think it is too ambitious, they can help you refine it. (This is what I did.)</p> <p>If you are more interested in the industry, you might be better off finding a company that is hiring interns. That might give you some work experience off the bat and might (depending on how you work and the connections you make) also help you get a job later on. Depending on where you are based, this might be a little harder to accomplish. For instance, if you are in a country where either the language or the culture is different, it might be harder for you to find a company that is willing to hire you. Or perhaps you might find one, but it might take you a lot longer than you expected. If you are a native of the country, that might not be an issue. But if you are an international student, perhaps it is nice to have a backup plan and contact a few supervisors as well.</p>"},{"location":"articles/Others/What%20I%20learnt%20from%20an%20AI%20Masters%20Part%201/#but-what-ideas-do-they-want","title":"But What Ideas Do They Want?","text":"<p>The whole point of a thesis is to solidify your foundations and help you find a field you would perhaps enjoy contributing your time and energy to. So, it is not necessary that you have to find a project that is completely new.  Many universities don't impose much of a guideline except for stating that you should use at least some of the concepts you learned in your master.  There is no \"wrong\" project. There is only a matter of feasibility in the time that you have. You might have a great idea, but if you don't have the time to implement it (even partially), it might help to save it for later. Sometimes you may have to change your idea to make it more feasible. But that is okay. (This is what I had to do, as my initial idea was too ambitious.)</p> <p>It would be nice to find something that you are interested in. Perhaps talking to your seniors or faculties might help if you are not sure what you want to do. </p> <p>Okay, so how do you find a project? You have the following options. Pick your adventure.</p>"},{"location":"articles/Others/What%20I%20learnt%20from%20an%20AI%20Masters%20Part%201/#on-your-own","title":"On Your Own","text":"<p>Okay, so you chose to find a project on your own. Yay! But how do you actually find something to work on? Well this depends on what kind of project you want to do, but I will list down a few things that might help you out. - Finding a Literature Gap : Simply put, this would be to dig through research in your field and find problems that they were not able to solve. Finding such a research gap does take time and effort, though. In some sense, this is also what the supervisors do, except they are more familiar with the field and might have an easier time in understanding the papers. (*Look at the \"Future work\" section of papers.) - Merge Projects : Suppose you find multiple projects that do similar/different things, and you want to see what happens if you combine them. That is a good start. (This is what I did.) - Continue Existing Research : Another way to find a project is to look at existing research and see if you have any other ideas that you can add to it. They might not solve the problem at hand, but even finding solutions that don't work is a good start and might lead to one that does. - Company Research Projects : Many large companies publish a lot of their projects as blog posts. For instance, one of my favorite ones is Google AI Blog. I have been following them on and off for many years now, and I have found many interesting projects that I would like to work on. This route may be helpful for you as well. - Seniors : Almost all universities have a thesis archive. You can look through them and see if you find something interesting. But of course, you can also ask your senior friends for inspiration. You may be able to continue their work or find supervisors they worked with.</p>"},{"location":"articles/Others/What%20I%20learnt%20from%20an%20AI%20Masters%20Part%201/#find-a-supervisor","title":"Find a Supervisor","text":"<p>Okay, so you chose to find a supervisor. For many people, this step is one of the hardest things to do. (Depending, of course, on the institute you are at and how many faculties are available.) In my opinion, it would serve you to make some relationships with the faculties about as soon as you can. This could be as simple as trying to find out what kind of research each of your faculties does.  At the end of the day, they are here for you, and if you show them some interest, they might be able to guide you more than you think. </p> <p>In my case, I remember getting this piece of advice from a senior during my bachelor, and since then, I have put a little extra effort into getting to know some of my faculties. I have to admit this made it easier to find a supervisor. My mentor not only guided me throughout the thesis, he helped me find a second supervisor and also trusted me to do my own project. He taught one of my favorite courses, and I remember just asking him how I could learn a little more in it, and he invited me to his office for a much longer discussion. To be honest, I had no idea he would be my supervisor after a year. I was just interested in what he was teaching.</p>"},{"location":"articles/Others/What%20I%20learnt%20from%20an%20AI%20Masters%20Part%201/#the-proposal","title":"The Proposal","text":"<p>Almost every university requires you to submit a proposal before you can start your thesis. This is a document that outlines what you want to do, how you plan to do it, and what you expect to achieve. It is also a document that your supervisor will use to judge whether or not your project is feasible and if they can guide you through it. Once you have the initial idea, creating a proposal will not take you that long, but what might take time is being able to phrase your idea in a way that is understandable and creating supporting diagrams, etc., that would make it easier for your supervisor to understand exactly what you want to do.</p> <p>Depending on your supervisor, getting an initial approval may be quick or may take a little bit of time. It would help to maintain communication throughout. You are probably not the only person under them, and they are genuinely busy people. While you wait, there is no harm in trying to flesh out the rest of your project. It might save you a little brainpower in the long run.</p>"},{"location":"articles/Others/What%20I%20learnt%20from%20an%20AI%20Masters%20Part%201/#some-tips-for-the-proposal","title":"Some Tips for the Proposal","text":"<p>While there is no \"correct\" way to write a proposal, there are some things that might help you out. I will list down some of the things that I found useful. - Look At Examples : Simple, but perhaps not always done. You are not the first person to do a thesis. There is no need to reinvent the wheel. Look at examples of previous proposals (ask your supervisor, perhaps), and save your brainpower for later. Trust me, you will need it. - TMLIF : Aka, tell me like I am five. How would you explain your idea to a five-year-old? Start there and then make it to the standard of an adult. Assume that the person you will present it to only knows about the basics and builds up from there. - Literature : It would be nice to have a small initial literature survey to show that your idea has some support from the research community. This means finding some papers that do similar things or have concepts that you will use. Since you will need to do this properly later on, just finding a few relevant papers is enough here. - Timeline : In most cases, a timeline is requested. While this is personal and my approach will not work for you, I recommend that you take into account resting time. This was something I only encountered later on, and it would have helped to think of it before. A thesis is a long task. You will lose motivation many times. It is quite normal, but if you don\u2019t plan for it, you might end up feeling miserable for no reason at all.  - Template : Most universities have a proposal template or guidelines you can follow. While they are not always strict, it is a good place to start. At least you will know what is expected of you. - How Much Is Too Much? : If you are doing your own project, it is hard to know when to stop. Just remember that this is not your entire project. This is just a draft, an idea. As long as what you have conveys your idea and how you plan to tackle it properly, that is enough. Keep it simple and short, stupid. :)</p>"},{"location":"articles/Others/What%20I%20learnt%20from%20an%20AI%20Masters%20Part%201/#an-example-my-thesis","title":"An Example: My Thesis","text":"<p>While my thesis is by no means a standard. If you are interested in Computer Vision, or want to see an example, feel free to look at the links below.  The project was about emulating Attention from Transformer networks in regular CNNs using gradient-based XAI techniques as a proxy - aka \u201cProxy Attention\u201d. (Yeah, I tried to make it sound fancy. Come on, just let me sound cool sometimes. ;p) You can find the paper here and the code along with all the writing here.</p>"},{"location":"articles/Others/What%20I%20learnt%20from%20an%20AI%20Masters%20Part%201/#fin","title":"Fin","text":"<p>This article is in the hopes that it will help someone out. Maybe have the help that I did not. I do not know who it will reach. But to whoever it does, best of luck :)</p> <p>Like these/Want more? Buy me a coffee! Kofi</p> <p>Want articles on something specific? Just ask!</p> <p>You can always contact me on LinkedIn, or drop me an Email</p>"},{"location":"articles/Productivity/CheckEmptySections/","title":"CheckEmptySections","text":"<p>toc: true title: CheckEmptySections</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Productivity/CheckEmptySections/#todo","title":"TODO","text":"<pre><code>import os\nfrom pathlib import Path\nimport argparse as ap\nimport concurrent.futures\n</code></pre> <pre><code>ags = ap.ArgumentParser()\nags.add_argument(\"-f\", help=\"File or folder name\")\nargs = ags.parse_args()\n\nmainpath = Path(args.f)\n</code></pre> <pre><code># Check if the input is a directory or a file\nif mainpath.is_dir() == True:\n    # If it's a directory, create a list of Path objects for all the files in the directory\n    all_files = [mainpath/Path(fl) for fl in os.listdir(mainpath)]\nelse:\n    # If it's a file, create a list with a single Path object for the file\n    all_files = [mainpath]\n</code></pre> <pre><code>def pipeline(txt_fn_list):\n    \"\"\"\n    Applies a series of functions to a text.\n\n    Parameters:\n        txt_fn_list: A list containing the text to be processed as the first element, and the functions to be applied as the remaining elements.\n\n    Returns:\n        The final result of applying all the functions to the text.\n    \"\"\"\n    # [txt, fn1, fn2....]\n    txt = txt_fn_list[0]\n    # Apply all fns one by one\n    for fn in txt_fn_list[1]:\n        txt = fn(txt)\n    return txt\n</code></pre> <pre><code>def read_md(path):\n    \"\"\"\n    Reads the contents of a Markdown file.\n\n    Parameters:\n        path: The path to the file.\n\n    Returns:\n        The contents of the file as a string.\n    \"\"\"\n    print(path)\n    try:\n        with open(path, 'r') as fin:\n            return fin.read()\n    except:\n        return None\n</code></pre> <pre><code>def check_blanks_hash(markdown):\n    \"\"\"\n    Finds headers in a Markdown text that have no content under them.\n\n    Parameters:\n        markdown: The Markdown text to be processed.\n\n    Returns:\n        A list of headers that have no content under them.\n    \"\"\"\n    if markdown != None:\n        lines = markdown.split('\\n')\n        headers = []\n        current_header = None\n        current_content = []\n        for line in lines:\n            if line.startswith('#'):\n                if current_header is not None:\n                    headers.append({'header': current_header, 'content': \" \".join(current_content)})\n                current_header = line\n                current_content = []\n            else:\n                current_content.append(line)\n        if current_header is not None:\n            headers.append({'header': current_header, 'content': \" \".join(current_content)})\n\n        # Return a list of headers that have no content under them\n        return [header[\"header\"] for header in headers if len(header[\"content\"]) &lt; 2]\n    else:\n        return None\n</code></pre> <pre><code>def main():\n    pipe_fns = [read_md, check_blanks_hash]\n    with concurrent.futures.ProcessPoolExecutor() as executor:\n        # Start a process for each file and store the returned result in a list\n        results = [executor.submit(pipeline, [file, pipe_fns]) for file in all_files]\n        for future in concurrent.futures.as_completed(results):\n            print(future.result())\n\nif __name__ == '__main__':\n    main()\n</code></pre>"},{"location":"articles/Productivity/Extensions%20that%20make%20writing%20research%20papers%20easier/","title":"Extensions that make writing research papers easier","text":"<p>toc: true title: Extensions that make writing research papers easier</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Productivity/Extensions%20that%20make%20writing%20research%20papers%20easier/#11-free-chromefirefox-extensions-that-make-research-easier","title":"11 Free Chrome/Firefox Extensions That Make Research Easier.","text":"<p>While researching anything, we tend to heavily rely on our browser. To make this process more efficient, quite a few \u201cplugins\u201d have been created over the years. Every major browser has hundreds, if not thousands of such plugins/extensions/add-ons. Like any infinite list of things, it\u2019s often overwhelming to find helpful ones.</p> <p>For my work, I read a lot of articles and skim through many web pages, blogs, you name it. In the process, I need to store this information somewhere. Either to write a research paper, or a blog like this one, or just for my knowledge. The following plugins have made my life a lot easier and so I thought I would share them with you.</p> <p>If any of these plugins make no sense to you, ignore them. You probably don\u2019t need them as of now. But you might later on!</p> <p>Disclaimer - I am not sponsored by or affiliated with any of the programs I mention. They are shared purely because I find them useful. </p>"},{"location":"articles/Productivity/Extensions%20that%20make%20writing%20research%20papers%20easier/#a-note-about-browsers","title":"A Note About Browsers","text":"<p>I know I only mention Chrome and Firefox. Anywhere I mention Chrome, you can safely assume that Microsoft Edge, Brave, Opera, and Vivaldi also work. The same links should work directly!</p>"},{"location":"articles/Productivity/Extensions%20that%20make%20writing%20research%20papers%20easier/#collecting-information","title":"Collecting Information","text":"<p>I like taking notes, and my tool of choice here is the Markdown (another format like txt) notes app Obsidian. Of course, you can use anything you want. There are endless note applications, so everyone has their preference. These two plugins have been invaluable in collecting information across pages. - Roam Highlighter  This little plugin is absolutely beautiful. You can call it with a shortcut and highlight across the whole page! It strips out useless formatting and converts them to Markdown. If you use Roam/Obsidian/any other markdown editor, it even auto-converts the links and converts the highlighted text to markdown.      - Chrome , Firefox - MarkDownload Sometimes you want large amounts of text from a webpage you come across. This plugin gets all the text/links/images etc from the page you are on and converts it into a format you can easily copy and paste from. Extremely handy isn\u2019t it?     - Chrome , Firefox</p>"},{"location":"articles/Productivity/Extensions%20that%20make%20writing%20research%20papers%20easier/#writing-research-papersarticles","title":"Writing Research Papers/Articles","text":"<p>A large chunk of my work involves writing technical articles and research papers. It\u2019s a lot of work, and I need shortcuts to help me out in the process. These plugin-ins have saved me a lot of headaches in the long run. - TamperMonkey: Bibtex copy This plugin is a bit of a special case. Instead of providing specific functionality, it enables users to write their scripts to modify any webpage in real-time. You can do anything from Getting direct links, endlessly loading Google search results to modifying Twitter.  While writing papers, citing them is a huge headache. Since I write my reports in LaTEX, I need the \u201cBibTex\u201d version from Google Scholar which is a pain. This little plugin automatically does that with a single click. You can find out how to install it here.     - Chrome , Firefox - SLext If you write your documents in LaTEX, chances are you use Overleaf to do so. It is a website that makes it extremely easy to write any kind of professional document using LaTEX. But it does have limitations, and the biggest bummer for me is the lack of tabs. This plugin adds just that, and it saves me so much trouble.     - Chrome , Firefox - Sci-Hub scholar I firmly believe that research should not be paywalled. (Even this article is available for free on my blog without the fancy stuff). If you are affiliated with a university or company, you might have access to as many papers as you want. But as an independent researcher? Well. Happy crying.  This plugin adds links to the website Sci-Hub directly in Google Scholar which lets you access a lot of paywalled research directly. (I would link it but I don\u2019t want to get demonetized).      - Chrome , Firefox - Unpaywall Similar to the previous one, this also lets you access paywalled articles by finding other un-paywalled versions of them from elsewhere on the web.     - Chrome , Firefox - Zotero/Mendeley Connector For anyone who reads a lot of research papers, managing them is probably the biggest headache. Mendeley and Zotero are probably the most popular library managers.  While browsing the web, you might want to directly save any research paper you like to your computer. This plugin lets you do that with a single click. Both the programs have this installed by default, you just need to enable them from the application itself - Zotero, Mendeley.</p>"},{"location":"articles/Productivity/Extensions%20that%20make%20writing%20research%20papers%20easier/#medium","title":"Medium","text":"<p>I admit most of you probably don\u2019t write articles yourself. But if you do, I find these two plugins useful for extending what is possible here on Medium.  - Code medium Adding proper code snippets is honestly such a pain on Medium. Maybe in time, this will be fixed, but for now, this plugin lets you directly create gists on Github. It looks pretty and just works. I write technical articles and trust me, it has saved me hours.     - Chrome , Firefox - TOC Medium If you have noticed, not every article has a clickable table of contexts like this one. If you were to do it manually, you might need to look at the HTML source code, and do a lot of drama. Instead, this plugin just lets you add the TOC just as you would any other element. It does not auto-update though, so I would recommend leaving it for after you are done with your article.  It is also sadly not available for Firefox.     - Chrome , Firefox(Not there)</p>"},{"location":"articles/Productivity/Extensions%20that%20make%20writing%20research%20papers%20easier/#honorable-mentions","title":"Honorable Mentions","text":"<p>Some of these are not exactly extensions, but I think they deserve to be mentioned anyway. - My Text Cleanup Script Although many of the applications I mentioned above let you copy the text in chunks, they don\u2019t offer any advanced formatting options. (Eg: cleaning up Wikipedia links, making lists, formatting paragraphs, etc.) Now, there are a million ways to do this. But my favorite is this script that I wrote a while back. It uses Python and lets you do whatever you want to the text in your clipboard. After processing is complete, it pastes it back to your clipboard.  This is not for everyone. But if you are interested, I\u2019ll be happy to explain how it works. Just ask!     - Github - Text Workflow This application is not free. (Sorry!) I have a Mac, and this app lets you do whatever my script above does but with a UI. If you want something free, use the previously mentioned script. I\u2019m sure there are other alternatives for Linux and Windows. I either use vim or my script. I have not used Windows in a long time and so I can\u2019t recommend anything.     - TextWorkflow  - Adblocker An adblocker is essential to save your sanity. (Although turning it off on websites you want to support is good!) These are my favorites.     - Chrome , Firefox - I don\u2019t care about cookies As the name suggests, this auto accepts only essential cookies from the prompt. It saves you that extra click and removes the banner that covers the entire bottom of web pages.      - Chrome , Firefox</p>"},{"location":"articles/Productivity/Extensions%20that%20make%20writing%20research%20papers%20easier/#fin","title":"Fin","text":"<p>This article is in the hopes that it will help someone out. Maybe have the help that I did not. I do not know who it will reach. But to whoever it does, best of luck :)</p> <p>Like these/Want more? Buy me a coffee! Kofi</p> <p>Want articles on something specific? Just ask!</p> <p>You can always contact me on LinkedIn, or drop me an Email</p>"},{"location":"articles/Productivity/Extracting%20Highlights%20from%20a%20PDF%20easily/","title":"Extracting Highlights from a PDF easily","text":"<p>toc: true title: Extracting Highlights from a PDF easily</p> <p>categories: [\"article\"] date modified:  date created: </p> <p>How to get PDF Highlights to Notes in 3 steps </p> <p>Reading a research paper/lecture slides/book? Made a lot of highlights in a PDF? Now want to get them into your notes as text? Don\u2019t want to have to type everything again? Here\u2019s your way out. Hey. Reading a research paper or a long document is itself a lot of effort. After that, I do not have the energy to again copy everything properly into my notes. I have been searching for a way to do that, but none of the options I found work for two-column layouts, or even maintain page order properly.</p> <p>(Disclaimer: I am not sponsored by, or hold any affiliations to any of the products mentioned below. I share them because I use them every day and think they would be useful to you.)</p>"},{"location":"articles/Productivity/Extracting%20Highlights%20from%20a%20PDF%20easily/#what-we-want-to-do","title":"What we want to do","text":"<p>Convert highlights like in this document on the left to notes with minimal effort.  I use a note application called Obsidian, but anything you use works here. As long as it supports text. </p>"},{"location":"articles/Productivity/Extracting%20Highlights%20from%20a%20PDF%20easily/#existing-programs-and-their-flaws","title":"Existing Programs and\u2026 their flaws","text":"<p>Many PDF viewers offer the ability to export notes into text. Like Skim for Mac, Adobe Acrobat, OneNote etc  But they have their fair share of issues - Most of them are paid - Two column layouts, like those in research papers are not handled very well - The export option removes all page information which makes it super hard to format it - They do not export comments or other annotations properly - They get very confused when the word or line spacing differs a little</p> <p>You get the point.</p>"},{"location":"articles/Productivity/Extracting%20Highlights%20from%20a%20PDF%20easily/#pdfannots","title":"pdfannots","text":"<p>After a lot of searching, I found a Python script on GitHub called pdfannots. Sadly their documentation makes it very hard for someone without experience to get it running. Hence this article.</p>"},{"location":"articles/Productivity/Extracting%20Highlights%20from%20a%20PDF%20easily/#installing-the-script","title":"Installing the script","text":"<p>There are not many steps involved here. But it might sound a little complicated. - Step 1: Install Python. If you are on Windows, select install \u2018pip\u2019 as well. If you are on Mac or Linux, you can skip this step as it already comes pre-installed with your system. - Step 2: Open a terminal (Hit the Windows button -&gt; Search/ Mac: Open Spotlight -&gt; Search/Linux: You probably know how to) - Step 3: Run (paste it and hit Enter) the following command</p> <pre><code>pip install pdfannots\n</code></pre> <p>(If you get an error, you probably did not install Python or pip. Try Step 1 again.) PS: Don\u2019t get annoyed at me for not counting these steps. This is a one-time install after all. Once it\u2019s on your laptop, you can just proceed with the ones below every other time.</p>"},{"location":"articles/Productivity/Extracting%20Highlights%20from%20a%20PDF%20easily/#getting-your-highlights","title":"Getting your highlights!","text":"<ul> <li>Step 1: Once that completes, identify where the PDF with highlights is saved on your computer. You can open the location in your file manager. Note the location. Replace  with this As an example : (Windows: \u201cC:\\Users\\Subha\\Documents\\paper.pdf)\u201d,  Mac : \u201c/Users/eragon/Documents/paper.pdf\u201d) <li>Step 2: Now go back to the terminal, and run the following </li> <pre><code>pdfannots &lt;filename&gt;\n</code></pre> <ul> <li>Step 3: Voila! Now just select all that output text, copy it, and paste it wherever. Easy right?</li> <li>Step 4: This is optional of course, but you can format your text however you want to. (I will write an article on how you can do that and update this blog later.)</li> </ul>"},{"location":"articles/Productivity/Extracting%20Highlights%20from%20a%20PDF%20easily/#specific-formatting","title":"Specific Formatting","text":"<p>Maybe your document did not get read properly. Here is a little FAQ. - Document not found: Check your file path properly. Maybe a little google search? Try dragging and dropping instead. - Two column research paper, use this instead: pdfannots \u2014cols=2  - Spaces all weird? : pdfannots \u2014word-margin=  - Weird technicalities? : Refer to the original page of the script. You can also ask the developers questions. - Want to automate common formatting, convert to markdown, etc? : (An article will come soon, but you can leave a comment in the meanwhile.)"},{"location":"articles/Productivity/Extracting%20Highlights%20from%20a%20PDF%20easily/#fin","title":"Fin","text":"<p>This article is in the hopes that it will help someone out. Maybe have the help that I did not. I do not know who it will reach. But to whoever it does, best of luck :)</p> <p>Have any questions? Comment or shoot me an email. Like these/Want more? Buy me a coffee! Kofi Want articles on something specific? Just ask. You can contact me on LinkedIn, drop me an Email</p>"},{"location":"articles/Productivity/Obisidian%20Daily%20Notes/","title":"Obisidian Daily Notes","text":"<p>toc: true title: Obisidian Daily Notes</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Productivity/Obisidian%20Daily%20Notes/#daily-notes-in-obsidian","title":"Daily Notes in Obsidian","text":"<p>Obsidian is one of my favorite productivity tools, but there are some things that I don't fully like about it. One of them that being the daily notes feature. I use Obsidian for journaling and getting an overview of my day while making notes and so being able to use this function efficiently would be very helpful to me. In this article, I talk about how I use daily notes in Obsidian, the tweaks I have made, the plugins I use, and the hotkeys I have set up. </p> <p>Note: None of the plugins I discuss are sponsored and I am sharing them only because I use almost them every day.</p>"},{"location":"articles/Productivity/Obisidian%20Daily%20Notes/#a-disclaimer","title":"A Disclaimer","text":"<p>This article is about the way I like to work. If it does not work for you, take what you want from it and modify the workflow to fit your style. There are no \u201crules\u201d. I wanted to write this article as I did not find too many of them on using Daily notes more efficiently.</p>"},{"location":"articles/Productivity/Obisidian%20Daily%20Notes/#why-use-daily-notes","title":"Why use Daily notes?","text":"<p>Daily notes help me track my daily activities in a structured way. This way, I can easily find what I did on a particular day and see if I'm progressing toward my goals. It helps me keep track of my time and allows me to see if I am spending too much or too little time on certain tasks, enabling me to make adjustments where needed.</p> <p>Furthermore, by keeping a record of my daily work, I can get a quick overview of my weekly work. This overview also helps me to find topics that I have recently worked on, which is useful when I want to continue working on them or refer to them later.  Having a place to temporarily store ideas before turning them into proper notes removes the pressure of having to write something perfect from the start. This way, I can record my thoughts without worrying about the format or accurately writing something, which reduces the chance of breaking my flow.</p> <p>An example of what a daily note for me might look like is as follows.</p>"},{"location":"articles/Productivity/Obisidian%20Daily%20Notes/#my-issues-with-daily-notes","title":"My issues with Daily notes","text":"<p>One of the main areas for improvement of the daily notes feature in Obsidian is the need for an overview. The lack of one makes it difficult to quickly see all of the notes I have created on a specific date or within a certain range of dates. </p> <p>It can also be hard to navigate between different dates, making it time-consuming to find the note I am looking for. Another issue that I wanted to tackle was the ability to record time. The lack of this means I don't have any record of the exact time I created or edited something, making it challenging to track how much time I spent on a particular task or activity. Additionally, getting to the daily notes page requires too many clicks and can be frustrating, especially because I use this feature frequently and need to access my daily notes quickly. These shortcomings make it less convenient for me to use the daily notes feature, making my workflow less efficient.</p>"},{"location":"articles/Productivity/Obisidian%20Daily%20Notes/#some-solutions","title":"Some solutions","text":"<p>Plugins are a great way to solve specific problems in my workflow. Some of the plugins that I have mentioned in this article, such as the Daily Notes Plugin and the Time Stamper Plugin, have greatly improved my experience with the daily notes feature in Obsidian. They provide an overview of all my daily notes, make it easy to navigate between them, and easily add timestamps to my notes. These plugins have helped me stay organized, find my notes quickly, and make the most of my time. In addition to using plugins, I also use shortcuts to make my workflow more efficient. I use shortcuts to navigate between pages quickly, create new notes and add timestamps without breaking my flow while working. These shortcuts help me focus on the task by reducing the time I would otherwise spend navigating through pages or menus.</p>"},{"location":"articles/Productivity/Obisidian%20Daily%20Notes/#templater-plugin","title":"Templater Plugin","text":"<p>The Templater plugin is a useful tool that I use to streamline the process of creating new notes in Obsidian. It allows me to insert a predefined template with a shortcut every time I start a new note. This template contains the date and time I created the note and when it was last modified. The modified time is automatically updated as I make changes to the note. It also has tags and headers, which makes it easy for me to organize my notes and find the ones I need more easily. This plugin saves me time and effort by providing a consistent and standardized format for all my notes. It also provides me with important information about when the note was created and last modified, which is useful for me to track the progress of my work. This helps me to stay organized and make the most of my time by making it easy to find and refer to my notes.</p> <p>The template I use is as follows. It uses the Liquid syntax to insert entries automatically. Note that I have configured the plugin to ignore the folder where I save these templates to prevent Obsidian from auto-converting the template into text. </p> <pre><code>---\ntoc: true\ntitle: &lt;% tp.file.toc: true\ntitle %&gt;\ncategories: ['temp']\ndate modified: &lt;% tp.date.now(\"dddd Do MMMM YYYY, ddd\") %&gt;\ndate created: &lt;% tp.date.now(\"dddd Do MMMM YYYY, ddd\") %&gt;\n---\n# &lt;% tp.file.toc: true\ntitle %&gt;\n</code></pre>"},{"location":"articles/Productivity/Obisidian%20Daily%20Notes/#daily-notes-plugin","title":"Daily Notes Plugin","text":"<p>The Daily Notes Plugin is a great solution to improve my daily note-taking experience. It provides a single-page overview of my daily notes, making it easy to navigate between them. Instead of hunting for something I wrote, I can scroll through the notes and find it quickly. Additionally, each date is editable directly, so I can skip opening multiple pages or searching for the note I want to edit. This makes it much more convenient and efficient for me to review, update or organize my daily notes. Another advantage of using this plugin is how simple it is to create new daily notes. Instead of navigating multiple pages or menus, I can click a button to create a new note for the day. This feature is incredibly useful for quickly capturing new ideas, thoughts, or information that comes up during the day and helps me to keep track of my daily activities and efficiently.</p> <p>The picture shows what this plugin looks like.</p>"},{"location":"articles/Productivity/Obisidian%20Daily%20Notes/#time-stamper","title":"Time Stamper","text":"<p>The Time Stamper Plugin is another very useful plugin in my note-taking process. It enables me to use a custom time stamp format, which gives me the hour and minute time as a new bullet point. This plugin makes it easy for me to track time and is an efficient way to keep track of what I do during the day. Not having to enter the time manually saves me time and makes my note-taking process more streamlined. I use this plugin mostly when I start a new topic. This way, I can quickly see when I began working on it. This plugin does not replace manually tracking time spent on a note which can be useful when I want a rough idea of the duration of a topic or task. </p> <p>The template I use to generate my timestamps is.</p> <pre><code>- **hh:mm** \n</code></pre> <p>This picture shows what it looks like.</p>"},{"location":"articles/Productivity/Obisidian%20Daily%20Notes/#useful-shortcuts","title":"Useful Shortcuts","text":"<p>I use some custom shortcuts to navigate between different pages in Obsidian quickly. These shortcuts save me time and effort by allowing me to jump between pages with a single keystroke. These shortcuts are essential to keep my work efficient and streamline my note-taking process.</p> <p>(Note that if you are on Windows or Linux, Command is replaced by Control and Option by the Alt key.)</p> <p>One shortcut I often use is Command+Shift+G, which takes me directly to the daily notes page. This shortcut allows me to quickly access my daily notes and start working on them without navigating through different menus or pages.</p> <p>Another shortcut that I use frequently is Command+Shift+T. This shortcut creates a timestamp quickly and helps me keep track of time when I start a new topic or task, making it easier to track the time spent on each task.</p> <p>For navigation between notes, I use Command+Option+Left Arrow to access the previous note quickly and Command+Option+Right Arrow to quickly access the next note. These shortcuts help me stay organized by allowing me to easily switch between notes without manually navigating through different pages.</p>"},{"location":"articles/Productivity/Obsidian%20Plugins/","title":"Obsidian Plugins","text":"<p>toc: true title: Obsidian Plugins</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Productivity/Obsidian%20Plugins/#my-favourite-obsidian-plugins-for-research-notes-2-bonus-tips","title":"My Favourite Obsidian Plugins for Research Notes + 2 Bonus Tips","text":"<p>Obsidian is my favourite program for taking notes. Be it for research, general things I learn, summaries from papers, lecture notes and the like. Out of the box, it does so many things really well. But, its real power lies in the vast number of plugins it has. Most of these are user created, and you can even make your own (or hack one together)! In this sea of functionality, these are the top few that I use. Grouped by the type of task for easier lookup.</p> <p>(Disclaimer : I am not sponsored by either Obsidian or any of the authors of the plugins mentioned here. These are personal preferences.)</p>"},{"location":"articles/Productivity/Obsidian%20Plugins/#the-use-case","title":"The use case","text":"<p>I am a student, researcher and programmer. I take lecture notes, read a lot of research papers, articles and books. These come down to a lot of information. Of course, there\u2019s no way I can remember all of these bits of fragmented information.  Therefore, drumroll\u2026, I use Obsidian to help me put these bits of information in a place I can easily access. Since I use this almost everyday, I want taking notes to be as painless and efficient as possible.  These plugins are a huge help in doing exactly that. (Ordered by the type of task)</p>"},{"location":"articles/Productivity/Obsidian%20Plugins/#how-to-install-these-plugins","title":"How to install these plugins?","text":"<p>This is a simple step. Simple open Obsidian Settings, Scroll down a bit and select \u201cCommunity plugins\u201d. Disable Restrictive mode, and then browse to your hearts content!</p>"},{"location":"articles/Productivity/Obsidian%20Plugins/#writing","title":"Writing","text":"<p>Writing notes is the major objective here. So how do we make it extra painless? Plugins of course! - Dynamic Table of Contents : Many times, I take notes for a long form text. Sometimes these notes end up pretty huge, and it becomes slightly harder to find something. What about adding a Table Of Contents to the start? Sounds great, but what if we update the note? In comes this plugin, with an automatically updating TOC. - Tags : Super simple, also built in. Adding \u201c#topic1, #topic2 etc\u201d to a file to make it easier to search and organise. - Frontmatter Tag Suggest : Tags are great, but who remembers which ones they used before? Nobody. This plugin autocompletes tags based on ones you have used in previous notes. You can create new ones the normal way of course.  - Note Refactor : Made a huge note with a lot of headings? Why not split them into individual topics and maintain links to them? This makes it easier for you to have one major idea per note. Here I have a bunch of test headings, you can see how after applying them they become new notes that link to the current file. - Paste URL into selection : The name says it all doesn\u2019t it? - Templater : Another plugin I use daily. I like starting my notes with \u201cdate_created\u201d, \u201cdate_modified\u201d, \u201ctags\u201d, \u201ctoc: true title\u201d and insert the file name as the header. Since I do this for every single note, why not automate it? This plugin lets you create blocks of dynamic text to be inserted with a keyboard shortcut. I use \u201cCmd+Shift+I\u201d (\u201cControl+Shift+I\u201d for Windows) - Typewriter Scroll : Zen Mode is a way of life. This lets me focus on what I am writing by automatically scrolling the page, and dimming the rest of the text apart from the line I am currently writing. I do disable it while reading though. - Command Palette : This one is pretty obvious, but this built in plugin is just a text search. You can quickly open files with a (Cmd/Control + O) that brings up a searchable menu, or use (Cmd/Control + P) to bring up a searchable list of quick actions. - Vim Mode : This little option is not for everyone honestly. If you have never heard of Vim, just skip this point. I use vim as my default text editor for everything else. And I can\u2019t live without its keybindings. This just lets me use the vim keys for everything.</p>"},{"location":"articles/Productivity/Obsidian%20Plugins/#research","title":"Research","text":"<p>For research (AI research in my case), we have three main objectives :  - Merge important information from a large number of sources. - Find links between ideas that you did not see. - Maintain a daily log as something of a lab notebook. There are 5 plugins that fulfil these criteria pretty decently.  - Daily Notes : This is a Core plugin and comes with Obsidian. Essentially it\u2019s a journal. You can add whatever you want to it and it is created every day. I use it to keep a time stamped log of what I did that day. It is also useful if you just want to dump a bunch of information but don\u2019t want to format and organise it just yet. - TimeStamper : In my daily notes, I like having timestamps (eg - 9:30 : I did xyz). This plugin lets me set a custom format and a keyboard shortcut. I have set it to \u201cCmd+T\u201d (for Mac or Control+T for Windows) - Backlinks : A real game changer and another built in plugin. This shows you every file that either is linked in the current file, or refers to the current one. Identifying links between concepts, and finding more of them is absolutely invaluable in research. - Quick LaTEX for Obsidian : LaTEX is probably the easiest way of writing professional looking math-y stuff, be it equations or formulae or anything similar. This plugin has a lot of options for autocomplete, formatting, and makes my job almost ridiculously easy. Here\u2019s how it looks. (Just typing a random equation)</p>"},{"location":"articles/Productivity/Obsidian%20Plugins/#organising","title":"Organising","text":"<p>What do you do once you have a lot of files, you organise them of course! Now Obsidian by default makes it pretty easy to do this. But these plugins make organising less of a chore and much more of a fun thing to do. - Local Images : To make my notes more informative, I sometimes paste images. Now many times these are links from some website, which makes it a little risky, because what if the website stops working? This plugin automatically downloads image links in your notes and saves them locally. (It also links to the correct downloaded file.) - Graph view : Oh the gift and curse of a pretty graph. I sometimes use this to navigate between my links either to or from a file. It also gives me a very useful overview of what I have. I generally use the \u201cLocal graph\u201d that shows me a graph for the current note, rather than the \u201cGlobal\u201d full one which shows me everything. (It\u2019s pretty, but unhelpful) - Linter : Maybe I have a bunch of empty lines, empty list items, my headers are not in sentence case, my text is not formatted, my paragraphs are weird. Or anything like that. I am lazy, so I use the Linter plugin to automatically perform a bunch of processing and clean up my files.  - Tag Wrangler : Have a lot of tags? View/Edit/Change them across every file that uses them in one place. Also useful for finding files that match a few criteria. - File Cleaner : Remove empty files, unreferenced images etc. Keeping your \u201cDigital Garden\u201d pruned and bug free. - Obsidian Link Converter : Because I host my Obsidian Vault on a personal website, sometimes the links that Obsidian uses don\u2019t work, this plugin lets me mass convert them to a format that does.</p>"},{"location":"articles/Productivity/Obsidian%20Plugins/#bonus-tips","title":"Bonus tips!!","text":"<ul> <li>Make sure every file has a single major idea. If you have too many, use the \u201cNote Refactor\u201d to put them in their own files. This will make it extremely easy to refer to the \u201cIdeas\u201d in the text somewhere else instead of linking to the whole text. </li> <li>Want pages that consolidate all the notes that have a particular tag together and save them automatically to a single file? Say you want a file that has links to all the notes that have the tag \u201c#apple\u201d. Here is a little script that I wrote which does just that.</li> </ul>"},{"location":"articles/Productivity/Obsidian%20Plugins/#fin","title":"Fin","text":"<p>This article is in the hopes that it will help someone out. Maybe have the help that I did not. I do not know who it will reach. But to whoever it does, best of luck :)</p> <p>Like these/Want more? Buy me a coffee! Kofi</p> <p>Want articles on something specific? Just ask!</p> <p>You can always contact me on LinkedIn, or drop me an Email</p>"},{"location":"articles/Productivity/Pomodoro%20-%20A%20means%20but%20not%20the%20end/","title":"Pomodoro   A means but not the end","text":"<p>toc: true title: Pomodoro - A means but not the end</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Productivity/Pomodoro%20-%20A%20means%20but%20not%20the%20end/#pomodoro-a-means-but-not-the-end","title":"Pomodoro : A Means but not the End","text":"<p>In our quest for productivity, many ideas, tools, and theories have sprung up over the ages. Some work, some don\u2019t, and some are versions of previous ones with a \u201cmodern\u201d twist. The concept of the Pomodoro timer seems to have stood the test of time. The hustle culture especially has glorified its existence and made it out to be something of a magic pill that either works for you or does absolutely nothing.  I think it is a very valuable tool. But in time, we have stopped thinking of it as a tool and made it out to be more of a rule.  So how do we make it work for us?</p> <p>(Disclaimer - I am no self-help productivity guru. This works for me, and I share it in the hopes that it helps someone else. Don\u2019t take my words as a golden rule.)</p>"},{"location":"articles/Productivity/Pomodoro%20-%20A%20means%20but%20not%20the%20end/#a-definition","title":"A definition","text":"<p>Before we move further it is my habit to define the terms we work with. A Pomodoro timer, in its essence, is a combination of time blocking and scheduling rest periods. It has \u201ccycles\u201d that are combinations of a 25-minute deep work session followed by a 5-minute break. After four such cycles, a longer break of 45 minutes can be taken. In theory, it does sound pretty good. So why is it that it doesn\u2019t work for so many of us?</p>"},{"location":"articles/Productivity/Pomodoro%20-%20A%20means%20but%20not%20the%20end/#why-does-it-fail","title":"Why does it fail","text":"<p>I think there are a few simple reasons why it might not work for you. Which one(s) is(are) it for you? - You try sticking to the 25-5-25-5.. timing, but it just doesn\u2019t work. - You start one, but something comes up in between and then it just doesn\u2019t work. - You think it should give you hours of focus, and when it doesn\u2019t, you decide to just use something else instead. - The breaks are not timed right. - You end up constantly looking at the timer and it is way too distracting.</p> <p>Sounds like you? Welcome to the club. Something else? Let me know in the comments. Either way, let\u2019s make it work for us.</p>"},{"location":"articles/Productivity/Pomodoro%20-%20A%20means%20but%20not%20the%20end/#redefining-our-objective","title":"Redefining our objective","text":"<p>I believe that the common theme we face with using the Pomodoro, or honestly any other productivity technique is that we put too many expectations on it. At the end of the day, it\u2019s just a tool. The ability to use a tool depends on who wields it.  Our objective is not to work for long long hours. It is to focus, and get into an undistracted state where you are deeply concentrated on getting whatever you have to do, done. A \u201cflow state\u201d if you want to use a trendy term.  Pomodoro can help there. But only if you let it.</p>"},{"location":"articles/Productivity/Pomodoro%20-%20A%20means%20but%20not%20the%20end/#how-i-use-it","title":"How I use it","text":"<p>Indeed, that was a pretty long-winded introduction to something rather simple. I use it as a means to get started. I don\u2019t think I have ever completed a \u201ccycle\u201d recently. But almost every time, it does help me set the tone for my work session of the day. As of writing this article, I had a Pomodoro of 30 minutes going. After that initial time, I think I spent about an hour more. I didn\u2019t check on the timer then. I just sat down and finished my writing for the morning.</p> <p>But, as it goes, this is not perfect. In time I have noticed a few factors that make or break my session. - Planning. If I don\u2019t plan out my work for the day, and just get started, nothing I do works. I\u2019m still too distracted even with the timer on. I like to block off times for work on a calendar and try my best to stick to them.  - Changing the timings. A 30 - 5 - 30 \u2026 timing works for me when it comes to longer running tasks. Sometimes, a task I pick is more challenging and I end up adjusting the breaks to give me some more rest. - Breaks are subjective. There is no way for Pomodoro to know what you are working on. If the break comes when you are way too focused and working hard, skip it. Take it later though. Add them up. - Finding your productive times. To make use of the timer, try to find the general times in a day that you have more mental clarity and headspace. For me, it\u2019s earlier in the day. And maybe a few hours in the evening. I do have to say that, these times aren\u2019t fixed in stone. Pick what works for you. - Start with a completed task. I find the satisfaction of finishing something very motivating. I have noticed that if the first task you do in your work session is something you know for sure that you can complete, it does set the tone for the rest of the time. Try ordering your work that way. - Play around with the timings. With some experimentation, you will find one that works for you. - Don\u2019t stick with it. Ironic, I know. Use it to start and then do what you need to.</p>"},{"location":"articles/Productivity/Pomodoro%20-%20A%20means%20but%20not%20the%20end/#fin","title":"Fin","text":"<p>This article is in the hopes that it will help someone out. Maybe have the help that I did not. I do not know who it will reach. But to whoever it does, best of luck :)</p> <p>Like these/Want more? Buy me a coffee! Kofi</p> <p>Want articles on something specific? Just ask!</p> <p>You can always contact me on LinkedIn, or drop me an Email</p>"},{"location":"articles/Productivity/Taking%20notes%20from%20websites%20to%20markdown%20-%20A%20workflow/","title":"Taking notes from websites to markdown   A workflow","text":"<p>toc: true title: Taking notes from websites to markdown - A workflow</p> <p>categories: [\"article\"] date modified:  date created: </p> <p>Taking notes from websites to markdown - A workflow #inprogress #article</p>"},{"location":"articles/Productivity/Taking%20notes%20from%20websites%20to%20markdown%20-%20A%20workflow/#why","title":"Why","text":""},{"location":"articles/Productivity/Taking%20notes%20from%20websites%20to%20markdown%20-%20A%20workflow/#what-we-want","title":"What we want","text":""},{"location":"articles/Productivity/Taking%20notes%20from%20websites%20to%20markdown%20-%20A%20workflow/#obsidian-quick-intro","title":"Obsidian Quick intro","text":""},{"location":"articles/Productivity/Taking%20notes%20from%20websites%20to%20markdown%20-%20A%20workflow/#why-markdown","title":"Why markdown","text":""},{"location":"articles/Productivity/Taking%20notes%20from%20websites%20to%20markdown%20-%20A%20workflow/#chrome-extension","title":"Chrome extension","text":"<p>Extension Roam Highlighter</p>"},{"location":"articles/Productivity/Taking%20notes%20from%20websites%20to%20markdown%20-%20A%20workflow/#script","title":"Script","text":"<p>```py, webtomd_imports, webtomd_imports import clipboard import os from pathlib import path import re</p> <p>def apply_transforms(txt, list_of_trans):     for trans in list_of_trans:         txt = trans(txt)     return txt</p> <p>def replacer(txt, dict_of_replace):     for rep in dict_of_replace.keys():         txt = txt.replace(rep, dict_of_replace[rep])     return txt</p> <p>def regexreplacer(txt, dict_of_replace):     for rep in dict_of_replace.keys():         txt = re.sub(rep, dict_of_replace[rep], txt)     return txt</p> <p>def indent_transform(txt):     l = txt.split(\"\\n\")     return \"\\n\".join([x.strip() for x in l])</p> <p>def paragraph_converter(txt):     l = txt.split(\"\\n\")     for item in range(len(l)):         if len(l[item])&gt;0 and l[item][0] not in [\"#\",\" \",]:             l[item] = \"- \"+l[item]     return \"\\n\".join(l)</p> <pre><code>\n## Practically Using it\n</code></pre> <p>dict_regex_replace = {     r'[.*?]':\"\", #wiki links }</p> <p>dict_of_replace = {     #\"\": \"\",     \"- \": \"# \",     \"\": \"\",     \"***\": \"\",     \"[latex]\": \"\\(\",     \"[/latex]\": \"\\)\",         \"(&lt;https://en.wikipedia.org/w/index.php?toc: true title=\":\" \",     \"(https://en.wikipedia.org/w/index.php?toc: true title=\":\" \",     \"s&amp;action=edit&amp;redlink=1\":\" \", }</p> <pre><code>\n</code></pre> <p>text = clipboard.paste() text = replacer(text, dict_of_replace) text = regexreplacer(text, dict_regex_replace) text = apply_transforms(text, [     indent_transform,     paragraph_converter, ]) clipboard.copy(text) ```</p>"},{"location":"articles/Productivity/Taking%20notes%20from%20websites%20to%20markdown%20-%20A%20workflow/#faq","title":"FAQ","text":""},{"location":"articles/Productivity/Taking%20notes%20from%20websites%20to%20markdown%20-%20A%20workflow/#why-not-a-program","title":"Why not a program?","text":""},{"location":"articles/Productivity/Taking%20notes%20from%20websites%20to%20markdown%20-%20A%20workflow/#fin","title":"Fin","text":"<p>This article is in the hopes that it will help someone out. Maybe have the help that I did not. I do not know who it will reach. But to whoever it does, best of luck :)</p> <p>Like these/Want more? Buy me a coffee! Kofi Want articles on something specific? Just ask. You can contact me on LinkedIn, drop me an Email</p>"},{"location":"articles/Scalar/","title":"Scalar Academy Articles","text":""},{"location":"articles/Scalar/#scalar-academy-articles","title":"Scalar Academy Articles","text":"<ul> <li>This section has some of the articles I wrote on commission for Scalar Academy.</li> <li>These are unpublished as of now but can be eventually found here.</li> </ul>"},{"location":"articles/Scalar/Autoencoders%20with%20Convolutions/","title":"Autoencoders with Convolutions","text":"<p>toc: true title: Autoencoders with Convolutions</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Scalar/Autoencoders%20with%20Convolutions/#autoencoders-with-convolutions","title":"Autoencoders with Convolutions","text":"<p>:::section{.abstract}</p>"},{"location":"articles/Scalar/Autoencoders%20with%20Convolutions/#overview","title":"Overview","text":"<p>In the absence of labels in a dataset, only a few models can perform well. The Convolutional Autoencoder is a model that can be used to re-create images from a dataset, creating an unsupervised classifier and an image generator in the process. This model uses an Encoder-Bottleneck-Decoder architecture to understand the latent space of the dataset and re-create the images. ::: :::section{.scope}</p>"},{"location":"articles/Scalar/Autoencoders%20with%20Convolutions/#scope","title":"Scope","text":"<ul> <li>This article explains the principle behind the Convolutional Autoencoder.</li> <li>It explores the architecture of the Autoencoder.</li> <li>It presents a template we can use to implement the Autoencoder in Tensorflow.</li> <li>The article also covers the loss functions and optimizers required to train a Convolutional Autoencoder.</li> </ul> <p>::: :::section{.main}</p>"},{"location":"articles/Scalar/Autoencoders%20with%20Convolutions/#introduction","title":"Introduction","text":"<p>To be able to learn how to re-create a dataset, a model must have an understanding of the underlying latent space. The Convolutional Autoencoder compresses the information in an image dataset by applying successive convolutions. This output is passed to a Bottleneck layer, the smallest possible representation of the dataset. Using this compressed representation, the Decoder attempts to recreate the original dataset. In the process of re-creation, the compressed output resembles a sort of ../../Dimensionality Reduction|Dimensionality Reduction procedure, while the Reconstruction Loss can be used as a classification metric. This article explores the architecture and methods behind creating a Convolutional Autoencoder. </p>"},{"location":"articles/Scalar/Autoencoders%20with%20Convolutions/#what-is-an-autoencoder","title":"What is an Autoencoder?","text":"<p>The convolutional Autoencoder is part of a family of models that can reduce the noise in data. In the noise reduction task, these models learn the latent space by reconstructing the data. Autoencoders are split into three main parts - the Encoder, the Bottleneck, and the Decoder. The Encoder compresses the input data while keeping the useful features. The Bottleneck is responsible for choosing the important features that can flow through it to the Decoder. Finally, the Decoder uses the features passed to it by the Bottleneck layer to reconstruct the input.</p> <p>The architecture diagram of a convolutional autoencoder is shown below. [IMAGE {1} { arch } START SAMPLE]  [IMAGE {1} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Autoencoders%20with%20Convolutions/#encoder-structure","title":"Encoder Structure","text":"<p>The Encoder part of the network is to compress the input data and passes it to the Bottleneck layer. The compression creates a knowledge representation much smaller than the original input but has most of its features. This part of the network comprises blocks of convolutions followed by pooling layers that, in turn, further help to create a compressed data representation. The output of an ideal Encoder should be the same as the input but with a smaller size. The Encoder should be sensitive to the inputs to recreate it and not over-sensitive. Being over-sensitive would make the model memorize the inputs perfectly and then overfit the data. </p>"},{"location":"articles/Scalar/Autoencoders%20with%20Convolutions/#bottleneck-layer","title":"Bottleneck layer","text":"<p>The Bottleneck is the most important layer of an Autoencoder. This module stores the compressed knowledge that is passed to the Decoder. The Bottleneck restricts information flow by only allowing important parts of the compressed representation to pass through to the Decoder. Doing so ensures that the input data has the maximum possible information extracted from it and the most useful correlations found. This part of the architecture is also a measure against overfitting as it prevents the network from memorizing the input data directly.  Note that smaller bottlenecks lead to lesser overfitting (to an extent).</p>"},{"location":"articles/Scalar/Autoencoders%20with%20Convolutions/#decoder-structure","title":"Decoder Structure","text":"<p>This part of the network is a \"Decompressor\" that attempts to recreate an image given its latent attributes. The Decoder gets the compressed information from the Bottleneck layer and then uses upsampling and convolutions to reconstruct it. The output generated by the Decoder is compared with the ground truth to quantify the network's performance.</p>"},{"location":"articles/Scalar/Autoencoders%20with%20Convolutions/#latent-space-structure","title":"Latent Space Structure","text":"<p>The latent space of a network is the compressed representation it creates from an input dataset. This latent space usually has hundreds of dimensions and is hard to visualize directly. More complex neural networks have latent spaces so hard to visualize that they are generally referred to as black boxes. In a convolutional autoencoder, the better the representation of the data, the richer the latent space. The space structure here is a large matrix of tensors that encode the weights of layers of the network. </p>"},{"location":"articles/Scalar/Autoencoders%20with%20Convolutions/#uses-of-autoencoder","title":"Uses of Autoencoder","text":"<p>The Convolutional Autoencoder architecture is good for a lot of use cases. Some of these are explained below.</p>"},{"location":"articles/Scalar/Autoencoders%20with%20Convolutions/#reducing-complexity","title":"Reducing Complexity","text":"<p>The Encoder of the model works very well as a ../../Dimensionality Reduction|dimensionality reduction technique. For example, if we consider an image dataset, we can compress every image before feeding it to another model. This compression reduces the number of input values and thus makes the model less likely to be biased toward smaller details. The Autoencoder thus helps in improving the performance of a second model.</p>"},{"location":"articles/Scalar/Autoencoders%20with%20Convolutions/#anomaly-detection","title":"Anomaly Detection","text":"<p>An Autoencoder is generally used for reconstructing the base data using an Encoder-Bottleneck-Decoder architecture. Thus if the output reconstruction has a much larger error for a given sample, this sample could be an outlier. We can thus use the reconstruction error to find unusual data points in a dataset.</p>"},{"location":"articles/Scalar/Autoencoders%20with%20Convolutions/#unsupervised-learning","title":"Unsupervised Learning","text":"<p>A convolutional Autoencoder's information compression ability is a good start for an unsupervised learning problem. Using the Autoencoder as a ../../Dimensionality Reduction|dimensionality reduction technique allows the data to be clustered without any labels much more easily. This clustering may not be useful but can be a starting point for many other solutions.</p>"},{"location":"articles/Scalar/Autoencoders%20with%20Convolutions/#what-is-a-cnn","title":"What is a CNN?","text":"<p>A CNN is one of the foundation stones of Deep Learning that can take an input data sample and learn to recognize it given other such samples. A CNN generally comprises an input, multiple hidden layers, and an output. CNN's are composed of individual neurons that respond to specific sets of stimuli and combine their responses to perform many tasks such as classification, clustering, segmentation, and others. CNNs are useful because they can understand spatial and temporal dependencies given large amounts of data by learning feature \"filters\". Complex CNNs can model large amounts of data previously impossible for a computer to understand. </p> <p>A simple CNN is shown below. [IMAGE {2} { CNN } START SAMPLE]  [IMAGE {2} FINISH SAMPLE]</p> <p>This article elaborates on a CNN-based architecture called the convolutional Autoencoder.</p>"},{"location":"articles/Scalar/Autoencoders%20with%20Convolutions/#implementation-of-an-autoencoder","title":"Implementation of an Autoencoder","text":"<p>The Convolutional Autoencoder has a few hyper-parameters that must be tweaked before training. The section below discusses these hyper-parameters, the Reconstruction loss used, and the general implementation of the architecture of a simple convolutional Autoencoder.</p> <p>An example use case would be to re-create the MNIST dataset. The following image shows the input and output of an Autoencoder that was trained on such a task. The first row is the original input and the second row is the output of the Autoencoder. In this case, a perfect reconstruction is obtained. [IMAGE {3} { Example } START SAMPLE]  [IMAGE {3} FINISH SAMPLE]</p> <p>A complete demonstration of the code to re-create the MNIST dataset can be found on this link.</p>"},{"location":"articles/Scalar/Autoencoders%20with%20Convolutions/#code-size","title":"Code size","text":"<p>The code size is defined as how large the bottleneck layer is, consequently deciding to what extent the input data is compressed before being Decoded. The code size is the most important hyper-parameter to tune.</p>"},{"location":"articles/Scalar/Autoencoders%20with%20Convolutions/#number-of-layers","title":"Number of Layers","text":"<p>The convolutional Autoencoder is similar to other types of networks in that the number of layers is a hyper-parameter. Note that increasing the number of layers increases the time to train a network. A higher model depth also increases inference time.</p>"},{"location":"articles/Scalar/Autoencoders%20with%20Convolutions/#number-of-nodes-per-layer","title":"Number of Nodes per Layer","text":"<p>This hyper-parameter controls the weights per layer. As a general rule, the number of nodes decreases in the Encoder and increases in the Decoder.</p>"},{"location":"articles/Scalar/Autoencoders%20with%20Convolutions/#reconstruction-loss","title":"Reconstruction loss","text":"<p>The loss function the convolutional Autoencoder is trained to minimize is called the reconstruction error. This loss function depends on the type of data we use. In the case of image-based data, the reconstruction loss can be either an MSE, an L1, or Binary Cross Entropy loss.</p>"},{"location":"articles/Scalar/Autoencoders%20with%20Convolutions/#encoder","title":"Encoder","text":"<p>The Encoder can be created with a stack of 2D Convolutions starting with a large size and slowly reducing in dimensions. Each of the convolutions is followed by a 2D Max-Pooling layer. The ReLU activation is used throughout.  In Keras, the Encoder can look something like this.</p> <pre><code>x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\nx = layers.MaxPooling2D((2, 2), padding='same')(x)\nx = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = layers.MaxPooling2D((2, 2), padding='same')(x)\nx = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nencoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n</code></pre>"},{"location":"articles/Scalar/Autoencoders%20with%20Convolutions/#decoder","title":"Decoder","text":"<p>The Decoder comprises blocks of 2D convolutions followed by Up Sampling layers. This part of the network looks something like the following in Keras.</p> <pre><code>x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\nx = layers.UpSampling2D((2, 2))(x)\nx = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = layers.UpSampling2D((2, 2))(x)\nx = layers.Conv2D(16, (3, 3), activation='relu')(x)\nx = layers.UpSampling2D((2, 2))(x)\ndecoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n</code></pre> <p>::: :::section{.summary}</p>"},{"location":"articles/Scalar/Autoencoders%20with%20Convolutions/#conclusion","title":"Conclusion","text":"<ul> <li>Convolutional Autoencoders are a powerful unsupervised learning technique.</li> <li>The article explained the Encoder-Bottleneck-Decoder architecture in detail.</li> <li>The Reconstruction Loss obtained is a valuable classification and image generation resource.</li> <li>The article also explained multiple use cases such as Anomaly Detection, Complexity Reduction, and some others.</li> <li>This article also provided a template for implementing a Convolutional Autoencoder in Tensorflow. :::</li> </ul>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/","title":"Building a GAN from scratch","text":"<p>toc: true title: Building a GAN from scratch</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/#building-a-gan-from-scratch","title":"Building a GAN from scratch","text":"<p>:::section{.abstract}</p>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/#overview","title":"Overview","text":"<p>Generating images from scratch is a huge deal in computer vision. A Generative Adversarial Network(GAN) was one of the first models to generate new images in an unsupervised manner efficiently. A GAN is not a single model but a family of different architectures used for image generation.</p> <p>This article will look at the first Generative Adversarial Network, a vanilla GAN. We will learn how to make a Generative Adversarial Network from scratch. ::: :::section{.scope}</p>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/#scope","title":"Scope","text":"<p>This article covers the following topics: - What is a Generative Adversarial Network, and how to make a Generative Adversarial Network from scratch? - What is the architecture of a GAN, and what are the loss functions and optimizers required to train one? - How to feed a custom dataset to a GAN and use it to generate novel images.</p> <p>::: :::section{.main}</p>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/#introduction","title":"Introduction","text":"<p>A GAN is a network we can use to create novel images given any vision dataset. In most cases, they are unsupervised, but many architectures also consider labels during training. Some examples of outputs GANs are shown here.</p> <p>[IMAGE {1} Summer to Winter START SAMPLE]  [IMAGE {1} FINISH SAMPLE]</p> <p>[IMAGE {2} Face Generation START SAMPLE]  [IMAGE {2} FINISH SAMPLE]</p> <p>GANs have much bigger and more complex architectural pipelines than a standard Convolutional network. They generally have two major structures, the Generator and the Discriminator. These structures are Convolutional networks that we can substitute for other networks that perform similar functions. </p> <p>The training paradigm for GANs is called Adversarial Training and relies on an interplay between the Generator and the Discriminator. </p> <p>This article will look at what a Generative Adversarial Network is and its components. After we understand the parts, we will build our own GAN from scratch and train it on a dataset of handwritten images (MNIST). </p>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/#architecture-of-a-gan","title":"Architecture of a GAN","text":"<p>One of the hardest parts of understanding how to make a Generative Adversarial Network is comprehending the architecture. GANs are very different from regular neural networks in that they are composed of two completely different neural networks - The Generator and the Discriminator.</p> <p>Consider the architecture diagram shown below. [IMAGE {3} Architecture Diagram START SAMPLE]  [IMAGE {3} FINISH SAMPLE]</p> <p>The first part of the architecture is the Generator, whose job is to create images realistic enough that the Discriminator cannot tell the difference between a fake image and a real one.</p> <p>[IMAGE {4} Generator And Discriminator START SAMPLE]  [IMAGE {4} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/#generator","title":"Generator","text":"<p>The Generator can be considered a network that takes a random noise and then arranges the pixels to make it look like a real image. It is also a simple neural network composed of blocks of fully connected linear layers (FC) and Leaky ReLU activations. In the final layer of the Generator, the LeakyReLU is replaced by a Tanh activation. The Tanh activation is chosen as we do not want probabilities but want to take the generated image and squish it to the range of (-1,1). This range is the range of the MNIST data images.</p>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/#discriminator","title":"Discriminator","text":"<p>The second part of the network is the Discriminator, whose job is to take the images that the Generator creates and return the probability that the image is real.  The Discriminator is a binary classifier and comprises blocks of fully connected linear layers (FC), Leaky ReLU activations, and ../../Dropout|Dropout layers. The final layer of the Discriminator is a block with an FC layer and a Sigmoid at the end. The Sigmoid is responsible for returning the classification probability that we want.</p>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/#demystifying-the-loss-function","title":"Demystifying the loss function","text":"<p>Loss functions are an essential part of any neural network pipeline. Before we learn how to make a Generative Adversarial Network, we first need to understand the loss functions.</p>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/#discriminator-loss","title":"Discriminator loss","text":"<p>The Discriminator's job is to classify the generated images into real or fake and return the probability that it is real. To do so, it needs to do extremely well at ensuring that the input it gets belongs to the real dataset. It should also ensure that if the input is fake, it is not classified as belonging to the real dataset.  Mathematically, this can be understood as maximizing \\(D(x)\\) and minimizing \\(D(G(z))\\).</p>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/#generator-loss","title":"Generator loss","text":"<p>The Generator is tasked with ensuring that the Discriminator is fooled. It can do so by creating realistic images that the Discriminator thinks are real. This process can be thought of as ensuring that the Discriminator classifies an image sampled from the fake dataset as belonging to the real one.  Mathematically, this is formulated as maximizing \\(D(G(z))\\). Using this as the loss might lead to the network becoming extremely confident, even if it is wrong. To prevent this from happening, \\(log(D(G(z)))\\) is used instead. </p>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/#total-loss","title":"Total loss","text":"<p>There is no net loss that is used in practice. Still, while learning to make a Generative Adversarial Network, we must consider the total theoretical loss the network is trying to optimize. Training a Generative Adversarial Network is a game between two enemies (aka adversaries). In other words, this is a MinMax game where one party attempts to reduce the probability of the other winning. Both parties are simultaneously also trying to increase their chances of winning. Mathematically, this can be represented as \\(\\(\\underset{G}{min} \\underset{D}{max} V(D,G) = \\mathbb{E}_{x \\sim p_{data}(x)}[log(D(x)] + \\mathbb{E}_{z \\sim p_{z}}[log(1 - D(G(z))]\\)\\)</p>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/#heuristic-loss","title":"Heuristic loss","text":"<p>Another aspect of knowing how to make a Generative Adversarial Network is understanding heuristics. These heuristics are not part of any network directly but are training guidelines that work for most GANs. (Any GAN created before 2016, at least.) We can use these heuristics to ensure stable reductions in the loss landscape, which is key to training a Generative Adversarial Network well. - If the network has any pooling layers, they can be replaced with [../../Strided|Strided] convolutions in the Discriminator and fractionally ../../Strided|Strided convolutions in the Generator. - We can use Batch Normalization layers in the Generator and the Discriminator. - If the architecture is deep, we should remove FC layers for better performance. - As for activations, the ReLU activation should be used for all the layers. The only exception is the output layer, where a TanH activation should be used.</p>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/#training-a-gan","title":"Training a GAN","text":"<p>We need an optimization algorithm that performs gradient descent on the network weights to train the GAN. The SGD (Stochastic Gradient Descent) algorithm is used for a vanilla GAN such as ours. The Generator and the Discriminator are assigned to their SGD optimizer for training. This procedure ensures that they both learn independent weights. Since the outputs of both networks flow to and from each other, they are influenced by each other as well.</p> <p>The general training paradigm for any GAN is as follows. This paradigm is always a good place to refer to when figuring out how to build a Generative Adversarial Network. - Obtain an image, and create a random noise of the same size as the image.  - Pass these images to the Discriminator and obtain the probability of the image passed being real or fake. - Create another noise of the same size as before, and pass it to the Generator. - Train the Generator with this input data. - Repeat all the previous steps until the weights are successfully optimized and satisfactory results are obtained. </p>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/#coding-a-gan","title":"Coding a GAN","text":"<p>In this article, we will create a GAN that can create novel handwritten digits every time it is called. We will take all the concepts we have learnt and, finally, learn how to make a Generative Adversarial Network in Python using the Tensorflow library. Before actually building the network and training pipeline, we need to choose a dataset and set up the optimizers and loss functions.  After the initial set-up is completed, we can train the network and generate our handwritten digits (or any other data).</p>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/#imports","title":"Imports","text":"<p>First, we import all the required libraries. We will import the plotting library matplotlib and the numerical processing library numpy. In this case, we will import all the required functions from Tensorflow.</p> <pre><code>from __future__ import print_function, division\n\nfrom keras.datasets import mnist\nfrom keras.layers import Input, Dense, Reshape, Flatten, [../../Dropout|Dropout](../../Dropout|Dropout.md)\nfrom keras.layers import BatchNormalization, Activation, ZeroPadding2D\nfrom keras.layers import LeakyReLU\nfrom keras.layers.convolutional import UpSampling2D, Conv2D\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam, SGD\n\nimport matplotlib.pyplot as plt\nimport sys\nimport numpy as np\n</code></pre>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/#setup-configuration","title":"Setup Configuration","text":"<p>To further understand how to make a Generative Adversarial Network, we need to explore our configuration options. We first define the size of the image we want to load and generate. Since we are using the MNIST dataset, we set this to 28x28. The MNIST dataset is grayscale, and this only has one channel. We can set the size of the latent space to 100. If the dataset was more complex, We could choose a higher number.</p> <pre><code>num_rows = 28\nnum_cols = 28\nnum_channels = 1\ninput_shape = (num_rows, num_cols, num_channels)\nz_size = 100\nopt = SGD()\n</code></pre>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/#dataset","title":"Dataset","text":"<p>The dataset we use in this article is the Modified National Institute of Standards and Technology database or MNIST. It is a dataset of handwritten digits almost ubiquitous in deep learning. A sample of this dataset is shown below.  [IMAGE {5} MNIST START SAMPLE]  [IMAGE {5} FINISH SAMPLE]</p> <p>The MNIST is a very simple dataset for modern networks to model, so it is a good challenge for our vanilla GAN.</p> <p>The MNIST dataset comes pre-installed with Keras, and we can directly use it. We need to pre-process the images by normalizing them and converting them to 3 dimensions to pass them to the network (a Generative Adversarial Network cannot directly process 2D images without changing the architecture). We also create proxy containers for the real and fake images to save memory during training.</p> <pre><code>(train_ims, _), (_, _) = mnist.load_data()\ntrain_ims = train_ims / 127.5 - 1.\ntrain_ims = np.expand_dims(train_ims, axis=3)\n\nvalid = np.ones((batch_size, 1))\nfake = np.zeros((batch_size, 1))\n</code></pre>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/#networks","title":"Networks","text":"<p>We now look at the network architecture to understand how to make a Generative Adversarial Network from scratch. </p>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/#discriminator_1","title":"Discriminator","text":"<p>To create the Discriminator, we define a function that returns a model with the network defined. This function does not compile the model as we need to call it multiple times, and pre-compiling it will lead to issues when we do.</p> <pre><code>def build_discriminator():\n\n    disc_model = Sequential()\n    disc_model.add(Flatten(input_shape=input_shape))\n    disc_model.add(Dense(512))\n    disc_model.add(LeakyReLU(alpha=0.2))\n    disc_model.add(Dense(256))\n    disc_model.add(LeakyReLU(alpha=0.2))\n    disc_model.add(Dense(1, activation='sigmoid'))\n\n    disc_img = Input(shape=input_shape)\n    validity = disc_model(disc_img)\n    return Model(disc_img, validity)\n</code></pre>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/#generator_1","title":"Generator","text":"<p>The Generator is built similarly to the Discriminator. We define a custom function to create the Generator but do not compile it for now. The noise is also generated and passed through the network here.</p> <pre><code>def build_generator():\n\n    gen_model = Sequential()\n    gen_model.add(Dense(256, input_dim=z_size))\n    gen_model.add(LeakyReLU(alpha=0.2))\n    gen_model.add(BatchNormalization(momentum=0.8))\n    gen_model.add(Dense(512))\n    gen_model.add(LeakyReLU(alpha=0.2))\n    gen_model.add(BatchNormalization(momentum=0.8))\n    gen_model.add(Dense(1024))\n    gen_model.add(LeakyReLU(alpha=0.2))\n    gen_model.add(BatchNormalization(momentum=0.8))\n    gen_model.add(Dense(np.prod(input_shape), activation='tanh'))\n    gen_model.add(Reshape(input_shape))\n\n    gen_noise = Input(shape=(z_size,))\n    gen_img = gen_model(gen_noise)\n    return Model(gen_noise, gen_img)\n</code></pre>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/#optimization","title":"Optimization","text":"<p>We define the following functions to set up the optimizers for both networks. We will be using an SGD optimizer in this case for both models.</p> <pre><code># discriminator\ndisc= build_discriminator()\ndisc.compile(loss='binary_crossentropy',\n    optimizer='sgd',\n    metrics=['accuracy'])\n\nz = Input(shape=(z_size,))\n# generator\nimg = generator(z)\n\ndisc.trainable = False\n\nvalidity = disc(img)\n\n# combined model\ncombined = Model(z, validity)\ncombined.compile(loss='binary_crossentropy', optimizer='sgd')\n</code></pre>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/#training","title":"Training","text":"<p>Before we can train, we need to define a few utility functions. The first function sets up both the Generator and the Discriminator for training. It compiles the combined model and also creates noise.</p> <pre><code>def intialize_model():\n    disc= build_discriminator()\n    disc.compile(loss='binary_crossentropy',\n        optimizer='sgd',\n        metrics=['accuracy'])\n\n    generator = build_generator()\n\n    z = Input(shape=(z_size,))\n    img = generator(z)\n\n    disc.trainable = False\n\n    validity = disc(img)\n\n    combined = Model(z, validity)\n    combined.compile(loss='binary_crossentropy', optimizer='sgd')\n    return disc, generator, combined\n</code></pre> <p>The entire training loop is then as follows. This loop follows the exact procedure described in previous sections. We also add a running counter that tells us how far along we are in training and saves the outputs every sample_interval epochs.</p> <pre><code>def train(epochs, batch_size=128, sample_interval=50):\n    # load images   \n    (train_ims, _), (_, _) = mnist.load_data()\n    # preprocess\n    train_ims = train_ims / 127.5 - 1.\n    train_ims = np.expand_dims(train_ims, axis=3)\n\n    valid = np.ones((batch_size, 1))\n    fake = np.zeros((batch_size, 1))\n    # training loop\n    for epoch in range(epochs):\n\n        batch_index = np.random.randint(0, train_ims.shape[0], batch_size)\n        imgs = train_ims[batch_index]\n    # create noise\n        noise = np.random.normal(0, 1, (batch_size, z_size))\n    # predict using Generator\n        gen_imgs = gen.predict(noise)\n    # calculate loss functions\n        real_disc_loss = disc.train_on_batch(imgs, valid)\n        fake_disc_loss = disc.train_on_batch(gen_imgs, fake)\n        disc_loss_total = 0.5 * np.add(real_disc_loss, fake_disc_loss)\n\n        noise = np.random.normal(0, 1, (batch_size, z_size))\n\n        g_loss = full_model.train_on_batch(noise, valid)\n    # show progress\n        print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, disc_loss_total[0], 100*disc_loss_total[1], g_loss))\n    # save outputs every few epochs\n        if epoch % sample_interval == 0:\n            one_batch(epoch)\ndisc, gen, full_model = intialize_model()\ntrain(epochs=10000, batch_size=32, sample_interval=200)\n</code></pre> <p>After defining these functions, we train it for as many epochs as we want. For the sake of this article, we can train it for 10,000 epochs. Longer epochs do not necessarily mean better performance.</p>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/#testing","title":"Testing","text":"<p>We also need a function that samples a batch of data to generate images on demand during/after training. This function creates a random noise vector and uses the trained Generator to perform a prediction on the noise. The generated images are then plotted for a batch of images.</p> <pre><code>def one_batch(epoch):\n    row, col = 5, 5\n    noise = np.random.normal(0, 1, (r * c, z_size))\n    gen_imgs = gen.predict(noise)\n\n    # Rescale images 0 - 1\n    gen_imgs = .5 * gen_imgs + .5\n\n    fig, axs = plt.subplots(r, c)\n    cnt_axis = 0\n    plt.cla()\n    plt.clf()\n    for i in range(row):\n        for j in range(col):\n            axs[i,j].imshow(gen_imgs[cnt_axis, :,:,0], cmap='gray')\n            axs[i,j].axis('off')\n            cnt_axis += 1\n    fig.savefig(\"images/%d.png\" % epoch)\n    plt.close()\n</code></pre> <p>In the training loop, if the number of passed epochs is a multiple of the sample interval (how many epochs to skip before saving the outputs), we call this function and save the images. We can also do this later on.</p> <pre><code>if epoch % sample_interval == 0:\n    one_batch(epoch)\n</code></pre>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/#results","title":"Results","text":"<p>The code we wrote saves images at an interval of 200 epochs. For clarity, we can look at the images generated at the start, at 400 epochs, at 5000 epochs and finally after 10,000 epochs.</p> <p>At the start, we have random noise. [IMAGE {6} Epoch 0 START SAMPLE]  [IMAGE {6} FINISH SAMPLE]</p> <p>After 400 epochs, we are getting somewhere slowly. But these results are different from real digits. [IMAGE {7} Epoch 400 START SAMPLE]  [IMAGE {7} FINISH SAMPLE]</p> <p>After 5000 epochs, we can see figures that resemble the MNIST dataset. [IMAGE {8} Epoch 5000 START SAMPLE]  [IMAGE {8} FINISH SAMPLE]</p> <p>After training the network for the entire 10,000 epochs, we get the following outputs.  [IMAGE {9} Final results START SAMPLE]  [IMAGE {9} FINISH SAMPLE]</p> <p>These images look very close to the handwritten number data we fed the network. Note that none of these exact images was previously shown to the network, and the network generated these as we trained it. ::: :::section{.summary}</p>"},{"location":"articles/Scalar/Building%20a%20GAN%20from%20scratch/#conclusion","title":"Conclusion","text":"<ul> <li>This article taught us how to make a Generative Adversarial Network from scratch.</li> <li>We looked at the architecture of a vanilla GAN and understood the loss functions required to train it.</li> <li>We also made our own Generative Adversarial Network in Python and trained it on MNIST data.</li> <li>Finally, we looked at the stepwise results we obtained from training our GAN. :::</li> </ul>"},{"location":"articles/Scalar/Building%20the%20Word2Vec%20Model%20in%20Gensim/","title":"Building the Word2Vec Model in Gensim","text":"<p>toc: true title: Building the Word2Vec Model in Gensim</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Scalar/Building%20the%20Word2Vec%20Model%20in%20Gensim/#building-the-word2vec-model-in-gensim","title":"# Building the Word2Vec Model in Gensim","text":"<p>:::section{.abstract}</p>"},{"location":"articles/Scalar/Building%20the%20Word2Vec%20Model%20in%20Gensim/#overview","title":"Overview","text":"<p>Word2Vec is a family of models that can take large corpora and represent them in vector space. These representations, also known as word embeddings, are extremely useful as they help us perform many tasks in NLP. From recommender systems to analysing sentiments from internet feeds to large-scale chatbots, word embeddings have brought life to the field of NLP for decades. Word2Vec, one of the older models, is relatively simple to implement. After implementing it we will use word embedding ../../visualization|visualization to further understand how the model works. ::: :::section{.scope}</p>"},{"location":"articles/Scalar/Building%20the%20Word2Vec%20Model%20in%20Gensim/#scope","title":"Scope","text":"<p>This article covers the following topics: - What are Word2Vec and Gensim. - How to train a Word2Vec model using a text corpora. - Parameters that can be tweaked in a Word2Vec model. - How to load and pre-process text for Word2Vec. - How to perform word embedding visualization in TensorBoard.  ::: :::section{.main}</p>"},{"location":"articles/Scalar/Building%20the%20Word2Vec%20Model%20in%20Gensim/#what-are-we-building","title":"What Are We Building?","text":"<p>In this article, we are modeling text data by converting a large corpora of text into a Vector model using Word2Vec. We will be using the Python library gensim to do so. We also will build the pipeline needed for word embedding visualization using the Tensorflow Embedding Projector as well as save the trained model for inference.</p>"},{"location":"articles/Scalar/Building%20the%20Word2Vec%20Model%20in%20Gensim/#problem-statement","title":"Problem Statement","text":"<p>Our problem statement for this article is to create a pipeline using gensim that uses Word2Vec to process a text corpora, visualize the embeddings, and save the trained model to disk.</p>"},{"location":"articles/Scalar/Building%20the%20Word2Vec%20Model%20in%20Gensim/#pre-requisites","title":"Pre-Requisites","text":"<p>Before moving to the actual implementation, there are some pre-requisite topics that we need to know. A summary of them is as follows.</p>"},{"location":"articles/Scalar/Building%20the%20Word2Vec%20Model%20in%20Gensim/#embeddings-and-word-embedding-visualization","title":"Embeddings and Word Embedding Visualization","text":"<p>The output of a Word2Vec model is a word embedding. There are many other models which give similar embeddings, some better than Word2Vec as well. These are synonymous with word vectors for our use case. </p>"},{"location":"articles/Scalar/Building%20the%20Word2Vec%20Model%20in%20Gensim/#stopwords","title":"Stopwords","text":"<p>Common words like \"the\", \"to\", etc., do not add much to the model but can negatively influence the embedding.</p>"},{"location":"articles/Scalar/Building%20the%20Word2Vec%20Model%20in%20Gensim/#cbow","title":"CBOW","text":"<p>A continuous bag of words uses a single hidden layer NN to predict a source word based on its neighbouring words. It uses a sliding window over the sentence to generate these pairs. Consider these examples as (X, Y) pairs to be passed into a model.  An example: Given the sentence \"I love gensim a lot\" and a sliding window of 2, we get ([I, gensim], love), ([love, a], gensim) etc</p>"},{"location":"articles/Scalar/Building%20the%20Word2Vec%20Model%20in%20Gensim/#skip-gram","title":"Skip-gram","text":"<p>Skip Grams are a mirror of CBOW. It also uses a similar single hidden layer NN with a sliding window but uses the context words to predict the source word.  An example: Given the sentence \"I love gensim a lot\" and a sliding window of 2, we get (love, [I, gensim]), (gensim, [love, a]) etc</p>"},{"location":"articles/Scalar/Building%20the%20Word2Vec%20Model%20in%20Gensim/#how-are-we-going-to-build-this","title":"How Are We Going To Build This?","text":"<p>We are going to load a custom data file as an input to the model and preprocess it to make it fit for the model. After that, we will load the gensim implementation of Word2Vec and train it on the data we loaded. Once the model is done training, we will export the model to disk and load it the trained model using Tensorflow Embedding Projector for word embedding visualization. In the process, we also will save and load the model for further inference. </p>"},{"location":"articles/Scalar/Building%20the%20Word2Vec%20Model%20in%20Gensim/#final-output","title":"Final Output","text":"<p>The final output that we will get from the model is the text corpora that we load converted to vector space. This vector space can then be used to find similar words from the text and be passed to other neural network models if required. An example word embedding might look something like this.</p>"},{"location":"articles/Scalar/Building%20the%20Word2Vec%20Model%20in%20Gensim/#requirements","title":"Requirements","text":"<p>To create a Word2Vec model, we need to first understand what it is. We will also be looking at the library Gensim where we obtain the Word2Vec model from.</p>"},{"location":"articles/Scalar/Building%20the%20Word2Vec%20Model%20in%20Gensim/#what-is-word2vec","title":"What Is Word2Vec?","text":"<p>Word vectors are a numerical representation of text content. Word2Vec is a model that converts large text corpora to a vector representation as  doing so provides the corpora with the following properties : - Since they are converted to numerical vectors, they can be fed into any numerical model, such as a neural network.  - The converted vectors can be compared by using distance metrics such as the ../../Cosine Distance|cosine distance function \\(cos(\\theta) = \\frac{A\\cdot B}{||A||\\cdot||B||}\\) ( where A and B are vectors). These metrics make it easy to find related words like the one we want to achieve.</p>"},{"location":"articles/Scalar/Building%20the%20Word2Vec%20Model%20in%20Gensim/#what-is-gensim","title":"What is Gensim?","text":"<p>Gensim is a text processing library that lets us train models like Word2Vec very quickly. The library has many more features, such as finding related documents using trained word embeddings and other methods of vectorization that are beyond the scope of this article.</p>"},{"location":"articles/Scalar/Building%20the%20Word2Vec%20Model%20in%20Gensim/#building-word2vec-model-with-gensim","title":"Building Word2Vec Model with Gensim","text":"<p>Now that we have understood the problem statement, we can start building the model using gensim. We first load all the required packages and data. </p>"},{"location":"articles/Scalar/Building%20the%20Word2Vec%20Model%20in%20Gensim/#loading-packages-and-data","title":"Loading Packages and Data","text":"<p>Before we build the Word2Vec Model, we need to load a few packages along with the data. These packages can be installed using pip. (Eg : <code>pip install gensim</code>) if they are not already present on the system that is being used. We also download the stopwords and punctuation data from nltk.</p> <pre><code>import nltk  \nnltk.download('stopwords')  \nnltk.download('punkt')\nnltk.download('gutenberg')\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk import word_tokenize\nfrom gensim.models import Word2Vec as w2v\n</code></pre> <p>After this, we load the data. For this demo, we will be using text from the book \"Emma\" by \"Jane Austen\". This dataset is a public domain dataset from Project Gutenberg that comes with nltk. We can get it using the following code. </p> <pre><code>import nltk\nnltk.download('gutenberg')\n!cp /root/nltk_data/corpora/gutenberg/austen-emma.txt sample.txt\n</code></pre> <p>We can also use custom text by creating a text file called \"sample.txt\" in the same directory as the code and pasting whatever we want. (Make sure it is English text).</p>"},{"location":"articles/Scalar/Building%20the%20Word2Vec%20Model%20in%20Gensim/#data-preprocessing","title":"Data Preprocessing","text":"<p>After loading the data, we need to pre-process it to be able to pass it to the model by removing stopwords and punctuation and converting the words into lowercase tokens. We should get something like this <code>['emma', 'jane', 'Austen', '1816']</code></p> <pre><code>sw = stopwords.words('English') # this is a list of stopwords\n# Function to remove stopwords per line if they are present in the line\ndef rem_stops_line(line, words):\n    if len(line) &gt;1:\n        return [w for w in line if w not in words]\n    else:\n        return line\n\n# Remove stop words for an entire text. Separate functions make it easier to parallelise if required.\ndef remove_stops(text, words = SW):\n    return [rem_stops_line(line, words) for line in text]\n\n# Open the file and convert it to a list of lines\nwith open('sample.txt', 'r') as f:\n    lines = f.readlines()\n\n# Remove new lines, convert all to lowercase, remove punctuation and stop words and tokenise\nlines = [line.rstrip('\\n').lower() for line in lines]\nlines = [line.translate(str.maketrans('', '', string.punctuation)) for line in lines]\nlines = [word_tokenize(line) for line in lines]\nfiltered_lines = remove_stops(text = lines, words = SW)\n\nprint(filtered_lines[:10])\n</code></pre>"},{"location":"articles/Scalar/Building%20the%20Word2Vec%20Model%20in%20Gensim/#gensim-word2vec-model-training","title":"Gensim Word2Vec Model Training","text":"<p>Once both the data and the model have been loaded, we can train it on the data using the following code.</p> <pre><code>w = w2v(\n    filtered_lines,\n    min_count=3,  \n    sg = 1,       # 1 for skip-gram, 0 for cbow\n    window=7   # sliding window size\n)      \n</code></pre>"},{"location":"articles/Scalar/Building%20the%20Word2Vec%20Model%20in%20Gensim/#parameters-of-the-word2vec-model","title":"Parameters of the Word2Vec Model","text":"<p>The Word2Vec model implemented in gensim has a few parameters that we can tune based on the task. They are explained as follows: - sentences : This is the preprocessed input text. - size : This is the maximum dimension size of the output vector. - window : This is the sliding window size. - min_count : The minimum word frequency below which words would not be passed to the model. - workers : This is the number of parallel threads for processing. - sg : 1 for the Skip Gram model, 0 for the CBOW model.     - CBOW is prone to overfitting words that frequently appear in the same contexts, so try SkipGrams as well.     - Skip grams need more data and are more resource intensive but perform better. Choose it based on the task at hand. - iter : This is the number of iterations the model will update it's gradients for. Tweaking these parameters also help improving the accuracy of the word embedding visualization.</p>"},{"location":"articles/Scalar/Building%20the%20Word2Vec%20Model%20in%20Gensim/#compute-similarities","title":"Compute Similarities","text":"<p>The Word2Vec model can also be used to find similar words in a text.  We can find words similar to a random word we pick from the text to see our model works. Since we used data from Emma, let us try searching for the word \"book\".</p> <pre><code>print(w.wv.most_similar('book'))\n</code></pre> <p>We get the following words and how related the model thinks they are to the word \"book\".</p> <pre><code>[('peace', 0.9995625615119934), ('exercise', 0.999549388885498), ('burst', 0.9995266199111938), ('purpose', 0.9995185732841492), ('meet', 0.9995156526565552), ('mei', 0.9995115995407104), ('move', 0.9995064735412598), ('week', 0.9995056986808777), ('views', 0.9995036125183105), ('persons', 0.9995019435882568)]\n</code></pre>"},{"location":"articles/Scalar/Building%20the%20Word2Vec%20Model%20in%20Gensim/#t-sne-visualizations","title":"T-SNE Visualizations","text":"<p>To see what the embedding space looks like, we can give these embeddings to Tensorboard. To do so, make sure the model is saved. Here we have saved it as \"wvecemma\". Now we use a script that comes inbuilt with gensim to convert our Word2Vec model to the Tensorboard format.</p> <pre><code>python -m gensim.scripts.word2vec2tensor -i \"wvecemma\" -o \"model\"\n</code></pre> <p>We get two files, \"model_tensor.tsv\" and \"model_metadata.tsv\".</p> <p>To convert the model to a Keras Embedding, use the code (for model w), <code>w.wv.get_keras_embedding()</code></p> <p>Now we can either open Tensorboard (if you have it installed) and navigate to this folder and open the generated files, or go to this website Tensorflow Projector. On the website, click the Load button. For Step 1, choose the \"model_tensor.tsv\" file, and for Step 2, choose the other one. </p> <p>We can then see the embeddings directly.</p> <p>[IMAGE {1} {Embedding Projector} START SAMPLE]  [IMAGE {1} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Building%20the%20Word2Vec%20Model%20in%20Gensim/#saving-and-loading-the-model","title":"Saving and Loading the Model","text":"<p>To prevent having to train again, we save the model to disk using the following code. </p> <pre><code>w.wv.save_word2vec_format(\"wvecemma\") # save to disk \n</code></pre> <p>This model can then be loaded for inference during production using the following code.</p> <pre><code>model = gensim.models.KeyedVectors.load_word2vec_format(\"wvecemma.bin.gz\", binary=True) # load from disk\n</code></pre> <p>::: :::section{.summary}</p>"},{"location":"articles/Scalar/Building%20the%20Word2Vec%20Model%20in%20Gensim/#conclusion","title":"Conclusion","text":"<ul> <li>This article taught us how to implement the Word2Vec model in gensim. </li> <li>We learnt how to perform word embedding visualization using the TensorBoard Embedding Projector.</li> <li>We also learnt how to use our own data to train a Word2Vec model.</li> </ul> <p>:::</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/","title":"CycleGAN #scalar","text":"<p>toc: true title: CycleGAN #scalar</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#translating-images-using-a-cyclegan-scalar","title":"Translating Images Using a CycleGAN #scalar","text":"<p>:::section{.abstract}</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#overview","title":"Overview","text":"<p>The field of computer vision has been trying to create AI that creates never seen before images for decades. Generative networks such as the CycleGAN are part of a long line of such research, but one that performs extremely well in tasks ranging from converting images to paintings to changing the weather in images. The CycleGAN is rather different from many approaches before it as it is an unpaired Image2Image translation task with these tasks being cyclic in nature. In this article, we will explore what all these terms mean and how to put them into practise in a CycleGAN.</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#disclaimer","title":"Disclaimer","text":"<p>This is an intermediate level article and introduces a significant number of new terms. Attempting to understand this article is not recommended before mastering how a ../../Basic GAN|basic GAN (eg: DCGAN) works. Being so complex, it is advised to slow down and understand a section before moving on to the next. ::: :::section{.scope}</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#scope-of-the-article","title":"Scope of the Article","text":"<p>This article covers the following concepts - What is an unpaired Image2Image task - What is GAN and subsequently, what is a CycleGAN - Concepts such as Generators, Discriminator, Encoder Decoder architectures - Latent space as an easier means of understanding CycleGANs - Architectural Details and Training procedure of CycleGANs - How to use CycleGANs in various domains ::: :::section{.main}</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#note-about-the-code","title":"Note About The Code","text":"<p>This article does not contain the code to run a CycleGAN. This was done to prevent the article from becoming extremely huge. Instead, every concept that would be required to understand the code is explained in detail below. The entire code with examples can be found on the official Tensorflow/Keras documentation website. On understanding this article, this code will become extremely easy to comprehend and use.</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#quick-recap","title":"Quick Recap","text":"<p>This section gives a recap of the important concepts we need to understand CycleGAN. </p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#image2image-translation","title":"Image2Image Translation","text":"<p>An image translation task\u2019s objective is to convert from one image to either text or another image. An example of the same would be taking a picture of a sunset and converting that picture to the style of the artist Van Gogh. There are many such Image translation tasks, but the one in consideration in this article is specifically converting from an image to another image aka Image2Image.</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#paired-vs-unpaired-translation","title":"Paired vs Unpaired Translation","text":"<p>An important detail about the CycleGAN is that unlike most other GANs or UNet style architectures, it uses an unpaired translation. This means that the image, label pairs that are being passed into the model are not related to each other. In contrary to say, a classification task where the label passed is the exact label of the image passed. This might be slightly confusing to understand without knowledge of latent space. More explanations can be found in the next section</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#gan","title":"GAN","text":"<p>GANs are a special class of architectures that have two components, one that tries to get better at a task, and the other that tries to find out how badly the first part is performing. The training procedure is somewhat similar to a game with one component being an \u201cadversary\u201d of the other, hence the term \u201cAdversarial network\u201d. The generative term comes into play as these networks are used to create novel images from existing data.</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#adversarial-training","title":"Adversarial Training","text":"<p>A useful analogy to understand how a GAN is trained is the classic \u201ccop\u201d vs \u201cthief\u201d analogy. Assume that the thief in this case is trying to forge a painting by Van Gogh, while the cop tries to prove the thief wrong. The thief first comes up with a forgery, and the cop says no, this is fake and is not the real one because of some reason. The thief then shows a modified image to the cop with minor differences. This scenario repeats until the cop can no longer tell the difference between the real and the fake images. This type of training is called adversarial training. Using a second opinion to improve the outputs of the first component of the model. A useful advantage here is that the data does not need to be labelled. </p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#generator","title":"Generator","text":"<p>The generator is the \u201cthief\u201d. It starts with random noise to create a fake image and traverses the latent space until the Discriminator can no longer tell the difference between the fake and the real images.</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#discriminator","title":"Discriminator","text":"<p>Consequently, the discriminator is the \u201ccop\u201d. It is essentially a classifier that returns a metric of how fake the image looks. </p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#encoder-decoder-architecture","title":"Encoder Decoder Architecture","text":"<p>Many networks such as the UNet and GANs have a two sided architecture that involves ../../Downsampling|downsampling the image until a point and then upsampling from there on. The Encoder is the first half which downsamples the image and condenses the information in a batch of data down into the smallest possible unit.  The decoder does the opposite, it takes this smallest possible unit and attempts to recreate the original input. In the process, it learns how to traverse the latent space and create the required translation. </p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#residual-block","title":"Residual Block","text":"<p>The Encoder Decoder architecture has a major drawback, in the process of compressing the image information and reconstructing it, a lot of information is lost during the operations. The Residual Block is the answer to this dilemma. It essentially contains a \u201cSkip Connection\u201d that ensures that the gradients from the previous layer are carried over to the next layer.  This is done very simply. If \\(F(x)\\) is the network, then for an input \\(x_{i}\\), \\(x_i = F(x_{i-1}) + x_{i-1}\\). </p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#cost-function","title":"Cost Function","text":"<p>A cost function is the objective that the network tries to minimise. In essence, it is a metric of how well the network performs with respect to a task. For image classification, it could be CrossEntropy. CycleGAN has a rather complex cost function that is explained in later sections.</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#latent-space","title":"Latent Space","text":"<p>Understanding latent space is the key to fully comprehending the CycleGAN. It can be thought of as an n-dimensional vector space that contains every possible image that can be generated from the given data. It is not possible to entirely visualise this directly but a useful analogy is considering faces.  If we consider the faces of every person that we know and \u201caverage\u201d them together, we would end up with a \u201cgeneric face\u201d that has traits from every face that we considered. From this \u201cgeneric face\u201d, if we were to attempt to recreate any of the other faces, we would have to \u201cadd\u201d or \u201csubtract\u201d some features from the face to reach the other one. This can be thought of as \u201ctraversing\u201d the latent space. Thus in essence, the latent space contains all such possible faces. In theory then, it makes sense to assume that if we can approximate this latent space, we can translate any image to the other by traversing it. The CycleGAN attempts to do just that. Traversal can go in both directions, hence it\u2019s \u201ccyclic\u201d nature.</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#cyclegan-architecture","title":"CycleGAN Architecture","text":"<p>The CycleGAN architecture is divided into two major parts - The Generator and the Discriminator. The Generator further has the Encoder, the Transformer and the Decoder as components.</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#encoder-block","title":"Encoder Block","text":"<p>The encoder uses convolution layers to consolidate information from the data and compress it into the least possible representational unit. The number of channels consequently increase. In the current model, there are 3 convolution operations. The final output of the model reduces the original image size by 3/4th and passes it to the Transformer Block.</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#transformer-block","title":"\u201cTransformer\u201d Block","text":"<p>The Transformer Block has nothing to do with \u201cTransformer architectures\u201d but is called so because it takes the output of the encoder and transformers it so the decoder can use it. In the CycleGAN, this block has around 6-9 Residual blocks. This is done to ensure maximum information extraction from the compressed representation that the encoder generates.</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#decoder-block","title":"Decoder Block","text":"<p>The decoder block then takes the inputs from the transformer block and passes it through two de-convolution layers. </p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#discriminator_1","title":"Discriminator","text":"<p>The Discriminator in the CycleGAN is another type of GAN - \u201cPatchGAN\u201d. This special type of Discriminator uses patches of the input image to map to outputs. Unlike a normal GAN that maps from a 256x256 sized image to a scalar result (\u201creal\u201d or \u201cfake), the PatchGAN maps it to NxN sized arrays of outputs \\(X\\) where each \\(X_{i,j}\\) maps to (\u201creal\u201d, \u201cfake\u201d). This is run as a convolution through the entire image and the results are averaged out.</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#loss-functions","title":"Loss Functions","text":"<p>CycleGAN uses a mix of three loss functions. Along with adversarial loss, a cycle consistency loss and an identity loss are used to create the final objective function.</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#cycle-consistency-loss","title":"Cycle Consistency Loss","text":"<p>This is the most important part of the CycleGAN research. Considering two image domains \\(X\\) and \\(Y\\), the Cycle consistency loss uses two different mappings \\(G: X \\rightarrow Y\\) and \\(F : Y \\rightarrow X\\). These mappings are bijections, aka reverses of each other. (Hence \u201ccyclic\u201d). As a mathematical expression, the Cycle Consistency Loss \\(\\mathcal{L}_{cyc}\\) can then be represented as \\(\\(\\mathcal{L}_{cyc}(G, F, X, Y) = \\frac{1}{m}\\Sigma_{i=1}^{m}[(F(G(x_{i})-x_{i})+ (G(F(y_{i}))-y_{i})]\\)\\).</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#identity-loss","title":"Identity Loss","text":"<p>Another loss function that CycleGAN proposes is the Identity loss. \\(\\(L_{identity}(G,F) = \\mathbb{E}_{y \\sim p_{data}(y)}[||G(y)-y)||_{1}] + \\mathbb{E}_{x \\sim p_{data}(x)}[||F(x)-x)||_{1}]\\)\\) This is especially useful for converting to and from photos and paintings. The loss is used to preserve the color information during transformation and attempts to make sure that the reverse color is not used. If a part of the image looks like it belongs to the target image already, it is not mapped to something else. In principle, it makes the model more conservative if the content to be transformed is not known.</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#objectivecost-function","title":"Objective/Cost Function","text":"<p>The net loss function is therefore a combination of all the three losses just described. A hyper parameter \\(\\lambda\\) is used to control the strength of the transfer. It is usually set to 10. \\(\\(\\mathcal{L}_{GAN}(G, F, D_{X}, D_{Y}) = \\mathcal{L}_{GAN}(G, D_{Y}, X, Y) + \\mathcal{L}_{GAN}(F, D_{X}, X, Y) + \\lambda \\mathcal{L}_{cyc}(G,F)\\)\\)</p> <p>Thus the function that we wish to solve is finding the value of the optimisers that gives the best loss while maintaining the ability to convert to and from the target image. This can be seen in the formula. \\(\\(G^{*},F^{*} =\\underset{G,F}{argmin} \\underset{D_{X}, D_{Y}}{max} \\mathcal{L}_{GAN}(G, F, D_{X}, D_{Y})\\)\\)</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#other-useful-details-about-the-architecture","title":"Other Useful Details About The Architecture","text":"<p>The CycleGAN paper and code have a lot of interesting tweaks that were done to improve performance. Some of the ones that are not usually mentioned are as follows.</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#separate-optimizers","title":"Separate Optimizers","text":"<p>There are two optimisers for the discriminator and the generator each. (Four in total.) Using two separate optimisers ensure that the model learns to convert images in both directions and minimises the loss for both sets of generators and discriminators.</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#instance-normalisation","title":"Instance Normalisation","text":"<p>Instance normalisation is a regularisation technique that allows the network to remove specific contrast information when transferring style information between images. This technique makes CycleGANs extremely useful for image stylisation tasks. The formula is similar to that of Batch Normalisation and is left in this article as a reference.  \\(\\(y_{tijk} = \\frac{x_{tijk} - \\mu_{ti}}{\\sqrt{\\sigma_{ti}^2 + \\epsilon}},     \\quad     \\mu_{ti} = \\frac{1}{HW}\\sum_{l=1}^W \\sum_{m=1}^H x_{tilm},     \\quad     \\sigma_{ti}^2 = \\frac{1}{HW}\\sum_{l=1}^W \\sum_{m=1}^H (x_{tilm} - mu_{ti})^2\\)\\)</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#fractional-stride","title":"Fractional Stride","text":"<p>Most networks use a stride that is a whole number. CycleGAN has two types of convolutions. One type that has a stride of 2, while the other that has a stride of \\(\\frac{1}{2}\\). This is a special case of convolution that is also known as a \u201cde-convolution\u201d. A fractional stride upsamples an image from a smaller dimension to a larger one. A whole number stride downsamples it.</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#reflection-padding","title":"Reflection Padding","text":"<p>When performing convolutions, the sliding window does not always fit the size of the image to be convolved, padding is used in those cases to make up for the missing pixels. In CycleGAN, a reflection padding is used which just means that the missing pixels are filled in with its neighbouring pixels before being convolved instead of being filled with a \u201cblack\u201d 0 pixel. This helps to preserve some more content information.</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#photos-to-paintings","title":"Photos To Paintings","text":"<p>To convert photos to paintings, the procedure remains exactly the same as before. The only difference is the dataset. As long as the dataset contains images in different folders with different painting style information alongside a folder of plain photos, CycleGAN can convert between them. The original paper has many such results. Some of which are shown below.</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#more-use-cases","title":"More Use Cases","text":"<p>Just like converting photos to paintings, a similar thought process can be applied to find other uses cases. The ones that the paper mention are as follows : - Style Transfer : Same as photos to and from paintings except with other types of imagery than just paintings. - Object Transformation : Convert to and from objects within ImageNet classes by traversing the latent space. Eg: Converting apples to oranges, zebras to horses etc. - Season Transfer : Converting images taken in Winter to summer and vice versa.</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#limitations","title":"Limitations","text":"<p>Every method has its limitations. CycleGAN performs poorly when given geometrical transformations. This is because it is trained to change appearances but it does not penalise changes in geometry.  ::: :::section{.summary}</p>"},{"location":"articles/Scalar/CycleGAN%20%23scalar/#conclusion","title":"Conclusion","text":"<p>In this article, we learnt about CycleGAN and all the architectural details required to create it. We explored the concept of a latent space and understood how a GAN works by traversing it. We also looked at many applications of a CycleGAN and how to train one on our own data. :::</p>"},{"location":"articles/Scalar/DCGAN%20%E2%80%93%20Adding%20convolution%20to%20a%20GAN/","title":"DCGAN \u2013 Adding convolution to a GAN","text":"<p>toc: true title: DCGAN \u2013 Adding convolution to a GAN</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Scalar/DCGAN%20%E2%80%93%20Adding%20convolution%20to%20a%20GAN/#dcgan-adding-convolution-to-a-gan","title":"DCGAN \u2013 Adding convolution to a GAN","text":"<p>:::section{.abstract}</p>"},{"location":"articles/Scalar/DCGAN%20%E2%80%93%20Adding%20convolution%20to%20a%20GAN/#overview","title":"Overview","text":"<p>Generative networks are a fascinating subfield of Computer vision. The GAN, in particular, is a training paradigm and a family of network architectures that convert a simple convolutional network to generate novel images based on an image dataset. This training is generally unpaired and does not require any labels. The original GAN architecture was unstable and had issues returning random noise as an output. The DCGAN was proposed as an alternative architecture with many tweaks over the original to counter issues such as mode collapse, diminished gradients, and non-convergence. ::: :::section{.scope}</p>"},{"location":"articles/Scalar/DCGAN%20%E2%80%93%20Adding%20convolution%20to%20a%20GAN/#scope","title":"Scope","text":"<ul> <li>This article explains the concept of GANs and how DCGANs differ from Vanilla GANs.</li> <li>It shows how to build a DCGAN from scratch using PyTorch for image generation using the ../../CIFAR|CIFAR dataset.</li> <li>It explains the preprocessing and loading of the ../../CIFAR|CIFAR dataset using a DataLoader.</li> <li>It describes the architecture of the DCGAN and the reasoning behind the choices of layers and activation functions.</li> <li>The article also describes how to train the network, generate new images, and improve the training time and the results.</li> </ul> <p>::: :::section{.main}</p>"},{"location":"articles/Scalar/DCGAN%20%E2%80%93%20Adding%20convolution%20to%20a%20GAN/#introduction-to-dggan","title":"Introduction to DGGAN","text":"<p>This article will explore using a Deep Convolutional Generative Adversarial Network (DCGAN) to generate new images from the ../../CIFAR|CIFAR dataset. GANs are neural networks designed to generate new, previously unseen data similar to the input data the model trained on. DCGANs are a variation of GANs that address issues that can arise with standard GANs by using deep convolutional neural networks in both the Generator and the Discriminator.</p> <p>This architecture allows larger image sizes than in standard GANs, as convolutional layers can efficiently process images with many pixels. Additionally, DCGANs use batch normalization and leaky ReLU activations in the Discriminator and transposed convolutional layers in the Generator, improving performance and stability during training.</p> <p>We will use PyTorch to build the DCGAN from scratch, train it on the [../../CIFAR|CIFAR] dataset, and write scripts to generate new images. The goal is to generate photorealistic images that resemble one of the ten classes in the ../../CIFAR|CIFAR dataset. Before we begin, we will set up the necessary libraries and create folders to store the models' images and weights. This article will guide the implementation process and explain the reasoning for some architectural choices.</p> <p>:::</p> <p>:::section{.main}</p>"},{"location":"articles/Scalar/DCGAN%20%E2%80%93%20Adding%20convolution%20to%20a%20GAN/#need-for-dcgan","title":"Need for DCGAN","text":"<ul> <li>A simple convolutional GAN needs to be more stable to generate images with a high resolution and suffers from mode collapse. </li> <li>DCGAN, on the other hand, has an architecture that uses not just convolutions but also transposed convolutions and other improvements. </li> <li>These changes help the network learn better and generate images more stably compared to other architectures that came before it. </li> <li>The DCGAN research was a monumental step for GANs as it was one of the earliest stable unsupervised image generators. </li> <li>Understanding how it works is the gateway to creating more advanced GANs.</li> </ul> <p>:::section{.main}</p>"},{"location":"articles/Scalar/DCGAN%20%E2%80%93%20Adding%20convolution%20to%20a%20GAN/#pre-requisites","title":"Pre-requisites","text":"<p>To understand the DCGAN Architecture, we need to know some pre-requisite concepts. Since the entire architecture is made up of blocks of the same components, knowing them is helpful.</p>"},{"location":"articles/Scalar/DCGAN%20%E2%80%93%20Adding%20convolution%20to%20a%20GAN/#transposed-convolutionsde-convolution","title":"Transposed Convolutions/De-Convolution","text":"<p>A De-Convolution is an upsampling method that uses transforms opposite to a normal convolution operation. It maintains the input's shape and pattern that a standard convolution would possess.  [IMAGE {1} { Transposed Convolution } START SAMPLE]  [IMAGE {1} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/DCGAN%20%E2%80%93%20Adding%20convolution%20to%20a%20GAN/#stridedstrided-convolutions","title":"../../Strided|Strided Convolutions","text":"<p>The stride in a Convolution determines how many steps the moving filter skips over in an image. In a general Convolution, the stride is set to 1. To perform ../../Downsampling|downsampling, we can set the stride to any number above 1. Larger numbers are only sometimes good; only experimenting with the parameter can be used to understand which to pick. [IMAGE {2} {Strided Convolution} START SAMPLE]  [IMAGE {2} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/DCGAN%20%E2%80%93%20Adding%20convolution%20to%20a%20GAN/#leaky-relu","title":"Leaky ReLU","text":"<p>The Leaky ReLU activation is a small modification over the ReLU that is useful for networks with sparse gradients like the DCGAN. Due to the GAN architecture and training methodology, some nodes that use ReLU tend to die out and do nothing. The Leaky ReLU accounts for negative values by having a smaller slope instead of going straight to zero.  The change is quite minor but makes a huge difference. While the ReLU is defined as \\(max(0, x)\\), the Leaky ReLU is \\(max(0,01x, x)\\)</p> <p>[IMAGE {3} {Leaky ReLU} START SAMPLE]  [IMAGE {3} FINISH SAMPLE] ::: :::section{.main}</p>"},{"location":"articles/Scalar/DCGAN%20%E2%80%93%20Adding%20convolution%20to%20a%20GAN/#architecture","title":"Architecture","text":"<p>The DCGAN architecture follows a similar pattern to many GAN architectures, with a Generator and a Discriminator to process inputs. </p> <p>[IMAGE {4} {Architecture} START SAMPLE]  [IMAGE {4} FINISH SAMPLE]</p> <p>The general flow of input looks something like the following. For every iteration, randomly generated noise is passed to the Generator. The Discriminator gets a random image sampled from the dataset. The Generator uses the learned weights to modify the noise closer to the target image. The Generator then passes this modified image to the Discriminator, which predicts how real the image looks and returns a probability of the same. The loss from both parts is combined to minimize the loss functions for the Generator and the Discriminator using back-propagation. </p> <p>An important point to note for both parts is that the weights are initialized differently for the Convolutional and Batch Normalization layers. If the layer is Convolutional, the weights are from a random normal distribution with a standard deviation of 0.02 and a mean of 0. If the layer is a Batch Normalization layer, a standard deviation of 0.02 means of 1.0 with a bias of 0 is used. </p>"},{"location":"articles/Scalar/DCGAN%20%E2%80%93%20Adding%20convolution%20to%20a%20GAN/#deconvolutional-generator","title":"Deconvolutional Generator","text":"<p>[IMAGE {5} {Generator} START SAMPLE]  [IMAGE {5} FINISH SAMPLE]</p> <p>The Generator maps the input from its latent space to the vector data space. This part of the network outputs an RGB image the same size as the training image (3x64x64).  The Generator comprises blocks of Transposed Convolutions, Batch Normalizations, and ReLU layers. The output is passed through a Tanh activation that maps it to a range of [-1,1].  The DCGAN authors also found that using a Batch Normalization layer after a Transposed Convolution led to the best results by aiding the gradient flow between the layers. This effect was previously never studied in depth. In the architecture diagram of this component, nz stands for the width of the input, ngf stands for the shape of the maps that the network creates, and nc refers to a count of the channels that the output will have (Eg : 3 channels for RGB, 4 for RGBA).</p>"},{"location":"articles/Scalar/DCGAN%20%E2%80%93%20Adding%20convolution%20to%20a%20GAN/#convolutional-discriminator","title":"Convolutional Discriminator","text":"<p>The Discriminator is a mirror of the Generator except for a few changes. The input size remains the same as the Generator (3x64x64). Instead of a De-Convolution, a ../../Strided|Strided Convolution is used. A Leaky ReLU version of ReLU replaces the ReLU activations. The final layer is a Sigmoid layer to return the probability of real vs. fake.  The DCGAN architecture also uses ../../Strided|Strided Convolutions to downsample the images instead of Pooling, allowing the network to learn a custom pooling function. </p>"},{"location":"articles/Scalar/DCGAN%20%E2%80%93%20Adding%20convolution%20to%20a%20GAN/#implementation","title":"Implementation","text":"<p>To generate images using a DCGAN, we first need to prepare our dataset. This process includes creating a DataLoader to load the images, preprocessing them as necessary, and sending batches of the data to the GPU memory for efficient processing.</p> <p>Next, we need to define the architecture of the DCGAN, including the Generator and Discriminator networks. This process involves specifying the number and type of layers and initializing the weights of these layers. We must also send the network architecture to the GPU memory for efficient processing.</p> <p>Once the data and network are ready, we can train the DCGAN. During training, the network learns to map random noise from the latent space to images that resemble the training data. After training, we can use the Generator to generate new images by providing random noise from the latent space.</p>"},{"location":"articles/Scalar/DCGAN%20%E2%80%93%20Adding%20convolution%20to%20a%20GAN/#defining-the-discriminator","title":"Defining the Discriminator","text":"<p>In the DCGAN, the Discriminator differentiates between the images generated by the Generator as real or fake. Its architecture resembles the Generator but with a few modifications. Specifically, the Discriminator incorporates ../../Strided|Strided Convolution layers, a LeakyReLU activation function, and several layers of Batch Normalization. Lastly, the output is passed through a Sigmoid layer that returns a probability value.</p> <p>For the process of DCGAN image generation, the Discriminator uses ../../Strided|Strided Convolutions in place of Pooling layers. This approach enables the network to develop custom padding functions, improving performance. This approach is a key technique that helps the Discriminator to distinguish between real and fake images more accurately.</p> <pre><code>ngpu = 1\nnz = 100\nngf = 64\nndf = 64\n\nclass Disc_model(nn.Module):\n    def __init__(self, ngpu):\n        super(Disc_model, self).__init__()\n        self.ngpu = ngpu\n        self.main = nn.Sequential(\n            nn.Conv2d(num_channels, ndf, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 8),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, input):\n        if input.is_cuda and self.ngpu &gt; 1:\n            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n        else:\n            output = self.main(input)\n\n        return output.view(-1, 1).squeeze(1)\n</code></pre>"},{"location":"articles/Scalar/DCGAN%20%E2%80%93%20Adding%20convolution%20to%20a%20GAN/#defining-the-generator","title":"Defining the Generator","text":"<p>The Generator in a DCGAN is responsible for taking a random vector from the latent space and mapping it to an image in the vector data space. This mapping uses a series of transposed convolutional layers, batch normalization layers, and ReLU activation layers. Using batch normalization after the transposed convolutional layers helps improve the gradient flow through the network, resulting in better performance and stability during the training process. The final layer of the Generator uses a Tanh activation function to ensure that the output image is in the range of [-1, 1], which is the expected range for image data.</p> <pre><code>class Gen_model(nn.Module):\n    def __init__(self, ngpu):\n        super(Gen_model, self).__init__()\n        self.ngpu = ngpu\n        self.main = nn.Sequential(\n            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 8),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf, num_channels, 4, 2, 1, bias=False),\n            nn.Tanh()\n        )\n\n    def forward(self, input):\n        if input.is_cuda and self.ngpu &gt; 1:\n            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n        else:\n            output = self.main(input)\n            return output\n</code></pre>"},{"location":"articles/Scalar/DCGAN%20%E2%80%93%20Adding%20convolution%20to%20a%20GAN/#defining-the-inputs","title":"Defining the inputs","text":"<p>The CIFAR10 dataset is utilized in this article provided by the Canadian Institute for Advanced Research. This dataset consists of ten classes of images that are similar to the MNIST format but with 3-channel RGB. The CIFAR10 dataset is widely used for benchmarking image classification models and is an easily learned dataset.</p> <p>Before using the dataset, it must be loaded and preprocessed. PyTorch has an inbuilt CIFAR10 dataset implementation that we can load directly. If the dataset is being used for the first time, it must be downloaded. Once the dataset is loaded, images are resized to a common size of 64x64x3. Although CIFAR10 is a clean dataset, this resizing step is still important to standardize the images. Finally, the images are normalized and converted to PyTorch tensors.</p> <p>A DataLoader is then created, a class that creates optimized batches of data to pass to the model. If available, this DataLoader is sent to the GPU to accelerate the DCGAN image generation process.</p> <pre><code>dataset = tv_data.CIFAR10(root=\"./data\", download=True,\n                           transform=transforms.Compose([\n                               transforms.Resize(64),\n                               transforms.ToTensor(),\n                               transforms. Normalize ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                           ]))\nnum_channels=3\n\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=128,\n                                         shuffle=True, num_workers=2)\ncurrent_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n</code></pre>"},{"location":"articles/Scalar/DCGAN%20%E2%80%93%20Adding%20convolution%20to%20a%20GAN/#starting-the-dcgan","title":"Starting the DCGAN","text":"<p>To streamline the workflow, some empty containers are set up at the beginning of the process. A fixed noise of shape (128, size of latent space, 1, 1) is created and transferred to the GPU memory. The labels for real images are also set as one and for fake images as 0. The network will run for 25 epochs in this example. For tracking progress and analyzing performance, arrays are created to store the Generator and Discriminator loss during training.</p> <pre><code>fixed_noise = torch.randn(128, nz, 1, 1).to(current_device)\nreal_label = 1\nfake_label = 0\n\nniter = 25\ng_loss = []\nd_loss = []\n</code></pre>"},{"location":"articles/Scalar/DCGAN%20%E2%80%93%20Adding%20convolution%20to%20a%20GAN/#computing-the-loss-function","title":"Computing the loss function","text":"<p>The DCGAN image generation process involves two loss functions, one for the Generator and another for the Discriminator.</p> <p>The Discriminator loss function penalizes the model for incorrectly classifying a real image as fake or a fake image as real. This loss can be thought of as maximizing the following function: \\(\\(\\nabla_{\\theta_{d}} \\frac{1}{m} \\Sigma_{i=1}^{m}[log D(x^{(i)}) + log(1-D(G(z^{(i)})))]\\)\\)</p> <p>The Generator loss function considers the Discriminator's output, rewarding the Generator if it can fool the Discriminator into thinking the fake image is real. If this condition is not met, the Generator is penalized. This loss can be thought of as minimizing the following function: \\(\\(\\nabla_{\\theta_{g}} \\frac{1}{m} \\Sigma_{i=1}^{m}log(1-D(G(z^{(i)})))\\)\\)</p> <p>In summary, the Discriminator's role is to maximize its loss function, and Generator's role is to minimize its loss function, which results in Generator creating an image similar to real images. These fake images should be identified as real by the Discriminator.</p> <pre><code>model_Gen = Gen_model(ngpu).to(current_device)\nmodel_Gen.apply(weights_normal_init)\nmodel_Disc = Disc_model(ngpu).to(current_device)\nmodel_Disc.apply(weights_normal_init)\nloss_func = nn.BCELoss()\n</code></pre>"},{"location":"articles/Scalar/DCGAN%20%E2%80%93%20Adding%20convolution%20to%20a%20GAN/#optimizing-the-loss","title":"Optimizing the loss","text":"<p>In this implementation, for DCGAN image generation, the ADAM optimizer is used with a learning rate of 0.0002, and the beta parameters are set to (0.5, 0.999) to minimize the loss function. Different optimizers are used for each of them to ensure that the Generator and Discriminator learn independently.</p> <pre><code>optimizerD = optim.Adam(model_Disc.parameters(), lr=0.0002, betas=(0.5, 0.999))\noptimizerG = optim.Adam(model_Gen.parameters(), lr=0.0002, betas=(0.5, 0.999))\n</code></pre>"},{"location":"articles/Scalar/DCGAN%20%E2%80%93%20Adding%20convolution%20to%20a%20GAN/#train-the-dcgan","title":"Train the DCGAN","text":"<p>The DCGAN image generation process involves training the network before generating new images. The procedure is done in the following steps.</p> <ul> <li>For each epoch, random noise is sent as an input to the Generator.</li> <li>The Discriminator also receives a random image sampled from the dataset.</li> <li>The Generator then uses its learned weights to transform the noise to be more similar to the target image. These weights allow the Generator to learn the mapping between random noise and the latent space of the image dataset.</li> <li>The Generator sends the modified image to the Discriminator.</li> <li>The Discriminator evaluates the realism of the generated image and communicates it to the Generator through a probability metric.</li> <li>This process of the Generator creating new images and the Discriminator evaluating it continues until the desired number of epochs.</li> <li>Once the training is completed, the Generator can generate new images by inputting random noise.</li> </ul> <pre><code>for epoch in tqdm(range(niter), total = niter):\n    for i, data in enumerate(dataloader, 0):\n        model_Disc.zero_grad()\n        device_model = data[0].to(current_device)\n        batch_size = device_model.size(0)\n        label = torch.full((batch_size,), real_label).to(current_device)\n\n        output = model_Disc(device_model) # Discriminator output\n        disc_error_real = loss_func(output.float(), label.float()) \n        disc_error_real.backward() # disc loss for real image\n        D_x = output.mean().item()\n\n        noise = torch.randn(batch_size, nz, 1, 1).to(current_device) # create noise\n        fake = model_Gen(noise) # Fake image\n        label.fill_(fake_label) # Fill with 0\n        output = model_Disc(fake.detach())\n        disc_error_fake = loss_func(output.float(), label.float()) # disc loss for fake image\n        disc_error_fake.backward() \n        D_G_z1 = output.mean().item()\n        disc_error = disc_error_real + disc_error_fake\n        optimizerD.step()\n\n        model_Gen.zero_grad()\n        label.fill_(real_label) # fill with 1\n        output = model_Disc(fake.float()) # disc output\n        gen_error = loss_func(output.float(), label.float())\n        gen_error.backward()\n        D_G_z2 = output.mean().item()\n        optimizerG.step()\n\n        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f' % (epoch, niter, i, len(dataloader), disc_error.item(), gen_error.item(), D_x, D_G_z1, D_G_z2))\n\n        if i % 100 == 0: # save images every 100 steps\n            print('saving the output')\n            vutils.save_image(device_model,'./images/real_samples.png',normalize=True)\n            fake = model_Gen(fixed_noise)\n            vutils.save_image(fake.detach(),'./images/fake_samples_epoch_%03d.png' % (epoch),normalize=True)\n\n    torch.save(model_Gen.state_dict(), 'weights/model_Gen_epoch_%d.pth' % (epoch))\n    torch.save(model_Disc.state_dict(), 'weights/model_Disc_epoch_%d.pth' % (epoch))\n</code></pre> <p>This article trains the network for 25 epochs. To get a better understanding of the progression of the training, we compare the original sample to the outputs generated at the 0th, 10th, and 25th epochs. As the training progresses, the ./images folder is periodically checked every 100 steps to observe the output. After the training is completed, the final results are as follows.</p> <p>[IMAGE {5} Original Sample/Target START SAMPLE]  [IMAGE {5} FINISH SAMPLE]</p> <p>[IMAGE {6} Epoch 0 START SAMPLE]  [IMAGE {6} FINISH SAMPLE]</p> <p>[IMAGE {7} Epoch 10 START SAMPLE]  [IMAGE {7} FINISH SAMPLE]</p> <p>[IMAGE {8} Final Results START SAMPLE]  [IMAGE {8} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/DCGAN%20%E2%80%93%20Adding%20convolution%20to%20a%20GAN/#weight-initialization","title":"Weight Initialization","text":"<p>The DCGAN model requires a careful weight initialization scheme. If the layer is a Convolutional layer, we can take the initialization values from a Normal distribution in the range of (0.0,0.02). On the other hand, if the layer is a Batch Normalization layer, we can take the weights from a Normal distribution in the range of (0.0, 0.02) while we can set the bias to 0.</p> <pre><code>def weights_normal_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        m.weight.data.normal_(0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        m.weight.data.normal_(0.0, 0.02)\n        m.bias.data.fill_(0)\n</code></pre> <p>::: :::section{.summary}</p>"},{"location":"articles/Scalar/DCGAN%20%E2%80%93%20Adding%20convolution%20to%20a%20GAN/#conclusion","title":"Conclusion","text":"<ul> <li>The article has explained the concept of GANs and the specific architecture of DCGANs, which are a variation that can handle larger images.</li> <li>It has also provided a step-by-step guide on how to build a DCGAN from scratch using the PyTorch library and the ../../CIFAR|CIFAR dataset.</li> <li>The implementation process, including loading the dataset and preprocessing it, creating the network architecture and initialization of weights, as well as training the network, has been explained.</li> <li>The final output is expected to be a set of photorealistic images that resemble one of the classes in the ../../CIFAR|CIFAR dataset, which is a significant achievement.</li> <li>GANs, particularly DCGANs, have a wide range of applications and can generate images of different objects, depending on the dataset used to train the network. This article provides a foundation for further research and experimentation with GANs.</li> </ul> <p>:::</p>"},{"location":"articles/Scalar/Differences%20between%20Discriminative%20and%20Generative%20models/","title":"Differences between Discriminative and Generative models","text":"<p>toc: true title: Differences between Discriminative and Generative models</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Scalar/Differences%20between%20Discriminative%20and%20Generative%20models/#differences-between-discriminative-and-generative-models","title":"Differences between Discriminative and Generative models","text":"<p>:::section{.abstract}</p>"},{"location":"articles/Scalar/Differences%20between%20Discriminative%20and%20Generative%20models/#overview","title":"Overview","text":"<p>Machine learning models can be broadly classified into discriminative and generative. Discriminative models, such as logistic regression, support vector machines, and decision [../../Trees|trees], learn to model boundaries around classes in a dataset and estimate the conditional probability of the target variable given the data. On the other hand, generative models, such as latent Dirichlet allocation, Bayesian networks, and hidden Markov models, create new data points by estimating the joint probability distribution of the data and the target variable. Generative models are often used for unsupervised tasks, such as topic modelling and ../../Dimensionality Reduction|dimensionality reduction, while discriminative models are more commonly used for classification and regression. ::: :::section{.scope}</p>"},{"location":"articles/Scalar/Differences%20between%20Discriminative%20and%20Generative%20models/#scope","title":"Scope","text":"<ul> <li>The article introduces the concept of discriminative and generative models in the context of machine learning.</li> <li>The article explains the differences between these two models and how they approach tasks differently.</li> <li>The article provides examples of commonly used machine learning models in the discriminative or generative category.</li> <li>The article discusses the applications of discriminative and generative models in various tasks, such as classification, regression, and unsupervised learning.</li> <li>The article also compares the advantages and disadvantages of discriminative and generative models.</li> </ul> <p>::: :::section{.main}</p>"},{"location":"articles/Scalar/Differences%20between%20Discriminative%20and%20Generative%20models/#introduction","title":"Introduction","text":"<p>Various Machine Learning models have been proposed over the years, each for different tasks. A broad categorization of these models is to classify them into Generative and Discriminative models. Discriminative models estimate the conditional probability, while Generative models estimate the joint probability distribution. This article will examine the difference between Generative and Discriminative models. We will also introduce several commonly used ML models and categorize them into these two groups.</p>"},{"location":"articles/Scalar/Differences%20between%20Discriminative%20and%20Generative%20models/#discriminative-model","title":"Discriminative Model","text":"<p>Discriminative Models are a family of models that do not generate new data points but learn to model boundaries around classes in a dataset instead. These models aim to maximize the separation between the classes in the dataset to perform classification or Regression. Discriminative models estimate the conditional probability \\(P(Y|X =x)\\) on a data X and a target Y.  Note that sometimes classifiers that do not use a probability model are called Discriminative Models.</p>"},{"location":"articles/Scalar/Differences%20between%20Discriminative%20and%20Generative%20models/#logistic-regression","title":"Logistic Regression","text":"<p>Logistic Regression is a classification algorithm that uses the Sigmoid function instead of a linear function to model data.</p> <p>The Sigmoid curve is shown in the figure below.</p> <p>[IMAGE {1} { Sigmoid Curve } START SAMPLE]  [IMAGE {1} FINISH SAMPLE]</p> <p>We can also use Logistic Regression for multi-class tasks by modelling each class separately. Therefore, the Regression's outcome must be a discrete or categorical value. (e.g., Yes/No, True/False) The model's output is a probabilistic value in the range [0,1]. The modelled curve that the logistic function uses indicates the likelihood of the binary decision.  The following equation can mathematically represent Logistic Regression. \\(\\(log[\\frac{y}{1-y}] = b_0 + b_1 x_1 + b_2 x_2 + \u2026 + b_n x_n\\)\\)</p> <p>Considering the difference between Generative and Discriminative models is important in understanding why these models are Discriminative.</p>"},{"location":"articles/Scalar/Differences%20between%20Discriminative%20and%20Generative%20models/#support-vector-machine","title":"Support Vector Machine","text":"<p>A Support Vector Machine (SVM) is a supervised classification and regression algorithm that uses the concept of hyperplanes. These hyperplanes can be understood as multi-dimensional linear ../../Decision Boundaries|decision boundaries that separate groups of unequal data points.  An example of a hyperplane is shown below.</p> <p>[IMAGE {2 } { SVM } START SAMPLE]  [IMAGE { 2} FINISH SAMPLE]</p> <p>An optimal fit of the SVM occurs when a hyperplane is furthest from the training data points of any of the classes\u2014the larger this distance margin, the lower the error of the classifier.  To better understand how the SVM works, consider a group of data points like the one shown in the diagram. It is a good fit if the hyperplane separates the points in the space so they are clustered according to their labels. If not, further iterations of the algorithm are performed. </p>"},{"location":"articles/Scalar/Differences%20between%20Discriminative%20and%20Generative%20models/#decision-tree","title":"Decision Tree","text":"<p>Decision ../../Trees|trees are tree-based decision models that use an internal structure of a root node followed by successive child leaf nodes. The leaf nodes are a placeholder for the classification label, and the branches show the outcomes of the decision. The paths from the tree's root to the leaves represent the classifier rules. Each tree and sub-tree models a single decision and enumerates all the possible decisions to choose the best one. A Decision tree can be optimal if it represents most of the data with the least number of levels. Decision [../../Trees|trees] are helpful for classification but can be extended for Regression using different algorithms. These ../../Trees|trees are computationally efficient, and many tree-based optimizations have been created over the years to make them perform even faster. An example of such a tree is shown below.  [IMAGE {3 } { Decision Tree } START SAMPLE]  [IMAGE { 3} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Differences%20between%20Discriminative%20and%20Generative%20models/#random-forest","title":"Random Forest","text":"<p>[IMAGE {4 } { Random Forest } START SAMPLE]  [IMAGE { 4} FINISH SAMPLE]</p> <p>Random Forest models use a forest of Decision [../../Trees|Trees] to make better decisions by combining each tree's decisions. The most popular decision across the ../../Trees|trees for a task is the best after the aggregation. This technique of aggregating multiple results from similar processes is called Ensembling.  The second component of the Random Forest pertains to another technique called Bagging. Bagging differs from Ensembling because, in Bagging, the data is different for every model, while in Ensembling, the different models are run on the same data. In Bagging, a random sample with replacement is chosen multiple times to create a data sample. These data samples are then used to train the model independently. After training all these models, the majority vote is taken to find a better estimate of the data. Random forests combine the concepts of Bagging and Ensembling to decide the best feature splits and select subsets of the same. This algorithm is better than using a single Decision Tree as it reduces bias and the net variance, generating better predictions.</p> <p>Bagging and Ensembling might seem like they help model the joint probability distribution, but that is not the case. Understanding the difference between Generative and Discriminative models can clear this confusion.</p>"},{"location":"articles/Scalar/Differences%20between%20Discriminative%20and%20Generative%20models/#generative-models","title":"Generative Models","text":"<p>Generative Models are a family of models that create new data points. They are generally used for unsupervised tasks. Generative Models use the joint probability distribution \\(P(X, Y)\\) on a variable X and a target variable Y to model the data and perform inference by estimating the probability of the new data point belonging to any given class.</p>"},{"location":"articles/Scalar/Differences%20between%20Discriminative%20and%20Generative%20models/#latent-dirichlet-allocation-ldalda","title":"Latent Dirichlet Allocation (../../LDA|LDA)","text":"<p>[../../LDA|LDA] models aim to accurately estimate the classwise mean and variance of the data points in a given dataset. After calculating these statistics, [../../LDA|LDA] makes predictions by estimating the probability of the new class belonging to any of the classes in the original data. In ML, [../../LDA|LDA] models are used for topic modelling and discovery. [../../LDA|LDA] is similar to [../../PCA|PCA] in that it also performs a [../../Dimensionality Reduction|dimensionality reduction]. But unlike [../../PCA|PCA], ../../LDA|LDA maximizes the class separation and not the variance of the data. This principle is illustrated in the figure below.</p> <p>[IMAGE {5 } { LDA } START SAMPLE]  [IMAGE { 5} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Differences%20between%20Discriminative%20and%20Generative%20models/#bayesian-network","title":"Bayesian Network","text":"<p>A Bayesian Network is a graph-based probabilistic model that uses a special graph structure known as a DAG - Directed Acyclic Graph to model conditional dependencies between the given variables. These networks are useful in finding the possible cause of an event, given several contributing factors. A classic example of what a Bayesian Network looks like is shown below.</p> <p>[IMAGE {6 } { Bayesian Network } START SAMPLE]  [IMAGE { 6} FINISH SAMPLE]</p> <p>The Bayesian Network uses this graph to model the joint probability distribution. Each of the edges in the graph represents a dependency, while each node represents a unique variable. The model can then use this learnt distribution for inference. We can use Bayesian Networks to infer unobserved variables, learn parameters from the data and learn the structure of a manually created data distribution.</p> <p>Note that each represents Boolean variables if there are \\(m\\) parent nodes. A minimum of \\(2^m\\) entries are required to model the possible events.</p>"},{"location":"articles/Scalar/Differences%20between%20Discriminative%20and%20Generative%20models/#hidden-markov-model","title":"Hidden Markov Model","text":"<p>A Markov process is a sequential process where the previous item only influences the next item in the sequence. A Markov Chain, therefore, is a graph that uses probabilities to denote how likely it is to move to the next state in the chain. (If it is not clear how this is a Generative model, refer to the section on the difference between Generative and Discriminative models) An example Markov Chain is shown below. [IMAGE {7 } { Markov Chain } START SAMPLE]  [IMAGE { 7} FINISH SAMPLE]</p> <p>A Hidden Markov Model is a graph where the chain is unobservable. The inputs the model receives are combined with the probabilities of the previous step. This combination is used to calculate the next step in the graph.  A constraint in an HMM is that at a certain time \\(t= t_{0}\\), the target Y must be influenced only by the state of X at \\(t= t_{0}\\). The states of Y at \\(t= t_{0}\\) should not be affected by the states of X and Y at \\(t &lt; t_{0}\\).</p> <p>An example of a Markov Model is shown here for reference. [IMAGE {8 } { HMM } START SAMPLE]  [IMAGE { 8} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Differences%20between%20Discriminative%20and%20Generative%20models/#autoregressive-model","title":"Autoregressive model","text":"<p>An Autoregressive model is used in time series forecasting. This model uses the past values in the time series to predict values that might occur in the future. An Autoregressive model gets its name as it is a regression of itself. These models are generally represented as stochastic difference equations that use linear combinations of past values to model the data. A mathematical representation is as follows.</p> <p>\\(y_{t} + c + \\phi_{1} y_{t-1} + \\phi_{2} y_{t-2} + \u2026 + \\phi_{p} y_{t-p} + \\epsilon_{t}\\) where  \\(\\epsilon_{t}\\) is white noise.  Note that changing the patterns for \\(\\phi\\) changes the time series. Varying the error term does not change the pattern but modifies the scale of the data instead.</p> <p>An example of an Autoregressive model is shown below. [IMAGE {9 } { Autoregressive Model } START SAMPLE]  [IMAGE { 9} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Differences%20between%20Discriminative%20and%20Generative%20models/#generative-adversarial-network","title":"Generative Adversarial Network","text":"<p>Generative Adversarial Networks are models that take large image datasets as input and generate new images. A GAN models the data distribution by exploiting the latent space of the dataset given to it. A GAN comprises two parts - A Generator and a Discriminator. These parts play a MinMax Game, where the Generator creates novel images from random noise while the Discriminator classifies the outputs into real or fake. When the Discriminator can no longer distinguish between real and fake images created by the Generator, the GAN training is said to be complete.</p> <p>An example of a GAN that converts images to a different style is shown in the following image. [IMAGE {10 } { GAN } START SAMPLE]  [IMAGE { 10} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Differences%20between%20Discriminative%20and%20Generative%20models/#discriminative-vs-generative-models","title":"Discriminative vs Generative Models","text":"<p>The difference between Generative and Discriminative models is summarised in the following table.</p> Generative Models Discriminative Models Aim to understand the data distribution Aim to model the data decision boundary Uses the joint probability Uses the conditional probability Relatively computationally expensive Relatively cheaper computationally Unsupervised Tasks Supervised Tasks Harmed by outliers More robust to the presence of outliers Models how data is placed in space Generates boundaries around similar classes of data in space <p>::: :::section{.summary}</p>"},{"location":"articles/Scalar/Differences%20between%20Discriminative%20and%20Generative%20models/#conclusion","title":"Conclusion","text":"<ul> <li>In summary, discriminative and generative models are two categories of machine learning models that approach tasks differently.</li> <li>Discriminative models aim to maximize the separation between classes in a dataset to perform classification or regression. </li> <li>In contrast, generative models create new data points by estimating the joint probability distribution of the data and the target variable. </li> <li>Both models have their own set of advantages and disadvantages and can be applied to various tasks. </li> </ul> <p>:::</p>"},{"location":"articles/Scalar/Generating%20Images%20using%20GANs%20in%20Tensorflow/","title":"Generating Images using GANs in Tensorflow","text":"<p>toc: true title: Generating Images using GANs in Tensorflow</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Scalar/Generating%20Images%20using%20GANs%20in%20Tensorflow/#generating-images-using-gans-in-tensorflow","title":"Generating Images using GANs in Tensorflow","text":"<p>:::section{.abstract}</p>"},{"location":"articles/Scalar/Generating%20Images%20using%20GANs%20in%20Tensorflow/#overview","title":"Overview","text":"<p>This article explains using a Generative Adversarial Network (GAN) to generate new images of handwritten digits. A GAN is a machine-learning model consisting of a generator and a discriminator. The generator creates novel images from random, while the Discriminator attempts to prove that the images generated are fake. The GAN is trained on the MNIST dataset of handwritten digits and is evaluated by testing it on unseen data and creating new images using the generator. The final output of the GAN is a batch of images that look like handwritten digits. The article provides code for reading the dataset, creating the required architecture, computing loss functions, training the network, and testing the network.</p> <p>::: :::section{.scope}</p>"},{"location":"articles/Scalar/Generating%20Images%20using%20GANs%20in%20Tensorflow/#scope","title":"Scope","text":"<ul> <li>The article provides a general overview of Generative Adversarial Networks (GANs) and their use in image generation.</li> <li>The specific goal of the article is to demonstrate how to create a GAN from scratch using the Tensorflow library and train it on the MNIST dataset to generate new images of handwritten digits.</li> <li>The article explains the architecture and components of a GAN, including the generator and Discriminator.</li> <li>The article also provides code for reading and preprocessing the MNIST dataset, creating the GAN architecture, computing loss functions, training the network, and testing the network.</li> <li>The article also discusses the final output of the GAN, which should be a batch of images that look like handwritten digits.</li> </ul> <p>::: :::section{.main}</p>"},{"location":"articles/Scalar/Generating%20Images%20using%20GANs%20in%20Tensorflow/#what-are-we-building","title":"What are we building?","text":"<p>Creating novel images given an image dataset is one of the strengths of a specific branch of models called Generative Adversarial Networks (GAN). These networks specialize in unsupervised/semi-supervised image generation given any image data.  This article uses the GANs image generation ability to create novel handwritten digits. We perform this generation by training the network on a dataset of handwritten digits. We will create a simple GAN from scratch using the Tensorflow library, train it on the MNIST dataset and generate new images of handwritten digits. </p>"},{"location":"articles/Scalar/Generating%20Images%20using%20GANs%20in%20Tensorflow/#pre-requisites","title":"Pre-requisites","text":""},{"location":"articles/Scalar/Generating%20Images%20using%20GANs%20in%20Tensorflow/#what-are-gans","title":"What are GANs","text":"<p>GANs, or Generative Adversarial Networks, are a family of networks used for unsupervised image generation, converting between images to another, and many other applications. They are composed of two parts - a Generator and a Discriminator. The Generator creates novel images from random. The Discriminator attempts to prove that the images generated are fake. This game leads to a training approach dubbed \"Adversarial Learning\". This article focuses on implementing a GAN and its image-generation ability to create new handwritten digits.</p>"},{"location":"articles/Scalar/Generating%20Images%20using%20GANs%20in%20Tensorflow/#how-are-we-going-to-build-this","title":"How are we going to build this?","text":"<p>In this article, we focus on the GAN's image generation ability. To let the GAN learn about images, we must first load an image dataset and preprocess it. After loading the data, we must create the GAN and write the training and testing code. The below sections focus on implementing these features and generating new images from the MNIST dataset.</p>"},{"location":"articles/Scalar/Generating%20Images%20using%20GANs%20in%20Tensorflow/#final-output","title":"Final Output","text":"<p>The final output we want should be a batch of images that look like handwritten digits. The image shown below is what we get after training the GAN for 10000 epochs on the MNIST dataset.</p> <p>[IMAGE {1} { Final results } START SAMPLE]  [IMAGE {1} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Generating%20Images%20using%20GANs%20in%20Tensorflow/#requirements-list-the-libraries-modules-and-other-requirements-needed-for-the-project","title":"Requirements (List the libraries, modules, and other requirements needed for the project)","text":"<p>Before creating the GAN's image generation module, we must import a few libraries. We will import all the functions, layers and dataset loaders from Tensorflow. We will also import numpy (a math library) and matplotlib (a plotting library). </p> <p>We also need to set up some that will make up our configuration for running the module. The shape of the image is defined as a matrix of 28x28x1. The last dimension corresponds to the number of channels in an image. Since we are using the MNIST dataset in black and white, we only have a single channel.</p> <p>The zsize is the shape of the latent space we want to generate. In this case, we set it to 100. This number could be modified if required. </p> <pre><code>from __future__ import print_function, division\n\nfrom keras.datasets import mnist\nfrom keras.layers import Input, Dense, Reshape, Flatten, [../../Dropout|Dropout](../../Dropout|Dropout.md)\nfrom keras.layers import BatchNormalization, Activation, ZeroPadding2D\nfrom keras.layers import LeakyReLU\nfrom keras.layers.convolutional import UpSampling2D, Conv2D\nfrom keras.models import Sequential, Model\nfrom keras. optimizers import Adam, SGD\n\nimport matplotlib.pyplot as plt\nimport sys\nimport numpy as np\n\nnum_rows = 28\nnum_cols = 28\nnum_channels = 1\ninput_shape = (num_rows, num_cols, num_channels)\nz_size = 100\n</code></pre>"},{"location":"articles/Scalar/Generating%20Images%20using%20GANs%20in%20Tensorflow/#building-the-model","title":"Building the Model","text":"<p>The GAN we want to create comprises two major parts - The Generator and the Discriminator. The Generator is responsible for creating novel images, while the Discriminator is responsible for understanding how good the generated image is.  The entire architecture we want to build for the GANs image generation is shown in the following diagram.</p> <p>[IMAGE {2} { Architecture Diagram } START SAMPLE]  [IMAGE {2} FINISH SAMPLE]</p> <p>The sections below explain how to read a dataset, create the required architecture, compute the loss functions and train the network. Finally, the code to test the network and create new images is also shown.</p>"},{"location":"articles/Scalar/Generating%20Images%20using%20GANs%20in%20Tensorflow/#reading-the-dataset","title":"Reading the dataset","text":"<p>This article will use the MNIST (Modified National Institute of Standards and Technology) dataset. This dataset has a larger number of handwritten digits of 28x28 and is one of the most widely used datasets in computer vision. The MNIST is an easy dataset for a GAN such as the one we are building, as it has small, single channels images.  A sample of the dataset is shown below.</p> <p>We only need to write a little code to load the MNIST dataset as Tensorflow comes with it inbuilt. After loading the dataset, we normalize it and then reshape it to 3 dimensions. This reshaping enables the GAN architecture to use this 2D data. We also pre-allocate some memory for our training and validation data. </p> <pre><code>(train_ims, _), (_, _) = mnist.load_data()\ntrain_ims = train_ims / 127.5 - 1.\ntrain_ims = np.expand_dims(train_ims, axis=3)\n\nvalid = np.ones((batch_size, 1))\nfake = np.zeros((batch_size, 1))\n</code></pre>"},{"location":"articles/Scalar/Generating%20Images%20using%20GANs%20in%20Tensorflow/#defining-the-generator","title":"Defining the Generator","text":"<p>[IMAGE {3} { Generator And Discriminator } START SAMPLE]  [IMAGE {3} FINISH SAMPLE]</p> <p>The job of the Generator (D) is to create realistic images that the Discriminator fails to understand are fake. Thus, the Generator is an essential component that enables a GANs image generation ability. The architecture we consider in this article comprises fully connected layers (FC) and Leaky ReLU activations. The final layer of the Generator has a TanH activation rather than a LeakyReLU. This replacement was done because we wanted to convert the generated image to the same range as the original MNIST dataset (-1,1).</p> <pre><code>def build_generator():\n    gen_model = Sequential()\n    gen_model.add(Dense(256, input_dim=z_size))\n    gen_model.add(LeakyReLU(alpha=0.2))\n    gen_model.add(BatchNormalization(momentum=0.8))\n    gen_model.add(Dense(512))\n    gen_model.add(LeakyReLU(alpha=0.2))\n    gen_model.add(BatchNormalization(momentum=0.8))\n    gen_model.add(Dense(1024))\n    gen_model.add(LeakyReLU(alpha=0.2))\n    gen_model.add(BatchNormalization(momentum=0.8))\n    gen_model.add(Dense(np.prod(input_shape), activation='tanh'))\n    gen_model.add(Reshape(input_shape))\n\n    gen_noise = Input(shape=(z_size,))\n    gen_img = gen_model(gen_noise)\n    return Model(gen_noise, gen_img)\n</code></pre>"},{"location":"articles/Scalar/Generating%20Images%20using%20GANs%20in%20Tensorflow/#defining-the-discriminator","title":"Defining the Discriminator","text":"<p>The GAN uses the Discriminator (D) to identify how real the Generator's outputs look by returning a probability of real vs fake. This part of the network can be thought of as a binary classification problem. To solve this binary classification problem, we need a rather simple network composed of blocks of Fully Connect Layers (FC), Leaky ReLU activations and ../../Dropout|Dropout layers. Note that the final layer has a block with an FC layer and a Sigmoid.  The final Sigmoid activation returns the classification probability that we require.</p> <pre><code>def build_discriminator():\n\n    disc_model = Sequential()\n    disc_model.add(Flatten(input_shape=input_shape))\n    disc_model.add(Dense(512))\n    disc_model.add(LeakyReLU(alpha=0.2))\n    disc_model.add(Dense(256))\n    disc_model.add(LeakyReLU(alpha=0.2))\n    disc_model.add(Dense(1, activation='sigmoid'))\n\n    disc_img = Input(shape=input_shape)\n    validity = disc_model(disc_img)\n    return Model(disc_img, validity)\n</code></pre>"},{"location":"articles/Scalar/Generating%20Images%20using%20GANs%20in%20Tensorflow/#computing-the-loss-function","title":"Computing the loss function","text":"<p>To make the GANs image generation procedure smoother, we need to supply it with metrics that show how well it is performing now. Loss functions do just that.</p> <p>The Discriminator classifies the generated images into real or fake and returns the probability of it being real. To make this distinction, it needs to ensure that the input it receives is part of the real dataset. And if the input received is fake, it is not classified as part of the real dataset. We can mathematically understand this difference as maximizing \\(D(x)\\) and minimizing \\(D(G(z))\\).</p> <p>Building on these concepts, the Generator is tasked with fooling the Discriminator by creating realistic images. We can understand this procedure as ensuring that when the Discriminator gets an image sampled from the fake dataset, it thinks that the image belongs to the real dataset instead. We can mathematically understand this procedure as maximizing \\(D(G(z))\\). It is to be. Note that just using this part of the formulae as a loss function sometimes makes the network confident about the wrong outputs. To prevent this assumption, we use \\(log(D(G(z)))\\) instead.</p> <p>The net cost function for the GAN's image generation can be thus mathematically represented as \\(\\(\\underset{G}{min} \\underset{D}{max} V(D, G) = \\mathbb{E}_{x \\sim p_{data}(x)}[log(D(x)] + \\mathbb{E}_{z \\sim p_{z}}[log(1 - D(G(z))]\\)\\)</p> <p>Training a GAN such as this is a delicate balance and can be considered a game between two enemies. (Hence the name - Adversarial Learning.) Since either party attempts to influence the opposition and reduce the others' chance of winning, this is a MinMax game.</p> <p>We can then create the Generator and Discriminator with a Binary Crossentropy loss.</p> <pre><code># discriminator\ndisc= build_discriminator()\ndisc.compile(loss='binary_crossentropy',\n    optimizer='sgd',\n    metrics=['accuracy'])\n\nz = Input(shape=(z_size,))\n# generator\nimg = generator(z)\n\ndisc.trainable = False\n\nvalidity = disc(img)\n\n# combined model\ncombined = Model(z, validity)\ncombined.compile(loss='binary_crossentropy', optimizer='sgd')\n</code></pre>"},{"location":"articles/Scalar/Generating%20Images%20using%20GANs%20in%20Tensorflow/#optimizing-the-loss","title":"Optimizing the loss","text":"<p>To train the network, we need the GAN to play the MinMax game. The training procedure hinges on performing Gradient Descent on the network weights. To reduce the training time and ensure that the training does not get stuck on the loss landscape, we use a Stochastic version of GD, aka Stochastic Gradient Descent.  Both the Discriminator and the Generator have different losses. If We gave both these networks a single loss function, they would not be able to optimize each other. </p> <pre><code>def intialize_model():\n    disc= build_discriminator()\n    disc.compile(loss='binary_crossentropy',\n        optimizer='sgd',\n        metrics=['accuracy'])\n\n    generator = build_generator()\n\n    z = Input(shape=(z_size,))\n    img = generator(z)\n\n    disc.trainable = False\n\n    validity = disc(img)\n\n    combined = Model(z, validity)\n    combined.compile(loss='binary_crossentropy', optimizer='sgd')\n    return disc, Generator, and combined\n</code></pre> <p>Having defined all the required functions, we can train the network to optimize the losses. The steps we follow for the GAN's image generation are as follows. - Load an image, and generate random noise of the same size as the loaded image. - Send these images to the Discriminator and calculate the real vs fake probability for the same. - Generate another noise of the same size. Send this noise to the Generator. - Run training for the Generator for a few epochs. - Repeat all the steps until a satisfactory image is generated.</p> <p>These steps are directly translated into the code shown below.</p> <pre><code>def train(epochs, batch_size=128, sample_interval=50):\n    # load images   \n    (train_ims, _), (_, _) = mnist.load_data()\n    # preprocess\n    train_ims = train_ims / 127.5 - 1.\n    train_ims = np.expand_dims(train_ims, axis=3)\n\n    valid = np.ones((batch_size, 1))\n    fake = np.zeros((batch_size, 1))\n    # training loop\n    for epoch in range(epochs):\n\n        batch_index = np.random.randint(0, train_ims.shape[0], batch_size)\n        imgs = train_ims[batch_index]\n    # create noise\n        noise = np.random.normal(0, 1, (batch_size, z_size))\n    # predict using Generator\n        gen_imgs = gen.predict(noise)\n    # calculate loss functions\n        real_disc_loss = disc.train_on_batch(imgs, valid)\n        fake_disc_loss = disc.train_on_batch(gen_imgs, fake)\n        disc_loss_total = 0.5 * np.add(real_disc_loss, fake_disc_loss)\n\n        noise = np.random.normal(0, 1, (batch_size, z_size))\n\n        g_loss = full_model.train_on_batch(noise, valid)\n    # show progress\n        print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, disc_loss_total[0], 100*disc_loss_total[1], g_loss))\n    # save outputs every few epochs\n        if epoch % sample_interval == 0:\n            one_batch(epoch)\n</code></pre>"},{"location":"articles/Scalar/Generating%20Images%20using%20GANs%20in%20Tensorflow/#generating-handwritten-digits","title":"Generating handwritten digits","text":"<p>Finally, we can generate handwritten digits from the MNIST dataset. To look at how far the network has trained the images, we create a helper function to store predictions from the Generator for a batch of images. This function creates random noise, passes them to the Generator, processes it for displaying and then saves it to a folder. We run this helper function every 200 epochs.</p> <pre><code>def one_batch(epoch):\n    r, c = 5, 5\n    noise = np.random.normal(0, 1, (r * c, z_size))\n    gen_imgs = gen.predict(noise)\n\n    # Rescale images 0 - 1\n    gen_imgs = 0.5 * gen_imgs + 0.5\n\n    fig, axs = plt.subplots(r, c)\n    cnt = 0\n    for i in range(r):\n        for j in range(c):\n            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n            axs[i,j].axis('off')\n            cnt += 1\n    fig.savefig(\"images/%d.png\" % epoch)\n    plt.close()\n</code></pre> <p>For this article, we trained the GAN for around 10,000 epochs with a batch size of 32. We save the generated images every 200 epochs in the images folder.</p> <pre><code>disc, gen, full_model = intialize_model()\ntrain(epochs=10000, batch_size=32, sample_interval=200)\n</code></pre> <p>We can now look at the results of the GAN's image generation at the start, at 400 epochs, at 5000 epochs and the final result at 10000 epochs.</p> <p>At the start, we have random noise. [IMAGE {4} { Epoch 0 } START SAMPLE]  [IMAGE {4} FINISH SAMPLE]</p> <p>After 400 epochs, we are getting somewhere slowly. But these results are different from real digits. [IMAGE {5} { Epoch 400 } START SAMPLE]  [IMAGE {5} FINISH SAMPLE]</p> <p>After 5000 epochs, we can see figures that resemble the MNIST dataset. [IMAGE {6} { Epoch 5000 } START SAMPLE]  [IMAGE {6} FINISH SAMPLE]</p> <p>After training the network for the entire 10,000 epochs, we get the following outputs.  [IMAGE {7} { Final results } START SAMPLE]  [IMAGE {7} FINISH SAMPLE]</p> <p>These images look very close to the handwritten number data we fed the network. These images were not shown to the network during training and were generated from scratch.</p>"},{"location":"articles/Scalar/Generating%20Images%20using%20GANs%20in%20Tensorflow/#whats-next","title":"What's next","text":"<p>The output we got from the GANs image generation is good, but there are many ways we can improve it. Without leaving the scope of this article, we can experiment with a few parameters. Some of them are as follows: - Try different values of the latent space variable z_size to see if the performance improves. - Try training the model for a larger number of epochs. We trained it for 10000; try doubling or tripling that to see if the results improve or worsen. - Try different datasets such as the Fashion MNIST or the Moving MNIST. These datasets follow the same structure as the MNIST, making it possible to use the code we wrote directly. - Finally, it is worth experimenting with other architectures such as CycleGAN, DCGAN etc. Many of them would only require changing the functions of the Generator and Discriminator.</p> <p>::: :::section{.summary}</p>"},{"location":"articles/Scalar/Generating%20Images%20using%20GANs%20in%20Tensorflow/#conclusion","title":"Conclusion","text":"<ul> <li>GANs are machine learning models that can generate new images from a dataset.</li> <li>In this article, a simple GAN is created using the Tensorflow library and trained on the MNIST dataset.</li> <li>The GAN comprises two parts: a Generator that creates novel images from random and a Discriminator that attempts to prove that the images generated are fake.</li> <li>The final output is a batch of images that look like handwritten digits, as shown in the example image provided.</li> <li>The GAN is trained by supplying it with metrics and loss functions that show how well it correctly classifies real and fake images. </li> <li>The GAN is then evaluated by testing it on unseen data and creating new images using the generator.</li> </ul> <p>:::</p>"},{"location":"articles/Scalar/Image%20Classification%20using%20TensorFlow/","title":"Image Classification using TensorFlow","text":"<p>toc: true title: Image Classification using TensorFlow</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Scalar/Image%20Classification%20using%20TensorFlow/#image-classification-using-tensorflow","title":"Image Classification using TensorFlow","text":"<p>:::section{.abstract}</p>"},{"location":"articles/Scalar/Image%20Classification%20using%20TensorFlow/#overview","title":"Overview","text":"<p>Image Classification is one of the basic tasks in Deep Learning. Given a dataset with images of different categories, we create a Deep Learning model and a pipeline to classify these images. We can create models in any library, but Tensorflow is a good starting point for beginners, and we will use this library to create an image classifier. ::: :::section{.main}</p>"},{"location":"articles/Scalar/Image%20Classification%20using%20TensorFlow/#what-are-we-building","title":"What are we building?","text":"<p>This article will tackle a Tensorflow image classification problem by creating a neural network that can classify images from the CIFAR10 dataset. We will explore the concepts of Pre-Processing, Augmentation, and Performance Optimisation. We will learn how to load a dataset, build the model and finally train the model we created using the dataset. We will also learn how to use the trained model to make predictions on custom images.  The following sections explain these concepts and how to implement them using Tensorflow.</p>"},{"location":"articles/Scalar/Image%20Classification%20using%20TensorFlow/#pre-requisites","title":"Pre-requisites","text":"<p>Before we get to the actual code, we must understand a few pre-requisite terms. They are explained here.</p>"},{"location":"articles/Scalar/Image%20Classification%20using%20TensorFlow/#data-loaders","title":"Data Loaders","text":"<p>A Data Loader is a utility function that enables Tensorflow to optimize the data loading performance. The Loader does this by pre-allocating memory, creating batched containers, and applying many other tweaks to improve performance. </p>"},{"location":"articles/Scalar/Image%20Classification%20using%20TensorFlow/#data-augmentation","title":"Data Augmentation","text":"<p>Data Augmentation is a [../../Regularization|regularization] technique that improves performance by applying transformations on the base image. These transformations enable the model to see a much richer dataset without additional data collection. Data augmentation is extremely useful for small to medium-sized datasets. There are many augmentations, such as random flipping, random color jitter, random resized ../../Cropping|cropping, and many others.</p> <p>[IMAGE {1} Data Augmentation  START SAMPLE]  [IMAGE {1} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Image%20Classification%20using%20TensorFlow/#lambda-functions","title":"Lambda functions","text":"<p>Lambda functions are special functions in Tensorflow that lets the user create functions without explicitly defining a function call. These functions are useful for improving the readability of the code and avoiding defining extra functions for single use. </p>"},{"location":"articles/Scalar/Image%20Classification%20using%20TensorFlow/#map-functions","title":"Map functions","text":"<p>In deep learning, there are many times when we need to apply a function over a batch of data. Sequentially performing these tasks is extremely time-consuming, so we use map functions to apply a function in parallel over any batch of data.</p>"},{"location":"articles/Scalar/Image%20Classification%20using%20TensorFlow/#how-are-we-going-to-build-this","title":"How are we going to build this?","text":"<p>In this article, we will be building a Tensorflow image classification model. After loading the required libraries, we first load the data. Here, we will use the CIFAR10 dataset. After loading the data, we split it into the train, test, and validation components and then create batches of the same. To optimize performance, we will also be using caching and pre-fetching. After creating the required data loaders, we can create the model. This demo will use a ResNet50 model with the Adam optimizer and a Sparse Cross-Entropy loss function. Once we have loaded both the data and the model, we can finally train the model on the data and then evaluate its performance. All of these steps are detailed in the sections below.</p>"},{"location":"articles/Scalar/Image%20Classification%20using%20TensorFlow/#final-output","title":"Final Output","text":"<p>The final output we want is a Tensorflow image classification model that can identify the class of a given image. We want our model to learn from the CIFAR10 dataset and understand all ten classes accurately. For example, if we pass this 64x64 image to the model, it should classify it as a horse. [IMAGE {2} Classified Data START SAMPLE]  [IMAGE {2} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Image%20Classification%20using%20TensorFlow/#requirements","title":"Requirements","text":"<p>Before creating a Tensorflow image classification model, we need to import the required modules. Apart from the base Tensorflow library, we also import the Keras package. Keras is a wrapper around Tensorflow that simplifies building neural networks. We will also import a library called Tensorflow Datasets that will enable us to load and pre-process our dataset faster.</p> <pre><code>import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_datasets as tfds\nimport os\n</code></pre>"},{"location":"articles/Scalar/Image%20Classification%20using%20TensorFlow/#building-the-classifier","title":"Building the Classifier","text":"<p>We can now move on to building the classifier with the libraries we implemented. The below sections explain how to load the dataset, pre-process it, optimize it for use, and pass it to the model. We also explore how to create a model using Tensorflow and how to train it on the CIFAR10 dataset. Finally, we also learn how to evaluate a trained model on the test dataset. </p>"},{"location":"articles/Scalar/Image%20Classification%20using%20TensorFlow/#download-and-explore-the-dataset","title":"Download and explore the dataset","text":"<p>For this article, we will be using the CIFAR10 dataset. This dataset has 60000 32x32 color images grouped into ten classes. Before we create the model, we need to load and pre-process the dataset. A sample of images is shown below.</p> <p>[IMAGE {3} CIFAR10 START SAMPLE]  [IMAGE {3} FINISH SAMPLE]</p> <p>We split the dataset into training, testing, and validation and loaded the dataset with labels using the as_supervised option. To verify that we loaded the data correctly, we checked the size of the splits we had just created. If they are not zero or tiny numbers, we can know that our code has worked so far.</p> <pre><code>train_dataset, validation_dataset, test_dataset = tfds.load(\n    \"cifar10\",\n    split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n    as_supervised=True,\n)\n\nprint(\"Number of training samples: %d\" % tf.data.experimental.cardinality(train_dataset))\nprint(\n    \"Number of validation samples: %d\" % tf.data.experimental.cardinality(validation_dataset)\n)\nprint(\"Number of test samples: %d\" % tf.data.experimental.cardinality(test_dataset))\n</code></pre>"},{"location":"articles/Scalar/Image%20Classification%20using%20TensorFlow/#configure-the-dataset-for-performance","title":"Configure the dataset for performance","text":"<p>Simply loading the data and passing it to the model works out of the box but leads to a sharp down in performance. We need to perform some tweaks to ensure that we use our resources optimally. We first define our image size as 128x128x3 pixels and use a lambda function to resize all the images in our dataset to this image size.  The next optimization we perform is converting the dataset into batches of 64 and informing Keras that we wish to cache the data and prefetch 10 samples.  Prefetching data reduces the time it takes to pass the data to the memory by preallocating memory and fetching a few extra samples for the next time the model is called.</p> <pre><code>size = (128, 128)\nbs = 64\n\ntrain_dataset = train_dataset.map(lambda x, y: (tf.image.resize(x, size), y))\nvalidation_dataset = validation_dataset.map(lambda x, y: (tf.image.resize(x, size), y))\ntest_dataset = test_dataset.map(lambda x, y: (tf.image.resize(x, size), y))\n\ntrain_dataset = train_dataset.cache().batch(bs).prefetch(buffer_size=10)\nvalidation_dataset = validation_dataset.cache().batch(bs).prefetch(buffer_size=10)\ntest_dataset = test_dataset.cache().batch(bs).prefetch(buffer_size=10)\n</code></pre>"},{"location":"articles/Scalar/Image%20Classification%20using%20TensorFlow/#create-the-model","title":"Create the model","text":"<p>Since we wish to maximize performance, we also use two simple Data Augmentation techniques. The first one randomly flips the images along the horizontal axis to ensure that the model learns some spatial information. The second Augmentation we use is Random Rotation. We only want to apply this for some images, so we use a lower probability. Applying it to every image might make the model perform worse.</p> <p>In this article, we use the Tensorflow image classification model ResNet50. This model uses the concept of Skip Connections to improve performance. We will not create the model from scratch but use the Keras implementation. To the function call, we need to pass in the weights from which we wish to use the pre-trained model. Since we are training the model from scratch here, we will pass the option as None. If we were using transfer learning, we would use the option \"imagenet\". We also need to pass the image size (128x128x3), the number of classes (10), and whether we want to include the whole model. This final option is only useful for transfer learning.</p> <p>[IMAGE {4} Skip Connections START SAMPLE]  [IMAGE {4} FINISH SAMPLE]</p> <p>Once we load the model, we create an input, pass the current batch through the Augmentation, and finally, a Fully Connected (FC) layer with a size of 10 (CIFAR10 has ten classes). This final model is the one we will be used for training on our data.  We will use the summary function to check the layers to verify if we created the model correctly.</p> <pre><code>aug_transforms = keras.Sequential(\n    [layers.RandomFlip(\"horizontal\"), layers.RandomRotation(0.1),]\n)\n\nmodel_base = keras.applications.ResNet50(\n    weights=None, \n    input_shape=(128, 128, 3),\n    classes = 10,\n    include_top=True\n)\n\ninputs = keras.Input(shape=(128, 128, 3))\n\nx = aug_transforms(inputs) \nx = model_base(x, training=False)\noutputs = keras.layers.Dense(10)(x)\nfinal_model = keras.Model(inputs, outputs)\nfinal_model.summary()\n</code></pre>"},{"location":"articles/Scalar/Image%20Classification%20using%20TensorFlow/#train-the-model","title":"Train the model","text":"<p>We can finally move on to training our model on the CIFAR10 data. Since we have defined our model, we need to define all the parameters required for training it. In this article, we will use the Adam optimizer with the default parameters. We choose a Sparse Categorical Crossentropy function for the loss function as this task is a multi-class classification problem. The metric we use here is a Categorical Accuracy metric that checks how well the classifier performed across all the classes. We will now train the model for five epochs. We can perform further training by increasing the number of epochs.</p> <pre><code>final_model.compile(\n    optimizer=keras.optimizers.Adam(),\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n)\n\nnum_epochs = 5\nfinal_model.fit(train_dataset, epochs=num_epochs, validation_data=validation_dataset)\n</code></pre> <p>[IMAGE {5} Training START SAMPLE]  [IMAGE {5} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Image%20Classification%20using%20TensorFlow/#evaluating-the-model","title":"Evaluating the Model","text":"<p>Five epochs are very small since we are not using transfer learning, and it is only done as a demo. After our model is done training, we can perform a full evaluation on it by performing predictions on the test dataset. While performing inference, we can increase the batch size as we are not training a network.  We can perform this evaluation by using the evaluate function from Keras. </p> <pre><code>results = final_model.evaluate(test_dataset, batch_size=128)\nprint(\"test loss, test acc:\", results)\n</code></pre> <p>A single prediction can be performed with the following code.</p> <pre><code>from PIL import Image\nimport numpy as np\nfrom skimage import transform\ndef load(filename):\n   np_image = Image.open(filename)\n   np_image = np.array(np_image).astype('float32')/255\n   np_image = transform.resize(np_image, (256, 256, 3))\n   np_image = np.expand_dims(np_image, axis=0)\n   return np_image\n\nimage = load('my_file.jpg')\nfinal_model.predict(image)\n</code></pre> <p>::: :::section{.summary}</p>"},{"location":"articles/Scalar/Image%20Classification%20using%20TensorFlow/#conclusion","title":"Conclusion","text":"<ul> <li>This article taught us how to build a Tensorflow Image Classification model.</li> <li>The article showed how to load the CIFAR10 dataset and pre-process it for training.</li> <li>It also explained how to create a simple ResNet50 model and how to train it on the CIFAR10 dataset.</li> <li>The article also explained how to evaluate the model and perform inference using the trained model. :::</li> </ul>"},{"location":"articles/Scalar/Implementing%20DCGAN%20to%20generate%20CIFAR%20images/","title":"Implementing DCGAN to generate CIFAR images","text":"<p>toc: true title: Implementing DCGAN to generate CIFAR images</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Scalar/Implementing%20DCGAN%20to%20generate%20CIFAR%20images/#implementing-dcgan-to-generate-cifarcifar-images","title":"Implementing DCGAN to generate ../../CIFAR|CIFAR images","text":""},{"location":"articles/Scalar/Implementing%20DCGAN%20to%20generate%20CIFAR%20images/#what-are-we-building","title":"What are we building?","text":"<p>Creating novel images is one of the strengths of Generative Adversarial Networks (GANs). In this article, we will build a DCGAN for image generation using the ../../CIFAR|CIFAR dataset. The DCGAN is a type of GAN that builds upon the Vanilla GAN and addresses some of its issues. The DCGAN is a good choice if the image data size is larger than 28x28. This network also leads to fewer chances of a mode collapse and is thus a better network than a standard GAN.  Here, we want the network to create realistic images to resemble any of the ten classes of the ../../CIFAR|CIFAR dataset. We will create the DCGAN from scratch using PyTorch, train it and write scripts to generate our images. </p>"},{"location":"articles/Scalar/Implementing%20DCGAN%20to%20generate%20CIFAR%20images/#what-are-dgans","title":"What are DGANs","text":"<p>Researchers created the Vanilla GAN architecture to generate images in an unsupervised manner from image datasets. But this GAN had quite a few flaws that impacted its training. DCGANs are a modification of the Vanilla GAN architecture. The implementation of the Discriminator and Generator is configured to tackle some of the issues of the original GAN. Some of the changes are as follows.  Convolutional layers are used explicitly in the Discriminator. In this architecture, the Generator explicitly uses Transposed Convolution layers. The Discriminator relies on Batch Normalization along with LeakyReLU activations. The Generator, on the other hand, uses ReLU activations.  The DCGAN image generation process is almost similar to the Vanilla GAN except for a few tweaks to the optimizer and the architecture itself.</p>"},{"location":"articles/Scalar/Implementing%20DCGAN%20to%20generate%20CIFAR%20images/#how-are-we-going-to-build-this","title":"How are we going to build this?","text":"<p>To build the DCGAN, we will use the Python library PyTorch. We will first import PyTorch and other required libraries. We then load the image dataset using a DataLoader, which is the CIFAR10 dataset in this case. After we load the data, we create the functions that make up the DCGAN. We can then train the network on this dataset and generate new photorealistic images that look like they were part of the CIFAR10 dataset.  The below sections focus on implementing all the functions required to create a DCGAN image generation pipeline.</p>"},{"location":"articles/Scalar/Implementing%20DCGAN%20to%20generate%20CIFAR%20images/#final-output","title":"Final Output","text":"<p>The final output we want is photorealistic images that look like they might belong to the CIFAR10 dataset. The result that we get is shown below. </p> <p>[IMAGE {1} Final Output START SAMPLE]  [IMAGE {1} FINISH SAMPLE]</p> <p>Note that longer training might yield better results but take significantly longer.</p>"},{"location":"articles/Scalar/Implementing%20DCGAN%20to%20generate%20CIFAR%20images/#requirements","title":"Requirements","text":"<p>Before starting the DCGAN image generation process, we must import some libraries and perform set-up operations. First, we must create folders to store the models' images and weights using the <code>mkdir</code> command. We import the PyTorch library and all the required features we need that comes with it. We also import the numerical processing library numpy and the plotting library matplotlib.  Training a GAN takes quite a long time. To further improve performance, we enable a flag in Pytorch that enables benchmarking. Pytorch runs a few checks on your current device during the benchmarking process to determine which algorithms perform the best. These checks let you run slightly more optimized code for your current device. </p> <pre><code>!mkdir images\n!mkdir weights\nfrom __future__ import print_function\nimport os\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data\nimport torchvision.datasets as tv_data\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nfrom tqdm import tqdm\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ncudnn.benchmark = True\n</code></pre>"},{"location":"articles/Scalar/Implementing%20DCGAN%20to%20generate%20CIFAR%20images/#implementing-dcgan-to-generate-cifarcifar-images_1","title":"Implementing DCGAN to generate ../../CIFAR|CIFAR images","text":"<p>We can now move on to the main DCGAN image generation process. To generate the images, we need to create a DataLoader, load the ../../CIFAR|CIFAR images,  preprocess them, and send batches of this data to the GPU memory. We also need to create the network architecture and initialize the weights of its components. This network also needs to be sent to the GPU memory.  After these initial steps have been completed, we can finally train the network and generate new images. </p> <p>The DCGAN architecture is similar to many other GAN architectures and consists of a Generator and a Discriminator. The Generator is responsible for creating photo-realistic images from random noise to fool the Discriminator. On the other hand, the Discriminator takes the outputs of the Generator and returns the probability that the generated image is real. The Generator uses this probability to improve its generation capabilities by training the model. The architecture diagram of the DCGAN is shown below. [IMAGE {2} Architecture START SAMPLE]  [IMAGE {2} FINISH SAMPLE]</p> <p>[IMAGE {3} Generator START SAMPLE]  [IMAGE {3} FINISH SAMPLE]</p> <p>In the architecture, ngpu stands for the number of GPUs. In this case, we will only be using a single one. nz stands for the width of the input. ngf and ndf denote the shape of the maps that the Generator and Discriminator create, respectively. nc is the number of channels that the image has.</p> <p>We first start by loading our data and understanding how it looks.</p>"},{"location":"articles/Scalar/Implementing%20DCGAN%20to%20generate%20CIFAR%20images/#exploring-the-dataset","title":"Exploring the dataset","text":"<p>This article uses the CIFAR10 (Canadian Institute for Advanced Research) dataset. This dataset contains ten classes of images similar to the MNIST format but in 3-channel RGB. The CIFAR10 is a very common dataset for benchmarking image classification models and is easy for a model to learn.</p> <p>Before we can explore the dataset, we must load and preprocess it. PyTorch comes with the CIFAR10 dataset inbuilt, and we can directly load it. If this is the first time we have used this dataset, it may not exist locally, and we need to download it first. After that, we need to resize all the images to a common size of 64x64x3. CIFAR10 is a clean dataset, and this resizing step is probably unnecessary, but it is a good practice to uphold. We also normalize the images and convert them to the PyTorch tensors. In PyTorch, we need to create a DataLoader, simply a class that creates optimized batches of data to pass to the model.  We send this DataLoader to the GPU if we are using one to enhance the speed of the DCGAN image generation process.</p> <pre><code>dataset = tv_data.CIFAR10(root=\"./data\", download=True,\n                           transform=transforms.Compose([\n                               transforms.Resize(64),\n                               transforms.ToTensor(),\n                               transforms. Normalize ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                           ]))\nnum_channels=3\n\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=128,\n                                         shuffle=True, num_workers=2)\ncurrent_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n</code></pre> <p>After loading the data, we can see how it looks. To visualize a batch of data, we iterate over the DataLoader to grab a single batch of images. After obtaining the images, we can create a grid the size of a single batch, pad the images to make them look neater and normalize them. This batch of images is still on the GPU, which means that we cannot plot it on the CPU without sending it back.  </p> <pre><code>single_batch = next(iter(dataloader))\nplt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.toc: true\ntitle(\"Training Images\")\nplt.imshow(np.transpose(vutils.make_grid(single_batch[0].to(current_device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n</code></pre> <p>[IMAGE {4} Training Images START SAMPLE]  [IMAGE {4} FINISH SAMPLE]</p> <p>As we can see, the dataset comprises ten classes of images from which we plot a random sample.</p>"},{"location":"articles/Scalar/Implementing%20DCGAN%20to%20generate%20CIFAR%20images/#defining-the-discriminator","title":"Defining the Discriminator","text":"<p>The Discriminator in the DCGAN is responsible for classifying the images returned by the Generator as real or fake. Architecturally, the Discriminator is almost a mirror of the Generator with minor differences. The Discriminator uses a ../../Strided|Strided Convolution and a LeakyReLU along with Batch Normalization layers. The final layer is a Sigmoid layer that returns the probability we want.  For DCGAN image generation, the Discriminator uses ../../Strided|Strided Convolutions instead of Pooling layers. This choice allows the network to learn custom padding functions that, in turn, improve performance.</p> <pre><code>ngpu = 1\nnz = 100\nngf = 64\nndf = 64\n\ndef weights_normal_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        m.weight.data.normal_(0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        m.bias.data.fill_(0)\n\nclass Disc_model(nn.Module):\n    def __init__(self, ngpu):\n        super(Disc_model, self).__init__()\n        self.ngpu = ngpu\n        self.main = nn.Sequential(\n            nn.Conv2d(num_channels, ndf, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 8),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, input):\n        if input.is_cuda and self.ngpu &gt; 1:\n            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n        else:\n            output = self.main(input)\n\n        return output.view(-1, 1).squeeze(1)\n</code></pre>"},{"location":"articles/Scalar/Implementing%20DCGAN%20to%20generate%20CIFAR%20images/#defining-the-generator","title":"Defining the Generator","text":"<p>The Generator is responsible for mapping the input data from the latent space to the vector data space. In this part of the network, we get an RGB image as an output that can then be passed to the Discriminator. The generated image size is the same as the original training images but in channel first indexing (3x64x64). The Generator comprises blocks with Transposed Convolutions, Batch Normalizations and ReLU layers. The final layer has a Tanh activation used to make the data to a range of [-1,1]. In this part of the DCGAN image generation process, the DCGAN uses Batch Normalization layers after Transposed convolutions. This shift enables a smoother gradient flow between the layers of the network. </p> <pre><code>class Gen_model(nn.Module):\n    def __init__(self, ngpu):\n        super(Gen_model, self).__init__()\n        self.ngpu = ngpu\n        self.main = nn.Sequential(\n            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 8),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf, num_channels, 4, 2, 1, bias=False),\n            nn.Tanh()\n        )\n\n    def forward(self, input):\n        if input.is_cuda and self.ngpu &gt; 1:\n            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n        else:\n            output = self.main(input)\n            return output\n</code></pre>"},{"location":"articles/Scalar/Implementing%20DCGAN%20to%20generate%20CIFAR%20images/#defining-the-inputs","title":"Defining the inputs","text":"<p>We need to set up some empty containers for an optimized workflow. We first create a fixed noise with the shape (128, size of latent space, 1, 1) and send it to the GPU. We also denote the label of the real image as one and the fake image as 0. For this article, we will run the network for 25 epochs.  We also pre-allocate arrays to store the Generator and Discriminator loss during training. </p> <pre><code>fixed_noise = torch.randn(128, nz, 1, 1).to(current_device)\nreal_label = 1\nfake_label = 0\n\nniter = 25\ng_loss = []\nd_loss = []\n</code></pre>"},{"location":"articles/Scalar/Implementing%20DCGAN%20to%20generate%20CIFAR%20images/#computing-the-loss-function","title":"Computing the loss function","text":"<p>The DCGAN image generation pipeline has two loss functions, for the Generator and Discriminator, respectively.  The Discriminator penalizes wrongly classifying a real image as a fake or a fake image as real. This concept can be thought of as maximizing the following function. \\(\\(\\nabla_{\\theta_{d}} \\frac{1}{m} \\Sigma_{i=1}^{m}[log D(x^{(i)}) + log(1-D(G(z^{(i)})))]\\)\\)</p> <p>The Generator loss takes the output of the Discriminator into account and rewards it if the Generator is fooled into thinking the fake image is real. If this condition is not satisfied, the Generator is penalized. This concept can be thought of as minimizing the following function. \\(\\(\\nabla_{\\theta_{g}} \\frac{1}{m} \\Sigma_{i=1}^{m}log(1-D(G(z^{(i)})))\\)\\)</p> <pre><code>model_Gen = Gen_model(ngpu).to(current_device)\nmodel_Gen.apply(weights_normal_init)\nmodel_Disc = Disc_model(ngpu).to(current_device)\nmodel_Disc.apply(weights_normal_init)\nloss_func = nn.BCELoss()\n</code></pre>"},{"location":"articles/Scalar/Implementing%20DCGAN%20to%20generate%20CIFAR%20images/#optimizing-the-loss","title":"Optimizing the loss","text":"<p>We will use the ADAM optimizer with a learning rate of 0.0002 and the beta parameters set to (0.5m, 0.999) to optimize the loss. The Generator and Discriminator have different optimizers to ensure that they both learn independently.</p> <pre><code>optimizerD = optim.Adam(model_Disc.parameters(), lr=0.0002, betas=(0.5, 0.999))\noptimizerG = optim.Adam(model_Gen.parameters(), lr=0.0002, betas=(0.5, 0.999))\n</code></pre>"},{"location":"articles/Scalar/Implementing%20DCGAN%20to%20generate%20CIFAR%20images/#train-the-dcgan","title":"Train the DCGAN","text":"<p>To run DCGAN image generation, we need to train the network first. The general procedure is as follows. For each epoch, the noise is sent to the Generator. The Discriminator also gets a random image sampled from the dataset. The Generator then uses the weights it has learned to modify the noise to be closer to the target image. In doing so, the Generator learns a mapping between random noise and the latent space of the image dataset. The Generator then sends the tweaked image to the Discriminator. The Discriminator then predicts how real it thinks the generated image is and informs the Generator using a probability metric. </p> <pre><code>for epoch in tqdm(range(niter), total = niter):\n    for i, data in enumerate(dataloader, 0):\n        model_Disc.zero_grad()\n        device_model = data[0].to(current_device)\n        batch_size = device_model.size(0)\n        label = torch.full((batch_size,), real_label).to(current_device)\n\n        output = model_Disc(device_model) # Discriminator output\n        disc_error_real = loss_func(output.float(), label.float()) \n        disc_error_real.backward() # disc loss for real image\n        D_x = output.mean().item()\n\n        noise = torch.randn(batch_size, nz, 1, 1).to(current_device) # create noise\n        fake = model_Gen(noise) # Fake image\n        label.fill_(fake_label) # Fill with 0\n        output = model_Disc(fake.detach())\n        disc_error_fake = loss_func(output.float(), label.float()) # disc loss for fake image\n        disc_error_fake.backward() \n        D_G_z1 = output.mean().item()\n        disc_error = disc_error_real + disc_error_fake\n        optimizerD.step()\n\n        model_Gen.zero_grad()\n        label.fill_(real_label) # fill with 1\n        output = model_Disc(fake.float()) # disc output\n        gen_error = loss_func(output.float(), label.float())\n        gen_error.backward()\n        D_G_z2 = output.mean().item()\n        optimizerG.step()\n\n        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f' % (epoch, niter, i, len(dataloader), disc_error.item(), gen_error.item(), D_x, D_G_z1, D_G_z2))\n\n        if i % 100 == 0: # save images every 100 steps\n            print('saving the output')\n            vutils.save_image(device_model,'./images/real_samples.png',normalize=True)\n            fake = model_Gen(fixed_noise)\n            vutils.save_image(fake.detach(),'./images/fake_samples_epoch_%03d.png' % (epoch),normalize=True)\n\n    torch.save(model_Gen.state_dict(), 'weights/model_Gen_epoch_%d.pth' % (epoch))\n    torch.save(model_Disc.state_dict(), 'weights/model_Disc_epoch_%d.pth' % (epoch))\n</code></pre> <p>In this article, we train the network for 25 epochs. After the training is complete and even during training, we can periodically check the <code>./images</code> folder to see outputs every 100 steps.  The results we get are as follows.</p> <p>To understand the training progression, we look at the original sample and then the outputs at 0, ten, and 25 epochs.</p> <p>[IMAGE {5} Original Sample/Target START SAMPLE]  [IMAGE {5} FINISH SAMPLE]</p> <p>[IMAGE {6} Epoch 0 START SAMPLE]  [IMAGE {6} FINISH SAMPLE]</p> <p>[IMAGE {7} Epoch 10 START SAMPLE]  [IMAGE {7} FINISH SAMPLE]</p> <p>[IMAGE {8} Final Results START SAMPLE]  [IMAGE {8} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Implementing%20DCGAN%20to%20generate%20CIFAR%20images/#whats-next","title":"What's next","text":"<p>We can apply a few tweaks to the DCGAN in further experiments. Some of them are mentioned below. - Tweaking the z_size variable and either increasing or decreasing it might lead to better performance. - Longer training might also lead to better results. - Using Label Smoothing Cross Entropy Loss instead of just a Cross Entropy Loss might also improve performance. - There is a long list of tweaks proposed by one of the creators of the PyTorch library regarding the DCGAN. The article mentioned is quite a few years old but gives a good background for further experiments on the DCGAN image generation process.</p>"},{"location":"articles/Scalar/Implementing%20DCGAN%20to%20generate%20CIFAR%20images/#conclusion","title":"Conclusion","text":"<ul> <li>A DCGAN was built using PyTorch to generate images from the CIFAR10 dataset.</li> <li>The DCGAN is a modified version of a Vanilla GAN that addresses some issues and leads to fewer chances of mode collapse.</li> <li>Suggestions for further experimentation with the DCGAN include adjusting the z_size variable, increasing training time, and using Label Smoothing Cross Entropy Loss.</li> </ul>"},{"location":"articles/Scalar/Improving%20Model%20Accuracy%20in%20Image%20Classification/","title":"Improving Model Accuracy in Image Classification","text":"<p>toc: true title: Improving Model Accuracy in Image Classification</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Scalar/Improving%20Model%20Accuracy%20in%20Image%20Classification/#improving-model-accuracy-in-image-classification","title":"Improving Model Accuracy in Image Classification","text":"<p>:::section{.abstract}</p>"},{"location":"articles/Scalar/Improving%20Model%20Accuracy%20in%20Image%20Classification/#overview","title":"Overview","text":"<p>Improving image classification accuracy is one of the biggest hurdles in deep learning. Apart from using a deeper network and better data, many techniques have been developed to optimize network performance. Some techniques, such as [../../Dropout|Dropout], target training bottlenecks in the architecture itself, while others, like ../../Regularization|Regularization, are more focused on improving the overall pipeline.  ::: :::section{.scope}</p>"},{"location":"articles/Scalar/Improving%20Model%20Accuracy%20in%20Image%20Classification/#scope","title":"Scope","text":"<ul> <li>This article explains the concepts of Overfitting and Underfitting.</li> <li>Dropout and other ../../Regularization|Regularization techniques like Data Augmentation are explained.</li> <li>The article also explains Early Stopping and other pipeline tweaks such as Hyperparameter Tuning and Transfer Learning.</li> </ul> <p>::: :::section{.main}</p>"},{"location":"articles/Scalar/Improving%20Model%20Accuracy%20in%20Image%20Classification/#introduction","title":"Introduction","text":"<p>It is often impossible to always have better data or larger models. In such cases, using techniques like [../../Regularization|Regularization] and Transfer Learning not only optimize training time but also care for the lack of data. Algorithms such as ../../Dropout|Dropout and Early Stopping tackle the challenges of Overfitting.  This article provides an introduction to many such algorithms and pipeline tweaks that help in the process of improving model accuracy in image classification.</p>"},{"location":"articles/Scalar/Improving%20Model%20Accuracy%20in%20Image%20Classification/#improving-model-accuracy","title":"Improving Model Accuracy","text":"<p>The two biggest hurdles in training neural networks are Overfitting and Underfitting. In the first case, the network memories the data, and in the second, the network does not learn enough. The following techniques can be divided into categories based on these two concepts. [../../Dropout|Dropout] layers, Data augmentation, ../../Regularization|Regularization, Early Stopping, tackle Overfitting.  Transfer Learning and Hyperparameter Tuning tackle Underfitting. If there is a lack of data, we can use Transfer learning and Data Augmentation. The other algorithms can be experimented with if the model does not perform well. The below sections explain all of these algorithms.</p>"},{"location":"articles/Scalar/Improving%20Model%20Accuracy%20in%20Image%20Classification/#overfitting-and-underfitting","title":"Overfitting and Underfitting","text":"<p>Training a neural network is a balancing act that requires understanding many metrics.  Training accuracy is defined as the model's accuracy during training time on the train/test split of the data.  Validation accuracy is defined as the model's performance when tested on real-world data that the model has never seen. If, in improving image classification accuracy, the training accuracy is far higher than the validation accuracy for many epochs, this is called Overfitting. In Overfitting, the model focuses too heavily on the training data and essentially fails to predict any sample it has yet to see before. </p> <p>If the training accuracy is very low and the validation accuracy seems to fluctuate or is much higher than the training accuracy, this is called Underfitting. In Underfitting, the model must be more powerful to fit the data.  Both Overfitting and Underfitting can be countered in many ways, but it is to be noted that they have a delicate balance. Learning to understand which of these the network is going through is essential in being able to improve image classification accuracy.</p> <p>[IMAGE {1} Overfitting_Underfitting START SAMPLE]  [IMAGE {1} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Improving%20Model%20Accuracy%20in%20Image%20Classification/#dropoutdropout-layers","title":"../../Dropout|Dropout layers","text":"<p>When the single unit in a network computes gradients wrt the error, it also considers the other units and tries to fix their mistakes. This dependency is known as Co Adaptation and leads to the formation of complex relations that encourages Overfitting. ../../Dropout|Dropout layers reduce co-dependence between the neurons in a network by randomly (with a probability p) setting neuron activations to 0. This layer is applied to Dense (Fully connected) layers in a network. [../../Dropout|Dropout] helps with smaller datasets and slightly with larger ones. If the dataset is bigger, ../../Dropout|Dropout can help performance as more information is recovered. Similarly, if the dataset is too large, the model performance might also worsen. During testing, the weights are scaled by the probability p.</p> <p>[IMAGE {2} Dropout START SAMPLE]  [IMAGE {2} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Improving%20Model%20Accuracy%20in%20Image%20Classification/#data-augmentation","title":"Data Augmentation","text":"<p>Neural networks are extremely data-hungry, and training them requires many training examples. It is, of course, only sometimes possible to have a large amount of training data. We can use a method called Data Augmentation to artificially expand the number of available examples. In essence, Data Augmentation is the process of tweaking the given examples multiple times in different ways to generate new training samples from the existing images. Some examples of Data Augmentation for image data include Random Flipping, Jittering Brightness/Contrast, Random Resizing, and Random ../../Cropping|Cropping. Some Data Augmentations are shown below.</p> <p>[IMAGE {3} Augmentation START SAMPLE]  [IMAGE {3} FINISH SAMPLE]</p> <p>Data augmentation is a good method for improving image classification accuracy. This technique is not restricted to images; we can apply similar concepts to every other data domain. Data Augmentation also has the added benefit of being a regularizer by showing the model data from different perspectives.</p>"},{"location":"articles/Scalar/Improving%20Model%20Accuracy%20in%20Image%20Classification/#regularizationregularization","title":"../../Regularization|Regularization","text":"<p>One of the biggest challenges neural networks face during training is Overfitting. Penalizing complex models that have better performance during training but not during validation is one way of reducing the effects of Overfitting. The objective of training neural networks is for them to be used on real data outside the training set. Penalizing models that learn too much of the training set is called [../../Regularization|Regularization]. A ../../Regularization|regularization term is used to control the penalty applied to the model. This term is also a hyperparameter, as increasing it too much may hurt model performance.  Many algorithms perform [../../Regularization|Regularization] during training, such as Data Augmentation, Early Stopping, ../../Dropout|Dropout, etc.</p>"},{"location":"articles/Scalar/Improving%20Model%20Accuracy%20in%20Image%20Classification/#early-stopping","title":"Early Stopping","text":"<p>Early Stopping is a ../../Regularization|regularization technique that improves image classification accuracy by intentionally stopping the training when validation loss increases. Training is stopped as training a model for too many epochs sometimes causes Overfitting. In Early Stopping, the number of epochs becomes a tunable hyperparameter. We continuously store the best parameters during training, and when these parameters no longer change for several epochs, we stop training.  The idea of Early Stopping can be seen in this diagram. [IMAGE {4} Early Stopping START SAMPLE]  [IMAGE {4} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Improving%20Model%20Accuracy%20in%20Image%20Classification/#transfer-learning","title":"Transfer Learning","text":"<p>Training large-scale image models are time and energy-consuming. Since most vision datasets have some common features, it is possible to take a network trained on a similar dataset and use the trained features to reduce training time on a different dataset.  Transfer learning is a procedure that lets a pre-trained model be used either as a feature extractor or as a weight initializer. In most cases, Transfer learning is used for fine-tuning. We can transfer knowledge from a network trained on a complex task to a simpler one or from a network trained on large amounts of data to one with fewer data.  Transfer learning is thus a potential key to multi-task learning, an active field of research in deep learning. This technique is also key in quickly improving image classification accuracy with fewer data. The following diagram shows the concept behind using Transfer learning to improve image classification accuracy.</p>"},{"location":"articles/Scalar/Improving%20Model%20Accuracy%20in%20Image%20Classification/#hyperparameter-tuning","title":"Hyperparameter tuning","text":"<p>Every DL model and training pipeline has parameters we can tune to optimize performance. Parameters can include - how many epochs to train the network, weight decay, optimizers, learning rate, and a lot more. Each hyperparameter can have multiple values, and these quickly add up to hundreds or more different cases to try.  Hyperparameter tuning is the art of tweaking these parameters to create an optimal model in the shortest amount of time. We can test only some parameters, but a tuning service can estimate which hyperparameter to keep and which to discard. Many algorithms enable such a service, one of them being a grid search over the hyperparameter space. If the hyperparameter in question reduces model performance, it is dropped, and sometimes similar hyperparameters are also dropped.  Hyperparameter tuning is a challenging problem as every task requires different requirements. Tuning hundreds of parameters is a balancing act between the choices.  This technique is one of the final bits of the pipeline that leads to improving image classification accuracy. </p> <p>::: :::section{.summary}</p>"},{"location":"articles/Scalar/Improving%20Model%20Accuracy%20in%20Image%20Classification/#conclusion","title":"Conclusion","text":"<ul> <li>In this article, we learned the importance of other algorithms in improving image classification accuracy.</li> <li>We looked at the concepts of Overfitting and Underfitting and understood how they affect model training.</li> <li>We also looked at many algorithms that improve performance by modifying the architecture or changing how we train the network.</li> <li>We understood what techniques to use when we lack data.</li> <li>We also tackled improving the existing model's performance by tuning its hyperparameters. :::</li> </ul>"},{"location":"articles/Scalar/Intro%20to%20Conditional%20GANS/","title":"Intro to Conditional GANS","text":"<p>toc: true title: Intro to Conditional GANS</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Scalar/Intro%20to%20Conditional%20GANS/#introduction-to-conditional-gans","title":"Introduction to Conditional GANs","text":"<p>:::section{.abstract}</p>"},{"location":"articles/Scalar/Intro%20to%20Conditional%20GANS/#overview","title":"Overview","text":"<p>Generating novel images from an image dataset has been a dream in Computer Vision. Being able to influence the generation of these images was made possible by a family of GANs named Conditional GANs. The following article explores these CGANs and shows how the DCGAN was modified to have the ability to control latent space traversal to a certain extent. We also look at the training paradigm and cover some challenges we might encounter while training a CGAN on our data. ::: :::section{.scope}</p>"},{"location":"articles/Scalar/Intro%20to%20Conditional%20GANS/#scope","title":"Scope","text":"<ul> <li>This article provides an overview of Conditional GANs (CGANs) and their ability to influence the generation of images.</li> <li>It talks about the differences between CGANs and normal GANs.</li> <li>It provides an explanation of the architecture of a CGAN and the added components for controlling feature generation.</li> <li>It discusses the loss functions and the training paradigm used in CGANs.</li> <li>It provides an overview of challenges that may arise when training a CGAN on specific data and how to potentially overcome them. ::: :::section{.main}</li> </ul>"},{"location":"articles/Scalar/Intro%20to%20Conditional%20GANS/#pre-requisites","title":"Pre-requisites","text":"<p>Before understanding CGANs, we need to understand some concepts.</p>"},{"location":"articles/Scalar/Intro%20to%20Conditional%20GANS/#z-space","title":"Z Space","text":"<p>Consider the task of generating new faces from a large dataset of faces. To create a new face, we can take an average of all the faces. Now, to create a new face, we need to tweak the average face a little. We could make the nose a little longer, the mouth smaller and so on. Our average face would also have the same features as human faces but be in between all the faces.  These transformations can be thought of as a kind of interpolation. In essence, we consider the faces as vectors and instead of moving from one to the other, we move to an intermediate point in between. We get new faces depending on which \"direction\" we choose to interpolate between these face vectors.  This transformation enables CGANs to have more control over what they generate.</p>"},{"location":"articles/Scalar/Intro%20to%20Conditional%20GANS/#introduction","title":"Introduction","text":"<p>CGANs are a variant of GANs that allow for greater control over the features of the generated images. They build upon the DCGAN architecture, which is a popular architecture for GANs, and have a similar architecture with some small differences. The main difference between a CGAN and a DCGAN is the ability of a CGAN to control which features are modified in the generated images. This is achieved by conditioning the generator with additional information, such as labels, during the training process.</p> <p>This added complexity allows the CGAN to generate images with specific features, such as generating a specific type of fruit with certain characteristics. By providing the generator with more information, it can create a more diverse set of images while still preserving the features that we want. Additionally, the CGAN has a better ability to generalize to unseen data, which is an essential aspect when it comes to image generation tasks. Overall, the CGAN architecture is an important step forward in the field of GANs, as it allows for more control over the generation process and improves the quality of the generated images.</p> <p>This article takes an in-depth look at CGANs. </p>"},{"location":"articles/Scalar/Intro%20to%20Conditional%20GANS/#what-is-a-conditional-gan","title":"What is a conditional GAN?","text":"<p>A Conditional GAN (CGAN) is a modification of the DCGAN architecture that allows for more control over the features of the generated images. Unlike the DCGAN, a CGAN can selectively modify certain features of the generated image by conditioning the generator with additional information, such as labels, during training. This input allows the generator to generate images consistent with the conditioning information and specific characteristics that the labels represent. The differences between a CGAN and a DCGAN come from changes to the training methodology. In a CGAN, the generator is guided by the labels during training to traverse the latent space, the lower-dimensional space of random noise input that the generator uses to create images. These labels give the CGAN more control over what it generates by allowing it to traverse the latent space more precisely and be guided by the labels.</p> <p>An example would include choosing specific features of the face to modify.</p> <p>[IMAGE {0} { CGAN Example } START SAMPLE]  [IMAGE {0} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Intro%20to%20Conditional%20GANS/#how-is-it-different-from-gan","title":"How is it different from GAN","text":"<p>There are a few significant differences between a GAN and a CGAN. This article compares the CGAN to the DCGAN, as the latter is the base for many advanced GANs. These differences are summarized in the following table.</p> GAN CGAN Output features are not controllable Output features can be controlled Unsupervised Semi-Supervised Discriminator does not receive labels Discriminator requires labels Discriminator evaluates similarity between input and target images Discriminator considers input and target images and their respective labels"},{"location":"articles/Scalar/Intro%20to%20Conditional%20GANS/#architecture","title":"Architecture","text":"<p>The overall architecture of a CGAN is similar to that of a DCGAN but with minor modifications. The Discriminator architecture in a CGAN is similar to that of a DCGAN, consisting of several convolutional layers, batch normalization layers, and Leaky ReLU activation functions. However, in a CGAN, the Discriminator receives an additional input, the conditioning information, such as labels, and the generated image. This extra input allows the Discriminator to consider both the image's realism and the consistency of the conditioning information when evaluating the generated image. The Generator architecture in a CGAN is similar to that of a DCGAN, consisting of several transpose convolutional layers, batch normalization layers, and ReLU activation functions. However, in a CGAN, the Generator receives an additional input, the conditioning information, and the random noise used as the latent code. This input allows the Generator to generate images consistent with the conditioning information.</p> <p>[IMAGE {1} { CGAN Architecture } START SAMPLE]  [IMAGE {1} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Intro%20to%20Conditional%20GANS/#the-discriminators-network","title":"The Discriminator's network","text":"<p>The Discriminator in a CGAN has a similar architecture as the DCGAN, consisting of several convolutional layers, batch normalization layers, and Leaky ReLU activation functions. However, an additional hot-encoding layer is added to consider the current image's labels. This layer is used to represent the conditioning information, such as the labels, in a format that the network can process. This addition allows the Discriminator to consider both the image's realism and the consistency of the conditioning information when evaluating the generated image. Thus it can guide the generator to create images with specific characteristics.</p> <p>[IMAGE {2} { Discriminator Architecture } START SAMPLE]  [IMAGE {2} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Intro%20to%20Conditional%20GANS/#the-generators-network","title":"The Generator's network","text":"<p>The Generator in a CGAN also has a similar architecture as the DCGAN, consisting of several transposed convolutional layers, batch normalization layers, and ReLU activation functions. However, it also has an additional layer added to take into consideration the labels. This added layer helps the generator create images with certain characteristics and make them more consistent with the conditioning information.</p>"},{"location":"articles/Scalar/Intro%20to%20Conditional%20GANS/#loss-functions","title":"Loss functions","text":"<p>To train the network, we use two loss functions for the Generator and the Discriminator of the CGAN, respectively.</p>"},{"location":"articles/Scalar/Intro%20to%20Conditional%20GANS/#generator-loss","title":"Generator Loss","text":"<p>Since the Generator's objective is to create better fake images gradually, it needs to minimize the difference between the predicted image and the target. The model uses ../../One hot|one hot encoded label in this architecture to decide which features to care for. The loss function thus is the following.</p> \\[\\mathcal{L}^{(G)}(\\theta^{(G)}, \\theta^{(D)}) = - \\mathbb{E}_{z} log \\mathcal{D} (\\mathcal{G} (z|y\u2019))\\] <p>The equation can be thought of as: given a label, use the Generator to traverse the latent space and create an image. Then pass the created image through the Discriminator and find how well we performed. </p>"},{"location":"articles/Scalar/Intro%20to%20Conditional%20GANS/#discriminator-loss","title":"Discriminator Loss","text":"<p>Since the objective of the Discriminator is to label the generated images, its outputs are the probability that the image is true. The loss function is, therefore, the following. (This is a Binary Cross Entropy Loss function)</p> \\[ \\mathcal{L}^{(D)}(\\theta^{(G)}, \\theta^{(D)})= - \\mathbb{E}_{x \\sim p_{data}}log \\mathcal{D}(x|y) - \\mathbb{E}_{z} log (1- \\mathcal{D}(\\mathcal{G}(z|y')))\\]"},{"location":"articles/Scalar/Intro%20to%20Conditional%20GANS/#training","title":"Training","text":"<p>Training a CGAN is similar to training any other GAN. The Discriminator and the Generator work parallel to create novel images and identify how real they look. The Generator first starts with random noise and passes it to the Discriminator. The Discriminator, in this case, is also provided with labels and returns a probability of how real it thinks the generated image is. This probability is passed to the Generator, which updates its weights to generate better images slowly. This cycle continues until the required quality of images is generated.</p>"},{"location":"articles/Scalar/Intro%20to%20Conditional%20GANS/#training-flow","title":"Training Flow","text":"<p>Training a CGAN is similar to training any other GAN, the main difference being the use of conditioning information to guide the network in generating specific features. We can break down the process into several steps:</p> <ul> <li>The Generator starts with a random noise, often called a latent code, as its input. This noise is passed through the generator network, which maps it to an image in the data space.</li> <li>The generated image and its corresponding conditioning information, such as labels, are passed to the Discriminator. The Discriminator evaluates the image based on its similarity to the real images and the consistency of the conditioning information. It returns a probability of how realistic the generated image is.</li> <li>The probability is passed back to the Generator, which uses it to update its weights to generate better images. - The weights are updated to minimize the difference between the generated and real images.</li> <li>This process is repeated for several iterations until the Generator can produce images that are of the desired quality. During this process, the Discriminator and Generator improve each other, with the Discriminator getting better at identifying realistic images and the Generator getting better at producing realistic images.</li> </ul> <p>One important thing to note is that, during the training process, we must provide the Discriminator with real images and the conditioning information. The additional information allows the Discriminator to make informed decisions about the realism of the generated images and to detect if the conditioning information is consistent with the generated image.</p>"},{"location":"articles/Scalar/Intro%20to%20Conditional%20GANS/#challenges-with-conditional-generation","title":"Challenges with Conditional generation","text":"<p>No model is perfect. CGANs have multiple issues as well. Some of these have been tackled by later research, while others are still active research areas. </p> <p>[IMAGE {3} { Discriminator Training Flow } START SAMPLE]  [IMAGE {3} FINISH SAMPLE]</p> <p>[IMAGE {4} { Generator Training Flow } START SAMPLE]  [IMAGE {4} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Intro%20to%20Conditional%20GANS/#feature-correlation","title":"Feature Correlation","text":"<p>Another challenge with CGANs is related to the correlation of features in the dataset, which can cause the generated images to be biased toward certain characteristics. For instance, when working with an image dataset of fruits, if the dataset contains images of mostly red apples, the output of the CGAN will also be biased toward generating red apples. Similarly, if the dataset contains mostly pears with spots, the CGAN will generate images of pears with spots.</p> <p>This feature correlation can cause problems when we want to generate an image of a fruit with certain characteristics that do not align with the features of the images in the dataset. For example, if we want to generate an apple with the spots of a pear, the CGAN might modify the entire apple instead of just the spots because these features are tightly linked in the dataset. This problem can make generating images with specific characteristics difficult or even impossible.</p> <p>One solution to this problem is to use larger and more diverse datasets that contain a wide range of images with various features. These datasets will help reduce feature correlation and increase the range of images the CGAN can generate. Pre-processing, such as data augmentation or removing correlation between features, might also help mitigate this issue.</p>"},{"location":"articles/Scalar/Intro%20to%20Conditional%20GANS/#z-space-entanglement","title":"Z-Space Entanglement","text":"<p>The Z-Space is the space of all possible points where a generator could generate an image. In other words, it is the space of all possible random inputs to the generator.</p> <p>When a generator generates an image, it takes a point from the Z-space and maps it to an image in the data space. The idea is that the generator learns a mapping from the latent space to the data space to generate new images by sampling from the latent space. However, this process is not always straightforward, as the latent space may need to be better structured or may not be entirely controllable.</p> <p>One of the challenges of working with the latent space is that it is often high-dimensional, which makes it difficult to visualize and understand. Additionally, the space may not be smoothly connected, resulting in \"entanglement,\" where the generator produces unexpected results when the latent space is traversed. Entanglement occurs when interpolation between examples becomes hard to perform and can lead to difficulties in controlling the generation process, making it difficult to generate specific images.</p>"},{"location":"articles/Scalar/Intro%20to%20Conditional%20GANS/#classifier-gradients","title":"Classifier Gradients","text":"<p>Another challenge with CGANs is related to the ability of the network to identify and modify specific features in the generated images. For the CGAN to make changes in a specific way, it must first be able to understand and interpret what we want it to modify. For example, in the case of generating fruits, if we want to generate an image of a fruit with a longer stem, the network must first be able to understand what a stem is and what it means for it to be longer.</p> <p>This understanding can be difficult for the network because the feature we want to modify may not always be clearly defined, or the network may need more information to understand. In some cases, the network may generate images different from what we want because it may interpret our request differently or need more information to make the desired change. Additionally, the feature we want to change might be harder to identify in the images. Hence the network might need help to learn it.</p> <p>One solution to this problem is to use more explicit and detailed conditioning information, such as annotations or labels, to guide the network in identifying and modifying specific features. For example, in the case of generating fruits, we could provide the network with detailed annotation data on the fruits, including information on the size, shape, and position of the stem. However, this approach requires a large amount of labeled data, which may only sometimes be available or can be time-consuming to acquire.</p> <p>Overall, being able to modify specific features in the generated images is a challenging task for CGANs and requires careful consideration of the available data and the network architecture used.</p> <p>::: :::section{.summary}</p>"},{"location":"articles/Scalar/Intro%20to%20Conditional%20GANS/#conclusion","title":"Conclusion","text":"<ul> <li>In conclusion, this article discussed Conditional GANs (CGANs), a family of GANs that allow for control over the features modified in the generated image.</li> <li>The CGAN builds upon the DCGAN architecture and mainly differs in its training methodology, which allows for traversing the latent space by conditioning the generator with labels during training. </li> <li>The article also compared CGANs to DCGANs, highlighting the key differences between the two, such as the output feature control and the semi-supervised nature of CGANs. </li> <li>The article also provided an overview of CGAN architecture and the challenges one may face while training a CGAN. </li> <li>Overall, the article offers a comprehensive introduction to the concept and application of Conditional GANs, making it a valuable resource for anyone interested in this area of computer vision. :::</li> </ul>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/","title":"Masked Language Modeling in BERT #scalar","text":"<p>toc: true title: Masked Language Modeling in BERT #scalar</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#masked-language-modelingmasked-language-modeling-in-bert-scalar","title":"../../Masked Language Modeling|Masked Language Modeling in BERT #scalar","text":"<p>masked language model explained</p> <p>:::section{.abstract}</p>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#overview","title":"Overview","text":"<p>Language modelling is a massive domain and has many sub-research areas. One such domain involves understanding contextual information about words in a sentence. This task can be done in many ways, and masked language modelling is one such method. In the past few years, Transformer based models have reached SOTA(state of the art) in many NLP domains. BERT is one such model. In this article, we will understand how to train BERT to fill in missing words in a sentence using MLM.</p> <p>::: :::section{.scope}</p>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#scope-of-the-article","title":"Scope of the Article","text":"<p>This article covers the following topics: - ../../Masked Language Modeling|Masked Language Modeling explained in an easy-to-understand manner - Quickly recap all the pre-requisite terms to build an MLM model - Go over some libraries that are essential to MLM - How to build a BERT-based MLM model using our data in Tensorflow/Keras</p> <p>::: :::section{.main}</p>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#masked-language-modelingmasked-language-modeling-explained","title":"../../Masked Language Modeling|Masked Language Modeling Explained","text":"<p>To a NN model, the word context has no meaning. So, we need to find ways to make the model consider surrounding words to learn which context words appear. For example, consider the sentence, \"I am eating an ice cream\". In this, the \"ice cream\" is being \"eaten\". What would an appropriate word be if we now remove the word \"eating\" and have the sentence as \"I am ___ an ice cream\"? We can consider something along the lines of \"licking\", \"eating\", \"sharing\", etc. However, we cannot say \"drowning\", \"cycle\", \"chair\", or other random words.</p> <p>In the same way, to ensure the model learns which word is appropriate, it needs to understand the structure of language. As modellers, we need to help it do so.  Quite simply, all we do is give the model inputs with blanks as a \"token\" <code>&lt;MASK&gt;</code> along with the word that should be there. We can create data in this format by taking any text and running over it. How to do so will be explained later on.</p>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#quick-recap","title":"Quick Recap","text":"<p>This section gives a small recap of all the important concepts we need to understand the code.</p>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#tokens","title":"Tokens","text":"<p>Tokens can be considered parts of a sentence that contribute to understanding. A sentence such as \"I am Jane Austen\" can have the tokens <code>[\"I\", \"am\", \"Jane\", \"Austen\"]</code>. As a computer does not understand words, we need to convert these to numerical values. To do so, we give each word a unique ID. Something like <code>[100, 101, 102, 103]</code> etc.</p>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#attention","title":"Attention","text":"<p>One of the most important concepts in Machine learning today, attention mechanisms give models the power to decide where to look in an input. Compared to CNNs, this makes models such as Transformers perform much better as it simultaneously learns which parts of the input would be better along with what the input could be classified. </p>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#transformers","title":"Transformers","text":"<p>Transformers are a large family of models that employ different variants of attention mechanisms. They first started in NLP but have also branched out to computer vision due to their immense potential. They generally have an Encoder-Decoder architecture with multiple \"heads\". Each head is responsible for its attention.</p>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#bert","title":"BERT","text":"<p>BERT is part of a sub-family of transformer architectures made for NLP and led to a sea of other new models that reached SOTA. It can be used in many different contexts, especially MLM, next-word prediction, question answering and many more.</p>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#transfer-learning","title":"Transfer Learning","text":"<p>A training paradigm that changed the DL world by allowing any researcher with limited resources to use SOTA models for inference and fine-tune them to their needs. A model like BERT requires Terabytes of data before it can be trained to extremely high levels. This level of computing is almost impossible for most people to have apart from companies with massive funding and resources. However, now we can use their trained models and make them work for our tasks.</p>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#stopwords","title":"Stopwords","text":"<p>Words that do not add much value to the model but are repeated enough times for it to become a problem. These are generally removed before modelling.</p>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#mlm-vs-clm-vs-word2vec","title":"MLM vs CLM vs Word2Vec","text":"<p>The major difference between MLM and CLM is that CLM can only take into account words that occur before it in a sentence, unlike MLM, which is bi-directional. This difference means that CLM does better for generating large amounts of text. However, MLM is better for contextually understanding text (refer to the ../../Masked Language Modeling|Masked Language Modeling Explained section). Word2Vec, on the other hand, has similar ideas but the embeddings it generates have weaker contextual information than Transformer based models. The outputs it produces can also be used as a part of BERT training, although it is not usually required.</p>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#libraries-we-need","title":"Libraries We Need","text":"<p>We need a few libraries to make this work.</p>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#tensorflowkeras","title":"Tensorflow/Keras","text":"<p>TF is one of the major DL libraries in Python. We will be using it for training our model.</p>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#hugging-face-transformers","title":"Hugging Face Transformers","text":"<p>This library is one of the recent developments in the open-source community. It is a database of trained models and datasets that can be directly used in any codebase. They have thousands of tasks, making it extremely easy to get results fast. We will use their pre-trained BERT model.</p>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#nltk","title":"NLTK","text":"<p>A text processing library that we will use to clean up our text before passing it to the model.</p>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#seabornmatplotlib","title":"Seaborn/Matplotlib","text":"<p>These libraries are used for plotting our training performance.</p>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#implementation","title":"Implementation","text":"<p>Now for the code.</p>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#imports","title":"Imports","text":"<p>We first import all the required packages. We also download the stopwords and punctuation data from nltk.</p> <p>\"`python import nltk nltk.download('stopwords') nltk.download('punkt') nltk.download('gutenberg') import string from nltk.corpus import stopwords import seaborn as sns</p> <p>from transformers import BertTokenizer, TFBertForMaskedLM import tensorflow as tf import numpy as np import re import matplotlib.pyplot as plt sns.set()</p> <pre><code>\n### Data\nFor this demo, we use text from the book \"Emma\" by \"Jane Austen\". This dataset is a public domain dataset from Project Gutenberg that comes with nltk. We can download it using the following code. \n\"`python\nimport nltk\nnltk.download('gutenberg')\n!cp /root/nltk_data/corpora/gutenberg/austen-emma.txt sample.txt\n</code></pre> <p>We can also use custom text by creating a text file called \"sample.txt\" in the same directory as the code and pasting whatever we want. (Make sure it is English text).</p> <p>We then pre-process the data by removing stopwords and punctuation and converting the words into tokens BERT needs. Since every Transformer model has their configuration of tokens in the pre-trained model, we will use the tokenizer that Hugging face provides us. </p> <p>(Note: Here, we only take the first 1000 lines from the text. Language models take a long time to train; this is just a demo. If we have GPUs, the entire data can be used.) \"`Python tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')</p> <p>sw = stopwords.words('english') # this is a list of stopwords</p>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#take-first-1000-sentences-for-demo-purposes","title":"Take first 1000 sentences for demo purposes","text":"<p>with open('sample.txt', 'r') as f:     lines = f.readlines()[:1000]</p>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#remove-new-lines-convert-all-to-lowercase-remove-punctuation-and-stop-words-and-tokenize","title":"Remove new lines, convert all to lowercase, remove punctuation and stop words and tokenize","text":"<p>lines = [line.rstrip('\\n').lower() for line in lines] lines = [line.translate(str.maketrans('', '', string.punctuation)) for line in lines]</p> <p>def rem_stops_line(line, words):     # Function to remove stopwords per line if they are present in the line     if len(line) &gt;1:         return [w for w in line if w not in words]     else:         return line</p> <p>def remove_stops(text, words = sw):     # Remove stop words for an entire text. Separate functions make it easier to parallelize if required.     return [rem_stops_line(line, words) for line in text]</p> <p>filtered_lines = remove_stops(text = lines, words = sw) inputs = tokenizer(lines,max_length=100,truncation=True,padding='max_length',return_tensors='tf')</p> <pre><code>\n### Masked Language Model Explained Further\nWe use the model from the Transformers library directly. The uncased model converts all text into lowercase. Other models do not, and any of them can be used. This one was chosen for the sake of this demo.\n\"`Python\nmodel = TFBertForMaskedLM.from_pretrained('bert-base-uncased')\n</code></pre> <p>In ../../Masked Language Modeling|Masked Language Modeling, we explained that every sentence needs to be converted to a format with words masked using a special token, <code>&lt;MASK&gt;</code>. We can do that by using the tokenized words and making the model aware of which token number corresponds to this special token. (In this case, it is 103). In the original paper, token numbers 101 and 102 were replaced, but we ignore that here. (It is not relevant for now.)</p> <p>\"`Python</p>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#mask","title":"MASK","text":"<p>inp_ids = [] lbs = [] for idx, inp in enumerate(inputs.input_ids.numpy()):     current_tokens = list(set(range(100)) -                           set(np.where((inp == 101) | (inp == 102)                              | (inp == 0))[0].tolist()))     # Find number of tokens to mask     num_token_masked = 0.15 * len(current_tokens)     token_to_mask = np.random.choice(np.array(actual_tokens),                                       size=int(num_token_masked),                                       replace=False)     # Store special token and inform model     inp[token_to_mask.tolist()] = 103     inp_ids.append(inp)</p>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#convert-the-tokens-to-tensor-format","title":"Convert the tokens to tensor format","text":"<p>inp_ids = tf.convert_to_tensor(inp_ids) inputs['input_ids'] = inp_ids</p> <pre><code>\n### Training the Model\nNow that we have all the required data and the model, we need to train it on our data.\nIf the system does not have a GPU or access to a cloud GPU is unavailable, this model will take a very long time to train. Consider using lesser data.\n\nConsidering we have a GPU, we first check if TF can find it.\n\"`Python\nprint('GPU name: ', tf.config.experimental.list_physical_devices('GPU'))\n</code></pre> <p>We use a Sparse Categorical Crossentropy loss with logits enabled. (logits are enabled if the model does not end with a Softmax. BERT does not.). We use a learning rate of 1e-3 for the Adam Optimizer.  Finally, we run training for around ten epochs. \"`Python</p>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#compile-and-train","title":"Compile and Train","text":"<p>lr = 1e-3 loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),loss=loss) history = model.fit([inputs.input_ids,inputs.attention_mask],inputs.labels,verbose=1,batch_size=16,epochs=10)</p> <pre><code>\n### Loss\nWe plot the loss per epoch to see if our model is learning anything.\nWe can see that the loss has decreased, which is a good sign! Our model is learning. More data and longer training will help the model be better than before.\n\n### Prediction\nJust training a model is useless. We need to be able to use it for prediction. To do that, we need to define a few functions. We need to be able to find the `&lt;MASK&gt;` tokens in the sentence, we need to tokenize the sentence and pass it into the model for prediction. And finally, we need to do this for multiple sentences. \nThe following functions do exactly these. \n\n```python\ndef find_masks(inp):\n    # Find position of the masks in a sentence\n    return np.where(inp.input_ids.numpy()[0] == 103)[0].tolist()\n\ndef single_prediction(model, inp, mask_loc):\n    # Prediction for all the positions of the masks\n    return model(inp).logits[0].numpy()[mask_loc]\n\ndef return_prediction(model, query):\n    # Return a prediction for a single sentence\n    inp = tokenizer(query,return_tensors='tf')\n    mask_loc = find_masks(inp)\n    # Find prediction with the highest confidence\n    predicted_tokens = np.argmax(single_prediction(model, inp, mask_loc),axis=1).tolist()\n    # Decode the numerical value of the returned ID back to the word \n    return tokenizer.decode(predicted_tokens)\n\ndef multiple_preds(model, query_list):\n    # Return predictions for a list of queries\n    preds = [f\"{x} -&gt; {return_prediction(model, x).split(' ')}\" for x in query_list]\n    for i in preds: print(i)\n</code></pre>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#predictions","title":"Predictions","text":"<p>After training, we can finally give the model a practice exam! Since we fine-tuned it on the book \"Emma\", we give it the following sentences. <code>[\"too well [MASK] for her\", \"nice to [MASK] her\", \"Emma [MASK] a girl who wanted a [MASK]\"]</code></p> <p>\"`Python query_list = [\"too well [MASK] for her\", \"nice to [MASK] her\", \"Emma [MASK] a girl who wanted a [MASK]\"] multiple_preds(model, query_list)</p> <pre><code>\nAs an output we get the following. We see that it performs quite well even with such a short training! \n\n\"`plaintext\ntoo well [MASK] for her -&gt; ['suited']\nnice to [MASK] her -&gt; ['see']\nEmma [MASK] a girl who wanted a [MASK] -&gt; ['was', 'chance']\n</code></pre>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#further-tips","title":"Further Tips","text":"<ul> <li>Language models are generally very heavy to use. If possible, using Mixed Precision training helps</li> <li>Having more GPU memory is more useful than having a faster GPU for language models</li> <li>Multiple GPUs are useful for expanding available memory</li> <li>There are smaller variants of BERT that use less memory. </li> <li>Hugging Face has a huge list of models that we can use. Trying them might lead to better results.</li> <li>To get over the overwhelming number of pre-trained models, pick the task and find benchmarks in that task. PaperswithCode is a great place to start.</li> </ul> <p>::: :::section{.summary}</p>"},{"location":"articles/Scalar/Masked%20Language%20Modeling%20in%20BERT%20%23scalar/#conclusion","title":"Conclusion","text":"<p>This article showed us masked language modelling explained. We learnt the following: - What MLM is and when to use it.  - How to pre-process our data for MLM - How to fine-tune pre-trained BERT models for MLM - How to perform predictions over multiple sentences with our fine-tuned models.</p> <p>:::</p>"},{"location":"articles/Scalar/Reconstructing%20the%20MNIST%20images%20using%20an%20autoencoder/","title":"Reconstructing the MNIST images using an autoencoder","text":"<p>toc: true title: Reconstructing the MNIST images using an autoencoder</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Scalar/Reconstructing%20the%20MNIST%20images%20using%20an%20autoencoder/#reconstructing-mnist-images-using-an-autoencoder","title":"Reconstructing MNIST images using an Autoencoder","text":"<p>:::section{.abstract}</p>"},{"location":"articles/Scalar/Reconstructing%20the%20MNIST%20images%20using%20an%20autoencoder/#overview","title":"Overview","text":"<p>Given noisy images, an Autoencoder is a family of models that can convert these noisy images to their original form. These models are unsupervised and use an Encoder-Decoder architecture to re-create the original images given noisy variants of the same. In the process of re-creation, the model also learns to model the latent space of the dataset. :::  :::section{.main}</p>"},{"location":"articles/Scalar/Reconstructing%20the%20MNIST%20images%20using%20an%20autoencoder/#scope","title":"Scope","text":"<ul> <li>This article explores the concepts required to build a simple Autoencoder.</li> <li>It explains how to implement an Autoencoder using Tensorflow.</li> <li>It explains how to use an Autoencoder to re-create MNIST images.</li> <li>The article also explains how to train an Autoencoder model and use the trained model for inference.</li> </ul>"},{"location":"articles/Scalar/Reconstructing%20the%20MNIST%20images%20using%20an%20autoencoder/#what-are-we-building","title":"What are we building?","text":"<p>In this article, we will build an Autoencoder in Tensorflow that can re-create MNIST images. We will create functions to load and pre-process the dataset, along with creating noisy versions of the data points. We will create the Encoder-Decoder structure of the Autoencoder and then use the noisy and real images as inputs to it. After training the model, we will use it to generate new images. The following sections elaborate on these points.</p>"},{"location":"articles/Scalar/Reconstructing%20the%20MNIST%20images%20using%20an%20autoencoder/#pre-requisites","title":"Pre-requisites","text":"<p>Before moving to the implementation, we must understand some prerequisite terms.</p>"},{"location":"articles/Scalar/Reconstructing%20the%20MNIST%20images%20using%20an%20autoencoder/#transposed-convolution","title":"Transposed Convolution","text":"<p>2D Convolutions compress information from images into smaller representations by ../../Downsampling|downsampling them. Transposed Convolutions perform the opposite operation. These convolutions take compressed/small images and attempt to expand their sizes. An illustration of how this happens is as follows.</p> <p>[IMAGE {1} Transposed Conv START SAMPLE]  [IMAGE {1} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Reconstructing%20the%20MNIST%20images%20using%20an%20autoencoder/#what-are-autoencoders","title":"What are Autoencoders","text":"<p>Autoencoders are models that we created to reduce noise in images. In attempting to learn how to reduce noise, they model the latent space of the dataset. Any architecture that understands the latent space can then re-create the original forms of the images from the noisy variants. In the process, the model can not only act as an unsupervised classifier but also be used to generate new images. AutoEncoders have an Encoder-Decoder structure where the Encoder compresses the image while the Decoder re-creates the original image from the compressed representation. </p>"},{"location":"articles/Scalar/Reconstructing%20the%20MNIST%20images%20using%20an%20autoencoder/#how-are-we-going-to-build-this","title":"How are we going to build this?","text":"<p>To build an autoencoder that can recreate MNIST images, we will be using the Tensorflow library. We will create functions to load the MNIST dataset and pre-process it. We will also need to create a random noise generator and a function to plot a batch of images. Once we have these functions, we can create the Autoencoder. The network structure follows an Encoder-Decoder pattern, and we will explore how to create that using Tensorflow. We will then train the Autoencoder on the MNIST data and use the trained model to re-create examples from the dataset.  The sections below elaborate on these steps.</p>"},{"location":"articles/Scalar/Reconstructing%20the%20MNIST%20images%20using%20an%20autoencoder/#final-output","title":"Final Output","text":"<p>The final output of the model should be a near-perfect representation of the MNIST dataset. After training the model for a few epochs. The first row of images is the training data, while the second row contains the images generated by the Autoencoder. These rows are almost the same, which shows that our model has done a good job. [IMAGE {2} Final Output START SAMPLE]  [IMAGE {2} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Reconstructing%20the%20MNIST%20images%20using%20an%20autoencoder/#requirements","title":"Requirements","text":"<p>We must import some libraries and write a few functions to create a model that can read and re-create mnist images.  Since we will be using the Tensorflow library, we import it and its other useful components. We import the numerical processing library numpy and also a plotting library matplotlib.</p> <pre><code>from tensorflow.keras.datasets import mnist\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import layers\nimport numpy as np\nfrom tensorflow.keras.models import Model\nimport tensorflow as tf\n</code></pre> <p>We also need to write some helper functions. The first function takes an array as an input and reshapes it to the size that the model requires.</p> <pre><code>def data_proc(dat):\n    larr = len(dat)\n    return np.reshape(dat.astype(\"float32\") /255.0 , (larr, 28,28,1))\n</code></pre> <p>The second helper function is used to take an array, add Gaussian noise, and ensure that the values lie in the range (0,1).</p> <pre><code>def gen_noise(array):\n    noisy_array = array + 0.4 * np.random.normal(\n        loc=0.0, scale=1.0, size=array.shape\n    )\n    return np.clip(noisy_array, 0.0, 1.0)\n</code></pre> <p>To understand if our model is performing well, we will need to display batches of images. The third function takes two arrays - the input array and the predicted images array and plots them in two rows.</p> <pre><code>def display(array1, array2):\n    n = 10\n    indices = np.random.randint(len(array1), size=n)\n    images1 = array1[indices, :]\n    images2 = array2[indices, :]\n    plt.figure(figsize=(20, 4))\n    for i, (image1, image2) in enumerate(zip(images1, images2)):\n        ax = plt.subplot(2, n, i + 1)\n        plt.imshow(image1.reshape(28, 28))\n        plt.gray()\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n        ax = plt.subplot(2, n, i + 1 + n)\n        plt.imshow(image2.reshape(28, 28))\n        plt.gray()\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n    plt.show()\n</code></pre>"},{"location":"articles/Scalar/Reconstructing%20the%20MNIST%20images%20using%20an%20autoencoder/#building-the-autoencoder","title":"Building the AutoEncoder","text":"<p>The following sections explain how to create a simple Autoencoder in Tensorflow and use MNIST images to train it. We will first see how to load the MNIST data and preprocess it for our needs. After converting the data to the right format, we will build and train the model. The architecture of the network is split into three major parts - the Encoder, the Bottleneck, and the Decoder. The Encoder is used to compress the input images while also preserving useful information. The Bottleneck chooses which features are relevant to flow through to the Decoder, and the Decoder re-creates the images using the outputs of the Bottleneck. The Autoencoder attempts to learn the latent space of the data in the process of this reconstruction.</p> <p>The architecture diagram of an autoencoder is shown below. [IMAGE {3} arch START SAMPLE]  [IMAGE {3} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Reconstructing%20the%20MNIST%20images%20using%20an%20autoencoder/#preparing-the-dataset","title":"Preparing the dataset","text":"<p>The MNIST dataset is already included with Tensorflow as a split dataset so we can load it directly. We use the default splits into train and test datasets and then pass them to the pre-processing function we defined earlier. The second half of the inputs to the model are noisy versions of the original MNIST images. We use the gen_noise function we defined before to create these noise images. Note that the larger the noise, the more distorted the image gets, and the harder the model must work to re-create them. We will also visualize the noise data alongside the original. [IMAGE {4} Data Visualized START SAMPLE]  [IMAGE {4} FINISH SAMPLE]</p> <pre><code>(ds_train, _), (ds_test, _) = mnist.load_data()\nds_train,ds_test = data_proc(ds_train), data_proc(ds_test)\n\nnoisy_ds_train, noisy_ds_test = gen_noise(ds_train), gen_noise(ds_test)\n\ndisplay(ds_train, noisy_ds_train)\n</code></pre>"},{"location":"articles/Scalar/Reconstructing%20the%20MNIST%20images%20using%20an%20autoencoder/#defining-the-encoder","title":"Defining the Encoder","text":"<p>The Encoder of the network uses blocks of Convolutions and Max Pooling layers with ReLU activations. The objective is to compress the input data before passing it through the network. The output of this part of the network should be a compressed version of the original data. Since the MNIST images are of shape 28x28x1, we create an input with that shape.</p> <pre><code>input = layers.Input(shape=(28, 28, 1))\n\n# Encoder\nx = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input)\nx = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\nx = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n</code></pre>"},{"location":"articles/Scalar/Reconstructing%20the%20MNIST%20images%20using%20an%20autoencoder/#defining-the-bottleneck","title":"Defining the Bottleneck","text":"<p>Unlike the other two components, the Bottleneck does not need to be explicitly programmed. Because the output of the Encoder's final MaxPooling layer is very small, the Decoder must learn to recreate the images using this compressed representation.  In more complex implementations of Autoencoders, modifying the Bottleneck is also an option.</p>"},{"location":"articles/Scalar/Reconstructing%20the%20MNIST%20images%20using%20an%20autoencoder/#defining-the-decoder","title":"Defining the Decoder","text":"<p>The Decoder comprises Transposed Convolutions with a stride of 2. The final layer of the model is a simple 2D convolution with the sigmoid activation function.  Since this part of the network is used to recreate images from the compressed representation, upsampling is done using the Transposed Convolution. Larger strides are used for upsampling the images in fewer steps.</p> <pre><code># Decoder\nx = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\nx = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\nx = layers.Conv2D(1, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n</code></pre>"},{"location":"articles/Scalar/Reconstructing%20the%20MNIST%20images%20using%20an%20autoencoder/#training-the-model","title":"Training the model","text":"<p>After defining the model, we must compile it with the Optimiser and the loss function. This article will use the Adam Optimiser and a Binary Cross Entropy loss function.</p> <pre><code># conv_autoenc_model\nconv_autoenc_model = Model(input, x)\nconv_autoenc_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\nconv_autoenc_model.summary()\n</code></pre> <p>After we compile the model, we can finally train it on the modified MNIST images we generated at the start of the article. We will train the model for 50 epochs with a batch size of 128. We also pass the validation data to the model. </p> <pre><code>conv_autoenc_model.fit(\n    x=ds_train,\n    y=ds_train,\n    epochs=50,\n    batch_size=128,\n    shuffle=True,\n    validation_data=(ds_test, ds_test),\n)\n</code></pre>"},{"location":"articles/Scalar/Reconstructing%20the%20MNIST%20images%20using%20an%20autoencoder/#reconstructing-images","title":"Reconstructing images","text":"<p>After training the model, we can use the trained model to generate predictions. We display the re-created images using the function we wrote previously.</p> <pre><code>preds = conv_autoenc_model.predict(ds_test)\ndisplay(ds_test, preds)\n</code></pre> <p>::: :::section{.summary}</p>"},{"location":"articles/Scalar/Reconstructing%20the%20MNIST%20images%20using%20an%20autoencoder/#conclusion","title":"Conclusion","text":"<ul> <li>In this article, we implemented a simple Autoencoder to re-create the MNIST image dataset.</li> <li>We learned how to load and pre-process the MNIST images to make them fit the Autoencoder model.</li> <li>We explored the architecture of the network and understood how to implement it using Tensorflow. </li> <li>Finally, we learned how to train the Autoencoder and use it to generate new images. :::</li> </ul>"},{"location":"articles/Scalar/Siamese%20Network/","title":"Siamese Network","text":"<p>toc: true title: Siamese Network</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Scalar/Siamese%20Network/#siamese-network","title":"Siamese Network","text":"<p>:::section{.abstract}</p>"},{"location":"articles/Scalar/Siamese%20Network/#overview","title":"Overview","text":"<p>The lack of data is a huge hurdle for any Deep learning task. Finding large datasets is nearly impossible in domains such as facial recognition, signature verification, text similarity, and many others. In many cases, a single example of each class is present. A regular CNN fails to perform in these cases, but if a network learns to minimize a similarity metric between images, it can easily perform this task. The Siamese Network is a class of architectures that excel at this one-shot learning task.  This article explains the workings behind the Siamese Network and provides an implementation for Signature Verification. ::: :::section{.scope}</p>"},{"location":"articles/Scalar/Siamese%20Network/#scope","title":"Scope","text":"<ul> <li>This article explains the concept of Siamese Networks and why they are useful.</li> <li>It explains the multiple loss functions behind Siamese Networks.</li> <li>It talks about few-shot learning and how to apply it to tasks.</li> <li>It talks about some of the use cases of Siamese Networks.</li> <li>The article also explains how to create a Siamese Network for a Signature Verification task using PyTorch. ::: :::section{.main}</li> </ul>"},{"location":"articles/Scalar/Siamese%20Network/#introduction","title":"Introduction","text":"<p>Siamese networks are a one-shot classification paradigm where only a single example is enough for the network to classify images accurately. This network uses the concept of Contrastive Loss, which finds a pairwise similarity score between the images in the Dataset. Instead of learning the content of the images, the Siamese network learns the differences and similarities between them. This unique learning paradigm makes these networks much more robust to the lack of data and improves performance without needing domain-specific information.</p> <p>Signature verification is a task in which these networks excel. This task aims to identify forged signatures given a single signature sample for thousands of people. This task is quite challenging due to the vast differences between individual signatures and the need for more training data. </p> <p>In this article, we will explore the task of Signature Verification using these Siamese Networks and create a working model using PyTorch.</p>"},{"location":"articles/Scalar/Siamese%20Network/#what-are-siamese-networks","title":"What Are Siamese Networks?","text":"<p>Siamese Networks are a family of networks that uses two identical subnetworks for one-shot classification. The sub-networks share the same configuration, parameters, and weights but have different inputs. Unlike a regular CNN that learns to predict multiple classes using vast amounts of data, a Siamese Network learns a similarity function. We can use the learned function to differentiate between classes without needing a lot of data. These networks are specialized in one-shot classification, which means that in many cases, they only need a single example to classify images accurately.</p> <p>As a real-life use case, Siamese Networks are applied to face recognition and signature verification tasks. Consider the face recognition task done for a company that wants to take an automated face-based attendance. The company would only have a single picture of its employees. A regular CNN would have been incapable of accurately classifying thousands of employees based on a single image of each of them. A Siamese network, on the other hand, excels at this task.</p>"},{"location":"articles/Scalar/Siamese%20Network/#exploring-few-shot-learning","title":"Exploring Few-Shot Learning","text":"<p>Few shot models are a family of architectures that rely not on the number of training examples but on exploiting the differences between a small number of samples. This property allows them to make predictions ranging from a few samples to a single sample. The advantage of few-shot learning comes into play when the training data is very small. For large datasets, this training paradigm could be more helpful.</p>"},{"location":"articles/Scalar/Siamese%20Network/#architecture-of-siamese-networks","title":"Architecture of Siamese Networks","text":"<p>The objective of the Siamese network is to find similar inputs and magnify the differences between dissimilar pairs. The architecture of this network is shown in the figure below.</p> <p>[IMAGE {1} {Architecture} START SAMPLE]  [IMAGE {1} FINISH SAMPLE]</p> <p>Some features that set Siamese networks apart from the usual CNN architecture are as follows. - The network has two different inputs. Each of these inputs is passed into identical subnetworks. - The inputs are passed through a Convolutional network first and then encoded.  - Any changes to one side of the network are reflected on the other. - The network returns an encoding that is a similarity score. This score can be used to differentiate between classes.  - The network is a one-shot classifier and does not require a lot of examples per class. </p>"},{"location":"articles/Scalar/Siamese%20Network/#loss-functions-used-in-siamese-networks","title":"Loss Functions Used in Siamese Networks","text":"<p>The Siamese Network uses multiple loss functions. They are explained below.</p>"},{"location":"articles/Scalar/Siamese%20Network/#binary-cross-entropy-loss","title":"Binary Cross Entropy Loss","text":"<p>This loss is one of the common image classification loss functions. The Siamese network uses this loss to classify the image pairs as similar or dissimilar.</p>"},{"location":"articles/Scalar/Siamese%20Network/#contrastive-loss","title":"Contrastive Loss","text":"<p>The Contrastive Loss function finds the difference between image pairs by using distance as a similarity measure. This function is useful when there are few training examples per class.  A caveat of using Contrastive loss is that it requires pairs of both negative and positive training samples. We can visualize this loss in the figure below.</p> <p>[IMAGE {2} {Contrastive Loss} START SAMPLE]  [IMAGE {2} FINISH SAMPLE]</p> <p>The Contrastive Loss equation is \\(\\((1-Y) \\frac{1}{2} D^{2}_{w} + (Y) + \\frac{1}{2} (max(0, m - D^{2}_{\\omega}))\\)\\) When Y is 0, the inputs share the same class. When the value of Y is 1, they are from different classes. The margin m defines the margin that the distance function uses to identify pairs that contribute to the loss. The value of m is always greater than 0. D denotes Euclidean distance.</p>"},{"location":"articles/Scalar/Siamese%20Network/#triplet-loss","title":"Triplet Loss","text":"<p>The triplet loss uses triples of data. These triples can be seen in the image below. [IMAGE {3} {Triplet Loss} START SAMPLE]  [IMAGE {3} FINISH SAMPLE]</p> <p>The objective of the triplet loss function is to maximize the distance between the anchor and the negative samples while minimizing the distance between the anchor and the positive samples. This task is shown in the below image.</p> <p>The Triplet loss is defined as \\(\\(L = max(d(a,p) - d(a,n) + margin, 0)\\)\\)</p>"},{"location":"articles/Scalar/Siamese%20Network/#building-a-signature-verification-model-with-siamese-networks","title":"Building a Signature Verification Model With Siamese Networks","text":"<p>Signature verification is the task of identifying forged signatures given a dataset of real ones. For this task, a model has to learn the difference between hundreds of signatures. Given a fake or a real signature, the model has to differentiate between them. This verification task is extremely hard for a regular CNN due to the complexity of changes and lack of training samples. In most cases, only a single signature is available per person, and the model needs to learn how to verify signatures for thousands of people. The following sections explore building a model to tackle this task using PyTorch.</p>"},{"location":"articles/Scalar/Siamese%20Network/#dataset","title":"Dataset","text":"<p>The Dataset we will be using is a signature verification dataset known as ICDAR 2011. This Dataset contains Dutch signatures that are either forged or original. An example of the data is shown below.</p> <p>[IMAGE {4} {Examples} START SAMPLE]  [IMAGE {4} FINISH SAMPLE]</p> <p>We can download the Dataset from this drive link.</p>"},{"location":"articles/Scalar/Siamese%20Network/#description-of-problem-statement","title":"Description of problem statement","text":"<p>This article considers recognizing fake signatures as part of a signature verification problem. We aim to take a dataset of signatures and use a Siamese network to predict which of the test signatures belong to real people and which are forged.  We need to create a pipeline that reads the Dataset, creates image pairs, and passes them to the Siamese network. After training the network on the Dataset, we need to create functions for inference.</p>"},{"location":"articles/Scalar/Siamese%20Network/#imports","title":"Imports","text":"<p>To create the Siamese Network, we need to import a few libraries. We import the Pillow library(PIL) for image processing. We will import the plotting package matplotlib, the numerical library numpy, and the progress bar library tqdm for other utilities. We will use Pytorch and torchvisionto train and build the network.</p> <pre><code>from PIL import Image\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader, Dataset\nimport PIL.images\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as utils\nimport torchvision\nimport torchvision.transforms as transforms\nimport torchvision.utils\nfrom tqdm import tqdm\n</code></pre>"},{"location":"articles/Scalar/Siamese%20Network/#utility-functions","title":"Utility Functions","text":"<p>To visualize the network's outputs, we create a function that takes the images and the labels as inputs and plots them in an easy-to-visualize grid.</p> <pre><code>def imshow(img, text=None, should_save=False):\n    npimg = img.numpy()\n    plt.axis(\"off\")\n    if text:\n        plt.text(\n            75,\n            8,\n            style= \"italic\",\n            fontweight= \"bold\",\n            bbox={\"face color\": \"white\", \"alpha\": 0.8, \"pad\": 10},\n        )\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n</code></pre>"},{"location":"articles/Scalar/Siamese%20Network/#data-preprocessing","title":"Data preprocessing","text":"<p>The data structure used by the Siamese network is very different from the usual image classification networks. Instead of providing an image and a label, the Dataset Generator for the Siamese network must provide pairs of images. These pairs are converted to Black and white and are then resized and converted to Tensors.  There are two types of pairs - the positive pair, where both the inputs images are identical, and the negative pair, where the images are not identical. We also create a function that returns the size of the Dataset when called.</p> <pre><code>dir_train = \"train\"\ndf_train = \"train_data.csv\"\ndf_val = \"test_data.csv\"\ndir_val = \"test\"\nbs = 32\nnum_epoch = 20\n\nclass PairedDataset:\n    def __init__(self, df_train=None, dir_train=None, transform=None, load_subset = None):\n        self.train_df = PD.read_csv(df_train)\n        if load_subset!=None:\n            self.train_df = self.train_df[:load_subset]\n        self.train_df.columns = [\"image1\", \"image2\", \"label\"]\n        self.train_dir = dir_train\n        self.transform = transform\n\n    def __getitem__(self, index):\n        pair1 = os.path.join(self.train_dir, self.train_df.iat[index, 0])\n        pair2 = os.path.join(self.train_dir, self.train_df.iat[index, 1])\n\n        pair_left = Image.open(pair1).convert(\"L\")\n        pair_right = Image.open(pair2).convert(\"L\")\n\n        if self.transform is not None:\n            pair_left = self.transform(pair_left)\n            pair_right = self.transform(pair_right)\n\n        return (\n            pair_left,\n            pair_right,\n            torch.from_numpy(\n                np.array([int(self.train_df.iat[index, 2])], dtype=np.float32)\n            ),\n        )\n\n    def __len__(self):\n        return len(self.train_df)\n\n</code></pre>"},{"location":"articles/Scalar/Siamese%20Network/#brief-description-of-the-features","title":"Brief Description of the features","text":"<p>The features that the network gets are pairs of images. There are positive or negative data pairs. Both the pairs are image data and are Tensor representations of the underlying images.  The labels provided to the Siamese network are categorical. </p>"},{"location":"articles/Scalar/Siamese%20Network/#standardization-of-the-features","title":"Standardization of the features","text":"<p>To standardize the features, we first convert them to Black and White. We also resized all the images to be (105x105) square as the Siamese Network requires this size. Finally, we convert all the images to Tensors to improve performance and be able to use the GPU.</p> <pre><code>transform=transforms.Compose(\n        [transforms.Resize((105, 105)), transforms.ToTensor()]\n)\n</code></pre>"},{"location":"articles/Scalar/Siamese%20Network/#splitting-the-dataset","title":"Splitting the Dataset","text":"<p>To ensure that the model can be used for prediction and not just training, we split the Dataset into training and testing parts.  For simplicity, we only use the first 1000 data points. Setting the load_subset function to None would use the entire Dataset but take much longer. We do not perform Data Augmentation here, but that is an option to make the network perform better in the long run.</p> <pre><code>train_ds = PairedDataset(\n    df_train,\n    dir_train,\n    transform=transforms.Compose(\n        [transforms.Resize((105, 105)), transforms.ToTensor()]\n    ),\n    load_subset=1000\n)\neval_ds = PairedDataset(\n    df_val,\n    dir_val,\n    transform=transforms.Compose(\n        [transforms.Resize((105, 105)), transforms.ToTensor()]\n    ),\n    load_subset=1000\n)\n</code></pre>"},{"location":"articles/Scalar/Siamese%20Network/#neural-network-architecture","title":"Neural Network Architecture","text":"<p>We can create the architecture that we described above in a few steps.  First, we create a function that creates blocks of Convolutions, Batch Normalisation, and ReLU with different input and output channels. We give this function the option of having a ../../Dropout|Dropout layer at the end or skipping that layer. We also create another function that generates blocks of FC layers followed by ReLU layers. We can use these functions to create the Sequential model that defines the Siamese Network. After creating the CNN part of the architecture using the functions we defined earlier, we have to create the FC part of the network. Note that different padding and kernel sizes are used across the network.  The FC part of the network is blocks of Linear layers followed by ReLU activations.  Once we have defined the architecture, we can run a forward pass for the data we pass to the network. Note that the view function is used to resize the output of the previous block by flattening dimensions. After creating this function, we can start training the Siamese network on the data. </p> <pre><code>class Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n\n        self.cnn1 = nn.Sequential(\n            self.conv_bn_relu(1, 96, 11, 1, False),\n            self.conv_bn_relu(96, 256, 5, 2, True),\n            nn.Conv2d(256,384 , kernel_size=3,stride=1,padding=1),\n            nn.BatchNorm2d(384),\n            nn.ReLU(inplace=True),\n            self.conv_bn_relu(384, 256, 3, 1, True),\n        )\n\n        self.fc1 = nn.Sequential(\n            self.linrel(30976, 1024),\n            nn.Dropout2d(p=0.5),\n            self.linrel(1024, 128),\n            nn.Linear(128,2))\n\n    def linrel(self, inc, outc): return nn.Sequential(nn.Linear(inc, outc), nn.ReLU(inplace=True))\n\n    def conv_bn_relu(self,inc, outc, ks, pad,dropout = True):\n        if dropout == True:\n            return nn.Sequential(\n                nn.Conv2d(inc, outc, kernel_size=ks,stride=1,padding=pad),\n                nn.BatchNorm2d(outc),\n                nn.ReLU(inplace=True),\n                nn.MaxPool2d(3, stride=2),\n                nn.Dropout2d(p=0.3),\n            )\n        else:\n            return nn.Sequential(\n                nn.Conv2d(inc, outc, kernel_size=ks,stride=1),\n                nn.BatchNorm2d(outc),\n                nn.ReLU(inplace=True),\n                nn.MaxPool2d(3, stride=2),\n            )\n\n    def forward_once(self, x):\n        output = self.cnn1(x)\n        output = output.view(output.size()[0], -1)\n        output = self.fc1(output)\n        return output\n\n    def forward(self, input1, input2):\n        out1 = self.forward_once(input1)\n        out2 = self.forward_once(input2)\n        return out1, out2\n</code></pre>"},{"location":"articles/Scalar/Siamese%20Network/#loss-function","title":"Loss Function","text":"<p>The loss function that the Siamese Network uses is contrastive loss. We can define this loss using the equations mentioned earlier in the article.  To improve code performance, instead of defining the loss as a simple function, we inherit from nn.Module and create a class that returns the outputs of the function. This wrapper will allow PyTorch to optimize the code for better runtime performance.</p> <pre><code>class ContrastiveLoss(nn.Module):\n    def __init__(self, margin=2.0):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n\n    def forward(self, out1, out2, label):\n        euclidean_distance = F.pairwise_distance(out1, out2)\n        return torch.mean(\n            (1 - label) * torch.pow(euclidean_distance, 2)\n            + (label)\n            * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n        )\n</code></pre>"},{"location":"articles/Scalar/Siamese%20Network/#training-the-siamese-network","title":"Training the Siamese Network","text":"<p>Now that we have loaded and cleaned up the data, we can start training the Siamese network using it. To do so, we first create the training and testing data loaders. Note that the evaluation DataLoader has a batch size of 1 as we want to perform one-by-one evaluations. We then send the model to the GPU and define the Contrastive Loss and the Adam optimizer.</p> <pre><code>dl_train = DataLoader(train_ds,\n                        shuffle=True,\n                        num_workers=8,\n                        batch_size=bs) \ndl_eval = DataLoader(eval_ds,\n                        shuffle=True,\n                        num_workers=8,\n                        batch_size=1) \n\nnet = Model().cuda()\ncriterion = ContrastiveLoss()\noptimizer = torch.optim.Adam(net.parameters(), lr=1e-3, weight_decay=0.0005)\n</code></pre> <p>We then write a function that takes the train DataLoader as an argument. We keep a running array of the loss and the counter to plot it later. After that, we iterate over the points in the DataLoader. For every point, we send the pairs to the GPU, run the pairs through the network, and calculate the Contrastive Loss. We can then perform the backward pass and return the net loss for a batch of data.</p> <pre><code>def train(dl_train):\n    loss=[] \n    counter=[]\n    iteration_number = 0\n    for i, data in tqdm(enumerate(dl_train,0), total = len(dl_train)):\n      pair_left, pair_right , label = data\n      pair_left, pair_right , label = pair_left.cuda(), pair_right.cuda() , label.cuda()\n      optimizer.zero_grad()\n      out1,out2 = net(pair_left,pair_right)\n      loss_contrastive = criterion(out1,out2,label)\n      loss_contrastive.backward()\n      optimizer.step()\n      loss.append(loss_contrastive.item())\n    loss = np.array(loss)\n    return loss.mean()/len(dl_train)\n\n</code></pre> <p>We can train the model for several epochs using the function we just created. This article only trains the model for a few epochs as a demo. If the evaluation loss is the best we have seen across the entire training period, we save the model for inference at that epoch.</p> <pre><code>for epoch in tqdm(range(1,num_epoch)):\n  best_eval_loss = 9999\n  train_loss = train(dl_train)\n  eval_loss = eval(dl_eval)\n\n  print(f\"Training loss {train_loss}\")\n  print(f\"Eval loss {eval_loss}\")\n\n  if eval_loss&lt;best_eval_loss:\n    best_eval_loss = eval_loss\n    print(f\"Best Eval loss{best_eval_loss}\")\n    torch.save(net.state_dict(), \"model.pth\")\n    print(\"Model Saved Successfully\") \n</code></pre> <p>[IMAGE {5} {Training} START SAMPLE]  [IMAGE {5} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Siamese%20Network/#testing-the-model","title":"Testing the model","text":"<p>After training the model, we can evaluate it and run inference for a single data point. Similar to the training function, we create an evaluation function that takes the test data loader as input. We iterate the data loader one at a time and obtain the pairs of images we wish to test. We pass these image pairs to the GPU and run the model over them. After obtaining the output from the model, we find the Contrastive loss and save it to a list.</p> <pre><code>def eval(dl_eval):\n    loss=[] \n    counter=[]\n    iteration_number = 0\n    for i, data in tqdm(enumerate(dl_eval,0), total=len(dl_eval)):\n      pair_left, pair_right , label = data\n      pair_left, pair_right , label = pair_left.cuda(), pair_right.cuda() , label.cuda()\n      out1,out2 = net(pair_left,pair_right)\n      loss_contrastive = criterion(out1,out2,label)\n      loss.append(loss_contrastive.item())\n    loss = np.array(loss)\n    return loss.mean()/len(dl_eval)\n</code></pre> <p>We can now run the code for a single evaluation over all the test data points. To visualize the performance, we will plot the image and print the pairwise distances between the data points the model identifies. We can then plot these results as a grid.</p> <pre><code>for i, data in enumerate(dl_eval, 0):\n    x0, x1, label = data\n    concat = torch.cat((x0, x1), 0)\n    out1, out2 = net(x0.to('cuda'), x1.to('cuda'))\n\n    eucledian_distance = F.pairwise_distance(out1, out2)\n    print(label)\n    if label == torch.FloatTensor([0](0.md)):\n        label = \"Original Pair Of Signature\"\n    else:\n        label = \"Forged Pair Of Signature\"\n\n    imshow(torchvision.utils.make_grid(concat))\n    print(\"Predicted Euclidean Distance:-\", eucledian_distance.item())\n    print(\"Actual Label:-\", label)\n    if i == 4:\n        break\n\n</code></pre> <p>[IMAGE {6} {Outputs} START SAMPLE]  [IMAGE {6} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Siamese%20Network/#pros-and-cons-of-siamese-networks","title":"Pros and Cons of Siamese Networks","text":"<p>Like all Deep Learning applications, Siamese Networks have multiple pros and cons. Some of them are listed below.</p>"},{"location":"articles/Scalar/Siamese%20Network/#cons","title":"Cons","text":"<ul> <li>The biggest disadvantage of using a Siamese network is that it returns only a similarity score. Since the network's output is a distance metric, it does not sum up to 1. This property makes it harder to use in some cases.</li> </ul>"},{"location":"articles/Scalar/Siamese%20Network/#pros","title":"Pros","text":"<ul> <li>Siamese networks are robust to varying numbers of examples in classes. This robustness is due to the network requiring very little information about the classes.</li> <li>Domain-specific information does not need to be provided to the network to classify images.</li> <li>Siamese networks can perform predictions even with a single image per class.</li> </ul>"},{"location":"articles/Scalar/Siamese%20Network/#applications","title":"Applications","text":"<p>Siamese Networks have quite a few applications. Some of them are as follows.</p>"},{"location":"articles/Scalar/Siamese%20Network/#facial-recognition","title":"Facial Recognition","text":"<p>Due to the paired nature of the Siamese networks, one-short facial recognition is a good use case to use this network. The contrastive loss is used to push different faces away from each other and pull similar faces closer. In doing so, the Siamese network learns to identify faces without requiring too many examples.</p>"},{"location":"articles/Scalar/Siamese%20Network/#fingerprints","title":"Fingerprints","text":"<p>Similar to facial recognition, we can also use Siamese Networks for fingerprint recognition. Once the fingerprints in the database have been cleaned and pre-processed, we can feed them pairwise to the network. The Siamese network then learns to find their differences and identify which fingerprint is valid and invalid.</p>"},{"location":"articles/Scalar/Siamese%20Network/#signature-verification","title":"Signature Verification","text":"<p>This article focused on implementing Signature Verification using Siamese networks. As we saw in this article, we can create a pairwise dataset using signatures and the network to identify which signatures are forged and which are real. </p>"},{"location":"articles/Scalar/Siamese%20Network/#text-similarity","title":"Text Similarity","text":"<p>Another useful application of Siamese Networks is Text similarity. Given multiple pieces of text, the network can be fed a pairwise dataset and tasked with identifying which are similar. Examples of such tasks include - finding similar questions from a question bank and using Siamese networks to find similar documents from a text database.</p> <p>::: :::section{.summary}</p>"},{"location":"articles/Scalar/Siamese%20Network/#conclusion","title":"Conclusion","text":"<ul> <li>Siamese networks are a powerful tool for classifying datasets with few examples per class.</li> <li>We learned the concepts behind Siamese networks and understood the architecture, loss functions used, and how to train such a network.</li> <li>We explored the Signature verification task using the ICDAR 2011 dataset and implemented a model to identify forged signatures.</li> <li>We also understood the entire training and testing pipeline for Siamese networks, including its paired data representation. :::</li> </ul>"},{"location":"articles/Scalar/StackGAN/","title":"StackGAN","text":"<p>toc: true title: StackGAN</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Scalar/StackGAN/#stackgan","title":"StackGAN","text":"<p>:::section{.abstract}</p>"},{"location":"articles/Scalar/StackGAN/#overview","title":"Overview","text":"<p>In image generation, the GAN architecture is one of the best ones. The StackGAN architecture addresses some of the flaws of basic GANs by decomposing the task of generating images into multiple parts. This article will focus on the training paradigm proposed by StackGAN and take an in-depth look at its architecture.  ::: :::section{.scope}</p>"},{"location":"articles/Scalar/StackGAN/#scope","title":"Scope","text":"<ul> <li>The scope of this article is to provide an introduction to StackGANs.</li> <li>The article focuses on understanding how a StackGAN works, how it differs from other GANs and where We can use it.</li> <li>Once these concepts are understood, the architecture is explained in detail with all the different stages and how they are linked.</li> </ul> <p>::: :::section{.main}</p>"},{"location":"articles/Scalar/StackGAN/#introduction","title":"Introduction","text":"<p>Generating novel photorealistic images is a huge part of the computer vision process in many fields, such as photo editing, design and other graphics-related work. Many attempts to generate high-resolution images have been made in the past, and StackGAN is one of the major ones.  Instead of performing the generation task in one go as most existing architectures do, a StackGAN uses two separate GANs. The authors of the StackGAN made this architectural choice to replicate how a human artist paints a picture. They first start with a rough sketch and a colour blockout, then move on to refining the details of the sketch. They then add more information based on the description of what they want to paint. This article looks at StackGAN and how and why it works. The multi-stage architecture and the loss functions are also explained, along with the need to have such a modification to the GAN paradigm.</p> <p>Some of the images generated by StackGAN given their descriptions are shown below.</p> <p>[IMAGE {1} Example Images START SAMPLE]  [IMAGE {1} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/StackGAN/#what-is-a-stackgan","title":"What is a StackGAN","text":"<p>The StackGAN is a multi-modal network that can produce much higher quality images than many networks by first generating a low-quality image and then rectifying it to increase the image's resolution. A StackGAN is a modification of the general GAN training paradigm were generating new objects is split into sub-tasks. This split makes training the network much easier. The StackGAN research paper also introduces a technique called \"Conditioning augmentation\" that produces better results.</p>"},{"location":"articles/Scalar/StackGAN/#pre-requisites","title":"Pre Requisites","text":"<p>Before understanding the StackGAN architecture, we need to understand the concept of Conditional GANs (CGANs). In a CGAN, the Generator and Discriminator are given conditioning variables \\(c\\) alongside the input. These enable the Generator to create images influenced by these variables. This conditioning is formulated as \\(G(z,c), D(x,c)\\) for the Generator and the Discriminator, respectively.</p>"},{"location":"articles/Scalar/StackGAN/#architecture","title":"Architecture","text":"<p>The StackGAN comprises two parts - Stage I and Stage II GANs. The first stage generates low-quality images by \"sketching\" a primitive shape and colouring the image with a simple colour blockout based on the text description provided. The background is generated from random noise. The second stage corrects defects in the output of the first stage by re-reading the provided description and then completing the details the first phase missed. The output of the second stage is thus a high-resolution image.</p> <p>[IMAGE {2} Architecture START SAMPLE]  [IMAGE {2} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/StackGAN/#stage-i-gan","title":"Stage I GAN","text":"<p>Stage I of the GAN is focused on generating a rough sketch with simple colours from the description.</p>"},{"location":"articles/Scalar/StackGAN/#architecture_1","title":"Architecture","text":"<p>It is first fed into a fully connected layer(FC) to understand the embedding. The output of this FC layer is then passed to the Generator, which attempts to learn how to create the image better. The Discriminator takes the text embeddings and compresses them to a smaller representation using another FC layer. The image is also passed through a few ../../Downsampling|downsampling blocks until it is a size the network can use. The final down-sampled image is combined with the text embedding and passed through a 1x1 convolutional layer. The final layer is another FC layer that returns the probability of the generated image being real or fake.</p>"},{"location":"articles/Scalar/StackGAN/#loss-functions","title":"Loss functions","text":"<p>Consider the text embeddings of the required description as \\(\\varphi{t}\\). The meaning of the text embeddings is sampled from the Gaussian conditioning variables \\(\\hat{c{0}}\\).  Stage I first trains the Discriminator and then the Generator to alternatively maximize the discriminator and generator losses. The equations for these loss functions are as follows.</p> \\[\\mathcal{L}_{D{0}} = \\mathbb{E}{(I{0},t)\\sim p{data}}[log D{0}(I{0}, \\varphi{t})]+ \\\\ \\mathbb{E}{z \\sim p{z}, t \\sim p{data}}[log(1- D{0}(G{0}(z , \\hat{c{0}}, \\varphi_{t})))]\\] \\[\\mathcal{L}_{G{0}}= \\mathbb{E}{z \\sim p{z}, t \\sim p{data}}[log(1- D{0}(G{0}(z, \\hat{c{0}}),\\varphi{t}))] + \\\\ \\lambda D{KL}(\\mathcal{N}(\\mu{0}(\\varphi{t}), \\Sigma{0}(\\varphi{t}))|| \\mathcal{N}(0, I))\\] <p>\\(z\\) is a noise vector that is randomly sampled from the Gaussian distribution \\(p_{z}\\). A regularizing parameter is provided in the \\(\\lambda\\) variable. The StackGAN research uses a \\(\\lambda = 1\\) for the paper. </p>"},{"location":"articles/Scalar/StackGAN/#stage-ii-gan","title":"Stage II GAN","text":"<p>The Stage II GAN receives the output of the Stage I GAN and refines it by re-considering the descriptions. </p>"},{"location":"articles/Scalar/StackGAN/#architecture_2","title":"Architecture","text":"<p>The StackGANs Stage II Generator follows an encoder-decoder architecture with residual blocks. Text embedding is used first to create the conditioning variables. The result of Stage I is passed through ../../Downsampling|downsampling layers and then concatenated with the features obtained from the text embedding. The output of these layers is then upsampled to generate high-resolution images. The Discriminator architecture is almost identical to Stage I, except for a few extra down-sampling layers. These down-sampling layers were included as the output of this part of the network is of a higher resolution than Stage I.</p>"},{"location":"articles/Scalar/StackGAN/#loss-functions_1","title":"Loss functions","text":"<p>If the low-resolution image is given by \\(s_{0}\\) and the Gaussian sampled latent variables are given by \\(\\hat{c}\\), the Discriminator and Generator are trained by alternatively maximizing the value of the Discriminator loss and minimizing the Generator loss. The equations for these loss functions are the same as the Stage I GAN, except the low-resolution image \\(s_{0}\\) is used instead of the noise \\(z\\). It is also to be noted that the noise \\(z\\) is not used in Stage II as the StackGAN is meant to preserve the required randomness with the previous stage. A different FC layer is also used here that generates different statistical outputs compared to Stage I to learn better features.</p>"},{"location":"articles/Scalar/StackGAN/#more-architectural-details","title":"More architectural details","text":"<p>Some architectural details were also mentioned in the StackGAN research. These details apply to both the Generator and the Discriminator. - The up-sampling blocks are composed of nearest neighbour upsampling and then passed to a 3x3 stride one convolutional layer. Besides the final layer, Batch Normalization and the ReLU activation are applied after every convolution.  - The residual blocks have 3x3 stride 1 convolutions.  - The StackGAN model that generates 256x256 images has four residual blocks, while the one that generates 128x128 images has only two blocks. - The down-sampling blocks have 4x4 stride two convolutions and LeakyReLU instead of ReLU.  - The first ../../Downsampling|downsampling block does not have a Batch Normalization layer.</p>"},{"location":"articles/Scalar/StackGAN/#embedding","title":"Embedding","text":"<p>Contrary to other networks where the text embeddings are transformed using non-linear techniques, the StackGAN uses additional variables and a process called Conditioning Augmentation. These embeddings are more robust to minor changes in the data manifold and work with lesser image data. </p>"},{"location":"articles/Scalar/StackGAN/#conditioning-augmentation","title":"Conditioning Augmentation","text":"<p>Conditioning Augmentation is one of the major contributions of the StackGAN research. Given a text description \\(t\\), the StackGAN uses an embedding to convert it to input for the Generator. Under circumstances where the data is limited, the latent space of the embedding is not fully exploited and leads to changes in the data manifold. These changes in the manifold are not desirable and hurt performance. </p> <p>Conditioning Augmentation uses these to create more training pairs from a small subset of data. Instead of using a fixed conditioning variable, StackGAN samples latent variables from a Gaussian distribution. The mean and ../../Covariance|covariance matrix is generated for a text embedding \\(\\varphi_{t}\\). </p> <p>The secondary objective of Conditioning Augmentation is to encourage reducing changes in the output with small changes in the data manifold. To do this, StackGAN uses a ../../Regularization|regularization term called KL Divergence as part of the Generator. This is given by, \\(\\(D{KL}(\\mathcal{N}(\\mu(\\varphi{t}), \\Sigma(\\varphi_{t})) || \\mathcal{N}(0,I))\\)\\) </p>"},{"location":"articles/Scalar/StackGAN/#need-for-stackgan","title":"Need for StackGAN","text":"<p>Even though generating novel photorealistic images is easy enough to do with a GAN such as DCGAN, generating higher-resolution images is a hard problem. Previously failed approaches have tried stacking more up-sampling layers. StackGAN, using the decomposition of the generation and refinement tasks, can generate 256x256 images.  The StackGAN training paradigm can be used with existing GANs to improve performance as it generates higher image sizes. ::: :::section{.summary}</p>"},{"location":"articles/Scalar/StackGAN/#conclusion","title":"Conclusion","text":"<p>In this article, we looked at StackGAN and all its components. - We understood how to decompose the task of generating novel images using a StackGAN. - We looked at the architectural details of the StackGAN, its' embeddings and the respective training stages. - We also explored Conditional Augmentation and understood why it was proposed. :::</p>"},{"location":"articles/Scalar/Text_proc/","title":"Image","text":"In\u00a0[1]: Copied! <pre>import os\nimport re\n# %pip install clipboard\nimport clipboard\n</pre> import os import re # %pip install clipboard import clipboard In\u00a0[2]: Copied! <pre>def gen_image_hackmd():\n    link = input(\"Enter link\")\n    name = input(\"Enter name\")\n    count = int(input(\"Enter count\"))\n    print(\"\\n\\n\")\n    return f\"\"\"[IMAGE { {count} } { {name} } START SAMPLE]\n![{name}](https://hackmd.io/_uploads/{link})\n[IMAGE { {count} } FINISH SAMPLE]\"\"\".replace(\"\\\\\",\"\").replace(\"'\", \"\")\n</pre> def gen_image_hackmd():     link = input(\"Enter link\")     name = input(\"Enter name\")     count = int(input(\"Enter count\"))     print(\"\\n\\n\")     return f\"\"\"[IMAGE { {count} } { {name} } START SAMPLE] ![{name}](https://hackmd.io/_uploads/{link}) [IMAGE { {count} } FINISH SAMPLE]\"\"\".replace(\"\\\\\",\"\").replace(\"'\", \"\") In\u00a0[3]: Copied! <pre>def setup_base(main_paras):\n#     main_paras = input('Enter main paras')\n    para_string = \"\"\"\n    :::section{.abstract}\n    ## Overview\n    :::\n    :::section{.scope}\n    ## Scope\n    This article covers the following topics:\n    \n    :::\n    :::section{.main}\n    \"\"\"\n    para_string += f\"\\n{main_paras}\"\n    para_string += \"\"\"\n    :::\n    :::section{.summary}\n\n    ## Conclusion\n    :::\n    \"\"\"\n    return para_string\n</pre> def setup_base(main_paras): #     main_paras = input('Enter main paras')     para_string = \"\"\"     :::section{.abstract}     ## Overview     :::     :::section{.scope}     ## Scope     This article covers the following topics:          :::     :::section{.main}     \"\"\"     para_string += f\"\\n{main_paras}\"     para_string += \"\"\"     :::     :::section{.summary}      ## Conclusion     :::     \"\"\"     return para_string In\u00a0[12]: Copied! <pre>clipboard.copy(gen_image_hackmd())\n# print(gen_image_hackmd())\n</pre> clipboard.copy(gen_image_hackmd()) # print(gen_image_hackmd()) <pre>\n\n\n</pre> In\u00a0[4]: Copied! <pre>main_parts = \"\"\"\n## Introduction\n## What Are Siamese Networks?\n- (how do they work?)\n\n- (Proper explanation with real life examples)\n## Exploring Few-Shot Learning\n## Architecture of Siamese Networks\n## Loss Functions Used in Siamese Networks\n## Building a Signature Verification Modeil With Siamese Networks\n### Dataset\n### Description of problem statement\n### Data preprocessing\n### Brief description of the features (numerical, categorical, etc.)\n### Standardization of the features\n### Splitting the dataset\n### Neural Network Architecture \n### Loss Function \n### Training the Siamese Network\n### Testing the model \n    - (Should include a section showing how to perform inference with the model on a single data point)\n    - (Note for the writer - use an incremental approach here, break the projects into different steps/parts and make it easy for the reader to follow through your code with proper outputs and explanation)\n## Pros and Cons of Siamese Networks\n## Applications\n\"\"\"\n# print(setup_base(main_parts))\nclipboard.copy(setup_base(main_parts))\n</pre> main_parts = \"\"\" ## Introduction ## What Are Siamese Networks? - (how do they work?)  - (Proper explanation with real life examples) ## Exploring Few-Shot Learning ## Architecture of Siamese Networks ## Loss Functions Used in Siamese Networks ## Building a Signature Verification Modeil With Siamese Networks ### Dataset ### Description of problem statement ### Data preprocessing ### Brief description of the features (numerical, categorical, etc.) ### Standardization of the features ### Splitting the dataset ### Neural Network Architecture  ### Loss Function  ### Training the Siamese Network ### Testing the model      - (Should include a section showing how to perform inference with the model on a single data point)     - (Note for the writer - use an incremental approach here, break the projects into different steps/parts and make it easy for the reader to follow through your code with proper outputs and explanation) ## Pros and Cons of Siamese Networks ## Applications \"\"\" # print(setup_base(main_parts)) clipboard.copy(setup_base(main_parts)) In\u00a0[71]: Copied! <pre>get_inpt = clipboard.paste()\nsplit_inps = get_inpt.split(\"\\n\")\nfixed_text = []\ntemp_rep = \"\"\nfor line in split_inps:\n    if \"IMAGE\" in line:\n        if line.count(\"}\") &lt;= 1:\n            if \"START\" in line:\n                st = line.find(\"}\") + 1\n                end = line.find(\"START\")\n                found_string = line[st:end]\n                new_string = \" {\" + found_string + \"} \"\n                line = line.replace(found_string, new_string)\n                temp_rep = line\n\n            # if \"FINISH\" in line:\n            #     st = line.find(\"}\") + 1\n            #     end = line.find(\"FINISH\")\n            #     found_string = line[st:end]\n            #     new_string = \" {\" + temp_rep + \"} FINISH\"\n            #     line = line.replace(\"FINISH\", new_string)\n        # else:\n        #     if \"START\" in line:\n        #         temp_rep = line[line.find(\"} {\")+1 : line.find(\"} ST\")]\n        #         temp_rep = temp_rep.replace(\"}\", \"\")\n        #         temp_rep = temp_rep.replace(\"{\", \"\")\n\n    fixed_text.append(line)\nclipboard.copy(\"\\n\".join(fixed_text))\n# print(\"\\n\".join(fixed_text))\n</pre> get_inpt = clipboard.paste() split_inps = get_inpt.split(\"\\n\") fixed_text = [] temp_rep = \"\" for line in split_inps:     if \"IMAGE\" in line:         if line.count(\"}\") &lt;= 1:             if \"START\" in line:                 st = line.find(\"}\") + 1                 end = line.find(\"START\")                 found_string = line[st:end]                 new_string = \" {\" + found_string + \"} \"                 line = line.replace(found_string, new_string)                 temp_rep = line              # if \"FINISH\" in line:             #     st = line.find(\"}\") + 1             #     end = line.find(\"FINISH\")             #     found_string = line[st:end]             #     new_string = \" {\" + temp_rep + \"} FINISH\"             #     line = line.replace(\"FINISH\", new_string)         # else:         #     if \"START\" in line:         #         temp_rep = line[line.find(\"} {\")+1 : line.find(\"} ST\")]         #         temp_rep = temp_rep.replace(\"}\", \"\")         #         temp_rep = temp_rep.replace(\"{\", \"\")      fixed_text.append(line) clipboard.copy(\"\\n\".join(fixed_text)) # print(\"\\n\".join(fixed_text)) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"articles/Scalar/Text_proc/#image","title":"Image\u00b6","text":""},{"location":"articles/Scalar/Text_proc/#setup-article","title":"Setup Article\u00b6","text":""},{"location":"articles/Scalar/Text_proc/#fix-image-entries","title":"Fix image entries\u00b6","text":""},{"location":"articles/Scalar/Time%20series%20forecasting%20using%20LSTM/","title":"Time series forecasting using LSTM","text":"<p>toc: true title: Time series forecasting using LSTM</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Scalar/Time%20series%20forecasting%20using%20LSTM/#time-series-forecasting-using-lstm","title":"Time series forecasting using LSTM","text":"<p>:::section{.abstract}</p>"},{"location":"articles/Scalar/Time%20series%20forecasting%20using%20LSTM/#overview","title":"Overview","text":"<p>Any temporal data can be framed as a time series task. Data such as heart rates, stock market prices, sensor logs and many others fall under the category of time series data. There are many Deep Learning architectures that are used to model such data, LSTMs being one of them. This article focuses on building an LSTM time series model. :::</p> <p>:::section{.main}</p>"},{"location":"articles/Scalar/Time%20series%20forecasting%20using%20LSTM/#what-are-we-building","title":"What are we building?","text":"<p>In this article, we will be creating an LSTM time series model. We will be using data that we generate and create a simple LSTM that can model it accurately. To perform this task, we will write functions that can generate data, model it and perform predictions on future points.  We will implement this model using Tensorflow and the below sections explain how to perform just that.</p>"},{"location":"articles/Scalar/Time%20series%20forecasting%20using%20LSTM/#pre-requisites","title":"Pre-Requisites","text":"<p>Before moving on to creating the LSTM time series model, we must understand some pre-requisite information.</p>"},{"location":"articles/Scalar/Time%20series%20forecasting%20using%20LSTM/#what-is-time-series","title":"What is Time Series?","text":"<p>A time series data is any temporal data that has a discrete time interval and almost equidistant time steps. The general task is to estimate the function that was used to generate such the time series. If the function can be estimated correctly, future points that the model has not encountered yet can be predicted. Examples of time series include heart rate data, stock market data and many others.</p>"},{"location":"articles/Scalar/Time%20series%20forecasting%20using%20LSTM/#rnns","title":"RNNs","text":"<p>RNNs are a family of models that take entire series as inputs and return series as outputs. This algorithm is a sequential process and contains hidden states that model the underlying data. Unlike a simple Convolutional network that uses Backpropagation, an RNN uses a modified variant called Backpropagation through time (BPTT) that enables it to embed temporal data. An RNN is said to be Turing complete and is used in domains such as Natural Language Processing, Computer Vision, Robotics and many others. The RNN architecture is made up of gates and is shown below.</p> <p>[IMAGE {1} RNN START SAMPLE]  [IMAGE {1} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Time%20series%20forecasting%20using%20LSTM/#problems-with-classical-rnns","title":"Problems with Classical RNNs","text":"<p>RNNs suffer from a variety of problems due to their sequential nature. - RNNs fail to model longer sequences. This property makes it very hard to use for data that has a long temporal span. - The classical RNN also had an issue with exploding and vanishing gradients due to the way the underlying architecture worked. These problems make an RNN very unstable. </p>"},{"location":"articles/Scalar/Time%20series%20forecasting%20using%20LSTM/#what-is-lstm","title":"What is LSTM?","text":"<p>LSTMs are a modified version of RNNs with different gates that enable the architecture to model much longer sequences. The LSTMs use gated connections that learn which features to forget and which to remember. The ability to choose what to forget makes them much better than a classical RNN. LSTMs are also a lot more stable and have a smaller chance of exploding or vanishing gradients. The LSTM architecture is shown below.</p> <p>[IMAGE {2} LSTM START SAMPLE]  [IMAGE {2} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Time%20series%20forecasting%20using%20LSTM/#how-are-we-going-to-build-this","title":"How are we going to build this?","text":"<p>To build an LSTM time series model, we will write functions that can generate a time series data. Once we have the data, we will pre-process it and make it fit to be used by the model. We will also write a function that can display the results of the model. After creating these helper functions, we will create a simple LSTM model and train it using the data we generated previously. The LSTM time series model we will be using in this article is just comprised of a single LSTM block followed by a FC layer and is very easy to implement. After implementing all the required functions, we will train the model and use it to predict future points. The following sections detail the implementation. </p>"},{"location":"articles/Scalar/Time%20series%20forecasting%20using%20LSTM/#final-output","title":"Final Output","text":"<p>The final output of the LSTM time series model is a prediction of future points that the model has not encountered yet. The output we get after training the model for ~50 epochs is shown below. [IMAGE {3} Final Output START SAMPLE]  [IMAGE {3} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Time%20series%20forecasting%20using%20LSTM/#requirements","title":"Requirements","text":"<p>There are many libraries that we need to implement an LSTM time series model. Since we will be building the architecture in Tensorflow, we import it first. We will also be using the numerical processing library numpy, the tabular data library pandas and the plotting libraries matplotlib and seaborn. The rc module in matplotlib enables configuring some of the plots and comes in handy later on.</p> <pre><code>import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport pandas as pd\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\n</code></pre>"},{"location":"articles/Scalar/Time%20series%20forecasting%20using%20LSTM/#building-the-time-series-forecaster","title":"Building the Time Series Forecaster","text":"<p>The Time Series Forecaster model has a simple LSTM based architecture. Before creating it, we have to write functions to set up the library, generate and load and finally pre-process the data.  The model we will use for this article is a Sequential model comprising an LSTM block followed by a Fully Connected layer. We will then use the generated data and this model to train a LSTM time series prediction model. We will use the trained model to predict points in the future that the model has not seen before. The following sections detail all of these points.</p>"},{"location":"articles/Scalar/Time%20series%20forecasting%20using%20LSTM/#setup","title":"Setup","text":"<p>To set up our modules, we set the RANDOM_SEED variable. This variable sets the seed for the random number generator and ensures that we get the same \u201crandom\u201d numbers every time. This is not useful in practice but is done only for demonstration purposes. We also modify the plot to be a white style grid with a muted palette for better display.</p> <pre><code>sns.set(style='whitegrid', palette='muted', font_scale=1.5)\nrcParams['figure.figsize'] = 16, 10\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntf.random.set_seed(RANDOM_SEED)\n</code></pre>"},{"location":"articles/Scalar/Time%20series%20forecasting%20using%20LSTM/#data","title":"Data","text":"<p>To generate the data, we create a custom function that uses a combination of a Sin wave and a small Gaussian noise. These values are generated in the range of (0,200) with a step of 0.1 .  To see how this data looks like, we can plot it using matplotlib.</p> <pre><code>data_time = np.arange(0, 200, 0.1)\nsin_values = np.sin(data_time) + np.random.normal(scale=0.5, size=len(data_time))\nplt.plot(data_time, sin_values, label='sine (with noise)');\n</code></pre> <p>[IMAGE {4} Original Data START SAMPLE]  [IMAGE {4} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Time%20series%20forecasting%20using%20LSTM/#data-pre-processing","title":"Data Pre-processing","text":"<p>Now, we need to convert this data into a DataFrame before passing it to the model. Doing so makes future processes much easier. We also split the data into training and testing components. The first few rows of the DataFrame are shown here.</p> <p>[IMAGE {5} Pre-Processing START SAMPLE]  [IMAGE {5} FINISH SAMPLE]</p> <pre><code>data_full = pd.DataFrame(dict(sine=sin_values), index=data_time, columns=['sine'])\ndata_full.head()\n\nlen_train = int(len(data_full) * 0.8)\nlen_test = len(data_full) - len_train\ntrain, test = data_full.iloc[0:len_train], data_full.iloc[len_train:len(data_full)]\n</code></pre> <p>Now that we have created a data frame, we will use it to generate batches of data. We do this using the following function and create the input and labels for both training and testing.</p> <pre><code>def gen_data(X, y, num_steps=1):\n    Xs, ys = [], []\n    for i in range(len(X) - num_steps):\n        Xs.append(X.iloc[i:(i + num_steps)].values)       \n        ys.append(y.iloc[i + num_steps])\n    return np.array(Xs), np.array(ys)\n\nnum_steps = 10\ntrainX, trainY = gen_data(train, train.sine, num_steps)\ntestX, testY = gen_data(test, test.sine, num_steps)\n</code></pre>"},{"location":"articles/Scalar/Time%20series%20forecasting%20using%20LSTM/#implementing-the-sequential-model","title":"Implementing the Sequential model","text":"<p>We can finally implement the LSTM time series model. This is a very simple model and just has a single LSTM layer followed by a FC layer.  We compile the model with the Mean Squared Error loss function and an Adam Optimiser. This compiled model can now be trained on the generated data.</p> <pre><code>lstm_model = keras.Sequential()\nlstm_model.add(keras.layers.LSTM(128, input_shape=(trainX.shape[1], trainX.shape[2])))\nlstm_model.add(keras.layers.Dense(1))\nlstm_model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(0.001))\n</code></pre>"},{"location":"articles/Scalar/Time%20series%20forecasting%20using%20LSTM/#early-stopping-callback","title":"Early Stopping Callback","text":"<p>Time series model tend to Overfit really easily. To reduce the probability of Overfitting, the Early Stopping callback is used. This callback uses the number of epochs as a hyper parameter. If the validation accuracy does not increase for a few epochs, the model is saved and training is stopped. This stops the training before the model starts to focus too much on the training data.</p> <pre><code>callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)]\n</code></pre>"},{"location":"articles/Scalar/Time%20series%20forecasting%20using%20LSTM/#model-training","title":"Model Training","text":"<p>Once we have defined all the required functions, we can train the model. In this article we train the LSTM time series model for 30 epochs with a batch size of 16. We use a validation split of 0.1% and also supply the Early Stopping callback that we defined earlier.</p> <pre><code>history = lstm_model.fit(\n    trainX, trainY, \n    epochs=30, \n    batch_size=16, \n    validation_split=0.1,\n    shuffle=False,\n    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)],\n)\n</code></pre> <p>[IMAGE {6} Training START SAMPLE]  [IMAGE {6} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Time%20series%20forecasting%20using%20LSTM/#evaluation","title":"Evaluation","text":"<p>After training the model, we can use the evaluate function to perform a batch evaluation on the test dataset. We can see that the model performs pretty decently. </p> <pre><code>lstm_model.evaluate(testX)\n</code></pre> <p>To visualize the training performance, we plot both the training and validation losses throughout history. We can see that the model is learning stably and is neither Overfitting nor Underfitting the data.</p> <pre><code>plt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='test')\nplt.legend();\n</code></pre> <p>[IMAGE {7} Evaluation START SAMPLE]  [IMAGE {7} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Time%20series%20forecasting%20using%20LSTM/#predicting-a-new-point-in-the-future","title":"Predicting a new point in the future","text":"<p>No LSTM time series model is useful without the ability to predict future points. We can use the predict function on a set of future points to see how well the model can predict the results. After performing inference, we plot the results against the actual data.</p> <pre><code>y_pred = lstm_model.predict(testX)\nplt.plot(testY, marker='.', label=\"true\")\nplt.plot(y_pred, 'r', label=\"prediction\")\nplt.ylabel('Value')\nplt.xlabel('Time Step')\nplt.legend()\nplt.show();\n</code></pre> <p>We can see that the model did perform pretty decently. Further improvements in performance can be obtained by training for longer, using more data and many other methods that are beyond the scope of this article.</p> <p>::: :::section{.summary}</p>"},{"location":"articles/Scalar/Time%20series%20forecasting%20using%20LSTM/#conclusion","title":"Conclusion","text":"<ul> <li>In this article, we learnt what an LSTM model is and why it was created.</li> <li>We learnt how to create an LSTM model in Tensorflow.</li> <li>We also learnt how to generate our own time series data using a sin curve.</li> <li>Finally, we trained an LSTM time series model on the generated data.</li> <li>We also learned how to use the trained model to predict points in the future and display its predictions. :::</li> </ul>"},{"location":"articles/Scalar/Transfer%20Learning%20and%20Fine-tuning/","title":"Transfer Learning and Fine tuning","text":"<p>toc: true title: Transfer Learning and Fine-tuning</p> <p>categories: [\"article\"] date modified:  date created: </p>"},{"location":"articles/Scalar/Transfer%20Learning%20and%20Fine-tuning/#transfer-learning-and-fine-tuning","title":"Transfer Learning and Fine-tuning","text":"<p>:::section{.abstract}</p>"},{"location":"articles/Scalar/Transfer%20Learning%20and%20Fine-tuning/#overview","title":"Overview","text":"<p>Training deep learning models requires a massive amount of labeled data. In most cases, this data needs to be made available or easier to clean up. Many approaches for working with limited data sets have been created over the years, Transfer Learning being one of the breakthroughs. Transfer learning enables us to fine-tune a model pre-trained on a large dataset on our task.  ::: :::section{.scope}</p>"},{"location":"articles/Scalar/Transfer%20Learning%20and%20Fine-tuning/#scope","title":"Scope","text":"<ul> <li>This article explains the principles behind Transfer Learning.</li> <li>It covers the method of fine-tuning using a pre-trained model.</li> <li>It elaborates on the principles of freezing and unfreezing weights.</li> <li>The article also discusses implementing the Transfer Learning pipeline in Tensorflow. ::: :::section{.main}</li> </ul>"},{"location":"articles/Scalar/Transfer%20Learning%20and%20Fine-tuning/#introduction","title":"Introduction","text":"<p>Transfer Learning is useful for smaller datasets and can be considered an intelligent weight initialization scheme. Instead of randomly initializing the weights of the model like we usually do, we obtain weights from a model trained on a larger dataset. Any company/individual with the funds can train a larger model and make its weights public. After doing so, we can train these models on any other similar dataset much faster than before.  This article explores the concept of Transfer Learning by creating a network that can identify ten different classes from the CIFAR10 dataset by fine-tuning a model pre-trained on the ImageNet dataset (1000 classes). </p>"},{"location":"articles/Scalar/Transfer%20Learning%20and%20Fine-tuning/#transfer-learning","title":"Transfer Learning","text":"<p>In a DL pipeline, Transfer Learning is usually done when the data available is too less to train a network properly. The general approach for a Transfer Learning workflow is as follows. - Obtain a pre-trained model on data similar to your current dataset. For example, many models are pre-trained on the ImageNet dataset in computer vision approaches. Since the ImageNet dataset has classes relating to real-life objects and things, models pre-trained on it already have some knowledge of the world. - Load the model and understand its layer structure. - Freeze the weights of the model. Freezing the weights sets these layers to be un-trainable and prevents them from having their existing knowledge destroyed by the Transfer Learning process. - Append new layers to the frozen part of the model. These new layers can be trained and use the pre-trained weights to learn faster. - Train the new model on a new dataset.</p>"},{"location":"articles/Scalar/Transfer%20Learning%20and%20Fine-tuning/#implementation","title":"Implementation","text":"<p>This article will explore how to take a model trained on ImageNet and fine-tune it on new data. We will create this implementation in Tensorflow and use the Cats and Dogs dataset from Kaggle.</p>"},{"location":"articles/Scalar/Transfer%20Learning%20and%20Fine-tuning/#pre-requisites","title":"Pre-Requisites.","text":"<p>Before we can fine-tune a model, we must decide what base model we need. We also need to load and preprocess the dataset. Since Transfer Learning is generally used for small datasets, we take a subset of the Cats and Dogs dataset for this example.</p>"},{"location":"articles/Scalar/Transfer%20Learning%20and%20Fine-tuning/#imports","title":"Imports","text":"<p>We first import the required libraries. We use Tensorflow for the entire pipeline. </p> <pre><code>import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_datasets as tfds\nimport os\nimport zipfile\n</code></pre>"},{"location":"articles/Scalar/Transfer%20Learning%20and%20Fine-tuning/#loading-the-data","title":"Loading the Data","text":"<p>Since the Cats and Dogs dataset is not a part of Tensorflow, we download it from Kaggle and then use the tensorflow_datasets library to load it into memory. After loading, we split the data into train and test while also sub-setting it.</p> <pre><code>train_dataset, validation_dataset, test_dataset = tfds.load(\n    \"cats_vs_dogs\",\n    split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n    as_supervised=True,\n)\n</code></pre> <p>An example subset of the data is shown below. [IMAGE {1} CatsDogs START SAMPLE]  [IMAGE {1} FINISH SAMPLE]</p> <p>We can then convert the data into batches, split them into data loaders, and optimize the data loading using caching and pre-fetching. We use a batch size of 32 for this example. After loading, we can also apply some simple data augmentation methods. For example, we use Random Horizontal Flipping and Random Rotation.</p> <pre><code>size = (150, 150)\nbs = 32\naug_transforms = keras.Sequential(\n    [layers.RandomFlip(\"horizontal\"), layers.RandomRotation(0.1),]\n)\n\ntrain_dataset = train_dataset.map(lambda x, y: (tf.image.resize(x, size), y))\nvalidation_dataset = validation_dataset.map(lambda x, y: (tf.image.resize(x, size), y))\ntest_dataset = test_dataset.map(lambda x, y: (tf.image.resize(x, size), y))\n\n\ntrain_dataset = train_dataset.cache().batch(bs).prefetch(buffer_size=10)\nvalidation_dataset = validation_dataset.cache().batch(bs).prefetch(buffer_size=10)\ntest_dataset = test_dataset.cache().batch(bs).prefetch(buffer_size=10)\n</code></pre> <p>This article uses an ../../Xception|Xception model pre-trained on the ImageNet dataset and applied to images 150x150x3 in size. The important point is to exclude the pre-trained model's final classification layer. This final layer is just for classification, and we only care about the layers before it.</p> <pre><code>model_pretrained = keras.applications.Xception(\n    weights=\"imagenet\", \n    input_shape=(150, 150, 3),\n    include_top=False,\n)\n</code></pre> <p>The ../../Xception|Xception model architecture is shown here. [IMAGE {2} arch START SAMPLE]  [IMAGE {2} FINISH SAMPLE]</p>"},{"location":"articles/Scalar/Transfer%20Learning%20and%20Fine-tuning/#fine-tuning","title":"Fine-Tuning","text":"<p>Now, we freeze the layers of the model we just loaded by setting the trainable parameter to False. After that, we create a model on top of the frozen layers and apply the data augmentations we defined. The ../../Xception|Xception model's caveat is that it defines the inputs are scaled from the original range of (0,255) to the range of (-1.0, 1.0). We perform this rescaling using the Rescaling layer as follows.</p> <pre><code>model_pretrained.trainable = False\n\ninputs = keras.Input(shape=(150, 150, 3))\nrescale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n\nx = aug_transforms(inputs) \nx = rescale_layer(x)\n</code></pre>"},{"location":"articles/Scalar/Transfer%20Learning%20and%20Fine-tuning/#unfreeze-the-top-layers-of-the-model","title":"Unfreeze the top layers of the model","text":"<p>The [../../Xception|Xception] model also contains Batch Normalization layers that should not be trained when the model is unfrozen. To make sure this is the case, we disable the training mode. We also apply a GlobalAveragePooling followed by ../../Dropout|Dropout layers to improve performance further. Global Average Pooling is an alternative to the Fully Connected layer (FC) that preserves spatial information better. Since our pre-trained model uses different data, these layers are useful here. The final layer is an FC layer for a binary classification task. </p> <pre><code>x = model_pretrained(x, training=False)\nx = keras.layers.GlobalAveragePooling2D()(x)\nx = keras.layers.Dropout(0.2)(x) \n\noutputs = keras.layers.Dense(1)(x)\nfinal_model = keras.Model(inputs, outputs)\n</code></pre> <p>We can now train the new layers that we created.</p> <pre><code>final_model.compile(\n    optimizer=keras.optimizers.Adam(),\n    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n    metrics=[keras.metrics.BinaryAccuracy()],\n)\n\nnum_epochs = 5\nfinal_model.fit(train_dataset, epochs=num_epochs, validation_data=validation_dataset)\n</code></pre> <p>Now that we trained the new layers, we unfreeze the entire model and then train it with a very small learning rate. This gradual training leads to much better performance. Note that the Batch Normalization layers are not updating during this training, as if they did, it would badly hurt performance.</p> <pre><code>model_pretrained.trainable = True\nfinal_model.summary()\n\nfinal_model.compile(\n    optimizer=keras.optimizers.Adam(1e-5),\n    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n    metrics=[keras.metrics.BinaryAccuracy()],\n)\n\nnum_epochs = 5\nfinal_model.fit(train_dataset, epochs=num_epochs, validation_data=validation_dataset)\n</code></pre>"},{"location":"articles/Scalar/Transfer%20Learning%20and%20Fine-tuning/#evaluation-and-prediction","title":"Evaluation and prediction","text":"<p>This example shows how useful Transfer Learning is for quickly training small datasets. After training the model, we evaluate the test dataset. The model still performs quite well despite the few training epochs and fewer data.  [IMAGE {3} Results START SAMPLE]  [IMAGE {3} FINISH SAMPLE]</p> <p>::: :::section{.summary}</p>"},{"location":"articles/Scalar/Transfer%20Learning%20and%20Fine-tuning/#conclusion","title":"Conclusion","text":"<ul> <li>Transfer Learning is a powerful method when fewer data is present.</li> <li>As long as the pre-trained model uses similar data, a niche model can be fine-tuned using it.</li> <li>Selectively freezing the pre-trained layers and training the rest is a way to achieve the effects of fine-tuning.</li> <li>After an initial round of selective training, unfreezing the model and training the entire model improves performance.</li> <li>The Transfer Learning approach is thus an invaluable breakthrough in Deep Learning. :::</li> </ul>"}]}