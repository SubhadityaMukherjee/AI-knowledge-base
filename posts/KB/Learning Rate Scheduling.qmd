---
categories: ['temp']
title: Learning Rate Scheduling
date modified: Monday, October 10th 2022, 2:02:23 pm
date created: Tuesday, July 26th 2022, 8:33:15 pm
---

# Learning Rate [Scheduling](Scheduling.qmd)
- [Learning Rate Decay tricks](Learning%20Rate%20Decay%20tricks.qmd)
- [Gradient Descent gradients](Gradient%20Descent%20gradients.qmd)
- Increasing the batch size, reduces noise in the #gradients so a larger learning rate is okay
- [Linear Learning Rate Scaling](Linear%20Learning%20Rate%20Scaling.qmd)
- [Learning Rate Warmup](Learning%20Rate%20Warmup.qmd)



