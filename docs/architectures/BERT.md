---
title: BERT
---

# BERT
- Bidirectional Encoder rep from transformers
- [[Self supervised]]
- Masked language modeling, next sentence prediction
- ![[Pasted image 20220307183916.png]]
- [CLS] : start of classification task, [SEP] between sentences, [MASK] : masked token









