---
tags: temp
title: Features
date modified: Wednesday, August 10th 2022, 11:41:29 am
date created: Tuesday, July 26th 2022, 8:33:15 pm
---

# Features

## Dimensions

### Wide
- Had to train
- More number of neurons
- Easy parallel
- Infinitely wide -> Gaussian process

### Deep
- Easier to train
- Less data
- Linear amount
- Difficult to parallelize

## Why
- Domain Adaptation
- Structure exploitation
- Relevant features

## Random Things
- 1 hidden layer [Perceptron](Perceptron.md) -> Universal fn estimator
- Best generalization -> First order optimization

